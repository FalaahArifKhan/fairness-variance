{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa3300c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c64872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:55:54.052462Z",
     "start_time": "2024-01-06T10:55:54.038357Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "619e9cd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:56:09.679156Z",
     "start_time": "2024-01-06T10:56:09.668186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de831b15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.457257Z",
     "start_time": "2024-01-06T11:15:26.114625Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b566957c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.466361Z",
     "start_time": "2024-01-06T11:15:26.457627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0d832a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.478005Z",
     "start_time": "2024-01-06T11:15:26.467253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/dh3553/projects/fairness-variance\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e85bf1",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1094639e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.734704Z",
     "start_time": "2024-01-06T11:15:28.036691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import ACSIncomeDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_inprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77759409",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbc40b14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.772286Z",
     "start_time": "2024-01-06T11:15:31.735883Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'ADB_acs_income'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIRNESS_INTERVENTION_NAME = 'ADB'\n",
    "FAIR_INTERVENTION_PARAMS_LST = ['debiased_classifier']\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                     FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, 'folk_GA_2018_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5631dce1",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f99b566",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.813421Z",
     "start_time": "2024-01-06T11:15:31.771935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairness_variance'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "509b7d3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.096974Z",
     "start_time": "2024-01-06T11:15:31.811395Z"
    }
   },
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da024da6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.138747Z",
     "start_time": "2024-01-06T11:15:32.097343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current session uuid:  bbba3cc4-760b-4e93-bb97-3a2077202cce\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d986e7",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5db71e26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:33.528732Z",
     "start_time": "2024-01-06T11:15:33.475702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL</th>\n",
       "      <th>COW</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>RELP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>WKHP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>230</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4110</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4130</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4020</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8300</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SCHL COW MAR  OCCP POBP RELP SEX RAC1P  AGEP  WKHP\n",
       "0   23   7   3   230   36    0   1     1    55  55.0\n",
       "1   16   1   5  4110   13    2   2     1    20  35.0\n",
       "2   16   4   3  4130   51    0   2     1    59  30.0\n",
       "3   18   4   1  4020   13    0   1     2    43  40.0\n",
       "4   14   1   1  8300   20    1   2     2    33  20.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = ACSIncomeDataset(state=['GA'], year=2018, with_nulls=False,\n",
    "                               subsample_size=15_000, subsample_seed=42)\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3846b13f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:34.580537Z",
     "start_time": "2024-01-06T11:15:34.538952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa04b2c",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0914dd8",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c24f19a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:37.135031Z",
     "start_time": "2024-01-06T11:15:37.105079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a662b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:44.618835Z",
     "start_time": "2024-01-06T11:15:43.745040Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:04:06 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 100,\n",
      " 'experiment_iteration': 'Exp_iter_1',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 100,\n",
      " 'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc38ee9c876469caefd18438ec5bf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:04:06 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=724)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0a941737a8417cb4f7946d88b35431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8c917d6c174359aff6c81106515faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.703511; batch adversarial loss: 0.868435\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433493; batch adversarial loss: 0.870017\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396227; batch adversarial loss: 0.863279\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393296; batch adversarial loss: 0.784595\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335170; batch adversarial loss: 0.729312\n",
      "epoch 5; iter: 0; batch classifier loss: 0.302273; batch adversarial loss: 0.718420\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340553; batch adversarial loss: 0.671042\n",
      "epoch 7; iter: 0; batch classifier loss: 0.317702; batch adversarial loss: 0.662751\n",
      "epoch 8; iter: 0; batch classifier loss: 0.252170; batch adversarial loss: 0.648393\n",
      "epoch 9; iter: 0; batch classifier loss: 0.292380; batch adversarial loss: 0.613334\n",
      "epoch 10; iter: 0; batch classifier loss: 0.278500; batch adversarial loss: 0.582467\n",
      "epoch 11; iter: 0; batch classifier loss: 0.315808; batch adversarial loss: 0.541661\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282857; batch adversarial loss: 0.547508\n",
      "epoch 13; iter: 0; batch classifier loss: 0.245198; batch adversarial loss: 0.570313\n",
      "epoch 14; iter: 0; batch classifier loss: 0.295288; batch adversarial loss: 0.471533\n",
      "epoch 15; iter: 0; batch classifier loss: 0.255773; batch adversarial loss: 0.471669\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227866; batch adversarial loss: 0.459387\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265236; batch adversarial loss: 0.390383\n",
      "epoch 18; iter: 0; batch classifier loss: 0.221451; batch adversarial loss: 0.492176\n",
      "epoch 19; iter: 0; batch classifier loss: 0.235272; batch adversarial loss: 0.424545\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222551; batch adversarial loss: 0.393122\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149757; batch adversarial loss: 0.495092\n",
      "epoch 22; iter: 0; batch classifier loss: 0.181218; batch adversarial loss: 0.386822\n",
      "epoch 23; iter: 0; batch classifier loss: 0.139735; batch adversarial loss: 0.457702\n",
      "epoch 24; iter: 0; batch classifier loss: 0.153798; batch adversarial loss: 0.475582\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132027; batch adversarial loss: 0.444322\n",
      "epoch 26; iter: 0; batch classifier loss: 0.129947; batch adversarial loss: 0.370190\n",
      "epoch 27; iter: 0; batch classifier loss: 0.140482; batch adversarial loss: 0.350910\n",
      "epoch 28; iter: 0; batch classifier loss: 0.166366; batch adversarial loss: 0.481889\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178009; batch adversarial loss: 0.357132\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774951fe",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abb3b5f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EXPERIMENT_SEEDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Configs for an experiment iteration\u001b[39;00m\n\u001b[1;32m      2\u001b[0m exp_iter_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 3\u001b[0m experiment_seed \u001b[38;5;241m=\u001b[39m \u001b[43mEXPERIMENT_SEEDS\u001b[49m[exp_iter_num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m tuned_params_filenames \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      6\u001b[0m tuned_params_df_paths \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_fairness_interventions_exp\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                       FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, tuned_params_filename)\n\u001b[1;32m      8\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m tuned_params_filename \u001b[38;5;129;01min\u001b[39;00m tuned_params_filenames]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EXPERIMENT_SEEDS' is not defined"
     ]
    }
   ],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b52fb564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:56.249510Z",
     "start_time": "2024-01-04T20:53:56.233525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 17:15:39 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 200,\n",
      " 'experiment_iteration': 'Exp_iter_2',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 200,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5645c6009d3b48d29619a238bc476502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 17:15:39 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 17:15:39 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([322, 293, 576, 300, 391, 343, 294, 558, 560, 439, 355, 440, 277,\n",
      "            492, 644, 639, 589, 259, 313, 129],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([322, 293, 576, 300, 391, 343, 294, 558, 560, 439, 355, 440, 277,\n",
      "            492, 644, 639, 589, 259, 313, 129],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 200, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c0277603884950a0c35cc9dcc3f539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7137564e8e0d4fcbbbfaaf03d73e170a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa30ab3dbbfe4acb8557a8c1e2d6556b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a36e32d08b44c1b01ae496881c6b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac2ecae",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c1adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aa7bbde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:46.750905Z",
     "start_time": "2024-01-04T20:53:46.744795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:05:20 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 300,\n",
      " 'experiment_iteration': 'Exp_iter_3',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 300,\n",
      " 'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd71aaca46bd49848758500a4ec45e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:05:20 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=728)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 4329,   723,  8157,  8934,  5880,  1877,  9980,  9115, 13634,\n",
      "            12168,  6957,  9083, 14260,  5349,  7879,  3078, 10032, 13643,\n",
      "            12025,  7489],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 4329,   723,  8157,  8934,  5880,  1877,  9980,  9115, 13634,\n",
      "            12168,  6957,  9083, 14260,  5349,  7879,  3078, 10032, 13643,\n",
      "            12025,  7489],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f73ff0d065a49c881be658ae00c8b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4c71d0adf44b5298a649831384b7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.712449; batch adversarial loss: 0.612325\n",
      "epoch 1; iter: 0; batch classifier loss: 0.407294; batch adversarial loss: 0.625717\n",
      "epoch 2; iter: 0; batch classifier loss: 0.414136; batch adversarial loss: 0.564792\n",
      "epoch 3; iter: 0; batch classifier loss: 0.361810; batch adversarial loss: 0.544649\n",
      "epoch 4; iter: 0; batch classifier loss: 0.288210; batch adversarial loss: 0.543436\n",
      "epoch 5; iter: 0; batch classifier loss: 0.386532; batch adversarial loss: 0.518284\n",
      "epoch 6; iter: 0; batch classifier loss: 0.297419; batch adversarial loss: 0.572795\n",
      "epoch 7; iter: 0; batch classifier loss: 0.309227; batch adversarial loss: 0.477846\n",
      "epoch 8; iter: 0; batch classifier loss: 0.268266; batch adversarial loss: 0.485256\n",
      "epoch 9; iter: 0; batch classifier loss: 0.260124; batch adversarial loss: 0.560126\n",
      "epoch 10; iter: 0; batch classifier loss: 0.314201; batch adversarial loss: 0.465653\n",
      "epoch 11; iter: 0; batch classifier loss: 0.241053; batch adversarial loss: 0.486562\n",
      "epoch 12; iter: 0; batch classifier loss: 0.215618; batch adversarial loss: 0.468523\n",
      "epoch 13; iter: 0; batch classifier loss: 0.243792; batch adversarial loss: 0.494496\n",
      "epoch 14; iter: 0; batch classifier loss: 0.196501; batch adversarial loss: 0.472422\n",
      "epoch 15; iter: 0; batch classifier loss: 0.226821; batch adversarial loss: 0.594564\n",
      "epoch 16; iter: 0; batch classifier loss: 0.270699; batch adversarial loss: 0.527505\n",
      "epoch 17; iter: 0; batch classifier loss: 0.287986; batch adversarial loss: 0.479877\n",
      "epoch 18; iter: 0; batch classifier loss: 0.232158; batch adversarial loss: 0.566356\n",
      "epoch 19; iter: 0; batch classifier loss: 0.297663; batch adversarial loss: 0.540767\n",
      "epoch 20; iter: 0; batch classifier loss: 0.269359; batch adversarial loss: 0.547492\n",
      "epoch 21; iter: 0; batch classifier loss: 0.288404; batch adversarial loss: 0.484026\n",
      "epoch 22; iter: 0; batch classifier loss: 0.428921; batch adversarial loss: 0.530613\n",
      "epoch 23; iter: 0; batch classifier loss: 0.409481; batch adversarial loss: 0.402865\n",
      "epoch 24; iter: 0; batch classifier loss: 0.246020; batch adversarial loss: 0.508659\n",
      "epoch 25; iter: 0; batch classifier loss: 0.180831; batch adversarial loss: 0.491510\n",
      "epoch 26; iter: 0; batch classifier loss: 0.144345; batch adversarial loss: 0.565471\n",
      "epoch 27; iter: 0; batch classifier loss: 0.143091; batch adversarial loss: 0.475226\n",
      "epoch 28; iter: 0; batch classifier loss: 0.122716; batch adversarial loss: 0.506123\n",
      "epoch 29; iter: 0; batch classifier loss: 0.102358; batch adversarial loss: 0.402040\n",
      "epoch 30; iter: 0; batch classifier loss: 0.132452; batch adversarial loss: 0.514725\n",
      "epoch 31; iter: 0; batch classifier loss: 0.101077; batch adversarial loss: 0.392108\n",
      "epoch 32; iter: 0; batch classifier loss: 0.144052; batch adversarial loss: 0.424612\n",
      "epoch 33; iter: 0; batch classifier loss: 0.099980; batch adversarial loss: 0.498366\n",
      "epoch 34; iter: 0; batch classifier loss: 0.112015; batch adversarial loss: 0.471385\n",
      "epoch 35; iter: 0; batch classifier loss: 0.177548; batch adversarial loss: 0.543244\n",
      "epoch 36; iter: 0; batch classifier loss: 0.146579; batch adversarial loss: 0.437729\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113618; batch adversarial loss: 0.493970\n",
      "epoch 38; iter: 0; batch classifier loss: 0.164356; batch adversarial loss: 0.432598\n",
      "epoch 39; iter: 0; batch classifier loss: 0.103700; batch adversarial loss: 0.445680\n",
      "epoch 40; iter: 0; batch classifier loss: 0.119440; batch adversarial loss: 0.499749\n",
      "epoch 41; iter: 0; batch classifier loss: 0.078097; batch adversarial loss: 0.538856\n",
      "epoch 42; iter: 0; batch classifier loss: 0.086516; batch adversarial loss: 0.496715\n",
      "epoch 43; iter: 0; batch classifier loss: 0.109820; batch adversarial loss: 0.464573\n",
      "epoch 44; iter: 0; batch classifier loss: 0.115123; batch adversarial loss: 0.455271\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097536; batch adversarial loss: 0.476336\n",
      "epoch 46; iter: 0; batch classifier loss: 0.089119; batch adversarial loss: 0.427186\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096750; batch adversarial loss: 0.507459\n",
      "epoch 48; iter: 0; batch classifier loss: 0.111337; batch adversarial loss: 0.456874\n",
      "epoch 49; iter: 0; batch classifier loss: 0.085294; batch adversarial loss: 0.446828\n",
      "epoch 50; iter: 0; batch classifier loss: 0.093290; batch adversarial loss: 0.534642\n",
      "epoch 51; iter: 0; batch classifier loss: 0.065628; batch adversarial loss: 0.483840\n",
      "epoch 52; iter: 0; batch classifier loss: 0.091787; batch adversarial loss: 0.447394\n",
      "epoch 53; iter: 0; batch classifier loss: 0.121420; batch adversarial loss: 0.472362\n",
      "epoch 54; iter: 0; batch classifier loss: 0.159109; batch adversarial loss: 0.369347\n",
      "epoch 55; iter: 0; batch classifier loss: 0.094133; batch adversarial loss: 0.420673\n",
      "epoch 56; iter: 0; batch classifier loss: 0.100414; batch adversarial loss: 0.452758\n",
      "epoch 57; iter: 0; batch classifier loss: 0.119083; batch adversarial loss: 0.412013\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090936; batch adversarial loss: 0.547777\n",
      "epoch 59; iter: 0; batch classifier loss: 0.092891; batch adversarial loss: 0.419214\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122256; batch adversarial loss: 0.489748\n",
      "epoch 61; iter: 0; batch classifier loss: 0.079566; batch adversarial loss: 0.463628\n",
      "epoch 62; iter: 0; batch classifier loss: 0.083283; batch adversarial loss: 0.425812\n",
      "epoch 63; iter: 0; batch classifier loss: 0.091382; batch adversarial loss: 0.364738\n",
      "epoch 64; iter: 0; batch classifier loss: 0.054622; batch adversarial loss: 0.427161\n",
      "epoch 65; iter: 0; batch classifier loss: 0.056137; batch adversarial loss: 0.463484\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085346; batch adversarial loss: 0.423004\n",
      "epoch 67; iter: 0; batch classifier loss: 0.048157; batch adversarial loss: 0.407600\n",
      "epoch 68; iter: 0; batch classifier loss: 0.079966; batch adversarial loss: 0.489812\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094214; batch adversarial loss: 0.463804\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078887; batch adversarial loss: 0.375812\n",
      "epoch 71; iter: 0; batch classifier loss: 0.049934; batch adversarial loss: 0.491805\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064701; batch adversarial loss: 0.398974\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076822; batch adversarial loss: 0.346942\n",
      "epoch 74; iter: 0; batch classifier loss: 0.108684; batch adversarial loss: 0.463640\n",
      "epoch 75; iter: 0; batch classifier loss: 0.120567; batch adversarial loss: 0.467340\n",
      "epoch 76; iter: 0; batch classifier loss: 0.149908; batch adversarial loss: 0.484445\n",
      "epoch 77; iter: 0; batch classifier loss: 0.100105; batch adversarial loss: 0.468677\n",
      "epoch 78; iter: 0; batch classifier loss: 0.087733; batch adversarial loss: 0.463071\n",
      "epoch 79; iter: 0; batch classifier loss: 0.047644; batch adversarial loss: 0.430615\n",
      "epoch 80; iter: 0; batch classifier loss: 0.037152; batch adversarial loss: 0.425191\n",
      "epoch 81; iter: 0; batch classifier loss: 0.124684; batch adversarial loss: 0.435010\n",
      "epoch 82; iter: 0; batch classifier loss: 0.082762; batch adversarial loss: 0.454876\n",
      "epoch 83; iter: 0; batch classifier loss: 0.103173; batch adversarial loss: 0.401615\n",
      "epoch 84; iter: 0; batch classifier loss: 0.145040; batch adversarial loss: 0.444871\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059374; batch adversarial loss: 0.474095\n",
      "epoch 86; iter: 0; batch classifier loss: 0.071653; batch adversarial loss: 0.419076\n",
      "epoch 87; iter: 0; batch classifier loss: 0.030676; batch adversarial loss: 0.365188\n",
      "epoch 88; iter: 0; batch classifier loss: 0.095254; batch adversarial loss: 0.348559\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065115; batch adversarial loss: 0.478049\n",
      "epoch 90; iter: 0; batch classifier loss: 0.087047; batch adversarial loss: 0.425206\n",
      "epoch 91; iter: 0; batch classifier loss: 0.044428; batch adversarial loss: 0.553769\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070752; batch adversarial loss: 0.453587\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061630; batch adversarial loss: 0.417107\n",
      "epoch 94; iter: 0; batch classifier loss: 0.086486; batch adversarial loss: 0.531823\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068484; batch adversarial loss: 0.517707\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058087; batch adversarial loss: 0.503601\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063183; batch adversarial loss: 0.465105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.082042; batch adversarial loss: 0.406133\n",
      "epoch 99; iter: 0; batch classifier loss: 0.087972; batch adversarial loss: 0.456496\n",
      "epoch 100; iter: 0; batch classifier loss: 0.073395; batch adversarial loss: 0.448079\n",
      "epoch 101; iter: 0; batch classifier loss: 0.067503; batch adversarial loss: 0.456347\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066094; batch adversarial loss: 0.481233\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041966; batch adversarial loss: 0.520371\n",
      "epoch 104; iter: 0; batch classifier loss: 0.090569; batch adversarial loss: 0.447273\n",
      "epoch 105; iter: 0; batch classifier loss: 0.028340; batch adversarial loss: 0.537231\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042836; batch adversarial loss: 0.480278\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052036; batch adversarial loss: 0.513140\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069494; batch adversarial loss: 0.437493\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060692; batch adversarial loss: 0.425448\n",
      "epoch 110; iter: 0; batch classifier loss: 0.080727; batch adversarial loss: 0.451005\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050503; batch adversarial loss: 0.313759\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046054; batch adversarial loss: 0.425038\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053893; batch adversarial loss: 0.425974\n",
      "epoch 114; iter: 0; batch classifier loss: 0.066314; batch adversarial loss: 0.431372\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062429; batch adversarial loss: 0.457194\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060046; batch adversarial loss: 0.409112\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033642; batch adversarial loss: 0.404307\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029360; batch adversarial loss: 0.466230\n",
      "epoch 119; iter: 0; batch classifier loss: 0.072909; batch adversarial loss: 0.349554\n",
      "epoch 120; iter: 0; batch classifier loss: 0.060790; batch adversarial loss: 0.423883\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029321; batch adversarial loss: 0.430766\n",
      "epoch 122; iter: 0; batch classifier loss: 0.061772; batch adversarial loss: 0.401725\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025746; batch adversarial loss: 0.379690\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038968; batch adversarial loss: 0.491307\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052306; batch adversarial loss: 0.445321\n",
      "epoch 126; iter: 0; batch classifier loss: 0.073191; batch adversarial loss: 0.528734\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022112; batch adversarial loss: 0.446271\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028079; batch adversarial loss: 0.466262\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036039; batch adversarial loss: 0.464092\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017407; batch adversarial loss: 0.414456\n",
      "epoch 131; iter: 0; batch classifier loss: 0.016661; batch adversarial loss: 0.396068\n",
      "epoch 132; iter: 0; batch classifier loss: 0.055359; batch adversarial loss: 0.364486\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040794; batch adversarial loss: 0.479580\n",
      "epoch 134; iter: 0; batch classifier loss: 0.046697; batch adversarial loss: 0.521264\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028806; batch adversarial loss: 0.479092\n",
      "epoch 136; iter: 0; batch classifier loss: 0.015963; batch adversarial loss: 0.491378\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037806; batch adversarial loss: 0.469369\n",
      "epoch 138; iter: 0; batch classifier loss: 0.042625; batch adversarial loss: 0.415153\n",
      "epoch 139; iter: 0; batch classifier loss: 0.054971; batch adversarial loss: 0.394826\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036494; batch adversarial loss: 0.521342\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022296; batch adversarial loss: 0.346004\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026180; batch adversarial loss: 0.455020\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011330; batch adversarial loss: 0.432997\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017393; batch adversarial loss: 0.519918\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030497; batch adversarial loss: 0.484386\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015111; batch adversarial loss: 0.512666\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025002; batch adversarial loss: 0.488871\n",
      "epoch 148; iter: 0; batch classifier loss: 0.005546; batch adversarial loss: 0.480716\n",
      "epoch 149; iter: 0; batch classifier loss: 0.104375; batch adversarial loss: 0.458985\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012402; batch adversarial loss: 0.462491\n",
      "epoch 151; iter: 0; batch classifier loss: 0.045208; batch adversarial loss: 0.556167\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011151; batch adversarial loss: 0.336980\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031954; batch adversarial loss: 0.375144\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032643; batch adversarial loss: 0.458868\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027582; batch adversarial loss: 0.342888\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014015; batch adversarial loss: 0.541990\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012684; batch adversarial loss: 0.458803\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035808; batch adversarial loss: 0.447900\n",
      "epoch 159; iter: 0; batch classifier loss: 0.057201; batch adversarial loss: 0.460285\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014800; batch adversarial loss: 0.459107\n",
      "epoch 161; iter: 0; batch classifier loss: 0.075670; batch adversarial loss: 0.522596\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033861; batch adversarial loss: 0.409563\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037234; batch adversarial loss: 0.424690\n",
      "epoch 164; iter: 0; batch classifier loss: 0.051285; batch adversarial loss: 0.469498\n",
      "epoch 165; iter: 0; batch classifier loss: 0.048500; batch adversarial loss: 0.538068\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032848; batch adversarial loss: 0.552482\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029058; batch adversarial loss: 0.474552\n",
      "epoch 168; iter: 0; batch classifier loss: 0.056924; batch adversarial loss: 0.414611\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024289; batch adversarial loss: 0.458812\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022492; batch adversarial loss: 0.500359\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021598; batch adversarial loss: 0.411714\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040825; batch adversarial loss: 0.392859\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025346; batch adversarial loss: 0.535288\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027058; batch adversarial loss: 0.366840\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041937; batch adversarial loss: 0.444598\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017818; batch adversarial loss: 0.497407\n",
      "epoch 177; iter: 0; batch classifier loss: 0.052103; batch adversarial loss: 0.407688\n",
      "epoch 178; iter: 0; batch classifier loss: 0.036655; batch adversarial loss: 0.456493\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039321; batch adversarial loss: 0.496743\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011033; batch adversarial loss: 0.499300\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017952; batch adversarial loss: 0.473511\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028681; batch adversarial loss: 0.472965\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033801; batch adversarial loss: 0.459965\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012559; batch adversarial loss: 0.515288\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014498; batch adversarial loss: 0.444328\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015225; batch adversarial loss: 0.426547\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018059; batch adversarial loss: 0.496962\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018205; batch adversarial loss: 0.485703\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008672; batch adversarial loss: 0.559631\n",
      "epoch 190; iter: 0; batch classifier loss: 0.042005; batch adversarial loss: 0.535681\n",
      "epoch 191; iter: 0; batch classifier loss: 0.069765; batch adversarial loss: 0.450565\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012318; batch adversarial loss: 0.371491\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019608; batch adversarial loss: 0.480707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.016758; batch adversarial loss: 0.466198\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016671; batch adversarial loss: 0.426396\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007005; batch adversarial loss: 0.437108\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017319; batch adversarial loss: 0.526108\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015683; batch adversarial loss: 0.391922\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008987; batch adversarial loss: 0.405147\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695507; batch adversarial loss: 0.647855\n",
      "epoch 1; iter: 0; batch classifier loss: 0.446975; batch adversarial loss: 0.627431\n",
      "epoch 2; iter: 0; batch classifier loss: 0.447916; batch adversarial loss: 0.637104\n",
      "epoch 3; iter: 0; batch classifier loss: 0.459073; batch adversarial loss: 0.617969\n",
      "epoch 4; iter: 0; batch classifier loss: 0.506349; batch adversarial loss: 0.580998\n",
      "epoch 5; iter: 0; batch classifier loss: 0.437770; batch adversarial loss: 0.597041\n",
      "epoch 6; iter: 0; batch classifier loss: 0.437695; batch adversarial loss: 0.572287\n",
      "epoch 7; iter: 0; batch classifier loss: 0.385935; batch adversarial loss: 0.565688\n",
      "epoch 8; iter: 0; batch classifier loss: 0.308104; batch adversarial loss: 0.532480\n",
      "epoch 9; iter: 0; batch classifier loss: 0.323963; batch adversarial loss: 0.534272\n",
      "epoch 10; iter: 0; batch classifier loss: 0.308381; batch adversarial loss: 0.498483\n",
      "epoch 11; iter: 0; batch classifier loss: 0.321903; batch adversarial loss: 0.592769\n",
      "epoch 12; iter: 0; batch classifier loss: 0.261391; batch adversarial loss: 0.539817\n",
      "epoch 13; iter: 0; batch classifier loss: 0.253448; batch adversarial loss: 0.564136\n",
      "epoch 14; iter: 0; batch classifier loss: 0.206995; batch adversarial loss: 0.532763\n",
      "epoch 15; iter: 0; batch classifier loss: 0.252504; batch adversarial loss: 0.465427\n",
      "epoch 16; iter: 0; batch classifier loss: 0.224112; batch adversarial loss: 0.497870\n",
      "epoch 17; iter: 0; batch classifier loss: 0.248738; batch adversarial loss: 0.435859\n",
      "epoch 18; iter: 0; batch classifier loss: 0.149088; batch adversarial loss: 0.468210\n",
      "epoch 19; iter: 0; batch classifier loss: 0.135289; batch adversarial loss: 0.449925\n",
      "epoch 20; iter: 0; batch classifier loss: 0.103951; batch adversarial loss: 0.561248\n",
      "epoch 21; iter: 0; batch classifier loss: 0.190078; batch adversarial loss: 0.446728\n",
      "epoch 22; iter: 0; batch classifier loss: 0.174638; batch adversarial loss: 0.512601\n",
      "epoch 23; iter: 0; batch classifier loss: 0.204691; batch adversarial loss: 0.434997\n",
      "epoch 24; iter: 0; batch classifier loss: 0.175712; batch adversarial loss: 0.464115\n",
      "epoch 25; iter: 0; batch classifier loss: 0.126078; batch adversarial loss: 0.427486\n",
      "epoch 26; iter: 0; batch classifier loss: 0.133962; batch adversarial loss: 0.510861\n",
      "epoch 27; iter: 0; batch classifier loss: 0.126183; batch adversarial loss: 0.469357\n",
      "epoch 28; iter: 0; batch classifier loss: 0.168007; batch adversarial loss: 0.486050\n",
      "epoch 29; iter: 0; batch classifier loss: 0.118453; batch adversarial loss: 0.399764\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167683; batch adversarial loss: 0.445931\n",
      "epoch 31; iter: 0; batch classifier loss: 0.142647; batch adversarial loss: 0.516007\n",
      "epoch 32; iter: 0; batch classifier loss: 0.105300; batch adversarial loss: 0.462053\n",
      "epoch 33; iter: 0; batch classifier loss: 0.119219; batch adversarial loss: 0.514822\n",
      "epoch 34; iter: 0; batch classifier loss: 0.113282; batch adversarial loss: 0.469004\n",
      "epoch 35; iter: 0; batch classifier loss: 0.106087; batch adversarial loss: 0.536186\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140150; batch adversarial loss: 0.537350\n",
      "epoch 37; iter: 0; batch classifier loss: 0.058730; batch adversarial loss: 0.477117\n",
      "epoch 38; iter: 0; batch classifier loss: 0.110321; batch adversarial loss: 0.484581\n",
      "epoch 39; iter: 0; batch classifier loss: 0.103962; batch adversarial loss: 0.452214\n",
      "epoch 40; iter: 0; batch classifier loss: 0.056775; batch adversarial loss: 0.480054\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125737; batch adversarial loss: 0.414444\n",
      "epoch 42; iter: 0; batch classifier loss: 0.080600; batch adversarial loss: 0.483303\n",
      "epoch 43; iter: 0; batch classifier loss: 0.099695; batch adversarial loss: 0.535989\n",
      "epoch 44; iter: 0; batch classifier loss: 0.090088; batch adversarial loss: 0.414318\n",
      "epoch 45; iter: 0; batch classifier loss: 0.083643; batch adversarial loss: 0.559938\n",
      "epoch 46; iter: 0; batch classifier loss: 0.069263; batch adversarial loss: 0.464316\n",
      "epoch 47; iter: 0; batch classifier loss: 0.070716; batch adversarial loss: 0.469866\n",
      "epoch 48; iter: 0; batch classifier loss: 0.073876; batch adversarial loss: 0.485696\n",
      "epoch 49; iter: 0; batch classifier loss: 0.061163; batch adversarial loss: 0.458913\n",
      "epoch 50; iter: 0; batch classifier loss: 0.072866; batch adversarial loss: 0.492763\n",
      "epoch 51; iter: 0; batch classifier loss: 0.068099; batch adversarial loss: 0.511833\n",
      "epoch 52; iter: 0; batch classifier loss: 0.056206; batch adversarial loss: 0.514126\n",
      "epoch 53; iter: 0; batch classifier loss: 0.075769; batch adversarial loss: 0.355467\n",
      "epoch 54; iter: 0; batch classifier loss: 0.089479; batch adversarial loss: 0.459060\n",
      "epoch 55; iter: 0; batch classifier loss: 0.088097; batch adversarial loss: 0.395866\n",
      "epoch 56; iter: 0; batch classifier loss: 0.056402; batch adversarial loss: 0.577723\n",
      "epoch 57; iter: 0; batch classifier loss: 0.051494; batch adversarial loss: 0.426005\n",
      "epoch 58; iter: 0; batch classifier loss: 0.068065; batch adversarial loss: 0.419594\n",
      "epoch 59; iter: 0; batch classifier loss: 0.109446; batch adversarial loss: 0.400513\n",
      "epoch 60; iter: 0; batch classifier loss: 0.082812; batch adversarial loss: 0.459237\n",
      "epoch 61; iter: 0; batch classifier loss: 0.065135; batch adversarial loss: 0.436522\n",
      "epoch 62; iter: 0; batch classifier loss: 0.086340; batch adversarial loss: 0.457401\n",
      "epoch 63; iter: 0; batch classifier loss: 0.075361; batch adversarial loss: 0.458790\n",
      "epoch 64; iter: 0; batch classifier loss: 0.056464; batch adversarial loss: 0.467131\n",
      "epoch 65; iter: 0; batch classifier loss: 0.056650; batch adversarial loss: 0.460402\n",
      "epoch 66; iter: 0; batch classifier loss: 0.097273; batch adversarial loss: 0.394100\n",
      "epoch 67; iter: 0; batch classifier loss: 0.077817; batch adversarial loss: 0.443696\n",
      "epoch 68; iter: 0; batch classifier loss: 0.068475; batch adversarial loss: 0.534878\n",
      "epoch 69; iter: 0; batch classifier loss: 0.058795; batch adversarial loss: 0.505437\n",
      "epoch 70; iter: 0; batch classifier loss: 0.070113; batch adversarial loss: 0.504849\n",
      "epoch 71; iter: 0; batch classifier loss: 0.067006; batch adversarial loss: 0.537211\n",
      "epoch 72; iter: 0; batch classifier loss: 0.052112; batch adversarial loss: 0.446929\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047467; batch adversarial loss: 0.421354\n",
      "epoch 74; iter: 0; batch classifier loss: 0.041000; batch adversarial loss: 0.508349\n",
      "epoch 75; iter: 0; batch classifier loss: 0.043968; batch adversarial loss: 0.470907\n",
      "epoch 76; iter: 0; batch classifier loss: 0.054379; batch adversarial loss: 0.506129\n",
      "epoch 77; iter: 0; batch classifier loss: 0.059235; batch adversarial loss: 0.444376\n",
      "epoch 78; iter: 0; batch classifier loss: 0.053728; batch adversarial loss: 0.440628\n",
      "epoch 79; iter: 0; batch classifier loss: 0.026529; batch adversarial loss: 0.522424\n",
      "epoch 80; iter: 0; batch classifier loss: 0.053406; batch adversarial loss: 0.434396\n",
      "epoch 81; iter: 0; batch classifier loss: 0.048883; batch adversarial loss: 0.458623\n",
      "epoch 82; iter: 0; batch classifier loss: 0.038624; batch adversarial loss: 0.444078\n",
      "epoch 83; iter: 0; batch classifier loss: 0.037618; batch adversarial loss: 0.416118\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045750; batch adversarial loss: 0.489522\n",
      "epoch 85; iter: 0; batch classifier loss: 0.023664; batch adversarial loss: 0.447687\n",
      "epoch 86; iter: 0; batch classifier loss: 0.039178; batch adversarial loss: 0.437364\n",
      "epoch 87; iter: 0; batch classifier loss: 0.088766; batch adversarial loss: 0.438183\n",
      "epoch 88; iter: 0; batch classifier loss: 0.056153; batch adversarial loss: 0.513475\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065694; batch adversarial loss: 0.465387\n",
      "epoch 90; iter: 0; batch classifier loss: 0.082961; batch adversarial loss: 0.473021\n",
      "epoch 91; iter: 0; batch classifier loss: 0.042608; batch adversarial loss: 0.420899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.047510; batch adversarial loss: 0.455178\n",
      "epoch 93; iter: 0; batch classifier loss: 0.042036; batch adversarial loss: 0.498342\n",
      "epoch 94; iter: 0; batch classifier loss: 0.030207; batch adversarial loss: 0.440762\n",
      "epoch 95; iter: 0; batch classifier loss: 0.024937; batch adversarial loss: 0.492992\n",
      "epoch 96; iter: 0; batch classifier loss: 0.025202; batch adversarial loss: 0.433533\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077001; batch adversarial loss: 0.533414\n",
      "epoch 98; iter: 0; batch classifier loss: 0.028367; batch adversarial loss: 0.348728\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049811; batch adversarial loss: 0.413522\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039376; batch adversarial loss: 0.483007\n",
      "epoch 101; iter: 0; batch classifier loss: 0.030797; batch adversarial loss: 0.378191\n",
      "epoch 102; iter: 0; batch classifier loss: 0.069267; batch adversarial loss: 0.463010\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036012; batch adversarial loss: 0.409409\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027559; batch adversarial loss: 0.662135\n",
      "epoch 105; iter: 0; batch classifier loss: 0.025107; batch adversarial loss: 0.445737\n",
      "epoch 106; iter: 0; batch classifier loss: 0.015484; batch adversarial loss: 0.463526\n",
      "epoch 107; iter: 0; batch classifier loss: 0.019324; batch adversarial loss: 0.469856\n",
      "epoch 108; iter: 0; batch classifier loss: 0.029502; batch adversarial loss: 0.481006\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033278; batch adversarial loss: 0.468512\n",
      "epoch 110; iter: 0; batch classifier loss: 0.019984; batch adversarial loss: 0.482639\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041761; batch adversarial loss: 0.592785\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040513; batch adversarial loss: 0.528221\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034764; batch adversarial loss: 0.475176\n",
      "epoch 114; iter: 0; batch classifier loss: 0.045358; batch adversarial loss: 0.485667\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022781; batch adversarial loss: 0.540828\n",
      "epoch 116; iter: 0; batch classifier loss: 0.018084; batch adversarial loss: 0.518852\n",
      "epoch 117; iter: 0; batch classifier loss: 0.071734; batch adversarial loss: 0.464903\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046356; batch adversarial loss: 0.483081\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047635; batch adversarial loss: 0.499922\n",
      "epoch 120; iter: 0; batch classifier loss: 0.010243; batch adversarial loss: 0.474626\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048385; batch adversarial loss: 0.374776\n",
      "epoch 122; iter: 0; batch classifier loss: 0.024361; batch adversarial loss: 0.401434\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040299; batch adversarial loss: 0.438210\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021368; batch adversarial loss: 0.599248\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038157; batch adversarial loss: 0.462347\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048086; batch adversarial loss: 0.372095\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060626; batch adversarial loss: 0.468309\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056632; batch adversarial loss: 0.462779\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025663; batch adversarial loss: 0.506501\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041319; batch adversarial loss: 0.468811\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018292; batch adversarial loss: 0.536206\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020802; batch adversarial loss: 0.394624\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032352; batch adversarial loss: 0.533602\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028976; batch adversarial loss: 0.426241\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050924; batch adversarial loss: 0.401051\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020000; batch adversarial loss: 0.384583\n",
      "epoch 137; iter: 0; batch classifier loss: 0.019373; batch adversarial loss: 0.387886\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024547; batch adversarial loss: 0.477005\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014217; batch adversarial loss: 0.492512\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013864; batch adversarial loss: 0.426290\n",
      "epoch 141; iter: 0; batch classifier loss: 0.013093; batch adversarial loss: 0.438730\n",
      "epoch 142; iter: 0; batch classifier loss: 0.015564; batch adversarial loss: 0.404409\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026937; batch adversarial loss: 0.458411\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018623; batch adversarial loss: 0.507003\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048129; batch adversarial loss: 0.447930\n",
      "epoch 146; iter: 0; batch classifier loss: 0.073308; batch adversarial loss: 0.499732\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024931; batch adversarial loss: 0.441156\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020610; batch adversarial loss: 0.418520\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013379; batch adversarial loss: 0.422226\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016455; batch adversarial loss: 0.449104\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012608; batch adversarial loss: 0.409414\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019819; batch adversarial loss: 0.510325\n",
      "epoch 153; iter: 0; batch classifier loss: 0.006936; batch adversarial loss: 0.497660\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018910; batch adversarial loss: 0.394904\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027189; batch adversarial loss: 0.468300\n",
      "epoch 156; iter: 0; batch classifier loss: 0.063928; batch adversarial loss: 0.574744\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024830; batch adversarial loss: 0.453594\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009567; batch adversarial loss: 0.490086\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022797; batch adversarial loss: 0.463433\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010988; batch adversarial loss: 0.474790\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013929; batch adversarial loss: 0.475162\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031142; batch adversarial loss: 0.484147\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015808; batch adversarial loss: 0.465509\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021116; batch adversarial loss: 0.503289\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024160; batch adversarial loss: 0.442825\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035182; batch adversarial loss: 0.476628\n",
      "epoch 167; iter: 0; batch classifier loss: 0.043566; batch adversarial loss: 0.496943\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007549; batch adversarial loss: 0.375508\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018890; batch adversarial loss: 0.457170\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014177; batch adversarial loss: 0.395800\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033545; batch adversarial loss: 0.482071\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015569; batch adversarial loss: 0.431002\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026411; batch adversarial loss: 0.376963\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024434; batch adversarial loss: 0.453151\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009338; batch adversarial loss: 0.461782\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011836; batch adversarial loss: 0.406605\n",
      "epoch 177; iter: 0; batch classifier loss: 0.067248; batch adversarial loss: 0.531667\n",
      "epoch 178; iter: 0; batch classifier loss: 0.005822; batch adversarial loss: 0.474788\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015242; batch adversarial loss: 0.447088\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010947; batch adversarial loss: 0.405094\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009471; batch adversarial loss: 0.549570\n",
      "epoch 182; iter: 0; batch classifier loss: 0.044493; batch adversarial loss: 0.550022\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006221; batch adversarial loss: 0.383685\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016154; batch adversarial loss: 0.559190\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015633; batch adversarial loss: 0.499785\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020465; batch adversarial loss: 0.472872\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019813; batch adversarial loss: 0.509378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.015565; batch adversarial loss: 0.515059\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030391; batch adversarial loss: 0.433253\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014309; batch adversarial loss: 0.387039\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008577; batch adversarial loss: 0.545749\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011769; batch adversarial loss: 0.460221\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023571; batch adversarial loss: 0.386554\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005454; batch adversarial loss: 0.476338\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026053; batch adversarial loss: 0.386281\n",
      "epoch 196; iter: 0; batch classifier loss: 0.065222; batch adversarial loss: 0.458725\n",
      "epoch 197; iter: 0; batch classifier loss: 0.002339; batch adversarial loss: 0.526546\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011029; batch adversarial loss: 0.444452\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015828; batch adversarial loss: 0.486281\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676526; batch adversarial loss: 0.528555\n",
      "epoch 1; iter: 0; batch classifier loss: 0.511649; batch adversarial loss: 0.582953\n",
      "epoch 2; iter: 0; batch classifier loss: 0.450571; batch adversarial loss: 0.631556\n",
      "epoch 3; iter: 0; batch classifier loss: 0.431669; batch adversarial loss: 0.635330\n",
      "epoch 4; iter: 0; batch classifier loss: 0.362609; batch adversarial loss: 0.582295\n",
      "epoch 5; iter: 0; batch classifier loss: 0.476508; batch adversarial loss: 0.647708\n",
      "epoch 6; iter: 0; batch classifier loss: 0.364254; batch adversarial loss: 0.601129\n",
      "epoch 7; iter: 0; batch classifier loss: 0.420923; batch adversarial loss: 0.488549\n",
      "epoch 8; iter: 0; batch classifier loss: 0.446085; batch adversarial loss: 0.606444\n",
      "epoch 9; iter: 0; batch classifier loss: 0.685149; batch adversarial loss: 0.597847\n",
      "epoch 10; iter: 0; batch classifier loss: 0.630442; batch adversarial loss: 0.557913\n",
      "epoch 11; iter: 0; batch classifier loss: 0.603858; batch adversarial loss: 0.525645\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540732; batch adversarial loss: 0.509480\n",
      "epoch 13; iter: 0; batch classifier loss: 0.449548; batch adversarial loss: 0.564217\n",
      "epoch 14; iter: 0; batch classifier loss: 0.336374; batch adversarial loss: 0.475228\n",
      "epoch 15; iter: 0; batch classifier loss: 0.282431; batch adversarial loss: 0.451611\n",
      "epoch 16; iter: 0; batch classifier loss: 0.367239; batch adversarial loss: 0.472589\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348034; batch adversarial loss: 0.505734\n",
      "epoch 18; iter: 0; batch classifier loss: 0.239861; batch adversarial loss: 0.508196\n",
      "epoch 19; iter: 0; batch classifier loss: 0.297315; batch adversarial loss: 0.459959\n",
      "epoch 20; iter: 0; batch classifier loss: 0.259709; batch adversarial loss: 0.486959\n",
      "epoch 21; iter: 0; batch classifier loss: 0.191810; batch adversarial loss: 0.549100\n",
      "epoch 22; iter: 0; batch classifier loss: 0.220294; batch adversarial loss: 0.417816\n",
      "epoch 23; iter: 0; batch classifier loss: 0.209811; batch adversarial loss: 0.481890\n",
      "epoch 24; iter: 0; batch classifier loss: 0.238470; batch adversarial loss: 0.428914\n",
      "epoch 25; iter: 0; batch classifier loss: 0.204955; batch adversarial loss: 0.485471\n",
      "epoch 26; iter: 0; batch classifier loss: 0.156019; batch adversarial loss: 0.440820\n",
      "epoch 27; iter: 0; batch classifier loss: 0.184805; batch adversarial loss: 0.453690\n",
      "epoch 28; iter: 0; batch classifier loss: 0.203972; batch adversarial loss: 0.420969\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197676; batch adversarial loss: 0.490605\n",
      "epoch 30; iter: 0; batch classifier loss: 0.198797; batch adversarial loss: 0.478053\n",
      "epoch 31; iter: 0; batch classifier loss: 0.186964; batch adversarial loss: 0.505901\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140942; batch adversarial loss: 0.495361\n",
      "epoch 33; iter: 0; batch classifier loss: 0.144560; batch adversarial loss: 0.495425\n",
      "epoch 34; iter: 0; batch classifier loss: 0.163715; batch adversarial loss: 0.374096\n",
      "epoch 35; iter: 0; batch classifier loss: 0.156458; batch adversarial loss: 0.430635\n",
      "epoch 36; iter: 0; batch classifier loss: 0.248478; batch adversarial loss: 0.480425\n",
      "epoch 37; iter: 0; batch classifier loss: 0.107660; batch adversarial loss: 0.506658\n",
      "epoch 38; iter: 0; batch classifier loss: 0.132034; batch adversarial loss: 0.459592\n",
      "epoch 39; iter: 0; batch classifier loss: 0.190403; batch adversarial loss: 0.469658\n",
      "epoch 40; iter: 0; batch classifier loss: 0.110313; batch adversarial loss: 0.411996\n",
      "epoch 41; iter: 0; batch classifier loss: 0.142124; batch adversarial loss: 0.456884\n",
      "epoch 42; iter: 0; batch classifier loss: 0.141005; batch adversarial loss: 0.506805\n",
      "epoch 43; iter: 0; batch classifier loss: 0.149445; batch adversarial loss: 0.424906\n",
      "epoch 44; iter: 0; batch classifier loss: 0.143530; batch adversarial loss: 0.573163\n",
      "epoch 45; iter: 0; batch classifier loss: 0.151473; batch adversarial loss: 0.426335\n",
      "epoch 46; iter: 0; batch classifier loss: 0.159841; batch adversarial loss: 0.489108\n",
      "epoch 47; iter: 0; batch classifier loss: 0.116692; batch adversarial loss: 0.398878\n",
      "epoch 48; iter: 0; batch classifier loss: 0.110018; batch adversarial loss: 0.486618\n",
      "epoch 49; iter: 0; batch classifier loss: 0.165974; batch adversarial loss: 0.502615\n",
      "epoch 50; iter: 0; batch classifier loss: 0.189188; batch adversarial loss: 0.503985\n",
      "epoch 51; iter: 0; batch classifier loss: 0.136603; batch adversarial loss: 0.441308\n",
      "epoch 52; iter: 0; batch classifier loss: 0.167389; batch adversarial loss: 0.406714\n",
      "epoch 53; iter: 0; batch classifier loss: 0.143428; batch adversarial loss: 0.367250\n",
      "epoch 54; iter: 0; batch classifier loss: 0.190728; batch adversarial loss: 0.440330\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079584; batch adversarial loss: 0.557090\n",
      "epoch 56; iter: 0; batch classifier loss: 0.158900; batch adversarial loss: 0.435317\n",
      "epoch 57; iter: 0; batch classifier loss: 0.156922; batch adversarial loss: 0.463243\n",
      "epoch 58; iter: 0; batch classifier loss: 0.146234; batch adversarial loss: 0.369815\n",
      "epoch 59; iter: 0; batch classifier loss: 0.148163; batch adversarial loss: 0.504905\n",
      "epoch 60; iter: 0; batch classifier loss: 0.100915; batch adversarial loss: 0.393374\n",
      "epoch 61; iter: 0; batch classifier loss: 0.142100; batch adversarial loss: 0.494234\n",
      "epoch 62; iter: 0; batch classifier loss: 0.192900; batch adversarial loss: 0.432293\n",
      "epoch 63; iter: 0; batch classifier loss: 0.090180; batch adversarial loss: 0.530991\n",
      "epoch 64; iter: 0; batch classifier loss: 0.207231; batch adversarial loss: 0.444297\n",
      "epoch 65; iter: 0; batch classifier loss: 0.134253; batch adversarial loss: 0.404256\n",
      "epoch 66; iter: 0; batch classifier loss: 0.136401; batch adversarial loss: 0.440738\n",
      "epoch 67; iter: 0; batch classifier loss: 0.149583; batch adversarial loss: 0.438768\n",
      "epoch 68; iter: 0; batch classifier loss: 0.127958; batch adversarial loss: 0.444246\n",
      "epoch 69; iter: 0; batch classifier loss: 0.217828; batch adversarial loss: 0.395875\n",
      "epoch 70; iter: 0; batch classifier loss: 0.125405; batch adversarial loss: 0.433080\n",
      "epoch 71; iter: 0; batch classifier loss: 0.110563; batch adversarial loss: 0.467612\n",
      "epoch 72; iter: 0; batch classifier loss: 0.159019; batch adversarial loss: 0.419205\n",
      "epoch 73; iter: 0; batch classifier loss: 0.178217; batch adversarial loss: 0.409419\n",
      "epoch 74; iter: 0; batch classifier loss: 0.139647; batch adversarial loss: 0.483556\n",
      "epoch 75; iter: 0; batch classifier loss: 0.124591; batch adversarial loss: 0.433910\n",
      "epoch 76; iter: 0; batch classifier loss: 0.162440; batch adversarial loss: 0.510678\n",
      "epoch 77; iter: 0; batch classifier loss: 0.165383; batch adversarial loss: 0.470292\n",
      "epoch 78; iter: 0; batch classifier loss: 0.158923; batch adversarial loss: 0.461265\n",
      "epoch 79; iter: 0; batch classifier loss: 0.164802; batch adversarial loss: 0.452230\n",
      "epoch 80; iter: 0; batch classifier loss: 0.131755; batch adversarial loss: 0.421788\n",
      "epoch 81; iter: 0; batch classifier loss: 0.107398; batch adversarial loss: 0.386679\n",
      "epoch 82; iter: 0; batch classifier loss: 0.110977; batch adversarial loss: 0.390325\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083217; batch adversarial loss: 0.538810\n",
      "epoch 84; iter: 0; batch classifier loss: 0.132112; batch adversarial loss: 0.486862\n",
      "epoch 85; iter: 0; batch classifier loss: 0.124553; batch adversarial loss: 0.434506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.169148; batch adversarial loss: 0.446910\n",
      "epoch 87; iter: 0; batch classifier loss: 0.189696; batch adversarial loss: 0.312357\n",
      "epoch 88; iter: 0; batch classifier loss: 0.121653; batch adversarial loss: 0.413209\n",
      "epoch 89; iter: 0; batch classifier loss: 0.124385; batch adversarial loss: 0.439693\n",
      "epoch 90; iter: 0; batch classifier loss: 0.081605; batch adversarial loss: 0.541945\n",
      "epoch 91; iter: 0; batch classifier loss: 0.165463; batch adversarial loss: 0.453938\n",
      "epoch 92; iter: 0; batch classifier loss: 0.140796; batch adversarial loss: 0.433950\n",
      "epoch 93; iter: 0; batch classifier loss: 0.128990; batch adversarial loss: 0.508101\n",
      "epoch 94; iter: 0; batch classifier loss: 0.105619; batch adversarial loss: 0.413067\n",
      "epoch 95; iter: 0; batch classifier loss: 0.106712; batch adversarial loss: 0.387577\n",
      "epoch 96; iter: 0; batch classifier loss: 0.133177; batch adversarial loss: 0.387753\n",
      "epoch 97; iter: 0; batch classifier loss: 0.101595; batch adversarial loss: 0.463552\n",
      "epoch 98; iter: 0; batch classifier loss: 0.106662; batch adversarial loss: 0.475475\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071940; batch adversarial loss: 0.467499\n",
      "epoch 100; iter: 0; batch classifier loss: 0.146409; batch adversarial loss: 0.484154\n",
      "epoch 101; iter: 0; batch classifier loss: 0.131664; batch adversarial loss: 0.466096\n",
      "epoch 102; iter: 0; batch classifier loss: 0.069598; batch adversarial loss: 0.512527\n",
      "epoch 103; iter: 0; batch classifier loss: 0.091914; batch adversarial loss: 0.371755\n",
      "epoch 104; iter: 0; batch classifier loss: 0.109409; batch adversarial loss: 0.360060\n",
      "epoch 105; iter: 0; batch classifier loss: 0.091406; batch adversarial loss: 0.545840\n",
      "epoch 106; iter: 0; batch classifier loss: 0.094661; batch adversarial loss: 0.463533\n",
      "epoch 107; iter: 0; batch classifier loss: 0.104562; batch adversarial loss: 0.449807\n",
      "epoch 108; iter: 0; batch classifier loss: 0.125905; batch adversarial loss: 0.431693\n",
      "epoch 109; iter: 0; batch classifier loss: 0.101699; batch adversarial loss: 0.469154\n",
      "epoch 110; iter: 0; batch classifier loss: 0.104945; batch adversarial loss: 0.468846\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057419; batch adversarial loss: 0.487072\n",
      "epoch 112; iter: 0; batch classifier loss: 0.089799; batch adversarial loss: 0.474581\n",
      "epoch 113; iter: 0; batch classifier loss: 0.072710; batch adversarial loss: 0.552064\n",
      "epoch 114; iter: 0; batch classifier loss: 0.094770; batch adversarial loss: 0.474317\n",
      "epoch 115; iter: 0; batch classifier loss: 0.144114; batch adversarial loss: 0.369676\n",
      "epoch 116; iter: 0; batch classifier loss: 0.073175; batch adversarial loss: 0.388237\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049054; batch adversarial loss: 0.494957\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033091; batch adversarial loss: 0.499216\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049338; batch adversarial loss: 0.414965\n",
      "epoch 120; iter: 0; batch classifier loss: 0.064735; batch adversarial loss: 0.403561\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027901; batch adversarial loss: 0.504586\n",
      "epoch 122; iter: 0; batch classifier loss: 0.096106; batch adversarial loss: 0.529754\n",
      "epoch 123; iter: 0; batch classifier loss: 0.069229; batch adversarial loss: 0.461003\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040687; batch adversarial loss: 0.462449\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031025; batch adversarial loss: 0.364176\n",
      "epoch 126; iter: 0; batch classifier loss: 0.068136; batch adversarial loss: 0.387153\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033377; batch adversarial loss: 0.459723\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052616; batch adversarial loss: 0.475839\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048529; batch adversarial loss: 0.437583\n",
      "epoch 130; iter: 0; batch classifier loss: 0.064335; batch adversarial loss: 0.406402\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037176; batch adversarial loss: 0.483362\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032211; batch adversarial loss: 0.414005\n",
      "epoch 133; iter: 0; batch classifier loss: 0.054796; batch adversarial loss: 0.496190\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035224; batch adversarial loss: 0.396722\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037280; batch adversarial loss: 0.591016\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024297; batch adversarial loss: 0.498876\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032809; batch adversarial loss: 0.401337\n",
      "epoch 138; iter: 0; batch classifier loss: 0.043347; batch adversarial loss: 0.546553\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035230; batch adversarial loss: 0.323755\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013453; batch adversarial loss: 0.385703\n",
      "epoch 141; iter: 0; batch classifier loss: 0.056283; batch adversarial loss: 0.476427\n",
      "epoch 142; iter: 0; batch classifier loss: 0.051014; batch adversarial loss: 0.505259\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029450; batch adversarial loss: 0.450902\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029948; batch adversarial loss: 0.463936\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026994; batch adversarial loss: 0.469230\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022096; batch adversarial loss: 0.519532\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034734; batch adversarial loss: 0.522674\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024403; batch adversarial loss: 0.443774\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020060; batch adversarial loss: 0.366167\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033385; batch adversarial loss: 0.512311\n",
      "epoch 151; iter: 0; batch classifier loss: 0.072833; batch adversarial loss: 0.399010\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032483; batch adversarial loss: 0.403563\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025366; batch adversarial loss: 0.446736\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041285; batch adversarial loss: 0.494580\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038027; batch adversarial loss: 0.411533\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022147; batch adversarial loss: 0.460302\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028662; batch adversarial loss: 0.480842\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033679; batch adversarial loss: 0.421748\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027535; batch adversarial loss: 0.461153\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044059; batch adversarial loss: 0.437333\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033674; batch adversarial loss: 0.391494\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026592; batch adversarial loss: 0.441898\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035728; batch adversarial loss: 0.489932\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033108; batch adversarial loss: 0.507674\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012364; batch adversarial loss: 0.433429\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011604; batch adversarial loss: 0.457405\n",
      "epoch 167; iter: 0; batch classifier loss: 0.038862; batch adversarial loss: 0.435940\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026848; batch adversarial loss: 0.409002\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021572; batch adversarial loss: 0.490411\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024691; batch adversarial loss: 0.444333\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023262; batch adversarial loss: 0.503252\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026012; batch adversarial loss: 0.465058\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016131; batch adversarial loss: 0.411043\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022394; batch adversarial loss: 0.399494\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011897; batch adversarial loss: 0.412738\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024003; batch adversarial loss: 0.456142\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013509; batch adversarial loss: 0.507399\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011372; batch adversarial loss: 0.427181\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028115; batch adversarial loss: 0.490822\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027841; batch adversarial loss: 0.453381\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016533; batch adversarial loss: 0.412858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.026858; batch adversarial loss: 0.458086\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020800; batch adversarial loss: 0.407836\n",
      "epoch 184; iter: 0; batch classifier loss: 0.052344; batch adversarial loss: 0.344922\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006661; batch adversarial loss: 0.539398\n",
      "epoch 186; iter: 0; batch classifier loss: 0.055992; batch adversarial loss: 0.380526\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026185; batch adversarial loss: 0.496429\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040387; batch adversarial loss: 0.411712\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023620; batch adversarial loss: 0.404611\n",
      "epoch 190; iter: 0; batch classifier loss: 0.033328; batch adversarial loss: 0.444480\n",
      "epoch 191; iter: 0; batch classifier loss: 0.035182; batch adversarial loss: 0.413446\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012745; batch adversarial loss: 0.427354\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011354; batch adversarial loss: 0.446965\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019761; batch adversarial loss: 0.447223\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016555; batch adversarial loss: 0.468850\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009029; batch adversarial loss: 0.297849\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015763; batch adversarial loss: 0.420043\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020635; batch adversarial loss: 0.368898\n",
      "epoch 199; iter: 0; batch classifier loss: 0.034711; batch adversarial loss: 0.461501\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697224; batch adversarial loss: 0.754479\n",
      "epoch 1; iter: 0; batch classifier loss: 0.539834; batch adversarial loss: 0.702658\n",
      "epoch 2; iter: 0; batch classifier loss: 0.510558; batch adversarial loss: 0.647818\n",
      "epoch 3; iter: 0; batch classifier loss: 0.425112; batch adversarial loss: 0.606204\n",
      "epoch 4; iter: 0; batch classifier loss: 0.375560; batch adversarial loss: 0.571174\n",
      "epoch 5; iter: 0; batch classifier loss: 0.334129; batch adversarial loss: 0.636177\n",
      "epoch 6; iter: 0; batch classifier loss: 0.285713; batch adversarial loss: 0.609927\n",
      "epoch 7; iter: 0; batch classifier loss: 0.327526; batch adversarial loss: 0.546039\n",
      "epoch 8; iter: 0; batch classifier loss: 0.288144; batch adversarial loss: 0.519144\n",
      "epoch 9; iter: 0; batch classifier loss: 0.335444; batch adversarial loss: 0.543287\n",
      "epoch 10; iter: 0; batch classifier loss: 0.326841; batch adversarial loss: 0.533441\n",
      "epoch 11; iter: 0; batch classifier loss: 0.370217; batch adversarial loss: 0.513780\n",
      "epoch 12; iter: 0; batch classifier loss: 0.360373; batch adversarial loss: 0.450882\n",
      "epoch 13; iter: 0; batch classifier loss: 0.294126; batch adversarial loss: 0.557151\n",
      "epoch 14; iter: 0; batch classifier loss: 0.325593; batch adversarial loss: 0.469098\n",
      "epoch 15; iter: 0; batch classifier loss: 0.267658; batch adversarial loss: 0.489147\n",
      "epoch 16; iter: 0; batch classifier loss: 0.355693; batch adversarial loss: 0.466980\n",
      "epoch 17; iter: 0; batch classifier loss: 0.290880; batch adversarial loss: 0.434203\n",
      "epoch 18; iter: 0; batch classifier loss: 0.286717; batch adversarial loss: 0.515860\n",
      "epoch 19; iter: 0; batch classifier loss: 0.219056; batch adversarial loss: 0.520641\n",
      "epoch 20; iter: 0; batch classifier loss: 0.190995; batch adversarial loss: 0.560011\n",
      "epoch 21; iter: 0; batch classifier loss: 0.338116; batch adversarial loss: 0.471474\n",
      "epoch 22; iter: 0; batch classifier loss: 0.287883; batch adversarial loss: 0.542016\n",
      "epoch 23; iter: 0; batch classifier loss: 0.232450; batch adversarial loss: 0.517910\n",
      "epoch 24; iter: 0; batch classifier loss: 0.223923; batch adversarial loss: 0.485439\n",
      "epoch 25; iter: 0; batch classifier loss: 0.227110; batch adversarial loss: 0.479496\n",
      "epoch 26; iter: 0; batch classifier loss: 0.211486; batch adversarial loss: 0.495389\n",
      "epoch 27; iter: 0; batch classifier loss: 0.235735; batch adversarial loss: 0.499876\n",
      "epoch 28; iter: 0; batch classifier loss: 0.222132; batch adversarial loss: 0.486849\n",
      "epoch 29; iter: 0; batch classifier loss: 0.240944; batch adversarial loss: 0.480820\n",
      "epoch 30; iter: 0; batch classifier loss: 0.243561; batch adversarial loss: 0.479681\n",
      "epoch 31; iter: 0; batch classifier loss: 0.247759; batch adversarial loss: 0.458338\n",
      "epoch 32; iter: 0; batch classifier loss: 0.207733; batch adversarial loss: 0.363010\n",
      "epoch 33; iter: 0; batch classifier loss: 0.234922; batch adversarial loss: 0.471670\n",
      "epoch 34; iter: 0; batch classifier loss: 0.179734; batch adversarial loss: 0.521188\n",
      "epoch 35; iter: 0; batch classifier loss: 0.183648; batch adversarial loss: 0.414074\n",
      "epoch 36; iter: 0; batch classifier loss: 0.225696; batch adversarial loss: 0.517622\n",
      "epoch 37; iter: 0; batch classifier loss: 0.185535; batch adversarial loss: 0.424853\n",
      "epoch 38; iter: 0; batch classifier loss: 0.176930; batch adversarial loss: 0.369739\n",
      "epoch 39; iter: 0; batch classifier loss: 0.189056; batch adversarial loss: 0.420829\n",
      "epoch 40; iter: 0; batch classifier loss: 0.180087; batch adversarial loss: 0.381700\n",
      "epoch 41; iter: 0; batch classifier loss: 0.199390; batch adversarial loss: 0.429808\n",
      "epoch 42; iter: 0; batch classifier loss: 0.209463; batch adversarial loss: 0.414432\n",
      "epoch 43; iter: 0; batch classifier loss: 0.152414; batch adversarial loss: 0.417401\n",
      "epoch 44; iter: 0; batch classifier loss: 0.156763; batch adversarial loss: 0.509532\n",
      "epoch 45; iter: 0; batch classifier loss: 0.215458; batch adversarial loss: 0.412833\n",
      "epoch 46; iter: 0; batch classifier loss: 0.187900; batch adversarial loss: 0.422865\n",
      "epoch 47; iter: 0; batch classifier loss: 0.245272; batch adversarial loss: 0.502406\n",
      "epoch 48; iter: 0; batch classifier loss: 0.209695; batch adversarial loss: 0.508398\n",
      "epoch 49; iter: 0; batch classifier loss: 0.165074; batch adversarial loss: 0.509821\n",
      "epoch 50; iter: 0; batch classifier loss: 0.148107; batch adversarial loss: 0.457648\n",
      "epoch 51; iter: 0; batch classifier loss: 0.202889; batch adversarial loss: 0.524460\n",
      "epoch 52; iter: 0; batch classifier loss: 0.195164; batch adversarial loss: 0.419959\n",
      "epoch 53; iter: 0; batch classifier loss: 0.129630; batch adversarial loss: 0.422289\n",
      "epoch 54; iter: 0; batch classifier loss: 0.282228; batch adversarial loss: 0.435843\n",
      "epoch 55; iter: 0; batch classifier loss: 0.189246; batch adversarial loss: 0.526667\n",
      "epoch 56; iter: 0; batch classifier loss: 0.148678; batch adversarial loss: 0.465973\n",
      "epoch 57; iter: 0; batch classifier loss: 0.212359; batch adversarial loss: 0.435572\n",
      "epoch 58; iter: 0; batch classifier loss: 0.219355; batch adversarial loss: 0.430931\n",
      "epoch 59; iter: 0; batch classifier loss: 0.222755; batch adversarial loss: 0.468128\n",
      "epoch 60; iter: 0; batch classifier loss: 0.202996; batch adversarial loss: 0.476935\n",
      "epoch 61; iter: 0; batch classifier loss: 0.157589; batch adversarial loss: 0.483896\n",
      "epoch 62; iter: 0; batch classifier loss: 0.175714; batch adversarial loss: 0.520406\n",
      "epoch 63; iter: 0; batch classifier loss: 0.177504; batch adversarial loss: 0.450183\n",
      "epoch 64; iter: 0; batch classifier loss: 0.203069; batch adversarial loss: 0.488935\n",
      "epoch 65; iter: 0; batch classifier loss: 0.228822; batch adversarial loss: 0.411711\n",
      "epoch 66; iter: 0; batch classifier loss: 0.230764; batch adversarial loss: 0.485286\n",
      "epoch 67; iter: 0; batch classifier loss: 0.169266; batch adversarial loss: 0.425309\n",
      "epoch 68; iter: 0; batch classifier loss: 0.139782; batch adversarial loss: 0.516345\n",
      "epoch 69; iter: 0; batch classifier loss: 0.161638; batch adversarial loss: 0.470067\n",
      "epoch 70; iter: 0; batch classifier loss: 0.149715; batch adversarial loss: 0.494172\n",
      "epoch 71; iter: 0; batch classifier loss: 0.214232; batch adversarial loss: 0.477653\n",
      "epoch 72; iter: 0; batch classifier loss: 0.231290; batch adversarial loss: 0.540256\n",
      "epoch 73; iter: 0; batch classifier loss: 0.168313; batch adversarial loss: 0.446838\n",
      "epoch 74; iter: 0; batch classifier loss: 0.181498; batch adversarial loss: 0.529415\n",
      "epoch 75; iter: 0; batch classifier loss: 0.207585; batch adversarial loss: 0.508065\n",
      "epoch 76; iter: 0; batch classifier loss: 0.195728; batch adversarial loss: 0.411894\n",
      "epoch 77; iter: 0; batch classifier loss: 0.154863; batch adversarial loss: 0.566802\n",
      "epoch 78; iter: 0; batch classifier loss: 0.208401; batch adversarial loss: 0.469068\n",
      "epoch 79; iter: 0; batch classifier loss: 0.128501; batch adversarial loss: 0.495615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.159144; batch adversarial loss: 0.434380\n",
      "epoch 81; iter: 0; batch classifier loss: 0.193025; batch adversarial loss: 0.387183\n",
      "epoch 82; iter: 0; batch classifier loss: 0.227874; batch adversarial loss: 0.446421\n",
      "epoch 83; iter: 0; batch classifier loss: 0.184807; batch adversarial loss: 0.480570\n",
      "epoch 84; iter: 0; batch classifier loss: 0.203143; batch adversarial loss: 0.314556\n",
      "epoch 85; iter: 0; batch classifier loss: 0.220347; batch adversarial loss: 0.530014\n",
      "epoch 86; iter: 0; batch classifier loss: 0.170287; batch adversarial loss: 0.386231\n",
      "epoch 87; iter: 0; batch classifier loss: 0.179682; batch adversarial loss: 0.434363\n",
      "epoch 88; iter: 0; batch classifier loss: 0.186372; batch adversarial loss: 0.423029\n",
      "epoch 89; iter: 0; batch classifier loss: 0.157417; batch adversarial loss: 0.494675\n",
      "epoch 90; iter: 0; batch classifier loss: 0.125137; batch adversarial loss: 0.613903\n",
      "epoch 91; iter: 0; batch classifier loss: 0.176286; batch adversarial loss: 0.386606\n",
      "epoch 92; iter: 0; batch classifier loss: 0.164513; batch adversarial loss: 0.444083\n",
      "epoch 93; iter: 0; batch classifier loss: 0.139181; batch adversarial loss: 0.470290\n",
      "epoch 94; iter: 0; batch classifier loss: 0.244871; batch adversarial loss: 0.433095\n",
      "epoch 95; iter: 0; batch classifier loss: 0.171664; batch adversarial loss: 0.436794\n",
      "epoch 96; iter: 0; batch classifier loss: 0.154448; batch adversarial loss: 0.423356\n",
      "epoch 97; iter: 0; batch classifier loss: 0.143910; batch adversarial loss: 0.519404\n",
      "epoch 98; iter: 0; batch classifier loss: 0.168659; batch adversarial loss: 0.523193\n",
      "epoch 99; iter: 0; batch classifier loss: 0.146617; batch adversarial loss: 0.485110\n",
      "epoch 100; iter: 0; batch classifier loss: 0.172480; batch adversarial loss: 0.396464\n",
      "epoch 101; iter: 0; batch classifier loss: 0.164851; batch adversarial loss: 0.431200\n",
      "epoch 102; iter: 0; batch classifier loss: 0.254827; batch adversarial loss: 0.400181\n",
      "epoch 103; iter: 0; batch classifier loss: 0.183299; batch adversarial loss: 0.442429\n",
      "epoch 104; iter: 0; batch classifier loss: 0.184741; batch adversarial loss: 0.443595\n",
      "epoch 105; iter: 0; batch classifier loss: 0.138405; batch adversarial loss: 0.546325\n",
      "epoch 106; iter: 0; batch classifier loss: 0.105118; batch adversarial loss: 0.472290\n",
      "epoch 107; iter: 0; batch classifier loss: 0.134777; batch adversarial loss: 0.483430\n",
      "epoch 108; iter: 0; batch classifier loss: 0.127005; batch adversarial loss: 0.371228\n",
      "epoch 109; iter: 0; batch classifier loss: 0.087630; batch adversarial loss: 0.418819\n",
      "epoch 110; iter: 0; batch classifier loss: 0.105789; batch adversarial loss: 0.486952\n",
      "epoch 111; iter: 0; batch classifier loss: 0.070022; batch adversarial loss: 0.486876\n",
      "epoch 112; iter: 0; batch classifier loss: 0.060027; batch adversarial loss: 0.483931\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058661; batch adversarial loss: 0.513965\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050660; batch adversarial loss: 0.540940\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053895; batch adversarial loss: 0.483116\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027012; batch adversarial loss: 0.503860\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061195; batch adversarial loss: 0.433594\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057790; batch adversarial loss: 0.388894\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046002; batch adversarial loss: 0.417612\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057660; batch adversarial loss: 0.491794\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036385; batch adversarial loss: 0.313826\n",
      "epoch 122; iter: 0; batch classifier loss: 0.027518; batch adversarial loss: 0.456581\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028729; batch adversarial loss: 0.427228\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059359; batch adversarial loss: 0.457305\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028987; batch adversarial loss: 0.407880\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044670; batch adversarial loss: 0.379744\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026652; batch adversarial loss: 0.549649\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036758; batch adversarial loss: 0.433151\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035497; batch adversarial loss: 0.469098\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035235; batch adversarial loss: 0.441790\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039837; batch adversarial loss: 0.526249\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035263; batch adversarial loss: 0.450079\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013429; batch adversarial loss: 0.477839\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045231; batch adversarial loss: 0.439025\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039577; batch adversarial loss: 0.406389\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039780; batch adversarial loss: 0.530802\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018532; batch adversarial loss: 0.506796\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025655; batch adversarial loss: 0.482743\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049100; batch adversarial loss: 0.454859\n",
      "epoch 140; iter: 0; batch classifier loss: 0.015389; batch adversarial loss: 0.525289\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038529; batch adversarial loss: 0.463787\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044356; batch adversarial loss: 0.495386\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025016; batch adversarial loss: 0.504552\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045622; batch adversarial loss: 0.480700\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025892; batch adversarial loss: 0.437237\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016389; batch adversarial loss: 0.529801\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018712; batch adversarial loss: 0.495587\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016709; batch adversarial loss: 0.458471\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013411; batch adversarial loss: 0.397422\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039818; batch adversarial loss: 0.539796\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020461; batch adversarial loss: 0.438735\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032460; batch adversarial loss: 0.482864\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017911; batch adversarial loss: 0.553711\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034227; batch adversarial loss: 0.522535\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011670; batch adversarial loss: 0.433418\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020728; batch adversarial loss: 0.466930\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016828; batch adversarial loss: 0.456852\n",
      "epoch 158; iter: 0; batch classifier loss: 0.040857; batch adversarial loss: 0.437463\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031929; batch adversarial loss: 0.495799\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026149; batch adversarial loss: 0.521935\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031110; batch adversarial loss: 0.414212\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033207; batch adversarial loss: 0.464209\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012850; batch adversarial loss: 0.400396\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027623; batch adversarial loss: 0.488998\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012660; batch adversarial loss: 0.461805\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022944; batch adversarial loss: 0.455440\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022219; batch adversarial loss: 0.514164\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016989; batch adversarial loss: 0.529322\n",
      "epoch 169; iter: 0; batch classifier loss: 0.046229; batch adversarial loss: 0.519243\n",
      "epoch 170; iter: 0; batch classifier loss: 0.036299; batch adversarial loss: 0.419563\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018220; batch adversarial loss: 0.400629\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007428; batch adversarial loss: 0.474314\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024882; batch adversarial loss: 0.432165\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017059; batch adversarial loss: 0.358220\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037483; batch adversarial loss: 0.437909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.009349; batch adversarial loss: 0.388056\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026814; batch adversarial loss: 0.435899\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033380; batch adversarial loss: 0.451759\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006785; batch adversarial loss: 0.515516\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021415; batch adversarial loss: 0.493600\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010591; batch adversarial loss: 0.445677\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012820; batch adversarial loss: 0.464135\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021921; batch adversarial loss: 0.514456\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017291; batch adversarial loss: 0.518813\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025186; batch adversarial loss: 0.523916\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032146; batch adversarial loss: 0.527203\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018242; batch adversarial loss: 0.553337\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024430; batch adversarial loss: 0.374440\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017624; batch adversarial loss: 0.600245\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009691; batch adversarial loss: 0.428692\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011540; batch adversarial loss: 0.465002\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013961; batch adversarial loss: 0.376051\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017290; batch adversarial loss: 0.472962\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017092; batch adversarial loss: 0.464856\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015205; batch adversarial loss: 0.485467\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017061; batch adversarial loss: 0.532152\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007917; batch adversarial loss: 0.479674\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013941; batch adversarial loss: 0.533762\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023115; batch adversarial loss: 0.528081\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705015; batch adversarial loss: 0.741792\n",
      "epoch 1; iter: 0; batch classifier loss: 0.526725; batch adversarial loss: 0.692469\n",
      "epoch 2; iter: 0; batch classifier loss: 0.387941; batch adversarial loss: 0.629862\n",
      "epoch 3; iter: 0; batch classifier loss: 0.293889; batch adversarial loss: 0.607647\n",
      "epoch 4; iter: 0; batch classifier loss: 0.381329; batch adversarial loss: 0.604219\n",
      "epoch 5; iter: 0; batch classifier loss: 0.250528; batch adversarial loss: 0.578970\n",
      "epoch 6; iter: 0; batch classifier loss: 0.287112; batch adversarial loss: 0.562654\n",
      "epoch 7; iter: 0; batch classifier loss: 0.281490; batch adversarial loss: 0.567230\n",
      "epoch 8; iter: 0; batch classifier loss: 0.313755; batch adversarial loss: 0.530749\n",
      "epoch 9; iter: 0; batch classifier loss: 0.291385; batch adversarial loss: 0.506385\n",
      "epoch 10; iter: 0; batch classifier loss: 0.280780; batch adversarial loss: 0.533746\n",
      "epoch 11; iter: 0; batch classifier loss: 0.247667; batch adversarial loss: 0.506924\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251116; batch adversarial loss: 0.486368\n",
      "epoch 13; iter: 0; batch classifier loss: 0.275763; batch adversarial loss: 0.525912\n",
      "epoch 14; iter: 0; batch classifier loss: 0.234406; batch adversarial loss: 0.468983\n",
      "epoch 15; iter: 0; batch classifier loss: 0.309554; batch adversarial loss: 0.494125\n",
      "epoch 16; iter: 0; batch classifier loss: 0.237499; batch adversarial loss: 0.497116\n",
      "epoch 17; iter: 0; batch classifier loss: 0.282160; batch adversarial loss: 0.504312\n",
      "epoch 18; iter: 0; batch classifier loss: 0.194987; batch adversarial loss: 0.489416\n",
      "epoch 19; iter: 0; batch classifier loss: 0.217796; batch adversarial loss: 0.471737\n",
      "epoch 20; iter: 0; batch classifier loss: 0.248704; batch adversarial loss: 0.506430\n",
      "epoch 21; iter: 0; batch classifier loss: 0.210723; batch adversarial loss: 0.515419\n",
      "epoch 22; iter: 0; batch classifier loss: 0.201356; batch adversarial loss: 0.463134\n",
      "epoch 23; iter: 0; batch classifier loss: 0.192149; batch adversarial loss: 0.479026\n",
      "epoch 24; iter: 0; batch classifier loss: 0.189008; batch adversarial loss: 0.515721\n",
      "epoch 25; iter: 0; batch classifier loss: 0.171685; batch adversarial loss: 0.480278\n",
      "epoch 26; iter: 0; batch classifier loss: 0.144962; batch adversarial loss: 0.438504\n",
      "epoch 27; iter: 0; batch classifier loss: 0.153204; batch adversarial loss: 0.499542\n",
      "epoch 28; iter: 0; batch classifier loss: 0.179421; batch adversarial loss: 0.502753\n",
      "epoch 29; iter: 0; batch classifier loss: 0.163968; batch adversarial loss: 0.454561\n",
      "epoch 30; iter: 0; batch classifier loss: 0.157689; batch adversarial loss: 0.479331\n",
      "epoch 31; iter: 0; batch classifier loss: 0.159557; batch adversarial loss: 0.468322\n",
      "epoch 32; iter: 0; batch classifier loss: 0.162618; batch adversarial loss: 0.477427\n",
      "epoch 33; iter: 0; batch classifier loss: 0.174509; batch adversarial loss: 0.427798\n",
      "epoch 34; iter: 0; batch classifier loss: 0.121801; batch adversarial loss: 0.536877\n",
      "epoch 35; iter: 0; batch classifier loss: 0.161286; batch adversarial loss: 0.447720\n",
      "epoch 36; iter: 0; batch classifier loss: 0.111385; batch adversarial loss: 0.487515\n",
      "epoch 37; iter: 0; batch classifier loss: 0.142508; batch adversarial loss: 0.369449\n",
      "epoch 38; iter: 0; batch classifier loss: 0.131374; batch adversarial loss: 0.441453\n",
      "epoch 39; iter: 0; batch classifier loss: 0.155104; batch adversarial loss: 0.473880\n",
      "epoch 40; iter: 0; batch classifier loss: 0.129227; batch adversarial loss: 0.347419\n",
      "epoch 41; iter: 0; batch classifier loss: 0.113187; batch adversarial loss: 0.414503\n",
      "epoch 42; iter: 0; batch classifier loss: 0.151577; batch adversarial loss: 0.518568\n",
      "epoch 43; iter: 0; batch classifier loss: 0.099200; batch adversarial loss: 0.485958\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101358; batch adversarial loss: 0.439243\n",
      "epoch 45; iter: 0; batch classifier loss: 0.135154; batch adversarial loss: 0.462408\n",
      "epoch 46; iter: 0; batch classifier loss: 0.078104; batch adversarial loss: 0.439785\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112212; batch adversarial loss: 0.488864\n",
      "epoch 48; iter: 0; batch classifier loss: 0.083401; batch adversarial loss: 0.504662\n",
      "epoch 49; iter: 0; batch classifier loss: 0.071939; batch adversarial loss: 0.367720\n",
      "epoch 50; iter: 0; batch classifier loss: 0.073109; batch adversarial loss: 0.460548\n",
      "epoch 51; iter: 0; batch classifier loss: 0.113251; batch adversarial loss: 0.386549\n",
      "epoch 52; iter: 0; batch classifier loss: 0.093603; batch adversarial loss: 0.472305\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084982; batch adversarial loss: 0.526097\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096908; batch adversarial loss: 0.396202\n",
      "epoch 55; iter: 0; batch classifier loss: 0.076364; batch adversarial loss: 0.475658\n",
      "epoch 56; iter: 0; batch classifier loss: 0.104981; batch adversarial loss: 0.416280\n",
      "epoch 57; iter: 0; batch classifier loss: 0.052902; batch adversarial loss: 0.427974\n",
      "epoch 58; iter: 0; batch classifier loss: 0.135196; batch adversarial loss: 0.466087\n",
      "epoch 59; iter: 0; batch classifier loss: 0.101760; batch adversarial loss: 0.458855\n",
      "epoch 60; iter: 0; batch classifier loss: 0.058335; batch adversarial loss: 0.437075\n",
      "epoch 61; iter: 0; batch classifier loss: 0.070417; batch adversarial loss: 0.441836\n",
      "epoch 62; iter: 0; batch classifier loss: 0.113044; batch adversarial loss: 0.495483\n",
      "epoch 63; iter: 0; batch classifier loss: 0.061603; batch adversarial loss: 0.520924\n",
      "epoch 64; iter: 0; batch classifier loss: 0.100982; batch adversarial loss: 0.457440\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087080; batch adversarial loss: 0.468304\n",
      "epoch 66; iter: 0; batch classifier loss: 0.044432; batch adversarial loss: 0.376108\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059065; batch adversarial loss: 0.449026\n",
      "epoch 68; iter: 0; batch classifier loss: 0.054848; batch adversarial loss: 0.556895\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094347; batch adversarial loss: 0.425307\n",
      "epoch 70; iter: 0; batch classifier loss: 0.077815; batch adversarial loss: 0.517616\n",
      "epoch 71; iter: 0; batch classifier loss: 0.038790; batch adversarial loss: 0.384726\n",
      "epoch 72; iter: 0; batch classifier loss: 0.053134; batch adversarial loss: 0.589346\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083409; batch adversarial loss: 0.451103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.047052; batch adversarial loss: 0.399301\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075812; batch adversarial loss: 0.380284\n",
      "epoch 76; iter: 0; batch classifier loss: 0.090453; batch adversarial loss: 0.507028\n",
      "epoch 77; iter: 0; batch classifier loss: 0.099922; batch adversarial loss: 0.446644\n",
      "epoch 78; iter: 0; batch classifier loss: 0.051369; batch adversarial loss: 0.371300\n",
      "epoch 79; iter: 0; batch classifier loss: 0.088882; batch adversarial loss: 0.453113\n",
      "epoch 80; iter: 0; batch classifier loss: 0.051572; batch adversarial loss: 0.380318\n",
      "epoch 81; iter: 0; batch classifier loss: 0.036214; batch adversarial loss: 0.465544\n",
      "epoch 82; iter: 0; batch classifier loss: 0.024802; batch adversarial loss: 0.372797\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035945; batch adversarial loss: 0.468858\n",
      "epoch 84; iter: 0; batch classifier loss: 0.043401; batch adversarial loss: 0.400541\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059426; batch adversarial loss: 0.524975\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069187; batch adversarial loss: 0.489885\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047143; batch adversarial loss: 0.512915\n",
      "epoch 88; iter: 0; batch classifier loss: 0.056549; batch adversarial loss: 0.516553\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050806; batch adversarial loss: 0.414420\n",
      "epoch 90; iter: 0; batch classifier loss: 0.058224; batch adversarial loss: 0.416055\n",
      "epoch 91; iter: 0; batch classifier loss: 0.070428; batch adversarial loss: 0.414173\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069736; batch adversarial loss: 0.486324\n",
      "epoch 93; iter: 0; batch classifier loss: 0.033509; batch adversarial loss: 0.430139\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042648; batch adversarial loss: 0.437325\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053125; batch adversarial loss: 0.424475\n",
      "epoch 96; iter: 0; batch classifier loss: 0.052589; batch adversarial loss: 0.530739\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081553; batch adversarial loss: 0.449408\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067468; batch adversarial loss: 0.446316\n",
      "epoch 99; iter: 0; batch classifier loss: 0.033460; batch adversarial loss: 0.356999\n",
      "epoch 100; iter: 0; batch classifier loss: 0.022440; batch adversarial loss: 0.485017\n",
      "epoch 101; iter: 0; batch classifier loss: 0.035399; batch adversarial loss: 0.614371\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068990; batch adversarial loss: 0.460324\n",
      "epoch 103; iter: 0; batch classifier loss: 0.013673; batch adversarial loss: 0.478764\n",
      "epoch 104; iter: 0; batch classifier loss: 0.014997; batch adversarial loss: 0.533024\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046868; batch adversarial loss: 0.494129\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052584; batch adversarial loss: 0.412954\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039415; batch adversarial loss: 0.466885\n",
      "epoch 108; iter: 0; batch classifier loss: 0.018863; batch adversarial loss: 0.469579\n",
      "epoch 109; iter: 0; batch classifier loss: 0.074990; batch adversarial loss: 0.449668\n",
      "epoch 110; iter: 0; batch classifier loss: 0.016873; batch adversarial loss: 0.455877\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039808; batch adversarial loss: 0.470589\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031223; batch adversarial loss: 0.518202\n",
      "epoch 113; iter: 0; batch classifier loss: 0.018090; batch adversarial loss: 0.502547\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036500; batch adversarial loss: 0.464982\n",
      "epoch 115; iter: 0; batch classifier loss: 0.018177; batch adversarial loss: 0.461592\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041698; batch adversarial loss: 0.392349\n",
      "epoch 117; iter: 0; batch classifier loss: 0.019001; batch adversarial loss: 0.446881\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054605; batch adversarial loss: 0.549561\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054246; batch adversarial loss: 0.430466\n",
      "epoch 120; iter: 0; batch classifier loss: 0.023097; batch adversarial loss: 0.417801\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038065; batch adversarial loss: 0.562795\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043829; batch adversarial loss: 0.506581\n",
      "epoch 123; iter: 0; batch classifier loss: 0.015069; batch adversarial loss: 0.511990\n",
      "epoch 124; iter: 0; batch classifier loss: 0.012796; batch adversarial loss: 0.482541\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028714; batch adversarial loss: 0.544465\n",
      "epoch 126; iter: 0; batch classifier loss: 0.009927; batch adversarial loss: 0.424457\n",
      "epoch 127; iter: 0; batch classifier loss: 0.012334; batch adversarial loss: 0.430772\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017312; batch adversarial loss: 0.440096\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026346; batch adversarial loss: 0.409993\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029106; batch adversarial loss: 0.394934\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040218; batch adversarial loss: 0.452033\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039968; batch adversarial loss: 0.465153\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015087; batch adversarial loss: 0.531606\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026056; batch adversarial loss: 0.480243\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023760; batch adversarial loss: 0.376264\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026140; batch adversarial loss: 0.390246\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017568; batch adversarial loss: 0.431706\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023565; batch adversarial loss: 0.482607\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013821; batch adversarial loss: 0.480850\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035264; batch adversarial loss: 0.437530\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019256; batch adversarial loss: 0.507363\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016893; batch adversarial loss: 0.496340\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023170; batch adversarial loss: 0.549493\n",
      "epoch 144; iter: 0; batch classifier loss: 0.023920; batch adversarial loss: 0.507776\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024440; batch adversarial loss: 0.462788\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023247; batch adversarial loss: 0.387598\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027289; batch adversarial loss: 0.476588\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021386; batch adversarial loss: 0.492162\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036784; batch adversarial loss: 0.453607\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039225; batch adversarial loss: 0.540629\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017374; batch adversarial loss: 0.410947\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019724; batch adversarial loss: 0.393552\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024802; batch adversarial loss: 0.543277\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039879; batch adversarial loss: 0.558678\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025702; batch adversarial loss: 0.361434\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026405; batch adversarial loss: 0.509139\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012269; batch adversarial loss: 0.404222\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034632; batch adversarial loss: 0.527991\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012839; batch adversarial loss: 0.399416\n",
      "epoch 160; iter: 0; batch classifier loss: 0.006688; batch adversarial loss: 0.423427\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008477; batch adversarial loss: 0.449761\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034939; batch adversarial loss: 0.509030\n",
      "epoch 163; iter: 0; batch classifier loss: 0.008312; batch adversarial loss: 0.504434\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032338; batch adversarial loss: 0.357394\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014426; batch adversarial loss: 0.463891\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026038; batch adversarial loss: 0.430883\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008783; batch adversarial loss: 0.450501\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027456; batch adversarial loss: 0.440469\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030589; batch adversarial loss: 0.499798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.024063; batch adversarial loss: 0.475068\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010108; batch adversarial loss: 0.469623\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023297; batch adversarial loss: 0.425210\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018955; batch adversarial loss: 0.500277\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028158; batch adversarial loss: 0.449901\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016906; batch adversarial loss: 0.461663\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012936; batch adversarial loss: 0.509908\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020245; batch adversarial loss: 0.516126\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020994; batch adversarial loss: 0.534730\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020363; batch adversarial loss: 0.514556\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012210; batch adversarial loss: 0.517691\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030304; batch adversarial loss: 0.400849\n",
      "epoch 182; iter: 0; batch classifier loss: 0.004200; batch adversarial loss: 0.498731\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012827; batch adversarial loss: 0.519938\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012822; batch adversarial loss: 0.394173\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025169; batch adversarial loss: 0.456468\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021742; batch adversarial loss: 0.514479\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016836; batch adversarial loss: 0.461897\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040485; batch adversarial loss: 0.436875\n",
      "epoch 189; iter: 0; batch classifier loss: 0.042244; batch adversarial loss: 0.493899\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013494; batch adversarial loss: 0.467278\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021238; batch adversarial loss: 0.439481\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004379; batch adversarial loss: 0.470927\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010443; batch adversarial loss: 0.419418\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008681; batch adversarial loss: 0.534381\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006900; batch adversarial loss: 0.527557\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010899; batch adversarial loss: 0.441281\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034701; batch adversarial loss: 0.515093\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006257; batch adversarial loss: 0.434193\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016917; batch adversarial loss: 0.395748\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718808; batch adversarial loss: 1.075923\n",
      "epoch 1; iter: 0; batch classifier loss: 0.587988; batch adversarial loss: 1.182122\n",
      "epoch 2; iter: 0; batch classifier loss: 0.834320; batch adversarial loss: 1.194034\n",
      "epoch 3; iter: 0; batch classifier loss: 0.986430; batch adversarial loss: 1.122279\n",
      "epoch 4; iter: 0; batch classifier loss: 1.060969; batch adversarial loss: 0.994662\n",
      "epoch 5; iter: 0; batch classifier loss: 1.017725; batch adversarial loss: 0.919645\n",
      "epoch 6; iter: 0; batch classifier loss: 0.810774; batch adversarial loss: 0.837989\n",
      "epoch 7; iter: 0; batch classifier loss: 0.763448; batch adversarial loss: 0.766172\n",
      "epoch 8; iter: 0; batch classifier loss: 0.734560; batch adversarial loss: 0.697139\n",
      "epoch 9; iter: 0; batch classifier loss: 0.598105; batch adversarial loss: 0.647706\n",
      "epoch 10; iter: 0; batch classifier loss: 0.283440; batch adversarial loss: 0.615286\n",
      "epoch 11; iter: 0; batch classifier loss: 0.248354; batch adversarial loss: 0.608421\n",
      "epoch 12; iter: 0; batch classifier loss: 0.203636; batch adversarial loss: 0.582418\n",
      "epoch 13; iter: 0; batch classifier loss: 0.229777; batch adversarial loss: 0.534347\n",
      "epoch 14; iter: 0; batch classifier loss: 0.237060; batch adversarial loss: 0.505980\n",
      "epoch 15; iter: 0; batch classifier loss: 0.262082; batch adversarial loss: 0.545428\n",
      "epoch 16; iter: 0; batch classifier loss: 0.168021; batch adversarial loss: 0.577847\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265425; batch adversarial loss: 0.508546\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197079; batch adversarial loss: 0.544232\n",
      "epoch 19; iter: 0; batch classifier loss: 0.207984; batch adversarial loss: 0.516171\n",
      "epoch 20; iter: 0; batch classifier loss: 0.242323; batch adversarial loss: 0.475593\n",
      "epoch 21; iter: 0; batch classifier loss: 0.137723; batch adversarial loss: 0.450404\n",
      "epoch 22; iter: 0; batch classifier loss: 0.227146; batch adversarial loss: 0.497474\n",
      "epoch 23; iter: 0; batch classifier loss: 0.176474; batch adversarial loss: 0.499684\n",
      "epoch 24; iter: 0; batch classifier loss: 0.179267; batch adversarial loss: 0.568923\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179307; batch adversarial loss: 0.541001\n",
      "epoch 26; iter: 0; batch classifier loss: 0.207099; batch adversarial loss: 0.476741\n",
      "epoch 27; iter: 0; batch classifier loss: 0.110292; batch adversarial loss: 0.394628\n",
      "epoch 28; iter: 0; batch classifier loss: 0.239136; batch adversarial loss: 0.423721\n",
      "epoch 29; iter: 0; batch classifier loss: 0.138103; batch adversarial loss: 0.434502\n",
      "epoch 30; iter: 0; batch classifier loss: 0.080874; batch adversarial loss: 0.447131\n",
      "epoch 31; iter: 0; batch classifier loss: 0.123748; batch adversarial loss: 0.433384\n",
      "epoch 32; iter: 0; batch classifier loss: 0.090796; batch adversarial loss: 0.483641\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143485; batch adversarial loss: 0.472054\n",
      "epoch 34; iter: 0; batch classifier loss: 0.113576; batch adversarial loss: 0.450542\n",
      "epoch 35; iter: 0; batch classifier loss: 0.113046; batch adversarial loss: 0.433098\n",
      "epoch 36; iter: 0; batch classifier loss: 0.085303; batch adversarial loss: 0.508832\n",
      "epoch 37; iter: 0; batch classifier loss: 0.099792; batch adversarial loss: 0.424560\n",
      "epoch 38; iter: 0; batch classifier loss: 0.100319; batch adversarial loss: 0.459659\n",
      "epoch 39; iter: 0; batch classifier loss: 0.088652; batch adversarial loss: 0.419204\n",
      "epoch 40; iter: 0; batch classifier loss: 0.092349; batch adversarial loss: 0.443458\n",
      "epoch 41; iter: 0; batch classifier loss: 0.058699; batch adversarial loss: 0.445304\n",
      "epoch 42; iter: 0; batch classifier loss: 0.083339; batch adversarial loss: 0.479481\n",
      "epoch 43; iter: 0; batch classifier loss: 0.133440; batch adversarial loss: 0.389463\n",
      "epoch 44; iter: 0; batch classifier loss: 0.079322; batch adversarial loss: 0.398650\n",
      "epoch 45; iter: 0; batch classifier loss: 0.121807; batch adversarial loss: 0.445862\n",
      "epoch 46; iter: 0; batch classifier loss: 0.060035; batch adversarial loss: 0.522638\n",
      "epoch 47; iter: 0; batch classifier loss: 0.099400; batch adversarial loss: 0.496292\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081994; batch adversarial loss: 0.479213\n",
      "epoch 49; iter: 0; batch classifier loss: 0.062282; batch adversarial loss: 0.398314\n",
      "epoch 50; iter: 0; batch classifier loss: 0.055186; batch adversarial loss: 0.513098\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083435; batch adversarial loss: 0.474350\n",
      "epoch 52; iter: 0; batch classifier loss: 0.050537; batch adversarial loss: 0.468300\n",
      "epoch 53; iter: 0; batch classifier loss: 0.091893; batch adversarial loss: 0.499620\n",
      "epoch 54; iter: 0; batch classifier loss: 0.055440; batch adversarial loss: 0.424340\n",
      "epoch 55; iter: 0; batch classifier loss: 0.053474; batch adversarial loss: 0.466910\n",
      "epoch 56; iter: 0; batch classifier loss: 0.057079; batch adversarial loss: 0.433746\n",
      "epoch 57; iter: 0; batch classifier loss: 0.041380; batch adversarial loss: 0.483195\n",
      "epoch 58; iter: 0; batch classifier loss: 0.045389; batch adversarial loss: 0.418508\n",
      "epoch 59; iter: 0; batch classifier loss: 0.069552; batch adversarial loss: 0.500795\n",
      "epoch 60; iter: 0; batch classifier loss: 0.038241; batch adversarial loss: 0.394941\n",
      "epoch 61; iter: 0; batch classifier loss: 0.049969; batch adversarial loss: 0.515145\n",
      "epoch 62; iter: 0; batch classifier loss: 0.034319; batch adversarial loss: 0.556186\n",
      "epoch 63; iter: 0; batch classifier loss: 0.050466; batch adversarial loss: 0.451124\n",
      "epoch 64; iter: 0; batch classifier loss: 0.071660; batch adversarial loss: 0.532203\n",
      "epoch 65; iter: 0; batch classifier loss: 0.037432; batch adversarial loss: 0.465925\n",
      "epoch 66; iter: 0; batch classifier loss: 0.052007; batch adversarial loss: 0.419221\n",
      "epoch 67; iter: 0; batch classifier loss: 0.023192; batch adversarial loss: 0.547157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.028704; batch adversarial loss: 0.533382\n",
      "epoch 69; iter: 0; batch classifier loss: 0.041275; batch adversarial loss: 0.391434\n",
      "epoch 70; iter: 0; batch classifier loss: 0.034802; batch adversarial loss: 0.478208\n",
      "epoch 71; iter: 0; batch classifier loss: 0.035391; batch adversarial loss: 0.475259\n",
      "epoch 72; iter: 0; batch classifier loss: 0.038957; batch adversarial loss: 0.421369\n",
      "epoch 73; iter: 0; batch classifier loss: 0.058887; batch adversarial loss: 0.396210\n",
      "epoch 74; iter: 0; batch classifier loss: 0.037915; batch adversarial loss: 0.469512\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071591; batch adversarial loss: 0.459908\n",
      "epoch 76; iter: 0; batch classifier loss: 0.035839; batch adversarial loss: 0.340777\n",
      "epoch 77; iter: 0; batch classifier loss: 0.053112; batch adversarial loss: 0.578660\n",
      "epoch 78; iter: 0; batch classifier loss: 0.056267; batch adversarial loss: 0.463326\n",
      "epoch 79; iter: 0; batch classifier loss: 0.028795; batch adversarial loss: 0.518970\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054450; batch adversarial loss: 0.470717\n",
      "epoch 81; iter: 0; batch classifier loss: 0.049576; batch adversarial loss: 0.432802\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052812; batch adversarial loss: 0.498117\n",
      "epoch 83; iter: 0; batch classifier loss: 0.040160; batch adversarial loss: 0.369689\n",
      "epoch 84; iter: 0; batch classifier loss: 0.030198; batch adversarial loss: 0.441269\n",
      "epoch 85; iter: 0; batch classifier loss: 0.066069; batch adversarial loss: 0.520639\n",
      "epoch 86; iter: 0; batch classifier loss: 0.024264; batch adversarial loss: 0.510112\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042843; batch adversarial loss: 0.464906\n",
      "epoch 88; iter: 0; batch classifier loss: 0.027874; batch adversarial loss: 0.419151\n",
      "epoch 89; iter: 0; batch classifier loss: 0.011129; batch adversarial loss: 0.375476\n",
      "epoch 90; iter: 0; batch classifier loss: 0.017822; batch adversarial loss: 0.539332\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057540; batch adversarial loss: 0.429556\n",
      "epoch 92; iter: 0; batch classifier loss: 0.059133; batch adversarial loss: 0.443667\n",
      "epoch 93; iter: 0; batch classifier loss: 0.023585; batch adversarial loss: 0.504821\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058702; batch adversarial loss: 0.434291\n",
      "epoch 95; iter: 0; batch classifier loss: 0.049228; batch adversarial loss: 0.437550\n",
      "epoch 96; iter: 0; batch classifier loss: 0.024959; batch adversarial loss: 0.460416\n",
      "epoch 97; iter: 0; batch classifier loss: 0.036703; batch adversarial loss: 0.458118\n",
      "epoch 98; iter: 0; batch classifier loss: 0.020103; batch adversarial loss: 0.389498\n",
      "epoch 99; iter: 0; batch classifier loss: 0.020225; batch adversarial loss: 0.445289\n",
      "epoch 100; iter: 0; batch classifier loss: 0.019852; batch adversarial loss: 0.419477\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062267; batch adversarial loss: 0.380154\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053901; batch adversarial loss: 0.497792\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048309; batch adversarial loss: 0.486277\n",
      "epoch 104; iter: 0; batch classifier loss: 0.042485; batch adversarial loss: 0.471539\n",
      "epoch 105; iter: 0; batch classifier loss: 0.016802; batch adversarial loss: 0.376260\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057879; batch adversarial loss: 0.499937\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050115; batch adversarial loss: 0.512654\n",
      "epoch 108; iter: 0; batch classifier loss: 0.027433; batch adversarial loss: 0.518447\n",
      "epoch 109; iter: 0; batch classifier loss: 0.019877; batch adversarial loss: 0.420465\n",
      "epoch 110; iter: 0; batch classifier loss: 0.055441; batch adversarial loss: 0.437916\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030244; batch adversarial loss: 0.376512\n",
      "epoch 112; iter: 0; batch classifier loss: 0.023435; batch adversarial loss: 0.524220\n",
      "epoch 113; iter: 0; batch classifier loss: 0.024056; batch adversarial loss: 0.568334\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032977; batch adversarial loss: 0.447830\n",
      "epoch 115; iter: 0; batch classifier loss: 0.018236; batch adversarial loss: 0.395008\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035032; batch adversarial loss: 0.450322\n",
      "epoch 117; iter: 0; batch classifier loss: 0.017032; batch adversarial loss: 0.470794\n",
      "epoch 118; iter: 0; batch classifier loss: 0.013612; batch adversarial loss: 0.497024\n",
      "epoch 119; iter: 0; batch classifier loss: 0.079269; batch adversarial loss: 0.429209\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032143; batch adversarial loss: 0.438173\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025557; batch adversarial loss: 0.452858\n",
      "epoch 122; iter: 0; batch classifier loss: 0.013175; batch adversarial loss: 0.415217\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046025; batch adversarial loss: 0.449075\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039757; batch adversarial loss: 0.482631\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022183; batch adversarial loss: 0.398795\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047922; batch adversarial loss: 0.437941\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034955; batch adversarial loss: 0.479217\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040426; batch adversarial loss: 0.541098\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031217; batch adversarial loss: 0.390890\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028158; batch adversarial loss: 0.424383\n",
      "epoch 131; iter: 0; batch classifier loss: 0.053483; batch adversarial loss: 0.502591\n",
      "epoch 132; iter: 0; batch classifier loss: 0.014307; batch adversarial loss: 0.536809\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020918; batch adversarial loss: 0.479987\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018110; batch adversarial loss: 0.531190\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032175; batch adversarial loss: 0.486526\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022410; batch adversarial loss: 0.469898\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026507; batch adversarial loss: 0.420778\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029899; batch adversarial loss: 0.487856\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037501; batch adversarial loss: 0.438979\n",
      "epoch 140; iter: 0; batch classifier loss: 0.077792; batch adversarial loss: 0.403731\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034234; batch adversarial loss: 0.438358\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033107; batch adversarial loss: 0.388332\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019554; batch adversarial loss: 0.451561\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040917; batch adversarial loss: 0.465359\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016896; batch adversarial loss: 0.470050\n",
      "epoch 146; iter: 0; batch classifier loss: 0.014352; batch adversarial loss: 0.422331\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029045; batch adversarial loss: 0.446614\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012129; batch adversarial loss: 0.394329\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025676; batch adversarial loss: 0.439579\n",
      "epoch 150; iter: 0; batch classifier loss: 0.045022; batch adversarial loss: 0.477694\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042931; batch adversarial loss: 0.450038\n",
      "epoch 152; iter: 0; batch classifier loss: 0.050225; batch adversarial loss: 0.447326\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025830; batch adversarial loss: 0.438232\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027763; batch adversarial loss: 0.479767\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028465; batch adversarial loss: 0.490217\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027359; batch adversarial loss: 0.431797\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025631; batch adversarial loss: 0.433050\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019662; batch adversarial loss: 0.447309\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017700; batch adversarial loss: 0.484453\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007489; batch adversarial loss: 0.440427\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013651; batch adversarial loss: 0.463443\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010835; batch adversarial loss: 0.448656\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022334; batch adversarial loss: 0.506463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.028744; batch adversarial loss: 0.566047\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009979; batch adversarial loss: 0.471335\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018520; batch adversarial loss: 0.403492\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032034; batch adversarial loss: 0.440951\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008559; batch adversarial loss: 0.462974\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026893; batch adversarial loss: 0.474390\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010008; batch adversarial loss: 0.449605\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015990; batch adversarial loss: 0.466612\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016077; batch adversarial loss: 0.402651\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031546; batch adversarial loss: 0.422687\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010996; batch adversarial loss: 0.444903\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038985; batch adversarial loss: 0.438679\n",
      "epoch 176; iter: 0; batch classifier loss: 0.057096; batch adversarial loss: 0.434633\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023846; batch adversarial loss: 0.439423\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010570; batch adversarial loss: 0.523379\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009828; batch adversarial loss: 0.508174\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040693; batch adversarial loss: 0.424820\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011982; batch adversarial loss: 0.504925\n",
      "epoch 182; iter: 0; batch classifier loss: 0.040767; batch adversarial loss: 0.462454\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025531; batch adversarial loss: 0.440265\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032887; batch adversarial loss: 0.377819\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022492; batch adversarial loss: 0.486417\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009812; batch adversarial loss: 0.510562\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040237; batch adversarial loss: 0.499815\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018270; batch adversarial loss: 0.513706\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011428; batch adversarial loss: 0.457194\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007313; batch adversarial loss: 0.531782\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033586; batch adversarial loss: 0.479454\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027573; batch adversarial loss: 0.456041\n",
      "epoch 193; iter: 0; batch classifier loss: 0.054364; batch adversarial loss: 0.561003\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021294; batch adversarial loss: 0.446604\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011026; batch adversarial loss: 0.423403\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012444; batch adversarial loss: 0.491705\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005188; batch adversarial loss: 0.516587\n",
      "epoch 198; iter: 0; batch classifier loss: 0.033250; batch adversarial loss: 0.404807\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009232; batch adversarial loss: 0.449110\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728617; batch adversarial loss: 0.567476\n",
      "epoch 1; iter: 0; batch classifier loss: 0.421034; batch adversarial loss: 0.609218\n",
      "epoch 2; iter: 0; batch classifier loss: 0.415507; batch adversarial loss: 0.632668\n",
      "epoch 3; iter: 0; batch classifier loss: 0.465887; batch adversarial loss: 0.570480\n",
      "epoch 4; iter: 0; batch classifier loss: 0.321110; batch adversarial loss: 0.589592\n",
      "epoch 5; iter: 0; batch classifier loss: 0.432417; batch adversarial loss: 0.579671\n",
      "epoch 6; iter: 0; batch classifier loss: 0.395221; batch adversarial loss: 0.581469\n",
      "epoch 7; iter: 0; batch classifier loss: 0.434687; batch adversarial loss: 0.623805\n",
      "epoch 8; iter: 0; batch classifier loss: 0.475161; batch adversarial loss: 0.564178\n",
      "epoch 9; iter: 0; batch classifier loss: 0.495276; batch adversarial loss: 0.538159\n",
      "epoch 10; iter: 0; batch classifier loss: 0.430332; batch adversarial loss: 0.526423\n",
      "epoch 11; iter: 0; batch classifier loss: 0.437487; batch adversarial loss: 0.516890\n",
      "epoch 12; iter: 0; batch classifier loss: 0.299591; batch adversarial loss: 0.478020\n",
      "epoch 13; iter: 0; batch classifier loss: 0.261288; batch adversarial loss: 0.446914\n",
      "epoch 14; iter: 0; batch classifier loss: 0.302442; batch adversarial loss: 0.498787\n",
      "epoch 15; iter: 0; batch classifier loss: 0.237079; batch adversarial loss: 0.439234\n",
      "epoch 16; iter: 0; batch classifier loss: 0.239043; batch adversarial loss: 0.460612\n",
      "epoch 17; iter: 0; batch classifier loss: 0.199972; batch adversarial loss: 0.444763\n",
      "epoch 18; iter: 0; batch classifier loss: 0.186840; batch adversarial loss: 0.449508\n",
      "epoch 19; iter: 0; batch classifier loss: 0.315619; batch adversarial loss: 0.464857\n",
      "epoch 20; iter: 0; batch classifier loss: 0.218143; batch adversarial loss: 0.379094\n",
      "epoch 21; iter: 0; batch classifier loss: 0.150598; batch adversarial loss: 0.468651\n",
      "epoch 22; iter: 0; batch classifier loss: 0.178625; batch adversarial loss: 0.441477\n",
      "epoch 23; iter: 0; batch classifier loss: 0.165819; batch adversarial loss: 0.471109\n",
      "epoch 24; iter: 0; batch classifier loss: 0.175379; batch adversarial loss: 0.466141\n",
      "epoch 25; iter: 0; batch classifier loss: 0.142043; batch adversarial loss: 0.450698\n",
      "epoch 26; iter: 0; batch classifier loss: 0.153233; batch adversarial loss: 0.448818\n",
      "epoch 27; iter: 0; batch classifier loss: 0.110513; batch adversarial loss: 0.477237\n",
      "epoch 28; iter: 0; batch classifier loss: 0.124000; batch adversarial loss: 0.496215\n",
      "epoch 29; iter: 0; batch classifier loss: 0.108892; batch adversarial loss: 0.442000\n",
      "epoch 30; iter: 0; batch classifier loss: 0.155709; batch adversarial loss: 0.380401\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156993; batch adversarial loss: 0.518149\n",
      "epoch 32; iter: 0; batch classifier loss: 0.136990; batch adversarial loss: 0.496431\n",
      "epoch 33; iter: 0; batch classifier loss: 0.124481; batch adversarial loss: 0.429082\n",
      "epoch 34; iter: 0; batch classifier loss: 0.129644; batch adversarial loss: 0.463814\n",
      "epoch 35; iter: 0; batch classifier loss: 0.231444; batch adversarial loss: 0.409215\n",
      "epoch 36; iter: 0; batch classifier loss: 0.130369; batch adversarial loss: 0.423642\n",
      "epoch 37; iter: 0; batch classifier loss: 0.145820; batch adversarial loss: 0.443112\n",
      "epoch 38; iter: 0; batch classifier loss: 0.091665; batch adversarial loss: 0.427466\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132785; batch adversarial loss: 0.429221\n",
      "epoch 40; iter: 0; batch classifier loss: 0.151015; batch adversarial loss: 0.462302\n",
      "epoch 41; iter: 0; batch classifier loss: 0.132999; batch adversarial loss: 0.487419\n",
      "epoch 42; iter: 0; batch classifier loss: 0.113092; batch adversarial loss: 0.392954\n",
      "epoch 43; iter: 0; batch classifier loss: 0.093834; batch adversarial loss: 0.459152\n",
      "epoch 44; iter: 0; batch classifier loss: 0.135582; batch adversarial loss: 0.435093\n",
      "epoch 45; iter: 0; batch classifier loss: 0.137526; batch adversarial loss: 0.511388\n",
      "epoch 46; iter: 0; batch classifier loss: 0.153751; batch adversarial loss: 0.466667\n",
      "epoch 47; iter: 0; batch classifier loss: 0.120143; batch adversarial loss: 0.480872\n",
      "epoch 48; iter: 0; batch classifier loss: 0.146737; batch adversarial loss: 0.421290\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114454; batch adversarial loss: 0.479464\n",
      "epoch 50; iter: 0; batch classifier loss: 0.148420; batch adversarial loss: 0.590344\n",
      "epoch 51; iter: 0; batch classifier loss: 0.101349; batch adversarial loss: 0.447649\n",
      "epoch 52; iter: 0; batch classifier loss: 0.144636; batch adversarial loss: 0.430111\n",
      "epoch 53; iter: 0; batch classifier loss: 0.150078; batch adversarial loss: 0.384191\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110651; batch adversarial loss: 0.496412\n",
      "epoch 55; iter: 0; batch classifier loss: 0.139718; batch adversarial loss: 0.553344\n",
      "epoch 56; iter: 0; batch classifier loss: 0.109889; batch adversarial loss: 0.422658\n",
      "epoch 57; iter: 0; batch classifier loss: 0.100480; batch adversarial loss: 0.406653\n",
      "epoch 58; iter: 0; batch classifier loss: 0.067065; batch adversarial loss: 0.459955\n",
      "epoch 59; iter: 0; batch classifier loss: 0.096623; batch adversarial loss: 0.404814\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105554; batch adversarial loss: 0.502320\n",
      "epoch 61; iter: 0; batch classifier loss: 0.070443; batch adversarial loss: 0.445068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.116862; batch adversarial loss: 0.434664\n",
      "epoch 63; iter: 0; batch classifier loss: 0.072160; batch adversarial loss: 0.542397\n",
      "epoch 64; iter: 0; batch classifier loss: 0.115496; batch adversarial loss: 0.389974\n",
      "epoch 65; iter: 0; batch classifier loss: 0.092970; batch adversarial loss: 0.426166\n",
      "epoch 66; iter: 0; batch classifier loss: 0.147530; batch adversarial loss: 0.315947\n",
      "epoch 67; iter: 0; batch classifier loss: 0.076499; batch adversarial loss: 0.559929\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078452; batch adversarial loss: 0.459189\n",
      "epoch 69; iter: 0; batch classifier loss: 0.086862; batch adversarial loss: 0.546012\n",
      "epoch 70; iter: 0; batch classifier loss: 0.093888; batch adversarial loss: 0.518970\n",
      "epoch 71; iter: 0; batch classifier loss: 0.133805; batch adversarial loss: 0.489592\n",
      "epoch 72; iter: 0; batch classifier loss: 0.133036; batch adversarial loss: 0.453072\n",
      "epoch 73; iter: 0; batch classifier loss: 0.073914; batch adversarial loss: 0.386401\n",
      "epoch 74; iter: 0; batch classifier loss: 0.084850; batch adversarial loss: 0.461097\n",
      "epoch 75; iter: 0; batch classifier loss: 0.142451; batch adversarial loss: 0.432824\n",
      "epoch 76; iter: 0; batch classifier loss: 0.168643; batch adversarial loss: 0.463785\n",
      "epoch 77; iter: 0; batch classifier loss: 0.122038; batch adversarial loss: 0.369031\n",
      "epoch 78; iter: 0; batch classifier loss: 0.121202; batch adversarial loss: 0.461832\n",
      "epoch 79; iter: 0; batch classifier loss: 0.042575; batch adversarial loss: 0.451954\n",
      "epoch 80; iter: 0; batch classifier loss: 0.109553; batch adversarial loss: 0.464403\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083875; batch adversarial loss: 0.397812\n",
      "epoch 82; iter: 0; batch classifier loss: 0.122069; batch adversarial loss: 0.484687\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063440; batch adversarial loss: 0.456453\n",
      "epoch 84; iter: 0; batch classifier loss: 0.076381; batch adversarial loss: 0.475903\n",
      "epoch 85; iter: 0; batch classifier loss: 0.056869; batch adversarial loss: 0.473872\n",
      "epoch 86; iter: 0; batch classifier loss: 0.045091; batch adversarial loss: 0.440451\n",
      "epoch 87; iter: 0; batch classifier loss: 0.035059; batch adversarial loss: 0.428537\n",
      "epoch 88; iter: 0; batch classifier loss: 0.079963; batch adversarial loss: 0.435966\n",
      "epoch 89; iter: 0; batch classifier loss: 0.094364; batch adversarial loss: 0.448415\n",
      "epoch 90; iter: 0; batch classifier loss: 0.104627; batch adversarial loss: 0.480955\n",
      "epoch 91; iter: 0; batch classifier loss: 0.144062; batch adversarial loss: 0.409828\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062078; batch adversarial loss: 0.517954\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069085; batch adversarial loss: 0.429373\n",
      "epoch 94; iter: 0; batch classifier loss: 0.060186; batch adversarial loss: 0.374786\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081522; batch adversarial loss: 0.497929\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056338; batch adversarial loss: 0.357688\n",
      "epoch 97; iter: 0; batch classifier loss: 0.067735; batch adversarial loss: 0.426868\n",
      "epoch 98; iter: 0; batch classifier loss: 0.041810; batch adversarial loss: 0.451216\n",
      "epoch 99; iter: 0; batch classifier loss: 0.108607; batch adversarial loss: 0.409099\n",
      "epoch 100; iter: 0; batch classifier loss: 0.095689; batch adversarial loss: 0.449740\n",
      "epoch 101; iter: 0; batch classifier loss: 0.023186; batch adversarial loss: 0.466364\n",
      "epoch 102; iter: 0; batch classifier loss: 0.040838; batch adversarial loss: 0.460725\n",
      "epoch 103; iter: 0; batch classifier loss: 0.091618; batch adversarial loss: 0.438447\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034132; batch adversarial loss: 0.369784\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060804; batch adversarial loss: 0.395542\n",
      "epoch 106; iter: 0; batch classifier loss: 0.080351; batch adversarial loss: 0.487410\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058136; batch adversarial loss: 0.464758\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040666; batch adversarial loss: 0.431204\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060641; batch adversarial loss: 0.438419\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048231; batch adversarial loss: 0.385520\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049402; batch adversarial loss: 0.422623\n",
      "epoch 112; iter: 0; batch classifier loss: 0.089312; batch adversarial loss: 0.416853\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035876; batch adversarial loss: 0.449547\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035036; batch adversarial loss: 0.427324\n",
      "epoch 115; iter: 0; batch classifier loss: 0.087779; batch adversarial loss: 0.407484\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037607; batch adversarial loss: 0.457791\n",
      "epoch 117; iter: 0; batch classifier loss: 0.063796; batch adversarial loss: 0.493797\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060926; batch adversarial loss: 0.504755\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032139; batch adversarial loss: 0.390078\n",
      "epoch 120; iter: 0; batch classifier loss: 0.059946; batch adversarial loss: 0.544894\n",
      "epoch 121; iter: 0; batch classifier loss: 0.074497; batch adversarial loss: 0.454054\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039967; batch adversarial loss: 0.454329\n",
      "epoch 123; iter: 0; batch classifier loss: 0.017138; batch adversarial loss: 0.359233\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020496; batch adversarial loss: 0.471028\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034814; batch adversarial loss: 0.502225\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048815; batch adversarial loss: 0.410621\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043024; batch adversarial loss: 0.449746\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056087; batch adversarial loss: 0.442512\n",
      "epoch 129; iter: 0; batch classifier loss: 0.055019; batch adversarial loss: 0.565137\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033662; batch adversarial loss: 0.410727\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031014; batch adversarial loss: 0.429460\n",
      "epoch 132; iter: 0; batch classifier loss: 0.079317; batch adversarial loss: 0.387750\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018856; batch adversarial loss: 0.491864\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052613; batch adversarial loss: 0.418142\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040360; batch adversarial loss: 0.510662\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057922; batch adversarial loss: 0.459063\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029271; batch adversarial loss: 0.394992\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028228; batch adversarial loss: 0.478496\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025095; batch adversarial loss: 0.442532\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036232; batch adversarial loss: 0.533536\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031505; batch adversarial loss: 0.499496\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043797; batch adversarial loss: 0.433718\n",
      "epoch 143; iter: 0; batch classifier loss: 0.057932; batch adversarial loss: 0.484692\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012559; batch adversarial loss: 0.441258\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026071; batch adversarial loss: 0.459843\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025047; batch adversarial loss: 0.450703\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027709; batch adversarial loss: 0.366132\n",
      "epoch 148; iter: 0; batch classifier loss: 0.041480; batch adversarial loss: 0.410996\n",
      "epoch 149; iter: 0; batch classifier loss: 0.008511; batch adversarial loss: 0.533436\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020317; batch adversarial loss: 0.444850\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030493; batch adversarial loss: 0.404294\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032488; batch adversarial loss: 0.483577\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015482; batch adversarial loss: 0.454859\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020040; batch adversarial loss: 0.487892\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013658; batch adversarial loss: 0.418060\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024692; batch adversarial loss: 0.500281\n",
      "epoch 157; iter: 0; batch classifier loss: 0.078661; batch adversarial loss: 0.493501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.016335; batch adversarial loss: 0.475205\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023186; batch adversarial loss: 0.509217\n",
      "epoch 160; iter: 0; batch classifier loss: 0.050539; batch adversarial loss: 0.446753\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028565; batch adversarial loss: 0.384870\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026626; batch adversarial loss: 0.552575\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020548; batch adversarial loss: 0.471891\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022595; batch adversarial loss: 0.537591\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024071; batch adversarial loss: 0.590260\n",
      "epoch 166; iter: 0; batch classifier loss: 0.057160; batch adversarial loss: 0.531094\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018969; batch adversarial loss: 0.342312\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020164; batch adversarial loss: 0.392466\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023320; batch adversarial loss: 0.468816\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020608; batch adversarial loss: 0.455941\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027031; batch adversarial loss: 0.487835\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019410; batch adversarial loss: 0.410046\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026220; batch adversarial loss: 0.419444\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033975; batch adversarial loss: 0.433580\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019596; batch adversarial loss: 0.491564\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027519; batch adversarial loss: 0.497376\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046598; batch adversarial loss: 0.468738\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010844; batch adversarial loss: 0.470695\n",
      "epoch 179; iter: 0; batch classifier loss: 0.049351; batch adversarial loss: 0.508580\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023863; batch adversarial loss: 0.440420\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017166; batch adversarial loss: 0.435457\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009180; batch adversarial loss: 0.502304\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017555; batch adversarial loss: 0.508531\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016417; batch adversarial loss: 0.487561\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020389; batch adversarial loss: 0.506796\n",
      "epoch 186; iter: 0; batch classifier loss: 0.034830; batch adversarial loss: 0.436585\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040021; batch adversarial loss: 0.425606\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011015; batch adversarial loss: 0.428343\n",
      "epoch 189; iter: 0; batch classifier loss: 0.062585; batch adversarial loss: 0.513845\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007028; batch adversarial loss: 0.404229\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023409; batch adversarial loss: 0.388968\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015396; batch adversarial loss: 0.459834\n",
      "epoch 193; iter: 0; batch classifier loss: 0.099118; batch adversarial loss: 0.447469\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032321; batch adversarial loss: 0.495185\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023498; batch adversarial loss: 0.509742\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031279; batch adversarial loss: 0.370521\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009122; batch adversarial loss: 0.470166\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014195; batch adversarial loss: 0.562921\n",
      "epoch 199; iter: 0; batch classifier loss: 0.036664; batch adversarial loss: 0.497345\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674988; batch adversarial loss: 0.825167\n",
      "epoch 1; iter: 0; batch classifier loss: 0.495297; batch adversarial loss: 0.807981\n",
      "epoch 2; iter: 0; batch classifier loss: 0.387329; batch adversarial loss: 0.735297\n",
      "epoch 3; iter: 0; batch classifier loss: 0.382962; batch adversarial loss: 0.694043\n",
      "epoch 4; iter: 0; batch classifier loss: 0.314965; batch adversarial loss: 0.666709\n",
      "epoch 5; iter: 0; batch classifier loss: 0.298237; batch adversarial loss: 0.642047\n",
      "epoch 6; iter: 0; batch classifier loss: 0.270357; batch adversarial loss: 0.617637\n",
      "epoch 7; iter: 0; batch classifier loss: 0.403646; batch adversarial loss: 0.590799\n",
      "epoch 8; iter: 0; batch classifier loss: 0.311055; batch adversarial loss: 0.563631\n",
      "epoch 9; iter: 0; batch classifier loss: 0.251695; batch adversarial loss: 0.539401\n",
      "epoch 10; iter: 0; batch classifier loss: 0.242362; batch adversarial loss: 0.514022\n",
      "epoch 11; iter: 0; batch classifier loss: 0.272953; batch adversarial loss: 0.497494\n",
      "epoch 12; iter: 0; batch classifier loss: 0.230626; batch adversarial loss: 0.520707\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331151; batch adversarial loss: 0.444342\n",
      "epoch 14; iter: 0; batch classifier loss: 0.305301; batch adversarial loss: 0.447461\n",
      "epoch 15; iter: 0; batch classifier loss: 0.260864; batch adversarial loss: 0.432346\n",
      "epoch 16; iter: 0; batch classifier loss: 0.300135; batch adversarial loss: 0.456314\n",
      "epoch 17; iter: 0; batch classifier loss: 0.213934; batch adversarial loss: 0.400845\n",
      "epoch 18; iter: 0; batch classifier loss: 0.189828; batch adversarial loss: 0.433990\n",
      "epoch 19; iter: 0; batch classifier loss: 0.202248; batch adversarial loss: 0.448486\n",
      "epoch 20; iter: 0; batch classifier loss: 0.212701; batch adversarial loss: 0.413078\n",
      "epoch 21; iter: 0; batch classifier loss: 0.217710; batch adversarial loss: 0.475641\n",
      "epoch 22; iter: 0; batch classifier loss: 0.177521; batch adversarial loss: 0.330356\n",
      "epoch 23; iter: 0; batch classifier loss: 0.160046; batch adversarial loss: 0.424858\n",
      "epoch 24; iter: 0; batch classifier loss: 0.262621; batch adversarial loss: 0.385792\n",
      "epoch 25; iter: 0; batch classifier loss: 0.180524; batch adversarial loss: 0.401096\n",
      "epoch 26; iter: 0; batch classifier loss: 0.205233; batch adversarial loss: 0.388333\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162457; batch adversarial loss: 0.431645\n",
      "epoch 28; iter: 0; batch classifier loss: 0.215782; batch adversarial loss: 0.344341\n",
      "epoch 29; iter: 0; batch classifier loss: 0.218352; batch adversarial loss: 0.378391\n",
      "epoch 30; iter: 0; batch classifier loss: 0.122004; batch adversarial loss: 0.419607\n",
      "epoch 31; iter: 0; batch classifier loss: 0.097368; batch adversarial loss: 0.436017\n",
      "epoch 32; iter: 0; batch classifier loss: 0.197993; batch adversarial loss: 0.352174\n",
      "epoch 33; iter: 0; batch classifier loss: 0.112472; batch adversarial loss: 0.448874\n",
      "epoch 34; iter: 0; batch classifier loss: 0.138284; batch adversarial loss: 0.281960\n",
      "epoch 35; iter: 0; batch classifier loss: 0.147915; batch adversarial loss: 0.442419\n",
      "epoch 36; iter: 0; batch classifier loss: 0.160153; batch adversarial loss: 0.436203\n",
      "epoch 37; iter: 0; batch classifier loss: 0.147477; batch adversarial loss: 0.425130\n",
      "epoch 38; iter: 0; batch classifier loss: 0.086801; batch adversarial loss: 0.430775\n",
      "epoch 39; iter: 0; batch classifier loss: 0.152916; batch adversarial loss: 0.403983\n",
      "epoch 40; iter: 0; batch classifier loss: 0.164073; batch adversarial loss: 0.387217\n",
      "epoch 41; iter: 0; batch classifier loss: 0.121720; batch adversarial loss: 0.299766\n",
      "epoch 42; iter: 0; batch classifier loss: 0.136383; batch adversarial loss: 0.458715\n",
      "epoch 43; iter: 0; batch classifier loss: 0.130545; batch adversarial loss: 0.400104\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118480; batch adversarial loss: 0.330050\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117290; batch adversarial loss: 0.372146\n",
      "epoch 46; iter: 0; batch classifier loss: 0.150939; batch adversarial loss: 0.413459\n",
      "epoch 47; iter: 0; batch classifier loss: 0.132612; batch adversarial loss: 0.412346\n",
      "epoch 48; iter: 0; batch classifier loss: 0.083303; batch adversarial loss: 0.386734\n",
      "epoch 49; iter: 0; batch classifier loss: 0.120738; batch adversarial loss: 0.459459\n",
      "epoch 50; iter: 0; batch classifier loss: 0.089862; batch adversarial loss: 0.444293\n",
      "epoch 51; iter: 0; batch classifier loss: 0.077882; batch adversarial loss: 0.425290\n",
      "epoch 52; iter: 0; batch classifier loss: 0.131795; batch adversarial loss: 0.466456\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084750; batch adversarial loss: 0.397510\n",
      "epoch 54; iter: 0; batch classifier loss: 0.126099; batch adversarial loss: 0.458982\n",
      "epoch 55; iter: 0; batch classifier loss: 0.093019; batch adversarial loss: 0.378598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.113321; batch adversarial loss: 0.455049\n",
      "epoch 57; iter: 0; batch classifier loss: 0.057172; batch adversarial loss: 0.362799\n",
      "epoch 58; iter: 0; batch classifier loss: 0.132982; batch adversarial loss: 0.505137\n",
      "epoch 59; iter: 0; batch classifier loss: 0.068778; batch adversarial loss: 0.350995\n",
      "epoch 60; iter: 0; batch classifier loss: 0.093311; batch adversarial loss: 0.396153\n",
      "epoch 61; iter: 0; batch classifier loss: 0.063245; batch adversarial loss: 0.426299\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093666; batch adversarial loss: 0.378514\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103893; batch adversarial loss: 0.383635\n",
      "epoch 64; iter: 0; batch classifier loss: 0.086487; batch adversarial loss: 0.445510\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065718; batch adversarial loss: 0.460984\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060965; batch adversarial loss: 0.381012\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082109; batch adversarial loss: 0.464818\n",
      "epoch 68; iter: 0; batch classifier loss: 0.063129; batch adversarial loss: 0.385470\n",
      "epoch 69; iter: 0; batch classifier loss: 0.057979; batch adversarial loss: 0.416377\n",
      "epoch 70; iter: 0; batch classifier loss: 0.118104; batch adversarial loss: 0.490394\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073354; batch adversarial loss: 0.340744\n",
      "epoch 72; iter: 0; batch classifier loss: 0.079658; batch adversarial loss: 0.441678\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077364; batch adversarial loss: 0.458516\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067856; batch adversarial loss: 0.462329\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071527; batch adversarial loss: 0.412641\n",
      "epoch 76; iter: 0; batch classifier loss: 0.084648; batch adversarial loss: 0.387699\n",
      "epoch 77; iter: 0; batch classifier loss: 0.146105; batch adversarial loss: 0.466675\n",
      "epoch 78; iter: 0; batch classifier loss: 0.058505; batch adversarial loss: 0.396755\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063607; batch adversarial loss: 0.319503\n",
      "epoch 80; iter: 0; batch classifier loss: 0.085777; batch adversarial loss: 0.426454\n",
      "epoch 81; iter: 0; batch classifier loss: 0.052165; batch adversarial loss: 0.320004\n",
      "epoch 82; iter: 0; batch classifier loss: 0.079884; batch adversarial loss: 0.460984\n",
      "epoch 83; iter: 0; batch classifier loss: 0.066070; batch adversarial loss: 0.364068\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068036; batch adversarial loss: 0.498556\n",
      "epoch 85; iter: 0; batch classifier loss: 0.040005; batch adversarial loss: 0.455540\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053324; batch adversarial loss: 0.467494\n",
      "epoch 87; iter: 0; batch classifier loss: 0.094127; batch adversarial loss: 0.461856\n",
      "epoch 88; iter: 0; batch classifier loss: 0.109916; batch adversarial loss: 0.415505\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068675; batch adversarial loss: 0.417765\n",
      "epoch 90; iter: 0; batch classifier loss: 0.112435; batch adversarial loss: 0.455500\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056559; batch adversarial loss: 0.550912\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052792; batch adversarial loss: 0.549496\n",
      "epoch 93; iter: 0; batch classifier loss: 0.079855; batch adversarial loss: 0.392670\n",
      "epoch 94; iter: 0; batch classifier loss: 0.085198; batch adversarial loss: 0.350902\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052439; batch adversarial loss: 0.396999\n",
      "epoch 96; iter: 0; batch classifier loss: 0.079738; batch adversarial loss: 0.401016\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057786; batch adversarial loss: 0.421891\n",
      "epoch 98; iter: 0; batch classifier loss: 0.078903; batch adversarial loss: 0.470904\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069490; batch adversarial loss: 0.437008\n",
      "epoch 100; iter: 0; batch classifier loss: 0.092661; batch adversarial loss: 0.369456\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049950; batch adversarial loss: 0.372001\n",
      "epoch 102; iter: 0; batch classifier loss: 0.085486; batch adversarial loss: 0.395091\n",
      "epoch 103; iter: 0; batch classifier loss: 0.099247; batch adversarial loss: 0.487754\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071854; batch adversarial loss: 0.403993\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045315; batch adversarial loss: 0.418631\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041793; batch adversarial loss: 0.409449\n",
      "epoch 107; iter: 0; batch classifier loss: 0.025131; batch adversarial loss: 0.405112\n",
      "epoch 108; iter: 0; batch classifier loss: 0.066766; batch adversarial loss: 0.382727\n",
      "epoch 109; iter: 0; batch classifier loss: 0.055352; batch adversarial loss: 0.410395\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064166; batch adversarial loss: 0.420643\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042867; batch adversarial loss: 0.433537\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043342; batch adversarial loss: 0.465020\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054116; batch adversarial loss: 0.404499\n",
      "epoch 114; iter: 0; batch classifier loss: 0.080059; batch adversarial loss: 0.424197\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051415; batch adversarial loss: 0.412040\n",
      "epoch 116; iter: 0; batch classifier loss: 0.064334; batch adversarial loss: 0.442244\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044263; batch adversarial loss: 0.462338\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037446; batch adversarial loss: 0.461630\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036719; batch adversarial loss: 0.496234\n",
      "epoch 120; iter: 0; batch classifier loss: 0.071356; batch adversarial loss: 0.381739\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041229; batch adversarial loss: 0.455217\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051188; batch adversarial loss: 0.439993\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057185; batch adversarial loss: 0.374543\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050555; batch adversarial loss: 0.428599\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039089; batch adversarial loss: 0.433675\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043783; batch adversarial loss: 0.457237\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046151; batch adversarial loss: 0.432795\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038913; batch adversarial loss: 0.354933\n",
      "epoch 129; iter: 0; batch classifier loss: 0.061047; batch adversarial loss: 0.391723\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022356; batch adversarial loss: 0.390920\n",
      "epoch 131; iter: 0; batch classifier loss: 0.060029; batch adversarial loss: 0.459208\n",
      "epoch 132; iter: 0; batch classifier loss: 0.056519; batch adversarial loss: 0.340630\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021778; batch adversarial loss: 0.556491\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020781; batch adversarial loss: 0.332115\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016467; batch adversarial loss: 0.427626\n",
      "epoch 136; iter: 0; batch classifier loss: 0.055020; batch adversarial loss: 0.416366\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017953; batch adversarial loss: 0.386307\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035308; batch adversarial loss: 0.434151\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044374; batch adversarial loss: 0.516035\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026109; batch adversarial loss: 0.394472\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021491; batch adversarial loss: 0.376974\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036978; batch adversarial loss: 0.458045\n",
      "epoch 143; iter: 0; batch classifier loss: 0.057846; batch adversarial loss: 0.502303\n",
      "epoch 144; iter: 0; batch classifier loss: 0.011563; batch adversarial loss: 0.469092\n",
      "epoch 145; iter: 0; batch classifier loss: 0.052703; batch adversarial loss: 0.479354\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024361; batch adversarial loss: 0.540771\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026078; batch adversarial loss: 0.416082\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033187; batch adversarial loss: 0.445923\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053722; batch adversarial loss: 0.467331\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030487; batch adversarial loss: 0.386596\n",
      "epoch 151; iter: 0; batch classifier loss: 0.060603; batch adversarial loss: 0.554781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.050132; batch adversarial loss: 0.459699\n",
      "epoch 153; iter: 0; batch classifier loss: 0.077569; batch adversarial loss: 0.614166\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036950; batch adversarial loss: 0.488500\n",
      "epoch 155; iter: 0; batch classifier loss: 0.094297; batch adversarial loss: 0.603671\n",
      "epoch 156; iter: 0; batch classifier loss: 0.079271; batch adversarial loss: 0.588399\n",
      "epoch 157; iter: 0; batch classifier loss: 0.109928; batch adversarial loss: 0.686668\n",
      "epoch 158; iter: 0; batch classifier loss: 0.076243; batch adversarial loss: 0.538445\n",
      "epoch 159; iter: 0; batch classifier loss: 0.094610; batch adversarial loss: 0.705043\n",
      "epoch 160; iter: 0; batch classifier loss: 0.149897; batch adversarial loss: 0.681201\n",
      "epoch 161; iter: 0; batch classifier loss: 0.116147; batch adversarial loss: 0.622358\n",
      "epoch 162; iter: 0; batch classifier loss: 0.082278; batch adversarial loss: 0.485987\n",
      "epoch 163; iter: 0; batch classifier loss: 0.106766; batch adversarial loss: 0.622818\n",
      "epoch 164; iter: 0; batch classifier loss: 0.117486; batch adversarial loss: 0.516506\n",
      "epoch 165; iter: 0; batch classifier loss: 0.096111; batch adversarial loss: 0.572186\n",
      "epoch 166; iter: 0; batch classifier loss: 0.151840; batch adversarial loss: 0.664589\n",
      "epoch 167; iter: 0; batch classifier loss: 0.101173; batch adversarial loss: 0.561777\n",
      "epoch 168; iter: 0; batch classifier loss: 0.212459; batch adversarial loss: 0.798894\n",
      "epoch 169; iter: 0; batch classifier loss: 0.107329; batch adversarial loss: 0.501018\n",
      "epoch 170; iter: 0; batch classifier loss: 0.167519; batch adversarial loss: 0.623543\n",
      "epoch 171; iter: 0; batch classifier loss: 0.205159; batch adversarial loss: 0.658597\n",
      "epoch 172; iter: 0; batch classifier loss: 0.201737; batch adversarial loss: 0.647769\n",
      "epoch 173; iter: 0; batch classifier loss: 0.186417; batch adversarial loss: 0.664053\n",
      "epoch 174; iter: 0; batch classifier loss: 0.193218; batch adversarial loss: 0.543918\n",
      "epoch 175; iter: 0; batch classifier loss: 0.125986; batch adversarial loss: 0.548300\n",
      "epoch 176; iter: 0; batch classifier loss: 0.109636; batch adversarial loss: 0.508275\n",
      "epoch 177; iter: 0; batch classifier loss: 0.111086; batch adversarial loss: 0.592402\n",
      "epoch 178; iter: 0; batch classifier loss: 0.086416; batch adversarial loss: 0.454108\n",
      "epoch 179; iter: 0; batch classifier loss: 0.144677; batch adversarial loss: 0.609191\n",
      "epoch 180; iter: 0; batch classifier loss: 0.232883; batch adversarial loss: 0.668948\n",
      "epoch 181; iter: 0; batch classifier loss: 0.194510; batch adversarial loss: 0.661008\n",
      "epoch 182; iter: 0; batch classifier loss: 0.173166; batch adversarial loss: 0.632384\n",
      "epoch 183; iter: 0; batch classifier loss: 0.152841; batch adversarial loss: 0.541916\n",
      "epoch 184; iter: 0; batch classifier loss: 0.132582; batch adversarial loss: 0.510723\n",
      "epoch 185; iter: 0; batch classifier loss: 0.107008; batch adversarial loss: 0.495696\n",
      "epoch 186; iter: 0; batch classifier loss: 0.182245; batch adversarial loss: 0.593466\n",
      "epoch 187; iter: 0; batch classifier loss: 0.161040; batch adversarial loss: 0.597197\n",
      "epoch 188; iter: 0; batch classifier loss: 0.138648; batch adversarial loss: 0.465120\n",
      "epoch 189; iter: 0; batch classifier loss: 0.174311; batch adversarial loss: 0.566030\n",
      "epoch 190; iter: 0; batch classifier loss: 0.140500; batch adversarial loss: 0.551738\n",
      "epoch 191; iter: 0; batch classifier loss: 0.199125; batch adversarial loss: 0.640600\n",
      "epoch 192; iter: 0; batch classifier loss: 0.111065; batch adversarial loss: 0.489340\n",
      "epoch 193; iter: 0; batch classifier loss: 0.109112; batch adversarial loss: 0.477802\n",
      "epoch 194; iter: 0; batch classifier loss: 0.162019; batch adversarial loss: 0.596243\n",
      "epoch 195; iter: 0; batch classifier loss: 0.151053; batch adversarial loss: 0.512227\n",
      "epoch 196; iter: 0; batch classifier loss: 0.116012; batch adversarial loss: 0.491761\n",
      "epoch 197; iter: 0; batch classifier loss: 0.112815; batch adversarial loss: 0.475701\n",
      "epoch 198; iter: 0; batch classifier loss: 0.119015; batch adversarial loss: 0.534255\n",
      "epoch 199; iter: 0; batch classifier loss: 0.127358; batch adversarial loss: 0.532503\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687396; batch adversarial loss: 0.682625\n",
      "epoch 1; iter: 0; batch classifier loss: 0.416201; batch adversarial loss: 0.643388\n",
      "epoch 2; iter: 0; batch classifier loss: 0.392040; batch adversarial loss: 0.624448\n",
      "epoch 3; iter: 0; batch classifier loss: 0.308583; batch adversarial loss: 0.605352\n",
      "epoch 4; iter: 0; batch classifier loss: 0.366760; batch adversarial loss: 0.557940\n",
      "epoch 5; iter: 0; batch classifier loss: 0.337699; batch adversarial loss: 0.516889\n",
      "epoch 6; iter: 0; batch classifier loss: 0.215635; batch adversarial loss: 0.565320\n",
      "epoch 7; iter: 0; batch classifier loss: 0.243292; batch adversarial loss: 0.501938\n",
      "epoch 8; iter: 0; batch classifier loss: 0.349728; batch adversarial loss: 0.533812\n",
      "epoch 9; iter: 0; batch classifier loss: 0.239557; batch adversarial loss: 0.501171\n",
      "epoch 10; iter: 0; batch classifier loss: 0.255738; batch adversarial loss: 0.517638\n",
      "epoch 11; iter: 0; batch classifier loss: 0.186158; batch adversarial loss: 0.513133\n",
      "epoch 12; iter: 0; batch classifier loss: 0.245844; batch adversarial loss: 0.468597\n",
      "epoch 13; iter: 0; batch classifier loss: 0.243802; batch adversarial loss: 0.496577\n",
      "epoch 14; iter: 0; batch classifier loss: 0.227677; batch adversarial loss: 0.558238\n",
      "epoch 15; iter: 0; batch classifier loss: 0.291121; batch adversarial loss: 0.523436\n",
      "epoch 16; iter: 0; batch classifier loss: 0.233726; batch adversarial loss: 0.437541\n",
      "epoch 17; iter: 0; batch classifier loss: 0.249298; batch adversarial loss: 0.529463\n",
      "epoch 18; iter: 0; batch classifier loss: 0.204988; batch adversarial loss: 0.442568\n",
      "epoch 19; iter: 0; batch classifier loss: 0.367433; batch adversarial loss: 0.518386\n",
      "epoch 20; iter: 0; batch classifier loss: 0.434300; batch adversarial loss: 0.505545\n",
      "epoch 21; iter: 0; batch classifier loss: 0.563599; batch adversarial loss: 0.570111\n",
      "epoch 22; iter: 0; batch classifier loss: 0.296876; batch adversarial loss: 0.479335\n",
      "epoch 23; iter: 0; batch classifier loss: 0.221089; batch adversarial loss: 0.460561\n",
      "epoch 24; iter: 0; batch classifier loss: 0.171315; batch adversarial loss: 0.546269\n",
      "epoch 25; iter: 0; batch classifier loss: 0.193089; batch adversarial loss: 0.508607\n",
      "epoch 26; iter: 0; batch classifier loss: 0.171122; batch adversarial loss: 0.515558\n",
      "epoch 27; iter: 0; batch classifier loss: 0.105233; batch adversarial loss: 0.418003\n",
      "epoch 28; iter: 0; batch classifier loss: 0.103026; batch adversarial loss: 0.516637\n",
      "epoch 29; iter: 0; batch classifier loss: 0.172454; batch adversarial loss: 0.423040\n",
      "epoch 30; iter: 0; batch classifier loss: 0.143393; batch adversarial loss: 0.417354\n",
      "epoch 31; iter: 0; batch classifier loss: 0.191609; batch adversarial loss: 0.529925\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146243; batch adversarial loss: 0.521664\n",
      "epoch 33; iter: 0; batch classifier loss: 0.121322; batch adversarial loss: 0.539357\n",
      "epoch 34; iter: 0; batch classifier loss: 0.164005; batch adversarial loss: 0.430254\n",
      "epoch 35; iter: 0; batch classifier loss: 0.162053; batch adversarial loss: 0.425522\n",
      "epoch 36; iter: 0; batch classifier loss: 0.122022; batch adversarial loss: 0.441000\n",
      "epoch 37; iter: 0; batch classifier loss: 0.078080; batch adversarial loss: 0.429342\n",
      "epoch 38; iter: 0; batch classifier loss: 0.112179; batch adversarial loss: 0.565902\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107296; batch adversarial loss: 0.428372\n",
      "epoch 40; iter: 0; batch classifier loss: 0.117244; batch adversarial loss: 0.500226\n",
      "epoch 41; iter: 0; batch classifier loss: 0.077296; batch adversarial loss: 0.381733\n",
      "epoch 42; iter: 0; batch classifier loss: 0.169533; batch adversarial loss: 0.488263\n",
      "epoch 43; iter: 0; batch classifier loss: 0.129550; batch adversarial loss: 0.438025\n",
      "epoch 44; iter: 0; batch classifier loss: 0.079338; batch adversarial loss: 0.565208\n",
      "epoch 45; iter: 0; batch classifier loss: 0.096810; batch adversarial loss: 0.430204\n",
      "epoch 46; iter: 0; batch classifier loss: 0.122099; batch adversarial loss: 0.392152\n",
      "epoch 47; iter: 0; batch classifier loss: 0.107277; batch adversarial loss: 0.416944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.114290; batch adversarial loss: 0.432510\n",
      "epoch 49; iter: 0; batch classifier loss: 0.088032; batch adversarial loss: 0.546913\n",
      "epoch 50; iter: 0; batch classifier loss: 0.106343; batch adversarial loss: 0.380498\n",
      "epoch 51; iter: 0; batch classifier loss: 0.102677; batch adversarial loss: 0.531059\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111335; batch adversarial loss: 0.525767\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096528; batch adversarial loss: 0.377928\n",
      "epoch 54; iter: 0; batch classifier loss: 0.080803; batch adversarial loss: 0.532324\n",
      "epoch 55; iter: 0; batch classifier loss: 0.085640; batch adversarial loss: 0.454689\n",
      "epoch 56; iter: 0; batch classifier loss: 0.112294; batch adversarial loss: 0.457932\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082878; batch adversarial loss: 0.449367\n",
      "epoch 58; iter: 0; batch classifier loss: 0.069057; batch adversarial loss: 0.475304\n",
      "epoch 59; iter: 0; batch classifier loss: 0.060295; batch adversarial loss: 0.378962\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122191; batch adversarial loss: 0.547193\n",
      "epoch 61; iter: 0; batch classifier loss: 0.108178; batch adversarial loss: 0.409984\n",
      "epoch 62; iter: 0; batch classifier loss: 0.067998; batch adversarial loss: 0.372696\n",
      "epoch 63; iter: 0; batch classifier loss: 0.106269; batch adversarial loss: 0.429786\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090501; batch adversarial loss: 0.456055\n",
      "epoch 65; iter: 0; batch classifier loss: 0.050176; batch adversarial loss: 0.481126\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062353; batch adversarial loss: 0.483297\n",
      "epoch 67; iter: 0; batch classifier loss: 0.075401; batch adversarial loss: 0.495918\n",
      "epoch 68; iter: 0; batch classifier loss: 0.098744; batch adversarial loss: 0.517049\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061353; batch adversarial loss: 0.461109\n",
      "epoch 70; iter: 0; batch classifier loss: 0.082122; batch adversarial loss: 0.449696\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092066; batch adversarial loss: 0.452127\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080035; batch adversarial loss: 0.460545\n",
      "epoch 73; iter: 0; batch classifier loss: 0.112075; batch adversarial loss: 0.502303\n",
      "epoch 74; iter: 0; batch classifier loss: 0.074591; batch adversarial loss: 0.494823\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071610; batch adversarial loss: 0.502013\n",
      "epoch 76; iter: 0; batch classifier loss: 0.056797; batch adversarial loss: 0.452087\n",
      "epoch 77; iter: 0; batch classifier loss: 0.092028; batch adversarial loss: 0.438429\n",
      "epoch 78; iter: 0; batch classifier loss: 0.063454; batch adversarial loss: 0.436628\n",
      "epoch 79; iter: 0; batch classifier loss: 0.073639; batch adversarial loss: 0.477625\n",
      "epoch 80; iter: 0; batch classifier loss: 0.039606; batch adversarial loss: 0.431345\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057623; batch adversarial loss: 0.419701\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053195; batch adversarial loss: 0.535131\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065558; batch adversarial loss: 0.458917\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082956; batch adversarial loss: 0.472609\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046978; batch adversarial loss: 0.487585\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074716; batch adversarial loss: 0.555431\n",
      "epoch 87; iter: 0; batch classifier loss: 0.113475; batch adversarial loss: 0.458998\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055618; batch adversarial loss: 0.460541\n",
      "epoch 89; iter: 0; batch classifier loss: 0.103715; batch adversarial loss: 0.506413\n",
      "epoch 90; iter: 0; batch classifier loss: 0.085073; batch adversarial loss: 0.440327\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068598; batch adversarial loss: 0.461323\n",
      "epoch 92; iter: 0; batch classifier loss: 0.043208; batch adversarial loss: 0.502094\n",
      "epoch 93; iter: 0; batch classifier loss: 0.082716; batch adversarial loss: 0.400326\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039132; batch adversarial loss: 0.373789\n",
      "epoch 95; iter: 0; batch classifier loss: 0.067240; batch adversarial loss: 0.431719\n",
      "epoch 96; iter: 0; batch classifier loss: 0.034847; batch adversarial loss: 0.487432\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044965; batch adversarial loss: 0.411007\n",
      "epoch 98; iter: 0; batch classifier loss: 0.040928; batch adversarial loss: 0.358389\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058916; batch adversarial loss: 0.451563\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074933; batch adversarial loss: 0.496004\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068713; batch adversarial loss: 0.390619\n",
      "epoch 102; iter: 0; batch classifier loss: 0.045674; batch adversarial loss: 0.515155\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053078; batch adversarial loss: 0.416212\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038650; batch adversarial loss: 0.390383\n",
      "epoch 105; iter: 0; batch classifier loss: 0.024208; batch adversarial loss: 0.507505\n",
      "epoch 106; iter: 0; batch classifier loss: 0.020505; batch adversarial loss: 0.520532\n",
      "epoch 107; iter: 0; batch classifier loss: 0.029513; batch adversarial loss: 0.507032\n",
      "epoch 108; iter: 0; batch classifier loss: 0.029354; batch adversarial loss: 0.495042\n",
      "epoch 109; iter: 0; batch classifier loss: 0.052700; batch adversarial loss: 0.512339\n",
      "epoch 110; iter: 0; batch classifier loss: 0.024898; batch adversarial loss: 0.543362\n",
      "epoch 111; iter: 0; batch classifier loss: 0.024534; batch adversarial loss: 0.409874\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059484; batch adversarial loss: 0.542042\n",
      "epoch 113; iter: 0; batch classifier loss: 0.036926; batch adversarial loss: 0.357873\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061592; batch adversarial loss: 0.392242\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065178; batch adversarial loss: 0.490590\n",
      "epoch 116; iter: 0; batch classifier loss: 0.077759; batch adversarial loss: 0.438699\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060036; batch adversarial loss: 0.432598\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033481; batch adversarial loss: 0.495941\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047234; batch adversarial loss: 0.478194\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031971; batch adversarial loss: 0.552933\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046873; batch adversarial loss: 0.491135\n",
      "epoch 122; iter: 0; batch classifier loss: 0.047789; batch adversarial loss: 0.450226\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032211; batch adversarial loss: 0.494214\n",
      "epoch 124; iter: 0; batch classifier loss: 0.049719; batch adversarial loss: 0.428834\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048526; batch adversarial loss: 0.507685\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039340; batch adversarial loss: 0.444559\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047877; batch adversarial loss: 0.470277\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043689; batch adversarial loss: 0.453595\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025526; batch adversarial loss: 0.467489\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016584; batch adversarial loss: 0.553292\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020905; batch adversarial loss: 0.381246\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030767; batch adversarial loss: 0.487789\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023242; batch adversarial loss: 0.495462\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062238; batch adversarial loss: 0.464362\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041919; batch adversarial loss: 0.457456\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020879; batch adversarial loss: 0.468113\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032960; batch adversarial loss: 0.578016\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017063; batch adversarial loss: 0.497056\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034511; batch adversarial loss: 0.476572\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034279; batch adversarial loss: 0.444151\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018471; batch adversarial loss: 0.519983\n",
      "epoch 142; iter: 0; batch classifier loss: 0.058431; batch adversarial loss: 0.451423\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023515; batch adversarial loss: 0.442066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.052670; batch adversarial loss: 0.382339\n",
      "epoch 145; iter: 0; batch classifier loss: 0.091264; batch adversarial loss: 0.362368\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020349; batch adversarial loss: 0.501204\n",
      "epoch 147; iter: 0; batch classifier loss: 0.058936; batch adversarial loss: 0.407115\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029609; batch adversarial loss: 0.456705\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032519; batch adversarial loss: 0.530561\n",
      "epoch 150; iter: 0; batch classifier loss: 0.058481; batch adversarial loss: 0.543323\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033571; batch adversarial loss: 0.426124\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020019; batch adversarial loss: 0.478604\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026506; batch adversarial loss: 0.448533\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040089; batch adversarial loss: 0.422160\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018672; batch adversarial loss: 0.456496\n",
      "epoch 156; iter: 0; batch classifier loss: 0.046844; batch adversarial loss: 0.411406\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030552; batch adversarial loss: 0.431996\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018756; batch adversarial loss: 0.478747\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049353; batch adversarial loss: 0.512989\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037261; batch adversarial loss: 0.466725\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025307; batch adversarial loss: 0.415767\n",
      "epoch 162; iter: 0; batch classifier loss: 0.068832; batch adversarial loss: 0.483863\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039775; batch adversarial loss: 0.513959\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019479; batch adversarial loss: 0.451185\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008013; batch adversarial loss: 0.511638\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026562; batch adversarial loss: 0.447973\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030280; batch adversarial loss: 0.437339\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045620; batch adversarial loss: 0.389782\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028808; batch adversarial loss: 0.545090\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035950; batch adversarial loss: 0.410556\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036309; batch adversarial loss: 0.554525\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019498; batch adversarial loss: 0.481375\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023138; batch adversarial loss: 0.492212\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030404; batch adversarial loss: 0.449922\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011851; batch adversarial loss: 0.515514\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017620; batch adversarial loss: 0.420962\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009900; batch adversarial loss: 0.428618\n",
      "epoch 178; iter: 0; batch classifier loss: 0.070975; batch adversarial loss: 0.462003\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008611; batch adversarial loss: 0.488652\n",
      "epoch 180; iter: 0; batch classifier loss: 0.047195; batch adversarial loss: 0.500744\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024554; batch adversarial loss: 0.469322\n",
      "epoch 182; iter: 0; batch classifier loss: 0.044154; batch adversarial loss: 0.494815\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025094; batch adversarial loss: 0.544977\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022080; batch adversarial loss: 0.367346\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017495; batch adversarial loss: 0.432026\n",
      "epoch 186; iter: 0; batch classifier loss: 0.047599; batch adversarial loss: 0.392348\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011349; batch adversarial loss: 0.419566\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041099; batch adversarial loss: 0.498033\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031071; batch adversarial loss: 0.484835\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026898; batch adversarial loss: 0.417363\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015581; batch adversarial loss: 0.484437\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032200; batch adversarial loss: 0.424075\n",
      "epoch 193; iter: 0; batch classifier loss: 0.046787; batch adversarial loss: 0.465154\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019474; batch adversarial loss: 0.495599\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010917; batch adversarial loss: 0.517238\n",
      "epoch 196; iter: 0; batch classifier loss: 0.066328; batch adversarial loss: 0.390210\n",
      "epoch 197; iter: 0; batch classifier loss: 0.086128; batch adversarial loss: 0.502169\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031040; batch adversarial loss: 0.524048\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018133; batch adversarial loss: 0.364731\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694625; batch adversarial loss: 0.797163\n",
      "epoch 1; iter: 0; batch classifier loss: 0.552139; batch adversarial loss: 0.759937\n",
      "epoch 2; iter: 0; batch classifier loss: 0.695039; batch adversarial loss: 0.728777\n",
      "epoch 3; iter: 0; batch classifier loss: 0.657142; batch adversarial loss: 0.670195\n",
      "epoch 4; iter: 0; batch classifier loss: 0.475708; batch adversarial loss: 0.637411\n",
      "epoch 5; iter: 0; batch classifier loss: 0.443732; batch adversarial loss: 0.580077\n",
      "epoch 6; iter: 0; batch classifier loss: 0.322615; batch adversarial loss: 0.559587\n",
      "epoch 7; iter: 0; batch classifier loss: 0.252213; batch adversarial loss: 0.550656\n",
      "epoch 8; iter: 0; batch classifier loss: 0.282715; batch adversarial loss: 0.594403\n",
      "epoch 9; iter: 0; batch classifier loss: 0.305702; batch adversarial loss: 0.583273\n",
      "epoch 10; iter: 0; batch classifier loss: 0.238849; batch adversarial loss: 0.564670\n",
      "epoch 11; iter: 0; batch classifier loss: 0.295965; batch adversarial loss: 0.496272\n",
      "epoch 12; iter: 0; batch classifier loss: 0.258840; batch adversarial loss: 0.511927\n",
      "epoch 13; iter: 0; batch classifier loss: 0.241332; batch adversarial loss: 0.558168\n",
      "epoch 14; iter: 0; batch classifier loss: 0.227512; batch adversarial loss: 0.499705\n",
      "epoch 15; iter: 0; batch classifier loss: 0.261771; batch adversarial loss: 0.511632\n",
      "epoch 16; iter: 0; batch classifier loss: 0.226016; batch adversarial loss: 0.501468\n",
      "epoch 17; iter: 0; batch classifier loss: 0.231966; batch adversarial loss: 0.559455\n",
      "epoch 18; iter: 0; batch classifier loss: 0.267651; batch adversarial loss: 0.565994\n",
      "epoch 19; iter: 0; batch classifier loss: 0.177378; batch adversarial loss: 0.504537\n",
      "epoch 20; iter: 0; batch classifier loss: 0.202298; batch adversarial loss: 0.437643\n",
      "epoch 21; iter: 0; batch classifier loss: 0.163612; batch adversarial loss: 0.486401\n",
      "epoch 22; iter: 0; batch classifier loss: 0.151668; batch adversarial loss: 0.454103\n",
      "epoch 23; iter: 0; batch classifier loss: 0.183824; batch adversarial loss: 0.495839\n",
      "epoch 24; iter: 0; batch classifier loss: 0.167128; batch adversarial loss: 0.562161\n",
      "epoch 25; iter: 0; batch classifier loss: 0.128717; batch adversarial loss: 0.441252\n",
      "epoch 26; iter: 0; batch classifier loss: 0.111883; batch adversarial loss: 0.507786\n",
      "epoch 27; iter: 0; batch classifier loss: 0.161137; batch adversarial loss: 0.412393\n",
      "epoch 28; iter: 0; batch classifier loss: 0.171565; batch adversarial loss: 0.534629\n",
      "epoch 29; iter: 0; batch classifier loss: 0.104286; batch adversarial loss: 0.375315\n",
      "epoch 30; iter: 0; batch classifier loss: 0.095313; batch adversarial loss: 0.540170\n",
      "epoch 31; iter: 0; batch classifier loss: 0.146847; batch adversarial loss: 0.435095\n",
      "epoch 32; iter: 0; batch classifier loss: 0.105216; batch adversarial loss: 0.511861\n",
      "epoch 33; iter: 0; batch classifier loss: 0.090418; batch adversarial loss: 0.469848\n",
      "epoch 34; iter: 0; batch classifier loss: 0.100276; batch adversarial loss: 0.447787\n",
      "epoch 35; iter: 0; batch classifier loss: 0.138953; batch adversarial loss: 0.395672\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128533; batch adversarial loss: 0.451265\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113238; batch adversarial loss: 0.484639\n",
      "epoch 38; iter: 0; batch classifier loss: 0.089934; batch adversarial loss: 0.458095\n",
      "epoch 39; iter: 0; batch classifier loss: 0.104520; batch adversarial loss: 0.432473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.120208; batch adversarial loss: 0.516314\n",
      "epoch 41; iter: 0; batch classifier loss: 0.081019; batch adversarial loss: 0.448721\n",
      "epoch 42; iter: 0; batch classifier loss: 0.107751; batch adversarial loss: 0.403621\n",
      "epoch 43; iter: 0; batch classifier loss: 0.065555; batch adversarial loss: 0.486701\n",
      "epoch 44; iter: 0; batch classifier loss: 0.099741; batch adversarial loss: 0.370099\n",
      "epoch 45; iter: 0; batch classifier loss: 0.061882; batch adversarial loss: 0.483959\n",
      "epoch 46; iter: 0; batch classifier loss: 0.087188; batch adversarial loss: 0.473910\n",
      "epoch 47; iter: 0; batch classifier loss: 0.081956; batch adversarial loss: 0.533608\n",
      "epoch 48; iter: 0; batch classifier loss: 0.091650; batch adversarial loss: 0.389182\n",
      "epoch 49; iter: 0; batch classifier loss: 0.069955; batch adversarial loss: 0.537405\n",
      "epoch 50; iter: 0; batch classifier loss: 0.101789; batch adversarial loss: 0.508396\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070285; batch adversarial loss: 0.433115\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082912; batch adversarial loss: 0.406953\n",
      "epoch 53; iter: 0; batch classifier loss: 0.074029; batch adversarial loss: 0.443681\n",
      "epoch 54; iter: 0; batch classifier loss: 0.066003; batch adversarial loss: 0.390328\n",
      "epoch 55; iter: 0; batch classifier loss: 0.068163; batch adversarial loss: 0.356794\n",
      "epoch 56; iter: 0; batch classifier loss: 0.048621; batch adversarial loss: 0.480712\n",
      "epoch 57; iter: 0; batch classifier loss: 0.057519; batch adversarial loss: 0.540605\n",
      "epoch 58; iter: 0; batch classifier loss: 0.051077; batch adversarial loss: 0.470413\n",
      "epoch 59; iter: 0; batch classifier loss: 0.056562; batch adversarial loss: 0.436232\n",
      "epoch 60; iter: 0; batch classifier loss: 0.034190; batch adversarial loss: 0.499415\n",
      "epoch 61; iter: 0; batch classifier loss: 0.046813; batch adversarial loss: 0.488726\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084264; batch adversarial loss: 0.441321\n",
      "epoch 63; iter: 0; batch classifier loss: 0.052423; batch adversarial loss: 0.439072\n",
      "epoch 64; iter: 0; batch classifier loss: 0.050939; batch adversarial loss: 0.469714\n",
      "epoch 65; iter: 0; batch classifier loss: 0.048939; batch adversarial loss: 0.532630\n",
      "epoch 66; iter: 0; batch classifier loss: 0.047916; batch adversarial loss: 0.391387\n",
      "epoch 67; iter: 0; batch classifier loss: 0.051359; batch adversarial loss: 0.501146\n",
      "epoch 68; iter: 0; batch classifier loss: 0.056111; batch adversarial loss: 0.463164\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061217; batch adversarial loss: 0.549476\n",
      "epoch 70; iter: 0; batch classifier loss: 0.073865; batch adversarial loss: 0.477268\n",
      "epoch 71; iter: 0; batch classifier loss: 0.040044; batch adversarial loss: 0.437772\n",
      "epoch 72; iter: 0; batch classifier loss: 0.105470; batch adversarial loss: 0.406110\n",
      "epoch 73; iter: 0; batch classifier loss: 0.056312; batch adversarial loss: 0.465016\n",
      "epoch 74; iter: 0; batch classifier loss: 0.039889; batch adversarial loss: 0.391236\n",
      "epoch 75; iter: 0; batch classifier loss: 0.025354; batch adversarial loss: 0.392173\n",
      "epoch 76; iter: 0; batch classifier loss: 0.036255; batch adversarial loss: 0.455723\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050491; batch adversarial loss: 0.403479\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059483; batch adversarial loss: 0.455839\n",
      "epoch 79; iter: 0; batch classifier loss: 0.059099; batch adversarial loss: 0.506205\n",
      "epoch 80; iter: 0; batch classifier loss: 0.051009; batch adversarial loss: 0.442880\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050225; batch adversarial loss: 0.438052\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053010; batch adversarial loss: 0.362192\n",
      "epoch 83; iter: 0; batch classifier loss: 0.057511; batch adversarial loss: 0.443345\n",
      "epoch 84; iter: 0; batch classifier loss: 0.037114; batch adversarial loss: 0.397377\n",
      "epoch 85; iter: 0; batch classifier loss: 0.056380; batch adversarial loss: 0.471350\n",
      "epoch 86; iter: 0; batch classifier loss: 0.041572; batch adversarial loss: 0.487384\n",
      "epoch 87; iter: 0; batch classifier loss: 0.028656; batch adversarial loss: 0.495389\n",
      "epoch 88; iter: 0; batch classifier loss: 0.047294; batch adversarial loss: 0.472400\n",
      "epoch 89; iter: 0; batch classifier loss: 0.029161; batch adversarial loss: 0.463865\n",
      "epoch 90; iter: 0; batch classifier loss: 0.044291; batch adversarial loss: 0.495982\n",
      "epoch 91; iter: 0; batch classifier loss: 0.025307; batch adversarial loss: 0.481353\n",
      "epoch 92; iter: 0; batch classifier loss: 0.036408; batch adversarial loss: 0.408050\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044200; batch adversarial loss: 0.411727\n",
      "epoch 94; iter: 0; batch classifier loss: 0.078021; batch adversarial loss: 0.457360\n",
      "epoch 95; iter: 0; batch classifier loss: 0.035563; batch adversarial loss: 0.495559\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055603; batch adversarial loss: 0.398075\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055903; batch adversarial loss: 0.542974\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055932; batch adversarial loss: 0.442920\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042706; batch adversarial loss: 0.487323\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066588; batch adversarial loss: 0.430550\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083375; batch adversarial loss: 0.409773\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048057; batch adversarial loss: 0.465256\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044687; batch adversarial loss: 0.429833\n",
      "epoch 104; iter: 0; batch classifier loss: 0.070794; batch adversarial loss: 0.410688\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060801; batch adversarial loss: 0.562417\n",
      "epoch 106; iter: 0; batch classifier loss: 0.017914; batch adversarial loss: 0.400932\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055360; batch adversarial loss: 0.446860\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033559; batch adversarial loss: 0.421228\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048572; batch adversarial loss: 0.472515\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025827; batch adversarial loss: 0.489964\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047148; batch adversarial loss: 0.420648\n",
      "epoch 112; iter: 0; batch classifier loss: 0.062879; batch adversarial loss: 0.521732\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035426; batch adversarial loss: 0.418211\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027553; batch adversarial loss: 0.532923\n",
      "epoch 115; iter: 0; batch classifier loss: 0.017321; batch adversarial loss: 0.462198\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024723; batch adversarial loss: 0.469345\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040646; batch adversarial loss: 0.483261\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024751; batch adversarial loss: 0.393620\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038765; batch adversarial loss: 0.531360\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042328; batch adversarial loss: 0.472297\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025856; batch adversarial loss: 0.431166\n",
      "epoch 122; iter: 0; batch classifier loss: 0.012894; batch adversarial loss: 0.341671\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031087; batch adversarial loss: 0.419497\n",
      "epoch 124; iter: 0; batch classifier loss: 0.012573; batch adversarial loss: 0.572194\n",
      "epoch 125; iter: 0; batch classifier loss: 0.075156; batch adversarial loss: 0.483443\n",
      "epoch 126; iter: 0; batch classifier loss: 0.014523; batch adversarial loss: 0.489605\n",
      "epoch 127; iter: 0; batch classifier loss: 0.013970; batch adversarial loss: 0.409798\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019951; batch adversarial loss: 0.515986\n",
      "epoch 129; iter: 0; batch classifier loss: 0.015642; batch adversarial loss: 0.484551\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032959; batch adversarial loss: 0.502782\n",
      "epoch 131; iter: 0; batch classifier loss: 0.057419; batch adversarial loss: 0.447489\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022534; batch adversarial loss: 0.332495\n",
      "epoch 133; iter: 0; batch classifier loss: 0.005083; batch adversarial loss: 0.425844\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049786; batch adversarial loss: 0.418582\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035377; batch adversarial loss: 0.475986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.014296; batch adversarial loss: 0.471614\n",
      "epoch 137; iter: 0; batch classifier loss: 0.058114; batch adversarial loss: 0.423416\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024089; batch adversarial loss: 0.426963\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026577; batch adversarial loss: 0.480827\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023248; batch adversarial loss: 0.328977\n",
      "epoch 141; iter: 0; batch classifier loss: 0.014947; batch adversarial loss: 0.449907\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045335; batch adversarial loss: 0.512581\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032350; batch adversarial loss: 0.538767\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012237; batch adversarial loss: 0.466365\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024373; batch adversarial loss: 0.514224\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018238; batch adversarial loss: 0.361405\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042307; batch adversarial loss: 0.442139\n",
      "epoch 148; iter: 0; batch classifier loss: 0.004666; batch adversarial loss: 0.484333\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033465; batch adversarial loss: 0.489643\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034142; batch adversarial loss: 0.493298\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013592; batch adversarial loss: 0.510730\n",
      "epoch 152; iter: 0; batch classifier loss: 0.046289; batch adversarial loss: 0.417672\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017800; batch adversarial loss: 0.511723\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017312; batch adversarial loss: 0.349644\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027714; batch adversarial loss: 0.376299\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021939; batch adversarial loss: 0.510625\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013218; batch adversarial loss: 0.492751\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011456; batch adversarial loss: 0.587881\n",
      "epoch 159; iter: 0; batch classifier loss: 0.009604; batch adversarial loss: 0.437934\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019824; batch adversarial loss: 0.394896\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043773; batch adversarial loss: 0.448870\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025015; batch adversarial loss: 0.449500\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014263; batch adversarial loss: 0.474353\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020557; batch adversarial loss: 0.395009\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009292; batch adversarial loss: 0.511819\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023034; batch adversarial loss: 0.590134\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019485; batch adversarial loss: 0.475210\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036435; batch adversarial loss: 0.503024\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018311; batch adversarial loss: 0.411465\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026726; batch adversarial loss: 0.482996\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017847; batch adversarial loss: 0.444578\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018684; batch adversarial loss: 0.441939\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009059; batch adversarial loss: 0.496263\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007381; batch adversarial loss: 0.400631\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006476; batch adversarial loss: 0.476231\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016528; batch adversarial loss: 0.403454\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016016; batch adversarial loss: 0.465350\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013867; batch adversarial loss: 0.436685\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026586; batch adversarial loss: 0.436556\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030951; batch adversarial loss: 0.507952\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009001; batch adversarial loss: 0.548991\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029202; batch adversarial loss: 0.382490\n",
      "epoch 183; iter: 0; batch classifier loss: 0.003358; batch adversarial loss: 0.500773\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008693; batch adversarial loss: 0.488239\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013974; batch adversarial loss: 0.402569\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011075; batch adversarial loss: 0.489196\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007951; batch adversarial loss: 0.535924\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008217; batch adversarial loss: 0.468528\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021586; batch adversarial loss: 0.501859\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013266; batch adversarial loss: 0.395318\n",
      "epoch 191; iter: 0; batch classifier loss: 0.002379; batch adversarial loss: 0.540915\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037722; batch adversarial loss: 0.536514\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029822; batch adversarial loss: 0.381635\n",
      "epoch 194; iter: 0; batch classifier loss: 0.046374; batch adversarial loss: 0.403402\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028514; batch adversarial loss: 0.436142\n",
      "epoch 196; iter: 0; batch classifier loss: 0.003945; batch adversarial loss: 0.442530\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029965; batch adversarial loss: 0.445167\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024760; batch adversarial loss: 0.443081\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008839; batch adversarial loss: 0.514143\n",
      "epoch 0; iter: 0; batch classifier loss: 0.658975; batch adversarial loss: 0.585375\n",
      "epoch 1; iter: 0; batch classifier loss: 0.446434; batch adversarial loss: 0.566085\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396046; batch adversarial loss: 0.640224\n",
      "epoch 3; iter: 0; batch classifier loss: 0.331963; batch adversarial loss: 0.584342\n",
      "epoch 4; iter: 0; batch classifier loss: 0.460388; batch adversarial loss: 0.615789\n",
      "epoch 5; iter: 0; batch classifier loss: 0.267205; batch adversarial loss: 0.548302\n",
      "epoch 6; iter: 0; batch classifier loss: 0.450525; batch adversarial loss: 0.611553\n",
      "epoch 7; iter: 0; batch classifier loss: 0.499717; batch adversarial loss: 0.571659\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553130; batch adversarial loss: 0.592027\n",
      "epoch 9; iter: 0; batch classifier loss: 0.471401; batch adversarial loss: 0.570808\n",
      "epoch 10; iter: 0; batch classifier loss: 0.483327; batch adversarial loss: 0.585528\n",
      "epoch 11; iter: 0; batch classifier loss: 0.524841; batch adversarial loss: 0.489589\n",
      "epoch 12; iter: 0; batch classifier loss: 0.362470; batch adversarial loss: 0.528526\n",
      "epoch 13; iter: 0; batch classifier loss: 0.318204; batch adversarial loss: 0.551693\n",
      "epoch 14; iter: 0; batch classifier loss: 0.301739; batch adversarial loss: 0.518288\n",
      "epoch 15; iter: 0; batch classifier loss: 0.308694; batch adversarial loss: 0.524871\n",
      "epoch 16; iter: 0; batch classifier loss: 0.245912; batch adversarial loss: 0.517710\n",
      "epoch 17; iter: 0; batch classifier loss: 0.248431; batch adversarial loss: 0.534654\n",
      "epoch 18; iter: 0; batch classifier loss: 0.185078; batch adversarial loss: 0.437107\n",
      "epoch 19; iter: 0; batch classifier loss: 0.284882; batch adversarial loss: 0.480976\n",
      "epoch 20; iter: 0; batch classifier loss: 0.228035; batch adversarial loss: 0.433571\n",
      "epoch 21; iter: 0; batch classifier loss: 0.146768; batch adversarial loss: 0.521422\n",
      "epoch 22; iter: 0; batch classifier loss: 0.222854; batch adversarial loss: 0.468161\n",
      "epoch 23; iter: 0; batch classifier loss: 0.179836; batch adversarial loss: 0.411777\n",
      "epoch 24; iter: 0; batch classifier loss: 0.241800; batch adversarial loss: 0.485837\n",
      "epoch 25; iter: 0; batch classifier loss: 0.108181; batch adversarial loss: 0.463395\n",
      "epoch 26; iter: 0; batch classifier loss: 0.215491; batch adversarial loss: 0.397226\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181685; batch adversarial loss: 0.460597\n",
      "epoch 28; iter: 0; batch classifier loss: 0.213136; batch adversarial loss: 0.506645\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170435; batch adversarial loss: 0.503693\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205090; batch adversarial loss: 0.433786\n",
      "epoch 31; iter: 0; batch classifier loss: 0.121070; batch adversarial loss: 0.508917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.192263; batch adversarial loss: 0.384541\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143953; batch adversarial loss: 0.416049\n",
      "epoch 34; iter: 0; batch classifier loss: 0.126528; batch adversarial loss: 0.488881\n",
      "epoch 35; iter: 0; batch classifier loss: 0.176546; batch adversarial loss: 0.499475\n",
      "epoch 36; iter: 0; batch classifier loss: 0.148187; batch adversarial loss: 0.453339\n",
      "epoch 37; iter: 0; batch classifier loss: 0.144073; batch adversarial loss: 0.500668\n",
      "epoch 38; iter: 0; batch classifier loss: 0.178681; batch adversarial loss: 0.458266\n",
      "epoch 39; iter: 0; batch classifier loss: 0.156749; batch adversarial loss: 0.452119\n",
      "epoch 40; iter: 0; batch classifier loss: 0.185412; batch adversarial loss: 0.444722\n",
      "epoch 41; iter: 0; batch classifier loss: 0.193456; batch adversarial loss: 0.425317\n",
      "epoch 42; iter: 0; batch classifier loss: 0.194898; batch adversarial loss: 0.438468\n",
      "epoch 43; iter: 0; batch classifier loss: 0.123334; batch adversarial loss: 0.487600\n",
      "epoch 44; iter: 0; batch classifier loss: 0.165391; batch adversarial loss: 0.478564\n",
      "epoch 45; iter: 0; batch classifier loss: 0.201162; batch adversarial loss: 0.506450\n",
      "epoch 46; iter: 0; batch classifier loss: 0.125249; batch adversarial loss: 0.440648\n",
      "epoch 47; iter: 0; batch classifier loss: 0.175336; batch adversarial loss: 0.407526\n",
      "epoch 48; iter: 0; batch classifier loss: 0.185503; batch adversarial loss: 0.381784\n",
      "epoch 49; iter: 0; batch classifier loss: 0.108192; batch adversarial loss: 0.455586\n",
      "epoch 50; iter: 0; batch classifier loss: 0.151358; batch adversarial loss: 0.449998\n",
      "epoch 51; iter: 0; batch classifier loss: 0.152708; batch adversarial loss: 0.461574\n",
      "epoch 52; iter: 0; batch classifier loss: 0.113138; batch adversarial loss: 0.521382\n",
      "epoch 53; iter: 0; batch classifier loss: 0.170292; batch adversarial loss: 0.437151\n",
      "epoch 54; iter: 0; batch classifier loss: 0.161700; batch adversarial loss: 0.390471\n",
      "epoch 55; iter: 0; batch classifier loss: 0.206140; batch adversarial loss: 0.393338\n",
      "epoch 56; iter: 0; batch classifier loss: 0.181935; batch adversarial loss: 0.530852\n",
      "epoch 57; iter: 0; batch classifier loss: 0.141773; batch adversarial loss: 0.421150\n",
      "epoch 58; iter: 0; batch classifier loss: 0.117361; batch adversarial loss: 0.486721\n",
      "epoch 59; iter: 0; batch classifier loss: 0.133764; batch adversarial loss: 0.371027\n",
      "epoch 60; iter: 0; batch classifier loss: 0.138719; batch adversarial loss: 0.408717\n",
      "epoch 61; iter: 0; batch classifier loss: 0.172389; batch adversarial loss: 0.494458\n",
      "epoch 62; iter: 0; batch classifier loss: 0.098808; batch adversarial loss: 0.522814\n",
      "epoch 63; iter: 0; batch classifier loss: 0.110279; batch adversarial loss: 0.452990\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098870; batch adversarial loss: 0.387901\n",
      "epoch 65; iter: 0; batch classifier loss: 0.187735; batch adversarial loss: 0.418029\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096197; batch adversarial loss: 0.467687\n",
      "epoch 67; iter: 0; batch classifier loss: 0.131979; batch adversarial loss: 0.387676\n",
      "epoch 68; iter: 0; batch classifier loss: 0.104315; batch adversarial loss: 0.474839\n",
      "epoch 69; iter: 0; batch classifier loss: 0.139040; batch adversarial loss: 0.476752\n",
      "epoch 70; iter: 0; batch classifier loss: 0.153772; batch adversarial loss: 0.512400\n",
      "epoch 71; iter: 0; batch classifier loss: 0.097215; batch adversarial loss: 0.469222\n",
      "epoch 72; iter: 0; batch classifier loss: 0.164266; batch adversarial loss: 0.380294\n",
      "epoch 73; iter: 0; batch classifier loss: 0.129289; batch adversarial loss: 0.482080\n",
      "epoch 74; iter: 0; batch classifier loss: 0.118178; batch adversarial loss: 0.358556\n",
      "epoch 75; iter: 0; batch classifier loss: 0.119413; batch adversarial loss: 0.355410\n",
      "epoch 76; iter: 0; batch classifier loss: 0.110580; batch adversarial loss: 0.407844\n",
      "epoch 77; iter: 0; batch classifier loss: 0.109446; batch adversarial loss: 0.527235\n",
      "epoch 78; iter: 0; batch classifier loss: 0.112161; batch adversarial loss: 0.503519\n",
      "epoch 79; iter: 0; batch classifier loss: 0.190411; batch adversarial loss: 0.485675\n",
      "epoch 80; iter: 0; batch classifier loss: 0.073084; batch adversarial loss: 0.565319\n",
      "epoch 81; iter: 0; batch classifier loss: 0.086967; batch adversarial loss: 0.457774\n",
      "epoch 82; iter: 0; batch classifier loss: 0.092952; batch adversarial loss: 0.484160\n",
      "epoch 83; iter: 0; batch classifier loss: 0.094773; batch adversarial loss: 0.470693\n",
      "epoch 84; iter: 0; batch classifier loss: 0.115168; batch adversarial loss: 0.355780\n",
      "epoch 85; iter: 0; batch classifier loss: 0.120422; batch adversarial loss: 0.463596\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070716; batch adversarial loss: 0.534973\n",
      "epoch 87; iter: 0; batch classifier loss: 0.120979; batch adversarial loss: 0.429424\n",
      "epoch 88; iter: 0; batch classifier loss: 0.103732; batch adversarial loss: 0.477089\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073846; batch adversarial loss: 0.388908\n",
      "epoch 90; iter: 0; batch classifier loss: 0.120859; batch adversarial loss: 0.477438\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073549; batch adversarial loss: 0.528457\n",
      "epoch 92; iter: 0; batch classifier loss: 0.087994; batch adversarial loss: 0.453114\n",
      "epoch 93; iter: 0; batch classifier loss: 0.066359; batch adversarial loss: 0.469069\n",
      "epoch 94; iter: 0; batch classifier loss: 0.085517; batch adversarial loss: 0.427037\n",
      "epoch 95; iter: 0; batch classifier loss: 0.108189; batch adversarial loss: 0.442085\n",
      "epoch 96; iter: 0; batch classifier loss: 0.094446; batch adversarial loss: 0.481484\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077157; batch adversarial loss: 0.453964\n",
      "epoch 98; iter: 0; batch classifier loss: 0.084906; batch adversarial loss: 0.390391\n",
      "epoch 99; iter: 0; batch classifier loss: 0.094656; batch adversarial loss: 0.401459\n",
      "epoch 100; iter: 0; batch classifier loss: 0.073661; batch adversarial loss: 0.494973\n",
      "epoch 101; iter: 0; batch classifier loss: 0.093996; batch adversarial loss: 0.438838\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063074; batch adversarial loss: 0.462199\n",
      "epoch 103; iter: 0; batch classifier loss: 0.081256; batch adversarial loss: 0.492571\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083877; batch adversarial loss: 0.359972\n",
      "epoch 105; iter: 0; batch classifier loss: 0.075820; batch adversarial loss: 0.347843\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041678; batch adversarial loss: 0.616559\n",
      "epoch 107; iter: 0; batch classifier loss: 0.070098; batch adversarial loss: 0.475257\n",
      "epoch 108; iter: 0; batch classifier loss: 0.035511; batch adversarial loss: 0.456895\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058954; batch adversarial loss: 0.544039\n",
      "epoch 110; iter: 0; batch classifier loss: 0.087341; batch adversarial loss: 0.444354\n",
      "epoch 111; iter: 0; batch classifier loss: 0.038127; batch adversarial loss: 0.411546\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041566; batch adversarial loss: 0.436133\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039602; batch adversarial loss: 0.519135\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060919; batch adversarial loss: 0.501915\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045160; batch adversarial loss: 0.489681\n",
      "epoch 116; iter: 0; batch classifier loss: 0.077596; batch adversarial loss: 0.521609\n",
      "epoch 117; iter: 0; batch classifier loss: 0.065339; batch adversarial loss: 0.408958\n",
      "epoch 118; iter: 0; batch classifier loss: 0.038588; batch adversarial loss: 0.403895\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051568; batch adversarial loss: 0.529096\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034545; batch adversarial loss: 0.459201\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040323; batch adversarial loss: 0.584142\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040768; batch adversarial loss: 0.571359\n",
      "epoch 123; iter: 0; batch classifier loss: 0.054929; batch adversarial loss: 0.487180\n",
      "epoch 124; iter: 0; batch classifier loss: 0.045256; batch adversarial loss: 0.387146\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031381; batch adversarial loss: 0.438107\n",
      "epoch 126; iter: 0; batch classifier loss: 0.041740; batch adversarial loss: 0.457637\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053598; batch adversarial loss: 0.438625\n",
      "epoch 128; iter: 0; batch classifier loss: 0.055624; batch adversarial loss: 0.373524\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048388; batch adversarial loss: 0.404299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.045518; batch adversarial loss: 0.397727\n",
      "epoch 131; iter: 0; batch classifier loss: 0.058038; batch adversarial loss: 0.510004\n",
      "epoch 132; iter: 0; batch classifier loss: 0.083038; batch adversarial loss: 0.501325\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033609; batch adversarial loss: 0.492376\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037524; batch adversarial loss: 0.556886\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042333; batch adversarial loss: 0.535541\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039238; batch adversarial loss: 0.498908\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036677; batch adversarial loss: 0.408591\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025891; batch adversarial loss: 0.494778\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021943; batch adversarial loss: 0.492218\n",
      "epoch 140; iter: 0; batch classifier loss: 0.011435; batch adversarial loss: 0.487797\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025364; batch adversarial loss: 0.439291\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039387; batch adversarial loss: 0.438538\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040708; batch adversarial loss: 0.507135\n",
      "epoch 144; iter: 0; batch classifier loss: 0.010004; batch adversarial loss: 0.574442\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024548; batch adversarial loss: 0.536537\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026974; batch adversarial loss: 0.430151\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021746; batch adversarial loss: 0.452265\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022322; batch adversarial loss: 0.468763\n",
      "epoch 149; iter: 0; batch classifier loss: 0.056597; batch adversarial loss: 0.410716\n",
      "epoch 150; iter: 0; batch classifier loss: 0.045076; batch adversarial loss: 0.425011\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017438; batch adversarial loss: 0.417720\n",
      "epoch 152; iter: 0; batch classifier loss: 0.050198; batch adversarial loss: 0.406606\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022855; batch adversarial loss: 0.415859\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021196; batch adversarial loss: 0.425172\n",
      "epoch 155; iter: 0; batch classifier loss: 0.051828; batch adversarial loss: 0.427806\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034586; batch adversarial loss: 0.398950\n",
      "epoch 157; iter: 0; batch classifier loss: 0.047707; batch adversarial loss: 0.417773\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038143; batch adversarial loss: 0.583043\n",
      "epoch 159; iter: 0; batch classifier loss: 0.044889; batch adversarial loss: 0.407574\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013767; batch adversarial loss: 0.489273\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022104; batch adversarial loss: 0.413221\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041253; batch adversarial loss: 0.492100\n",
      "epoch 163; iter: 0; batch classifier loss: 0.031454; batch adversarial loss: 0.420971\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011268; batch adversarial loss: 0.409537\n",
      "epoch 165; iter: 0; batch classifier loss: 0.056291; batch adversarial loss: 0.478728\n",
      "epoch 166; iter: 0; batch classifier loss: 0.005545; batch adversarial loss: 0.467738\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013506; batch adversarial loss: 0.438199\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009707; batch adversarial loss: 0.482710\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009471; batch adversarial loss: 0.514983\n",
      "epoch 170; iter: 0; batch classifier loss: 0.044290; batch adversarial loss: 0.478975\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016467; batch adversarial loss: 0.461510\n",
      "epoch 172; iter: 0; batch classifier loss: 0.065182; batch adversarial loss: 0.483658\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023588; batch adversarial loss: 0.388194\n",
      "epoch 174; iter: 0; batch classifier loss: 0.044707; batch adversarial loss: 0.615253\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022455; batch adversarial loss: 0.489708\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020900; batch adversarial loss: 0.506465\n",
      "epoch 177; iter: 0; batch classifier loss: 0.035439; batch adversarial loss: 0.449287\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019550; batch adversarial loss: 0.481701\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018409; batch adversarial loss: 0.405061\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012152; batch adversarial loss: 0.369739\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012122; batch adversarial loss: 0.488440\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009113; batch adversarial loss: 0.396689\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024587; batch adversarial loss: 0.385141\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022817; batch adversarial loss: 0.433737\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009862; batch adversarial loss: 0.603084\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022574; batch adversarial loss: 0.425584\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022028; batch adversarial loss: 0.451671\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013062; batch adversarial loss: 0.453249\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020241; batch adversarial loss: 0.465516\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007903; batch adversarial loss: 0.545645\n",
      "epoch 191; iter: 0; batch classifier loss: 0.067645; batch adversarial loss: 0.436971\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020576; batch adversarial loss: 0.438728\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012955; batch adversarial loss: 0.457630\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015154; batch adversarial loss: 0.475654\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014060; batch adversarial loss: 0.476559\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017734; batch adversarial loss: 0.469903\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016929; batch adversarial loss: 0.393106\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010605; batch adversarial loss: 0.543731\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021205; batch adversarial loss: 0.499715\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699171; batch adversarial loss: 0.671892\n",
      "epoch 1; iter: 0; batch classifier loss: 0.442438; batch adversarial loss: 0.637617\n",
      "epoch 2; iter: 0; batch classifier loss: 0.467225; batch adversarial loss: 0.612487\n",
      "epoch 3; iter: 0; batch classifier loss: 0.370555; batch adversarial loss: 0.571506\n",
      "epoch 4; iter: 0; batch classifier loss: 0.303966; batch adversarial loss: 0.540758\n",
      "epoch 5; iter: 0; batch classifier loss: 0.293988; batch adversarial loss: 0.569208\n",
      "epoch 6; iter: 0; batch classifier loss: 0.269652; batch adversarial loss: 0.552284\n",
      "epoch 7; iter: 0; batch classifier loss: 0.366900; batch adversarial loss: 0.563041\n",
      "epoch 8; iter: 0; batch classifier loss: 0.310534; batch adversarial loss: 0.510926\n",
      "epoch 9; iter: 0; batch classifier loss: 0.299987; batch adversarial loss: 0.515917\n",
      "epoch 10; iter: 0; batch classifier loss: 0.253537; batch adversarial loss: 0.499422\n",
      "epoch 11; iter: 0; batch classifier loss: 0.207573; batch adversarial loss: 0.456422\n",
      "epoch 12; iter: 0; batch classifier loss: 0.227615; batch adversarial loss: 0.457389\n",
      "epoch 13; iter: 0; batch classifier loss: 0.251291; batch adversarial loss: 0.556417\n",
      "epoch 14; iter: 0; batch classifier loss: 0.303990; batch adversarial loss: 0.583995\n",
      "epoch 15; iter: 0; batch classifier loss: 0.190086; batch adversarial loss: 0.521375\n",
      "epoch 16; iter: 0; batch classifier loss: 0.265160; batch adversarial loss: 0.530139\n",
      "epoch 17; iter: 0; batch classifier loss: 0.309672; batch adversarial loss: 0.543114\n",
      "epoch 18; iter: 0; batch classifier loss: 0.284610; batch adversarial loss: 0.420401\n",
      "epoch 19; iter: 0; batch classifier loss: 0.308995; batch adversarial loss: 0.532669\n",
      "epoch 20; iter: 0; batch classifier loss: 0.318861; batch adversarial loss: 0.454540\n",
      "epoch 21; iter: 0; batch classifier loss: 0.375315; batch adversarial loss: 0.524667\n",
      "epoch 22; iter: 0; batch classifier loss: 0.379451; batch adversarial loss: 0.505690\n",
      "epoch 23; iter: 0; batch classifier loss: 0.292201; batch adversarial loss: 0.474349\n",
      "epoch 24; iter: 0; batch classifier loss: 0.163115; batch adversarial loss: 0.518855\n",
      "epoch 25; iter: 0; batch classifier loss: 0.143932; batch adversarial loss: 0.509150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.213628; batch adversarial loss: 0.504666\n",
      "epoch 27; iter: 0; batch classifier loss: 0.178797; batch adversarial loss: 0.486527\n",
      "epoch 28; iter: 0; batch classifier loss: 0.123317; batch adversarial loss: 0.532071\n",
      "epoch 29; iter: 0; batch classifier loss: 0.174075; batch adversarial loss: 0.547099\n",
      "epoch 30; iter: 0; batch classifier loss: 0.171826; batch adversarial loss: 0.484180\n",
      "epoch 31; iter: 0; batch classifier loss: 0.084627; batch adversarial loss: 0.429675\n",
      "epoch 32; iter: 0; batch classifier loss: 0.178622; batch adversarial loss: 0.499441\n",
      "epoch 33; iter: 0; batch classifier loss: 0.131011; batch adversarial loss: 0.511003\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148016; batch adversarial loss: 0.462581\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129553; batch adversarial loss: 0.450811\n",
      "epoch 36; iter: 0; batch classifier loss: 0.093370; batch adversarial loss: 0.428412\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132881; batch adversarial loss: 0.424929\n",
      "epoch 38; iter: 0; batch classifier loss: 0.080736; batch adversarial loss: 0.499525\n",
      "epoch 39; iter: 0; batch classifier loss: 0.139811; batch adversarial loss: 0.411766\n",
      "epoch 40; iter: 0; batch classifier loss: 0.119339; batch adversarial loss: 0.521284\n",
      "epoch 41; iter: 0; batch classifier loss: 0.132224; batch adversarial loss: 0.448510\n",
      "epoch 42; iter: 0; batch classifier loss: 0.122814; batch adversarial loss: 0.441996\n",
      "epoch 43; iter: 0; batch classifier loss: 0.099840; batch adversarial loss: 0.478389\n",
      "epoch 44; iter: 0; batch classifier loss: 0.081661; batch adversarial loss: 0.409577\n",
      "epoch 45; iter: 0; batch classifier loss: 0.101417; batch adversarial loss: 0.444973\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127654; batch adversarial loss: 0.460872\n",
      "epoch 47; iter: 0; batch classifier loss: 0.086831; batch adversarial loss: 0.492234\n",
      "epoch 48; iter: 0; batch classifier loss: 0.115358; batch adversarial loss: 0.445068\n",
      "epoch 49; iter: 0; batch classifier loss: 0.095418; batch adversarial loss: 0.638409\n",
      "epoch 50; iter: 0; batch classifier loss: 0.131673; batch adversarial loss: 0.533034\n",
      "epoch 51; iter: 0; batch classifier loss: 0.151560; batch adversarial loss: 0.372937\n",
      "epoch 52; iter: 0; batch classifier loss: 0.081820; batch adversarial loss: 0.387215\n",
      "epoch 53; iter: 0; batch classifier loss: 0.139182; batch adversarial loss: 0.478240\n",
      "epoch 54; iter: 0; batch classifier loss: 0.152598; batch adversarial loss: 0.547191\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086187; batch adversarial loss: 0.409131\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082828; batch adversarial loss: 0.484235\n",
      "epoch 57; iter: 0; batch classifier loss: 0.143494; batch adversarial loss: 0.404301\n",
      "epoch 58; iter: 0; batch classifier loss: 0.125047; batch adversarial loss: 0.470683\n",
      "epoch 59; iter: 0; batch classifier loss: 0.116436; batch adversarial loss: 0.480178\n",
      "epoch 60; iter: 0; batch classifier loss: 0.143586; batch adversarial loss: 0.521057\n",
      "epoch 61; iter: 0; batch classifier loss: 0.110803; batch adversarial loss: 0.597572\n",
      "epoch 62; iter: 0; batch classifier loss: 0.120625; batch adversarial loss: 0.439297\n",
      "epoch 63; iter: 0; batch classifier loss: 0.083662; batch adversarial loss: 0.484067\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098760; batch adversarial loss: 0.476659\n",
      "epoch 65; iter: 0; batch classifier loss: 0.115160; batch adversarial loss: 0.457651\n",
      "epoch 66; iter: 0; batch classifier loss: 0.097942; batch adversarial loss: 0.512382\n",
      "epoch 67; iter: 0; batch classifier loss: 0.084634; batch adversarial loss: 0.541547\n",
      "epoch 68; iter: 0; batch classifier loss: 0.104439; batch adversarial loss: 0.500925\n",
      "epoch 69; iter: 0; batch classifier loss: 0.112474; batch adversarial loss: 0.457566\n",
      "epoch 70; iter: 0; batch classifier loss: 0.105957; batch adversarial loss: 0.565569\n",
      "epoch 71; iter: 0; batch classifier loss: 0.077726; batch adversarial loss: 0.503578\n",
      "epoch 72; iter: 0; batch classifier loss: 0.109044; batch adversarial loss: 0.476301\n",
      "epoch 73; iter: 0; batch classifier loss: 0.035569; batch adversarial loss: 0.387047\n",
      "epoch 74; iter: 0; batch classifier loss: 0.057592; batch adversarial loss: 0.436651\n",
      "epoch 75; iter: 0; batch classifier loss: 0.086173; batch adversarial loss: 0.505171\n",
      "epoch 76; iter: 0; batch classifier loss: 0.120958; batch adversarial loss: 0.477458\n",
      "epoch 77; iter: 0; batch classifier loss: 0.094083; batch adversarial loss: 0.498024\n",
      "epoch 78; iter: 0; batch classifier loss: 0.070286; batch adversarial loss: 0.456423\n",
      "epoch 79; iter: 0; batch classifier loss: 0.094989; batch adversarial loss: 0.371444\n",
      "epoch 80; iter: 0; batch classifier loss: 0.055939; batch adversarial loss: 0.520529\n",
      "epoch 81; iter: 0; batch classifier loss: 0.114077; batch adversarial loss: 0.476942\n",
      "epoch 82; iter: 0; batch classifier loss: 0.103785; batch adversarial loss: 0.438994\n",
      "epoch 83; iter: 0; batch classifier loss: 0.043055; batch adversarial loss: 0.451247\n",
      "epoch 84; iter: 0; batch classifier loss: 0.058831; batch adversarial loss: 0.533927\n",
      "epoch 85; iter: 0; batch classifier loss: 0.079043; batch adversarial loss: 0.513329\n",
      "epoch 86; iter: 0; batch classifier loss: 0.043846; batch adversarial loss: 0.421132\n",
      "epoch 87; iter: 0; batch classifier loss: 0.078849; batch adversarial loss: 0.353878\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054454; batch adversarial loss: 0.500896\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057532; batch adversarial loss: 0.437050\n",
      "epoch 90; iter: 0; batch classifier loss: 0.119575; batch adversarial loss: 0.518485\n",
      "epoch 91; iter: 0; batch classifier loss: 0.036053; batch adversarial loss: 0.500400\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060701; batch adversarial loss: 0.534998\n",
      "epoch 93; iter: 0; batch classifier loss: 0.118785; batch adversarial loss: 0.430115\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077118; batch adversarial loss: 0.476416\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081010; batch adversarial loss: 0.428649\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044248; batch adversarial loss: 0.397256\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060686; batch adversarial loss: 0.542572\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056696; batch adversarial loss: 0.394643\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045748; batch adversarial loss: 0.491023\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066992; batch adversarial loss: 0.430237\n",
      "epoch 101; iter: 0; batch classifier loss: 0.074225; batch adversarial loss: 0.415103\n",
      "epoch 102; iter: 0; batch classifier loss: 0.096414; batch adversarial loss: 0.456331\n",
      "epoch 103; iter: 0; batch classifier loss: 0.070008; batch adversarial loss: 0.405467\n",
      "epoch 104; iter: 0; batch classifier loss: 0.049253; batch adversarial loss: 0.410310\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050507; batch adversarial loss: 0.436850\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057869; batch adversarial loss: 0.404347\n",
      "epoch 107; iter: 0; batch classifier loss: 0.071398; batch adversarial loss: 0.467290\n",
      "epoch 108; iter: 0; batch classifier loss: 0.035990; batch adversarial loss: 0.519973\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045864; batch adversarial loss: 0.524659\n",
      "epoch 110; iter: 0; batch classifier loss: 0.066781; batch adversarial loss: 0.489257\n",
      "epoch 111; iter: 0; batch classifier loss: 0.046304; batch adversarial loss: 0.416034\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038980; batch adversarial loss: 0.454304\n",
      "epoch 113; iter: 0; batch classifier loss: 0.072629; batch adversarial loss: 0.392197\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054350; batch adversarial loss: 0.467592\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037641; batch adversarial loss: 0.416519\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054735; batch adversarial loss: 0.462867\n",
      "epoch 117; iter: 0; batch classifier loss: 0.064925; batch adversarial loss: 0.464487\n",
      "epoch 118; iter: 0; batch classifier loss: 0.015389; batch adversarial loss: 0.529618\n",
      "epoch 119; iter: 0; batch classifier loss: 0.077825; batch adversarial loss: 0.507659\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045612; batch adversarial loss: 0.504310\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021518; batch adversarial loss: 0.539007\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052399; batch adversarial loss: 0.439612\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029082; batch adversarial loss: 0.392630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.029493; batch adversarial loss: 0.434425\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061559; batch adversarial loss: 0.474740\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057874; batch adversarial loss: 0.515055\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044777; batch adversarial loss: 0.513400\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044606; batch adversarial loss: 0.545257\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039176; batch adversarial loss: 0.560748\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045886; batch adversarial loss: 0.471993\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030726; batch adversarial loss: 0.474043\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025150; batch adversarial loss: 0.448719\n",
      "epoch 133; iter: 0; batch classifier loss: 0.017694; batch adversarial loss: 0.461224\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026192; batch adversarial loss: 0.487919\n",
      "epoch 135; iter: 0; batch classifier loss: 0.015744; batch adversarial loss: 0.515019\n",
      "epoch 136; iter: 0; batch classifier loss: 0.075941; batch adversarial loss: 0.440226\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033993; batch adversarial loss: 0.483748\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056123; batch adversarial loss: 0.469921\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025273; batch adversarial loss: 0.402547\n",
      "epoch 140; iter: 0; batch classifier loss: 0.067070; batch adversarial loss: 0.509026\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030664; batch adversarial loss: 0.445434\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040914; batch adversarial loss: 0.417080\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023415; batch adversarial loss: 0.452684\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033518; batch adversarial loss: 0.363737\n",
      "epoch 145; iter: 0; batch classifier loss: 0.007965; batch adversarial loss: 0.440769\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025204; batch adversarial loss: 0.455914\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029690; batch adversarial loss: 0.457637\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012976; batch adversarial loss: 0.500725\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037014; batch adversarial loss: 0.489855\n",
      "epoch 150; iter: 0; batch classifier loss: 0.059969; batch adversarial loss: 0.375194\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044128; batch adversarial loss: 0.414819\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032706; batch adversarial loss: 0.532427\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030282; batch adversarial loss: 0.389921\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029435; batch adversarial loss: 0.503667\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038221; batch adversarial loss: 0.488671\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024571; batch adversarial loss: 0.469756\n",
      "epoch 157; iter: 0; batch classifier loss: 0.054014; batch adversarial loss: 0.469258\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017188; batch adversarial loss: 0.480274\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026809; batch adversarial loss: 0.468253\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015122; batch adversarial loss: 0.502550\n",
      "epoch 161; iter: 0; batch classifier loss: 0.057818; batch adversarial loss: 0.557679\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022516; batch adversarial loss: 0.409361\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028374; batch adversarial loss: 0.460189\n",
      "epoch 164; iter: 0; batch classifier loss: 0.051935; batch adversarial loss: 0.419048\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026752; batch adversarial loss: 0.422160\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030037; batch adversarial loss: 0.424510\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042675; batch adversarial loss: 0.412932\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029284; batch adversarial loss: 0.574124\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037705; batch adversarial loss: 0.536806\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034918; batch adversarial loss: 0.374075\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008721; batch adversarial loss: 0.565336\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016730; batch adversarial loss: 0.474067\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033338; batch adversarial loss: 0.482419\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023233; batch adversarial loss: 0.442727\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027541; batch adversarial loss: 0.417765\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017094; batch adversarial loss: 0.464001\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027985; batch adversarial loss: 0.462012\n",
      "epoch 178; iter: 0; batch classifier loss: 0.060231; batch adversarial loss: 0.442047\n",
      "epoch 179; iter: 0; batch classifier loss: 0.058618; batch adversarial loss: 0.421932\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024256; batch adversarial loss: 0.436692\n",
      "epoch 181; iter: 0; batch classifier loss: 0.041518; batch adversarial loss: 0.437616\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008155; batch adversarial loss: 0.516364\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025314; batch adversarial loss: 0.563384\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019043; batch adversarial loss: 0.405852\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031835; batch adversarial loss: 0.454915\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021663; batch adversarial loss: 0.506037\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025142; batch adversarial loss: 0.470563\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012329; batch adversarial loss: 0.396457\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031540; batch adversarial loss: 0.487353\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008396; batch adversarial loss: 0.542597\n",
      "epoch 191; iter: 0; batch classifier loss: 0.044140; batch adversarial loss: 0.591637\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008994; batch adversarial loss: 0.433696\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011940; batch adversarial loss: 0.476127\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017352; batch adversarial loss: 0.491183\n",
      "epoch 195; iter: 0; batch classifier loss: 0.048314; batch adversarial loss: 0.451058\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023122; batch adversarial loss: 0.525203\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018820; batch adversarial loss: 0.585411\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011315; batch adversarial loss: 0.477039\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010158; batch adversarial loss: 0.487833\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686998; batch adversarial loss: 0.722814\n",
      "epoch 1; iter: 0; batch classifier loss: 0.514661; batch adversarial loss: 0.702785\n",
      "epoch 2; iter: 0; batch classifier loss: 0.473498; batch adversarial loss: 0.671096\n",
      "epoch 3; iter: 0; batch classifier loss: 0.347172; batch adversarial loss: 0.627448\n",
      "epoch 4; iter: 0; batch classifier loss: 0.385134; batch adversarial loss: 0.593144\n",
      "epoch 5; iter: 0; batch classifier loss: 0.383360; batch adversarial loss: 0.539626\n",
      "epoch 6; iter: 0; batch classifier loss: 0.290623; batch adversarial loss: 0.529039\n",
      "epoch 7; iter: 0; batch classifier loss: 0.302533; batch adversarial loss: 0.535420\n",
      "epoch 8; iter: 0; batch classifier loss: 0.324447; batch adversarial loss: 0.501433\n",
      "epoch 9; iter: 0; batch classifier loss: 0.294837; batch adversarial loss: 0.482235\n",
      "epoch 10; iter: 0; batch classifier loss: 0.204687; batch adversarial loss: 0.530790\n",
      "epoch 11; iter: 0; batch classifier loss: 0.245760; batch adversarial loss: 0.468354\n",
      "epoch 12; iter: 0; batch classifier loss: 0.226689; batch adversarial loss: 0.432773\n",
      "epoch 13; iter: 0; batch classifier loss: 0.198100; batch adversarial loss: 0.528227\n",
      "epoch 14; iter: 0; batch classifier loss: 0.245749; batch adversarial loss: 0.441815\n",
      "epoch 15; iter: 0; batch classifier loss: 0.190918; batch adversarial loss: 0.439280\n",
      "epoch 16; iter: 0; batch classifier loss: 0.152214; batch adversarial loss: 0.504038\n",
      "epoch 17; iter: 0; batch classifier loss: 0.201514; batch adversarial loss: 0.493718\n",
      "epoch 18; iter: 0; batch classifier loss: 0.178336; batch adversarial loss: 0.442981\n",
      "epoch 19; iter: 0; batch classifier loss: 0.140482; batch adversarial loss: 0.464698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.160056; batch adversarial loss: 0.404010\n",
      "epoch 21; iter: 0; batch classifier loss: 0.162620; batch adversarial loss: 0.550842\n",
      "epoch 22; iter: 0; batch classifier loss: 0.159472; batch adversarial loss: 0.539125\n",
      "epoch 23; iter: 0; batch classifier loss: 0.123576; batch adversarial loss: 0.414255\n",
      "epoch 24; iter: 0; batch classifier loss: 0.170668; batch adversarial loss: 0.451078\n",
      "epoch 25; iter: 0; batch classifier loss: 0.189134; batch adversarial loss: 0.416834\n",
      "epoch 26; iter: 0; batch classifier loss: 0.133860; batch adversarial loss: 0.422004\n",
      "epoch 27; iter: 0; batch classifier loss: 0.106630; batch adversarial loss: 0.459672\n",
      "epoch 28; iter: 0; batch classifier loss: 0.172319; batch adversarial loss: 0.375668\n",
      "epoch 29; iter: 0; batch classifier loss: 0.150158; batch adversarial loss: 0.351432\n",
      "epoch 30; iter: 0; batch classifier loss: 0.101501; batch adversarial loss: 0.406036\n",
      "epoch 31; iter: 0; batch classifier loss: 0.155060; batch adversarial loss: 0.422767\n",
      "epoch 32; iter: 0; batch classifier loss: 0.155547; batch adversarial loss: 0.441675\n",
      "epoch 33; iter: 0; batch classifier loss: 0.109364; batch adversarial loss: 0.357755\n",
      "epoch 34; iter: 0; batch classifier loss: 0.114281; batch adversarial loss: 0.323511\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140878; batch adversarial loss: 0.396252\n",
      "epoch 36; iter: 0; batch classifier loss: 0.153863; batch adversarial loss: 0.391684\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113153; batch adversarial loss: 0.384147\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107012; batch adversarial loss: 0.461608\n",
      "epoch 39; iter: 0; batch classifier loss: 0.140433; batch adversarial loss: 0.460660\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124572; batch adversarial loss: 0.425374\n",
      "epoch 41; iter: 0; batch classifier loss: 0.149117; batch adversarial loss: 0.428907\n",
      "epoch 42; iter: 0; batch classifier loss: 0.083750; batch adversarial loss: 0.412358\n",
      "epoch 43; iter: 0; batch classifier loss: 0.102701; batch adversarial loss: 0.448947\n",
      "epoch 44; iter: 0; batch classifier loss: 0.108921; batch adversarial loss: 0.427804\n",
      "epoch 45; iter: 0; batch classifier loss: 0.130319; batch adversarial loss: 0.407004\n",
      "epoch 46; iter: 0; batch classifier loss: 0.094934; batch adversarial loss: 0.467186\n",
      "epoch 47; iter: 0; batch classifier loss: 0.116872; batch adversarial loss: 0.417220\n",
      "epoch 48; iter: 0; batch classifier loss: 0.080355; batch adversarial loss: 0.515006\n",
      "epoch 49; iter: 0; batch classifier loss: 0.081924; batch adversarial loss: 0.392996\n",
      "epoch 50; iter: 0; batch classifier loss: 0.084007; batch adversarial loss: 0.282151\n",
      "epoch 51; iter: 0; batch classifier loss: 0.112422; batch adversarial loss: 0.464684\n",
      "epoch 52; iter: 0; batch classifier loss: 0.075150; batch adversarial loss: 0.370545\n",
      "epoch 53; iter: 0; batch classifier loss: 0.086607; batch adversarial loss: 0.415490\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074315; batch adversarial loss: 0.469844\n",
      "epoch 55; iter: 0; batch classifier loss: 0.099881; batch adversarial loss: 0.500011\n",
      "epoch 56; iter: 0; batch classifier loss: 0.048557; batch adversarial loss: 0.419069\n",
      "epoch 57; iter: 0; batch classifier loss: 0.081157; batch adversarial loss: 0.415292\n",
      "epoch 58; iter: 0; batch classifier loss: 0.087352; batch adversarial loss: 0.351145\n",
      "epoch 59; iter: 0; batch classifier loss: 0.086797; batch adversarial loss: 0.496869\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105065; batch adversarial loss: 0.425533\n",
      "epoch 61; iter: 0; batch classifier loss: 0.075738; batch adversarial loss: 0.322134\n",
      "epoch 62; iter: 0; batch classifier loss: 0.069928; batch adversarial loss: 0.450357\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089136; batch adversarial loss: 0.466140\n",
      "epoch 64; iter: 0; batch classifier loss: 0.094852; batch adversarial loss: 0.418366\n",
      "epoch 65; iter: 0; batch classifier loss: 0.093076; batch adversarial loss: 0.442222\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085818; batch adversarial loss: 0.403418\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082059; batch adversarial loss: 0.456796\n",
      "epoch 68; iter: 0; batch classifier loss: 0.084938; batch adversarial loss: 0.506710\n",
      "epoch 69; iter: 0; batch classifier loss: 0.089397; batch adversarial loss: 0.423247\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103719; batch adversarial loss: 0.408867\n",
      "epoch 71; iter: 0; batch classifier loss: 0.040042; batch adversarial loss: 0.397630\n",
      "epoch 72; iter: 0; batch classifier loss: 0.047315; batch adversarial loss: 0.370334\n",
      "epoch 73; iter: 0; batch classifier loss: 0.064455; batch adversarial loss: 0.419287\n",
      "epoch 74; iter: 0; batch classifier loss: 0.062012; batch adversarial loss: 0.491456\n",
      "epoch 75; iter: 0; batch classifier loss: 0.079474; batch adversarial loss: 0.445410\n",
      "epoch 76; iter: 0; batch classifier loss: 0.114013; batch adversarial loss: 0.466142\n",
      "epoch 77; iter: 0; batch classifier loss: 0.054324; batch adversarial loss: 0.476110\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074278; batch adversarial loss: 0.469037\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057678; batch adversarial loss: 0.366656\n",
      "epoch 80; iter: 0; batch classifier loss: 0.086102; batch adversarial loss: 0.536291\n",
      "epoch 81; iter: 0; batch classifier loss: 0.094775; batch adversarial loss: 0.505420\n",
      "epoch 82; iter: 0; batch classifier loss: 0.081177; batch adversarial loss: 0.435251\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063252; batch adversarial loss: 0.387814\n",
      "epoch 84; iter: 0; batch classifier loss: 0.077527; batch adversarial loss: 0.399642\n",
      "epoch 85; iter: 0; batch classifier loss: 0.060740; batch adversarial loss: 0.366636\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089291; batch adversarial loss: 0.484666\n",
      "epoch 87; iter: 0; batch classifier loss: 0.052755; batch adversarial loss: 0.351204\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062608; batch adversarial loss: 0.508989\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080103; batch adversarial loss: 0.513703\n",
      "epoch 90; iter: 0; batch classifier loss: 0.083958; batch adversarial loss: 0.427221\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046476; batch adversarial loss: 0.396901\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063035; batch adversarial loss: 0.553998\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062480; batch adversarial loss: 0.517677\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047774; batch adversarial loss: 0.379881\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081649; batch adversarial loss: 0.389050\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082568; batch adversarial loss: 0.460206\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043166; batch adversarial loss: 0.440894\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049306; batch adversarial loss: 0.372742\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041109; batch adversarial loss: 0.429639\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046480; batch adversarial loss: 0.457975\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049825; batch adversarial loss: 0.395889\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054640; batch adversarial loss: 0.381579\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039767; batch adversarial loss: 0.443572\n",
      "epoch 104; iter: 0; batch classifier loss: 0.035224; batch adversarial loss: 0.475865\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040004; batch adversarial loss: 0.394764\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046683; batch adversarial loss: 0.409767\n",
      "epoch 107; iter: 0; batch classifier loss: 0.064300; batch adversarial loss: 0.454997\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048609; batch adversarial loss: 0.429757\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039917; batch adversarial loss: 0.578411\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052450; batch adversarial loss: 0.427485\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042800; batch adversarial loss: 0.357171\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031511; batch adversarial loss: 0.431989\n",
      "epoch 113; iter: 0; batch classifier loss: 0.021673; batch adversarial loss: 0.449029\n",
      "epoch 114; iter: 0; batch classifier loss: 0.008661; batch adversarial loss: 0.435095\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022653; batch adversarial loss: 0.496186\n",
      "epoch 116; iter: 0; batch classifier loss: 0.064288; batch adversarial loss: 0.512610\n",
      "epoch 117; iter: 0; batch classifier loss: 0.013215; batch adversarial loss: 0.515218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.029833; batch adversarial loss: 0.402710\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059173; batch adversarial loss: 0.665801\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054153; batch adversarial loss: 0.618474\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038846; batch adversarial loss: 0.451405\n",
      "epoch 122; iter: 0; batch classifier loss: 0.056547; batch adversarial loss: 0.509711\n",
      "epoch 123; iter: 0; batch classifier loss: 0.060854; batch adversarial loss: 0.528177\n",
      "epoch 124; iter: 0; batch classifier loss: 0.064408; batch adversarial loss: 0.536531\n",
      "epoch 125; iter: 0; batch classifier loss: 0.104160; batch adversarial loss: 0.606129\n",
      "epoch 126; iter: 0; batch classifier loss: 0.076939; batch adversarial loss: 0.566157\n",
      "epoch 127; iter: 0; batch classifier loss: 0.089150; batch adversarial loss: 0.526153\n",
      "epoch 128; iter: 0; batch classifier loss: 0.140088; batch adversarial loss: 0.645307\n",
      "epoch 129; iter: 0; batch classifier loss: 0.148159; batch adversarial loss: 0.661615\n",
      "epoch 130; iter: 0; batch classifier loss: 0.097160; batch adversarial loss: 0.536948\n",
      "epoch 131; iter: 0; batch classifier loss: 0.083560; batch adversarial loss: 0.493143\n",
      "epoch 132; iter: 0; batch classifier loss: 0.117172; batch adversarial loss: 0.646814\n",
      "epoch 133; iter: 0; batch classifier loss: 0.122234; batch adversarial loss: 0.702992\n",
      "epoch 134; iter: 0; batch classifier loss: 0.173439; batch adversarial loss: 0.607140\n",
      "epoch 135; iter: 0; batch classifier loss: 0.154858; batch adversarial loss: 0.537611\n",
      "epoch 136; iter: 0; batch classifier loss: 0.222420; batch adversarial loss: 0.712482\n",
      "epoch 137; iter: 0; batch classifier loss: 0.173225; batch adversarial loss: 0.664485\n",
      "epoch 138; iter: 0; batch classifier loss: 0.104017; batch adversarial loss: 0.494915\n",
      "epoch 139; iter: 0; batch classifier loss: 0.136780; batch adversarial loss: 0.543179\n",
      "epoch 140; iter: 0; batch classifier loss: 0.117704; batch adversarial loss: 0.507736\n",
      "epoch 141; iter: 0; batch classifier loss: 0.170334; batch adversarial loss: 0.716359\n",
      "epoch 142; iter: 0; batch classifier loss: 0.089537; batch adversarial loss: 0.536491\n",
      "epoch 143; iter: 0; batch classifier loss: 0.155197; batch adversarial loss: 0.596345\n",
      "epoch 144; iter: 0; batch classifier loss: 0.199963; batch adversarial loss: 0.674455\n",
      "epoch 145; iter: 0; batch classifier loss: 0.134072; batch adversarial loss: 0.477606\n",
      "epoch 146; iter: 0; batch classifier loss: 0.164441; batch adversarial loss: 0.520433\n",
      "epoch 147; iter: 0; batch classifier loss: 0.124881; batch adversarial loss: 0.456997\n",
      "epoch 148; iter: 0; batch classifier loss: 0.150387; batch adversarial loss: 0.529718\n",
      "epoch 149; iter: 0; batch classifier loss: 0.205451; batch adversarial loss: 0.618848\n",
      "epoch 150; iter: 0; batch classifier loss: 0.119817; batch adversarial loss: 0.511988\n",
      "epoch 151; iter: 0; batch classifier loss: 0.165514; batch adversarial loss: 0.600183\n",
      "epoch 152; iter: 0; batch classifier loss: 0.160353; batch adversarial loss: 0.512650\n",
      "epoch 153; iter: 0; batch classifier loss: 0.147000; batch adversarial loss: 0.519623\n",
      "epoch 154; iter: 0; batch classifier loss: 0.134706; batch adversarial loss: 0.590435\n",
      "epoch 155; iter: 0; batch classifier loss: 0.150418; batch adversarial loss: 0.606781\n",
      "epoch 156; iter: 0; batch classifier loss: 0.172366; batch adversarial loss: 0.470262\n",
      "epoch 157; iter: 0; batch classifier loss: 0.100488; batch adversarial loss: 0.362740\n",
      "epoch 158; iter: 0; batch classifier loss: 0.112112; batch adversarial loss: 0.451800\n",
      "epoch 159; iter: 0; batch classifier loss: 0.117807; batch adversarial loss: 0.487187\n",
      "epoch 160; iter: 0; batch classifier loss: 0.169370; batch adversarial loss: 0.511507\n",
      "epoch 161; iter: 0; batch classifier loss: 0.169218; batch adversarial loss: 0.609029\n",
      "epoch 162; iter: 0; batch classifier loss: 0.115014; batch adversarial loss: 0.447922\n",
      "epoch 163; iter: 0; batch classifier loss: 0.097911; batch adversarial loss: 0.480126\n",
      "epoch 164; iter: 0; batch classifier loss: 0.129035; batch adversarial loss: 0.490577\n",
      "epoch 165; iter: 0; batch classifier loss: 0.091366; batch adversarial loss: 0.462032\n",
      "epoch 166; iter: 0; batch classifier loss: 0.111166; batch adversarial loss: 0.386450\n",
      "epoch 167; iter: 0; batch classifier loss: 0.084279; batch adversarial loss: 0.430935\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040671; batch adversarial loss: 0.514896\n",
      "epoch 169; iter: 0; batch classifier loss: 0.045196; batch adversarial loss: 0.492172\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039634; batch adversarial loss: 0.553435\n",
      "epoch 171; iter: 0; batch classifier loss: 0.043267; batch adversarial loss: 0.441901\n",
      "epoch 172; iter: 0; batch classifier loss: 0.042993; batch adversarial loss: 0.535174\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033358; batch adversarial loss: 0.497461\n",
      "epoch 174; iter: 0; batch classifier loss: 0.065443; batch adversarial loss: 0.467582\n",
      "epoch 175; iter: 0; batch classifier loss: 0.057281; batch adversarial loss: 0.476581\n",
      "epoch 176; iter: 0; batch classifier loss: 0.064049; batch adversarial loss: 0.405584\n",
      "epoch 177; iter: 0; batch classifier loss: 0.079037; batch adversarial loss: 0.383823\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038820; batch adversarial loss: 0.451537\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036708; batch adversarial loss: 0.423820\n",
      "epoch 180; iter: 0; batch classifier loss: 0.058546; batch adversarial loss: 0.462813\n",
      "epoch 181; iter: 0; batch classifier loss: 0.062712; batch adversarial loss: 0.483067\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030977; batch adversarial loss: 0.472754\n",
      "epoch 183; iter: 0; batch classifier loss: 0.086590; batch adversarial loss: 0.473495\n",
      "epoch 184; iter: 0; batch classifier loss: 0.056429; batch adversarial loss: 0.448586\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040088; batch adversarial loss: 0.531149\n",
      "epoch 186; iter: 0; batch classifier loss: 0.056326; batch adversarial loss: 0.499302\n",
      "epoch 187; iter: 0; batch classifier loss: 0.070005; batch adversarial loss: 0.395490\n",
      "epoch 188; iter: 0; batch classifier loss: 0.072157; batch adversarial loss: 0.513065\n",
      "epoch 189; iter: 0; batch classifier loss: 0.046276; batch adversarial loss: 0.458815\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030747; batch adversarial loss: 0.437577\n",
      "epoch 191; iter: 0; batch classifier loss: 0.070465; batch adversarial loss: 0.440587\n",
      "epoch 192; iter: 0; batch classifier loss: 0.075166; batch adversarial loss: 0.425074\n",
      "epoch 193; iter: 0; batch classifier loss: 0.051039; batch adversarial loss: 0.474575\n",
      "epoch 194; iter: 0; batch classifier loss: 0.039747; batch adversarial loss: 0.452784\n",
      "epoch 195; iter: 0; batch classifier loss: 0.041096; batch adversarial loss: 0.470601\n",
      "epoch 196; iter: 0; batch classifier loss: 0.080671; batch adversarial loss: 0.375009\n",
      "epoch 197; iter: 0; batch classifier loss: 0.054671; batch adversarial loss: 0.366878\n",
      "epoch 198; iter: 0; batch classifier loss: 0.045567; batch adversarial loss: 0.324212\n",
      "epoch 199; iter: 0; batch classifier loss: 0.062841; batch adversarial loss: 0.465117\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698865; batch adversarial loss: 0.634653\n",
      "epoch 1; iter: 0; batch classifier loss: 0.377488; batch adversarial loss: 0.627531\n",
      "epoch 2; iter: 0; batch classifier loss: 0.377874; batch adversarial loss: 0.604646\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393083; batch adversarial loss: 0.556829\n",
      "epoch 4; iter: 0; batch classifier loss: 0.304348; batch adversarial loss: 0.534304\n",
      "epoch 5; iter: 0; batch classifier loss: 0.271967; batch adversarial loss: 0.567713\n",
      "epoch 6; iter: 0; batch classifier loss: 0.276453; batch adversarial loss: 0.540040\n",
      "epoch 7; iter: 0; batch classifier loss: 0.306285; batch adversarial loss: 0.488514\n",
      "epoch 8; iter: 0; batch classifier loss: 0.231269; batch adversarial loss: 0.476504\n",
      "epoch 9; iter: 0; batch classifier loss: 0.231770; batch adversarial loss: 0.525400\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269111; batch adversarial loss: 0.468637\n",
      "epoch 11; iter: 0; batch classifier loss: 0.225567; batch adversarial loss: 0.470136\n",
      "epoch 12; iter: 0; batch classifier loss: 0.254385; batch adversarial loss: 0.464679\n",
      "epoch 13; iter: 0; batch classifier loss: 0.257872; batch adversarial loss: 0.435020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.174141; batch adversarial loss: 0.546283\n",
      "epoch 15; iter: 0; batch classifier loss: 0.227302; batch adversarial loss: 0.524615\n",
      "epoch 16; iter: 0; batch classifier loss: 0.290100; batch adversarial loss: 0.473500\n",
      "epoch 17; iter: 0; batch classifier loss: 0.234044; batch adversarial loss: 0.486419\n",
      "epoch 18; iter: 0; batch classifier loss: 0.272292; batch adversarial loss: 0.547125\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236690; batch adversarial loss: 0.473418\n",
      "epoch 20; iter: 0; batch classifier loss: 0.365015; batch adversarial loss: 0.570066\n",
      "epoch 21; iter: 0; batch classifier loss: 0.249492; batch adversarial loss: 0.544471\n",
      "epoch 22; iter: 0; batch classifier loss: 0.278398; batch adversarial loss: 0.467232\n",
      "epoch 23; iter: 0; batch classifier loss: 0.296599; batch adversarial loss: 0.466684\n",
      "epoch 24; iter: 0; batch classifier loss: 0.303098; batch adversarial loss: 0.549625\n",
      "epoch 25; iter: 0; batch classifier loss: 0.338994; batch adversarial loss: 0.502810\n",
      "epoch 26; iter: 0; batch classifier loss: 0.282726; batch adversarial loss: 0.424276\n",
      "epoch 27; iter: 0; batch classifier loss: 0.333012; batch adversarial loss: 0.413826\n",
      "epoch 28; iter: 0; batch classifier loss: 0.228206; batch adversarial loss: 0.517975\n",
      "epoch 29; iter: 0; batch classifier loss: 0.142888; batch adversarial loss: 0.498625\n",
      "epoch 30; iter: 0; batch classifier loss: 0.156366; batch adversarial loss: 0.533828\n",
      "epoch 31; iter: 0; batch classifier loss: 0.165294; batch adversarial loss: 0.548889\n",
      "epoch 32; iter: 0; batch classifier loss: 0.135684; batch adversarial loss: 0.345324\n",
      "epoch 33; iter: 0; batch classifier loss: 0.107919; batch adversarial loss: 0.419450\n",
      "epoch 34; iter: 0; batch classifier loss: 0.154361; batch adversarial loss: 0.423844\n",
      "epoch 35; iter: 0; batch classifier loss: 0.087624; batch adversarial loss: 0.429507\n",
      "epoch 36; iter: 0; batch classifier loss: 0.117232; batch adversarial loss: 0.521098\n",
      "epoch 37; iter: 0; batch classifier loss: 0.089904; batch adversarial loss: 0.465131\n",
      "epoch 38; iter: 0; batch classifier loss: 0.084236; batch adversarial loss: 0.477030\n",
      "epoch 39; iter: 0; batch classifier loss: 0.097730; batch adversarial loss: 0.502274\n",
      "epoch 40; iter: 0; batch classifier loss: 0.111381; batch adversarial loss: 0.501631\n",
      "epoch 41; iter: 0; batch classifier loss: 0.114909; batch adversarial loss: 0.515187\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116140; batch adversarial loss: 0.468694\n",
      "epoch 43; iter: 0; batch classifier loss: 0.087900; batch adversarial loss: 0.510723\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105008; batch adversarial loss: 0.530050\n",
      "epoch 45; iter: 0; batch classifier loss: 0.131863; batch adversarial loss: 0.473164\n",
      "epoch 46; iter: 0; batch classifier loss: 0.084744; batch adversarial loss: 0.458193\n",
      "epoch 47; iter: 0; batch classifier loss: 0.120457; batch adversarial loss: 0.431294\n",
      "epoch 48; iter: 0; batch classifier loss: 0.098741; batch adversarial loss: 0.419701\n",
      "epoch 49; iter: 0; batch classifier loss: 0.078396; batch adversarial loss: 0.451026\n",
      "epoch 50; iter: 0; batch classifier loss: 0.076971; batch adversarial loss: 0.526113\n",
      "epoch 51; iter: 0; batch classifier loss: 0.065023; batch adversarial loss: 0.521247\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071845; batch adversarial loss: 0.446355\n",
      "epoch 53; iter: 0; batch classifier loss: 0.150737; batch adversarial loss: 0.412643\n",
      "epoch 54; iter: 0; batch classifier loss: 0.091640; batch adversarial loss: 0.480571\n",
      "epoch 55; iter: 0; batch classifier loss: 0.123095; batch adversarial loss: 0.463241\n",
      "epoch 56; iter: 0; batch classifier loss: 0.074460; batch adversarial loss: 0.437088\n",
      "epoch 57; iter: 0; batch classifier loss: 0.047130; batch adversarial loss: 0.447350\n",
      "epoch 58; iter: 0; batch classifier loss: 0.088705; batch adversarial loss: 0.438698\n",
      "epoch 59; iter: 0; batch classifier loss: 0.109973; batch adversarial loss: 0.467911\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122015; batch adversarial loss: 0.532390\n",
      "epoch 61; iter: 0; batch classifier loss: 0.068979; batch adversarial loss: 0.498917\n",
      "epoch 62; iter: 0; batch classifier loss: 0.049748; batch adversarial loss: 0.551391\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093148; batch adversarial loss: 0.421229\n",
      "epoch 64; iter: 0; batch classifier loss: 0.089128; batch adversarial loss: 0.405132\n",
      "epoch 65; iter: 0; batch classifier loss: 0.092017; batch adversarial loss: 0.482339\n",
      "epoch 66; iter: 0; batch classifier loss: 0.071891; batch adversarial loss: 0.470848\n",
      "epoch 67; iter: 0; batch classifier loss: 0.106813; batch adversarial loss: 0.404284\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061477; batch adversarial loss: 0.394191\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065783; batch adversarial loss: 0.423292\n",
      "epoch 70; iter: 0; batch classifier loss: 0.115347; batch adversarial loss: 0.415100\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071732; batch adversarial loss: 0.400658\n",
      "epoch 72; iter: 0; batch classifier loss: 0.059913; batch adversarial loss: 0.409972\n",
      "epoch 73; iter: 0; batch classifier loss: 0.134760; batch adversarial loss: 0.440019\n",
      "epoch 74; iter: 0; batch classifier loss: 0.099991; batch adversarial loss: 0.463172\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067010; batch adversarial loss: 0.430083\n",
      "epoch 76; iter: 0; batch classifier loss: 0.066203; batch adversarial loss: 0.476618\n",
      "epoch 77; iter: 0; batch classifier loss: 0.094147; batch adversarial loss: 0.522388\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079590; batch adversarial loss: 0.617966\n",
      "epoch 79; iter: 0; batch classifier loss: 0.041880; batch adversarial loss: 0.384844\n",
      "epoch 80; iter: 0; batch classifier loss: 0.074483; batch adversarial loss: 0.478722\n",
      "epoch 81; iter: 0; batch classifier loss: 0.053248; batch adversarial loss: 0.536560\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074094; batch adversarial loss: 0.467725\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061539; batch adversarial loss: 0.450483\n",
      "epoch 84; iter: 0; batch classifier loss: 0.076761; batch adversarial loss: 0.452856\n",
      "epoch 85; iter: 0; batch classifier loss: 0.081921; batch adversarial loss: 0.492843\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074801; batch adversarial loss: 0.431986\n",
      "epoch 87; iter: 0; batch classifier loss: 0.065624; batch adversarial loss: 0.552314\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078870; batch adversarial loss: 0.414228\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050660; batch adversarial loss: 0.424925\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042314; batch adversarial loss: 0.416250\n",
      "epoch 91; iter: 0; batch classifier loss: 0.050548; batch adversarial loss: 0.445840\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062897; batch adversarial loss: 0.479139\n",
      "epoch 93; iter: 0; batch classifier loss: 0.057753; batch adversarial loss: 0.476363\n",
      "epoch 94; iter: 0; batch classifier loss: 0.087031; batch adversarial loss: 0.438474\n",
      "epoch 95; iter: 0; batch classifier loss: 0.098000; batch adversarial loss: 0.472900\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065309; batch adversarial loss: 0.552929\n",
      "epoch 97; iter: 0; batch classifier loss: 0.080376; batch adversarial loss: 0.479684\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048279; batch adversarial loss: 0.442715\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057401; batch adversarial loss: 0.495904\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053478; batch adversarial loss: 0.366927\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050494; batch adversarial loss: 0.505550\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062575; batch adversarial loss: 0.532563\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072197; batch adversarial loss: 0.351245\n",
      "epoch 104; iter: 0; batch classifier loss: 0.090051; batch adversarial loss: 0.434942\n",
      "epoch 105; iter: 0; batch classifier loss: 0.033999; batch adversarial loss: 0.428605\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052752; batch adversarial loss: 0.405872\n",
      "epoch 107; iter: 0; batch classifier loss: 0.070759; batch adversarial loss: 0.432848\n",
      "epoch 108; iter: 0; batch classifier loss: 0.062404; batch adversarial loss: 0.475729\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037064; batch adversarial loss: 0.391307\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052684; batch adversarial loss: 0.446597\n",
      "epoch 111; iter: 0; batch classifier loss: 0.076606; batch adversarial loss: 0.406436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.110684; batch adversarial loss: 0.446545\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057213; batch adversarial loss: 0.571174\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052864; batch adversarial loss: 0.457801\n",
      "epoch 115; iter: 0; batch classifier loss: 0.066637; batch adversarial loss: 0.434936\n",
      "epoch 116; iter: 0; batch classifier loss: 0.098576; batch adversarial loss: 0.368316\n",
      "epoch 117; iter: 0; batch classifier loss: 0.020120; batch adversarial loss: 0.528724\n",
      "epoch 118; iter: 0; batch classifier loss: 0.034097; batch adversarial loss: 0.446728\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029723; batch adversarial loss: 0.507164\n",
      "epoch 120; iter: 0; batch classifier loss: 0.072464; batch adversarial loss: 0.566189\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039940; batch adversarial loss: 0.446562\n",
      "epoch 122; iter: 0; batch classifier loss: 0.091776; batch adversarial loss: 0.442507\n",
      "epoch 123; iter: 0; batch classifier loss: 0.069522; batch adversarial loss: 0.526312\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051237; batch adversarial loss: 0.478362\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039553; batch adversarial loss: 0.430636\n",
      "epoch 126; iter: 0; batch classifier loss: 0.097574; batch adversarial loss: 0.407494\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046689; batch adversarial loss: 0.435635\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028920; batch adversarial loss: 0.464181\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039053; batch adversarial loss: 0.478522\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028450; batch adversarial loss: 0.555749\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052540; batch adversarial loss: 0.424246\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051985; batch adversarial loss: 0.450118\n",
      "epoch 133; iter: 0; batch classifier loss: 0.088521; batch adversarial loss: 0.508625\n",
      "epoch 134; iter: 0; batch classifier loss: 0.061510; batch adversarial loss: 0.427525\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022722; batch adversarial loss: 0.529119\n",
      "epoch 136; iter: 0; batch classifier loss: 0.045293; batch adversarial loss: 0.451136\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052035; batch adversarial loss: 0.469255\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032539; batch adversarial loss: 0.392047\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037809; batch adversarial loss: 0.432902\n",
      "epoch 140; iter: 0; batch classifier loss: 0.063563; batch adversarial loss: 0.446854\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052927; batch adversarial loss: 0.369932\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034968; batch adversarial loss: 0.467494\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018520; batch adversarial loss: 0.548352\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029115; batch adversarial loss: 0.430421\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041563; batch adversarial loss: 0.410222\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039092; batch adversarial loss: 0.473026\n",
      "epoch 147; iter: 0; batch classifier loss: 0.061071; batch adversarial loss: 0.397342\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027836; batch adversarial loss: 0.460836\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053898; batch adversarial loss: 0.507974\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012648; batch adversarial loss: 0.477462\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033963; batch adversarial loss: 0.448516\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025912; batch adversarial loss: 0.546590\n",
      "epoch 153; iter: 0; batch classifier loss: 0.051336; batch adversarial loss: 0.448862\n",
      "epoch 154; iter: 0; batch classifier loss: 0.051983; batch adversarial loss: 0.519111\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037991; batch adversarial loss: 0.382460\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020353; batch adversarial loss: 0.436028\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021622; batch adversarial loss: 0.505982\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015271; batch adversarial loss: 0.440460\n",
      "epoch 159; iter: 0; batch classifier loss: 0.046474; batch adversarial loss: 0.393690\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032902; batch adversarial loss: 0.470746\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024557; batch adversarial loss: 0.407512\n",
      "epoch 162; iter: 0; batch classifier loss: 0.058539; batch adversarial loss: 0.450495\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028535; batch adversarial loss: 0.518129\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026422; batch adversarial loss: 0.457783\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020280; batch adversarial loss: 0.501532\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033264; batch adversarial loss: 0.473387\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025933; batch adversarial loss: 0.478288\n",
      "epoch 168; iter: 0; batch classifier loss: 0.057805; batch adversarial loss: 0.361773\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013398; batch adversarial loss: 0.484753\n",
      "epoch 170; iter: 0; batch classifier loss: 0.054440; batch adversarial loss: 0.465591\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047101; batch adversarial loss: 0.514719\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014648; batch adversarial loss: 0.443761\n",
      "epoch 173; iter: 0; batch classifier loss: 0.071875; batch adversarial loss: 0.466670\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022853; batch adversarial loss: 0.511883\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025368; batch adversarial loss: 0.483553\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017085; batch adversarial loss: 0.459043\n",
      "epoch 177; iter: 0; batch classifier loss: 0.055124; batch adversarial loss: 0.401099\n",
      "epoch 178; iter: 0; batch classifier loss: 0.036504; batch adversarial loss: 0.432962\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008806; batch adversarial loss: 0.490867\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031602; batch adversarial loss: 0.442411\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036884; batch adversarial loss: 0.485256\n",
      "epoch 182; iter: 0; batch classifier loss: 0.035355; batch adversarial loss: 0.465900\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016770; batch adversarial loss: 0.541325\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031811; batch adversarial loss: 0.374819\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028322; batch adversarial loss: 0.525010\n",
      "epoch 186; iter: 0; batch classifier loss: 0.068100; batch adversarial loss: 0.436915\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040368; batch adversarial loss: 0.452527\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018468; batch adversarial loss: 0.472084\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024702; batch adversarial loss: 0.606358\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020096; batch adversarial loss: 0.384146\n",
      "epoch 191; iter: 0; batch classifier loss: 0.064524; batch adversarial loss: 0.549230\n",
      "epoch 192; iter: 0; batch classifier loss: 0.061563; batch adversarial loss: 0.445205\n",
      "epoch 193; iter: 0; batch classifier loss: 0.050464; batch adversarial loss: 0.457222\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032775; batch adversarial loss: 0.470536\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029038; batch adversarial loss: 0.507111\n",
      "epoch 196; iter: 0; batch classifier loss: 0.039303; batch adversarial loss: 0.485695\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015021; batch adversarial loss: 0.480043\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021284; batch adversarial loss: 0.400675\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027057; batch adversarial loss: 0.445139\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678093; batch adversarial loss: 0.823798\n",
      "epoch 1; iter: 0; batch classifier loss: 0.413461; batch adversarial loss: 0.795079\n",
      "epoch 2; iter: 0; batch classifier loss: 0.536355; batch adversarial loss: 0.772059\n",
      "epoch 3; iter: 0; batch classifier loss: 0.606696; batch adversarial loss: 0.723116\n",
      "epoch 4; iter: 0; batch classifier loss: 0.675143; batch adversarial loss: 0.665551\n",
      "epoch 5; iter: 0; batch classifier loss: 0.654495; batch adversarial loss: 0.595641\n",
      "epoch 6; iter: 0; batch classifier loss: 0.365409; batch adversarial loss: 0.597629\n",
      "epoch 7; iter: 0; batch classifier loss: 0.352983; batch adversarial loss: 0.572022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.373783; batch adversarial loss: 0.546761\n",
      "epoch 9; iter: 0; batch classifier loss: 0.332233; batch adversarial loss: 0.534973\n",
      "epoch 10; iter: 0; batch classifier loss: 0.366343; batch adversarial loss: 0.492693\n",
      "epoch 11; iter: 0; batch classifier loss: 0.304410; batch adversarial loss: 0.514517\n",
      "epoch 12; iter: 0; batch classifier loss: 0.366262; batch adversarial loss: 0.470238\n",
      "epoch 13; iter: 0; batch classifier loss: 0.329330; batch adversarial loss: 0.534236\n",
      "epoch 14; iter: 0; batch classifier loss: 0.302686; batch adversarial loss: 0.596121\n",
      "epoch 15; iter: 0; batch classifier loss: 0.327574; batch adversarial loss: 0.529736\n",
      "epoch 16; iter: 0; batch classifier loss: 0.327287; batch adversarial loss: 0.497541\n",
      "epoch 17; iter: 0; batch classifier loss: 0.317522; batch adversarial loss: 0.475329\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359833; batch adversarial loss: 0.475777\n",
      "epoch 19; iter: 0; batch classifier loss: 0.308580; batch adversarial loss: 0.460707\n",
      "epoch 20; iter: 0; batch classifier loss: 0.289087; batch adversarial loss: 0.525671\n",
      "epoch 21; iter: 0; batch classifier loss: 0.306711; batch adversarial loss: 0.552058\n",
      "epoch 22; iter: 0; batch classifier loss: 0.344346; batch adversarial loss: 0.486968\n",
      "epoch 23; iter: 0; batch classifier loss: 0.270199; batch adversarial loss: 0.489496\n",
      "epoch 24; iter: 0; batch classifier loss: 0.293325; batch adversarial loss: 0.384270\n",
      "epoch 25; iter: 0; batch classifier loss: 0.210045; batch adversarial loss: 0.452658\n",
      "epoch 26; iter: 0; batch classifier loss: 0.218383; batch adversarial loss: 0.507640\n",
      "epoch 27; iter: 0; batch classifier loss: 0.150136; batch adversarial loss: 0.457868\n",
      "epoch 28; iter: 0; batch classifier loss: 0.196963; batch adversarial loss: 0.423983\n",
      "epoch 29; iter: 0; batch classifier loss: 0.198090; batch adversarial loss: 0.430261\n",
      "epoch 30; iter: 0; batch classifier loss: 0.156848; batch adversarial loss: 0.473879\n",
      "epoch 31; iter: 0; batch classifier loss: 0.260110; batch adversarial loss: 0.534716\n",
      "epoch 32; iter: 0; batch classifier loss: 0.148988; batch adversarial loss: 0.503328\n",
      "epoch 33; iter: 0; batch classifier loss: 0.113973; batch adversarial loss: 0.464697\n",
      "epoch 34; iter: 0; batch classifier loss: 0.196032; batch adversarial loss: 0.471564\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122430; batch adversarial loss: 0.443194\n",
      "epoch 36; iter: 0; batch classifier loss: 0.180246; batch adversarial loss: 0.487359\n",
      "epoch 37; iter: 0; batch classifier loss: 0.129060; batch adversarial loss: 0.473781\n",
      "epoch 38; iter: 0; batch classifier loss: 0.087681; batch adversarial loss: 0.425113\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107743; batch adversarial loss: 0.528634\n",
      "epoch 40; iter: 0; batch classifier loss: 0.147447; batch adversarial loss: 0.536480\n",
      "epoch 41; iter: 0; batch classifier loss: 0.152547; batch adversarial loss: 0.417575\n",
      "epoch 42; iter: 0; batch classifier loss: 0.093884; batch adversarial loss: 0.428434\n",
      "epoch 43; iter: 0; batch classifier loss: 0.114810; batch adversarial loss: 0.456146\n",
      "epoch 44; iter: 0; batch classifier loss: 0.162527; batch adversarial loss: 0.488156\n",
      "epoch 45; iter: 0; batch classifier loss: 0.140423; batch adversarial loss: 0.486653\n",
      "epoch 46; iter: 0; batch classifier loss: 0.136906; batch adversarial loss: 0.539168\n",
      "epoch 47; iter: 0; batch classifier loss: 0.066601; batch adversarial loss: 0.465544\n",
      "epoch 48; iter: 0; batch classifier loss: 0.119694; batch adversarial loss: 0.445671\n",
      "epoch 49; iter: 0; batch classifier loss: 0.097044; batch adversarial loss: 0.391679\n",
      "epoch 50; iter: 0; batch classifier loss: 0.082127; batch adversarial loss: 0.429687\n",
      "epoch 51; iter: 0; batch classifier loss: 0.072778; batch adversarial loss: 0.459864\n",
      "epoch 52; iter: 0; batch classifier loss: 0.072631; batch adversarial loss: 0.563202\n",
      "epoch 53; iter: 0; batch classifier loss: 0.082087; batch adversarial loss: 0.461538\n",
      "epoch 54; iter: 0; batch classifier loss: 0.056388; batch adversarial loss: 0.537471\n",
      "epoch 55; iter: 0; batch classifier loss: 0.105437; batch adversarial loss: 0.438702\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067058; batch adversarial loss: 0.472823\n",
      "epoch 57; iter: 0; batch classifier loss: 0.052395; batch adversarial loss: 0.410926\n",
      "epoch 58; iter: 0; batch classifier loss: 0.067175; batch adversarial loss: 0.449040\n",
      "epoch 59; iter: 0; batch classifier loss: 0.091745; batch adversarial loss: 0.505792\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065899; batch adversarial loss: 0.437187\n",
      "epoch 61; iter: 0; batch classifier loss: 0.073588; batch adversarial loss: 0.526963\n",
      "epoch 62; iter: 0; batch classifier loss: 0.055913; batch adversarial loss: 0.412921\n",
      "epoch 63; iter: 0; batch classifier loss: 0.059217; batch adversarial loss: 0.487236\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106796; batch adversarial loss: 0.463828\n",
      "epoch 65; iter: 0; batch classifier loss: 0.061037; batch adversarial loss: 0.496842\n",
      "epoch 66; iter: 0; batch classifier loss: 0.055445; batch adversarial loss: 0.485852\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073911; batch adversarial loss: 0.350384\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076604; batch adversarial loss: 0.517399\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064609; batch adversarial loss: 0.454926\n",
      "epoch 70; iter: 0; batch classifier loss: 0.062995; batch adversarial loss: 0.471895\n",
      "epoch 71; iter: 0; batch classifier loss: 0.051883; batch adversarial loss: 0.431975\n",
      "epoch 72; iter: 0; batch classifier loss: 0.053428; batch adversarial loss: 0.410278\n",
      "epoch 73; iter: 0; batch classifier loss: 0.050444; batch adversarial loss: 0.446263\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063975; batch adversarial loss: 0.498227\n",
      "epoch 75; iter: 0; batch classifier loss: 0.018963; batch adversarial loss: 0.514167\n",
      "epoch 76; iter: 0; batch classifier loss: 0.031681; batch adversarial loss: 0.525903\n",
      "epoch 77; iter: 0; batch classifier loss: 0.042277; batch adversarial loss: 0.480203\n",
      "epoch 78; iter: 0; batch classifier loss: 0.035320; batch adversarial loss: 0.453612\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063597; batch adversarial loss: 0.495808\n",
      "epoch 80; iter: 0; batch classifier loss: 0.038155; batch adversarial loss: 0.450825\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073824; batch adversarial loss: 0.403861\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053635; batch adversarial loss: 0.589688\n",
      "epoch 83; iter: 0; batch classifier loss: 0.041488; batch adversarial loss: 0.499389\n",
      "epoch 84; iter: 0; batch classifier loss: 0.040626; batch adversarial loss: 0.430044\n",
      "epoch 85; iter: 0; batch classifier loss: 0.023845; batch adversarial loss: 0.495589\n",
      "epoch 86; iter: 0; batch classifier loss: 0.028168; batch adversarial loss: 0.417557\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056428; batch adversarial loss: 0.461131\n",
      "epoch 88; iter: 0; batch classifier loss: 0.039899; batch adversarial loss: 0.582269\n",
      "epoch 89; iter: 0; batch classifier loss: 0.032240; batch adversarial loss: 0.404525\n",
      "epoch 90; iter: 0; batch classifier loss: 0.046578; batch adversarial loss: 0.389486\n",
      "epoch 91; iter: 0; batch classifier loss: 0.050363; batch adversarial loss: 0.472197\n",
      "epoch 92; iter: 0; batch classifier loss: 0.021559; batch adversarial loss: 0.483561\n",
      "epoch 93; iter: 0; batch classifier loss: 0.021499; batch adversarial loss: 0.372758\n",
      "epoch 94; iter: 0; batch classifier loss: 0.060087; batch adversarial loss: 0.430313\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054534; batch adversarial loss: 0.483778\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036372; batch adversarial loss: 0.497108\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052435; batch adversarial loss: 0.457419\n",
      "epoch 98; iter: 0; batch classifier loss: 0.024272; batch adversarial loss: 0.393219\n",
      "epoch 99; iter: 0; batch classifier loss: 0.013069; batch adversarial loss: 0.483486\n",
      "epoch 100; iter: 0; batch classifier loss: 0.023239; batch adversarial loss: 0.470369\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070038; batch adversarial loss: 0.458207\n",
      "epoch 102; iter: 0; batch classifier loss: 0.026043; batch adversarial loss: 0.434345\n",
      "epoch 103; iter: 0; batch classifier loss: 0.021178; batch adversarial loss: 0.435695\n",
      "epoch 104; iter: 0; batch classifier loss: 0.035449; batch adversarial loss: 0.493832\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041582; batch adversarial loss: 0.480261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.044390; batch adversarial loss: 0.447405\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034165; batch adversarial loss: 0.472475\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043332; batch adversarial loss: 0.401102\n",
      "epoch 109; iter: 0; batch classifier loss: 0.016522; batch adversarial loss: 0.506579\n",
      "epoch 110; iter: 0; batch classifier loss: 0.015092; batch adversarial loss: 0.453933\n",
      "epoch 111; iter: 0; batch classifier loss: 0.018993; batch adversarial loss: 0.377112\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031377; batch adversarial loss: 0.452741\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027374; batch adversarial loss: 0.454249\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046382; batch adversarial loss: 0.497761\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033451; batch adversarial loss: 0.463432\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027435; batch adversarial loss: 0.454305\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053798; batch adversarial loss: 0.438910\n",
      "epoch 118; iter: 0; batch classifier loss: 0.018262; batch adversarial loss: 0.395480\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042675; batch adversarial loss: 0.396331\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037760; batch adversarial loss: 0.582611\n",
      "epoch 121; iter: 0; batch classifier loss: 0.016383; batch adversarial loss: 0.462671\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038583; batch adversarial loss: 0.453594\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014711; batch adversarial loss: 0.399687\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030302; batch adversarial loss: 0.496534\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035036; batch adversarial loss: 0.417573\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048252; batch adversarial loss: 0.422874\n",
      "epoch 127; iter: 0; batch classifier loss: 0.052657; batch adversarial loss: 0.538890\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035805; batch adversarial loss: 0.521676\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026438; batch adversarial loss: 0.471111\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038711; batch adversarial loss: 0.486416\n",
      "epoch 131; iter: 0; batch classifier loss: 0.013423; batch adversarial loss: 0.393456\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028934; batch adversarial loss: 0.530283\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033500; batch adversarial loss: 0.463729\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030290; batch adversarial loss: 0.591969\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023761; batch adversarial loss: 0.447464\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025609; batch adversarial loss: 0.458263\n",
      "epoch 137; iter: 0; batch classifier loss: 0.013076; batch adversarial loss: 0.579781\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023518; batch adversarial loss: 0.441067\n",
      "epoch 139; iter: 0; batch classifier loss: 0.027874; batch adversarial loss: 0.457526\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028869; batch adversarial loss: 0.416643\n",
      "epoch 141; iter: 0; batch classifier loss: 0.012812; batch adversarial loss: 0.509047\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014819; batch adversarial loss: 0.438516\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037474; batch adversarial loss: 0.560749\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025469; batch adversarial loss: 0.397253\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011979; batch adversarial loss: 0.422722\n",
      "epoch 146; iter: 0; batch classifier loss: 0.004492; batch adversarial loss: 0.404609\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024832; batch adversarial loss: 0.515587\n",
      "epoch 148; iter: 0; batch classifier loss: 0.056592; batch adversarial loss: 0.449566\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017950; batch adversarial loss: 0.481310\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033730; batch adversarial loss: 0.400095\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037082; batch adversarial loss: 0.476832\n",
      "epoch 152; iter: 0; batch classifier loss: 0.043136; batch adversarial loss: 0.533577\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020294; batch adversarial loss: 0.425691\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011442; batch adversarial loss: 0.539106\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016487; batch adversarial loss: 0.429013\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015992; batch adversarial loss: 0.375528\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021526; batch adversarial loss: 0.479639\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027338; batch adversarial loss: 0.437334\n",
      "epoch 159; iter: 0; batch classifier loss: 0.047791; batch adversarial loss: 0.603723\n",
      "epoch 160; iter: 0; batch classifier loss: 0.077223; batch adversarial loss: 0.525231\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018186; batch adversarial loss: 0.446313\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016793; batch adversarial loss: 0.437598\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018296; batch adversarial loss: 0.482495\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034605; batch adversarial loss: 0.602933\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033601; batch adversarial loss: 0.400109\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010713; batch adversarial loss: 0.485118\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015903; batch adversarial loss: 0.409211\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035823; batch adversarial loss: 0.465280\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016428; batch adversarial loss: 0.432866\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039165; batch adversarial loss: 0.486211\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017711; batch adversarial loss: 0.402096\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005926; batch adversarial loss: 0.554592\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025242; batch adversarial loss: 0.465367\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012152; batch adversarial loss: 0.523463\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034243; batch adversarial loss: 0.441315\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015095; batch adversarial loss: 0.467224\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011906; batch adversarial loss: 0.455865\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030709; batch adversarial loss: 0.558447\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014939; batch adversarial loss: 0.451427\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035696; batch adversarial loss: 0.444183\n",
      "epoch 181; iter: 0; batch classifier loss: 0.048149; batch adversarial loss: 0.436002\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019120; batch adversarial loss: 0.479258\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021865; batch adversarial loss: 0.507334\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007824; batch adversarial loss: 0.396739\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014994; batch adversarial loss: 0.432589\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029163; batch adversarial loss: 0.518208\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014018; batch adversarial loss: 0.414671\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007811; batch adversarial loss: 0.447188\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023379; batch adversarial loss: 0.442768\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007639; batch adversarial loss: 0.459822\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010236; batch adversarial loss: 0.377319\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027858; batch adversarial loss: 0.471680\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018774; batch adversarial loss: 0.430637\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009052; batch adversarial loss: 0.462333\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011526; batch adversarial loss: 0.470952\n",
      "epoch 196; iter: 0; batch classifier loss: 0.043374; batch adversarial loss: 0.571229\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015804; batch adversarial loss: 0.488448\n",
      "epoch 198; iter: 0; batch classifier loss: 0.051466; batch adversarial loss: 0.473579\n",
      "epoch 199; iter: 0; batch classifier loss: 0.029426; batch adversarial loss: 0.422733\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688105; batch adversarial loss: 0.900477\n",
      "epoch 1; iter: 0; batch classifier loss: 0.527575; batch adversarial loss: 0.926792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.382789; batch adversarial loss: 0.818896\n",
      "epoch 3; iter: 0; batch classifier loss: 0.337878; batch adversarial loss: 0.818391\n",
      "epoch 4; iter: 0; batch classifier loss: 0.320337; batch adversarial loss: 0.732920\n",
      "epoch 5; iter: 0; batch classifier loss: 0.341576; batch adversarial loss: 0.664440\n",
      "epoch 6; iter: 0; batch classifier loss: 0.328945; batch adversarial loss: 0.676867\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300831; batch adversarial loss: 0.629498\n",
      "epoch 8; iter: 0; batch classifier loss: 0.256745; batch adversarial loss: 0.610204\n",
      "epoch 9; iter: 0; batch classifier loss: 0.314089; batch adversarial loss: 0.564215\n",
      "epoch 10; iter: 0; batch classifier loss: 0.249699; batch adversarial loss: 0.577532\n",
      "epoch 11; iter: 0; batch classifier loss: 0.291473; batch adversarial loss: 0.547050\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251016; batch adversarial loss: 0.567464\n",
      "epoch 13; iter: 0; batch classifier loss: 0.199122; batch adversarial loss: 0.585080\n",
      "epoch 14; iter: 0; batch classifier loss: 0.245133; batch adversarial loss: 0.516965\n",
      "epoch 15; iter: 0; batch classifier loss: 0.238724; batch adversarial loss: 0.540678\n",
      "epoch 16; iter: 0; batch classifier loss: 0.248599; batch adversarial loss: 0.457494\n",
      "epoch 17; iter: 0; batch classifier loss: 0.314823; batch adversarial loss: 0.450835\n",
      "epoch 18; iter: 0; batch classifier loss: 0.302573; batch adversarial loss: 0.423502\n",
      "epoch 19; iter: 0; batch classifier loss: 0.277203; batch adversarial loss: 0.459777\n",
      "epoch 20; iter: 0; batch classifier loss: 0.240110; batch adversarial loss: 0.491682\n",
      "epoch 21; iter: 0; batch classifier loss: 0.255920; batch adversarial loss: 0.489729\n",
      "epoch 22; iter: 0; batch classifier loss: 0.174362; batch adversarial loss: 0.442096\n",
      "epoch 23; iter: 0; batch classifier loss: 0.173496; batch adversarial loss: 0.454105\n",
      "epoch 24; iter: 0; batch classifier loss: 0.170159; batch adversarial loss: 0.438124\n",
      "epoch 25; iter: 0; batch classifier loss: 0.202352; batch adversarial loss: 0.480946\n",
      "epoch 26; iter: 0; batch classifier loss: 0.179335; batch adversarial loss: 0.400129\n",
      "epoch 27; iter: 0; batch classifier loss: 0.172247; batch adversarial loss: 0.494334\n",
      "epoch 28; iter: 0; batch classifier loss: 0.115902; batch adversarial loss: 0.380452\n",
      "epoch 29; iter: 0; batch classifier loss: 0.161306; batch adversarial loss: 0.485826\n",
      "epoch 30; iter: 0; batch classifier loss: 0.147143; batch adversarial loss: 0.403406\n",
      "epoch 31; iter: 0; batch classifier loss: 0.182880; batch adversarial loss: 0.482970\n",
      "epoch 32; iter: 0; batch classifier loss: 0.122562; batch adversarial loss: 0.450491\n",
      "epoch 33; iter: 0; batch classifier loss: 0.174926; batch adversarial loss: 0.394229\n",
      "epoch 34; iter: 0; batch classifier loss: 0.141682; batch adversarial loss: 0.443943\n",
      "epoch 35; iter: 0; batch classifier loss: 0.152288; batch adversarial loss: 0.400812\n",
      "epoch 36; iter: 0; batch classifier loss: 0.191070; batch adversarial loss: 0.406644\n",
      "epoch 37; iter: 0; batch classifier loss: 0.164747; batch adversarial loss: 0.391135\n",
      "epoch 38; iter: 0; batch classifier loss: 0.153548; batch adversarial loss: 0.368418\n",
      "epoch 39; iter: 0; batch classifier loss: 0.155229; batch adversarial loss: 0.441681\n",
      "epoch 40; iter: 0; batch classifier loss: 0.166737; batch adversarial loss: 0.388254\n",
      "epoch 41; iter: 0; batch classifier loss: 0.101216; batch adversarial loss: 0.498840\n",
      "epoch 42; iter: 0; batch classifier loss: 0.136382; batch adversarial loss: 0.345661\n",
      "epoch 43; iter: 0; batch classifier loss: 0.138469; batch adversarial loss: 0.332124\n",
      "epoch 44; iter: 0; batch classifier loss: 0.122919; batch adversarial loss: 0.413542\n",
      "epoch 45; iter: 0; batch classifier loss: 0.140611; batch adversarial loss: 0.418711\n",
      "epoch 46; iter: 0; batch classifier loss: 0.128564; batch adversarial loss: 0.473559\n",
      "epoch 47; iter: 0; batch classifier loss: 0.115872; batch adversarial loss: 0.400554\n",
      "epoch 48; iter: 0; batch classifier loss: 0.179476; batch adversarial loss: 0.480014\n",
      "epoch 49; iter: 0; batch classifier loss: 0.093041; batch adversarial loss: 0.335663\n",
      "epoch 50; iter: 0; batch classifier loss: 0.095439; batch adversarial loss: 0.395033\n",
      "epoch 51; iter: 0; batch classifier loss: 0.119517; batch adversarial loss: 0.385139\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082696; batch adversarial loss: 0.334302\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094877; batch adversarial loss: 0.494918\n",
      "epoch 54; iter: 0; batch classifier loss: 0.090895; batch adversarial loss: 0.422309\n",
      "epoch 55; iter: 0; batch classifier loss: 0.090091; batch adversarial loss: 0.501745\n",
      "epoch 56; iter: 0; batch classifier loss: 0.129448; batch adversarial loss: 0.459328\n",
      "epoch 57; iter: 0; batch classifier loss: 0.098290; batch adversarial loss: 0.405519\n",
      "epoch 58; iter: 0; batch classifier loss: 0.113313; batch adversarial loss: 0.439668\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070009; batch adversarial loss: 0.425433\n",
      "epoch 60; iter: 0; batch classifier loss: 0.108510; batch adversarial loss: 0.399226\n",
      "epoch 61; iter: 0; batch classifier loss: 0.164428; batch adversarial loss: 0.483244\n",
      "epoch 62; iter: 0; batch classifier loss: 0.119167; batch adversarial loss: 0.398959\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097385; batch adversarial loss: 0.476460\n",
      "epoch 64; iter: 0; batch classifier loss: 0.077277; batch adversarial loss: 0.410834\n",
      "epoch 65; iter: 0; batch classifier loss: 0.094840; batch adversarial loss: 0.515979\n",
      "epoch 66; iter: 0; batch classifier loss: 0.138247; batch adversarial loss: 0.431513\n",
      "epoch 67; iter: 0; batch classifier loss: 0.044840; batch adversarial loss: 0.435111\n",
      "epoch 68; iter: 0; batch classifier loss: 0.098537; batch adversarial loss: 0.518665\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071261; batch adversarial loss: 0.403527\n",
      "epoch 70; iter: 0; batch classifier loss: 0.092532; batch adversarial loss: 0.442646\n",
      "epoch 71; iter: 0; batch classifier loss: 0.062484; batch adversarial loss: 0.390566\n",
      "epoch 72; iter: 0; batch classifier loss: 0.076538; batch adversarial loss: 0.445452\n",
      "epoch 73; iter: 0; batch classifier loss: 0.105803; batch adversarial loss: 0.424810\n",
      "epoch 74; iter: 0; batch classifier loss: 0.116917; batch adversarial loss: 0.359695\n",
      "epoch 75; iter: 0; batch classifier loss: 0.094161; batch adversarial loss: 0.366532\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082166; batch adversarial loss: 0.414888\n",
      "epoch 77; iter: 0; batch classifier loss: 0.061499; batch adversarial loss: 0.523129\n",
      "epoch 78; iter: 0; batch classifier loss: 0.052753; batch adversarial loss: 0.384116\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075436; batch adversarial loss: 0.361469\n",
      "epoch 80; iter: 0; batch classifier loss: 0.085029; batch adversarial loss: 0.448519\n",
      "epoch 81; iter: 0; batch classifier loss: 0.113987; batch adversarial loss: 0.581253\n",
      "epoch 82; iter: 0; batch classifier loss: 0.072562; batch adversarial loss: 0.426053\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071256; batch adversarial loss: 0.460899\n",
      "epoch 84; iter: 0; batch classifier loss: 0.069677; batch adversarial loss: 0.493942\n",
      "epoch 85; iter: 0; batch classifier loss: 0.099051; batch adversarial loss: 0.406679\n",
      "epoch 86; iter: 0; batch classifier loss: 0.075146; batch adversarial loss: 0.479448\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068750; batch adversarial loss: 0.525952\n",
      "epoch 88; iter: 0; batch classifier loss: 0.091238; batch adversarial loss: 0.453775\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059971; batch adversarial loss: 0.443493\n",
      "epoch 90; iter: 0; batch classifier loss: 0.069245; batch adversarial loss: 0.448824\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064048; batch adversarial loss: 0.442818\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069692; batch adversarial loss: 0.405999\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067964; batch adversarial loss: 0.472696\n",
      "epoch 94; iter: 0; batch classifier loss: 0.078903; batch adversarial loss: 0.439617\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056471; batch adversarial loss: 0.424155\n",
      "epoch 96; iter: 0; batch classifier loss: 0.077327; batch adversarial loss: 0.428502\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081446; batch adversarial loss: 0.493095\n",
      "epoch 98; iter: 0; batch classifier loss: 0.069174; batch adversarial loss: 0.462092\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037021; batch adversarial loss: 0.368103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.044292; batch adversarial loss: 0.371089\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075649; batch adversarial loss: 0.446653\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058377; batch adversarial loss: 0.395841\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064168; batch adversarial loss: 0.444408\n",
      "epoch 104; iter: 0; batch classifier loss: 0.082391; batch adversarial loss: 0.468329\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051437; batch adversarial loss: 0.464302\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062886; batch adversarial loss: 0.497970\n",
      "epoch 107; iter: 0; batch classifier loss: 0.068898; batch adversarial loss: 0.393177\n",
      "epoch 108; iter: 0; batch classifier loss: 0.114510; batch adversarial loss: 0.531085\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060589; batch adversarial loss: 0.354685\n",
      "epoch 110; iter: 0; batch classifier loss: 0.062585; batch adversarial loss: 0.429990\n",
      "epoch 111; iter: 0; batch classifier loss: 0.092536; batch adversarial loss: 0.408933\n",
      "epoch 112; iter: 0; batch classifier loss: 0.068377; batch adversarial loss: 0.509665\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063576; batch adversarial loss: 0.404305\n",
      "epoch 114; iter: 0; batch classifier loss: 0.079142; batch adversarial loss: 0.441591\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059149; batch adversarial loss: 0.429876\n",
      "epoch 116; iter: 0; batch classifier loss: 0.071572; batch adversarial loss: 0.390526\n",
      "epoch 117; iter: 0; batch classifier loss: 0.069320; batch adversarial loss: 0.423463\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054733; batch adversarial loss: 0.428306\n",
      "epoch 119; iter: 0; batch classifier loss: 0.067989; batch adversarial loss: 0.422693\n",
      "epoch 120; iter: 0; batch classifier loss: 0.070712; batch adversarial loss: 0.384488\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033993; batch adversarial loss: 0.447923\n",
      "epoch 122; iter: 0; batch classifier loss: 0.064129; batch adversarial loss: 0.468544\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039164; batch adversarial loss: 0.514030\n",
      "epoch 124; iter: 0; batch classifier loss: 0.069015; batch adversarial loss: 0.472679\n",
      "epoch 125; iter: 0; batch classifier loss: 0.078619; batch adversarial loss: 0.433459\n",
      "epoch 126; iter: 0; batch classifier loss: 0.058767; batch adversarial loss: 0.491168\n",
      "epoch 127; iter: 0; batch classifier loss: 0.041502; batch adversarial loss: 0.381549\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052600; batch adversarial loss: 0.412016\n",
      "epoch 129; iter: 0; batch classifier loss: 0.074673; batch adversarial loss: 0.511189\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059232; batch adversarial loss: 0.410653\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038599; batch adversarial loss: 0.432816\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048000; batch adversarial loss: 0.403360\n",
      "epoch 133; iter: 0; batch classifier loss: 0.054691; batch adversarial loss: 0.407473\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048034; batch adversarial loss: 0.521867\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045175; batch adversarial loss: 0.394948\n",
      "epoch 136; iter: 0; batch classifier loss: 0.051339; batch adversarial loss: 0.475073\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023030; batch adversarial loss: 0.426981\n",
      "epoch 138; iter: 0; batch classifier loss: 0.060105; batch adversarial loss: 0.458651\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044765; batch adversarial loss: 0.549511\n",
      "epoch 140; iter: 0; batch classifier loss: 0.072673; batch adversarial loss: 0.384907\n",
      "epoch 141; iter: 0; batch classifier loss: 0.065707; batch adversarial loss: 0.441106\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019826; batch adversarial loss: 0.381627\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040777; batch adversarial loss: 0.439163\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025745; batch adversarial loss: 0.465172\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041099; batch adversarial loss: 0.464564\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034134; batch adversarial loss: 0.391755\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043813; batch adversarial loss: 0.457103\n",
      "epoch 148; iter: 0; batch classifier loss: 0.050572; batch adversarial loss: 0.451671\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029329; batch adversarial loss: 0.400021\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027369; batch adversarial loss: 0.496719\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033854; batch adversarial loss: 0.488880\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025718; batch adversarial loss: 0.513734\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034757; batch adversarial loss: 0.453746\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018597; batch adversarial loss: 0.520540\n",
      "epoch 155; iter: 0; batch classifier loss: 0.050355; batch adversarial loss: 0.643814\n",
      "epoch 156; iter: 0; batch classifier loss: 0.046904; batch adversarial loss: 0.560667\n",
      "epoch 157; iter: 0; batch classifier loss: 0.129323; batch adversarial loss: 0.796187\n",
      "epoch 158; iter: 0; batch classifier loss: 0.094806; batch adversarial loss: 0.507133\n",
      "epoch 159; iter: 0; batch classifier loss: 0.103054; batch adversarial loss: 0.668573\n",
      "epoch 160; iter: 0; batch classifier loss: 0.138464; batch adversarial loss: 0.592402\n",
      "epoch 161; iter: 0; batch classifier loss: 0.100214; batch adversarial loss: 0.650555\n",
      "epoch 162; iter: 0; batch classifier loss: 0.059799; batch adversarial loss: 0.496235\n",
      "epoch 163; iter: 0; batch classifier loss: 0.119986; batch adversarial loss: 0.628821\n",
      "epoch 164; iter: 0; batch classifier loss: 0.139356; batch adversarial loss: 0.577788\n",
      "epoch 165; iter: 0; batch classifier loss: 0.160994; batch adversarial loss: 0.636287\n",
      "epoch 166; iter: 0; batch classifier loss: 0.128145; batch adversarial loss: 0.612211\n",
      "epoch 167; iter: 0; batch classifier loss: 0.139665; batch adversarial loss: 0.536584\n",
      "epoch 168; iter: 0; batch classifier loss: 0.147131; batch adversarial loss: 0.593096\n",
      "epoch 169; iter: 0; batch classifier loss: 0.206761; batch adversarial loss: 0.772688\n",
      "epoch 170; iter: 0; batch classifier loss: 0.183790; batch adversarial loss: 0.743785\n",
      "epoch 171; iter: 0; batch classifier loss: 0.259446; batch adversarial loss: 0.845889\n",
      "epoch 172; iter: 0; batch classifier loss: 0.193289; batch adversarial loss: 0.674446\n",
      "epoch 173; iter: 0; batch classifier loss: 0.132398; batch adversarial loss: 0.579935\n",
      "epoch 174; iter: 0; batch classifier loss: 0.120049; batch adversarial loss: 0.532319\n",
      "epoch 175; iter: 0; batch classifier loss: 0.270413; batch adversarial loss: 0.757258\n",
      "epoch 176; iter: 0; batch classifier loss: 0.194221; batch adversarial loss: 0.667446\n",
      "epoch 177; iter: 0; batch classifier loss: 0.162591; batch adversarial loss: 0.644843\n",
      "epoch 178; iter: 0; batch classifier loss: 0.230740; batch adversarial loss: 0.640973\n",
      "epoch 179; iter: 0; batch classifier loss: 0.219154; batch adversarial loss: 0.743391\n",
      "epoch 180; iter: 0; batch classifier loss: 0.220555; batch adversarial loss: 0.725642\n",
      "epoch 181; iter: 0; batch classifier loss: 0.234519; batch adversarial loss: 0.654112\n",
      "epoch 182; iter: 0; batch classifier loss: 0.169317; batch adversarial loss: 0.552318\n",
      "epoch 183; iter: 0; batch classifier loss: 0.279129; batch adversarial loss: 0.766488\n",
      "epoch 184; iter: 0; batch classifier loss: 0.237576; batch adversarial loss: 0.589707\n",
      "epoch 185; iter: 0; batch classifier loss: 0.133937; batch adversarial loss: 0.550906\n",
      "epoch 186; iter: 0; batch classifier loss: 0.135866; batch adversarial loss: 0.495672\n",
      "epoch 187; iter: 0; batch classifier loss: 0.262657; batch adversarial loss: 0.708674\n",
      "epoch 188; iter: 0; batch classifier loss: 0.154790; batch adversarial loss: 0.552332\n",
      "epoch 189; iter: 0; batch classifier loss: 0.186107; batch adversarial loss: 0.582632\n",
      "epoch 190; iter: 0; batch classifier loss: 0.206365; batch adversarial loss: 0.610610\n",
      "epoch 191; iter: 0; batch classifier loss: 0.126308; batch adversarial loss: 0.498534\n",
      "epoch 192; iter: 0; batch classifier loss: 0.149436; batch adversarial loss: 0.605876\n",
      "epoch 193; iter: 0; batch classifier loss: 0.107808; batch adversarial loss: 0.484183\n",
      "epoch 194; iter: 0; batch classifier loss: 0.165111; batch adversarial loss: 0.550599\n",
      "epoch 195; iter: 0; batch classifier loss: 0.123663; batch adversarial loss: 0.465094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.143411; batch adversarial loss: 0.558884\n",
      "epoch 197; iter: 0; batch classifier loss: 0.115147; batch adversarial loss: 0.481620\n",
      "epoch 198; iter: 0; batch classifier loss: 0.155252; batch adversarial loss: 0.564987\n",
      "epoch 199; iter: 0; batch classifier loss: 0.139686; batch adversarial loss: 0.471769\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683530; batch adversarial loss: 0.799406\n",
      "epoch 1; iter: 0; batch classifier loss: 0.511503; batch adversarial loss: 0.754137\n",
      "epoch 2; iter: 0; batch classifier loss: 0.666019; batch adversarial loss: 0.755172\n",
      "epoch 3; iter: 0; batch classifier loss: 0.786818; batch adversarial loss: 0.700346\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598076; batch adversarial loss: 0.631556\n",
      "epoch 5; iter: 0; batch classifier loss: 0.458672; batch adversarial loss: 0.558884\n",
      "epoch 6; iter: 0; batch classifier loss: 0.361706; batch adversarial loss: 0.576522\n",
      "epoch 7; iter: 0; batch classifier loss: 0.410116; batch adversarial loss: 0.556522\n",
      "epoch 8; iter: 0; batch classifier loss: 0.405362; batch adversarial loss: 0.548632\n",
      "epoch 9; iter: 0; batch classifier loss: 0.358028; batch adversarial loss: 0.520120\n",
      "epoch 10; iter: 0; batch classifier loss: 0.331316; batch adversarial loss: 0.540377\n",
      "epoch 11; iter: 0; batch classifier loss: 0.326742; batch adversarial loss: 0.574510\n",
      "epoch 12; iter: 0; batch classifier loss: 0.316885; batch adversarial loss: 0.514458\n",
      "epoch 13; iter: 0; batch classifier loss: 0.299285; batch adversarial loss: 0.547004\n",
      "epoch 14; iter: 0; batch classifier loss: 0.294769; batch adversarial loss: 0.476805\n",
      "epoch 15; iter: 0; batch classifier loss: 0.365757; batch adversarial loss: 0.494890\n",
      "epoch 16; iter: 0; batch classifier loss: 0.286753; batch adversarial loss: 0.495337\n",
      "epoch 17; iter: 0; batch classifier loss: 0.251707; batch adversarial loss: 0.516615\n",
      "epoch 18; iter: 0; batch classifier loss: 0.325108; batch adversarial loss: 0.470111\n",
      "epoch 19; iter: 0; batch classifier loss: 0.255882; batch adversarial loss: 0.510430\n",
      "epoch 20; iter: 0; batch classifier loss: 0.239336; batch adversarial loss: 0.478341\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234616; batch adversarial loss: 0.523187\n",
      "epoch 22; iter: 0; batch classifier loss: 0.256699; batch adversarial loss: 0.507242\n",
      "epoch 23; iter: 0; batch classifier loss: 0.237062; batch adversarial loss: 0.411151\n",
      "epoch 24; iter: 0; batch classifier loss: 0.273784; batch adversarial loss: 0.454076\n",
      "epoch 25; iter: 0; batch classifier loss: 0.180758; batch adversarial loss: 0.505522\n",
      "epoch 26; iter: 0; batch classifier loss: 0.207002; batch adversarial loss: 0.473579\n",
      "epoch 27; iter: 0; batch classifier loss: 0.220194; batch adversarial loss: 0.449899\n",
      "epoch 28; iter: 0; batch classifier loss: 0.187976; batch adversarial loss: 0.535886\n",
      "epoch 29; iter: 0; batch classifier loss: 0.188032; batch adversarial loss: 0.521347\n",
      "epoch 30; iter: 0; batch classifier loss: 0.195305; batch adversarial loss: 0.448700\n",
      "epoch 31; iter: 0; batch classifier loss: 0.238741; batch adversarial loss: 0.487955\n",
      "epoch 32; iter: 0; batch classifier loss: 0.186291; batch adversarial loss: 0.548123\n",
      "epoch 33; iter: 0; batch classifier loss: 0.111198; batch adversarial loss: 0.467091\n",
      "epoch 34; iter: 0; batch classifier loss: 0.214133; batch adversarial loss: 0.402912\n",
      "epoch 35; iter: 0; batch classifier loss: 0.228887; batch adversarial loss: 0.425254\n",
      "epoch 36; iter: 0; batch classifier loss: 0.225365; batch adversarial loss: 0.429314\n",
      "epoch 37; iter: 0; batch classifier loss: 0.200247; batch adversarial loss: 0.531029\n",
      "epoch 38; iter: 0; batch classifier loss: 0.185789; batch adversarial loss: 0.472430\n",
      "epoch 39; iter: 0; batch classifier loss: 0.184381; batch adversarial loss: 0.485690\n",
      "epoch 40; iter: 0; batch classifier loss: 0.212721; batch adversarial loss: 0.483600\n",
      "epoch 41; iter: 0; batch classifier loss: 0.126301; batch adversarial loss: 0.523945\n",
      "epoch 42; iter: 0; batch classifier loss: 0.179611; batch adversarial loss: 0.545729\n",
      "epoch 43; iter: 0; batch classifier loss: 0.208186; batch adversarial loss: 0.481507\n",
      "epoch 44; iter: 0; batch classifier loss: 0.180351; batch adversarial loss: 0.356659\n",
      "epoch 45; iter: 0; batch classifier loss: 0.194798; batch adversarial loss: 0.486637\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126014; batch adversarial loss: 0.480004\n",
      "epoch 47; iter: 0; batch classifier loss: 0.180205; batch adversarial loss: 0.344531\n",
      "epoch 48; iter: 0; batch classifier loss: 0.186767; batch adversarial loss: 0.469016\n",
      "epoch 49; iter: 0; batch classifier loss: 0.174488; batch adversarial loss: 0.425575\n",
      "epoch 50; iter: 0; batch classifier loss: 0.207871; batch adversarial loss: 0.443013\n",
      "epoch 51; iter: 0; batch classifier loss: 0.154301; batch adversarial loss: 0.439730\n",
      "epoch 52; iter: 0; batch classifier loss: 0.175494; batch adversarial loss: 0.501524\n",
      "epoch 53; iter: 0; batch classifier loss: 0.174302; batch adversarial loss: 0.377665\n",
      "epoch 54; iter: 0; batch classifier loss: 0.161074; batch adversarial loss: 0.493095\n",
      "epoch 55; iter: 0; batch classifier loss: 0.203083; batch adversarial loss: 0.385614\n",
      "epoch 56; iter: 0; batch classifier loss: 0.214868; batch adversarial loss: 0.455605\n",
      "epoch 57; iter: 0; batch classifier loss: 0.161373; batch adversarial loss: 0.568168\n",
      "epoch 58; iter: 0; batch classifier loss: 0.200508; batch adversarial loss: 0.554934\n",
      "epoch 59; iter: 0; batch classifier loss: 0.210253; batch adversarial loss: 0.505274\n",
      "epoch 60; iter: 0; batch classifier loss: 0.214458; batch adversarial loss: 0.433549\n",
      "epoch 61; iter: 0; batch classifier loss: 0.235776; batch adversarial loss: 0.553428\n",
      "epoch 62; iter: 0; batch classifier loss: 0.192657; batch adversarial loss: 0.408034\n",
      "epoch 63; iter: 0; batch classifier loss: 0.172753; batch adversarial loss: 0.515584\n",
      "epoch 64; iter: 0; batch classifier loss: 0.148364; batch adversarial loss: 0.403466\n",
      "epoch 65; iter: 0; batch classifier loss: 0.161833; batch adversarial loss: 0.470079\n",
      "epoch 66; iter: 0; batch classifier loss: 0.182728; batch adversarial loss: 0.437066\n",
      "epoch 67; iter: 0; batch classifier loss: 0.152881; batch adversarial loss: 0.445503\n",
      "epoch 68; iter: 0; batch classifier loss: 0.156047; batch adversarial loss: 0.459455\n",
      "epoch 69; iter: 0; batch classifier loss: 0.177226; batch adversarial loss: 0.447907\n",
      "epoch 70; iter: 0; batch classifier loss: 0.131910; batch adversarial loss: 0.456504\n",
      "epoch 71; iter: 0; batch classifier loss: 0.194507; batch adversarial loss: 0.408566\n",
      "epoch 72; iter: 0; batch classifier loss: 0.139168; batch adversarial loss: 0.516899\n",
      "epoch 73; iter: 0; batch classifier loss: 0.174766; batch adversarial loss: 0.549321\n",
      "epoch 74; iter: 0; batch classifier loss: 0.163282; batch adversarial loss: 0.507674\n",
      "epoch 75; iter: 0; batch classifier loss: 0.229766; batch adversarial loss: 0.424937\n",
      "epoch 76; iter: 0; batch classifier loss: 0.244147; batch adversarial loss: 0.437483\n",
      "epoch 77; iter: 0; batch classifier loss: 0.220815; batch adversarial loss: 0.467981\n",
      "epoch 78; iter: 0; batch classifier loss: 0.251318; batch adversarial loss: 0.409392\n",
      "epoch 79; iter: 0; batch classifier loss: 0.183485; batch adversarial loss: 0.545272\n",
      "epoch 80; iter: 0; batch classifier loss: 0.181259; batch adversarial loss: 0.470021\n",
      "epoch 81; iter: 0; batch classifier loss: 0.258062; batch adversarial loss: 0.458214\n",
      "epoch 82; iter: 0; batch classifier loss: 0.209781; batch adversarial loss: 0.434651\n",
      "epoch 83; iter: 0; batch classifier loss: 0.187060; batch adversarial loss: 0.471114\n",
      "epoch 84; iter: 0; batch classifier loss: 0.214193; batch adversarial loss: 0.471408\n",
      "epoch 85; iter: 0; batch classifier loss: 0.226078; batch adversarial loss: 0.471442\n",
      "epoch 86; iter: 0; batch classifier loss: 0.153415; batch adversarial loss: 0.493786\n",
      "epoch 87; iter: 0; batch classifier loss: 0.171250; batch adversarial loss: 0.495405\n",
      "epoch 88; iter: 0; batch classifier loss: 0.226006; batch adversarial loss: 0.519111\n",
      "epoch 89; iter: 0; batch classifier loss: 0.226356; batch adversarial loss: 0.555311\n",
      "epoch 90; iter: 0; batch classifier loss: 0.260042; batch adversarial loss: 0.410724\n",
      "epoch 91; iter: 0; batch classifier loss: 0.132634; batch adversarial loss: 0.446930\n",
      "epoch 92; iter: 0; batch classifier loss: 0.138200; batch adversarial loss: 0.457909\n",
      "epoch 93; iter: 0; batch classifier loss: 0.154332; batch adversarial loss: 0.434810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.185768; batch adversarial loss: 0.534865\n",
      "epoch 95; iter: 0; batch classifier loss: 0.214022; batch adversarial loss: 0.457334\n",
      "epoch 96; iter: 0; batch classifier loss: 0.246885; batch adversarial loss: 0.459449\n",
      "epoch 97; iter: 0; batch classifier loss: 0.211859; batch adversarial loss: 0.458021\n",
      "epoch 98; iter: 0; batch classifier loss: 0.210808; batch adversarial loss: 0.531739\n",
      "epoch 99; iter: 0; batch classifier loss: 0.158766; batch adversarial loss: 0.434034\n",
      "epoch 100; iter: 0; batch classifier loss: 0.220658; batch adversarial loss: 0.434327\n",
      "epoch 101; iter: 0; batch classifier loss: 0.173829; batch adversarial loss: 0.555282\n",
      "epoch 102; iter: 0; batch classifier loss: 0.178902; batch adversarial loss: 0.434816\n",
      "epoch 103; iter: 0; batch classifier loss: 0.165075; batch adversarial loss: 0.506962\n",
      "epoch 104; iter: 0; batch classifier loss: 0.259048; batch adversarial loss: 0.398610\n",
      "epoch 105; iter: 0; batch classifier loss: 0.184566; batch adversarial loss: 0.458580\n",
      "epoch 106; iter: 0; batch classifier loss: 0.157219; batch adversarial loss: 0.447016\n",
      "epoch 107; iter: 0; batch classifier loss: 0.194824; batch adversarial loss: 0.374258\n",
      "epoch 108; iter: 0; batch classifier loss: 0.232969; batch adversarial loss: 0.445823\n",
      "epoch 109; iter: 0; batch classifier loss: 0.253464; batch adversarial loss: 0.568888\n",
      "epoch 110; iter: 0; batch classifier loss: 0.110655; batch adversarial loss: 0.544081\n",
      "epoch 111; iter: 0; batch classifier loss: 0.254676; batch adversarial loss: 0.410682\n",
      "epoch 112; iter: 0; batch classifier loss: 0.214659; batch adversarial loss: 0.423378\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343377; batch adversarial loss: 0.362860\n",
      "epoch 114; iter: 0; batch classifier loss: 0.237853; batch adversarial loss: 0.374703\n",
      "epoch 115; iter: 0; batch classifier loss: 0.090611; batch adversarial loss: 0.470788\n",
      "epoch 116; iter: 0; batch classifier loss: 0.114544; batch adversarial loss: 0.433286\n",
      "epoch 117; iter: 0; batch classifier loss: 0.151647; batch adversarial loss: 0.448666\n",
      "epoch 118; iter: 0; batch classifier loss: 0.234867; batch adversarial loss: 0.518067\n",
      "epoch 119; iter: 0; batch classifier loss: 0.181755; batch adversarial loss: 0.483324\n",
      "epoch 120; iter: 0; batch classifier loss: 0.210275; batch adversarial loss: 0.529648\n",
      "epoch 121; iter: 0; batch classifier loss: 0.167828; batch adversarial loss: 0.398489\n",
      "epoch 122; iter: 0; batch classifier loss: 0.223368; batch adversarial loss: 0.543899\n",
      "epoch 123; iter: 0; batch classifier loss: 0.165681; batch adversarial loss: 0.591413\n",
      "epoch 124; iter: 0; batch classifier loss: 0.178909; batch adversarial loss: 0.495151\n",
      "epoch 125; iter: 0; batch classifier loss: 0.150256; batch adversarial loss: 0.495166\n",
      "epoch 126; iter: 0; batch classifier loss: 0.192068; batch adversarial loss: 0.471139\n",
      "epoch 127; iter: 0; batch classifier loss: 0.231869; batch adversarial loss: 0.398998\n",
      "epoch 128; iter: 0; batch classifier loss: 0.140229; batch adversarial loss: 0.604114\n",
      "epoch 129; iter: 0; batch classifier loss: 0.261969; batch adversarial loss: 0.422648\n",
      "epoch 130; iter: 0; batch classifier loss: 0.218639; batch adversarial loss: 0.543819\n",
      "epoch 131; iter: 0; batch classifier loss: 0.224841; batch adversarial loss: 0.362372\n",
      "epoch 132; iter: 0; batch classifier loss: 0.205905; batch adversarial loss: 0.471034\n",
      "epoch 133; iter: 0; batch classifier loss: 0.237343; batch adversarial loss: 0.482767\n",
      "epoch 134; iter: 0; batch classifier loss: 0.214330; batch adversarial loss: 0.494959\n",
      "epoch 135; iter: 0; batch classifier loss: 0.194017; batch adversarial loss: 0.495102\n",
      "epoch 136; iter: 0; batch classifier loss: 0.217753; batch adversarial loss: 0.434822\n",
      "epoch 137; iter: 0; batch classifier loss: 0.144296; batch adversarial loss: 0.482750\n",
      "epoch 138; iter: 0; batch classifier loss: 0.231379; batch adversarial loss: 0.409897\n",
      "epoch 139; iter: 0; batch classifier loss: 0.201918; batch adversarial loss: 0.422110\n",
      "epoch 140; iter: 0; batch classifier loss: 0.212392; batch adversarial loss: 0.482801\n",
      "epoch 141; iter: 0; batch classifier loss: 0.165655; batch adversarial loss: 0.482857\n",
      "epoch 142; iter: 0; batch classifier loss: 0.162271; batch adversarial loss: 0.519175\n",
      "epoch 143; iter: 0; batch classifier loss: 0.152601; batch adversarial loss: 0.494548\n",
      "epoch 144; iter: 0; batch classifier loss: 0.233494; batch adversarial loss: 0.459223\n",
      "epoch 145; iter: 0; batch classifier loss: 0.162603; batch adversarial loss: 0.446756\n",
      "epoch 146; iter: 0; batch classifier loss: 0.227707; batch adversarial loss: 0.409742\n",
      "epoch 147; iter: 0; batch classifier loss: 0.267105; batch adversarial loss: 0.410767\n",
      "epoch 148; iter: 0; batch classifier loss: 0.218018; batch adversarial loss: 0.399499\n",
      "epoch 149; iter: 0; batch classifier loss: 0.240412; batch adversarial loss: 0.459257\n",
      "epoch 150; iter: 0; batch classifier loss: 0.196486; batch adversarial loss: 0.531110\n",
      "epoch 151; iter: 0; batch classifier loss: 0.218715; batch adversarial loss: 0.423136\n",
      "epoch 152; iter: 0; batch classifier loss: 0.161101; batch adversarial loss: 0.483519\n",
      "epoch 153; iter: 0; batch classifier loss: 0.171323; batch adversarial loss: 0.471056\n",
      "epoch 154; iter: 0; batch classifier loss: 0.240637; batch adversarial loss: 0.446401\n",
      "epoch 155; iter: 0; batch classifier loss: 0.173656; batch adversarial loss: 0.506576\n",
      "epoch 156; iter: 0; batch classifier loss: 0.161895; batch adversarial loss: 0.446495\n",
      "epoch 157; iter: 0; batch classifier loss: 0.162803; batch adversarial loss: 0.482704\n",
      "epoch 158; iter: 0; batch classifier loss: 0.145758; batch adversarial loss: 0.545395\n",
      "epoch 159; iter: 0; batch classifier loss: 0.220554; batch adversarial loss: 0.386390\n",
      "epoch 160; iter: 0; batch classifier loss: 0.203641; batch adversarial loss: 0.470463\n",
      "epoch 161; iter: 0; batch classifier loss: 0.240683; batch adversarial loss: 0.471111\n",
      "epoch 162; iter: 0; batch classifier loss: 0.271216; batch adversarial loss: 0.397844\n",
      "epoch 163; iter: 0; batch classifier loss: 0.160835; batch adversarial loss: 0.424754\n",
      "epoch 164; iter: 0; batch classifier loss: 0.189108; batch adversarial loss: 0.470458\n",
      "epoch 165; iter: 0; batch classifier loss: 0.190016; batch adversarial loss: 0.410012\n",
      "epoch 166; iter: 0; batch classifier loss: 0.195842; batch adversarial loss: 0.517417\n",
      "epoch 167; iter: 0; batch classifier loss: 0.164117; batch adversarial loss: 0.507285\n",
      "epoch 168; iter: 0; batch classifier loss: 0.137607; batch adversarial loss: 0.458482\n",
      "epoch 169; iter: 0; batch classifier loss: 0.137026; batch adversarial loss: 0.445827\n",
      "epoch 170; iter: 0; batch classifier loss: 0.149933; batch adversarial loss: 0.432345\n",
      "epoch 171; iter: 0; batch classifier loss: 0.086187; batch adversarial loss: 0.419572\n",
      "epoch 172; iter: 0; batch classifier loss: 0.067021; batch adversarial loss: 0.511943\n",
      "epoch 173; iter: 0; batch classifier loss: 0.046940; batch adversarial loss: 0.465154\n",
      "epoch 174; iter: 0; batch classifier loss: 0.066771; batch adversarial loss: 0.467134\n",
      "epoch 175; iter: 0; batch classifier loss: 0.042452; batch adversarial loss: 0.461389\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034112; batch adversarial loss: 0.449847\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022286; batch adversarial loss: 0.423726\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023121; batch adversarial loss: 0.460735\n",
      "epoch 179; iter: 0; batch classifier loss: 0.061867; batch adversarial loss: 0.457946\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025689; batch adversarial loss: 0.461415\n",
      "epoch 181; iter: 0; batch classifier loss: 0.044700; batch adversarial loss: 0.478097\n",
      "epoch 182; iter: 0; batch classifier loss: 0.058910; batch adversarial loss: 0.578245\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036050; batch adversarial loss: 0.476713\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022105; batch adversarial loss: 0.443482\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018493; batch adversarial loss: 0.396762\n",
      "epoch 186; iter: 0; batch classifier loss: 0.053509; batch adversarial loss: 0.391979\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019530; batch adversarial loss: 0.516329\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030559; batch adversarial loss: 0.375995\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025128; batch adversarial loss: 0.426259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.030673; batch adversarial loss: 0.418841\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031254; batch adversarial loss: 0.456708\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030698; batch adversarial loss: 0.502088\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023703; batch adversarial loss: 0.427731\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036525; batch adversarial loss: 0.479595\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018447; batch adversarial loss: 0.406137\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023439; batch adversarial loss: 0.381988\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014351; batch adversarial loss: 0.408211\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026586; batch adversarial loss: 0.423492\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032221; batch adversarial loss: 0.377542\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718969; batch adversarial loss: 0.612447\n",
      "epoch 1; iter: 0; batch classifier loss: 0.452572; batch adversarial loss: 0.635892\n",
      "epoch 2; iter: 0; batch classifier loss: 0.353779; batch adversarial loss: 0.619005\n",
      "epoch 3; iter: 0; batch classifier loss: 0.257500; batch adversarial loss: 0.569719\n",
      "epoch 4; iter: 0; batch classifier loss: 0.272622; batch adversarial loss: 0.565315\n",
      "epoch 5; iter: 0; batch classifier loss: 0.275101; batch adversarial loss: 0.516624\n",
      "epoch 6; iter: 0; batch classifier loss: 0.276180; batch adversarial loss: 0.540588\n",
      "epoch 7; iter: 0; batch classifier loss: 0.283078; batch adversarial loss: 0.529182\n",
      "epoch 8; iter: 0; batch classifier loss: 0.335384; batch adversarial loss: 0.475736\n",
      "epoch 9; iter: 0; batch classifier loss: 0.226155; batch adversarial loss: 0.483718\n",
      "epoch 10; iter: 0; batch classifier loss: 0.243575; batch adversarial loss: 0.506520\n",
      "epoch 11; iter: 0; batch classifier loss: 0.199932; batch adversarial loss: 0.490525\n",
      "epoch 12; iter: 0; batch classifier loss: 0.291790; batch adversarial loss: 0.508821\n",
      "epoch 13; iter: 0; batch classifier loss: 0.207982; batch adversarial loss: 0.459989\n",
      "epoch 14; iter: 0; batch classifier loss: 0.168777; batch adversarial loss: 0.458992\n",
      "epoch 15; iter: 0; batch classifier loss: 0.171196; batch adversarial loss: 0.491532\n",
      "epoch 16; iter: 0; batch classifier loss: 0.273582; batch adversarial loss: 0.559671\n",
      "epoch 17; iter: 0; batch classifier loss: 0.257747; batch adversarial loss: 0.500338\n",
      "epoch 18; iter: 0; batch classifier loss: 0.242355; batch adversarial loss: 0.472215\n",
      "epoch 19; iter: 0; batch classifier loss: 0.276151; batch adversarial loss: 0.540789\n",
      "epoch 20; iter: 0; batch classifier loss: 0.273042; batch adversarial loss: 0.520105\n",
      "epoch 21; iter: 0; batch classifier loss: 0.229380; batch adversarial loss: 0.478361\n",
      "epoch 22; iter: 0; batch classifier loss: 0.377290; batch adversarial loss: 0.601489\n",
      "epoch 23; iter: 0; batch classifier loss: 0.313264; batch adversarial loss: 0.500791\n",
      "epoch 24; iter: 0; batch classifier loss: 0.421684; batch adversarial loss: 0.452337\n",
      "epoch 25; iter: 0; batch classifier loss: 0.321055; batch adversarial loss: 0.474756\n",
      "epoch 26; iter: 0; batch classifier loss: 0.245894; batch adversarial loss: 0.447054\n",
      "epoch 27; iter: 0; batch classifier loss: 0.172666; batch adversarial loss: 0.511580\n",
      "epoch 28; iter: 0; batch classifier loss: 0.159275; batch adversarial loss: 0.444112\n",
      "epoch 29; iter: 0; batch classifier loss: 0.152517; batch adversarial loss: 0.410673\n",
      "epoch 30; iter: 0; batch classifier loss: 0.152249; batch adversarial loss: 0.440167\n",
      "epoch 31; iter: 0; batch classifier loss: 0.110029; batch adversarial loss: 0.390781\n",
      "epoch 32; iter: 0; batch classifier loss: 0.105043; batch adversarial loss: 0.423067\n",
      "epoch 33; iter: 0; batch classifier loss: 0.073935; batch adversarial loss: 0.486803\n",
      "epoch 34; iter: 0; batch classifier loss: 0.110178; batch adversarial loss: 0.378473\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160623; batch adversarial loss: 0.478636\n",
      "epoch 36; iter: 0; batch classifier loss: 0.111785; batch adversarial loss: 0.424204\n",
      "epoch 37; iter: 0; batch classifier loss: 0.078526; batch adversarial loss: 0.438410\n",
      "epoch 38; iter: 0; batch classifier loss: 0.071290; batch adversarial loss: 0.470430\n",
      "epoch 39; iter: 0; batch classifier loss: 0.141288; batch adversarial loss: 0.394955\n",
      "epoch 40; iter: 0; batch classifier loss: 0.106526; batch adversarial loss: 0.507389\n",
      "epoch 41; iter: 0; batch classifier loss: 0.086590; batch adversarial loss: 0.529132\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105946; batch adversarial loss: 0.424416\n",
      "epoch 43; iter: 0; batch classifier loss: 0.081928; batch adversarial loss: 0.407851\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085025; batch adversarial loss: 0.339962\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099228; batch adversarial loss: 0.435436\n",
      "epoch 46; iter: 0; batch classifier loss: 0.077070; batch adversarial loss: 0.429772\n",
      "epoch 47; iter: 0; batch classifier loss: 0.148207; batch adversarial loss: 0.432223\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082471; batch adversarial loss: 0.486118\n",
      "epoch 49; iter: 0; batch classifier loss: 0.090592; batch adversarial loss: 0.407193\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108832; batch adversarial loss: 0.426380\n",
      "epoch 51; iter: 0; batch classifier loss: 0.074849; batch adversarial loss: 0.446951\n",
      "epoch 52; iter: 0; batch classifier loss: 0.072146; batch adversarial loss: 0.511976\n",
      "epoch 53; iter: 0; batch classifier loss: 0.132215; batch adversarial loss: 0.536792\n",
      "epoch 54; iter: 0; batch classifier loss: 0.088266; batch adversarial loss: 0.463264\n",
      "epoch 55; iter: 0; batch classifier loss: 0.109874; batch adversarial loss: 0.389109\n",
      "epoch 56; iter: 0; batch classifier loss: 0.071206; batch adversarial loss: 0.389043\n",
      "epoch 57; iter: 0; batch classifier loss: 0.069497; batch adversarial loss: 0.397807\n",
      "epoch 58; iter: 0; batch classifier loss: 0.059677; batch adversarial loss: 0.474129\n",
      "epoch 59; iter: 0; batch classifier loss: 0.108170; batch adversarial loss: 0.425555\n",
      "epoch 60; iter: 0; batch classifier loss: 0.104705; batch adversarial loss: 0.408896\n",
      "epoch 61; iter: 0; batch classifier loss: 0.039612; batch adversarial loss: 0.397792\n",
      "epoch 62; iter: 0; batch classifier loss: 0.058652; batch adversarial loss: 0.510301\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093805; batch adversarial loss: 0.391900\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082472; batch adversarial loss: 0.467154\n",
      "epoch 65; iter: 0; batch classifier loss: 0.109275; batch adversarial loss: 0.433533\n",
      "epoch 66; iter: 0; batch classifier loss: 0.070371; batch adversarial loss: 0.497935\n",
      "epoch 67; iter: 0; batch classifier loss: 0.087970; batch adversarial loss: 0.436663\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060620; batch adversarial loss: 0.391179\n",
      "epoch 69; iter: 0; batch classifier loss: 0.084904; batch adversarial loss: 0.475750\n",
      "epoch 70; iter: 0; batch classifier loss: 0.060696; batch adversarial loss: 0.547133\n",
      "epoch 71; iter: 0; batch classifier loss: 0.072018; batch adversarial loss: 0.433603\n",
      "epoch 72; iter: 0; batch classifier loss: 0.118317; batch adversarial loss: 0.467713\n",
      "epoch 73; iter: 0; batch classifier loss: 0.071316; batch adversarial loss: 0.400050\n",
      "epoch 74; iter: 0; batch classifier loss: 0.086015; batch adversarial loss: 0.538739\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096715; batch adversarial loss: 0.411983\n",
      "epoch 76; iter: 0; batch classifier loss: 0.066930; batch adversarial loss: 0.446822\n",
      "epoch 77; iter: 0; batch classifier loss: 0.078486; batch adversarial loss: 0.481865\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079878; batch adversarial loss: 0.570599\n",
      "epoch 79; iter: 0; batch classifier loss: 0.107063; batch adversarial loss: 0.495581\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084330; batch adversarial loss: 0.488407\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071039; batch adversarial loss: 0.305696\n",
      "epoch 82; iter: 0; batch classifier loss: 0.061365; batch adversarial loss: 0.409690\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065641; batch adversarial loss: 0.489736\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046939; batch adversarial loss: 0.465018\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055670; batch adversarial loss: 0.460252\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064220; batch adversarial loss: 0.390364\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062021; batch adversarial loss: 0.469517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.095148; batch adversarial loss: 0.415830\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075673; batch adversarial loss: 0.452922\n",
      "epoch 90; iter: 0; batch classifier loss: 0.094828; batch adversarial loss: 0.488223\n",
      "epoch 91; iter: 0; batch classifier loss: 0.065731; batch adversarial loss: 0.558985\n",
      "epoch 92; iter: 0; batch classifier loss: 0.106014; batch adversarial loss: 0.350310\n",
      "epoch 93; iter: 0; batch classifier loss: 0.090915; batch adversarial loss: 0.409313\n",
      "epoch 94; iter: 0; batch classifier loss: 0.036902; batch adversarial loss: 0.442413\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051275; batch adversarial loss: 0.551052\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062616; batch adversarial loss: 0.529641\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066051; batch adversarial loss: 0.501609\n",
      "epoch 98; iter: 0; batch classifier loss: 0.089411; batch adversarial loss: 0.418664\n",
      "epoch 99; iter: 0; batch classifier loss: 0.060148; batch adversarial loss: 0.494658\n",
      "epoch 100; iter: 0; batch classifier loss: 0.109867; batch adversarial loss: 0.434548\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049634; batch adversarial loss: 0.494160\n",
      "epoch 102; iter: 0; batch classifier loss: 0.088302; batch adversarial loss: 0.516711\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046931; batch adversarial loss: 0.492726\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038728; batch adversarial loss: 0.484985\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044904; batch adversarial loss: 0.472854\n",
      "epoch 106; iter: 0; batch classifier loss: 0.113835; batch adversarial loss: 0.476491\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031832; batch adversarial loss: 0.502788\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037171; batch adversarial loss: 0.507898\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050259; batch adversarial loss: 0.426673\n",
      "epoch 110; iter: 0; batch classifier loss: 0.032046; batch adversarial loss: 0.387834\n",
      "epoch 111; iter: 0; batch classifier loss: 0.075191; batch adversarial loss: 0.444799\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045059; batch adversarial loss: 0.392486\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054776; batch adversarial loss: 0.507368\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029032; batch adversarial loss: 0.511980\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043839; batch adversarial loss: 0.457301\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055327; batch adversarial loss: 0.463642\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039144; batch adversarial loss: 0.423383\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039648; batch adversarial loss: 0.424830\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038572; batch adversarial loss: 0.400969\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044206; batch adversarial loss: 0.368051\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032594; batch adversarial loss: 0.359407\n",
      "epoch 122; iter: 0; batch classifier loss: 0.054640; batch adversarial loss: 0.462203\n",
      "epoch 123; iter: 0; batch classifier loss: 0.020444; batch adversarial loss: 0.517560\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030567; batch adversarial loss: 0.422028\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035124; batch adversarial loss: 0.423045\n",
      "epoch 126; iter: 0; batch classifier loss: 0.054807; batch adversarial loss: 0.420856\n",
      "epoch 127; iter: 0; batch classifier loss: 0.041875; batch adversarial loss: 0.382624\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043106; batch adversarial loss: 0.411924\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031516; batch adversarial loss: 0.492695\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045023; batch adversarial loss: 0.438984\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036470; batch adversarial loss: 0.495057\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038768; batch adversarial loss: 0.312827\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046192; batch adversarial loss: 0.452173\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048805; batch adversarial loss: 0.472706\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028826; batch adversarial loss: 0.413531\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043981; batch adversarial loss: 0.418782\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041166; batch adversarial loss: 0.530518\n",
      "epoch 138; iter: 0; batch classifier loss: 0.009848; batch adversarial loss: 0.485731\n",
      "epoch 139; iter: 0; batch classifier loss: 0.051690; batch adversarial loss: 0.422560\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017579; batch adversarial loss: 0.519840\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046927; batch adversarial loss: 0.399683\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013481; batch adversarial loss: 0.420947\n",
      "epoch 143; iter: 0; batch classifier loss: 0.061851; batch adversarial loss: 0.362896\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019137; batch adversarial loss: 0.415168\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022718; batch adversarial loss: 0.497466\n",
      "epoch 146; iter: 0; batch classifier loss: 0.011767; batch adversarial loss: 0.472452\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033768; batch adversarial loss: 0.495459\n",
      "epoch 148; iter: 0; batch classifier loss: 0.058440; batch adversarial loss: 0.448185\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018604; batch adversarial loss: 0.459952\n",
      "epoch 150; iter: 0; batch classifier loss: 0.009979; batch adversarial loss: 0.578180\n",
      "epoch 151; iter: 0; batch classifier loss: 0.046094; batch adversarial loss: 0.512484\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029915; batch adversarial loss: 0.452196\n",
      "epoch 153; iter: 0; batch classifier loss: 0.037462; batch adversarial loss: 0.455123\n",
      "epoch 154; iter: 0; batch classifier loss: 0.053475; batch adversarial loss: 0.411191\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020477; batch adversarial loss: 0.470110\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016626; batch adversarial loss: 0.482829\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042171; batch adversarial loss: 0.478280\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033999; batch adversarial loss: 0.485166\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016609; batch adversarial loss: 0.482108\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033356; batch adversarial loss: 0.327630\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042163; batch adversarial loss: 0.443791\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018579; batch adversarial loss: 0.493495\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027537; batch adversarial loss: 0.510201\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037966; batch adversarial loss: 0.511944\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024061; batch adversarial loss: 0.394076\n",
      "epoch 166; iter: 0; batch classifier loss: 0.042763; batch adversarial loss: 0.350516\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011484; batch adversarial loss: 0.429049\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024918; batch adversarial loss: 0.434416\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013909; batch adversarial loss: 0.457426\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023441; batch adversarial loss: 0.411644\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020379; batch adversarial loss: 0.478074\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015518; batch adversarial loss: 0.361218\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014999; batch adversarial loss: 0.428604\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038027; batch adversarial loss: 0.486538\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013618; batch adversarial loss: 0.438547\n",
      "epoch 176; iter: 0; batch classifier loss: 0.005429; batch adversarial loss: 0.445449\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011338; batch adversarial loss: 0.465813\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020002; batch adversarial loss: 0.503741\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016231; batch adversarial loss: 0.373359\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016710; batch adversarial loss: 0.399535\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030716; batch adversarial loss: 0.519233\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010308; batch adversarial loss: 0.491964\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006503; batch adversarial loss: 0.481489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.024242; batch adversarial loss: 0.529709\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015805; batch adversarial loss: 0.422064\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027933; batch adversarial loss: 0.538922\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010678; batch adversarial loss: 0.321617\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013471; batch adversarial loss: 0.475718\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019567; batch adversarial loss: 0.486147\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013134; batch adversarial loss: 0.514765\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007717; batch adversarial loss: 0.410917\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025941; batch adversarial loss: 0.423935\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023649; batch adversarial loss: 0.543700\n",
      "epoch 194; iter: 0; batch classifier loss: 0.029411; batch adversarial loss: 0.498240\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023730; batch adversarial loss: 0.544251\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027211; batch adversarial loss: 0.511467\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009606; batch adversarial loss: 0.396405\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013322; batch adversarial loss: 0.408022\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030088; batch adversarial loss: 0.505614\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705821; batch adversarial loss: 0.700123\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583629; batch adversarial loss: 0.649567\n",
      "epoch 2; iter: 0; batch classifier loss: 0.445506; batch adversarial loss: 0.604138\n",
      "epoch 3; iter: 0; batch classifier loss: 0.405280; batch adversarial loss: 0.592091\n",
      "epoch 4; iter: 0; batch classifier loss: 0.330624; batch adversarial loss: 0.548922\n",
      "epoch 5; iter: 0; batch classifier loss: 0.297860; batch adversarial loss: 0.597935\n",
      "epoch 6; iter: 0; batch classifier loss: 0.400362; batch adversarial loss: 0.577879\n",
      "epoch 7; iter: 0; batch classifier loss: 0.315357; batch adversarial loss: 0.560398\n",
      "epoch 8; iter: 0; batch classifier loss: 0.322868; batch adversarial loss: 0.504709\n",
      "epoch 9; iter: 0; batch classifier loss: 0.269309; batch adversarial loss: 0.518593\n",
      "epoch 10; iter: 0; batch classifier loss: 0.332307; batch adversarial loss: 0.519887\n",
      "epoch 11; iter: 0; batch classifier loss: 0.210891; batch adversarial loss: 0.543272\n",
      "epoch 12; iter: 0; batch classifier loss: 0.233831; batch adversarial loss: 0.532376\n",
      "epoch 13; iter: 0; batch classifier loss: 0.252648; batch adversarial loss: 0.485798\n",
      "epoch 14; iter: 0; batch classifier loss: 0.209460; batch adversarial loss: 0.510199\n",
      "epoch 15; iter: 0; batch classifier loss: 0.157316; batch adversarial loss: 0.489118\n",
      "epoch 16; iter: 0; batch classifier loss: 0.206906; batch adversarial loss: 0.499998\n",
      "epoch 17; iter: 0; batch classifier loss: 0.202153; batch adversarial loss: 0.500172\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197223; batch adversarial loss: 0.444961\n",
      "epoch 19; iter: 0; batch classifier loss: 0.192300; batch adversarial loss: 0.468826\n",
      "epoch 20; iter: 0; batch classifier loss: 0.218103; batch adversarial loss: 0.515417\n",
      "epoch 21; iter: 0; batch classifier loss: 0.215571; batch adversarial loss: 0.490200\n",
      "epoch 22; iter: 0; batch classifier loss: 0.151698; batch adversarial loss: 0.427709\n",
      "epoch 23; iter: 0; batch classifier loss: 0.157157; batch adversarial loss: 0.491215\n",
      "epoch 24; iter: 0; batch classifier loss: 0.154190; batch adversarial loss: 0.438092\n",
      "epoch 25; iter: 0; batch classifier loss: 0.143104; batch adversarial loss: 0.496279\n",
      "epoch 26; iter: 0; batch classifier loss: 0.116170; batch adversarial loss: 0.514271\n",
      "epoch 27; iter: 0; batch classifier loss: 0.177072; batch adversarial loss: 0.468876\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173780; batch adversarial loss: 0.420284\n",
      "epoch 29; iter: 0; batch classifier loss: 0.138163; batch adversarial loss: 0.453432\n",
      "epoch 30; iter: 0; batch classifier loss: 0.140047; batch adversarial loss: 0.433714\n",
      "epoch 31; iter: 0; batch classifier loss: 0.141157; batch adversarial loss: 0.429059\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126345; batch adversarial loss: 0.436040\n",
      "epoch 33; iter: 0; batch classifier loss: 0.148038; batch adversarial loss: 0.405065\n",
      "epoch 34; iter: 0; batch classifier loss: 0.128835; batch adversarial loss: 0.366434\n",
      "epoch 35; iter: 0; batch classifier loss: 0.124239; batch adversarial loss: 0.549707\n",
      "epoch 36; iter: 0; batch classifier loss: 0.135156; batch adversarial loss: 0.432542\n",
      "epoch 37; iter: 0; batch classifier loss: 0.146699; batch adversarial loss: 0.404595\n",
      "epoch 38; iter: 0; batch classifier loss: 0.146242; batch adversarial loss: 0.529167\n",
      "epoch 39; iter: 0; batch classifier loss: 0.115210; batch adversarial loss: 0.474976\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124203; batch adversarial loss: 0.438417\n",
      "epoch 41; iter: 0; batch classifier loss: 0.108696; batch adversarial loss: 0.354477\n",
      "epoch 42; iter: 0; batch classifier loss: 0.150600; batch adversarial loss: 0.409047\n",
      "epoch 43; iter: 0; batch classifier loss: 0.130027; batch adversarial loss: 0.444777\n",
      "epoch 44; iter: 0; batch classifier loss: 0.090166; batch adversarial loss: 0.537761\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108101; batch adversarial loss: 0.464844\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116522; batch adversarial loss: 0.452261\n",
      "epoch 47; iter: 0; batch classifier loss: 0.110037; batch adversarial loss: 0.371181\n",
      "epoch 48; iter: 0; batch classifier loss: 0.128800; batch adversarial loss: 0.433500\n",
      "epoch 49; iter: 0; batch classifier loss: 0.093812; batch adversarial loss: 0.379888\n",
      "epoch 50; iter: 0; batch classifier loss: 0.089671; batch adversarial loss: 0.448723\n",
      "epoch 51; iter: 0; batch classifier loss: 0.123010; batch adversarial loss: 0.403719\n",
      "epoch 52; iter: 0; batch classifier loss: 0.087361; batch adversarial loss: 0.583804\n",
      "epoch 53; iter: 0; batch classifier loss: 0.065663; batch adversarial loss: 0.421800\n",
      "epoch 54; iter: 0; batch classifier loss: 0.109716; batch adversarial loss: 0.482445\n",
      "epoch 55; iter: 0; batch classifier loss: 0.126941; batch adversarial loss: 0.487727\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065579; batch adversarial loss: 0.499682\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095328; batch adversarial loss: 0.513121\n",
      "epoch 58; iter: 0; batch classifier loss: 0.159344; batch adversarial loss: 0.396580\n",
      "epoch 59; iter: 0; batch classifier loss: 0.094617; batch adversarial loss: 0.503655\n",
      "epoch 60; iter: 0; batch classifier loss: 0.124057; batch adversarial loss: 0.430641\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113798; batch adversarial loss: 0.461771\n",
      "epoch 62; iter: 0; batch classifier loss: 0.107153; batch adversarial loss: 0.355399\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103224; batch adversarial loss: 0.474076\n",
      "epoch 64; iter: 0; batch classifier loss: 0.088532; batch adversarial loss: 0.443455\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082381; batch adversarial loss: 0.465761\n",
      "epoch 66; iter: 0; batch classifier loss: 0.112639; batch adversarial loss: 0.471262\n",
      "epoch 67; iter: 0; batch classifier loss: 0.174499; batch adversarial loss: 0.423899\n",
      "epoch 68; iter: 0; batch classifier loss: 0.101221; batch adversarial loss: 0.425086\n",
      "epoch 69; iter: 0; batch classifier loss: 0.096133; batch adversarial loss: 0.431013\n",
      "epoch 70; iter: 0; batch classifier loss: 0.118789; batch adversarial loss: 0.452441\n",
      "epoch 71; iter: 0; batch classifier loss: 0.106562; batch adversarial loss: 0.406490\n",
      "epoch 72; iter: 0; batch classifier loss: 0.057034; batch adversarial loss: 0.451252\n",
      "epoch 73; iter: 0; batch classifier loss: 0.137587; batch adversarial loss: 0.483687\n",
      "epoch 74; iter: 0; batch classifier loss: 0.041550; batch adversarial loss: 0.479086\n",
      "epoch 75; iter: 0; batch classifier loss: 0.041837; batch adversarial loss: 0.405776\n",
      "epoch 76; iter: 0; batch classifier loss: 0.106775; batch adversarial loss: 0.457717\n",
      "epoch 77; iter: 0; batch classifier loss: 0.131382; batch adversarial loss: 0.479419\n",
      "epoch 78; iter: 0; batch classifier loss: 0.124232; batch adversarial loss: 0.444344\n",
      "epoch 79; iter: 0; batch classifier loss: 0.091355; batch adversarial loss: 0.463694\n",
      "epoch 80; iter: 0; batch classifier loss: 0.102336; batch adversarial loss: 0.341521\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071572; batch adversarial loss: 0.470547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.073716; batch adversarial loss: 0.421142\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079744; batch adversarial loss: 0.438805\n",
      "epoch 84; iter: 0; batch classifier loss: 0.088056; batch adversarial loss: 0.405999\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051487; batch adversarial loss: 0.403052\n",
      "epoch 86; iter: 0; batch classifier loss: 0.136155; batch adversarial loss: 0.518330\n",
      "epoch 87; iter: 0; batch classifier loss: 0.116800; batch adversarial loss: 0.440829\n",
      "epoch 88; iter: 0; batch classifier loss: 0.112417; batch adversarial loss: 0.367722\n",
      "epoch 89; iter: 0; batch classifier loss: 0.118974; batch adversarial loss: 0.466602\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052205; batch adversarial loss: 0.427773\n",
      "epoch 91; iter: 0; batch classifier loss: 0.071492; batch adversarial loss: 0.423782\n",
      "epoch 92; iter: 0; batch classifier loss: 0.094235; batch adversarial loss: 0.527415\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050318; batch adversarial loss: 0.558167\n",
      "epoch 94; iter: 0; batch classifier loss: 0.055271; batch adversarial loss: 0.444469\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051885; batch adversarial loss: 0.431521\n",
      "epoch 96; iter: 0; batch classifier loss: 0.054352; batch adversarial loss: 0.417366\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081699; batch adversarial loss: 0.427297\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053222; batch adversarial loss: 0.450352\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043776; batch adversarial loss: 0.504602\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048638; batch adversarial loss: 0.482016\n",
      "epoch 101; iter: 0; batch classifier loss: 0.090688; batch adversarial loss: 0.501757\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050987; batch adversarial loss: 0.532817\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054141; batch adversarial loss: 0.445739\n",
      "epoch 104; iter: 0; batch classifier loss: 0.085258; batch adversarial loss: 0.382955\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053409; batch adversarial loss: 0.606188\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062967; batch adversarial loss: 0.380760\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051817; batch adversarial loss: 0.383094\n",
      "epoch 108; iter: 0; batch classifier loss: 0.085528; batch adversarial loss: 0.435995\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026924; batch adversarial loss: 0.526560\n",
      "epoch 110; iter: 0; batch classifier loss: 0.055691; batch adversarial loss: 0.409634\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049902; batch adversarial loss: 0.427423\n",
      "epoch 112; iter: 0; batch classifier loss: 0.018401; batch adversarial loss: 0.412870\n",
      "epoch 113; iter: 0; batch classifier loss: 0.084255; batch adversarial loss: 0.458825\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047579; batch adversarial loss: 0.507206\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054836; batch adversarial loss: 0.489772\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060163; batch adversarial loss: 0.460178\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026450; batch adversarial loss: 0.517735\n",
      "epoch 118; iter: 0; batch classifier loss: 0.017758; batch adversarial loss: 0.343848\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043931; batch adversarial loss: 0.458094\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042882; batch adversarial loss: 0.411562\n",
      "epoch 121; iter: 0; batch classifier loss: 0.069204; batch adversarial loss: 0.416193\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067908; batch adversarial loss: 0.476006\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034134; batch adversarial loss: 0.446927\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048690; batch adversarial loss: 0.387699\n",
      "epoch 125; iter: 0; batch classifier loss: 0.071345; batch adversarial loss: 0.450532\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030115; batch adversarial loss: 0.398228\n",
      "epoch 127; iter: 0; batch classifier loss: 0.016019; batch adversarial loss: 0.521974\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019617; batch adversarial loss: 0.458374\n",
      "epoch 129; iter: 0; batch classifier loss: 0.055863; batch adversarial loss: 0.377250\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038145; batch adversarial loss: 0.452112\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028034; batch adversarial loss: 0.362535\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027469; batch adversarial loss: 0.512600\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043070; batch adversarial loss: 0.453949\n",
      "epoch 134; iter: 0; batch classifier loss: 0.012862; batch adversarial loss: 0.419648\n",
      "epoch 135; iter: 0; batch classifier loss: 0.010149; batch adversarial loss: 0.495435\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023509; batch adversarial loss: 0.509436\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024377; batch adversarial loss: 0.536489\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028112; batch adversarial loss: 0.518013\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032062; batch adversarial loss: 0.550352\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038524; batch adversarial loss: 0.430647\n",
      "epoch 141; iter: 0; batch classifier loss: 0.050832; batch adversarial loss: 0.449339\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049741; batch adversarial loss: 0.412391\n",
      "epoch 143; iter: 0; batch classifier loss: 0.017656; batch adversarial loss: 0.486106\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030597; batch adversarial loss: 0.453193\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042866; batch adversarial loss: 0.282204\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026344; batch adversarial loss: 0.491159\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036186; batch adversarial loss: 0.465029\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017941; batch adversarial loss: 0.457121\n",
      "epoch 149; iter: 0; batch classifier loss: 0.061745; batch adversarial loss: 0.451950\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015525; batch adversarial loss: 0.497313\n",
      "epoch 151; iter: 0; batch classifier loss: 0.010466; batch adversarial loss: 0.469956\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039931; batch adversarial loss: 0.432873\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036423; batch adversarial loss: 0.512802\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028166; batch adversarial loss: 0.488147\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021337; batch adversarial loss: 0.433982\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022609; batch adversarial loss: 0.547337\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019601; batch adversarial loss: 0.398135\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016508; batch adversarial loss: 0.470648\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021192; batch adversarial loss: 0.451326\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015354; batch adversarial loss: 0.449325\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009129; batch adversarial loss: 0.393875\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026446; batch adversarial loss: 0.507921\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038747; batch adversarial loss: 0.383027\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021516; batch adversarial loss: 0.503763\n",
      "epoch 165; iter: 0; batch classifier loss: 0.076451; batch adversarial loss: 0.469147\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032659; batch adversarial loss: 0.485856\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014840; batch adversarial loss: 0.470867\n",
      "epoch 168; iter: 0; batch classifier loss: 0.050427; batch adversarial loss: 0.485626\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014220; batch adversarial loss: 0.460786\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024657; batch adversarial loss: 0.459126\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029038; batch adversarial loss: 0.428259\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012906; batch adversarial loss: 0.513973\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038454; batch adversarial loss: 0.442445\n",
      "epoch 174; iter: 0; batch classifier loss: 0.005986; batch adversarial loss: 0.522724\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012017; batch adversarial loss: 0.462171\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029034; batch adversarial loss: 0.453492\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033758; batch adversarial loss: 0.492020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.033001; batch adversarial loss: 0.383473\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008122; batch adversarial loss: 0.573468\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040814; batch adversarial loss: 0.496597\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011209; batch adversarial loss: 0.461617\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034656; batch adversarial loss: 0.424309\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015758; batch adversarial loss: 0.404266\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010699; batch adversarial loss: 0.603471\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021129; batch adversarial loss: 0.411933\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009915; batch adversarial loss: 0.508180\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015905; batch adversarial loss: 0.475286\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014993; batch adversarial loss: 0.549210\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017447; batch adversarial loss: 0.455392\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008291; batch adversarial loss: 0.414969\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010702; batch adversarial loss: 0.454945\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018052; batch adversarial loss: 0.450265\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014935; batch adversarial loss: 0.450206\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023942; batch adversarial loss: 0.480876\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016500; batch adversarial loss: 0.471527\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029333; batch adversarial loss: 0.531062\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019726; batch adversarial loss: 0.433384\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032436; batch adversarial loss: 0.447497\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024917; batch adversarial loss: 0.418267\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676901; batch adversarial loss: 0.878131\n",
      "epoch 1; iter: 0; batch classifier loss: 0.411604; batch adversarial loss: 0.925362\n",
      "epoch 2; iter: 0; batch classifier loss: 0.325158; batch adversarial loss: 0.910694\n",
      "epoch 3; iter: 0; batch classifier loss: 0.452724; batch adversarial loss: 0.825398\n",
      "epoch 4; iter: 0; batch classifier loss: 0.405140; batch adversarial loss: 0.763495\n",
      "epoch 5; iter: 0; batch classifier loss: 0.286950; batch adversarial loss: 0.667291\n",
      "epoch 6; iter: 0; batch classifier loss: 0.324706; batch adversarial loss: 0.659039\n",
      "epoch 7; iter: 0; batch classifier loss: 0.292157; batch adversarial loss: 0.620794\n",
      "epoch 8; iter: 0; batch classifier loss: 0.269153; batch adversarial loss: 0.580839\n",
      "epoch 9; iter: 0; batch classifier loss: 0.315240; batch adversarial loss: 0.571025\n",
      "epoch 10; iter: 0; batch classifier loss: 0.306843; batch adversarial loss: 0.557545\n",
      "epoch 11; iter: 0; batch classifier loss: 0.303767; batch adversarial loss: 0.558212\n",
      "epoch 12; iter: 0; batch classifier loss: 0.304267; batch adversarial loss: 0.551727\n",
      "epoch 13; iter: 0; batch classifier loss: 0.212731; batch adversarial loss: 0.533717\n",
      "epoch 14; iter: 0; batch classifier loss: 0.229764; batch adversarial loss: 0.499901\n",
      "epoch 15; iter: 0; batch classifier loss: 0.217561; batch adversarial loss: 0.491607\n",
      "epoch 16; iter: 0; batch classifier loss: 0.201475; batch adversarial loss: 0.501107\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221620; batch adversarial loss: 0.471341\n",
      "epoch 18; iter: 0; batch classifier loss: 0.195712; batch adversarial loss: 0.495650\n",
      "epoch 19; iter: 0; batch classifier loss: 0.193144; batch adversarial loss: 0.471785\n",
      "epoch 20; iter: 0; batch classifier loss: 0.261451; batch adversarial loss: 0.441978\n",
      "epoch 21; iter: 0; batch classifier loss: 0.210567; batch adversarial loss: 0.482723\n",
      "epoch 22; iter: 0; batch classifier loss: 0.138428; batch adversarial loss: 0.459349\n",
      "epoch 23; iter: 0; batch classifier loss: 0.170039; batch adversarial loss: 0.408358\n",
      "epoch 24; iter: 0; batch classifier loss: 0.188617; batch adversarial loss: 0.415092\n",
      "epoch 25; iter: 0; batch classifier loss: 0.191369; batch adversarial loss: 0.403965\n",
      "epoch 26; iter: 0; batch classifier loss: 0.129844; batch adversarial loss: 0.365609\n",
      "epoch 27; iter: 0; batch classifier loss: 0.144917; batch adversarial loss: 0.415341\n",
      "epoch 28; iter: 0; batch classifier loss: 0.107584; batch adversarial loss: 0.418380\n",
      "epoch 29; iter: 0; batch classifier loss: 0.124319; batch adversarial loss: 0.510016\n",
      "epoch 30; iter: 0; batch classifier loss: 0.181133; batch adversarial loss: 0.477167\n",
      "epoch 31; iter: 0; batch classifier loss: 0.136632; batch adversarial loss: 0.459230\n",
      "epoch 32; iter: 0; batch classifier loss: 0.121071; batch adversarial loss: 0.453516\n",
      "epoch 33; iter: 0; batch classifier loss: 0.088089; batch adversarial loss: 0.427003\n",
      "epoch 34; iter: 0; batch classifier loss: 0.103123; batch adversarial loss: 0.434543\n",
      "epoch 35; iter: 0; batch classifier loss: 0.119412; batch adversarial loss: 0.359647\n",
      "epoch 36; iter: 0; batch classifier loss: 0.073441; batch adversarial loss: 0.444652\n",
      "epoch 37; iter: 0; batch classifier loss: 0.178270; batch adversarial loss: 0.450131\n",
      "epoch 38; iter: 0; batch classifier loss: 0.073034; batch adversarial loss: 0.440227\n",
      "epoch 39; iter: 0; batch classifier loss: 0.090629; batch adversarial loss: 0.484364\n",
      "epoch 40; iter: 0; batch classifier loss: 0.131622; batch adversarial loss: 0.388392\n",
      "epoch 41; iter: 0; batch classifier loss: 0.116287; batch adversarial loss: 0.501565\n",
      "epoch 42; iter: 0; batch classifier loss: 0.073013; batch adversarial loss: 0.430312\n",
      "epoch 43; iter: 0; batch classifier loss: 0.130613; batch adversarial loss: 0.433950\n",
      "epoch 44; iter: 0; batch classifier loss: 0.081149; batch adversarial loss: 0.376511\n",
      "epoch 45; iter: 0; batch classifier loss: 0.056880; batch adversarial loss: 0.546882\n",
      "epoch 46; iter: 0; batch classifier loss: 0.101491; batch adversarial loss: 0.504068\n",
      "epoch 47; iter: 0; batch classifier loss: 0.089316; batch adversarial loss: 0.398772\n",
      "epoch 48; iter: 0; batch classifier loss: 0.135865; batch adversarial loss: 0.420607\n",
      "epoch 49; iter: 0; batch classifier loss: 0.170141; batch adversarial loss: 0.372834\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091730; batch adversarial loss: 0.403077\n",
      "epoch 51; iter: 0; batch classifier loss: 0.074762; batch adversarial loss: 0.404947\n",
      "epoch 52; iter: 0; batch classifier loss: 0.060295; batch adversarial loss: 0.501077\n",
      "epoch 53; iter: 0; batch classifier loss: 0.056853; batch adversarial loss: 0.366667\n",
      "epoch 54; iter: 0; batch classifier loss: 0.136014; batch adversarial loss: 0.502969\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079998; batch adversarial loss: 0.384040\n",
      "epoch 56; iter: 0; batch classifier loss: 0.069662; batch adversarial loss: 0.452343\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073849; batch adversarial loss: 0.447787\n",
      "epoch 58; iter: 0; batch classifier loss: 0.075363; batch adversarial loss: 0.394514\n",
      "epoch 59; iter: 0; batch classifier loss: 0.097652; batch adversarial loss: 0.374945\n",
      "epoch 60; iter: 0; batch classifier loss: 0.069845; batch adversarial loss: 0.299139\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071967; batch adversarial loss: 0.397526\n",
      "epoch 62; iter: 0; batch classifier loss: 0.059408; batch adversarial loss: 0.485962\n",
      "epoch 63; iter: 0; batch classifier loss: 0.074865; batch adversarial loss: 0.330875\n",
      "epoch 64; iter: 0; batch classifier loss: 0.055538; batch adversarial loss: 0.387293\n",
      "epoch 65; iter: 0; batch classifier loss: 0.069852; batch adversarial loss: 0.392180\n",
      "epoch 66; iter: 0; batch classifier loss: 0.026607; batch adversarial loss: 0.384893\n",
      "epoch 67; iter: 0; batch classifier loss: 0.071436; batch adversarial loss: 0.516741\n",
      "epoch 68; iter: 0; batch classifier loss: 0.051965; batch adversarial loss: 0.476148\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073788; batch adversarial loss: 0.438726\n",
      "epoch 70; iter: 0; batch classifier loss: 0.069190; batch adversarial loss: 0.413928\n",
      "epoch 71; iter: 0; batch classifier loss: 0.055434; batch adversarial loss: 0.497603\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062488; batch adversarial loss: 0.451882\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077064; batch adversarial loss: 0.494875\n",
      "epoch 74; iter: 0; batch classifier loss: 0.086940; batch adversarial loss: 0.350385\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063683; batch adversarial loss: 0.393828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.059682; batch adversarial loss: 0.471488\n",
      "epoch 77; iter: 0; batch classifier loss: 0.049374; batch adversarial loss: 0.400534\n",
      "epoch 78; iter: 0; batch classifier loss: 0.045921; batch adversarial loss: 0.456215\n",
      "epoch 79; iter: 0; batch classifier loss: 0.125794; batch adversarial loss: 0.427150\n",
      "epoch 80; iter: 0; batch classifier loss: 0.029513; batch adversarial loss: 0.476649\n",
      "epoch 81; iter: 0; batch classifier loss: 0.090394; batch adversarial loss: 0.430994\n",
      "epoch 82; iter: 0; batch classifier loss: 0.036877; batch adversarial loss: 0.428594\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059598; batch adversarial loss: 0.403218\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080382; batch adversarial loss: 0.405722\n",
      "epoch 85; iter: 0; batch classifier loss: 0.050900; batch adversarial loss: 0.431540\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061749; batch adversarial loss: 0.432407\n",
      "epoch 87; iter: 0; batch classifier loss: 0.038089; batch adversarial loss: 0.478229\n",
      "epoch 88; iter: 0; batch classifier loss: 0.088118; batch adversarial loss: 0.387024\n",
      "epoch 89; iter: 0; batch classifier loss: 0.055874; batch adversarial loss: 0.339107\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065537; batch adversarial loss: 0.411191\n",
      "epoch 91; iter: 0; batch classifier loss: 0.038775; batch adversarial loss: 0.450648\n",
      "epoch 92; iter: 0; batch classifier loss: 0.040336; batch adversarial loss: 0.441531\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056224; batch adversarial loss: 0.467923\n",
      "epoch 94; iter: 0; batch classifier loss: 0.071479; batch adversarial loss: 0.436147\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054023; batch adversarial loss: 0.408300\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068407; batch adversarial loss: 0.561213\n",
      "epoch 97; iter: 0; batch classifier loss: 0.098128; batch adversarial loss: 0.370444\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036222; batch adversarial loss: 0.416807\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041596; batch adversarial loss: 0.361838\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045832; batch adversarial loss: 0.385996\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062662; batch adversarial loss: 0.416828\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079023; batch adversarial loss: 0.472513\n",
      "epoch 103; iter: 0; batch classifier loss: 0.018832; batch adversarial loss: 0.350219\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063232; batch adversarial loss: 0.409174\n",
      "epoch 105; iter: 0; batch classifier loss: 0.078250; batch adversarial loss: 0.469513\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043375; batch adversarial loss: 0.394660\n",
      "epoch 107; iter: 0; batch classifier loss: 0.015914; batch adversarial loss: 0.395916\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042242; batch adversarial loss: 0.381733\n",
      "epoch 109; iter: 0; batch classifier loss: 0.125685; batch adversarial loss: 0.349487\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051995; batch adversarial loss: 0.380498\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044000; batch adversarial loss: 0.378555\n",
      "epoch 112; iter: 0; batch classifier loss: 0.084328; batch adversarial loss: 0.489869\n",
      "epoch 113; iter: 0; batch classifier loss: 0.072295; batch adversarial loss: 0.408589\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030469; batch adversarial loss: 0.458115\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057276; batch adversarial loss: 0.348235\n",
      "epoch 116; iter: 0; batch classifier loss: 0.068601; batch adversarial loss: 0.388245\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042625; batch adversarial loss: 0.398462\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040004; batch adversarial loss: 0.464960\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021791; batch adversarial loss: 0.480066\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049214; batch adversarial loss: 0.453353\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044928; batch adversarial loss: 0.376570\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046690; batch adversarial loss: 0.387437\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049929; batch adversarial loss: 0.399352\n",
      "epoch 124; iter: 0; batch classifier loss: 0.066050; batch adversarial loss: 0.423335\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054847; batch adversarial loss: 0.477661\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036433; batch adversarial loss: 0.505014\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024843; batch adversarial loss: 0.417616\n",
      "epoch 128; iter: 0; batch classifier loss: 0.068406; batch adversarial loss: 0.447029\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033503; batch adversarial loss: 0.479388\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044067; batch adversarial loss: 0.440802\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045954; batch adversarial loss: 0.413244\n",
      "epoch 132; iter: 0; batch classifier loss: 0.054116; batch adversarial loss: 0.472600\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053940; batch adversarial loss: 0.361293\n",
      "epoch 134; iter: 0; batch classifier loss: 0.044044; batch adversarial loss: 0.390294\n",
      "epoch 135; iter: 0; batch classifier loss: 0.070931; batch adversarial loss: 0.486210\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040174; batch adversarial loss: 0.348629\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042177; batch adversarial loss: 0.377929\n",
      "epoch 138; iter: 0; batch classifier loss: 0.067356; batch adversarial loss: 0.474104\n",
      "epoch 139; iter: 0; batch classifier loss: 0.066833; batch adversarial loss: 0.508092\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053473; batch adversarial loss: 0.424735\n",
      "epoch 141; iter: 0; batch classifier loss: 0.073737; batch adversarial loss: 0.453493\n",
      "epoch 142; iter: 0; batch classifier loss: 0.075978; batch adversarial loss: 0.473105\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046816; batch adversarial loss: 0.467584\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036084; batch adversarial loss: 0.445199\n",
      "epoch 145; iter: 0; batch classifier loss: 0.052103; batch adversarial loss: 0.425220\n",
      "epoch 146; iter: 0; batch classifier loss: 0.059902; batch adversarial loss: 0.495543\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040470; batch adversarial loss: 0.487006\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045025; batch adversarial loss: 0.449161\n",
      "epoch 149; iter: 0; batch classifier loss: 0.054968; batch adversarial loss: 0.516604\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026787; batch adversarial loss: 0.437246\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032868; batch adversarial loss: 0.452984\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035121; batch adversarial loss: 0.385896\n",
      "epoch 153; iter: 0; batch classifier loss: 0.048458; batch adversarial loss: 0.423991\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025908; batch adversarial loss: 0.491796\n",
      "epoch 155; iter: 0; batch classifier loss: 0.050345; batch adversarial loss: 0.479329\n",
      "epoch 156; iter: 0; batch classifier loss: 0.048964; batch adversarial loss: 0.377844\n",
      "epoch 157; iter: 0; batch classifier loss: 0.048038; batch adversarial loss: 0.437120\n",
      "epoch 158; iter: 0; batch classifier loss: 0.056539; batch adversarial loss: 0.443989\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029465; batch adversarial loss: 0.513164\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026597; batch adversarial loss: 0.461960\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036325; batch adversarial loss: 0.571368\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022096; batch adversarial loss: 0.445660\n",
      "epoch 163; iter: 0; batch classifier loss: 0.041422; batch adversarial loss: 0.361361\n",
      "epoch 164; iter: 0; batch classifier loss: 0.062947; batch adversarial loss: 0.434538\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028088; batch adversarial loss: 0.420290\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045051; batch adversarial loss: 0.434786\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041443; batch adversarial loss: 0.424595\n",
      "epoch 168; iter: 0; batch classifier loss: 0.041500; batch adversarial loss: 0.423103\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027549; batch adversarial loss: 0.457458\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030259; batch adversarial loss: 0.480947\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032491; batch adversarial loss: 0.508928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.018414; batch adversarial loss: 0.373924\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023136; batch adversarial loss: 0.339025\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026429; batch adversarial loss: 0.465164\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029424; batch adversarial loss: 0.394979\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040551; batch adversarial loss: 0.436425\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034365; batch adversarial loss: 0.466594\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019937; batch adversarial loss: 0.493637\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027091; batch adversarial loss: 0.389896\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028524; batch adversarial loss: 0.490733\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035043; batch adversarial loss: 0.518030\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021856; batch adversarial loss: 0.406343\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021537; batch adversarial loss: 0.493796\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017481; batch adversarial loss: 0.492883\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031432; batch adversarial loss: 0.466795\n",
      "epoch 186; iter: 0; batch classifier loss: 0.049502; batch adversarial loss: 0.414096\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023115; batch adversarial loss: 0.428417\n",
      "epoch 188; iter: 0; batch classifier loss: 0.039359; batch adversarial loss: 0.349061\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035868; batch adversarial loss: 0.448612\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032121; batch adversarial loss: 0.500041\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020897; batch adversarial loss: 0.450571\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012503; batch adversarial loss: 0.462865\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030772; batch adversarial loss: 0.459082\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015486; batch adversarial loss: 0.546153\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019647; batch adversarial loss: 0.439056\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024282; batch adversarial loss: 0.368399\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010840; batch adversarial loss: 0.371991\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037559; batch adversarial loss: 0.384276\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012649; batch adversarial loss: 0.381955\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686230; batch adversarial loss: 0.662400\n",
      "epoch 1; iter: 0; batch classifier loss: 0.468872; batch adversarial loss: 0.676715\n",
      "epoch 2; iter: 0; batch classifier loss: 0.357318; batch adversarial loss: 0.645516\n",
      "epoch 3; iter: 0; batch classifier loss: 0.427529; batch adversarial loss: 0.579516\n",
      "epoch 4; iter: 0; batch classifier loss: 0.334732; batch adversarial loss: 0.573335\n",
      "epoch 5; iter: 0; batch classifier loss: 0.288708; batch adversarial loss: 0.549953\n",
      "epoch 6; iter: 0; batch classifier loss: 0.393386; batch adversarial loss: 0.521183\n",
      "epoch 7; iter: 0; batch classifier loss: 0.225722; batch adversarial loss: 0.509093\n",
      "epoch 8; iter: 0; batch classifier loss: 0.295328; batch adversarial loss: 0.475787\n",
      "epoch 9; iter: 0; batch classifier loss: 0.237245; batch adversarial loss: 0.465476\n",
      "epoch 10; iter: 0; batch classifier loss: 0.213785; batch adversarial loss: 0.505748\n",
      "epoch 11; iter: 0; batch classifier loss: 0.235456; batch adversarial loss: 0.464148\n",
      "epoch 12; iter: 0; batch classifier loss: 0.218382; batch adversarial loss: 0.427617\n",
      "epoch 13; iter: 0; batch classifier loss: 0.228146; batch adversarial loss: 0.486976\n",
      "epoch 14; iter: 0; batch classifier loss: 0.157904; batch adversarial loss: 0.485711\n",
      "epoch 15; iter: 0; batch classifier loss: 0.161445; batch adversarial loss: 0.406979\n",
      "epoch 16; iter: 0; batch classifier loss: 0.165745; batch adversarial loss: 0.566494\n",
      "epoch 17; iter: 0; batch classifier loss: 0.233512; batch adversarial loss: 0.455049\n",
      "epoch 18; iter: 0; batch classifier loss: 0.188097; batch adversarial loss: 0.406405\n",
      "epoch 19; iter: 0; batch classifier loss: 0.159632; batch adversarial loss: 0.445865\n",
      "epoch 20; iter: 0; batch classifier loss: 0.127146; batch adversarial loss: 0.527817\n",
      "epoch 21; iter: 0; batch classifier loss: 0.170910; batch adversarial loss: 0.458625\n",
      "epoch 22; iter: 0; batch classifier loss: 0.092052; batch adversarial loss: 0.425566\n",
      "epoch 23; iter: 0; batch classifier loss: 0.108905; batch adversarial loss: 0.555920\n",
      "epoch 24; iter: 0; batch classifier loss: 0.158196; batch adversarial loss: 0.395828\n",
      "epoch 25; iter: 0; batch classifier loss: 0.152751; batch adversarial loss: 0.410302\n",
      "epoch 26; iter: 0; batch classifier loss: 0.152029; batch adversarial loss: 0.522031\n",
      "epoch 27; iter: 0; batch classifier loss: 0.133416; batch adversarial loss: 0.541833\n",
      "epoch 28; iter: 0; batch classifier loss: 0.160008; batch adversarial loss: 0.505182\n",
      "epoch 29; iter: 0; batch classifier loss: 0.126124; batch adversarial loss: 0.417262\n",
      "epoch 30; iter: 0; batch classifier loss: 0.174891; batch adversarial loss: 0.499716\n",
      "epoch 31; iter: 0; batch classifier loss: 0.213833; batch adversarial loss: 0.525213\n",
      "epoch 32; iter: 0; batch classifier loss: 0.139003; batch adversarial loss: 0.496029\n",
      "epoch 33; iter: 0; batch classifier loss: 0.216622; batch adversarial loss: 0.541392\n",
      "epoch 34; iter: 0; batch classifier loss: 0.172105; batch adversarial loss: 0.481373\n",
      "epoch 35; iter: 0; batch classifier loss: 0.186303; batch adversarial loss: 0.454467\n",
      "epoch 36; iter: 0; batch classifier loss: 0.155177; batch adversarial loss: 0.509790\n",
      "epoch 37; iter: 0; batch classifier loss: 0.088134; batch adversarial loss: 0.464303\n",
      "epoch 38; iter: 0; batch classifier loss: 0.172524; batch adversarial loss: 0.528241\n",
      "epoch 39; iter: 0; batch classifier loss: 0.155754; batch adversarial loss: 0.510833\n",
      "epoch 40; iter: 0; batch classifier loss: 0.087090; batch adversarial loss: 0.480659\n",
      "epoch 41; iter: 0; batch classifier loss: 0.145508; batch adversarial loss: 0.474505\n",
      "epoch 42; iter: 0; batch classifier loss: 0.224281; batch adversarial loss: 0.508936\n",
      "epoch 43; iter: 0; batch classifier loss: 0.113432; batch adversarial loss: 0.415451\n",
      "epoch 44; iter: 0; batch classifier loss: 0.180210; batch adversarial loss: 0.571586\n",
      "epoch 45; iter: 0; batch classifier loss: 0.136694; batch adversarial loss: 0.432528\n",
      "epoch 46; iter: 0; batch classifier loss: 0.246475; batch adversarial loss: 0.403762\n",
      "epoch 47; iter: 0; batch classifier loss: 0.148664; batch adversarial loss: 0.539749\n",
      "epoch 48; iter: 0; batch classifier loss: 0.103008; batch adversarial loss: 0.468778\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101688; batch adversarial loss: 0.515861\n",
      "epoch 50; iter: 0; batch classifier loss: 0.072730; batch adversarial loss: 0.391195\n",
      "epoch 51; iter: 0; batch classifier loss: 0.124483; batch adversarial loss: 0.455908\n",
      "epoch 52; iter: 0; batch classifier loss: 0.058392; batch adversarial loss: 0.479413\n",
      "epoch 53; iter: 0; batch classifier loss: 0.105860; batch adversarial loss: 0.474951\n",
      "epoch 54; iter: 0; batch classifier loss: 0.059825; batch adversarial loss: 0.300834\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077222; batch adversarial loss: 0.396656\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081632; batch adversarial loss: 0.401872\n",
      "epoch 57; iter: 0; batch classifier loss: 0.071315; batch adversarial loss: 0.550062\n",
      "epoch 58; iter: 0; batch classifier loss: 0.079171; batch adversarial loss: 0.478652\n",
      "epoch 59; iter: 0; batch classifier loss: 0.085135; batch adversarial loss: 0.402047\n",
      "epoch 60; iter: 0; batch classifier loss: 0.067519; batch adversarial loss: 0.484207\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103368; batch adversarial loss: 0.344299\n",
      "epoch 62; iter: 0; batch classifier loss: 0.098079; batch adversarial loss: 0.415131\n",
      "epoch 63; iter: 0; batch classifier loss: 0.060945; batch adversarial loss: 0.445198\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072266; batch adversarial loss: 0.321938\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065824; batch adversarial loss: 0.426694\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084545; batch adversarial loss: 0.467036\n",
      "epoch 67; iter: 0; batch classifier loss: 0.037264; batch adversarial loss: 0.369449\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060668; batch adversarial loss: 0.434374\n",
      "epoch 69; iter: 0; batch classifier loss: 0.055600; batch adversarial loss: 0.387373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.073060; batch adversarial loss: 0.505486\n",
      "epoch 71; iter: 0; batch classifier loss: 0.085056; batch adversarial loss: 0.426191\n",
      "epoch 72; iter: 0; batch classifier loss: 0.065597; batch adversarial loss: 0.431300\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076039; batch adversarial loss: 0.429374\n",
      "epoch 74; iter: 0; batch classifier loss: 0.080497; batch adversarial loss: 0.480854\n",
      "epoch 75; iter: 0; batch classifier loss: 0.049149; batch adversarial loss: 0.484658\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076442; batch adversarial loss: 0.485239\n",
      "epoch 77; iter: 0; batch classifier loss: 0.134308; batch adversarial loss: 0.459413\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082195; batch adversarial loss: 0.432979\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068891; batch adversarial loss: 0.334089\n",
      "epoch 80; iter: 0; batch classifier loss: 0.045778; batch adversarial loss: 0.470937\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079703; batch adversarial loss: 0.459622\n",
      "epoch 82; iter: 0; batch classifier loss: 0.047223; batch adversarial loss: 0.394516\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056635; batch adversarial loss: 0.489494\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079804; batch adversarial loss: 0.360363\n",
      "epoch 85; iter: 0; batch classifier loss: 0.092257; batch adversarial loss: 0.346304\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058369; batch adversarial loss: 0.463394\n",
      "epoch 87; iter: 0; batch classifier loss: 0.064965; batch adversarial loss: 0.460660\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059505; batch adversarial loss: 0.438469\n",
      "epoch 89; iter: 0; batch classifier loss: 0.078617; batch adversarial loss: 0.473861\n",
      "epoch 90; iter: 0; batch classifier loss: 0.094834; batch adversarial loss: 0.484269\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046804; batch adversarial loss: 0.435579\n",
      "epoch 92; iter: 0; batch classifier loss: 0.027742; batch adversarial loss: 0.431918\n",
      "epoch 93; iter: 0; batch classifier loss: 0.093835; batch adversarial loss: 0.453304\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075879; batch adversarial loss: 0.508915\n",
      "epoch 95; iter: 0; batch classifier loss: 0.067206; batch adversarial loss: 0.422272\n",
      "epoch 96; iter: 0; batch classifier loss: 0.075865; batch adversarial loss: 0.477935\n",
      "epoch 97; iter: 0; batch classifier loss: 0.111509; batch adversarial loss: 0.430925\n",
      "epoch 98; iter: 0; batch classifier loss: 0.106745; batch adversarial loss: 0.444794\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045312; batch adversarial loss: 0.466320\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051246; batch adversarial loss: 0.435782\n",
      "epoch 101; iter: 0; batch classifier loss: 0.072463; batch adversarial loss: 0.345280\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046836; batch adversarial loss: 0.434027\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048886; batch adversarial loss: 0.599573\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043450; batch adversarial loss: 0.549823\n",
      "epoch 105; iter: 0; batch classifier loss: 0.125623; batch adversarial loss: 0.405295\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067026; batch adversarial loss: 0.563982\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052790; batch adversarial loss: 0.536076\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030293; batch adversarial loss: 0.508292\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053430; batch adversarial loss: 0.410503\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040934; batch adversarial loss: 0.480143\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053398; batch adversarial loss: 0.473052\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033690; batch adversarial loss: 0.672029\n",
      "epoch 113; iter: 0; batch classifier loss: 0.074005; batch adversarial loss: 0.420573\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029067; batch adversarial loss: 0.346761\n",
      "epoch 115; iter: 0; batch classifier loss: 0.069407; batch adversarial loss: 0.359983\n",
      "epoch 116; iter: 0; batch classifier loss: 0.076428; batch adversarial loss: 0.561808\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043931; batch adversarial loss: 0.407852\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050263; batch adversarial loss: 0.351557\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048091; batch adversarial loss: 0.503007\n",
      "epoch 120; iter: 0; batch classifier loss: 0.058858; batch adversarial loss: 0.362925\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030484; batch adversarial loss: 0.534223\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039508; batch adversarial loss: 0.392368\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045664; batch adversarial loss: 0.449320\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046312; batch adversarial loss: 0.411699\n",
      "epoch 125; iter: 0; batch classifier loss: 0.070570; batch adversarial loss: 0.395519\n",
      "epoch 126; iter: 0; batch classifier loss: 0.053934; batch adversarial loss: 0.456181\n",
      "epoch 127; iter: 0; batch classifier loss: 0.065532; batch adversarial loss: 0.359301\n",
      "epoch 128; iter: 0; batch classifier loss: 0.059265; batch adversarial loss: 0.456241\n",
      "epoch 129; iter: 0; batch classifier loss: 0.075693; batch adversarial loss: 0.462186\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041721; batch adversarial loss: 0.381916\n",
      "epoch 131; iter: 0; batch classifier loss: 0.054351; batch adversarial loss: 0.411096\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039861; batch adversarial loss: 0.287171\n",
      "epoch 133; iter: 0; batch classifier loss: 0.080251; batch adversarial loss: 0.448838\n",
      "epoch 134; iter: 0; batch classifier loss: 0.022545; batch adversarial loss: 0.501236\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044082; batch adversarial loss: 0.389760\n",
      "epoch 136; iter: 0; batch classifier loss: 0.074675; batch adversarial loss: 0.397280\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023639; batch adversarial loss: 0.422257\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045686; batch adversarial loss: 0.429441\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033295; batch adversarial loss: 0.375054\n",
      "epoch 140; iter: 0; batch classifier loss: 0.008135; batch adversarial loss: 0.368371\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024626; batch adversarial loss: 0.374163\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040508; batch adversarial loss: 0.309064\n",
      "epoch 143; iter: 0; batch classifier loss: 0.065669; batch adversarial loss: 0.416409\n",
      "epoch 144; iter: 0; batch classifier loss: 0.043405; batch adversarial loss: 0.367218\n",
      "epoch 145; iter: 0; batch classifier loss: 0.055496; batch adversarial loss: 0.387250\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027451; batch adversarial loss: 0.463447\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038941; batch adversarial loss: 0.491095\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023421; batch adversarial loss: 0.348134\n",
      "epoch 149; iter: 0; batch classifier loss: 0.085801; batch adversarial loss: 0.477025\n",
      "epoch 150; iter: 0; batch classifier loss: 0.058950; batch adversarial loss: 0.472603\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020015; batch adversarial loss: 0.480638\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036462; batch adversarial loss: 0.387844\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008529; batch adversarial loss: 0.434428\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030444; batch adversarial loss: 0.386368\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037168; batch adversarial loss: 0.486893\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012125; batch adversarial loss: 0.427995\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021293; batch adversarial loss: 0.442384\n",
      "epoch 158; iter: 0; batch classifier loss: 0.064521; batch adversarial loss: 0.371962\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027176; batch adversarial loss: 0.449796\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017196; batch adversarial loss: 0.566844\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022116; batch adversarial loss: 0.417582\n",
      "epoch 162; iter: 0; batch classifier loss: 0.040769; batch adversarial loss: 0.449978\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028322; batch adversarial loss: 0.447679\n",
      "epoch 164; iter: 0; batch classifier loss: 0.069514; batch adversarial loss: 0.548372\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025010; batch adversarial loss: 0.511206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.029083; batch adversarial loss: 0.343481\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007812; batch adversarial loss: 0.584976\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026556; batch adversarial loss: 0.537637\n",
      "epoch 169; iter: 0; batch classifier loss: 0.058436; batch adversarial loss: 0.421224\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020995; batch adversarial loss: 0.435804\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023074; batch adversarial loss: 0.460868\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040459; batch adversarial loss: 0.461402\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011958; batch adversarial loss: 0.423011\n",
      "epoch 174; iter: 0; batch classifier loss: 0.066702; batch adversarial loss: 0.460699\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020484; batch adversarial loss: 0.497909\n",
      "epoch 176; iter: 0; batch classifier loss: 0.068537; batch adversarial loss: 0.388594\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008427; batch adversarial loss: 0.465997\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018724; batch adversarial loss: 0.422375\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039396; batch adversarial loss: 0.376868\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031714; batch adversarial loss: 0.446423\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030908; batch adversarial loss: 0.366339\n",
      "epoch 182; iter: 0; batch classifier loss: 0.076734; batch adversarial loss: 0.446945\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028239; batch adversarial loss: 0.440709\n",
      "epoch 184; iter: 0; batch classifier loss: 0.046720; batch adversarial loss: 0.460141\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031754; batch adversarial loss: 0.492731\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026056; batch adversarial loss: 0.400142\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036410; batch adversarial loss: 0.406785\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026904; batch adversarial loss: 0.323162\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010001; batch adversarial loss: 0.511071\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031121; batch adversarial loss: 0.386464\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018968; batch adversarial loss: 0.363948\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035600; batch adversarial loss: 0.435790\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012664; batch adversarial loss: 0.460616\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011019; batch adversarial loss: 0.463551\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009503; batch adversarial loss: 0.363785\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010149; batch adversarial loss: 0.457488\n",
      "epoch 197; iter: 0; batch classifier loss: 0.058731; batch adversarial loss: 0.398986\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037593; batch adversarial loss: 0.350697\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013248; batch adversarial loss: 0.441810\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675628; batch adversarial loss: 0.795659\n",
      "epoch 1; iter: 0; batch classifier loss: 0.380513; batch adversarial loss: 0.769335\n",
      "epoch 2; iter: 0; batch classifier loss: 0.298222; batch adversarial loss: 0.701801\n",
      "epoch 3; iter: 0; batch classifier loss: 0.387542; batch adversarial loss: 0.685918\n",
      "epoch 4; iter: 0; batch classifier loss: 0.329691; batch adversarial loss: 0.641230\n",
      "epoch 5; iter: 0; batch classifier loss: 0.309853; batch adversarial loss: 0.645367\n",
      "epoch 6; iter: 0; batch classifier loss: 0.328453; batch adversarial loss: 0.595371\n",
      "epoch 7; iter: 0; batch classifier loss: 0.327147; batch adversarial loss: 0.582690\n",
      "epoch 8; iter: 0; batch classifier loss: 0.312781; batch adversarial loss: 0.547333\n",
      "epoch 9; iter: 0; batch classifier loss: 0.267831; batch adversarial loss: 0.523510\n",
      "epoch 10; iter: 0; batch classifier loss: 0.272060; batch adversarial loss: 0.512556\n",
      "epoch 11; iter: 0; batch classifier loss: 0.211190; batch adversarial loss: 0.526470\n",
      "epoch 12; iter: 0; batch classifier loss: 0.245108; batch adversarial loss: 0.478959\n",
      "epoch 13; iter: 0; batch classifier loss: 0.262511; batch adversarial loss: 0.465492\n",
      "epoch 14; iter: 0; batch classifier loss: 0.265209; batch adversarial loss: 0.487898\n",
      "epoch 15; iter: 0; batch classifier loss: 0.240671; batch adversarial loss: 0.452638\n",
      "epoch 16; iter: 0; batch classifier loss: 0.197094; batch adversarial loss: 0.445403\n",
      "epoch 17; iter: 0; batch classifier loss: 0.227482; batch adversarial loss: 0.486909\n",
      "epoch 18; iter: 0; batch classifier loss: 0.199184; batch adversarial loss: 0.530043\n",
      "epoch 19; iter: 0; batch classifier loss: 0.205746; batch adversarial loss: 0.355779\n",
      "epoch 20; iter: 0; batch classifier loss: 0.241858; batch adversarial loss: 0.435735\n",
      "epoch 21; iter: 0; batch classifier loss: 0.260544; batch adversarial loss: 0.395589\n",
      "epoch 22; iter: 0; batch classifier loss: 0.221590; batch adversarial loss: 0.487784\n",
      "epoch 23; iter: 0; batch classifier loss: 0.206335; batch adversarial loss: 0.452831\n",
      "epoch 24; iter: 0; batch classifier loss: 0.226435; batch adversarial loss: 0.394017\n",
      "epoch 25; iter: 0; batch classifier loss: 0.170054; batch adversarial loss: 0.356579\n",
      "epoch 26; iter: 0; batch classifier loss: 0.189921; batch adversarial loss: 0.389916\n",
      "epoch 27; iter: 0; batch classifier loss: 0.200428; batch adversarial loss: 0.387611\n",
      "epoch 28; iter: 0; batch classifier loss: 0.211986; batch adversarial loss: 0.399721\n",
      "epoch 29; iter: 0; batch classifier loss: 0.146203; batch adversarial loss: 0.456024\n",
      "epoch 30; iter: 0; batch classifier loss: 0.161965; batch adversarial loss: 0.386095\n",
      "epoch 31; iter: 0; batch classifier loss: 0.127604; batch adversarial loss: 0.449180\n",
      "epoch 32; iter: 0; batch classifier loss: 0.111834; batch adversarial loss: 0.397718\n",
      "epoch 33; iter: 0; batch classifier loss: 0.121268; batch adversarial loss: 0.401189\n",
      "epoch 34; iter: 0; batch classifier loss: 0.181726; batch adversarial loss: 0.576244\n",
      "epoch 35; iter: 0; batch classifier loss: 0.145028; batch adversarial loss: 0.426511\n",
      "epoch 36; iter: 0; batch classifier loss: 0.143388; batch adversarial loss: 0.399958\n",
      "epoch 37; iter: 0; batch classifier loss: 0.126705; batch adversarial loss: 0.412529\n",
      "epoch 38; iter: 0; batch classifier loss: 0.108864; batch adversarial loss: 0.431712\n",
      "epoch 39; iter: 0; batch classifier loss: 0.146304; batch adversarial loss: 0.461918\n",
      "epoch 40; iter: 0; batch classifier loss: 0.155895; batch adversarial loss: 0.447078\n",
      "epoch 41; iter: 0; batch classifier loss: 0.118907; batch adversarial loss: 0.442284\n",
      "epoch 42; iter: 0; batch classifier loss: 0.141255; batch adversarial loss: 0.449312\n",
      "epoch 43; iter: 0; batch classifier loss: 0.153984; batch adversarial loss: 0.444072\n",
      "epoch 44; iter: 0; batch classifier loss: 0.133665; batch adversarial loss: 0.508575\n",
      "epoch 45; iter: 0; batch classifier loss: 0.129986; batch adversarial loss: 0.506365\n",
      "epoch 46; iter: 0; batch classifier loss: 0.103792; batch adversarial loss: 0.426439\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095096; batch adversarial loss: 0.422866\n",
      "epoch 48; iter: 0; batch classifier loss: 0.094804; batch adversarial loss: 0.459780\n",
      "epoch 49; iter: 0; batch classifier loss: 0.100472; batch adversarial loss: 0.501806\n",
      "epoch 50; iter: 0; batch classifier loss: 0.079951; batch adversarial loss: 0.455227\n",
      "epoch 51; iter: 0; batch classifier loss: 0.117819; batch adversarial loss: 0.446886\n",
      "epoch 52; iter: 0; batch classifier loss: 0.079528; batch adversarial loss: 0.441645\n",
      "epoch 53; iter: 0; batch classifier loss: 0.067662; batch adversarial loss: 0.425605\n",
      "epoch 54; iter: 0; batch classifier loss: 0.101565; batch adversarial loss: 0.446773\n",
      "epoch 55; iter: 0; batch classifier loss: 0.102325; batch adversarial loss: 0.396470\n",
      "epoch 56; iter: 0; batch classifier loss: 0.127129; batch adversarial loss: 0.422368\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112844; batch adversarial loss: 0.440453\n",
      "epoch 58; iter: 0; batch classifier loss: 0.083558; batch adversarial loss: 0.413598\n",
      "epoch 59; iter: 0; batch classifier loss: 0.091362; batch adversarial loss: 0.371834\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086333; batch adversarial loss: 0.418488\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114148; batch adversarial loss: 0.475625\n",
      "epoch 62; iter: 0; batch classifier loss: 0.096497; batch adversarial loss: 0.449632\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092632; batch adversarial loss: 0.396393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.114124; batch adversarial loss: 0.454746\n",
      "epoch 65; iter: 0; batch classifier loss: 0.083228; batch adversarial loss: 0.396638\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072386; batch adversarial loss: 0.392076\n",
      "epoch 67; iter: 0; batch classifier loss: 0.065417; batch adversarial loss: 0.462346\n",
      "epoch 68; iter: 0; batch classifier loss: 0.057472; batch adversarial loss: 0.444130\n",
      "epoch 69; iter: 0; batch classifier loss: 0.082122; batch adversarial loss: 0.437738\n",
      "epoch 70; iter: 0; batch classifier loss: 0.094222; batch adversarial loss: 0.424604\n",
      "epoch 71; iter: 0; batch classifier loss: 0.114388; batch adversarial loss: 0.431077\n",
      "epoch 72; iter: 0; batch classifier loss: 0.067932; batch adversarial loss: 0.447022\n",
      "epoch 73; iter: 0; batch classifier loss: 0.057207; batch adversarial loss: 0.397013\n",
      "epoch 74; iter: 0; batch classifier loss: 0.056780; batch adversarial loss: 0.482428\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071781; batch adversarial loss: 0.484493\n",
      "epoch 76; iter: 0; batch classifier loss: 0.097043; batch adversarial loss: 0.491232\n",
      "epoch 77; iter: 0; batch classifier loss: 0.099401; batch adversarial loss: 0.418474\n",
      "epoch 78; iter: 0; batch classifier loss: 0.046968; batch adversarial loss: 0.454748\n",
      "epoch 79; iter: 0; batch classifier loss: 0.122310; batch adversarial loss: 0.426822\n",
      "epoch 80; iter: 0; batch classifier loss: 0.100193; batch adversarial loss: 0.549889\n",
      "epoch 81; iter: 0; batch classifier loss: 0.109964; batch adversarial loss: 0.527194\n",
      "epoch 82; iter: 0; batch classifier loss: 0.111157; batch adversarial loss: 0.452128\n",
      "epoch 83; iter: 0; batch classifier loss: 0.091203; batch adversarial loss: 0.476287\n",
      "epoch 84; iter: 0; batch classifier loss: 0.099902; batch adversarial loss: 0.390237\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051388; batch adversarial loss: 0.348263\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062248; batch adversarial loss: 0.309060\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068895; batch adversarial loss: 0.414231\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064151; batch adversarial loss: 0.392598\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069709; batch adversarial loss: 0.440387\n",
      "epoch 90; iter: 0; batch classifier loss: 0.087744; batch adversarial loss: 0.433019\n",
      "epoch 91; iter: 0; batch classifier loss: 0.117390; batch adversarial loss: 0.411046\n",
      "epoch 92; iter: 0; batch classifier loss: 0.072269; batch adversarial loss: 0.452777\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062333; batch adversarial loss: 0.472166\n",
      "epoch 94; iter: 0; batch classifier loss: 0.055059; batch adversarial loss: 0.365552\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070945; batch adversarial loss: 0.431858\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037655; batch adversarial loss: 0.354124\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059102; batch adversarial loss: 0.438510\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074956; batch adversarial loss: 0.412023\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061664; batch adversarial loss: 0.403178\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038157; batch adversarial loss: 0.393018\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056089; batch adversarial loss: 0.494992\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063558; batch adversarial loss: 0.359355\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049154; batch adversarial loss: 0.449184\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053947; batch adversarial loss: 0.404630\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050373; batch adversarial loss: 0.430797\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045669; batch adversarial loss: 0.471909\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050060; batch adversarial loss: 0.492513\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045417; batch adversarial loss: 0.424126\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038380; batch adversarial loss: 0.466226\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040070; batch adversarial loss: 0.382762\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048910; batch adversarial loss: 0.430670\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040623; batch adversarial loss: 0.459900\n",
      "epoch 113; iter: 0; batch classifier loss: 0.021515; batch adversarial loss: 0.474867\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048011; batch adversarial loss: 0.424172\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027007; batch adversarial loss: 0.492225\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032042; batch adversarial loss: 0.529981\n",
      "epoch 117; iter: 0; batch classifier loss: 0.019305; batch adversarial loss: 0.427728\n",
      "epoch 118; iter: 0; batch classifier loss: 0.027794; batch adversarial loss: 0.394431\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053253; batch adversarial loss: 0.491800\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022714; batch adversarial loss: 0.518317\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037425; batch adversarial loss: 0.492700\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031347; batch adversarial loss: 0.493615\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029359; batch adversarial loss: 0.490534\n",
      "epoch 124; iter: 0; batch classifier loss: 0.056515; batch adversarial loss: 0.537251\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043283; batch adversarial loss: 0.550183\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026529; batch adversarial loss: 0.488622\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032447; batch adversarial loss: 0.589356\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052676; batch adversarial loss: 0.561181\n",
      "epoch 129; iter: 0; batch classifier loss: 0.066058; batch adversarial loss: 0.561523\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047073; batch adversarial loss: 0.483783\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036665; batch adversarial loss: 0.433096\n",
      "epoch 132; iter: 0; batch classifier loss: 0.080976; batch adversarial loss: 0.443345\n",
      "epoch 133; iter: 0; batch classifier loss: 0.161613; batch adversarial loss: 0.682838\n",
      "epoch 134; iter: 0; batch classifier loss: 0.181336; batch adversarial loss: 0.808622\n",
      "epoch 135; iter: 0; batch classifier loss: 0.108633; batch adversarial loss: 0.713450\n",
      "epoch 136; iter: 0; batch classifier loss: 0.115530; batch adversarial loss: 0.555819\n",
      "epoch 137; iter: 0; batch classifier loss: 0.140510; batch adversarial loss: 0.586466\n",
      "epoch 138; iter: 0; batch classifier loss: 0.105134; batch adversarial loss: 0.508168\n",
      "epoch 139; iter: 0; batch classifier loss: 0.163060; batch adversarial loss: 0.717234\n",
      "epoch 140; iter: 0; batch classifier loss: 0.133807; batch adversarial loss: 0.586262\n",
      "epoch 141; iter: 0; batch classifier loss: 0.131630; batch adversarial loss: 0.620220\n",
      "epoch 142; iter: 0; batch classifier loss: 0.129167; batch adversarial loss: 0.530835\n",
      "epoch 143; iter: 0; batch classifier loss: 0.076598; batch adversarial loss: 0.494633\n",
      "epoch 144; iter: 0; batch classifier loss: 0.129730; batch adversarial loss: 0.626894\n",
      "epoch 145; iter: 0; batch classifier loss: 0.068960; batch adversarial loss: 0.434044\n",
      "epoch 146; iter: 0; batch classifier loss: 0.153416; batch adversarial loss: 0.672546\n",
      "epoch 147; iter: 0; batch classifier loss: 0.060890; batch adversarial loss: 0.455603\n",
      "epoch 148; iter: 0; batch classifier loss: 0.269244; batch adversarial loss: 0.705888\n",
      "epoch 149; iter: 0; batch classifier loss: 0.186808; batch adversarial loss: 0.621064\n",
      "epoch 150; iter: 0; batch classifier loss: 0.128278; batch adversarial loss: 0.633744\n",
      "epoch 151; iter: 0; batch classifier loss: 0.171690; batch adversarial loss: 0.611758\n",
      "epoch 152; iter: 0; batch classifier loss: 0.104361; batch adversarial loss: 0.490762\n",
      "epoch 153; iter: 0; batch classifier loss: 0.164806; batch adversarial loss: 0.559166\n",
      "epoch 154; iter: 0; batch classifier loss: 0.143281; batch adversarial loss: 0.550119\n",
      "epoch 155; iter: 0; batch classifier loss: 0.170597; batch adversarial loss: 0.574706\n",
      "epoch 156; iter: 0; batch classifier loss: 0.123109; batch adversarial loss: 0.451614\n",
      "epoch 157; iter: 0; batch classifier loss: 0.147753; batch adversarial loss: 0.487586\n",
      "epoch 158; iter: 0; batch classifier loss: 0.165240; batch adversarial loss: 0.545542\n",
      "epoch 159; iter: 0; batch classifier loss: 0.115829; batch adversarial loss: 0.521554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.118252; batch adversarial loss: 0.505659\n",
      "epoch 161; iter: 0; batch classifier loss: 0.102452; batch adversarial loss: 0.504328\n",
      "epoch 162; iter: 0; batch classifier loss: 0.136113; batch adversarial loss: 0.549489\n",
      "epoch 163; iter: 0; batch classifier loss: 0.103878; batch adversarial loss: 0.548835\n",
      "epoch 164; iter: 0; batch classifier loss: 0.103852; batch adversarial loss: 0.477481\n",
      "epoch 165; iter: 0; batch classifier loss: 0.111889; batch adversarial loss: 0.451610\n",
      "epoch 166; iter: 0; batch classifier loss: 0.121862; batch adversarial loss: 0.529335\n",
      "epoch 167; iter: 0; batch classifier loss: 0.121596; batch adversarial loss: 0.510160\n",
      "epoch 168; iter: 0; batch classifier loss: 0.111632; batch adversarial loss: 0.485803\n",
      "epoch 169; iter: 0; batch classifier loss: 0.119960; batch adversarial loss: 0.487606\n",
      "epoch 170; iter: 0; batch classifier loss: 0.110530; batch adversarial loss: 0.468615\n",
      "epoch 171; iter: 0; batch classifier loss: 0.105475; batch adversarial loss: 0.575263\n",
      "epoch 172; iter: 0; batch classifier loss: 0.097780; batch adversarial loss: 0.512118\n",
      "epoch 173; iter: 0; batch classifier loss: 0.115620; batch adversarial loss: 0.510973\n",
      "epoch 174; iter: 0; batch classifier loss: 0.111354; batch adversarial loss: 0.460988\n",
      "epoch 175; iter: 0; batch classifier loss: 0.082970; batch adversarial loss: 0.494372\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045614; batch adversarial loss: 0.421484\n",
      "epoch 177; iter: 0; batch classifier loss: 0.058838; batch adversarial loss: 0.457283\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040122; batch adversarial loss: 0.408770\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038502; batch adversarial loss: 0.505479\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041214; batch adversarial loss: 0.467618\n",
      "epoch 181; iter: 0; batch classifier loss: 0.060578; batch adversarial loss: 0.429932\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032652; batch adversarial loss: 0.498854\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017162; batch adversarial loss: 0.431621\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021710; batch adversarial loss: 0.429085\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035352; batch adversarial loss: 0.469092\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025442; batch adversarial loss: 0.368157\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023695; batch adversarial loss: 0.454713\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015528; batch adversarial loss: 0.443750\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021908; batch adversarial loss: 0.455495\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012028; batch adversarial loss: 0.430418\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028989; batch adversarial loss: 0.409841\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029556; batch adversarial loss: 0.477829\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013008; batch adversarial loss: 0.460214\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024193; batch adversarial loss: 0.421384\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011012; batch adversarial loss: 0.442583\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009568; batch adversarial loss: 0.450011\n",
      "epoch 197; iter: 0; batch classifier loss: 0.035021; batch adversarial loss: 0.474338\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018410; batch adversarial loss: 0.452668\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016668; batch adversarial loss: 0.479602\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673649; batch adversarial loss: 0.617832\n",
      "epoch 1; iter: 0; batch classifier loss: 0.463248; batch adversarial loss: 0.617210\n",
      "epoch 2; iter: 0; batch classifier loss: 0.403414; batch adversarial loss: 0.587768\n",
      "epoch 3; iter: 0; batch classifier loss: 0.540661; batch adversarial loss: 0.636415\n",
      "epoch 4; iter: 0; batch classifier loss: 0.478680; batch adversarial loss: 0.577624\n",
      "epoch 5; iter: 0; batch classifier loss: 0.360266; batch adversarial loss: 0.619161\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572461; batch adversarial loss: 0.517321\n",
      "epoch 7; iter: 0; batch classifier loss: 0.451177; batch adversarial loss: 0.548673\n",
      "epoch 8; iter: 0; batch classifier loss: 0.427065; batch adversarial loss: 0.540917\n",
      "epoch 9; iter: 0; batch classifier loss: 0.474123; batch adversarial loss: 0.533630\n",
      "epoch 10; iter: 0; batch classifier loss: 0.376765; batch adversarial loss: 0.519933\n",
      "epoch 11; iter: 0; batch classifier loss: 0.317102; batch adversarial loss: 0.485387\n",
      "epoch 12; iter: 0; batch classifier loss: 0.250698; batch adversarial loss: 0.466400\n",
      "epoch 13; iter: 0; batch classifier loss: 0.286354; batch adversarial loss: 0.470678\n",
      "epoch 14; iter: 0; batch classifier loss: 0.254806; batch adversarial loss: 0.477972\n",
      "epoch 15; iter: 0; batch classifier loss: 0.260235; batch adversarial loss: 0.522499\n",
      "epoch 16; iter: 0; batch classifier loss: 0.267814; batch adversarial loss: 0.522840\n",
      "epoch 17; iter: 0; batch classifier loss: 0.224388; batch adversarial loss: 0.509223\n",
      "epoch 18; iter: 0; batch classifier loss: 0.267126; batch adversarial loss: 0.458578\n",
      "epoch 19; iter: 0; batch classifier loss: 0.241649; batch adversarial loss: 0.455572\n",
      "epoch 20; iter: 0; batch classifier loss: 0.209358; batch adversarial loss: 0.487628\n",
      "epoch 21; iter: 0; batch classifier loss: 0.228641; batch adversarial loss: 0.481079\n",
      "epoch 22; iter: 0; batch classifier loss: 0.162172; batch adversarial loss: 0.560342\n",
      "epoch 23; iter: 0; batch classifier loss: 0.213266; batch adversarial loss: 0.439364\n",
      "epoch 24; iter: 0; batch classifier loss: 0.187884; batch adversarial loss: 0.492307\n",
      "epoch 25; iter: 0; batch classifier loss: 0.164502; batch adversarial loss: 0.531896\n",
      "epoch 26; iter: 0; batch classifier loss: 0.152689; batch adversarial loss: 0.454504\n",
      "epoch 27; iter: 0; batch classifier loss: 0.172533; batch adversarial loss: 0.437619\n",
      "epoch 28; iter: 0; batch classifier loss: 0.187874; batch adversarial loss: 0.442492\n",
      "epoch 29; iter: 0; batch classifier loss: 0.172373; batch adversarial loss: 0.428713\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167805; batch adversarial loss: 0.487953\n",
      "epoch 31; iter: 0; batch classifier loss: 0.224495; batch adversarial loss: 0.477748\n",
      "epoch 32; iter: 0; batch classifier loss: 0.136082; batch adversarial loss: 0.426592\n",
      "epoch 33; iter: 0; batch classifier loss: 0.137874; batch adversarial loss: 0.442057\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142803; batch adversarial loss: 0.426182\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140681; batch adversarial loss: 0.418336\n",
      "epoch 36; iter: 0; batch classifier loss: 0.153080; batch adversarial loss: 0.428044\n",
      "epoch 37; iter: 0; batch classifier loss: 0.102067; batch adversarial loss: 0.468010\n",
      "epoch 38; iter: 0; batch classifier loss: 0.136500; batch adversarial loss: 0.450554\n",
      "epoch 39; iter: 0; batch classifier loss: 0.153498; batch adversarial loss: 0.482318\n",
      "epoch 40; iter: 0; batch classifier loss: 0.158162; batch adversarial loss: 0.377971\n",
      "epoch 41; iter: 0; batch classifier loss: 0.116429; batch adversarial loss: 0.513947\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105144; batch adversarial loss: 0.486515\n",
      "epoch 43; iter: 0; batch classifier loss: 0.116994; batch adversarial loss: 0.431750\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127487; batch adversarial loss: 0.478397\n",
      "epoch 45; iter: 0; batch classifier loss: 0.131013; batch adversarial loss: 0.383637\n",
      "epoch 46; iter: 0; batch classifier loss: 0.121469; batch adversarial loss: 0.397101\n",
      "epoch 47; iter: 0; batch classifier loss: 0.183510; batch adversarial loss: 0.475500\n",
      "epoch 48; iter: 0; batch classifier loss: 0.127148; batch adversarial loss: 0.426669\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107289; batch adversarial loss: 0.446230\n",
      "epoch 50; iter: 0; batch classifier loss: 0.151918; batch adversarial loss: 0.378651\n",
      "epoch 51; iter: 0; batch classifier loss: 0.168539; batch adversarial loss: 0.461634\n",
      "epoch 52; iter: 0; batch classifier loss: 0.134617; batch adversarial loss: 0.398070\n",
      "epoch 53; iter: 0; batch classifier loss: 0.120521; batch adversarial loss: 0.478577\n",
      "epoch 54; iter: 0; batch classifier loss: 0.128191; batch adversarial loss: 0.380114\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119283; batch adversarial loss: 0.476502\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119489; batch adversarial loss: 0.381976\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073564; batch adversarial loss: 0.483429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.096984; batch adversarial loss: 0.429070\n",
      "epoch 59; iter: 0; batch classifier loss: 0.118668; batch adversarial loss: 0.397284\n",
      "epoch 60; iter: 0; batch classifier loss: 0.147488; batch adversarial loss: 0.486243\n",
      "epoch 61; iter: 0; batch classifier loss: 0.076314; batch adversarial loss: 0.478004\n",
      "epoch 62; iter: 0; batch classifier loss: 0.124184; batch adversarial loss: 0.414685\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104339; batch adversarial loss: 0.554134\n",
      "epoch 64; iter: 0; batch classifier loss: 0.104611; batch adversarial loss: 0.419525\n",
      "epoch 65; iter: 0; batch classifier loss: 0.107644; batch adversarial loss: 0.490112\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088982; batch adversarial loss: 0.420591\n",
      "epoch 67; iter: 0; batch classifier loss: 0.113736; batch adversarial loss: 0.421854\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094237; batch adversarial loss: 0.446286\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103586; batch adversarial loss: 0.493303\n",
      "epoch 70; iter: 0; batch classifier loss: 0.157586; batch adversarial loss: 0.436768\n",
      "epoch 71; iter: 0; batch classifier loss: 0.106457; batch adversarial loss: 0.395427\n",
      "epoch 72; iter: 0; batch classifier loss: 0.091572; batch adversarial loss: 0.474873\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101201; batch adversarial loss: 0.388671\n",
      "epoch 74; iter: 0; batch classifier loss: 0.117277; batch adversarial loss: 0.450410\n",
      "epoch 75; iter: 0; batch classifier loss: 0.127657; batch adversarial loss: 0.432978\n",
      "epoch 76; iter: 0; batch classifier loss: 0.085789; batch adversarial loss: 0.331551\n",
      "epoch 77; iter: 0; batch classifier loss: 0.117922; batch adversarial loss: 0.453505\n",
      "epoch 78; iter: 0; batch classifier loss: 0.126327; batch adversarial loss: 0.400923\n",
      "epoch 79; iter: 0; batch classifier loss: 0.125180; batch adversarial loss: 0.473342\n",
      "epoch 80; iter: 0; batch classifier loss: 0.096152; batch adversarial loss: 0.459339\n",
      "epoch 81; iter: 0; batch classifier loss: 0.088687; batch adversarial loss: 0.485194\n",
      "epoch 82; iter: 0; batch classifier loss: 0.124551; batch adversarial loss: 0.415978\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061455; batch adversarial loss: 0.540604\n",
      "epoch 84; iter: 0; batch classifier loss: 0.081967; batch adversarial loss: 0.503668\n",
      "epoch 85; iter: 0; batch classifier loss: 0.116174; batch adversarial loss: 0.428467\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084258; batch adversarial loss: 0.425232\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076296; batch adversarial loss: 0.459266\n",
      "epoch 88; iter: 0; batch classifier loss: 0.097591; batch adversarial loss: 0.453408\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073207; batch adversarial loss: 0.409996\n",
      "epoch 90; iter: 0; batch classifier loss: 0.086201; batch adversarial loss: 0.404082\n",
      "epoch 91; iter: 0; batch classifier loss: 0.070527; batch adversarial loss: 0.512046\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044973; batch adversarial loss: 0.488058\n",
      "epoch 93; iter: 0; batch classifier loss: 0.049879; batch adversarial loss: 0.531951\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046542; batch adversarial loss: 0.437119\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052933; batch adversarial loss: 0.424657\n",
      "epoch 96; iter: 0; batch classifier loss: 0.042084; batch adversarial loss: 0.454611\n",
      "epoch 97; iter: 0; batch classifier loss: 0.083851; batch adversarial loss: 0.438175\n",
      "epoch 98; iter: 0; batch classifier loss: 0.069184; batch adversarial loss: 0.565306\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047915; batch adversarial loss: 0.496067\n",
      "epoch 100; iter: 0; batch classifier loss: 0.077981; batch adversarial loss: 0.353440\n",
      "epoch 101; iter: 0; batch classifier loss: 0.077718; batch adversarial loss: 0.439876\n",
      "epoch 102; iter: 0; batch classifier loss: 0.027382; batch adversarial loss: 0.484187\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072743; batch adversarial loss: 0.462262\n",
      "epoch 104; iter: 0; batch classifier loss: 0.085910; batch adversarial loss: 0.423530\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051246; batch adversarial loss: 0.466855\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049330; batch adversarial loss: 0.443592\n",
      "epoch 107; iter: 0; batch classifier loss: 0.088520; batch adversarial loss: 0.453215\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059591; batch adversarial loss: 0.399383\n",
      "epoch 109; iter: 0; batch classifier loss: 0.014018; batch adversarial loss: 0.502617\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048547; batch adversarial loss: 0.449634\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044527; batch adversarial loss: 0.346031\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042991; batch adversarial loss: 0.363548\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034105; batch adversarial loss: 0.481622\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041884; batch adversarial loss: 0.465681\n",
      "epoch 115; iter: 0; batch classifier loss: 0.047432; batch adversarial loss: 0.446769\n",
      "epoch 116; iter: 0; batch classifier loss: 0.025519; batch adversarial loss: 0.545279\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023695; batch adversarial loss: 0.472227\n",
      "epoch 118; iter: 0; batch classifier loss: 0.020822; batch adversarial loss: 0.459255\n",
      "epoch 119; iter: 0; batch classifier loss: 0.010009; batch adversarial loss: 0.434842\n",
      "epoch 120; iter: 0; batch classifier loss: 0.060886; batch adversarial loss: 0.518567\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038286; batch adversarial loss: 0.422570\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041626; batch adversarial loss: 0.458119\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027152; batch adversarial loss: 0.466764\n",
      "epoch 124; iter: 0; batch classifier loss: 0.012886; batch adversarial loss: 0.483361\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047535; batch adversarial loss: 0.439885\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042725; batch adversarial loss: 0.410974\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051174; batch adversarial loss: 0.459197\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019312; batch adversarial loss: 0.467555\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035098; batch adversarial loss: 0.432289\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038969; batch adversarial loss: 0.504495\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027034; batch adversarial loss: 0.426986\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015066; batch adversarial loss: 0.443042\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034101; batch adversarial loss: 0.448338\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048718; batch adversarial loss: 0.440045\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046966; batch adversarial loss: 0.478043\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032144; batch adversarial loss: 0.539612\n",
      "epoch 137; iter: 0; batch classifier loss: 0.012678; batch adversarial loss: 0.442431\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038462; batch adversarial loss: 0.521508\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026471; batch adversarial loss: 0.471288\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040811; batch adversarial loss: 0.438920\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044376; batch adversarial loss: 0.488118\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023712; batch adversarial loss: 0.465277\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025165; batch adversarial loss: 0.529941\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041674; batch adversarial loss: 0.428902\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021408; batch adversarial loss: 0.495442\n",
      "epoch 146; iter: 0; batch classifier loss: 0.043649; batch adversarial loss: 0.456765\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024121; batch adversarial loss: 0.392885\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029822; batch adversarial loss: 0.492198\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023893; batch adversarial loss: 0.477837\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033279; batch adversarial loss: 0.397972\n",
      "epoch 151; iter: 0; batch classifier loss: 0.071144; batch adversarial loss: 0.429893\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020749; batch adversarial loss: 0.423683\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011104; batch adversarial loss: 0.478884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.026957; batch adversarial loss: 0.450042\n",
      "epoch 155; iter: 0; batch classifier loss: 0.005722; batch adversarial loss: 0.542372\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044847; batch adversarial loss: 0.414976\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027634; batch adversarial loss: 0.501596\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020952; batch adversarial loss: 0.425545\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017152; batch adversarial loss: 0.570288\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020490; batch adversarial loss: 0.428311\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030133; batch adversarial loss: 0.395381\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023848; batch adversarial loss: 0.568867\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020891; batch adversarial loss: 0.491441\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031071; batch adversarial loss: 0.426378\n",
      "epoch 165; iter: 0; batch classifier loss: 0.004973; batch adversarial loss: 0.476569\n",
      "epoch 166; iter: 0; batch classifier loss: 0.043989; batch adversarial loss: 0.434137\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042579; batch adversarial loss: 0.448717\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038426; batch adversarial loss: 0.393565\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032418; batch adversarial loss: 0.440454\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032412; batch adversarial loss: 0.428564\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008166; batch adversarial loss: 0.455386\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017148; batch adversarial loss: 0.440187\n",
      "epoch 173; iter: 0; batch classifier loss: 0.003575; batch adversarial loss: 0.408094\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017496; batch adversarial loss: 0.401582\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010018; batch adversarial loss: 0.531272\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007595; batch adversarial loss: 0.404834\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019659; batch adversarial loss: 0.392402\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015636; batch adversarial loss: 0.419097\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017730; batch adversarial loss: 0.473025\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027594; batch adversarial loss: 0.395442\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027581; batch adversarial loss: 0.453592\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027629; batch adversarial loss: 0.488210\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028997; batch adversarial loss: 0.494156\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021768; batch adversarial loss: 0.336503\n",
      "epoch 185; iter: 0; batch classifier loss: 0.050018; batch adversarial loss: 0.392071\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010930; batch adversarial loss: 0.453189\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014319; batch adversarial loss: 0.488171\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020495; batch adversarial loss: 0.599970\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015594; batch adversarial loss: 0.469556\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021757; batch adversarial loss: 0.385229\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008940; batch adversarial loss: 0.509496\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010300; batch adversarial loss: 0.426177\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021190; batch adversarial loss: 0.459643\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014219; batch adversarial loss: 0.451215\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029583; batch adversarial loss: 0.470970\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015481; batch adversarial loss: 0.369809\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013523; batch adversarial loss: 0.468755\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004506; batch adversarial loss: 0.403177\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007654; batch adversarial loss: 0.511029\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667487; batch adversarial loss: 0.551227\n",
      "epoch 1; iter: 0; batch classifier loss: 0.423463; batch adversarial loss: 0.617244\n",
      "epoch 2; iter: 0; batch classifier loss: 0.392143; batch adversarial loss: 0.627536\n",
      "epoch 3; iter: 0; batch classifier loss: 0.408810; batch adversarial loss: 0.582462\n",
      "epoch 4; iter: 0; batch classifier loss: 0.299432; batch adversarial loss: 0.632394\n",
      "epoch 5; iter: 0; batch classifier loss: 0.289957; batch adversarial loss: 0.595078\n",
      "epoch 6; iter: 0; batch classifier loss: 0.359143; batch adversarial loss: 0.509529\n",
      "epoch 7; iter: 0; batch classifier loss: 0.314524; batch adversarial loss: 0.482257\n",
      "epoch 8; iter: 0; batch classifier loss: 0.307233; batch adversarial loss: 0.601026\n",
      "epoch 9; iter: 0; batch classifier loss: 0.345208; batch adversarial loss: 0.553869\n",
      "epoch 10; iter: 0; batch classifier loss: 0.398046; batch adversarial loss: 0.611567\n",
      "epoch 11; iter: 0; batch classifier loss: 0.362648; batch adversarial loss: 0.549983\n",
      "epoch 12; iter: 0; batch classifier loss: 0.371530; batch adversarial loss: 0.533511\n",
      "epoch 13; iter: 0; batch classifier loss: 0.328959; batch adversarial loss: 0.538490\n",
      "epoch 14; iter: 0; batch classifier loss: 0.375571; batch adversarial loss: 0.523404\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513692; batch adversarial loss: 0.541055\n",
      "epoch 16; iter: 0; batch classifier loss: 0.501187; batch adversarial loss: 0.537593\n",
      "epoch 17; iter: 0; batch classifier loss: 0.503227; batch adversarial loss: 0.520609\n",
      "epoch 18; iter: 0; batch classifier loss: 0.373126; batch adversarial loss: 0.411894\n",
      "epoch 19; iter: 0; batch classifier loss: 0.234397; batch adversarial loss: 0.458298\n",
      "epoch 20; iter: 0; batch classifier loss: 0.249825; batch adversarial loss: 0.536622\n",
      "epoch 21; iter: 0; batch classifier loss: 0.212031; batch adversarial loss: 0.476161\n",
      "epoch 22; iter: 0; batch classifier loss: 0.138738; batch adversarial loss: 0.452737\n",
      "epoch 23; iter: 0; batch classifier loss: 0.219481; batch adversarial loss: 0.372567\n",
      "epoch 24; iter: 0; batch classifier loss: 0.128756; batch adversarial loss: 0.491155\n",
      "epoch 25; iter: 0; batch classifier loss: 0.114898; batch adversarial loss: 0.459186\n",
      "epoch 26; iter: 0; batch classifier loss: 0.144693; batch adversarial loss: 0.546735\n",
      "epoch 27; iter: 0; batch classifier loss: 0.153416; batch adversarial loss: 0.554519\n",
      "epoch 28; iter: 0; batch classifier loss: 0.105701; batch adversarial loss: 0.566099\n",
      "epoch 29; iter: 0; batch classifier loss: 0.160061; batch adversarial loss: 0.488422\n",
      "epoch 30; iter: 0; batch classifier loss: 0.163329; batch adversarial loss: 0.531406\n",
      "epoch 31; iter: 0; batch classifier loss: 0.117465; batch adversarial loss: 0.450561\n",
      "epoch 32; iter: 0; batch classifier loss: 0.148962; batch adversarial loss: 0.432775\n",
      "epoch 33; iter: 0; batch classifier loss: 0.100115; batch adversarial loss: 0.582303\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142558; batch adversarial loss: 0.496415\n",
      "epoch 35; iter: 0; batch classifier loss: 0.100493; batch adversarial loss: 0.539931\n",
      "epoch 36; iter: 0; batch classifier loss: 0.123930; batch adversarial loss: 0.411991\n",
      "epoch 37; iter: 0; batch classifier loss: 0.133257; batch adversarial loss: 0.378678\n",
      "epoch 38; iter: 0; batch classifier loss: 0.113699; batch adversarial loss: 0.424306\n",
      "epoch 39; iter: 0; batch classifier loss: 0.117466; batch adversarial loss: 0.478245\n",
      "epoch 40; iter: 0; batch classifier loss: 0.117958; batch adversarial loss: 0.435442\n",
      "epoch 41; iter: 0; batch classifier loss: 0.108706; batch adversarial loss: 0.412836\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116847; batch adversarial loss: 0.377803\n",
      "epoch 43; iter: 0; batch classifier loss: 0.103986; batch adversarial loss: 0.434877\n",
      "epoch 44; iter: 0; batch classifier loss: 0.099779; batch adversarial loss: 0.465481\n",
      "epoch 45; iter: 0; batch classifier loss: 0.149396; batch adversarial loss: 0.542432\n",
      "epoch 46; iter: 0; batch classifier loss: 0.085491; batch adversarial loss: 0.402093\n",
      "epoch 47; iter: 0; batch classifier loss: 0.093796; batch adversarial loss: 0.377995\n",
      "epoch 48; iter: 0; batch classifier loss: 0.107092; batch adversarial loss: 0.416373\n",
      "epoch 49; iter: 0; batch classifier loss: 0.131733; batch adversarial loss: 0.434449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.108099; batch adversarial loss: 0.502238\n",
      "epoch 51; iter: 0; batch classifier loss: 0.182164; batch adversarial loss: 0.362234\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096704; batch adversarial loss: 0.464595\n",
      "epoch 53; iter: 0; batch classifier loss: 0.110292; batch adversarial loss: 0.427129\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110438; batch adversarial loss: 0.424628\n",
      "epoch 55; iter: 0; batch classifier loss: 0.129509; batch adversarial loss: 0.405625\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101898; batch adversarial loss: 0.381417\n",
      "epoch 57; iter: 0; batch classifier loss: 0.121085; batch adversarial loss: 0.536810\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080919; batch adversarial loss: 0.471892\n",
      "epoch 59; iter: 0; batch classifier loss: 0.122126; batch adversarial loss: 0.525948\n",
      "epoch 60; iter: 0; batch classifier loss: 0.101419; batch adversarial loss: 0.488795\n",
      "epoch 61; iter: 0; batch classifier loss: 0.132354; batch adversarial loss: 0.510104\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082285; batch adversarial loss: 0.430276\n",
      "epoch 63; iter: 0; batch classifier loss: 0.133640; batch adversarial loss: 0.504898\n",
      "epoch 64; iter: 0; batch classifier loss: 0.168932; batch adversarial loss: 0.496626\n",
      "epoch 65; iter: 0; batch classifier loss: 0.093105; batch adversarial loss: 0.457374\n",
      "epoch 66; iter: 0; batch classifier loss: 0.090946; batch adversarial loss: 0.447945\n",
      "epoch 67; iter: 0; batch classifier loss: 0.123018; batch adversarial loss: 0.395473\n",
      "epoch 68; iter: 0; batch classifier loss: 0.095811; batch adversarial loss: 0.463470\n",
      "epoch 69; iter: 0; batch classifier loss: 0.171645; batch adversarial loss: 0.389361\n",
      "epoch 70; iter: 0; batch classifier loss: 0.130111; batch adversarial loss: 0.426763\n",
      "epoch 71; iter: 0; batch classifier loss: 0.151778; batch adversarial loss: 0.490186\n",
      "epoch 72; iter: 0; batch classifier loss: 0.116863; batch adversarial loss: 0.459123\n",
      "epoch 73; iter: 0; batch classifier loss: 0.094279; batch adversarial loss: 0.554339\n",
      "epoch 74; iter: 0; batch classifier loss: 0.102452; batch adversarial loss: 0.450741\n",
      "epoch 75; iter: 0; batch classifier loss: 0.103972; batch adversarial loss: 0.483194\n",
      "epoch 76; iter: 0; batch classifier loss: 0.154653; batch adversarial loss: 0.386204\n",
      "epoch 77; iter: 0; batch classifier loss: 0.117367; batch adversarial loss: 0.438372\n",
      "epoch 78; iter: 0; batch classifier loss: 0.153711; batch adversarial loss: 0.513975\n",
      "epoch 79; iter: 0; batch classifier loss: 0.178727; batch adversarial loss: 0.372497\n",
      "epoch 80; iter: 0; batch classifier loss: 0.140427; batch adversarial loss: 0.430658\n",
      "epoch 81; iter: 0; batch classifier loss: 0.095173; batch adversarial loss: 0.425818\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090582; batch adversarial loss: 0.542210\n",
      "epoch 83; iter: 0; batch classifier loss: 0.123395; batch adversarial loss: 0.505434\n",
      "epoch 84; iter: 0; batch classifier loss: 0.103308; batch adversarial loss: 0.469981\n",
      "epoch 85; iter: 0; batch classifier loss: 0.124250; batch adversarial loss: 0.411570\n",
      "epoch 86; iter: 0; batch classifier loss: 0.140563; batch adversarial loss: 0.516053\n",
      "epoch 87; iter: 0; batch classifier loss: 0.157186; batch adversarial loss: 0.409483\n",
      "epoch 88; iter: 0; batch classifier loss: 0.116462; batch adversarial loss: 0.413180\n",
      "epoch 89; iter: 0; batch classifier loss: 0.089712; batch adversarial loss: 0.523641\n",
      "epoch 90; iter: 0; batch classifier loss: 0.109479; batch adversarial loss: 0.570987\n",
      "epoch 91; iter: 0; batch classifier loss: 0.099716; batch adversarial loss: 0.389610\n",
      "epoch 92; iter: 0; batch classifier loss: 0.126508; batch adversarial loss: 0.435529\n",
      "epoch 93; iter: 0; batch classifier loss: 0.136871; batch adversarial loss: 0.579013\n",
      "epoch 94; iter: 0; batch classifier loss: 0.064223; batch adversarial loss: 0.500207\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087000; batch adversarial loss: 0.405176\n",
      "epoch 96; iter: 0; batch classifier loss: 0.084437; batch adversarial loss: 0.476598\n",
      "epoch 97; iter: 0; batch classifier loss: 0.086740; batch adversarial loss: 0.511874\n",
      "epoch 98; iter: 0; batch classifier loss: 0.112240; batch adversarial loss: 0.445453\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071807; batch adversarial loss: 0.506377\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062454; batch adversarial loss: 0.487450\n",
      "epoch 101; iter: 0; batch classifier loss: 0.067491; batch adversarial loss: 0.417146\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050678; batch adversarial loss: 0.487911\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046327; batch adversarial loss: 0.485229\n",
      "epoch 104; iter: 0; batch classifier loss: 0.111254; batch adversarial loss: 0.436595\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059766; batch adversarial loss: 0.497214\n",
      "epoch 106; iter: 0; batch classifier loss: 0.064330; batch adversarial loss: 0.544774\n",
      "epoch 107; iter: 0; batch classifier loss: 0.054910; batch adversarial loss: 0.578721\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052403; batch adversarial loss: 0.539466\n",
      "epoch 109; iter: 0; batch classifier loss: 0.076038; batch adversarial loss: 0.406952\n",
      "epoch 110; iter: 0; batch classifier loss: 0.062263; batch adversarial loss: 0.408026\n",
      "epoch 111; iter: 0; batch classifier loss: 0.075029; batch adversarial loss: 0.414588\n",
      "epoch 112; iter: 0; batch classifier loss: 0.060931; batch adversarial loss: 0.507772\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052568; batch adversarial loss: 0.421465\n",
      "epoch 114; iter: 0; batch classifier loss: 0.086084; batch adversarial loss: 0.438404\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044540; batch adversarial loss: 0.382077\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053247; batch adversarial loss: 0.414642\n",
      "epoch 117; iter: 0; batch classifier loss: 0.063036; batch adversarial loss: 0.453127\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039834; batch adversarial loss: 0.539057\n",
      "epoch 119; iter: 0; batch classifier loss: 0.078512; batch adversarial loss: 0.478269\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036592; batch adversarial loss: 0.444037\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035639; batch adversarial loss: 0.518894\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059269; batch adversarial loss: 0.446796\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039297; batch adversarial loss: 0.501889\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054459; batch adversarial loss: 0.488657\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037845; batch adversarial loss: 0.469591\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048074; batch adversarial loss: 0.433025\n",
      "epoch 127; iter: 0; batch classifier loss: 0.073668; batch adversarial loss: 0.455394\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032120; batch adversarial loss: 0.435676\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037885; batch adversarial loss: 0.425766\n",
      "epoch 130; iter: 0; batch classifier loss: 0.060305; batch adversarial loss: 0.485076\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042550; batch adversarial loss: 0.413662\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035791; batch adversarial loss: 0.368756\n",
      "epoch 133; iter: 0; batch classifier loss: 0.047505; batch adversarial loss: 0.482067\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052943; batch adversarial loss: 0.453204\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023662; batch adversarial loss: 0.443340\n",
      "epoch 136; iter: 0; batch classifier loss: 0.070555; batch adversarial loss: 0.425178\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026203; batch adversarial loss: 0.496178\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027518; batch adversarial loss: 0.465236\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040522; batch adversarial loss: 0.474352\n",
      "epoch 140; iter: 0; batch classifier loss: 0.059594; batch adversarial loss: 0.472035\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053545; batch adversarial loss: 0.442968\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021007; batch adversarial loss: 0.525332\n",
      "epoch 143; iter: 0; batch classifier loss: 0.058627; batch adversarial loss: 0.533756\n",
      "epoch 144; iter: 0; batch classifier loss: 0.053165; batch adversarial loss: 0.514012\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026860; batch adversarial loss: 0.342803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.051555; batch adversarial loss: 0.414171\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028158; batch adversarial loss: 0.403639\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039759; batch adversarial loss: 0.456825\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039882; batch adversarial loss: 0.457213\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023219; batch adversarial loss: 0.476908\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029259; batch adversarial loss: 0.430078\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029116; batch adversarial loss: 0.499163\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030370; batch adversarial loss: 0.493822\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026959; batch adversarial loss: 0.477588\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049628; batch adversarial loss: 0.421985\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040741; batch adversarial loss: 0.363934\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013149; batch adversarial loss: 0.489271\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011868; batch adversarial loss: 0.517012\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018259; batch adversarial loss: 0.484133\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022080; batch adversarial loss: 0.383850\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024847; batch adversarial loss: 0.360167\n",
      "epoch 162; iter: 0; batch classifier loss: 0.052855; batch adversarial loss: 0.401315\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022359; batch adversarial loss: 0.554116\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031024; batch adversarial loss: 0.545982\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018800; batch adversarial loss: 0.465769\n",
      "epoch 166; iter: 0; batch classifier loss: 0.003729; batch adversarial loss: 0.336357\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031116; batch adversarial loss: 0.438537\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035894; batch adversarial loss: 0.438796\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022657; batch adversarial loss: 0.385247\n",
      "epoch 170; iter: 0; batch classifier loss: 0.054781; batch adversarial loss: 0.413522\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030708; batch adversarial loss: 0.404124\n",
      "epoch 172; iter: 0; batch classifier loss: 0.043760; batch adversarial loss: 0.442330\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024567; batch adversarial loss: 0.448785\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011899; batch adversarial loss: 0.586953\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032122; batch adversarial loss: 0.498000\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014683; batch adversarial loss: 0.400144\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015598; batch adversarial loss: 0.563760\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035139; batch adversarial loss: 0.493487\n",
      "epoch 179; iter: 0; batch classifier loss: 0.005082; batch adversarial loss: 0.466640\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011087; batch adversarial loss: 0.420694\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010997; batch adversarial loss: 0.516088\n",
      "epoch 182; iter: 0; batch classifier loss: 0.003169; batch adversarial loss: 0.504843\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014291; batch adversarial loss: 0.464721\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020248; batch adversarial loss: 0.528958\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026512; batch adversarial loss: 0.471838\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021836; batch adversarial loss: 0.439346\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035797; batch adversarial loss: 0.554784\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014664; batch adversarial loss: 0.526532\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027870; batch adversarial loss: 0.420954\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018725; batch adversarial loss: 0.422511\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020962; batch adversarial loss: 0.487461\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017583; batch adversarial loss: 0.496094\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019138; batch adversarial loss: 0.358049\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018298; batch adversarial loss: 0.598867\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031529; batch adversarial loss: 0.518902\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008683; batch adversarial loss: 0.471959\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015666; batch adversarial loss: 0.452954\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012600; batch adversarial loss: 0.456820\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033976; batch adversarial loss: 0.501500\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672498; batch adversarial loss: 0.680225\n",
      "epoch 1; iter: 0; batch classifier loss: 0.496500; batch adversarial loss: 0.654234\n",
      "epoch 2; iter: 0; batch classifier loss: 0.354704; batch adversarial loss: 0.632467\n",
      "epoch 3; iter: 0; batch classifier loss: 0.435255; batch adversarial loss: 0.613123\n",
      "epoch 4; iter: 0; batch classifier loss: 0.423265; batch adversarial loss: 0.606438\n",
      "epoch 5; iter: 0; batch classifier loss: 0.468870; batch adversarial loss: 0.571518\n",
      "epoch 6; iter: 0; batch classifier loss: 0.517990; batch adversarial loss: 0.610791\n",
      "epoch 7; iter: 0; batch classifier loss: 0.568280; batch adversarial loss: 0.549901\n",
      "epoch 8; iter: 0; batch classifier loss: 0.420276; batch adversarial loss: 0.553870\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416006; batch adversarial loss: 0.553223\n",
      "epoch 10; iter: 0; batch classifier loss: 0.390058; batch adversarial loss: 0.552439\n",
      "epoch 11; iter: 0; batch classifier loss: 0.409048; batch adversarial loss: 0.509438\n",
      "epoch 12; iter: 0; batch classifier loss: 0.408539; batch adversarial loss: 0.502478\n",
      "epoch 13; iter: 0; batch classifier loss: 0.333033; batch adversarial loss: 0.532215\n",
      "epoch 14; iter: 0; batch classifier loss: 0.381692; batch adversarial loss: 0.487064\n",
      "epoch 15; iter: 0; batch classifier loss: 0.303857; batch adversarial loss: 0.456887\n",
      "epoch 16; iter: 0; batch classifier loss: 0.331065; batch adversarial loss: 0.510242\n",
      "epoch 17; iter: 0; batch classifier loss: 0.333441; batch adversarial loss: 0.536985\n",
      "epoch 18; iter: 0; batch classifier loss: 0.294922; batch adversarial loss: 0.474908\n",
      "epoch 19; iter: 0; batch classifier loss: 0.279971; batch adversarial loss: 0.434639\n",
      "epoch 20; iter: 0; batch classifier loss: 0.247199; batch adversarial loss: 0.556013\n",
      "epoch 21; iter: 0; batch classifier loss: 0.217881; batch adversarial loss: 0.465652\n",
      "epoch 22; iter: 0; batch classifier loss: 0.204769; batch adversarial loss: 0.529808\n",
      "epoch 23; iter: 0; batch classifier loss: 0.278859; batch adversarial loss: 0.496784\n",
      "epoch 24; iter: 0; batch classifier loss: 0.268669; batch adversarial loss: 0.571396\n",
      "epoch 25; iter: 0; batch classifier loss: 0.210889; batch adversarial loss: 0.538313\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180765; batch adversarial loss: 0.460342\n",
      "epoch 27; iter: 0; batch classifier loss: 0.187330; batch adversarial loss: 0.516207\n",
      "epoch 28; iter: 0; batch classifier loss: 0.187383; batch adversarial loss: 0.448581\n",
      "epoch 29; iter: 0; batch classifier loss: 0.186596; batch adversarial loss: 0.486623\n",
      "epoch 30; iter: 0; batch classifier loss: 0.163811; batch adversarial loss: 0.492802\n",
      "epoch 31; iter: 0; batch classifier loss: 0.157296; batch adversarial loss: 0.432015\n",
      "epoch 32; iter: 0; batch classifier loss: 0.252508; batch adversarial loss: 0.475713\n",
      "epoch 33; iter: 0; batch classifier loss: 0.164838; batch adversarial loss: 0.479794\n",
      "epoch 34; iter: 0; batch classifier loss: 0.187440; batch adversarial loss: 0.490037\n",
      "epoch 35; iter: 0; batch classifier loss: 0.151294; batch adversarial loss: 0.553899\n",
      "epoch 36; iter: 0; batch classifier loss: 0.163495; batch adversarial loss: 0.417402\n",
      "epoch 37; iter: 0; batch classifier loss: 0.154227; batch adversarial loss: 0.385656\n",
      "epoch 38; iter: 0; batch classifier loss: 0.179378; batch adversarial loss: 0.501703\n",
      "epoch 39; iter: 0; batch classifier loss: 0.216092; batch adversarial loss: 0.558195\n",
      "epoch 40; iter: 0; batch classifier loss: 0.248022; batch adversarial loss: 0.429782\n",
      "epoch 41; iter: 0; batch classifier loss: 0.181659; batch adversarial loss: 0.458706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.178715; batch adversarial loss: 0.394839\n",
      "epoch 43; iter: 0; batch classifier loss: 0.204678; batch adversarial loss: 0.421139\n",
      "epoch 44; iter: 0; batch classifier loss: 0.217902; batch adversarial loss: 0.427637\n",
      "epoch 45; iter: 0; batch classifier loss: 0.128853; batch adversarial loss: 0.502423\n",
      "epoch 46; iter: 0; batch classifier loss: 0.210665; batch adversarial loss: 0.553044\n",
      "epoch 47; iter: 0; batch classifier loss: 0.187785; batch adversarial loss: 0.474384\n",
      "epoch 48; iter: 0; batch classifier loss: 0.236199; batch adversarial loss: 0.450518\n",
      "epoch 49; iter: 0; batch classifier loss: 0.202830; batch adversarial loss: 0.473990\n",
      "epoch 50; iter: 0; batch classifier loss: 0.173379; batch adversarial loss: 0.466160\n",
      "epoch 51; iter: 0; batch classifier loss: 0.209076; batch adversarial loss: 0.541221\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161193; batch adversarial loss: 0.502407\n",
      "epoch 53; iter: 0; batch classifier loss: 0.124010; batch adversarial loss: 0.460692\n",
      "epoch 54; iter: 0; batch classifier loss: 0.185344; batch adversarial loss: 0.484415\n",
      "epoch 55; iter: 0; batch classifier loss: 0.193354; batch adversarial loss: 0.399618\n",
      "epoch 56; iter: 0; batch classifier loss: 0.193982; batch adversarial loss: 0.497761\n",
      "epoch 57; iter: 0; batch classifier loss: 0.154609; batch adversarial loss: 0.546031\n",
      "epoch 58; iter: 0; batch classifier loss: 0.180197; batch adversarial loss: 0.425525\n",
      "epoch 59; iter: 0; batch classifier loss: 0.187497; batch adversarial loss: 0.398613\n",
      "epoch 60; iter: 0; batch classifier loss: 0.204604; batch adversarial loss: 0.440278\n",
      "epoch 61; iter: 0; batch classifier loss: 0.206067; batch adversarial loss: 0.527294\n",
      "epoch 62; iter: 0; batch classifier loss: 0.145170; batch adversarial loss: 0.485463\n",
      "epoch 63; iter: 0; batch classifier loss: 0.250116; batch adversarial loss: 0.479913\n",
      "epoch 64; iter: 0; batch classifier loss: 0.215515; batch adversarial loss: 0.457671\n",
      "epoch 65; iter: 0; batch classifier loss: 0.160873; batch adversarial loss: 0.342621\n",
      "epoch 66; iter: 0; batch classifier loss: 0.207186; batch adversarial loss: 0.455300\n",
      "epoch 67; iter: 0; batch classifier loss: 0.214855; batch adversarial loss: 0.445618\n",
      "epoch 68; iter: 0; batch classifier loss: 0.164681; batch adversarial loss: 0.509932\n",
      "epoch 69; iter: 0; batch classifier loss: 0.175218; batch adversarial loss: 0.478980\n",
      "epoch 70; iter: 0; batch classifier loss: 0.213573; batch adversarial loss: 0.424309\n",
      "epoch 71; iter: 0; batch classifier loss: 0.232860; batch adversarial loss: 0.372703\n",
      "epoch 72; iter: 0; batch classifier loss: 0.159622; batch adversarial loss: 0.466347\n",
      "epoch 73; iter: 0; batch classifier loss: 0.171374; batch adversarial loss: 0.565291\n",
      "epoch 74; iter: 0; batch classifier loss: 0.158587; batch adversarial loss: 0.518061\n",
      "epoch 75; iter: 0; batch classifier loss: 0.174228; batch adversarial loss: 0.491119\n",
      "epoch 76; iter: 0; batch classifier loss: 0.150927; batch adversarial loss: 0.458906\n",
      "epoch 77; iter: 0; batch classifier loss: 0.144481; batch adversarial loss: 0.588397\n",
      "epoch 78; iter: 0; batch classifier loss: 0.108415; batch adversarial loss: 0.424936\n",
      "epoch 79; iter: 0; batch classifier loss: 0.115623; batch adversarial loss: 0.531649\n",
      "epoch 80; iter: 0; batch classifier loss: 0.129235; batch adversarial loss: 0.416629\n",
      "epoch 81; iter: 0; batch classifier loss: 0.106255; batch adversarial loss: 0.511010\n",
      "epoch 82; iter: 0; batch classifier loss: 0.069201; batch adversarial loss: 0.451990\n",
      "epoch 83; iter: 0; batch classifier loss: 0.088898; batch adversarial loss: 0.436748\n",
      "epoch 84; iter: 0; batch classifier loss: 0.093365; batch adversarial loss: 0.545055\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076757; batch adversarial loss: 0.511080\n",
      "epoch 86; iter: 0; batch classifier loss: 0.103297; batch adversarial loss: 0.506915\n",
      "epoch 87; iter: 0; batch classifier loss: 0.095427; batch adversarial loss: 0.498444\n",
      "epoch 88; iter: 0; batch classifier loss: 0.056411; batch adversarial loss: 0.524083\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042755; batch adversarial loss: 0.483647\n",
      "epoch 90; iter: 0; batch classifier loss: 0.074427; batch adversarial loss: 0.454333\n",
      "epoch 91; iter: 0; batch classifier loss: 0.084569; batch adversarial loss: 0.343707\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066270; batch adversarial loss: 0.338613\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071354; batch adversarial loss: 0.454158\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047576; batch adversarial loss: 0.445867\n",
      "epoch 95; iter: 0; batch classifier loss: 0.061397; batch adversarial loss: 0.446102\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082095; batch adversarial loss: 0.506622\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064067; batch adversarial loss: 0.440449\n",
      "epoch 98; iter: 0; batch classifier loss: 0.065763; batch adversarial loss: 0.410263\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059239; batch adversarial loss: 0.409705\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044034; batch adversarial loss: 0.455814\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057491; batch adversarial loss: 0.420137\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063636; batch adversarial loss: 0.576462\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032575; batch adversarial loss: 0.470077\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050576; batch adversarial loss: 0.469312\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051501; batch adversarial loss: 0.535427\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062517; batch adversarial loss: 0.363099\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037418; batch adversarial loss: 0.574283\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028610; batch adversarial loss: 0.482506\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067534; batch adversarial loss: 0.475769\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043471; batch adversarial loss: 0.511395\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036425; batch adversarial loss: 0.532851\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075791; batch adversarial loss: 0.358005\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057062; batch adversarial loss: 0.443878\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061230; batch adversarial loss: 0.408747\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053576; batch adversarial loss: 0.385293\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029776; batch adversarial loss: 0.481834\n",
      "epoch 117; iter: 0; batch classifier loss: 0.019448; batch adversarial loss: 0.487458\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039511; batch adversarial loss: 0.466077\n",
      "epoch 119; iter: 0; batch classifier loss: 0.052167; batch adversarial loss: 0.397660\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032204; batch adversarial loss: 0.456032\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027130; batch adversarial loss: 0.517539\n",
      "epoch 122; iter: 0; batch classifier loss: 0.061029; batch adversarial loss: 0.503141\n",
      "epoch 123; iter: 0; batch classifier loss: 0.052152; batch adversarial loss: 0.439483\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023195; batch adversarial loss: 0.459851\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049046; batch adversarial loss: 0.429804\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037458; batch adversarial loss: 0.542114\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028274; batch adversarial loss: 0.444486\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026424; batch adversarial loss: 0.466794\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045295; batch adversarial loss: 0.397439\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026961; batch adversarial loss: 0.530197\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018864; batch adversarial loss: 0.402686\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025919; batch adversarial loss: 0.491744\n",
      "epoch 133; iter: 0; batch classifier loss: 0.048157; batch adversarial loss: 0.320641\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043112; batch adversarial loss: 0.426489\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023264; batch adversarial loss: 0.522955\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022332; batch adversarial loss: 0.432916\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017141; batch adversarial loss: 0.463352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.025105; batch adversarial loss: 0.545621\n",
      "epoch 139; iter: 0; batch classifier loss: 0.063332; batch adversarial loss: 0.417795\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027949; batch adversarial loss: 0.390072\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032427; batch adversarial loss: 0.461920\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031150; batch adversarial loss: 0.566615\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034842; batch adversarial loss: 0.456839\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028738; batch adversarial loss: 0.413781\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022669; batch adversarial loss: 0.477844\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028197; batch adversarial loss: 0.411964\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024008; batch adversarial loss: 0.467673\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020512; batch adversarial loss: 0.414731\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030419; batch adversarial loss: 0.479337\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020767; batch adversarial loss: 0.474853\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020216; batch adversarial loss: 0.432158\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013173; batch adversarial loss: 0.451699\n",
      "epoch 153; iter: 0; batch classifier loss: 0.073610; batch adversarial loss: 0.501588\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016291; batch adversarial loss: 0.548576\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023275; batch adversarial loss: 0.506442\n",
      "epoch 156; iter: 0; batch classifier loss: 0.054508; batch adversarial loss: 0.395932\n",
      "epoch 157; iter: 0; batch classifier loss: 0.058218; batch adversarial loss: 0.415792\n",
      "epoch 158; iter: 0; batch classifier loss: 0.051267; batch adversarial loss: 0.398220\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026633; batch adversarial loss: 0.380631\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010406; batch adversarial loss: 0.465606\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022050; batch adversarial loss: 0.417013\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030420; batch adversarial loss: 0.492522\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032490; batch adversarial loss: 0.384846\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012928; batch adversarial loss: 0.559116\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016198; batch adversarial loss: 0.406286\n",
      "epoch 166; iter: 0; batch classifier loss: 0.043573; batch adversarial loss: 0.487070\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017171; batch adversarial loss: 0.423338\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035290; batch adversarial loss: 0.400553\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027744; batch adversarial loss: 0.444024\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018568; batch adversarial loss: 0.581044\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027657; batch adversarial loss: 0.471406\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011117; batch adversarial loss: 0.485923\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025279; batch adversarial loss: 0.390024\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019255; batch adversarial loss: 0.561685\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032747; batch adversarial loss: 0.389624\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010754; batch adversarial loss: 0.428091\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023932; batch adversarial loss: 0.547668\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012834; batch adversarial loss: 0.458815\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021789; batch adversarial loss: 0.397409\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020088; batch adversarial loss: 0.558324\n",
      "epoch 181; iter: 0; batch classifier loss: 0.042657; batch adversarial loss: 0.475924\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016832; batch adversarial loss: 0.475360\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006153; batch adversarial loss: 0.390747\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020556; batch adversarial loss: 0.591715\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032114; batch adversarial loss: 0.439272\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016907; batch adversarial loss: 0.499522\n",
      "epoch 187; iter: 0; batch classifier loss: 0.004246; batch adversarial loss: 0.452985\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025813; batch adversarial loss: 0.440252\n",
      "epoch 189; iter: 0; batch classifier loss: 0.037301; batch adversarial loss: 0.464686\n",
      "epoch 190; iter: 0; batch classifier loss: 0.003044; batch adversarial loss: 0.481611\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009171; batch adversarial loss: 0.450377\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023853; batch adversarial loss: 0.459812\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032693; batch adversarial loss: 0.440334\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021705; batch adversarial loss: 0.480420\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029930; batch adversarial loss: 0.505530\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023057; batch adversarial loss: 0.499185\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016342; batch adversarial loss: 0.390377\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013890; batch adversarial loss: 0.438403\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011344; batch adversarial loss: 0.475369\n",
      "epoch 0; iter: 0; batch classifier loss: 0.652998; batch adversarial loss: 0.653686\n",
      "epoch 1; iter: 0; batch classifier loss: 0.440182; batch adversarial loss: 0.636012\n",
      "epoch 2; iter: 0; batch classifier loss: 0.399900; batch adversarial loss: 0.602621\n",
      "epoch 3; iter: 0; batch classifier loss: 0.313926; batch adversarial loss: 0.615712\n",
      "epoch 4; iter: 0; batch classifier loss: 0.318844; batch adversarial loss: 0.545386\n",
      "epoch 5; iter: 0; batch classifier loss: 0.315848; batch adversarial loss: 0.560203\n",
      "epoch 6; iter: 0; batch classifier loss: 0.300721; batch adversarial loss: 0.553117\n",
      "epoch 7; iter: 0; batch classifier loss: 0.256344; batch adversarial loss: 0.534202\n",
      "epoch 8; iter: 0; batch classifier loss: 0.275850; batch adversarial loss: 0.507795\n",
      "epoch 9; iter: 0; batch classifier loss: 0.216686; batch adversarial loss: 0.472866\n",
      "epoch 10; iter: 0; batch classifier loss: 0.199064; batch adversarial loss: 0.500836\n",
      "epoch 11; iter: 0; batch classifier loss: 0.233773; batch adversarial loss: 0.482568\n",
      "epoch 12; iter: 0; batch classifier loss: 0.209135; batch adversarial loss: 0.463795\n",
      "epoch 13; iter: 0; batch classifier loss: 0.169346; batch adversarial loss: 0.525167\n",
      "epoch 14; iter: 0; batch classifier loss: 0.184396; batch adversarial loss: 0.494073\n",
      "epoch 15; iter: 0; batch classifier loss: 0.184416; batch adversarial loss: 0.459238\n",
      "epoch 16; iter: 0; batch classifier loss: 0.200481; batch adversarial loss: 0.435815\n",
      "epoch 17; iter: 0; batch classifier loss: 0.155489; batch adversarial loss: 0.574594\n",
      "epoch 18; iter: 0; batch classifier loss: 0.183464; batch adversarial loss: 0.483579\n",
      "epoch 19; iter: 0; batch classifier loss: 0.225558; batch adversarial loss: 0.520564\n",
      "epoch 20; iter: 0; batch classifier loss: 0.191175; batch adversarial loss: 0.547122\n",
      "epoch 21; iter: 0; batch classifier loss: 0.146183; batch adversarial loss: 0.498612\n",
      "epoch 22; iter: 0; batch classifier loss: 0.140406; batch adversarial loss: 0.557200\n",
      "epoch 23; iter: 0; batch classifier loss: 0.197870; batch adversarial loss: 0.494139\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195537; batch adversarial loss: 0.571322\n",
      "epoch 25; iter: 0; batch classifier loss: 0.164814; batch adversarial loss: 0.472834\n",
      "epoch 26; iter: 0; batch classifier loss: 0.198174; batch adversarial loss: 0.547856\n",
      "epoch 27; iter: 0; batch classifier loss: 0.193064; batch adversarial loss: 0.550793\n",
      "epoch 28; iter: 0; batch classifier loss: 0.227737; batch adversarial loss: 0.549975\n",
      "epoch 29; iter: 0; batch classifier loss: 0.233408; batch adversarial loss: 0.513778\n",
      "epoch 30; iter: 0; batch classifier loss: 0.220383; batch adversarial loss: 0.552844\n",
      "epoch 31; iter: 0; batch classifier loss: 0.223606; batch adversarial loss: 0.427866\n",
      "epoch 32; iter: 0; batch classifier loss: 0.204942; batch adversarial loss: 0.460317\n",
      "epoch 33; iter: 0; batch classifier loss: 0.287448; batch adversarial loss: 0.505208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.201033; batch adversarial loss: 0.447153\n",
      "epoch 35; iter: 0; batch classifier loss: 0.222514; batch adversarial loss: 0.494243\n",
      "epoch 36; iter: 0; batch classifier loss: 0.297289; batch adversarial loss: 0.516092\n",
      "epoch 37; iter: 0; batch classifier loss: 0.229044; batch adversarial loss: 0.467328\n",
      "epoch 38; iter: 0; batch classifier loss: 0.207500; batch adversarial loss: 0.557596\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106783; batch adversarial loss: 0.380838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.139878; batch adversarial loss: 0.424067\n",
      "epoch 41; iter: 0; batch classifier loss: 0.133695; batch adversarial loss: 0.428873\n",
      "epoch 42; iter: 0; batch classifier loss: 0.080261; batch adversarial loss: 0.473159\n",
      "epoch 43; iter: 0; batch classifier loss: 0.046559; batch adversarial loss: 0.506440\n",
      "epoch 44; iter: 0; batch classifier loss: 0.093681; batch adversarial loss: 0.369262\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099859; batch adversarial loss: 0.401766\n",
      "epoch 46; iter: 0; batch classifier loss: 0.065176; batch adversarial loss: 0.460134\n",
      "epoch 47; iter: 0; batch classifier loss: 0.094753; batch adversarial loss: 0.500567\n",
      "epoch 48; iter: 0; batch classifier loss: 0.052730; batch adversarial loss: 0.511047\n",
      "epoch 49; iter: 0; batch classifier loss: 0.100604; batch adversarial loss: 0.556627\n",
      "epoch 50; iter: 0; batch classifier loss: 0.068559; batch adversarial loss: 0.459819\n",
      "epoch 51; iter: 0; batch classifier loss: 0.093483; batch adversarial loss: 0.493008\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082487; batch adversarial loss: 0.399290\n",
      "epoch 53; iter: 0; batch classifier loss: 0.063076; batch adversarial loss: 0.459702\n",
      "epoch 54; iter: 0; batch classifier loss: 0.057390; batch adversarial loss: 0.503007\n",
      "epoch 55; iter: 0; batch classifier loss: 0.070732; batch adversarial loss: 0.457584\n",
      "epoch 56; iter: 0; batch classifier loss: 0.070010; batch adversarial loss: 0.527798\n",
      "epoch 57; iter: 0; batch classifier loss: 0.078504; batch adversarial loss: 0.508365\n",
      "epoch 58; iter: 0; batch classifier loss: 0.068720; batch adversarial loss: 0.519785\n",
      "epoch 59; iter: 0; batch classifier loss: 0.121166; batch adversarial loss: 0.465521\n",
      "epoch 60; iter: 0; batch classifier loss: 0.084681; batch adversarial loss: 0.466193\n",
      "epoch 61; iter: 0; batch classifier loss: 0.100511; batch adversarial loss: 0.437177\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101287; batch adversarial loss: 0.443073\n",
      "epoch 63; iter: 0; batch classifier loss: 0.117068; batch adversarial loss: 0.400021\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073395; batch adversarial loss: 0.463572\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110011; batch adversarial loss: 0.508666\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086096; batch adversarial loss: 0.411356\n",
      "epoch 67; iter: 0; batch classifier loss: 0.104981; batch adversarial loss: 0.579072\n",
      "epoch 68; iter: 0; batch classifier loss: 0.119624; batch adversarial loss: 0.500771\n",
      "epoch 69; iter: 0; batch classifier loss: 0.069102; batch adversarial loss: 0.482680\n",
      "epoch 70; iter: 0; batch classifier loss: 0.061826; batch adversarial loss: 0.497687\n",
      "epoch 71; iter: 0; batch classifier loss: 0.091448; batch adversarial loss: 0.472865\n",
      "epoch 72; iter: 0; batch classifier loss: 0.076579; batch adversarial loss: 0.456321\n",
      "epoch 73; iter: 0; batch classifier loss: 0.105257; batch adversarial loss: 0.509527\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066356; batch adversarial loss: 0.464798\n",
      "epoch 75; iter: 0; batch classifier loss: 0.053102; batch adversarial loss: 0.484103\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072946; batch adversarial loss: 0.526862\n",
      "epoch 77; iter: 0; batch classifier loss: 0.089046; batch adversarial loss: 0.398395\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079137; batch adversarial loss: 0.396719\n",
      "epoch 79; iter: 0; batch classifier loss: 0.039292; batch adversarial loss: 0.386174\n",
      "epoch 80; iter: 0; batch classifier loss: 0.064883; batch adversarial loss: 0.423564\n",
      "epoch 81; iter: 0; batch classifier loss: 0.111792; batch adversarial loss: 0.498389\n",
      "epoch 82; iter: 0; batch classifier loss: 0.093738; batch adversarial loss: 0.472317\n",
      "epoch 83; iter: 0; batch classifier loss: 0.096362; batch adversarial loss: 0.502009\n",
      "epoch 84; iter: 0; batch classifier loss: 0.093101; batch adversarial loss: 0.448318\n",
      "epoch 85; iter: 0; batch classifier loss: 0.066382; batch adversarial loss: 0.428460\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074250; batch adversarial loss: 0.426969\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059841; batch adversarial loss: 0.487463\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067635; batch adversarial loss: 0.440326\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073271; batch adversarial loss: 0.486781\n",
      "epoch 90; iter: 0; batch classifier loss: 0.069012; batch adversarial loss: 0.486442\n",
      "epoch 91; iter: 0; batch classifier loss: 0.030043; batch adversarial loss: 0.507940\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071480; batch adversarial loss: 0.411939\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063833; batch adversarial loss: 0.453682\n",
      "epoch 94; iter: 0; batch classifier loss: 0.089510; batch adversarial loss: 0.450614\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064603; batch adversarial loss: 0.403486\n",
      "epoch 96; iter: 0; batch classifier loss: 0.060350; batch adversarial loss: 0.371915\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073261; batch adversarial loss: 0.413898\n",
      "epoch 98; iter: 0; batch classifier loss: 0.060744; batch adversarial loss: 0.518918\n",
      "epoch 99; iter: 0; batch classifier loss: 0.079070; batch adversarial loss: 0.452712\n",
      "epoch 100; iter: 0; batch classifier loss: 0.082451; batch adversarial loss: 0.457590\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050557; batch adversarial loss: 0.403947\n",
      "epoch 102; iter: 0; batch classifier loss: 0.040923; batch adversarial loss: 0.362751\n",
      "epoch 103; iter: 0; batch classifier loss: 0.071147; batch adversarial loss: 0.478934\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063572; batch adversarial loss: 0.549177\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051324; batch adversarial loss: 0.573537\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046901; batch adversarial loss: 0.457663\n",
      "epoch 107; iter: 0; batch classifier loss: 0.071941; batch adversarial loss: 0.540118\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053406; batch adversarial loss: 0.431653\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029879; batch adversarial loss: 0.400044\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051946; batch adversarial loss: 0.369981\n",
      "epoch 111; iter: 0; batch classifier loss: 0.108101; batch adversarial loss: 0.366180\n",
      "epoch 112; iter: 0; batch classifier loss: 0.048383; batch adversarial loss: 0.402566\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054369; batch adversarial loss: 0.466482\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042738; batch adversarial loss: 0.525393\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053346; batch adversarial loss: 0.449427\n",
      "epoch 116; iter: 0; batch classifier loss: 0.012738; batch adversarial loss: 0.422197\n",
      "epoch 117; iter: 0; batch classifier loss: 0.091809; batch adversarial loss: 0.388804\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042308; batch adversarial loss: 0.426477\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040444; batch adversarial loss: 0.484010\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046927; batch adversarial loss: 0.455785\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036528; batch adversarial loss: 0.465897\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045071; batch adversarial loss: 0.612476\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046508; batch adversarial loss: 0.531900\n",
      "epoch 124; iter: 0; batch classifier loss: 0.071167; batch adversarial loss: 0.446174\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025076; batch adversarial loss: 0.514212\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046979; batch adversarial loss: 0.457639\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022124; batch adversarial loss: 0.478298\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043022; batch adversarial loss: 0.601718\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029473; batch adversarial loss: 0.512435\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040097; batch adversarial loss: 0.419692\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028918; batch adversarial loss: 0.479699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.034953; batch adversarial loss: 0.457195\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029753; batch adversarial loss: 0.489618\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048260; batch adversarial loss: 0.426148\n",
      "epoch 135; iter: 0; batch classifier loss: 0.015797; batch adversarial loss: 0.500797\n",
      "epoch 136; iter: 0; batch classifier loss: 0.045072; batch adversarial loss: 0.415387\n",
      "epoch 137; iter: 0; batch classifier loss: 0.047243; batch adversarial loss: 0.455113\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017611; batch adversarial loss: 0.548643\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039279; batch adversarial loss: 0.480211\n",
      "epoch 140; iter: 0; batch classifier loss: 0.101973; batch adversarial loss: 0.359707\n",
      "epoch 141; iter: 0; batch classifier loss: 0.059472; batch adversarial loss: 0.514555\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045320; batch adversarial loss: 0.452738\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051327; batch adversarial loss: 0.460438\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048003; batch adversarial loss: 0.422173\n",
      "epoch 145; iter: 0; batch classifier loss: 0.065861; batch adversarial loss: 0.527895\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034293; batch adversarial loss: 0.530667\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043956; batch adversarial loss: 0.491844\n",
      "epoch 148; iter: 0; batch classifier loss: 0.070813; batch adversarial loss: 0.499766\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036931; batch adversarial loss: 0.441434\n",
      "epoch 150; iter: 0; batch classifier loss: 0.056293; batch adversarial loss: 0.482917\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031372; batch adversarial loss: 0.456008\n",
      "epoch 152; iter: 0; batch classifier loss: 0.058798; batch adversarial loss: 0.513552\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029187; batch adversarial loss: 0.419288\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028417; batch adversarial loss: 0.474946\n",
      "epoch 155; iter: 0; batch classifier loss: 0.075259; batch adversarial loss: 0.486736\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026276; batch adversarial loss: 0.458900\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031486; batch adversarial loss: 0.506167\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024806; batch adversarial loss: 0.420608\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020292; batch adversarial loss: 0.550728\n",
      "epoch 160; iter: 0; batch classifier loss: 0.049744; batch adversarial loss: 0.408187\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029614; batch adversarial loss: 0.427458\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020977; batch adversarial loss: 0.447173\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029233; batch adversarial loss: 0.473147\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037483; batch adversarial loss: 0.386819\n",
      "epoch 165; iter: 0; batch classifier loss: 0.039008; batch adversarial loss: 0.410060\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013484; batch adversarial loss: 0.470158\n",
      "epoch 167; iter: 0; batch classifier loss: 0.056201; batch adversarial loss: 0.532110\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022364; batch adversarial loss: 0.519902\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034617; batch adversarial loss: 0.472592\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018184; batch adversarial loss: 0.440483\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016724; batch adversarial loss: 0.562374\n",
      "epoch 172; iter: 0; batch classifier loss: 0.064960; batch adversarial loss: 0.483880\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031445; batch adversarial loss: 0.420677\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018613; batch adversarial loss: 0.496801\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017985; batch adversarial loss: 0.596220\n",
      "epoch 176; iter: 0; batch classifier loss: 0.038355; batch adversarial loss: 0.363335\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017452; batch adversarial loss: 0.460082\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025795; batch adversarial loss: 0.418202\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020275; batch adversarial loss: 0.534391\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010229; batch adversarial loss: 0.462934\n",
      "epoch 181; iter: 0; batch classifier loss: 0.065676; batch adversarial loss: 0.409068\n",
      "epoch 182; iter: 0; batch classifier loss: 0.055339; batch adversarial loss: 0.487419\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034520; batch adversarial loss: 0.435848\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036634; batch adversarial loss: 0.404419\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018683; batch adversarial loss: 0.488521\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008650; batch adversarial loss: 0.383193\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017850; batch adversarial loss: 0.411811\n",
      "epoch 188; iter: 0; batch classifier loss: 0.065823; batch adversarial loss: 0.377157\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017719; batch adversarial loss: 0.515429\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030746; batch adversarial loss: 0.521401\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037232; batch adversarial loss: 0.394233\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025416; batch adversarial loss: 0.510801\n",
      "epoch 193; iter: 0; batch classifier loss: 0.034195; batch adversarial loss: 0.469056\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025876; batch adversarial loss: 0.413366\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014339; batch adversarial loss: 0.511601\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029372; batch adversarial loss: 0.488802\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015551; batch adversarial loss: 0.531541\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028730; batch adversarial loss: 0.507779\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033453; batch adversarial loss: 0.464225\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698900; batch adversarial loss: 0.811571\n",
      "epoch 1; iter: 0; batch classifier loss: 0.550117; batch adversarial loss: 0.786608\n",
      "epoch 2; iter: 0; batch classifier loss: 0.642336; batch adversarial loss: 0.734613\n",
      "epoch 3; iter: 0; batch classifier loss: 0.812857; batch adversarial loss: 0.713197\n",
      "epoch 4; iter: 0; batch classifier loss: 0.632156; batch adversarial loss: 0.635369\n",
      "epoch 5; iter: 0; batch classifier loss: 0.421053; batch adversarial loss: 0.562732\n",
      "epoch 6; iter: 0; batch classifier loss: 0.435961; batch adversarial loss: 0.545397\n",
      "epoch 7; iter: 0; batch classifier loss: 0.372803; batch adversarial loss: 0.537738\n",
      "epoch 8; iter: 0; batch classifier loss: 0.355959; batch adversarial loss: 0.532836\n",
      "epoch 9; iter: 0; batch classifier loss: 0.369588; batch adversarial loss: 0.515077\n",
      "epoch 10; iter: 0; batch classifier loss: 0.263884; batch adversarial loss: 0.500075\n",
      "epoch 11; iter: 0; batch classifier loss: 0.366510; batch adversarial loss: 0.453939\n",
      "epoch 12; iter: 0; batch classifier loss: 0.284053; batch adversarial loss: 0.495102\n",
      "epoch 13; iter: 0; batch classifier loss: 0.271891; batch adversarial loss: 0.525055\n",
      "epoch 14; iter: 0; batch classifier loss: 0.308955; batch adversarial loss: 0.478938\n",
      "epoch 15; iter: 0; batch classifier loss: 0.227621; batch adversarial loss: 0.492361\n",
      "epoch 16; iter: 0; batch classifier loss: 0.262013; batch adversarial loss: 0.513213\n",
      "epoch 17; iter: 0; batch classifier loss: 0.183573; batch adversarial loss: 0.488413\n",
      "epoch 18; iter: 0; batch classifier loss: 0.249750; batch adversarial loss: 0.467479\n",
      "epoch 19; iter: 0; batch classifier loss: 0.195954; batch adversarial loss: 0.523909\n",
      "epoch 20; iter: 0; batch classifier loss: 0.238894; batch adversarial loss: 0.520258\n",
      "epoch 21; iter: 0; batch classifier loss: 0.271809; batch adversarial loss: 0.454402\n",
      "epoch 22; iter: 0; batch classifier loss: 0.167459; batch adversarial loss: 0.440048\n",
      "epoch 23; iter: 0; batch classifier loss: 0.214342; batch adversarial loss: 0.442850\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194190; batch adversarial loss: 0.465569\n",
      "epoch 25; iter: 0; batch classifier loss: 0.147959; batch adversarial loss: 0.475610\n",
      "epoch 26; iter: 0; batch classifier loss: 0.161976; batch adversarial loss: 0.389550\n",
      "epoch 27; iter: 0; batch classifier loss: 0.178532; batch adversarial loss: 0.445202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.199596; batch adversarial loss: 0.476267\n",
      "epoch 29; iter: 0; batch classifier loss: 0.186072; batch adversarial loss: 0.501341\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138945; batch adversarial loss: 0.450931\n",
      "epoch 31; iter: 0; batch classifier loss: 0.185628; batch adversarial loss: 0.521105\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154322; batch adversarial loss: 0.481123\n",
      "epoch 33; iter: 0; batch classifier loss: 0.138609; batch adversarial loss: 0.473812\n",
      "epoch 34; iter: 0; batch classifier loss: 0.150951; batch adversarial loss: 0.385864\n",
      "epoch 35; iter: 0; batch classifier loss: 0.180851; batch adversarial loss: 0.415399\n",
      "epoch 36; iter: 0; batch classifier loss: 0.129713; batch adversarial loss: 0.373192\n",
      "epoch 37; iter: 0; batch classifier loss: 0.159448; batch adversarial loss: 0.423520\n",
      "epoch 38; iter: 0; batch classifier loss: 0.122246; batch adversarial loss: 0.435465\n",
      "epoch 39; iter: 0; batch classifier loss: 0.118932; batch adversarial loss: 0.390759\n",
      "epoch 40; iter: 0; batch classifier loss: 0.143346; batch adversarial loss: 0.452456\n",
      "epoch 41; iter: 0; batch classifier loss: 0.133500; batch adversarial loss: 0.474477\n",
      "epoch 42; iter: 0; batch classifier loss: 0.235687; batch adversarial loss: 0.431319\n",
      "epoch 43; iter: 0; batch classifier loss: 0.115490; batch adversarial loss: 0.444548\n",
      "epoch 44; iter: 0; batch classifier loss: 0.108478; batch adversarial loss: 0.440670\n",
      "epoch 45; iter: 0; batch classifier loss: 0.175446; batch adversarial loss: 0.481463\n",
      "epoch 46; iter: 0; batch classifier loss: 0.091611; batch adversarial loss: 0.388791\n",
      "epoch 47; iter: 0; batch classifier loss: 0.102127; batch adversarial loss: 0.450359\n",
      "epoch 48; iter: 0; batch classifier loss: 0.127311; batch adversarial loss: 0.365584\n",
      "epoch 49; iter: 0; batch classifier loss: 0.131000; batch adversarial loss: 0.470016\n",
      "epoch 50; iter: 0; batch classifier loss: 0.139025; batch adversarial loss: 0.416686\n",
      "epoch 51; iter: 0; batch classifier loss: 0.103004; batch adversarial loss: 0.423108\n",
      "epoch 52; iter: 0; batch classifier loss: 0.121907; batch adversarial loss: 0.401878\n",
      "epoch 53; iter: 0; batch classifier loss: 0.120749; batch adversarial loss: 0.430055\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112026; batch adversarial loss: 0.418674\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079236; batch adversarial loss: 0.488111\n",
      "epoch 56; iter: 0; batch classifier loss: 0.115667; batch adversarial loss: 0.457116\n",
      "epoch 57; iter: 0; batch classifier loss: 0.094460; batch adversarial loss: 0.429703\n",
      "epoch 58; iter: 0; batch classifier loss: 0.067734; batch adversarial loss: 0.464906\n",
      "epoch 59; iter: 0; batch classifier loss: 0.117829; batch adversarial loss: 0.469797\n",
      "epoch 60; iter: 0; batch classifier loss: 0.114275; batch adversarial loss: 0.511272\n",
      "epoch 61; iter: 0; batch classifier loss: 0.083576; batch adversarial loss: 0.454770\n",
      "epoch 62; iter: 0; batch classifier loss: 0.103471; batch adversarial loss: 0.335567\n",
      "epoch 63; iter: 0; batch classifier loss: 0.077652; batch adversarial loss: 0.497930\n",
      "epoch 64; iter: 0; batch classifier loss: 0.117522; batch adversarial loss: 0.479534\n",
      "epoch 65; iter: 0; batch classifier loss: 0.071305; batch adversarial loss: 0.506131\n",
      "epoch 66; iter: 0; batch classifier loss: 0.122843; batch adversarial loss: 0.387901\n",
      "epoch 67; iter: 0; batch classifier loss: 0.058780; batch adversarial loss: 0.474305\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061494; batch adversarial loss: 0.536514\n",
      "epoch 69; iter: 0; batch classifier loss: 0.067776; batch adversarial loss: 0.428094\n",
      "epoch 70; iter: 0; batch classifier loss: 0.050269; batch adversarial loss: 0.358529\n",
      "epoch 71; iter: 0; batch classifier loss: 0.087518; batch adversarial loss: 0.445809\n",
      "epoch 72; iter: 0; batch classifier loss: 0.111619; batch adversarial loss: 0.383217\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047185; batch adversarial loss: 0.446321\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054407; batch adversarial loss: 0.505551\n",
      "epoch 75; iter: 0; batch classifier loss: 0.053583; batch adversarial loss: 0.409448\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075155; batch adversarial loss: 0.464977\n",
      "epoch 77; iter: 0; batch classifier loss: 0.114430; batch adversarial loss: 0.456388\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072439; batch adversarial loss: 0.519998\n",
      "epoch 79; iter: 0; batch classifier loss: 0.112381; batch adversarial loss: 0.510070\n",
      "epoch 80; iter: 0; batch classifier loss: 0.037134; batch adversarial loss: 0.538224\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066780; batch adversarial loss: 0.436922\n",
      "epoch 82; iter: 0; batch classifier loss: 0.072142; batch adversarial loss: 0.386831\n",
      "epoch 83; iter: 0; batch classifier loss: 0.039394; batch adversarial loss: 0.331296\n",
      "epoch 84; iter: 0; batch classifier loss: 0.047587; batch adversarial loss: 0.348549\n",
      "epoch 85; iter: 0; batch classifier loss: 0.045833; batch adversarial loss: 0.463752\n",
      "epoch 86; iter: 0; batch classifier loss: 0.087647; batch adversarial loss: 0.432169\n",
      "epoch 87; iter: 0; batch classifier loss: 0.041158; batch adversarial loss: 0.523362\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041003; batch adversarial loss: 0.453110\n",
      "epoch 89; iter: 0; batch classifier loss: 0.029198; batch adversarial loss: 0.390101\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053045; batch adversarial loss: 0.531035\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075899; batch adversarial loss: 0.397800\n",
      "epoch 92; iter: 0; batch classifier loss: 0.094233; batch adversarial loss: 0.388609\n",
      "epoch 93; iter: 0; batch classifier loss: 0.034574; batch adversarial loss: 0.416983\n",
      "epoch 94; iter: 0; batch classifier loss: 0.069139; batch adversarial loss: 0.396905\n",
      "epoch 95; iter: 0; batch classifier loss: 0.061155; batch adversarial loss: 0.463407\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058161; batch adversarial loss: 0.450389\n",
      "epoch 97; iter: 0; batch classifier loss: 0.110665; batch adversarial loss: 0.401820\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046073; batch adversarial loss: 0.419128\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041081; batch adversarial loss: 0.524684\n",
      "epoch 100; iter: 0; batch classifier loss: 0.080071; batch adversarial loss: 0.473510\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051180; batch adversarial loss: 0.480575\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052583; batch adversarial loss: 0.420074\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054649; batch adversarial loss: 0.494205\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058678; batch adversarial loss: 0.401184\n",
      "epoch 105; iter: 0; batch classifier loss: 0.072035; batch adversarial loss: 0.330080\n",
      "epoch 106; iter: 0; batch classifier loss: 0.061699; batch adversarial loss: 0.386549\n",
      "epoch 107; iter: 0; batch classifier loss: 0.078471; batch adversarial loss: 0.433127\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044857; batch adversarial loss: 0.486652\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041477; batch adversarial loss: 0.477626\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028829; batch adversarial loss: 0.484070\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030604; batch adversarial loss: 0.392449\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038867; batch adversarial loss: 0.422270\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025565; batch adversarial loss: 0.455782\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033589; batch adversarial loss: 0.380348\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039791; batch adversarial loss: 0.537699\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052326; batch adversarial loss: 0.510492\n",
      "epoch 117; iter: 0; batch classifier loss: 0.015127; batch adversarial loss: 0.413219\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060080; batch adversarial loss: 0.462694\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021665; batch adversarial loss: 0.399598\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034518; batch adversarial loss: 0.483963\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043092; batch adversarial loss: 0.408628\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044408; batch adversarial loss: 0.394925\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021512; batch adversarial loss: 0.449156\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031019; batch adversarial loss: 0.463816\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026609; batch adversarial loss: 0.442163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.029936; batch adversarial loss: 0.477626\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026856; batch adversarial loss: 0.436990\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037399; batch adversarial loss: 0.447441\n",
      "epoch 129; iter: 0; batch classifier loss: 0.068838; batch adversarial loss: 0.392137\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032885; batch adversarial loss: 0.439030\n",
      "epoch 131; iter: 0; batch classifier loss: 0.016833; batch adversarial loss: 0.421592\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023700; batch adversarial loss: 0.447545\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022571; batch adversarial loss: 0.397896\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039758; batch adversarial loss: 0.392246\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042590; batch adversarial loss: 0.424879\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021237; batch adversarial loss: 0.478404\n",
      "epoch 137; iter: 0; batch classifier loss: 0.061233; batch adversarial loss: 0.375323\n",
      "epoch 138; iter: 0; batch classifier loss: 0.075030; batch adversarial loss: 0.477648\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040591; batch adversarial loss: 0.442146\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029126; batch adversarial loss: 0.459242\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044561; batch adversarial loss: 0.371783\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016424; batch adversarial loss: 0.453839\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025403; batch adversarial loss: 0.443235\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048454; batch adversarial loss: 0.493980\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026570; batch adversarial loss: 0.369593\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022473; batch adversarial loss: 0.466989\n",
      "epoch 147; iter: 0; batch classifier loss: 0.053577; batch adversarial loss: 0.447842\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018567; batch adversarial loss: 0.470555\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025432; batch adversarial loss: 0.394491\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015940; batch adversarial loss: 0.526811\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020608; batch adversarial loss: 0.404141\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037118; batch adversarial loss: 0.342819\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020440; batch adversarial loss: 0.438060\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041111; batch adversarial loss: 0.485966\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044353; batch adversarial loss: 0.506059\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021042; batch adversarial loss: 0.399004\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019140; batch adversarial loss: 0.394437\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018967; batch adversarial loss: 0.402483\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026634; batch adversarial loss: 0.401645\n",
      "epoch 160; iter: 0; batch classifier loss: 0.038951; batch adversarial loss: 0.338426\n",
      "epoch 161; iter: 0; batch classifier loss: 0.050031; batch adversarial loss: 0.411748\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027182; batch adversarial loss: 0.421074\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038092; batch adversarial loss: 0.352163\n",
      "epoch 164; iter: 0; batch classifier loss: 0.041487; batch adversarial loss: 0.533436\n",
      "epoch 165; iter: 0; batch classifier loss: 0.060971; batch adversarial loss: 0.410394\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034659; batch adversarial loss: 0.480076\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015306; batch adversarial loss: 0.361705\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013797; batch adversarial loss: 0.554766\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037223; batch adversarial loss: 0.420021\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016543; batch adversarial loss: 0.467599\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029123; batch adversarial loss: 0.493666\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015502; batch adversarial loss: 0.375238\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007663; batch adversarial loss: 0.393618\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032761; batch adversarial loss: 0.499030\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021368; batch adversarial loss: 0.367712\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024466; batch adversarial loss: 0.394677\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026842; batch adversarial loss: 0.537394\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014378; batch adversarial loss: 0.443623\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010024; batch adversarial loss: 0.410774\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018388; batch adversarial loss: 0.371360\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033306; batch adversarial loss: 0.374344\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021294; batch adversarial loss: 0.460057\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014622; batch adversarial loss: 0.406660\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037159; batch adversarial loss: 0.439340\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037534; batch adversarial loss: 0.497634\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013342; batch adversarial loss: 0.395045\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008729; batch adversarial loss: 0.407126\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041932; batch adversarial loss: 0.451648\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016380; batch adversarial loss: 0.443072\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008630; batch adversarial loss: 0.457740\n",
      "epoch 191; iter: 0; batch classifier loss: 0.058585; batch adversarial loss: 0.433324\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031891; batch adversarial loss: 0.489522\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009598; batch adversarial loss: 0.424609\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027809; batch adversarial loss: 0.403892\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013437; batch adversarial loss: 0.436656\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024037; batch adversarial loss: 0.478005\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026111; batch adversarial loss: 0.385391\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013146; batch adversarial loss: 0.483278\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021104; batch adversarial loss: 0.433628\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691711; batch adversarial loss: 0.526711\n",
      "epoch 1; iter: 0; batch classifier loss: 0.412019; batch adversarial loss: 0.582649\n",
      "epoch 2; iter: 0; batch classifier loss: 0.526120; batch adversarial loss: 0.577352\n",
      "epoch 3; iter: 0; batch classifier loss: 0.266864; batch adversarial loss: 0.594290\n",
      "epoch 4; iter: 0; batch classifier loss: 0.374276; batch adversarial loss: 0.606459\n",
      "epoch 5; iter: 0; batch classifier loss: 0.285942; batch adversarial loss: 0.559949\n",
      "epoch 6; iter: 0; batch classifier loss: 0.308817; batch adversarial loss: 0.496319\n",
      "epoch 7; iter: 0; batch classifier loss: 0.252925; batch adversarial loss: 0.589942\n",
      "epoch 8; iter: 0; batch classifier loss: 0.280172; batch adversarial loss: 0.489940\n",
      "epoch 9; iter: 0; batch classifier loss: 0.378411; batch adversarial loss: 0.503706\n",
      "epoch 10; iter: 0; batch classifier loss: 0.312644; batch adversarial loss: 0.483314\n",
      "epoch 11; iter: 0; batch classifier loss: 0.386008; batch adversarial loss: 0.533297\n",
      "epoch 12; iter: 0; batch classifier loss: 0.330403; batch adversarial loss: 0.546100\n",
      "epoch 13; iter: 0; batch classifier loss: 0.397535; batch adversarial loss: 0.502003\n",
      "epoch 14; iter: 0; batch classifier loss: 0.335790; batch adversarial loss: 0.476978\n",
      "epoch 15; iter: 0; batch classifier loss: 0.339480; batch adversarial loss: 0.544980\n",
      "epoch 16; iter: 0; batch classifier loss: 0.508474; batch adversarial loss: 0.459132\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504767; batch adversarial loss: 0.475293\n",
      "epoch 18; iter: 0; batch classifier loss: 0.361712; batch adversarial loss: 0.470198\n",
      "epoch 19; iter: 0; batch classifier loss: 0.216635; batch adversarial loss: 0.457981\n",
      "epoch 20; iter: 0; batch classifier loss: 0.202916; batch adversarial loss: 0.523773\n",
      "epoch 21; iter: 0; batch classifier loss: 0.188851; batch adversarial loss: 0.520837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.158850; batch adversarial loss: 0.540270\n",
      "epoch 23; iter: 0; batch classifier loss: 0.125000; batch adversarial loss: 0.486115\n",
      "epoch 24; iter: 0; batch classifier loss: 0.153823; batch adversarial loss: 0.502772\n",
      "epoch 25; iter: 0; batch classifier loss: 0.139610; batch adversarial loss: 0.421317\n",
      "epoch 26; iter: 0; batch classifier loss: 0.140749; batch adversarial loss: 0.478940\n",
      "epoch 27; iter: 0; batch classifier loss: 0.105150; batch adversarial loss: 0.471575\n",
      "epoch 28; iter: 0; batch classifier loss: 0.134066; batch adversarial loss: 0.449129\n",
      "epoch 29; iter: 0; batch classifier loss: 0.143545; batch adversarial loss: 0.479737\n",
      "epoch 30; iter: 0; batch classifier loss: 0.163003; batch adversarial loss: 0.435987\n",
      "epoch 31; iter: 0; batch classifier loss: 0.107447; batch adversarial loss: 0.448124\n",
      "epoch 32; iter: 0; batch classifier loss: 0.088590; batch adversarial loss: 0.444118\n",
      "epoch 33; iter: 0; batch classifier loss: 0.133936; batch adversarial loss: 0.383993\n",
      "epoch 34; iter: 0; batch classifier loss: 0.109788; batch adversarial loss: 0.425638\n",
      "epoch 35; iter: 0; batch classifier loss: 0.102220; batch adversarial loss: 0.427825\n",
      "epoch 36; iter: 0; batch classifier loss: 0.124533; batch adversarial loss: 0.477158\n",
      "epoch 37; iter: 0; batch classifier loss: 0.081347; batch adversarial loss: 0.475065\n",
      "epoch 38; iter: 0; batch classifier loss: 0.076101; batch adversarial loss: 0.402323\n",
      "epoch 39; iter: 0; batch classifier loss: 0.083421; batch adversarial loss: 0.435194\n",
      "epoch 40; iter: 0; batch classifier loss: 0.074708; batch adversarial loss: 0.467823\n",
      "epoch 41; iter: 0; batch classifier loss: 0.089129; batch adversarial loss: 0.408366\n",
      "epoch 42; iter: 0; batch classifier loss: 0.118970; batch adversarial loss: 0.481141\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089815; batch adversarial loss: 0.512752\n",
      "epoch 44; iter: 0; batch classifier loss: 0.090819; batch adversarial loss: 0.597393\n",
      "epoch 45; iter: 0; batch classifier loss: 0.076447; batch adversarial loss: 0.502917\n",
      "epoch 46; iter: 0; batch classifier loss: 0.115329; batch adversarial loss: 0.460775\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095980; batch adversarial loss: 0.426948\n",
      "epoch 48; iter: 0; batch classifier loss: 0.063639; batch adversarial loss: 0.523409\n",
      "epoch 49; iter: 0; batch classifier loss: 0.052913; batch adversarial loss: 0.520860\n",
      "epoch 50; iter: 0; batch classifier loss: 0.056326; batch adversarial loss: 0.424517\n",
      "epoch 51; iter: 0; batch classifier loss: 0.077820; batch adversarial loss: 0.436541\n",
      "epoch 52; iter: 0; batch classifier loss: 0.064279; batch adversarial loss: 0.525357\n",
      "epoch 53; iter: 0; batch classifier loss: 0.069212; batch adversarial loss: 0.422868\n",
      "epoch 54; iter: 0; batch classifier loss: 0.070022; batch adversarial loss: 0.509022\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072237; batch adversarial loss: 0.438560\n",
      "epoch 56; iter: 0; batch classifier loss: 0.085358; batch adversarial loss: 0.389654\n",
      "epoch 57; iter: 0; batch classifier loss: 0.076568; batch adversarial loss: 0.440562\n",
      "epoch 58; iter: 0; batch classifier loss: 0.068458; batch adversarial loss: 0.558976\n",
      "epoch 59; iter: 0; batch classifier loss: 0.110398; batch adversarial loss: 0.498428\n",
      "epoch 60; iter: 0; batch classifier loss: 0.066538; batch adversarial loss: 0.364536\n",
      "epoch 61; iter: 0; batch classifier loss: 0.061630; batch adversarial loss: 0.417968\n",
      "epoch 62; iter: 0; batch classifier loss: 0.045981; batch adversarial loss: 0.633663\n",
      "epoch 63; iter: 0; batch classifier loss: 0.039471; batch adversarial loss: 0.484381\n",
      "epoch 64; iter: 0; batch classifier loss: 0.057942; batch adversarial loss: 0.429958\n",
      "epoch 65; iter: 0; batch classifier loss: 0.047060; batch adversarial loss: 0.476851\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060476; batch adversarial loss: 0.502358\n",
      "epoch 67; iter: 0; batch classifier loss: 0.053004; batch adversarial loss: 0.517139\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070791; batch adversarial loss: 0.422517\n",
      "epoch 69; iter: 0; batch classifier loss: 0.037353; batch adversarial loss: 0.492528\n",
      "epoch 70; iter: 0; batch classifier loss: 0.096595; batch adversarial loss: 0.452549\n",
      "epoch 71; iter: 0; batch classifier loss: 0.049677; batch adversarial loss: 0.536104\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054946; batch adversarial loss: 0.434454\n",
      "epoch 73; iter: 0; batch classifier loss: 0.046465; batch adversarial loss: 0.456888\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053272; batch adversarial loss: 0.459011\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073748; batch adversarial loss: 0.450514\n",
      "epoch 76; iter: 0; batch classifier loss: 0.052311; batch adversarial loss: 0.564000\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056647; batch adversarial loss: 0.341619\n",
      "epoch 78; iter: 0; batch classifier loss: 0.040958; batch adversarial loss: 0.516870\n",
      "epoch 79; iter: 0; batch classifier loss: 0.055031; batch adversarial loss: 0.464991\n",
      "epoch 80; iter: 0; batch classifier loss: 0.047068; batch adversarial loss: 0.483927\n",
      "epoch 81; iter: 0; batch classifier loss: 0.062166; batch adversarial loss: 0.489413\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046339; batch adversarial loss: 0.475437\n",
      "epoch 83; iter: 0; batch classifier loss: 0.052048; batch adversarial loss: 0.569825\n",
      "epoch 84; iter: 0; batch classifier loss: 0.064521; batch adversarial loss: 0.527400\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073038; batch adversarial loss: 0.592826\n",
      "epoch 86; iter: 0; batch classifier loss: 0.047897; batch adversarial loss: 0.521299\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079058; batch adversarial loss: 0.483925\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057928; batch adversarial loss: 0.507637\n",
      "epoch 89; iter: 0; batch classifier loss: 0.026033; batch adversarial loss: 0.468015\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056949; batch adversarial loss: 0.568003\n",
      "epoch 91; iter: 0; batch classifier loss: 0.041095; batch adversarial loss: 0.487796\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044390; batch adversarial loss: 0.528867\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044253; batch adversarial loss: 0.411213\n",
      "epoch 94; iter: 0; batch classifier loss: 0.035661; batch adversarial loss: 0.472759\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056309; batch adversarial loss: 0.411006\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056395; batch adversarial loss: 0.576546\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043918; batch adversarial loss: 0.462052\n",
      "epoch 98; iter: 0; batch classifier loss: 0.069359; batch adversarial loss: 0.542541\n",
      "epoch 99; iter: 0; batch classifier loss: 0.076650; batch adversarial loss: 0.548570\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047668; batch adversarial loss: 0.467612\n",
      "epoch 101; iter: 0; batch classifier loss: 0.118295; batch adversarial loss: 0.457728\n",
      "epoch 102; iter: 0; batch classifier loss: 0.027089; batch adversarial loss: 0.449252\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044479; batch adversarial loss: 0.496880\n",
      "epoch 104; iter: 0; batch classifier loss: 0.040606; batch adversarial loss: 0.438977\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042787; batch adversarial loss: 0.455185\n",
      "epoch 106; iter: 0; batch classifier loss: 0.099883; batch adversarial loss: 0.454887\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065972; batch adversarial loss: 0.441376\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040691; batch adversarial loss: 0.397538\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043052; batch adversarial loss: 0.396656\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031385; batch adversarial loss: 0.450004\n",
      "epoch 111; iter: 0; batch classifier loss: 0.025502; batch adversarial loss: 0.527198\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040310; batch adversarial loss: 0.505585\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057357; batch adversarial loss: 0.535576\n",
      "epoch 114; iter: 0; batch classifier loss: 0.031384; batch adversarial loss: 0.386254\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037370; batch adversarial loss: 0.492505\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055230; batch adversarial loss: 0.465608\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035719; batch adversarial loss: 0.416494\n",
      "epoch 118; iter: 0; batch classifier loss: 0.058604; batch adversarial loss: 0.424817\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034501; batch adversarial loss: 0.409018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.028545; batch adversarial loss: 0.537056\n",
      "epoch 121; iter: 0; batch classifier loss: 0.020767; batch adversarial loss: 0.504597\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035452; batch adversarial loss: 0.475434\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031178; batch adversarial loss: 0.462713\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031169; batch adversarial loss: 0.490757\n",
      "epoch 125; iter: 0; batch classifier loss: 0.065646; batch adversarial loss: 0.498577\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036666; batch adversarial loss: 0.485457\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021839; batch adversarial loss: 0.426530\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042052; batch adversarial loss: 0.539843\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047775; batch adversarial loss: 0.406026\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036877; batch adversarial loss: 0.483935\n",
      "epoch 131; iter: 0; batch classifier loss: 0.054086; batch adversarial loss: 0.485212\n",
      "epoch 132; iter: 0; batch classifier loss: 0.062868; batch adversarial loss: 0.399980\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035471; batch adversarial loss: 0.503553\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069079; batch adversarial loss: 0.391688\n",
      "epoch 135; iter: 0; batch classifier loss: 0.065693; batch adversarial loss: 0.440857\n",
      "epoch 136; iter: 0; batch classifier loss: 0.061260; batch adversarial loss: 0.473314\n",
      "epoch 137; iter: 0; batch classifier loss: 0.012349; batch adversarial loss: 0.444548\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044378; batch adversarial loss: 0.474821\n",
      "epoch 139; iter: 0; batch classifier loss: 0.065250; batch adversarial loss: 0.430462\n",
      "epoch 140; iter: 0; batch classifier loss: 0.072249; batch adversarial loss: 0.438104\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033315; batch adversarial loss: 0.397512\n",
      "epoch 142; iter: 0; batch classifier loss: 0.069903; batch adversarial loss: 0.465830\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020278; batch adversarial loss: 0.439546\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024123; batch adversarial loss: 0.513135\n",
      "epoch 145; iter: 0; batch classifier loss: 0.009122; batch adversarial loss: 0.473530\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042935; batch adversarial loss: 0.392477\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023918; batch adversarial loss: 0.473519\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013270; batch adversarial loss: 0.434931\n",
      "epoch 149; iter: 0; batch classifier loss: 0.045824; batch adversarial loss: 0.448845\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012421; batch adversarial loss: 0.518181\n",
      "epoch 151; iter: 0; batch classifier loss: 0.057010; batch adversarial loss: 0.418604\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039135; batch adversarial loss: 0.399435\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027495; batch adversarial loss: 0.428318\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026306; batch adversarial loss: 0.439124\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021461; batch adversarial loss: 0.481636\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023855; batch adversarial loss: 0.443677\n",
      "epoch 157; iter: 0; batch classifier loss: 0.043942; batch adversarial loss: 0.423500\n",
      "epoch 158; iter: 0; batch classifier loss: 0.007033; batch adversarial loss: 0.515772\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022340; batch adversarial loss: 0.531480\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031375; batch adversarial loss: 0.469212\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013588; batch adversarial loss: 0.344185\n",
      "epoch 162; iter: 0; batch classifier loss: 0.040578; batch adversarial loss: 0.476007\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034890; batch adversarial loss: 0.460146\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019785; batch adversarial loss: 0.468440\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037732; batch adversarial loss: 0.418018\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020488; batch adversarial loss: 0.439129\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017609; batch adversarial loss: 0.446476\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013952; batch adversarial loss: 0.409637\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027717; batch adversarial loss: 0.453872\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018756; batch adversarial loss: 0.531151\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026344; batch adversarial loss: 0.449331\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024988; batch adversarial loss: 0.454844\n",
      "epoch 173; iter: 0; batch classifier loss: 0.044809; batch adversarial loss: 0.348984\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039006; batch adversarial loss: 0.405944\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041417; batch adversarial loss: 0.443958\n",
      "epoch 176; iter: 0; batch classifier loss: 0.050793; batch adversarial loss: 0.550086\n",
      "epoch 177; iter: 0; batch classifier loss: 0.005940; batch adversarial loss: 0.438574\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023550; batch adversarial loss: 0.505565\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026347; batch adversarial loss: 0.445043\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028831; batch adversarial loss: 0.435943\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021406; batch adversarial loss: 0.567375\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011912; batch adversarial loss: 0.481313\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023011; batch adversarial loss: 0.452368\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010305; batch adversarial loss: 0.372166\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038369; batch adversarial loss: 0.464165\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021422; batch adversarial loss: 0.479563\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030762; batch adversarial loss: 0.410936\n",
      "epoch 188; iter: 0; batch classifier loss: 0.080600; batch adversarial loss: 0.406733\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034379; batch adversarial loss: 0.500108\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021740; batch adversarial loss: 0.526088\n",
      "epoch 191; iter: 0; batch classifier loss: 0.045698; batch adversarial loss: 0.517653\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014838; batch adversarial loss: 0.486767\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011982; batch adversarial loss: 0.452535\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015791; batch adversarial loss: 0.469309\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012426; batch adversarial loss: 0.485616\n",
      "epoch 196; iter: 0; batch classifier loss: 0.054304; batch adversarial loss: 0.457912\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023204; batch adversarial loss: 0.449284\n",
      "epoch 198; iter: 0; batch classifier loss: 0.035171; batch adversarial loss: 0.498148\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021616; batch adversarial loss: 0.471167\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677520; batch adversarial loss: 0.658499\n",
      "epoch 1; iter: 0; batch classifier loss: 0.474385; batch adversarial loss: 0.654712\n",
      "epoch 2; iter: 0; batch classifier loss: 0.415567; batch adversarial loss: 0.615291\n",
      "epoch 3; iter: 0; batch classifier loss: 0.375152; batch adversarial loss: 0.588418\n",
      "epoch 4; iter: 0; batch classifier loss: 0.326223; batch adversarial loss: 0.553918\n",
      "epoch 5; iter: 0; batch classifier loss: 0.293012; batch adversarial loss: 0.552311\n",
      "epoch 6; iter: 0; batch classifier loss: 0.299512; batch adversarial loss: 0.564730\n",
      "epoch 7; iter: 0; batch classifier loss: 0.287168; batch adversarial loss: 0.493852\n",
      "epoch 8; iter: 0; batch classifier loss: 0.261943; batch adversarial loss: 0.457806\n",
      "epoch 9; iter: 0; batch classifier loss: 0.202889; batch adversarial loss: 0.436029\n",
      "epoch 10; iter: 0; batch classifier loss: 0.277456; batch adversarial loss: 0.500330\n",
      "epoch 11; iter: 0; batch classifier loss: 0.211208; batch adversarial loss: 0.472944\n",
      "epoch 12; iter: 0; batch classifier loss: 0.210047; batch adversarial loss: 0.462593\n",
      "epoch 13; iter: 0; batch classifier loss: 0.258302; batch adversarial loss: 0.509717\n",
      "epoch 14; iter: 0; batch classifier loss: 0.207117; batch adversarial loss: 0.397786\n",
      "epoch 15; iter: 0; batch classifier loss: 0.164430; batch adversarial loss: 0.467621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.157579; batch adversarial loss: 0.432179\n",
      "epoch 17; iter: 0; batch classifier loss: 0.180280; batch adversarial loss: 0.460638\n",
      "epoch 18; iter: 0; batch classifier loss: 0.208339; batch adversarial loss: 0.463665\n",
      "epoch 19; iter: 0; batch classifier loss: 0.219526; batch adversarial loss: 0.565821\n",
      "epoch 20; iter: 0; batch classifier loss: 0.121439; batch adversarial loss: 0.461797\n",
      "epoch 21; iter: 0; batch classifier loss: 0.160666; batch adversarial loss: 0.408201\n",
      "epoch 22; iter: 0; batch classifier loss: 0.228493; batch adversarial loss: 0.499703\n",
      "epoch 23; iter: 0; batch classifier loss: 0.161656; batch adversarial loss: 0.539672\n",
      "epoch 24; iter: 0; batch classifier loss: 0.164408; batch adversarial loss: 0.503067\n",
      "epoch 25; iter: 0; batch classifier loss: 0.189921; batch adversarial loss: 0.513823\n",
      "epoch 26; iter: 0; batch classifier loss: 0.140318; batch adversarial loss: 0.391639\n",
      "epoch 27; iter: 0; batch classifier loss: 0.197824; batch adversarial loss: 0.611874\n",
      "epoch 28; iter: 0; batch classifier loss: 0.249722; batch adversarial loss: 0.526922\n",
      "epoch 29; iter: 0; batch classifier loss: 0.250310; batch adversarial loss: 0.544057\n",
      "epoch 30; iter: 0; batch classifier loss: 0.193182; batch adversarial loss: 0.597895\n",
      "epoch 31; iter: 0; batch classifier loss: 0.148482; batch adversarial loss: 0.438376\n",
      "epoch 32; iter: 0; batch classifier loss: 0.228771; batch adversarial loss: 0.558711\n",
      "epoch 33; iter: 0; batch classifier loss: 0.121013; batch adversarial loss: 0.362829\n",
      "epoch 34; iter: 0; batch classifier loss: 0.232206; batch adversarial loss: 0.449259\n",
      "epoch 35; iter: 0; batch classifier loss: 0.370014; batch adversarial loss: 0.460734\n",
      "epoch 36; iter: 0; batch classifier loss: 0.282020; batch adversarial loss: 0.487732\n",
      "epoch 37; iter: 0; batch classifier loss: 0.118378; batch adversarial loss: 0.336390\n",
      "epoch 38; iter: 0; batch classifier loss: 0.082159; batch adversarial loss: 0.423792\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131337; batch adversarial loss: 0.521498\n",
      "epoch 40; iter: 0; batch classifier loss: 0.114978; batch adversarial loss: 0.497654\n",
      "epoch 41; iter: 0; batch classifier loss: 0.060113; batch adversarial loss: 0.426484\n",
      "epoch 42; iter: 0; batch classifier loss: 0.132794; batch adversarial loss: 0.458796\n",
      "epoch 43; iter: 0; batch classifier loss: 0.066341; batch adversarial loss: 0.412426\n",
      "epoch 44; iter: 0; batch classifier loss: 0.075042; batch adversarial loss: 0.472087\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086331; batch adversarial loss: 0.482725\n",
      "epoch 46; iter: 0; batch classifier loss: 0.042589; batch adversarial loss: 0.435902\n",
      "epoch 47; iter: 0; batch classifier loss: 0.097872; batch adversarial loss: 0.403678\n",
      "epoch 48; iter: 0; batch classifier loss: 0.069058; batch adversarial loss: 0.473905\n",
      "epoch 49; iter: 0; batch classifier loss: 0.058843; batch adversarial loss: 0.387069\n",
      "epoch 50; iter: 0; batch classifier loss: 0.133529; batch adversarial loss: 0.501998\n",
      "epoch 51; iter: 0; batch classifier loss: 0.118742; batch adversarial loss: 0.449088\n",
      "epoch 52; iter: 0; batch classifier loss: 0.056763; batch adversarial loss: 0.477698\n",
      "epoch 53; iter: 0; batch classifier loss: 0.087509; batch adversarial loss: 0.419115\n",
      "epoch 54; iter: 0; batch classifier loss: 0.060925; batch adversarial loss: 0.407094\n",
      "epoch 55; iter: 0; batch classifier loss: 0.055133; batch adversarial loss: 0.470950\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081738; batch adversarial loss: 0.452696\n",
      "epoch 57; iter: 0; batch classifier loss: 0.066645; batch adversarial loss: 0.377689\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090989; batch adversarial loss: 0.444851\n",
      "epoch 59; iter: 0; batch classifier loss: 0.076844; batch adversarial loss: 0.470911\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076983; batch adversarial loss: 0.429176\n",
      "epoch 61; iter: 0; batch classifier loss: 0.110302; batch adversarial loss: 0.604657\n",
      "epoch 62; iter: 0; batch classifier loss: 0.070477; batch adversarial loss: 0.360238\n",
      "epoch 63; iter: 0; batch classifier loss: 0.055800; batch adversarial loss: 0.489033\n",
      "epoch 64; iter: 0; batch classifier loss: 0.112301; batch adversarial loss: 0.416074\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088940; batch adversarial loss: 0.399039\n",
      "epoch 66; iter: 0; batch classifier loss: 0.132496; batch adversarial loss: 0.427897\n",
      "epoch 67; iter: 0; batch classifier loss: 0.126121; batch adversarial loss: 0.420691\n",
      "epoch 68; iter: 0; batch classifier loss: 0.087282; batch adversarial loss: 0.398795\n",
      "epoch 69; iter: 0; batch classifier loss: 0.115580; batch adversarial loss: 0.432760\n",
      "epoch 70; iter: 0; batch classifier loss: 0.098844; batch adversarial loss: 0.419867\n",
      "epoch 71; iter: 0; batch classifier loss: 0.103439; batch adversarial loss: 0.418058\n",
      "epoch 72; iter: 0; batch classifier loss: 0.067476; batch adversarial loss: 0.395946\n",
      "epoch 73; iter: 0; batch classifier loss: 0.151106; batch adversarial loss: 0.469704\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089292; batch adversarial loss: 0.479909\n",
      "epoch 75; iter: 0; batch classifier loss: 0.145475; batch adversarial loss: 0.337980\n",
      "epoch 76; iter: 0; batch classifier loss: 0.099596; batch adversarial loss: 0.435924\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067350; batch adversarial loss: 0.384023\n",
      "epoch 78; iter: 0; batch classifier loss: 0.046542; batch adversarial loss: 0.424295\n",
      "epoch 79; iter: 0; batch classifier loss: 0.094305; batch adversarial loss: 0.468224\n",
      "epoch 80; iter: 0; batch classifier loss: 0.094838; batch adversarial loss: 0.422361\n",
      "epoch 81; iter: 0; batch classifier loss: 0.082191; batch adversarial loss: 0.513702\n",
      "epoch 82; iter: 0; batch classifier loss: 0.077305; batch adversarial loss: 0.487398\n",
      "epoch 83; iter: 0; batch classifier loss: 0.046532; batch adversarial loss: 0.390949\n",
      "epoch 84; iter: 0; batch classifier loss: 0.050645; batch adversarial loss: 0.370023\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084759; batch adversarial loss: 0.511062\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053896; batch adversarial loss: 0.397040\n",
      "epoch 87; iter: 0; batch classifier loss: 0.075665; batch adversarial loss: 0.458182\n",
      "epoch 88; iter: 0; batch classifier loss: 0.111401; batch adversarial loss: 0.443659\n",
      "epoch 89; iter: 0; batch classifier loss: 0.128522; batch adversarial loss: 0.551839\n",
      "epoch 90; iter: 0; batch classifier loss: 0.113485; batch adversarial loss: 0.411178\n",
      "epoch 91; iter: 0; batch classifier loss: 0.101572; batch adversarial loss: 0.401818\n",
      "epoch 92; iter: 0; batch classifier loss: 0.072986; batch adversarial loss: 0.416891\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072223; batch adversarial loss: 0.428331\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050346; batch adversarial loss: 0.412700\n",
      "epoch 95; iter: 0; batch classifier loss: 0.093377; batch adversarial loss: 0.499199\n",
      "epoch 96; iter: 0; batch classifier loss: 0.166397; batch adversarial loss: 0.389047\n",
      "epoch 97; iter: 0; batch classifier loss: 0.053971; batch adversarial loss: 0.444801\n",
      "epoch 98; iter: 0; batch classifier loss: 0.136983; batch adversarial loss: 0.505859\n",
      "epoch 99; iter: 0; batch classifier loss: 0.100481; batch adversarial loss: 0.432508\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060746; batch adversarial loss: 0.441881\n",
      "epoch 101; iter: 0; batch classifier loss: 0.087278; batch adversarial loss: 0.464994\n",
      "epoch 102; iter: 0; batch classifier loss: 0.103044; batch adversarial loss: 0.560070\n",
      "epoch 103; iter: 0; batch classifier loss: 0.082421; batch adversarial loss: 0.380904\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050600; batch adversarial loss: 0.423635\n",
      "epoch 105; iter: 0; batch classifier loss: 0.080735; batch adversarial loss: 0.430310\n",
      "epoch 106; iter: 0; batch classifier loss: 0.089711; batch adversarial loss: 0.465085\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072575; batch adversarial loss: 0.401712\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067333; batch adversarial loss: 0.479126\n",
      "epoch 109; iter: 0; batch classifier loss: 0.071076; batch adversarial loss: 0.385853\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039430; batch adversarial loss: 0.350535\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060023; batch adversarial loss: 0.469234\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042963; batch adversarial loss: 0.573768\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063208; batch adversarial loss: 0.424015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.051683; batch adversarial loss: 0.413680\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033785; batch adversarial loss: 0.472920\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034550; batch adversarial loss: 0.476973\n",
      "epoch 117; iter: 0; batch classifier loss: 0.062365; batch adversarial loss: 0.411533\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045476; batch adversarial loss: 0.493815\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036262; batch adversarial loss: 0.394391\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046309; batch adversarial loss: 0.441330\n",
      "epoch 121; iter: 0; batch classifier loss: 0.100439; batch adversarial loss: 0.379377\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067896; batch adversarial loss: 0.440504\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033600; batch adversarial loss: 0.493715\n",
      "epoch 124; iter: 0; batch classifier loss: 0.077774; batch adversarial loss: 0.434345\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057854; batch adversarial loss: 0.522515\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039183; batch adversarial loss: 0.483135\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045765; batch adversarial loss: 0.331822\n",
      "epoch 128; iter: 0; batch classifier loss: 0.079761; batch adversarial loss: 0.402944\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021419; batch adversarial loss: 0.441871\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048284; batch adversarial loss: 0.351705\n",
      "epoch 131; iter: 0; batch classifier loss: 0.092552; batch adversarial loss: 0.521128\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026574; batch adversarial loss: 0.368683\n",
      "epoch 133; iter: 0; batch classifier loss: 0.057923; batch adversarial loss: 0.528348\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049489; batch adversarial loss: 0.411255\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031449; batch adversarial loss: 0.473967\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042460; batch adversarial loss: 0.394955\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044141; batch adversarial loss: 0.410596\n",
      "epoch 138; iter: 0; batch classifier loss: 0.072081; batch adversarial loss: 0.429701\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037492; batch adversarial loss: 0.406052\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024649; batch adversarial loss: 0.455466\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035609; batch adversarial loss: 0.477768\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026759; batch adversarial loss: 0.438494\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041306; batch adversarial loss: 0.433035\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041129; batch adversarial loss: 0.457813\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032041; batch adversarial loss: 0.416819\n",
      "epoch 146; iter: 0; batch classifier loss: 0.071845; batch adversarial loss: 0.412912\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023813; batch adversarial loss: 0.432209\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012215; batch adversarial loss: 0.477303\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033561; batch adversarial loss: 0.378405\n",
      "epoch 150; iter: 0; batch classifier loss: 0.065540; batch adversarial loss: 0.456939\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022588; batch adversarial loss: 0.493507\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045040; batch adversarial loss: 0.387149\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013421; batch adversarial loss: 0.504132\n",
      "epoch 154; iter: 0; batch classifier loss: 0.053303; batch adversarial loss: 0.358470\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030449; batch adversarial loss: 0.392005\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024380; batch adversarial loss: 0.395740\n",
      "epoch 157; iter: 0; batch classifier loss: 0.049756; batch adversarial loss: 0.471375\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033951; batch adversarial loss: 0.546321\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035722; batch adversarial loss: 0.432151\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037147; batch adversarial loss: 0.510364\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036729; batch adversarial loss: 0.457842\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043646; batch adversarial loss: 0.368510\n",
      "epoch 163; iter: 0; batch classifier loss: 0.056428; batch adversarial loss: 0.467790\n",
      "epoch 164; iter: 0; batch classifier loss: 0.041724; batch adversarial loss: 0.419249\n",
      "epoch 165; iter: 0; batch classifier loss: 0.042052; batch adversarial loss: 0.467060\n",
      "epoch 166; iter: 0; batch classifier loss: 0.089940; batch adversarial loss: 0.419966\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026066; batch adversarial loss: 0.308080\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034748; batch adversarial loss: 0.451148\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036934; batch adversarial loss: 0.393260\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017819; batch adversarial loss: 0.442605\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021997; batch adversarial loss: 0.494620\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024886; batch adversarial loss: 0.363390\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025034; batch adversarial loss: 0.467954\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023479; batch adversarial loss: 0.393596\n",
      "epoch 175; iter: 0; batch classifier loss: 0.053371; batch adversarial loss: 0.487487\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026392; batch adversarial loss: 0.465772\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030803; batch adversarial loss: 0.347131\n",
      "epoch 178; iter: 0; batch classifier loss: 0.047909; batch adversarial loss: 0.396044\n",
      "epoch 179; iter: 0; batch classifier loss: 0.041849; batch adversarial loss: 0.487154\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013921; batch adversarial loss: 0.520911\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010979; batch adversarial loss: 0.336381\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024214; batch adversarial loss: 0.547923\n",
      "epoch 183; iter: 0; batch classifier loss: 0.079640; batch adversarial loss: 0.363491\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024484; batch adversarial loss: 0.390112\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038393; batch adversarial loss: 0.452659\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028741; batch adversarial loss: 0.471677\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015768; batch adversarial loss: 0.538870\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006087; batch adversarial loss: 0.389537\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007311; batch adversarial loss: 0.409238\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018700; batch adversarial loss: 0.509037\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013153; batch adversarial loss: 0.441798\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015890; batch adversarial loss: 0.446517\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008999; batch adversarial loss: 0.407197\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010955; batch adversarial loss: 0.394118\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025504; batch adversarial loss: 0.366889\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011932; batch adversarial loss: 0.491498\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026840; batch adversarial loss: 0.489006\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029437; batch adversarial loss: 0.442234\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028451; batch adversarial loss: 0.378353\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705645; batch adversarial loss: 0.695142\n",
      "epoch 1; iter: 0; batch classifier loss: 0.503136; batch adversarial loss: 0.670049\n",
      "epoch 2; iter: 0; batch classifier loss: 0.479003; batch adversarial loss: 0.641977\n",
      "epoch 3; iter: 0; batch classifier loss: 0.488594; batch adversarial loss: 0.620956\n",
      "epoch 4; iter: 0; batch classifier loss: 0.446504; batch adversarial loss: 0.598638\n",
      "epoch 5; iter: 0; batch classifier loss: 0.358434; batch adversarial loss: 0.619567\n",
      "epoch 6; iter: 0; batch classifier loss: 0.470051; batch adversarial loss: 0.602551\n",
      "epoch 7; iter: 0; batch classifier loss: 0.469766; batch adversarial loss: 0.541691\n",
      "epoch 8; iter: 0; batch classifier loss: 0.370840; batch adversarial loss: 0.555026\n",
      "epoch 9; iter: 0; batch classifier loss: 0.417647; batch adversarial loss: 0.561896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.420675; batch adversarial loss: 0.558801\n",
      "epoch 11; iter: 0; batch classifier loss: 0.400784; batch adversarial loss: 0.557846\n",
      "epoch 12; iter: 0; batch classifier loss: 0.460289; batch adversarial loss: 0.552551\n",
      "epoch 13; iter: 0; batch classifier loss: 0.291171; batch adversarial loss: 0.436224\n",
      "epoch 14; iter: 0; batch classifier loss: 0.312042; batch adversarial loss: 0.536403\n",
      "epoch 15; iter: 0; batch classifier loss: 0.293116; batch adversarial loss: 0.462548\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311798; batch adversarial loss: 0.524917\n",
      "epoch 17; iter: 0; batch classifier loss: 0.375745; batch adversarial loss: 0.534736\n",
      "epoch 18; iter: 0; batch classifier loss: 0.287724; batch adversarial loss: 0.492885\n",
      "epoch 19; iter: 0; batch classifier loss: 0.358557; batch adversarial loss: 0.443973\n",
      "epoch 20; iter: 0; batch classifier loss: 0.283258; batch adversarial loss: 0.519688\n",
      "epoch 21; iter: 0; batch classifier loss: 0.187128; batch adversarial loss: 0.503959\n",
      "epoch 22; iter: 0; batch classifier loss: 0.308877; batch adversarial loss: 0.422103\n",
      "epoch 23; iter: 0; batch classifier loss: 0.186212; batch adversarial loss: 0.443748\n",
      "epoch 24; iter: 0; batch classifier loss: 0.282969; batch adversarial loss: 0.455194\n",
      "epoch 25; iter: 0; batch classifier loss: 0.272133; batch adversarial loss: 0.442461\n",
      "epoch 26; iter: 0; batch classifier loss: 0.259094; batch adversarial loss: 0.434571\n",
      "epoch 27; iter: 0; batch classifier loss: 0.230342; batch adversarial loss: 0.501306\n",
      "epoch 28; iter: 0; batch classifier loss: 0.269065; batch adversarial loss: 0.504627\n",
      "epoch 29; iter: 0; batch classifier loss: 0.222127; batch adversarial loss: 0.474549\n",
      "epoch 30; iter: 0; batch classifier loss: 0.233775; batch adversarial loss: 0.462563\n",
      "epoch 31; iter: 0; batch classifier loss: 0.236649; batch adversarial loss: 0.430443\n",
      "epoch 32; iter: 0; batch classifier loss: 0.188710; batch adversarial loss: 0.541920\n",
      "epoch 33; iter: 0; batch classifier loss: 0.236567; batch adversarial loss: 0.438164\n",
      "epoch 34; iter: 0; batch classifier loss: 0.258768; batch adversarial loss: 0.469668\n",
      "epoch 35; iter: 0; batch classifier loss: 0.223372; batch adversarial loss: 0.509479\n",
      "epoch 36; iter: 0; batch classifier loss: 0.223707; batch adversarial loss: 0.443396\n",
      "epoch 37; iter: 0; batch classifier loss: 0.247424; batch adversarial loss: 0.475657\n",
      "epoch 38; iter: 0; batch classifier loss: 0.208375; batch adversarial loss: 0.476061\n",
      "epoch 39; iter: 0; batch classifier loss: 0.259379; batch adversarial loss: 0.432856\n",
      "epoch 40; iter: 0; batch classifier loss: 0.230891; batch adversarial loss: 0.404011\n",
      "epoch 41; iter: 0; batch classifier loss: 0.185940; batch adversarial loss: 0.547332\n",
      "epoch 42; iter: 0; batch classifier loss: 0.177371; batch adversarial loss: 0.471698\n",
      "epoch 43; iter: 0; batch classifier loss: 0.167777; batch adversarial loss: 0.453501\n",
      "epoch 44; iter: 0; batch classifier loss: 0.209109; batch adversarial loss: 0.471190\n",
      "epoch 45; iter: 0; batch classifier loss: 0.186341; batch adversarial loss: 0.543247\n",
      "epoch 46; iter: 0; batch classifier loss: 0.180695; batch adversarial loss: 0.523679\n",
      "epoch 47; iter: 0; batch classifier loss: 0.236548; batch adversarial loss: 0.478694\n",
      "epoch 48; iter: 0; batch classifier loss: 0.232904; batch adversarial loss: 0.411839\n",
      "epoch 49; iter: 0; batch classifier loss: 0.179996; batch adversarial loss: 0.374796\n",
      "epoch 50; iter: 0; batch classifier loss: 0.247387; batch adversarial loss: 0.485854\n",
      "epoch 51; iter: 0; batch classifier loss: 0.258729; batch adversarial loss: 0.495363\n",
      "epoch 52; iter: 0; batch classifier loss: 0.188231; batch adversarial loss: 0.426631\n",
      "epoch 53; iter: 0; batch classifier loss: 0.142693; batch adversarial loss: 0.435185\n",
      "epoch 54; iter: 0; batch classifier loss: 0.230449; batch adversarial loss: 0.481708\n",
      "epoch 55; iter: 0; batch classifier loss: 0.228453; batch adversarial loss: 0.494335\n",
      "epoch 56; iter: 0; batch classifier loss: 0.221061; batch adversarial loss: 0.448435\n",
      "epoch 57; iter: 0; batch classifier loss: 0.197238; batch adversarial loss: 0.552412\n",
      "epoch 58; iter: 0; batch classifier loss: 0.213839; batch adversarial loss: 0.435322\n",
      "epoch 59; iter: 0; batch classifier loss: 0.193167; batch adversarial loss: 0.471318\n",
      "epoch 60; iter: 0; batch classifier loss: 0.224566; batch adversarial loss: 0.423782\n",
      "epoch 61; iter: 0; batch classifier loss: 0.124048; batch adversarial loss: 0.530019\n",
      "epoch 62; iter: 0; batch classifier loss: 0.226879; batch adversarial loss: 0.542462\n",
      "epoch 63; iter: 0; batch classifier loss: 0.109092; batch adversarial loss: 0.446598\n",
      "epoch 64; iter: 0; batch classifier loss: 0.045525; batch adversarial loss: 0.506445\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077952; batch adversarial loss: 0.417856\n",
      "epoch 66; iter: 0; batch classifier loss: 0.094007; batch adversarial loss: 0.512168\n",
      "epoch 67; iter: 0; batch classifier loss: 0.102716; batch adversarial loss: 0.451697\n",
      "epoch 68; iter: 0; batch classifier loss: 0.123914; batch adversarial loss: 0.413942\n",
      "epoch 69; iter: 0; batch classifier loss: 0.119751; batch adversarial loss: 0.471148\n",
      "epoch 70; iter: 0; batch classifier loss: 0.104602; batch adversarial loss: 0.563579\n",
      "epoch 71; iter: 0; batch classifier loss: 0.114895; batch adversarial loss: 0.462783\n",
      "epoch 72; iter: 0; batch classifier loss: 0.059225; batch adversarial loss: 0.597172\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065076; batch adversarial loss: 0.345615\n",
      "epoch 74; iter: 0; batch classifier loss: 0.070079; batch adversarial loss: 0.442801\n",
      "epoch 75; iter: 0; batch classifier loss: 0.098687; batch adversarial loss: 0.374367\n",
      "epoch 76; iter: 0; batch classifier loss: 0.057241; batch adversarial loss: 0.533873\n",
      "epoch 77; iter: 0; batch classifier loss: 0.085869; batch adversarial loss: 0.425593\n",
      "epoch 78; iter: 0; batch classifier loss: 0.070632; batch adversarial loss: 0.410634\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082596; batch adversarial loss: 0.416173\n",
      "epoch 80; iter: 0; batch classifier loss: 0.081286; batch adversarial loss: 0.536901\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068446; batch adversarial loss: 0.457547\n",
      "epoch 82; iter: 0; batch classifier loss: 0.038864; batch adversarial loss: 0.438758\n",
      "epoch 83; iter: 0; batch classifier loss: 0.048783; batch adversarial loss: 0.534234\n",
      "epoch 84; iter: 0; batch classifier loss: 0.040225; batch adversarial loss: 0.470217\n",
      "epoch 85; iter: 0; batch classifier loss: 0.030846; batch adversarial loss: 0.412133\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084137; batch adversarial loss: 0.563595\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055697; batch adversarial loss: 0.492826\n",
      "epoch 88; iter: 0; batch classifier loss: 0.065355; batch adversarial loss: 0.429494\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051911; batch adversarial loss: 0.505535\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051237; batch adversarial loss: 0.396777\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057269; batch adversarial loss: 0.440190\n",
      "epoch 92; iter: 0; batch classifier loss: 0.038843; batch adversarial loss: 0.395893\n",
      "epoch 93; iter: 0; batch classifier loss: 0.035584; batch adversarial loss: 0.430691\n",
      "epoch 94; iter: 0; batch classifier loss: 0.037537; batch adversarial loss: 0.431176\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073649; batch adversarial loss: 0.409634\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044867; batch adversarial loss: 0.457806\n",
      "epoch 97; iter: 0; batch classifier loss: 0.038580; batch adversarial loss: 0.393744\n",
      "epoch 98; iter: 0; batch classifier loss: 0.060982; batch adversarial loss: 0.538049\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049784; batch adversarial loss: 0.405387\n",
      "epoch 100; iter: 0; batch classifier loss: 0.030048; batch adversarial loss: 0.441822\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070235; batch adversarial loss: 0.431291\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037033; batch adversarial loss: 0.380304\n",
      "epoch 103; iter: 0; batch classifier loss: 0.078246; batch adversarial loss: 0.394465\n",
      "epoch 104; iter: 0; batch classifier loss: 0.028558; batch adversarial loss: 0.438548\n",
      "epoch 105; iter: 0; batch classifier loss: 0.024589; batch adversarial loss: 0.454320\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036248; batch adversarial loss: 0.441191\n",
      "epoch 107; iter: 0; batch classifier loss: 0.019691; batch adversarial loss: 0.440848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.012462; batch adversarial loss: 0.521073\n",
      "epoch 109; iter: 0; batch classifier loss: 0.024072; batch adversarial loss: 0.383846\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023439; batch adversarial loss: 0.421337\n",
      "epoch 111; iter: 0; batch classifier loss: 0.014333; batch adversarial loss: 0.422693\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024920; batch adversarial loss: 0.347916\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040235; batch adversarial loss: 0.475162\n",
      "epoch 114; iter: 0; batch classifier loss: 0.018663; batch adversarial loss: 0.459379\n",
      "epoch 115; iter: 0; batch classifier loss: 0.030941; batch adversarial loss: 0.473045\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026370; batch adversarial loss: 0.385626\n",
      "epoch 117; iter: 0; batch classifier loss: 0.068625; batch adversarial loss: 0.414137\n",
      "epoch 118; iter: 0; batch classifier loss: 0.011273; batch adversarial loss: 0.465450\n",
      "epoch 119; iter: 0; batch classifier loss: 0.014393; batch adversarial loss: 0.427789\n",
      "epoch 120; iter: 0; batch classifier loss: 0.011120; batch adversarial loss: 0.525122\n",
      "epoch 121; iter: 0; batch classifier loss: 0.012869; batch adversarial loss: 0.391296\n",
      "epoch 122; iter: 0; batch classifier loss: 0.019459; batch adversarial loss: 0.520754\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035764; batch adversarial loss: 0.451618\n",
      "epoch 124; iter: 0; batch classifier loss: 0.015785; batch adversarial loss: 0.427831\n",
      "epoch 125; iter: 0; batch classifier loss: 0.014933; batch adversarial loss: 0.510644\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017475; batch adversarial loss: 0.472046\n",
      "epoch 127; iter: 0; batch classifier loss: 0.015090; batch adversarial loss: 0.465488\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031809; batch adversarial loss: 0.433032\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038128; batch adversarial loss: 0.346909\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025780; batch adversarial loss: 0.469888\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048711; batch adversarial loss: 0.471836\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019769; batch adversarial loss: 0.451661\n",
      "epoch 133; iter: 0; batch classifier loss: 0.010298; batch adversarial loss: 0.462853\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016479; batch adversarial loss: 0.425879\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022079; batch adversarial loss: 0.435622\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031352; batch adversarial loss: 0.453197\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049307; batch adversarial loss: 0.517605\n",
      "epoch 138; iter: 0; batch classifier loss: 0.007866; batch adversarial loss: 0.468774\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017536; batch adversarial loss: 0.545601\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017047; batch adversarial loss: 0.417859\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022402; batch adversarial loss: 0.541007\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029050; batch adversarial loss: 0.446239\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025439; batch adversarial loss: 0.428447\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024318; batch adversarial loss: 0.549324\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013072; batch adversarial loss: 0.434027\n",
      "epoch 146; iter: 0; batch classifier loss: 0.008137; batch adversarial loss: 0.473569\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032440; batch adversarial loss: 0.477573\n",
      "epoch 148; iter: 0; batch classifier loss: 0.009113; batch adversarial loss: 0.401973\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025744; batch adversarial loss: 0.451953\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026926; batch adversarial loss: 0.508528\n",
      "epoch 151; iter: 0; batch classifier loss: 0.006828; batch adversarial loss: 0.460173\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011703; batch adversarial loss: 0.434395\n",
      "epoch 153; iter: 0; batch classifier loss: 0.006662; batch adversarial loss: 0.429036\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021965; batch adversarial loss: 0.423768\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021470; batch adversarial loss: 0.568291\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022474; batch adversarial loss: 0.390056\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014865; batch adversarial loss: 0.489069\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010143; batch adversarial loss: 0.466739\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018110; batch adversarial loss: 0.541053\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012733; batch adversarial loss: 0.429795\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010969; batch adversarial loss: 0.417517\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018587; batch adversarial loss: 0.456106\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023341; batch adversarial loss: 0.475168\n",
      "epoch 164; iter: 0; batch classifier loss: 0.002527; batch adversarial loss: 0.453876\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032883; batch adversarial loss: 0.439614\n",
      "epoch 166; iter: 0; batch classifier loss: 0.051584; batch adversarial loss: 0.417329\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006792; batch adversarial loss: 0.491398\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027987; batch adversarial loss: 0.463573\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026126; batch adversarial loss: 0.458420\n",
      "epoch 170; iter: 0; batch classifier loss: 0.044058; batch adversarial loss: 0.387763\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008039; batch adversarial loss: 0.500560\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012530; batch adversarial loss: 0.462909\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010775; batch adversarial loss: 0.411620\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013308; batch adversarial loss: 0.548375\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031468; batch adversarial loss: 0.447673\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032585; batch adversarial loss: 0.434657\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021185; batch adversarial loss: 0.436577\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007988; batch adversarial loss: 0.442699\n",
      "epoch 179; iter: 0; batch classifier loss: 0.003635; batch adversarial loss: 0.445004\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009089; batch adversarial loss: 0.543144\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029530; batch adversarial loss: 0.404940\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030655; batch adversarial loss: 0.473072\n",
      "epoch 183; iter: 0; batch classifier loss: 0.003294; batch adversarial loss: 0.553615\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006284; batch adversarial loss: 0.497645\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013669; batch adversarial loss: 0.454618\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012252; batch adversarial loss: 0.526205\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010106; batch adversarial loss: 0.465178\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007804; batch adversarial loss: 0.506649\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006495; batch adversarial loss: 0.464561\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028591; batch adversarial loss: 0.442601\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022634; batch adversarial loss: 0.531645\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021120; batch adversarial loss: 0.431580\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006433; batch adversarial loss: 0.387347\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023807; batch adversarial loss: 0.431579\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015650; batch adversarial loss: 0.421898\n",
      "epoch 196; iter: 0; batch classifier loss: 0.003538; batch adversarial loss: 0.466402\n",
      "epoch 197; iter: 0; batch classifier loss: 0.049661; batch adversarial loss: 0.369783\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029158; batch adversarial loss: 0.520396\n",
      "epoch 199; iter: 0; batch classifier loss: 0.053631; batch adversarial loss: 0.429028\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696310; batch adversarial loss: 0.691910\n",
      "epoch 1; iter: 0; batch classifier loss: 0.535525; batch adversarial loss: 0.653595\n",
      "epoch 2; iter: 0; batch classifier loss: 0.442095; batch adversarial loss: 0.635818\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393884; batch adversarial loss: 0.594146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.429106; batch adversarial loss: 0.590648\n",
      "epoch 5; iter: 0; batch classifier loss: 0.435528; batch adversarial loss: 0.599702\n",
      "epoch 6; iter: 0; batch classifier loss: 0.472666; batch adversarial loss: 0.559756\n",
      "epoch 7; iter: 0; batch classifier loss: 0.486851; batch adversarial loss: 0.543652\n",
      "epoch 8; iter: 0; batch classifier loss: 0.514076; batch adversarial loss: 0.551363\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488643; batch adversarial loss: 0.516448\n",
      "epoch 10; iter: 0; batch classifier loss: 0.409937; batch adversarial loss: 0.522512\n",
      "epoch 11; iter: 0; batch classifier loss: 0.447535; batch adversarial loss: 0.561556\n",
      "epoch 12; iter: 0; batch classifier loss: 0.452271; batch adversarial loss: 0.509575\n",
      "epoch 13; iter: 0; batch classifier loss: 0.329763; batch adversarial loss: 0.553021\n",
      "epoch 14; iter: 0; batch classifier loss: 0.268299; batch adversarial loss: 0.474050\n",
      "epoch 15; iter: 0; batch classifier loss: 0.275470; batch adversarial loss: 0.497464\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281129; batch adversarial loss: 0.571704\n",
      "epoch 17; iter: 0; batch classifier loss: 0.297299; batch adversarial loss: 0.406347\n",
      "epoch 18; iter: 0; batch classifier loss: 0.303566; batch adversarial loss: 0.492912\n",
      "epoch 19; iter: 0; batch classifier loss: 0.319561; batch adversarial loss: 0.481052\n",
      "epoch 20; iter: 0; batch classifier loss: 0.350782; batch adversarial loss: 0.536043\n",
      "epoch 21; iter: 0; batch classifier loss: 0.291878; batch adversarial loss: 0.496011\n",
      "epoch 22; iter: 0; batch classifier loss: 0.268266; batch adversarial loss: 0.449472\n",
      "epoch 23; iter: 0; batch classifier loss: 0.263562; batch adversarial loss: 0.521437\n",
      "epoch 24; iter: 0; batch classifier loss: 0.225207; batch adversarial loss: 0.436628\n",
      "epoch 25; iter: 0; batch classifier loss: 0.255922; batch adversarial loss: 0.478592\n",
      "epoch 26; iter: 0; batch classifier loss: 0.398940; batch adversarial loss: 0.563396\n",
      "epoch 27; iter: 0; batch classifier loss: 0.249153; batch adversarial loss: 0.405926\n",
      "epoch 28; iter: 0; batch classifier loss: 0.209671; batch adversarial loss: 0.479553\n",
      "epoch 29; iter: 0; batch classifier loss: 0.303385; batch adversarial loss: 0.493306\n",
      "epoch 30; iter: 0; batch classifier loss: 0.265940; batch adversarial loss: 0.513607\n",
      "epoch 31; iter: 0; batch classifier loss: 0.284652; batch adversarial loss: 0.440379\n",
      "epoch 32; iter: 0; batch classifier loss: 0.280266; batch adversarial loss: 0.494045\n",
      "epoch 33; iter: 0; batch classifier loss: 0.181427; batch adversarial loss: 0.411641\n",
      "epoch 34; iter: 0; batch classifier loss: 0.246167; batch adversarial loss: 0.537651\n",
      "epoch 35; iter: 0; batch classifier loss: 0.197002; batch adversarial loss: 0.547775\n",
      "epoch 36; iter: 0; batch classifier loss: 0.219499; batch adversarial loss: 0.492209\n",
      "epoch 37; iter: 0; batch classifier loss: 0.282520; batch adversarial loss: 0.419889\n",
      "epoch 38; iter: 0; batch classifier loss: 0.176528; batch adversarial loss: 0.531031\n",
      "epoch 39; iter: 0; batch classifier loss: 0.169926; batch adversarial loss: 0.492909\n",
      "epoch 40; iter: 0; batch classifier loss: 0.207058; batch adversarial loss: 0.478840\n",
      "epoch 41; iter: 0; batch classifier loss: 0.196138; batch adversarial loss: 0.402151\n",
      "epoch 42; iter: 0; batch classifier loss: 0.277581; batch adversarial loss: 0.414781\n",
      "epoch 43; iter: 0; batch classifier loss: 0.159774; batch adversarial loss: 0.476327\n",
      "epoch 44; iter: 0; batch classifier loss: 0.274300; batch adversarial loss: 0.469733\n",
      "epoch 45; iter: 0; batch classifier loss: 0.208624; batch adversarial loss: 0.535284\n",
      "epoch 46; iter: 0; batch classifier loss: 0.190642; batch adversarial loss: 0.505063\n",
      "epoch 47; iter: 0; batch classifier loss: 0.186087; batch adversarial loss: 0.471434\n",
      "epoch 48; iter: 0; batch classifier loss: 0.211886; batch adversarial loss: 0.418330\n",
      "epoch 49; iter: 0; batch classifier loss: 0.216065; batch adversarial loss: 0.497823\n",
      "epoch 50; iter: 0; batch classifier loss: 0.165784; batch adversarial loss: 0.563931\n",
      "epoch 51; iter: 0; batch classifier loss: 0.212569; batch adversarial loss: 0.472034\n",
      "epoch 52; iter: 0; batch classifier loss: 0.236127; batch adversarial loss: 0.444017\n",
      "epoch 53; iter: 0; batch classifier loss: 0.209090; batch adversarial loss: 0.482431\n",
      "epoch 54; iter: 0; batch classifier loss: 0.209220; batch adversarial loss: 0.446406\n",
      "epoch 55; iter: 0; batch classifier loss: 0.162330; batch adversarial loss: 0.445691\n",
      "epoch 56; iter: 0; batch classifier loss: 0.169433; batch adversarial loss: 0.376131\n",
      "epoch 57; iter: 0; batch classifier loss: 0.163661; batch adversarial loss: 0.553702\n",
      "epoch 58; iter: 0; batch classifier loss: 0.188961; batch adversarial loss: 0.519045\n",
      "epoch 59; iter: 0; batch classifier loss: 0.254274; batch adversarial loss: 0.483282\n",
      "epoch 60; iter: 0; batch classifier loss: 0.180908; batch adversarial loss: 0.399765\n",
      "epoch 61; iter: 0; batch classifier loss: 0.202742; batch adversarial loss: 0.362779\n",
      "epoch 62; iter: 0; batch classifier loss: 0.223099; batch adversarial loss: 0.435379\n",
      "epoch 63; iter: 0; batch classifier loss: 0.137247; batch adversarial loss: 0.432814\n",
      "epoch 64; iter: 0; batch classifier loss: 0.160905; batch adversarial loss: 0.386930\n",
      "epoch 65; iter: 0; batch classifier loss: 0.226993; batch adversarial loss: 0.483799\n",
      "epoch 66; iter: 0; batch classifier loss: 0.170243; batch adversarial loss: 0.516518\n",
      "epoch 67; iter: 0; batch classifier loss: 0.148457; batch adversarial loss: 0.421142\n",
      "epoch 68; iter: 0; batch classifier loss: 0.192906; batch adversarial loss: 0.448216\n",
      "epoch 69; iter: 0; batch classifier loss: 0.166882; batch adversarial loss: 0.556872\n",
      "epoch 70; iter: 0; batch classifier loss: 0.198860; batch adversarial loss: 0.483831\n",
      "epoch 71; iter: 0; batch classifier loss: 0.205068; batch adversarial loss: 0.460005\n",
      "epoch 72; iter: 0; batch classifier loss: 0.252548; batch adversarial loss: 0.482839\n",
      "epoch 73; iter: 0; batch classifier loss: 0.184598; batch adversarial loss: 0.350249\n",
      "epoch 74; iter: 0; batch classifier loss: 0.201146; batch adversarial loss: 0.446903\n",
      "epoch 75; iter: 0; batch classifier loss: 0.229460; batch adversarial loss: 0.508072\n",
      "epoch 76; iter: 0; batch classifier loss: 0.099018; batch adversarial loss: 0.494556\n",
      "epoch 77; iter: 0; batch classifier loss: 0.133250; batch adversarial loss: 0.446469\n",
      "epoch 78; iter: 0; batch classifier loss: 0.152030; batch adversarial loss: 0.471460\n",
      "epoch 79; iter: 0; batch classifier loss: 0.121291; batch adversarial loss: 0.519390\n",
      "epoch 80; iter: 0; batch classifier loss: 0.189900; batch adversarial loss: 0.435568\n",
      "epoch 81; iter: 0; batch classifier loss: 0.129689; batch adversarial loss: 0.434075\n",
      "epoch 82; iter: 0; batch classifier loss: 0.092905; batch adversarial loss: 0.447852\n",
      "epoch 83; iter: 0; batch classifier loss: 0.184849; batch adversarial loss: 0.452218\n",
      "epoch 84; iter: 0; batch classifier loss: 0.132555; batch adversarial loss: 0.421428\n",
      "epoch 85; iter: 0; batch classifier loss: 0.128226; batch adversarial loss: 0.448590\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083072; batch adversarial loss: 0.456836\n",
      "epoch 87; iter: 0; batch classifier loss: 0.103646; batch adversarial loss: 0.440383\n",
      "epoch 88; iter: 0; batch classifier loss: 0.084946; batch adversarial loss: 0.467109\n",
      "epoch 89; iter: 0; batch classifier loss: 0.085563; batch adversarial loss: 0.471135\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050468; batch adversarial loss: 0.539380\n",
      "epoch 91; iter: 0; batch classifier loss: 0.090688; batch adversarial loss: 0.393872\n",
      "epoch 92; iter: 0; batch classifier loss: 0.075512; batch adversarial loss: 0.449057\n",
      "epoch 93; iter: 0; batch classifier loss: 0.103457; batch adversarial loss: 0.512669\n",
      "epoch 94; iter: 0; batch classifier loss: 0.080105; batch adversarial loss: 0.549289\n",
      "epoch 95; iter: 0; batch classifier loss: 0.067971; batch adversarial loss: 0.438561\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065233; batch adversarial loss: 0.314307\n",
      "epoch 97; iter: 0; batch classifier loss: 0.088596; batch adversarial loss: 0.406433\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054270; batch adversarial loss: 0.391901\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042954; batch adversarial loss: 0.518150\n",
      "epoch 100; iter: 0; batch classifier loss: 0.058636; batch adversarial loss: 0.400155\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049215; batch adversarial loss: 0.469345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.064206; batch adversarial loss: 0.432199\n",
      "epoch 103; iter: 0; batch classifier loss: 0.028045; batch adversarial loss: 0.431409\n",
      "epoch 104; iter: 0; batch classifier loss: 0.042568; batch adversarial loss: 0.423482\n",
      "epoch 105; iter: 0; batch classifier loss: 0.032814; batch adversarial loss: 0.502296\n",
      "epoch 106; iter: 0; batch classifier loss: 0.072672; batch adversarial loss: 0.493045\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045120; batch adversarial loss: 0.457093\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046052; batch adversarial loss: 0.484456\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041769; batch adversarial loss: 0.508826\n",
      "epoch 110; iter: 0; batch classifier loss: 0.082377; batch adversarial loss: 0.531971\n",
      "epoch 111; iter: 0; batch classifier loss: 0.063345; batch adversarial loss: 0.461292\n",
      "epoch 112; iter: 0; batch classifier loss: 0.028250; batch adversarial loss: 0.435339\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055562; batch adversarial loss: 0.459903\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033738; batch adversarial loss: 0.413599\n",
      "epoch 115; iter: 0; batch classifier loss: 0.068829; batch adversarial loss: 0.414374\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034320; batch adversarial loss: 0.486188\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047233; batch adversarial loss: 0.583575\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037686; batch adversarial loss: 0.543334\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033683; batch adversarial loss: 0.464453\n",
      "epoch 120; iter: 0; batch classifier loss: 0.029770; batch adversarial loss: 0.441194\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034067; batch adversarial loss: 0.398999\n",
      "epoch 122; iter: 0; batch classifier loss: 0.019200; batch adversarial loss: 0.442751\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050180; batch adversarial loss: 0.440282\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021136; batch adversarial loss: 0.615131\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048868; batch adversarial loss: 0.471787\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030734; batch adversarial loss: 0.373413\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022590; batch adversarial loss: 0.488113\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052700; batch adversarial loss: 0.437873\n",
      "epoch 129; iter: 0; batch classifier loss: 0.052554; batch adversarial loss: 0.420370\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017852; batch adversarial loss: 0.440577\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025867; batch adversarial loss: 0.410761\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042818; batch adversarial loss: 0.551654\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036311; batch adversarial loss: 0.487599\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039375; batch adversarial loss: 0.465660\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036356; batch adversarial loss: 0.485344\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037358; batch adversarial loss: 0.453645\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036435; batch adversarial loss: 0.411866\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016968; batch adversarial loss: 0.516607\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019820; batch adversarial loss: 0.409952\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019479; batch adversarial loss: 0.477402\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043457; batch adversarial loss: 0.478275\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020743; batch adversarial loss: 0.468005\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024973; batch adversarial loss: 0.453801\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037250; batch adversarial loss: 0.456668\n",
      "epoch 145; iter: 0; batch classifier loss: 0.053526; batch adversarial loss: 0.433342\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044812; batch adversarial loss: 0.398461\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026028; batch adversarial loss: 0.442183\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024329; batch adversarial loss: 0.436426\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030438; batch adversarial loss: 0.437125\n",
      "epoch 150; iter: 0; batch classifier loss: 0.061174; batch adversarial loss: 0.411879\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015562; batch adversarial loss: 0.400290\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018777; batch adversarial loss: 0.532708\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022276; batch adversarial loss: 0.496824\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026289; batch adversarial loss: 0.457781\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016337; batch adversarial loss: 0.480889\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045143; batch adversarial loss: 0.393276\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009648; batch adversarial loss: 0.509572\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027379; batch adversarial loss: 0.387235\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015708; batch adversarial loss: 0.393345\n",
      "epoch 160; iter: 0; batch classifier loss: 0.045971; batch adversarial loss: 0.446883\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009439; batch adversarial loss: 0.471696\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014178; batch adversarial loss: 0.514728\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009894; batch adversarial loss: 0.430175\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023608; batch adversarial loss: 0.437120\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019030; batch adversarial loss: 0.440046\n",
      "epoch 166; iter: 0; batch classifier loss: 0.067791; batch adversarial loss: 0.457343\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026035; batch adversarial loss: 0.429686\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026224; batch adversarial loss: 0.447518\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013099; batch adversarial loss: 0.349313\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014613; batch adversarial loss: 0.411640\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025517; batch adversarial loss: 0.447841\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013764; batch adversarial loss: 0.470637\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011903; batch adversarial loss: 0.480274\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023676; batch adversarial loss: 0.413711\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014184; batch adversarial loss: 0.414819\n",
      "epoch 176; iter: 0; batch classifier loss: 0.048537; batch adversarial loss: 0.383866\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014698; batch adversarial loss: 0.510518\n",
      "epoch 178; iter: 0; batch classifier loss: 0.042386; batch adversarial loss: 0.480147\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008454; batch adversarial loss: 0.385376\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010404; batch adversarial loss: 0.392435\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006070; batch adversarial loss: 0.529712\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036453; batch adversarial loss: 0.508583\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031781; batch adversarial loss: 0.487371\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023520; batch adversarial loss: 0.472865\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018328; batch adversarial loss: 0.453125\n",
      "epoch 186; iter: 0; batch classifier loss: 0.034468; batch adversarial loss: 0.559735\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013009; batch adversarial loss: 0.426083\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020608; batch adversarial loss: 0.507881\n",
      "epoch 189; iter: 0; batch classifier loss: 0.005020; batch adversarial loss: 0.587463\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024023; batch adversarial loss: 0.492777\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017637; batch adversarial loss: 0.494179\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014732; batch adversarial loss: 0.498466\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010080; batch adversarial loss: 0.456985\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023379; batch adversarial loss: 0.423534\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011827; batch adversarial loss: 0.459999\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013110; batch adversarial loss: 0.530316\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011737; batch adversarial loss: 0.454756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.025825; batch adversarial loss: 0.406956\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009796; batch adversarial loss: 0.517439\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685581; batch adversarial loss: 0.644394\n",
      "epoch 1; iter: 0; batch classifier loss: 0.474542; batch adversarial loss: 0.622950\n",
      "epoch 2; iter: 0; batch classifier loss: 0.307554; batch adversarial loss: 0.608165\n",
      "epoch 3; iter: 0; batch classifier loss: 0.347512; batch adversarial loss: 0.587368\n",
      "epoch 4; iter: 0; batch classifier loss: 0.288776; batch adversarial loss: 0.547067\n",
      "epoch 5; iter: 0; batch classifier loss: 0.301760; batch adversarial loss: 0.580318\n",
      "epoch 6; iter: 0; batch classifier loss: 0.228968; batch adversarial loss: 0.522314\n",
      "epoch 7; iter: 0; batch classifier loss: 0.254961; batch adversarial loss: 0.487157\n",
      "epoch 8; iter: 0; batch classifier loss: 0.318624; batch adversarial loss: 0.556078\n",
      "epoch 9; iter: 0; batch classifier loss: 0.269018; batch adversarial loss: 0.536854\n",
      "epoch 10; iter: 0; batch classifier loss: 0.297744; batch adversarial loss: 0.478147\n",
      "epoch 11; iter: 0; batch classifier loss: 0.268975; batch adversarial loss: 0.463873\n",
      "epoch 12; iter: 0; batch classifier loss: 0.186744; batch adversarial loss: 0.483016\n",
      "epoch 13; iter: 0; batch classifier loss: 0.208086; batch adversarial loss: 0.501700\n",
      "epoch 14; iter: 0; batch classifier loss: 0.209834; batch adversarial loss: 0.466878\n",
      "epoch 15; iter: 0; batch classifier loss: 0.201111; batch adversarial loss: 0.450811\n",
      "epoch 16; iter: 0; batch classifier loss: 0.250890; batch adversarial loss: 0.511326\n",
      "epoch 17; iter: 0; batch classifier loss: 0.197242; batch adversarial loss: 0.443883\n",
      "epoch 18; iter: 0; batch classifier loss: 0.269782; batch adversarial loss: 0.559877\n",
      "epoch 19; iter: 0; batch classifier loss: 0.199140; batch adversarial loss: 0.451079\n",
      "epoch 20; iter: 0; batch classifier loss: 0.202141; batch adversarial loss: 0.478277\n",
      "epoch 21; iter: 0; batch classifier loss: 0.206514; batch adversarial loss: 0.454055\n",
      "epoch 22; iter: 0; batch classifier loss: 0.158820; batch adversarial loss: 0.504933\n",
      "epoch 23; iter: 0; batch classifier loss: 0.228693; batch adversarial loss: 0.469003\n",
      "epoch 24; iter: 0; batch classifier loss: 0.248094; batch adversarial loss: 0.457487\n",
      "epoch 25; iter: 0; batch classifier loss: 0.295500; batch adversarial loss: 0.609657\n",
      "epoch 26; iter: 0; batch classifier loss: 0.295164; batch adversarial loss: 0.513823\n",
      "epoch 27; iter: 0; batch classifier loss: 0.401896; batch adversarial loss: 0.530193\n",
      "epoch 28; iter: 0; batch classifier loss: 0.446670; batch adversarial loss: 0.524626\n",
      "epoch 29; iter: 0; batch classifier loss: 0.269137; batch adversarial loss: 0.449049\n",
      "epoch 30; iter: 0; batch classifier loss: 0.206539; batch adversarial loss: 0.407065\n",
      "epoch 31; iter: 0; batch classifier loss: 0.112481; batch adversarial loss: 0.459201\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146039; batch adversarial loss: 0.483401\n",
      "epoch 33; iter: 0; batch classifier loss: 0.095939; batch adversarial loss: 0.414115\n",
      "epoch 34; iter: 0; batch classifier loss: 0.100120; batch adversarial loss: 0.422293\n",
      "epoch 35; iter: 0; batch classifier loss: 0.136853; batch adversarial loss: 0.448067\n",
      "epoch 36; iter: 0; batch classifier loss: 0.116460; batch adversarial loss: 0.490431\n",
      "epoch 37; iter: 0; batch classifier loss: 0.091743; batch adversarial loss: 0.494403\n",
      "epoch 38; iter: 0; batch classifier loss: 0.093984; batch adversarial loss: 0.406548\n",
      "epoch 39; iter: 0; batch classifier loss: 0.085886; batch adversarial loss: 0.453901\n",
      "epoch 40; iter: 0; batch classifier loss: 0.087850; batch adversarial loss: 0.428998\n",
      "epoch 41; iter: 0; batch classifier loss: 0.115054; batch adversarial loss: 0.436406\n",
      "epoch 42; iter: 0; batch classifier loss: 0.124758; batch adversarial loss: 0.462906\n",
      "epoch 43; iter: 0; batch classifier loss: 0.106273; batch adversarial loss: 0.548934\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098589; batch adversarial loss: 0.432056\n",
      "epoch 45; iter: 0; batch classifier loss: 0.092931; batch adversarial loss: 0.522471\n",
      "epoch 46; iter: 0; batch classifier loss: 0.083263; batch adversarial loss: 0.503844\n",
      "epoch 47; iter: 0; batch classifier loss: 0.088745; batch adversarial loss: 0.446865\n",
      "epoch 48; iter: 0; batch classifier loss: 0.067490; batch adversarial loss: 0.459529\n",
      "epoch 49; iter: 0; batch classifier loss: 0.081130; batch adversarial loss: 0.411642\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091494; batch adversarial loss: 0.503745\n",
      "epoch 51; iter: 0; batch classifier loss: 0.079343; batch adversarial loss: 0.534297\n",
      "epoch 52; iter: 0; batch classifier loss: 0.084705; batch adversarial loss: 0.550443\n",
      "epoch 53; iter: 0; batch classifier loss: 0.111289; batch adversarial loss: 0.443967\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096365; batch adversarial loss: 0.433820\n",
      "epoch 55; iter: 0; batch classifier loss: 0.064354; batch adversarial loss: 0.406162\n",
      "epoch 56; iter: 0; batch classifier loss: 0.086030; batch adversarial loss: 0.434331\n",
      "epoch 57; iter: 0; batch classifier loss: 0.076683; batch adversarial loss: 0.523822\n",
      "epoch 58; iter: 0; batch classifier loss: 0.060196; batch adversarial loss: 0.499995\n",
      "epoch 59; iter: 0; batch classifier loss: 0.075006; batch adversarial loss: 0.435397\n",
      "epoch 60; iter: 0; batch classifier loss: 0.069413; batch adversarial loss: 0.402895\n",
      "epoch 61; iter: 0; batch classifier loss: 0.060675; batch adversarial loss: 0.392264\n",
      "epoch 62; iter: 0; batch classifier loss: 0.073597; batch adversarial loss: 0.406097\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076689; batch adversarial loss: 0.410842\n",
      "epoch 64; iter: 0; batch classifier loss: 0.063315; batch adversarial loss: 0.515408\n",
      "epoch 65; iter: 0; batch classifier loss: 0.062270; batch adversarial loss: 0.431856\n",
      "epoch 66; iter: 0; batch classifier loss: 0.109897; batch adversarial loss: 0.347048\n",
      "epoch 67; iter: 0; batch classifier loss: 0.071388; batch adversarial loss: 0.555860\n",
      "epoch 68; iter: 0; batch classifier loss: 0.121968; batch adversarial loss: 0.440947\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075383; batch adversarial loss: 0.438785\n",
      "epoch 70; iter: 0; batch classifier loss: 0.110212; batch adversarial loss: 0.502430\n",
      "epoch 71; iter: 0; batch classifier loss: 0.085995; batch adversarial loss: 0.478859\n",
      "epoch 72; iter: 0; batch classifier loss: 0.043144; batch adversarial loss: 0.517004\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068057; batch adversarial loss: 0.364003\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066474; batch adversarial loss: 0.462952\n",
      "epoch 75; iter: 0; batch classifier loss: 0.092520; batch adversarial loss: 0.512814\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072077; batch adversarial loss: 0.487382\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063103; batch adversarial loss: 0.476257\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085753; batch adversarial loss: 0.436518\n",
      "epoch 79; iter: 0; batch classifier loss: 0.058718; batch adversarial loss: 0.438335\n",
      "epoch 80; iter: 0; batch classifier loss: 0.103517; batch adversarial loss: 0.441889\n",
      "epoch 81; iter: 0; batch classifier loss: 0.085029; batch adversarial loss: 0.418191\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063676; batch adversarial loss: 0.515270\n",
      "epoch 83; iter: 0; batch classifier loss: 0.102317; batch adversarial loss: 0.581992\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070012; batch adversarial loss: 0.487276\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076855; batch adversarial loss: 0.458590\n",
      "epoch 86; iter: 0; batch classifier loss: 0.174942; batch adversarial loss: 0.485741\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046783; batch adversarial loss: 0.469391\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042768; batch adversarial loss: 0.510738\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075587; batch adversarial loss: 0.449198\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042813; batch adversarial loss: 0.504736\n",
      "epoch 91; iter: 0; batch classifier loss: 0.091340; batch adversarial loss: 0.489802\n",
      "epoch 92; iter: 0; batch classifier loss: 0.116264; batch adversarial loss: 0.439525\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044926; batch adversarial loss: 0.532760\n",
      "epoch 94; iter: 0; batch classifier loss: 0.055431; batch adversarial loss: 0.544484\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060417; batch adversarial loss: 0.447791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.038315; batch adversarial loss: 0.470707\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075453; batch adversarial loss: 0.432099\n",
      "epoch 98; iter: 0; batch classifier loss: 0.090514; batch adversarial loss: 0.412552\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073719; batch adversarial loss: 0.425337\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050913; batch adversarial loss: 0.501185\n",
      "epoch 101; iter: 0; batch classifier loss: 0.036857; batch adversarial loss: 0.502656\n",
      "epoch 102; iter: 0; batch classifier loss: 0.018104; batch adversarial loss: 0.452194\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050304; batch adversarial loss: 0.422542\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058116; batch adversarial loss: 0.500647\n",
      "epoch 105; iter: 0; batch classifier loss: 0.094544; batch adversarial loss: 0.433901\n",
      "epoch 106; iter: 0; batch classifier loss: 0.087451; batch adversarial loss: 0.519308\n",
      "epoch 107; iter: 0; batch classifier loss: 0.113696; batch adversarial loss: 0.384499\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053194; batch adversarial loss: 0.424754\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066836; batch adversarial loss: 0.471981\n",
      "epoch 110; iter: 0; batch classifier loss: 0.073669; batch adversarial loss: 0.431215\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045592; batch adversarial loss: 0.486215\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039594; batch adversarial loss: 0.568461\n",
      "epoch 113; iter: 0; batch classifier loss: 0.050374; batch adversarial loss: 0.528337\n",
      "epoch 114; iter: 0; batch classifier loss: 0.058574; batch adversarial loss: 0.476445\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037865; batch adversarial loss: 0.475879\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037744; batch adversarial loss: 0.487407\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023754; batch adversarial loss: 0.465808\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052303; batch adversarial loss: 0.541485\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039855; batch adversarial loss: 0.554015\n",
      "epoch 120; iter: 0; batch classifier loss: 0.083856; batch adversarial loss: 0.438786\n",
      "epoch 121; iter: 0; batch classifier loss: 0.115165; batch adversarial loss: 0.432196\n",
      "epoch 122; iter: 0; batch classifier loss: 0.063993; batch adversarial loss: 0.449292\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025177; batch adversarial loss: 0.456070\n",
      "epoch 124; iter: 0; batch classifier loss: 0.089887; batch adversarial loss: 0.419833\n",
      "epoch 125; iter: 0; batch classifier loss: 0.070772; batch adversarial loss: 0.422286\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063261; batch adversarial loss: 0.461792\n",
      "epoch 127; iter: 0; batch classifier loss: 0.056700; batch adversarial loss: 0.431572\n",
      "epoch 128; iter: 0; batch classifier loss: 0.064015; batch adversarial loss: 0.445013\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038620; batch adversarial loss: 0.471597\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045625; batch adversarial loss: 0.530401\n",
      "epoch 131; iter: 0; batch classifier loss: 0.062432; batch adversarial loss: 0.463600\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032163; batch adversarial loss: 0.492191\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026276; batch adversarial loss: 0.452990\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019153; batch adversarial loss: 0.436542\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030026; batch adversarial loss: 0.354505\n",
      "epoch 136; iter: 0; batch classifier loss: 0.067499; batch adversarial loss: 0.489297\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034018; batch adversarial loss: 0.472607\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034312; batch adversarial loss: 0.467283\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049422; batch adversarial loss: 0.469836\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026222; batch adversarial loss: 0.520510\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044072; batch adversarial loss: 0.408060\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026048; batch adversarial loss: 0.492615\n",
      "epoch 143; iter: 0; batch classifier loss: 0.063638; batch adversarial loss: 0.511520\n",
      "epoch 144; iter: 0; batch classifier loss: 0.059493; batch adversarial loss: 0.409944\n",
      "epoch 145; iter: 0; batch classifier loss: 0.065852; batch adversarial loss: 0.435485\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024538; batch adversarial loss: 0.504660\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040849; batch adversarial loss: 0.413453\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036083; batch adversarial loss: 0.500212\n",
      "epoch 149; iter: 0; batch classifier loss: 0.050215; batch adversarial loss: 0.480861\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028798; batch adversarial loss: 0.463120\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031186; batch adversarial loss: 0.478041\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032791; batch adversarial loss: 0.489009\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023378; batch adversarial loss: 0.443394\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024167; batch adversarial loss: 0.497022\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041407; batch adversarial loss: 0.466917\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032775; batch adversarial loss: 0.426795\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016998; batch adversarial loss: 0.545094\n",
      "epoch 158; iter: 0; batch classifier loss: 0.065276; batch adversarial loss: 0.464696\n",
      "epoch 159; iter: 0; batch classifier loss: 0.051002; batch adversarial loss: 0.478681\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021795; batch adversarial loss: 0.422960\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038541; batch adversarial loss: 0.359366\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031808; batch adversarial loss: 0.405766\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025743; batch adversarial loss: 0.470118\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031705; batch adversarial loss: 0.395274\n",
      "epoch 165; iter: 0; batch classifier loss: 0.060882; batch adversarial loss: 0.486432\n",
      "epoch 166; iter: 0; batch classifier loss: 0.094781; batch adversarial loss: 0.492896\n",
      "epoch 167; iter: 0; batch classifier loss: 0.037365; batch adversarial loss: 0.401853\n",
      "epoch 168; iter: 0; batch classifier loss: 0.039279; batch adversarial loss: 0.466431\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020341; batch adversarial loss: 0.417376\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030938; batch adversarial loss: 0.561106\n",
      "epoch 171; iter: 0; batch classifier loss: 0.062287; batch adversarial loss: 0.506397\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018441; batch adversarial loss: 0.432143\n",
      "epoch 173; iter: 0; batch classifier loss: 0.062646; batch adversarial loss: 0.351462\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030700; batch adversarial loss: 0.472368\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015081; batch adversarial loss: 0.428370\n",
      "epoch 176; iter: 0; batch classifier loss: 0.070293; batch adversarial loss: 0.441701\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022812; batch adversarial loss: 0.432048\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021791; batch adversarial loss: 0.434723\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024893; batch adversarial loss: 0.478395\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022534; batch adversarial loss: 0.605585\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024998; batch adversarial loss: 0.531974\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028023; batch adversarial loss: 0.464815\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029575; batch adversarial loss: 0.389386\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013063; batch adversarial loss: 0.386186\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022442; batch adversarial loss: 0.456153\n",
      "epoch 186; iter: 0; batch classifier loss: 0.084889; batch adversarial loss: 0.397197\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030912; batch adversarial loss: 0.449459\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035795; batch adversarial loss: 0.362045\n",
      "epoch 189; iter: 0; batch classifier loss: 0.052489; batch adversarial loss: 0.301390\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029435; batch adversarial loss: 0.464113\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019538; batch adversarial loss: 0.422323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.032816; batch adversarial loss: 0.479526\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019348; batch adversarial loss: 0.466846\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021289; batch adversarial loss: 0.531614\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022372; batch adversarial loss: 0.427891\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028807; batch adversarial loss: 0.482693\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024376; batch adversarial loss: 0.453758\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013294; batch adversarial loss: 0.404243\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023010; batch adversarial loss: 0.380349\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684060; batch adversarial loss: 0.691780\n",
      "epoch 1; iter: 0; batch classifier loss: 0.509457; batch adversarial loss: 0.644149\n",
      "epoch 2; iter: 0; batch classifier loss: 0.496544; batch adversarial loss: 0.608895\n",
      "epoch 3; iter: 0; batch classifier loss: 0.323643; batch adversarial loss: 0.570590\n",
      "epoch 4; iter: 0; batch classifier loss: 0.394275; batch adversarial loss: 0.547877\n",
      "epoch 5; iter: 0; batch classifier loss: 0.277312; batch adversarial loss: 0.528859\n",
      "epoch 6; iter: 0; batch classifier loss: 0.287931; batch adversarial loss: 0.488799\n",
      "epoch 7; iter: 0; batch classifier loss: 0.315318; batch adversarial loss: 0.500840\n",
      "epoch 8; iter: 0; batch classifier loss: 0.235861; batch adversarial loss: 0.514226\n",
      "epoch 9; iter: 0; batch classifier loss: 0.260586; batch adversarial loss: 0.489612\n",
      "epoch 10; iter: 0; batch classifier loss: 0.227264; batch adversarial loss: 0.519169\n",
      "epoch 11; iter: 0; batch classifier loss: 0.255759; batch adversarial loss: 0.488886\n",
      "epoch 12; iter: 0; batch classifier loss: 0.235478; batch adversarial loss: 0.431573\n",
      "epoch 13; iter: 0; batch classifier loss: 0.246286; batch adversarial loss: 0.510067\n",
      "epoch 14; iter: 0; batch classifier loss: 0.240589; batch adversarial loss: 0.485777\n",
      "epoch 15; iter: 0; batch classifier loss: 0.190916; batch adversarial loss: 0.525753\n",
      "epoch 16; iter: 0; batch classifier loss: 0.260789; batch adversarial loss: 0.432575\n",
      "epoch 17; iter: 0; batch classifier loss: 0.195827; batch adversarial loss: 0.500995\n",
      "epoch 18; iter: 0; batch classifier loss: 0.193093; batch adversarial loss: 0.441981\n",
      "epoch 19; iter: 0; batch classifier loss: 0.254587; batch adversarial loss: 0.529221\n",
      "epoch 20; iter: 0; batch classifier loss: 0.290300; batch adversarial loss: 0.449326\n",
      "epoch 21; iter: 0; batch classifier loss: 0.301602; batch adversarial loss: 0.554917\n",
      "epoch 22; iter: 0; batch classifier loss: 0.377724; batch adversarial loss: 0.465356\n",
      "epoch 23; iter: 0; batch classifier loss: 0.419542; batch adversarial loss: 0.459586\n",
      "epoch 24; iter: 0; batch classifier loss: 0.471855; batch adversarial loss: 0.476228\n",
      "epoch 25; iter: 0; batch classifier loss: 0.273106; batch adversarial loss: 0.450827\n",
      "epoch 26; iter: 0; batch classifier loss: 0.139005; batch adversarial loss: 0.488123\n",
      "epoch 27; iter: 0; batch classifier loss: 0.183697; batch adversarial loss: 0.322802\n",
      "epoch 28; iter: 0; batch classifier loss: 0.163208; batch adversarial loss: 0.548689\n",
      "epoch 29; iter: 0; batch classifier loss: 0.159062; batch adversarial loss: 0.441113\n",
      "epoch 30; iter: 0; batch classifier loss: 0.137827; batch adversarial loss: 0.510118\n",
      "epoch 31; iter: 0; batch classifier loss: 0.138555; batch adversarial loss: 0.430242\n",
      "epoch 32; iter: 0; batch classifier loss: 0.123189; batch adversarial loss: 0.438879\n",
      "epoch 33; iter: 0; batch classifier loss: 0.129186; batch adversarial loss: 0.515060\n",
      "epoch 34; iter: 0; batch classifier loss: 0.134379; batch adversarial loss: 0.565788\n",
      "epoch 35; iter: 0; batch classifier loss: 0.099629; batch adversarial loss: 0.434963\n",
      "epoch 36; iter: 0; batch classifier loss: 0.116938; batch adversarial loss: 0.481462\n",
      "epoch 37; iter: 0; batch classifier loss: 0.134741; batch adversarial loss: 0.545733\n",
      "epoch 38; iter: 0; batch classifier loss: 0.120448; batch adversarial loss: 0.409613\n",
      "epoch 39; iter: 0; batch classifier loss: 0.090146; batch adversarial loss: 0.504375\n",
      "epoch 40; iter: 0; batch classifier loss: 0.071701; batch adversarial loss: 0.497385\n",
      "epoch 41; iter: 0; batch classifier loss: 0.079043; batch adversarial loss: 0.515841\n",
      "epoch 42; iter: 0; batch classifier loss: 0.097355; batch adversarial loss: 0.534587\n",
      "epoch 43; iter: 0; batch classifier loss: 0.126863; batch adversarial loss: 0.371222\n",
      "epoch 44; iter: 0; batch classifier loss: 0.082710; batch adversarial loss: 0.421390\n",
      "epoch 45; iter: 0; batch classifier loss: 0.135841; batch adversarial loss: 0.515987\n",
      "epoch 46; iter: 0; batch classifier loss: 0.129645; batch adversarial loss: 0.495790\n",
      "epoch 47; iter: 0; batch classifier loss: 0.097468; batch adversarial loss: 0.522644\n",
      "epoch 48; iter: 0; batch classifier loss: 0.103615; batch adversarial loss: 0.471528\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099719; batch adversarial loss: 0.478984\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074504; batch adversarial loss: 0.494787\n",
      "epoch 51; iter: 0; batch classifier loss: 0.147960; batch adversarial loss: 0.438826\n",
      "epoch 52; iter: 0; batch classifier loss: 0.069507; batch adversarial loss: 0.532878\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094703; batch adversarial loss: 0.441618\n",
      "epoch 54; iter: 0; batch classifier loss: 0.106645; batch adversarial loss: 0.537463\n",
      "epoch 55; iter: 0; batch classifier loss: 0.053611; batch adversarial loss: 0.489562\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101749; batch adversarial loss: 0.588005\n",
      "epoch 57; iter: 0; batch classifier loss: 0.127319; batch adversarial loss: 0.440975\n",
      "epoch 58; iter: 0; batch classifier loss: 0.066776; batch adversarial loss: 0.442951\n",
      "epoch 59; iter: 0; batch classifier loss: 0.057231; batch adversarial loss: 0.474123\n",
      "epoch 60; iter: 0; batch classifier loss: 0.135387; batch adversarial loss: 0.477380\n",
      "epoch 61; iter: 0; batch classifier loss: 0.143098; batch adversarial loss: 0.525114\n",
      "epoch 62; iter: 0; batch classifier loss: 0.087968; batch adversarial loss: 0.459039\n",
      "epoch 63; iter: 0; batch classifier loss: 0.114990; batch adversarial loss: 0.403766\n",
      "epoch 64; iter: 0; batch classifier loss: 0.101739; batch adversarial loss: 0.459798\n",
      "epoch 65; iter: 0; batch classifier loss: 0.133717; batch adversarial loss: 0.358967\n",
      "epoch 66; iter: 0; batch classifier loss: 0.081464; batch adversarial loss: 0.417989\n",
      "epoch 67; iter: 0; batch classifier loss: 0.056288; batch adversarial loss: 0.455067\n",
      "epoch 68; iter: 0; batch classifier loss: 0.115319; batch adversarial loss: 0.408675\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087834; batch adversarial loss: 0.408833\n",
      "epoch 70; iter: 0; batch classifier loss: 0.123014; batch adversarial loss: 0.521282\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058693; batch adversarial loss: 0.486709\n",
      "epoch 72; iter: 0; batch classifier loss: 0.109543; batch adversarial loss: 0.336657\n",
      "epoch 73; iter: 0; batch classifier loss: 0.073157; batch adversarial loss: 0.489354\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101741; batch adversarial loss: 0.393639\n",
      "epoch 75; iter: 0; batch classifier loss: 0.121339; batch adversarial loss: 0.496984\n",
      "epoch 76; iter: 0; batch classifier loss: 0.120233; batch adversarial loss: 0.446242\n",
      "epoch 77; iter: 0; batch classifier loss: 0.083725; batch adversarial loss: 0.459442\n",
      "epoch 78; iter: 0; batch classifier loss: 0.116472; batch adversarial loss: 0.376288\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068041; batch adversarial loss: 0.383302\n",
      "epoch 80; iter: 0; batch classifier loss: 0.069496; batch adversarial loss: 0.480757\n",
      "epoch 81; iter: 0; batch classifier loss: 0.086958; batch adversarial loss: 0.440453\n",
      "epoch 82; iter: 0; batch classifier loss: 0.080332; batch adversarial loss: 0.447734\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079276; batch adversarial loss: 0.471150\n",
      "epoch 84; iter: 0; batch classifier loss: 0.117182; batch adversarial loss: 0.475833\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065552; batch adversarial loss: 0.501130\n",
      "epoch 86; iter: 0; batch classifier loss: 0.092939; batch adversarial loss: 0.507547\n",
      "epoch 87; iter: 0; batch classifier loss: 0.111499; batch adversarial loss: 0.377029\n",
      "epoch 88; iter: 0; batch classifier loss: 0.125039; batch adversarial loss: 0.428271\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051211; batch adversarial loss: 0.381012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.088427; batch adversarial loss: 0.475124\n",
      "epoch 91; iter: 0; batch classifier loss: 0.089459; batch adversarial loss: 0.549732\n",
      "epoch 92; iter: 0; batch classifier loss: 0.095053; batch adversarial loss: 0.388403\n",
      "epoch 93; iter: 0; batch classifier loss: 0.074870; batch adversarial loss: 0.456759\n",
      "epoch 94; iter: 0; batch classifier loss: 0.120018; batch adversarial loss: 0.462026\n",
      "epoch 95; iter: 0; batch classifier loss: 0.107580; batch adversarial loss: 0.469200\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055542; batch adversarial loss: 0.403527\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059777; batch adversarial loss: 0.409122\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039283; batch adversarial loss: 0.429448\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073505; batch adversarial loss: 0.387805\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064083; batch adversarial loss: 0.343396\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054006; batch adversarial loss: 0.482642\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057198; batch adversarial loss: 0.562084\n",
      "epoch 103; iter: 0; batch classifier loss: 0.051888; batch adversarial loss: 0.474417\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057300; batch adversarial loss: 0.597043\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054788; batch adversarial loss: 0.516366\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039498; batch adversarial loss: 0.526495\n",
      "epoch 107; iter: 0; batch classifier loss: 0.093456; batch adversarial loss: 0.423369\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069405; batch adversarial loss: 0.473413\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060632; batch adversarial loss: 0.408500\n",
      "epoch 110; iter: 0; batch classifier loss: 0.087139; batch adversarial loss: 0.415479\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032135; batch adversarial loss: 0.468827\n",
      "epoch 112; iter: 0; batch classifier loss: 0.113822; batch adversarial loss: 0.461317\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048062; batch adversarial loss: 0.523252\n",
      "epoch 114; iter: 0; batch classifier loss: 0.070510; batch adversarial loss: 0.452315\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049054; batch adversarial loss: 0.494403\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040349; batch adversarial loss: 0.478578\n",
      "epoch 117; iter: 0; batch classifier loss: 0.085862; batch adversarial loss: 0.425509\n",
      "epoch 118; iter: 0; batch classifier loss: 0.065119; batch adversarial loss: 0.417094\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053211; batch adversarial loss: 0.374513\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041440; batch adversarial loss: 0.455110\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047418; batch adversarial loss: 0.352982\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035790; batch adversarial loss: 0.435061\n",
      "epoch 123; iter: 0; batch classifier loss: 0.108508; batch adversarial loss: 0.376365\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042877; batch adversarial loss: 0.494497\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027014; batch adversarial loss: 0.469044\n",
      "epoch 126; iter: 0; batch classifier loss: 0.056855; batch adversarial loss: 0.426235\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029265; batch adversarial loss: 0.478277\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030711; batch adversarial loss: 0.489669\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048231; batch adversarial loss: 0.359664\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039091; batch adversarial loss: 0.425006\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028982; batch adversarial loss: 0.509716\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033973; batch adversarial loss: 0.478010\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029123; batch adversarial loss: 0.363284\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033688; batch adversarial loss: 0.405050\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025050; batch adversarial loss: 0.423392\n",
      "epoch 136; iter: 0; batch classifier loss: 0.068254; batch adversarial loss: 0.481277\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033876; batch adversarial loss: 0.491460\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020322; batch adversarial loss: 0.457639\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030814; batch adversarial loss: 0.541262\n",
      "epoch 140; iter: 0; batch classifier loss: 0.082135; batch adversarial loss: 0.358559\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028251; batch adversarial loss: 0.544866\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033038; batch adversarial loss: 0.468174\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028023; batch adversarial loss: 0.464012\n",
      "epoch 144; iter: 0; batch classifier loss: 0.059289; batch adversarial loss: 0.451854\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044238; batch adversarial loss: 0.469584\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028457; batch adversarial loss: 0.454801\n",
      "epoch 147; iter: 0; batch classifier loss: 0.055484; batch adversarial loss: 0.400289\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016274; batch adversarial loss: 0.503529\n",
      "epoch 149; iter: 0; batch classifier loss: 0.005896; batch adversarial loss: 0.423194\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025074; batch adversarial loss: 0.387461\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029035; batch adversarial loss: 0.508605\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015209; batch adversarial loss: 0.495862\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034665; batch adversarial loss: 0.497902\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025671; batch adversarial loss: 0.464592\n",
      "epoch 155; iter: 0; batch classifier loss: 0.067523; batch adversarial loss: 0.485112\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050395; batch adversarial loss: 0.366583\n",
      "epoch 157; iter: 0; batch classifier loss: 0.066671; batch adversarial loss: 0.412135\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024800; batch adversarial loss: 0.318858\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033662; batch adversarial loss: 0.456473\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017831; batch adversarial loss: 0.349332\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043943; batch adversarial loss: 0.464498\n",
      "epoch 162; iter: 0; batch classifier loss: 0.050969; batch adversarial loss: 0.378637\n",
      "epoch 163; iter: 0; batch classifier loss: 0.044436; batch adversarial loss: 0.469851\n",
      "epoch 164; iter: 0; batch classifier loss: 0.043446; batch adversarial loss: 0.375663\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017662; batch adversarial loss: 0.498226\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027030; batch adversarial loss: 0.465813\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035824; batch adversarial loss: 0.429309\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045157; batch adversarial loss: 0.399658\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038944; batch adversarial loss: 0.425577\n",
      "epoch 170; iter: 0; batch classifier loss: 0.061467; batch adversarial loss: 0.448236\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030943; batch adversarial loss: 0.459155\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020818; batch adversarial loss: 0.468183\n",
      "epoch 173; iter: 0; batch classifier loss: 0.063016; batch adversarial loss: 0.469926\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020406; batch adversarial loss: 0.472824\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017688; batch adversarial loss: 0.512172\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016356; batch adversarial loss: 0.482872\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012943; batch adversarial loss: 0.544942\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037525; batch adversarial loss: 0.551973\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031544; batch adversarial loss: 0.448441\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017427; batch adversarial loss: 0.366726\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012165; batch adversarial loss: 0.378018\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023360; batch adversarial loss: 0.383488\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036825; batch adversarial loss: 0.394044\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011758; batch adversarial loss: 0.434540\n",
      "epoch 185; iter: 0; batch classifier loss: 0.005174; batch adversarial loss: 0.489419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.027103; batch adversarial loss: 0.446928\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019134; batch adversarial loss: 0.353916\n",
      "epoch 188; iter: 0; batch classifier loss: 0.045697; batch adversarial loss: 0.502679\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017631; batch adversarial loss: 0.533417\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022590; batch adversarial loss: 0.448602\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015923; batch adversarial loss: 0.436224\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024599; batch adversarial loss: 0.482577\n",
      "epoch 193; iter: 0; batch classifier loss: 0.042668; batch adversarial loss: 0.499514\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010041; batch adversarial loss: 0.413492\n",
      "epoch 195; iter: 0; batch classifier loss: 0.032564; batch adversarial loss: 0.469208\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027894; batch adversarial loss: 0.476122\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033657; batch adversarial loss: 0.419829\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028480; batch adversarial loss: 0.545527\n",
      "epoch 199; iter: 0; batch classifier loss: 0.037153; batch adversarial loss: 0.483735\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718580; batch adversarial loss: 0.750038\n",
      "epoch 1; iter: 0; batch classifier loss: 0.546823; batch adversarial loss: 0.672487\n",
      "epoch 2; iter: 0; batch classifier loss: 0.443221; batch adversarial loss: 0.652170\n",
      "epoch 3; iter: 0; batch classifier loss: 0.363699; batch adversarial loss: 0.614968\n",
      "epoch 4; iter: 0; batch classifier loss: 0.342491; batch adversarial loss: 0.574481\n",
      "epoch 5; iter: 0; batch classifier loss: 0.333943; batch adversarial loss: 0.572337\n",
      "epoch 6; iter: 0; batch classifier loss: 0.303548; batch adversarial loss: 0.577211\n",
      "epoch 7; iter: 0; batch classifier loss: 0.319656; batch adversarial loss: 0.538893\n",
      "epoch 8; iter: 0; batch classifier loss: 0.334319; batch adversarial loss: 0.552778\n",
      "epoch 9; iter: 0; batch classifier loss: 0.318145; batch adversarial loss: 0.502199\n",
      "epoch 10; iter: 0; batch classifier loss: 0.279328; batch adversarial loss: 0.508236\n",
      "epoch 11; iter: 0; batch classifier loss: 0.277482; batch adversarial loss: 0.477143\n",
      "epoch 12; iter: 0; batch classifier loss: 0.317115; batch adversarial loss: 0.513982\n",
      "epoch 13; iter: 0; batch classifier loss: 0.249400; batch adversarial loss: 0.549589\n",
      "epoch 14; iter: 0; batch classifier loss: 0.167666; batch adversarial loss: 0.482963\n",
      "epoch 15; iter: 0; batch classifier loss: 0.238295; batch adversarial loss: 0.500431\n",
      "epoch 16; iter: 0; batch classifier loss: 0.353341; batch adversarial loss: 0.484226\n",
      "epoch 17; iter: 0; batch classifier loss: 0.368325; batch adversarial loss: 0.523298\n",
      "epoch 18; iter: 0; batch classifier loss: 0.313104; batch adversarial loss: 0.472523\n",
      "epoch 19; iter: 0; batch classifier loss: 0.256328; batch adversarial loss: 0.497568\n",
      "epoch 20; iter: 0; batch classifier loss: 0.286373; batch adversarial loss: 0.421813\n",
      "epoch 21; iter: 0; batch classifier loss: 0.179794; batch adversarial loss: 0.488162\n",
      "epoch 22; iter: 0; batch classifier loss: 0.195362; batch adversarial loss: 0.450694\n",
      "epoch 23; iter: 0; batch classifier loss: 0.169733; batch adversarial loss: 0.475991\n",
      "epoch 24; iter: 0; batch classifier loss: 0.269778; batch adversarial loss: 0.516073\n",
      "epoch 25; iter: 0; batch classifier loss: 0.165428; batch adversarial loss: 0.497812\n",
      "epoch 26; iter: 0; batch classifier loss: 0.125691; batch adversarial loss: 0.501672\n",
      "epoch 27; iter: 0; batch classifier loss: 0.204155; batch adversarial loss: 0.489126\n",
      "epoch 28; iter: 0; batch classifier loss: 0.115957; batch adversarial loss: 0.438441\n",
      "epoch 29; iter: 0; batch classifier loss: 0.146528; batch adversarial loss: 0.507754\n",
      "epoch 30; iter: 0; batch classifier loss: 0.181738; batch adversarial loss: 0.510575\n",
      "epoch 31; iter: 0; batch classifier loss: 0.121201; batch adversarial loss: 0.463096\n",
      "epoch 32; iter: 0; batch classifier loss: 0.191021; batch adversarial loss: 0.433255\n",
      "epoch 33; iter: 0; batch classifier loss: 0.138103; batch adversarial loss: 0.439364\n",
      "epoch 34; iter: 0; batch classifier loss: 0.145652; batch adversarial loss: 0.441821\n",
      "epoch 35; iter: 0; batch classifier loss: 0.205434; batch adversarial loss: 0.455787\n",
      "epoch 36; iter: 0; batch classifier loss: 0.108893; batch adversarial loss: 0.492068\n",
      "epoch 37; iter: 0; batch classifier loss: 0.186635; batch adversarial loss: 0.512348\n",
      "epoch 38; iter: 0; batch classifier loss: 0.132309; batch adversarial loss: 0.453290\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132401; batch adversarial loss: 0.457460\n",
      "epoch 40; iter: 0; batch classifier loss: 0.121742; batch adversarial loss: 0.438390\n",
      "epoch 41; iter: 0; batch classifier loss: 0.118500; batch adversarial loss: 0.443311\n",
      "epoch 42; iter: 0; batch classifier loss: 0.111736; batch adversarial loss: 0.514947\n",
      "epoch 43; iter: 0; batch classifier loss: 0.112409; batch adversarial loss: 0.480050\n",
      "epoch 44; iter: 0; batch classifier loss: 0.113431; batch adversarial loss: 0.517869\n",
      "epoch 45; iter: 0; batch classifier loss: 0.083733; batch adversarial loss: 0.517784\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086888; batch adversarial loss: 0.458100\n",
      "epoch 47; iter: 0; batch classifier loss: 0.147134; batch adversarial loss: 0.517047\n",
      "epoch 48; iter: 0; batch classifier loss: 0.091113; batch adversarial loss: 0.448609\n",
      "epoch 49; iter: 0; batch classifier loss: 0.177108; batch adversarial loss: 0.513493\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098998; batch adversarial loss: 0.540433\n",
      "epoch 51; iter: 0; batch classifier loss: 0.065920; batch adversarial loss: 0.550153\n",
      "epoch 52; iter: 0; batch classifier loss: 0.073099; batch adversarial loss: 0.484024\n",
      "epoch 53; iter: 0; batch classifier loss: 0.101003; batch adversarial loss: 0.512318\n",
      "epoch 54; iter: 0; batch classifier loss: 0.065472; batch adversarial loss: 0.513693\n",
      "epoch 55; iter: 0; batch classifier loss: 0.068467; batch adversarial loss: 0.460337\n",
      "epoch 56; iter: 0; batch classifier loss: 0.136806; batch adversarial loss: 0.416269\n",
      "epoch 57; iter: 0; batch classifier loss: 0.096097; batch adversarial loss: 0.415499\n",
      "epoch 58; iter: 0; batch classifier loss: 0.070066; batch adversarial loss: 0.412252\n",
      "epoch 59; iter: 0; batch classifier loss: 0.076044; batch adversarial loss: 0.473002\n",
      "epoch 60; iter: 0; batch classifier loss: 0.085280; batch adversarial loss: 0.498774\n",
      "epoch 61; iter: 0; batch classifier loss: 0.058640; batch adversarial loss: 0.503549\n",
      "epoch 62; iter: 0; batch classifier loss: 0.046338; batch adversarial loss: 0.414356\n",
      "epoch 63; iter: 0; batch classifier loss: 0.083354; batch adversarial loss: 0.357507\n",
      "epoch 64; iter: 0; batch classifier loss: 0.065131; batch adversarial loss: 0.553472\n",
      "epoch 65; iter: 0; batch classifier loss: 0.115857; batch adversarial loss: 0.426924\n",
      "epoch 66; iter: 0; batch classifier loss: 0.083190; batch adversarial loss: 0.517821\n",
      "epoch 67; iter: 0; batch classifier loss: 0.118104; batch adversarial loss: 0.412414\n",
      "epoch 68; iter: 0; batch classifier loss: 0.041659; batch adversarial loss: 0.473168\n",
      "epoch 69; iter: 0; batch classifier loss: 0.068102; batch adversarial loss: 0.470129\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066633; batch adversarial loss: 0.455096\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079403; batch adversarial loss: 0.561166\n",
      "epoch 72; iter: 0; batch classifier loss: 0.076328; batch adversarial loss: 0.521247\n",
      "epoch 73; iter: 0; batch classifier loss: 0.080109; batch adversarial loss: 0.577573\n",
      "epoch 74; iter: 0; batch classifier loss: 0.070415; batch adversarial loss: 0.491508\n",
      "epoch 75; iter: 0; batch classifier loss: 0.053928; batch adversarial loss: 0.542095\n",
      "epoch 76; iter: 0; batch classifier loss: 0.049754; batch adversarial loss: 0.470806\n",
      "epoch 77; iter: 0; batch classifier loss: 0.106351; batch adversarial loss: 0.459016\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066857; batch adversarial loss: 0.515988\n",
      "epoch 79; iter: 0; batch classifier loss: 0.046058; batch adversarial loss: 0.454308\n",
      "epoch 80; iter: 0; batch classifier loss: 0.057492; batch adversarial loss: 0.449444\n",
      "epoch 81; iter: 0; batch classifier loss: 0.042117; batch adversarial loss: 0.492371\n",
      "epoch 82; iter: 0; batch classifier loss: 0.029491; batch adversarial loss: 0.484875\n",
      "epoch 83; iter: 0; batch classifier loss: 0.060800; batch adversarial loss: 0.418048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.057457; batch adversarial loss: 0.451021\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051672; batch adversarial loss: 0.382748\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058419; batch adversarial loss: 0.386399\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054564; batch adversarial loss: 0.452360\n",
      "epoch 88; iter: 0; batch classifier loss: 0.031277; batch adversarial loss: 0.395929\n",
      "epoch 89; iter: 0; batch classifier loss: 0.026612; batch adversarial loss: 0.501788\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068343; batch adversarial loss: 0.384331\n",
      "epoch 91; iter: 0; batch classifier loss: 0.028942; batch adversarial loss: 0.416235\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051443; batch adversarial loss: 0.457216\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044852; batch adversarial loss: 0.459446\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062273; batch adversarial loss: 0.469838\n",
      "epoch 95; iter: 0; batch classifier loss: 0.020733; batch adversarial loss: 0.493006\n",
      "epoch 96; iter: 0; batch classifier loss: 0.069419; batch adversarial loss: 0.460374\n",
      "epoch 97; iter: 0; batch classifier loss: 0.027244; batch adversarial loss: 0.406427\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061036; batch adversarial loss: 0.407136\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047746; batch adversarial loss: 0.548624\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037003; batch adversarial loss: 0.430599\n",
      "epoch 101; iter: 0; batch classifier loss: 0.034935; batch adversarial loss: 0.440300\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046896; batch adversarial loss: 0.471393\n",
      "epoch 103; iter: 0; batch classifier loss: 0.030715; batch adversarial loss: 0.521991\n",
      "epoch 104; iter: 0; batch classifier loss: 0.070236; batch adversarial loss: 0.471765\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044226; batch adversarial loss: 0.487917\n",
      "epoch 106; iter: 0; batch classifier loss: 0.028203; batch adversarial loss: 0.451506\n",
      "epoch 107; iter: 0; batch classifier loss: 0.026067; batch adversarial loss: 0.409053\n",
      "epoch 108; iter: 0; batch classifier loss: 0.023769; batch adversarial loss: 0.466283\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036198; batch adversarial loss: 0.491635\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064953; batch adversarial loss: 0.428849\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057600; batch adversarial loss: 0.554492\n",
      "epoch 112; iter: 0; batch classifier loss: 0.011058; batch adversarial loss: 0.475380\n",
      "epoch 113; iter: 0; batch classifier loss: 0.032657; batch adversarial loss: 0.532806\n",
      "epoch 114; iter: 0; batch classifier loss: 0.015584; batch adversarial loss: 0.601044\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070489; batch adversarial loss: 0.497731\n",
      "epoch 116; iter: 0; batch classifier loss: 0.010141; batch adversarial loss: 0.442939\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037317; batch adversarial loss: 0.486143\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030853; batch adversarial loss: 0.445426\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031834; batch adversarial loss: 0.504560\n",
      "epoch 120; iter: 0; batch classifier loss: 0.024307; batch adversarial loss: 0.491502\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029690; batch adversarial loss: 0.482730\n",
      "epoch 122; iter: 0; batch classifier loss: 0.019543; batch adversarial loss: 0.424502\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029258; batch adversarial loss: 0.502912\n",
      "epoch 124; iter: 0; batch classifier loss: 0.064577; batch adversarial loss: 0.471622\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027083; batch adversarial loss: 0.549617\n",
      "epoch 126; iter: 0; batch classifier loss: 0.058346; batch adversarial loss: 0.407042\n",
      "epoch 127; iter: 0; batch classifier loss: 0.011584; batch adversarial loss: 0.389466\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025754; batch adversarial loss: 0.446746\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025797; batch adversarial loss: 0.419114\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025713; batch adversarial loss: 0.516018\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042936; batch adversarial loss: 0.484524\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016928; batch adversarial loss: 0.450451\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025644; batch adversarial loss: 0.520784\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035038; batch adversarial loss: 0.412173\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014514; batch adversarial loss: 0.466401\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044772; batch adversarial loss: 0.441760\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040334; batch adversarial loss: 0.499419\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025313; batch adversarial loss: 0.413583\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040042; batch adversarial loss: 0.404194\n",
      "epoch 140; iter: 0; batch classifier loss: 0.015648; batch adversarial loss: 0.439863\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052214; batch adversarial loss: 0.528464\n",
      "epoch 142; iter: 0; batch classifier loss: 0.006822; batch adversarial loss: 0.496197\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018694; batch adversarial loss: 0.532809\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020427; batch adversarial loss: 0.480684\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017060; batch adversarial loss: 0.442716\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022595; batch adversarial loss: 0.490063\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024604; batch adversarial loss: 0.455264\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039638; batch adversarial loss: 0.450130\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021679; batch adversarial loss: 0.498700\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030216; batch adversarial loss: 0.504036\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024464; batch adversarial loss: 0.502269\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021283; batch adversarial loss: 0.530429\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017815; batch adversarial loss: 0.568025\n",
      "epoch 154; iter: 0; batch classifier loss: 0.048203; batch adversarial loss: 0.442839\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014231; batch adversarial loss: 0.474591\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045933; batch adversarial loss: 0.425347\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038302; batch adversarial loss: 0.385667\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026173; batch adversarial loss: 0.450173\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015217; batch adversarial loss: 0.420053\n",
      "epoch 160; iter: 0; batch classifier loss: 0.038411; batch adversarial loss: 0.523421\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015132; batch adversarial loss: 0.541465\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029260; batch adversarial loss: 0.535694\n",
      "epoch 163; iter: 0; batch classifier loss: 0.062214; batch adversarial loss: 0.607215\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027573; batch adversarial loss: 0.474002\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011031; batch adversarial loss: 0.383368\n",
      "epoch 166; iter: 0; batch classifier loss: 0.043176; batch adversarial loss: 0.400811\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022970; batch adversarial loss: 0.433875\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009022; batch adversarial loss: 0.411213\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028704; batch adversarial loss: 0.374922\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015663; batch adversarial loss: 0.413925\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016472; batch adversarial loss: 0.436836\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019984; batch adversarial loss: 0.409479\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034664; batch adversarial loss: 0.380548\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008555; batch adversarial loss: 0.481537\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008775; batch adversarial loss: 0.459876\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012024; batch adversarial loss: 0.493760\n",
      "epoch 177; iter: 0; batch classifier loss: 0.053590; batch adversarial loss: 0.519126\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022957; batch adversarial loss: 0.519312\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024416; batch adversarial loss: 0.464938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.023535; batch adversarial loss: 0.481900\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015605; batch adversarial loss: 0.503162\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015299; batch adversarial loss: 0.318020\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007506; batch adversarial loss: 0.544208\n",
      "epoch 184; iter: 0; batch classifier loss: 0.042526; batch adversarial loss: 0.460999\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008342; batch adversarial loss: 0.526005\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029373; batch adversarial loss: 0.447782\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039320; batch adversarial loss: 0.506009\n",
      "epoch 188; iter: 0; batch classifier loss: 0.046932; batch adversarial loss: 0.422232\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014312; batch adversarial loss: 0.403819\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025606; batch adversarial loss: 0.439934\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006929; batch adversarial loss: 0.507031\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021777; batch adversarial loss: 0.446350\n",
      "epoch 193; iter: 0; batch classifier loss: 0.036635; batch adversarial loss: 0.591076\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015182; batch adversarial loss: 0.523104\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011561; batch adversarial loss: 0.496248\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017533; batch adversarial loss: 0.396813\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025301; batch adversarial loss: 0.501832\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014028; batch adversarial loss: 0.480408\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012483; batch adversarial loss: 0.440154\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684349; batch adversarial loss: 0.529332\n",
      "epoch 1; iter: 0; batch classifier loss: 0.440491; batch adversarial loss: 0.616824\n",
      "epoch 2; iter: 0; batch classifier loss: 0.327800; batch adversarial loss: 0.616790\n",
      "epoch 3; iter: 0; batch classifier loss: 0.371312; batch adversarial loss: 0.576764\n",
      "epoch 4; iter: 0; batch classifier loss: 0.351545; batch adversarial loss: 0.608207\n",
      "epoch 5; iter: 0; batch classifier loss: 0.389992; batch adversarial loss: 0.600302\n",
      "epoch 6; iter: 0; batch classifier loss: 0.378253; batch adversarial loss: 0.515932\n",
      "epoch 7; iter: 0; batch classifier loss: 0.276617; batch adversarial loss: 0.561008\n",
      "epoch 8; iter: 0; batch classifier loss: 0.390634; batch adversarial loss: 0.557635\n",
      "epoch 9; iter: 0; batch classifier loss: 0.356613; batch adversarial loss: 0.522757\n",
      "epoch 10; iter: 0; batch classifier loss: 0.261575; batch adversarial loss: 0.548095\n",
      "epoch 11; iter: 0; batch classifier loss: 0.384167; batch adversarial loss: 0.504571\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491360; batch adversarial loss: 0.556305\n",
      "epoch 13; iter: 0; batch classifier loss: 0.462458; batch adversarial loss: 0.557493\n",
      "epoch 14; iter: 0; batch classifier loss: 0.613654; batch adversarial loss: 0.487059\n",
      "epoch 15; iter: 0; batch classifier loss: 0.427139; batch adversarial loss: 0.505688\n",
      "epoch 16; iter: 0; batch classifier loss: 0.293054; batch adversarial loss: 0.477821\n",
      "epoch 17; iter: 0; batch classifier loss: 0.253534; batch adversarial loss: 0.560244\n",
      "epoch 18; iter: 0; batch classifier loss: 0.222012; batch adversarial loss: 0.474660\n",
      "epoch 19; iter: 0; batch classifier loss: 0.209257; batch adversarial loss: 0.473808\n",
      "epoch 20; iter: 0; batch classifier loss: 0.260297; batch adversarial loss: 0.500510\n",
      "epoch 21; iter: 0; batch classifier loss: 0.227614; batch adversarial loss: 0.383909\n",
      "epoch 22; iter: 0; batch classifier loss: 0.166270; batch adversarial loss: 0.446972\n",
      "epoch 23; iter: 0; batch classifier loss: 0.208102; batch adversarial loss: 0.484691\n",
      "epoch 24; iter: 0; batch classifier loss: 0.130927; batch adversarial loss: 0.484114\n",
      "epoch 25; iter: 0; batch classifier loss: 0.187019; batch adversarial loss: 0.456817\n",
      "epoch 26; iter: 0; batch classifier loss: 0.116795; batch adversarial loss: 0.455296\n",
      "epoch 27; iter: 0; batch classifier loss: 0.163300; batch adversarial loss: 0.449790\n",
      "epoch 28; iter: 0; batch classifier loss: 0.226193; batch adversarial loss: 0.432235\n",
      "epoch 29; iter: 0; batch classifier loss: 0.102477; batch adversarial loss: 0.477883\n",
      "epoch 30; iter: 0; batch classifier loss: 0.192226; batch adversarial loss: 0.453556\n",
      "epoch 31; iter: 0; batch classifier loss: 0.139756; batch adversarial loss: 0.434644\n",
      "epoch 32; iter: 0; batch classifier loss: 0.139313; batch adversarial loss: 0.475192\n",
      "epoch 33; iter: 0; batch classifier loss: 0.156046; batch adversarial loss: 0.412865\n",
      "epoch 34; iter: 0; batch classifier loss: 0.146158; batch adversarial loss: 0.421369\n",
      "epoch 35; iter: 0; batch classifier loss: 0.105099; batch adversarial loss: 0.493915\n",
      "epoch 36; iter: 0; batch classifier loss: 0.101449; batch adversarial loss: 0.425842\n",
      "epoch 37; iter: 0; batch classifier loss: 0.089430; batch adversarial loss: 0.400584\n",
      "epoch 38; iter: 0; batch classifier loss: 0.119727; batch adversarial loss: 0.428407\n",
      "epoch 39; iter: 0; batch classifier loss: 0.166445; batch adversarial loss: 0.415584\n",
      "epoch 40; iter: 0; batch classifier loss: 0.139740; batch adversarial loss: 0.518024\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098638; batch adversarial loss: 0.461422\n",
      "epoch 42; iter: 0; batch classifier loss: 0.108440; batch adversarial loss: 0.505152\n",
      "epoch 43; iter: 0; batch classifier loss: 0.087656; batch adversarial loss: 0.510651\n",
      "epoch 44; iter: 0; batch classifier loss: 0.084185; batch adversarial loss: 0.439284\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104978; batch adversarial loss: 0.350596\n",
      "epoch 46; iter: 0; batch classifier loss: 0.055350; batch adversarial loss: 0.418077\n",
      "epoch 47; iter: 0; batch classifier loss: 0.105400; batch adversarial loss: 0.496626\n",
      "epoch 48; iter: 0; batch classifier loss: 0.128245; batch adversarial loss: 0.471079\n",
      "epoch 49; iter: 0; batch classifier loss: 0.102677; batch adversarial loss: 0.548636\n",
      "epoch 50; iter: 0; batch classifier loss: 0.099039; batch adversarial loss: 0.378256\n",
      "epoch 51; iter: 0; batch classifier loss: 0.091539; batch adversarial loss: 0.542134\n",
      "epoch 52; iter: 0; batch classifier loss: 0.084627; batch adversarial loss: 0.568100\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094022; batch adversarial loss: 0.449353\n",
      "epoch 54; iter: 0; batch classifier loss: 0.105012; batch adversarial loss: 0.467757\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084285; batch adversarial loss: 0.468720\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065733; batch adversarial loss: 0.472250\n",
      "epoch 57; iter: 0; batch classifier loss: 0.115804; batch adversarial loss: 0.421754\n",
      "epoch 58; iter: 0; batch classifier loss: 0.050685; batch adversarial loss: 0.471305\n",
      "epoch 59; iter: 0; batch classifier loss: 0.095869; batch adversarial loss: 0.498346\n",
      "epoch 60; iter: 0; batch classifier loss: 0.115847; batch adversarial loss: 0.443349\n",
      "epoch 61; iter: 0; batch classifier loss: 0.079814; batch adversarial loss: 0.495526\n",
      "epoch 62; iter: 0; batch classifier loss: 0.066187; batch adversarial loss: 0.452017\n",
      "epoch 63; iter: 0; batch classifier loss: 0.108587; batch adversarial loss: 0.358765\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106446; batch adversarial loss: 0.419073\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070907; batch adversarial loss: 0.431873\n",
      "epoch 66; iter: 0; batch classifier loss: 0.064496; batch adversarial loss: 0.511256\n",
      "epoch 67; iter: 0; batch classifier loss: 0.097561; batch adversarial loss: 0.466206\n",
      "epoch 68; iter: 0; batch classifier loss: 0.091903; batch adversarial loss: 0.535776\n",
      "epoch 69; iter: 0; batch classifier loss: 0.091380; batch adversarial loss: 0.386902\n",
      "epoch 70; iter: 0; batch classifier loss: 0.102120; batch adversarial loss: 0.462857\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079817; batch adversarial loss: 0.393574\n",
      "epoch 72; iter: 0; batch classifier loss: 0.152263; batch adversarial loss: 0.421117\n",
      "epoch 73; iter: 0; batch classifier loss: 0.081655; batch adversarial loss: 0.544309\n",
      "epoch 74; iter: 0; batch classifier loss: 0.112748; batch adversarial loss: 0.512595\n",
      "epoch 75; iter: 0; batch classifier loss: 0.094692; batch adversarial loss: 0.458870\n",
      "epoch 76; iter: 0; batch classifier loss: 0.084050; batch adversarial loss: 0.443482\n",
      "epoch 77; iter: 0; batch classifier loss: 0.082785; batch adversarial loss: 0.489661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.039111; batch adversarial loss: 0.422870\n",
      "epoch 79; iter: 0; batch classifier loss: 0.049627; batch adversarial loss: 0.461030\n",
      "epoch 80; iter: 0; batch classifier loss: 0.100784; batch adversarial loss: 0.458331\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057443; batch adversarial loss: 0.461363\n",
      "epoch 82; iter: 0; batch classifier loss: 0.089686; batch adversarial loss: 0.520535\n",
      "epoch 83; iter: 0; batch classifier loss: 0.093558; batch adversarial loss: 0.415753\n",
      "epoch 84; iter: 0; batch classifier loss: 0.093461; batch adversarial loss: 0.431783\n",
      "epoch 85; iter: 0; batch classifier loss: 0.097160; batch adversarial loss: 0.475840\n",
      "epoch 86; iter: 0; batch classifier loss: 0.111077; batch adversarial loss: 0.496594\n",
      "epoch 87; iter: 0; batch classifier loss: 0.078837; batch adversarial loss: 0.459633\n",
      "epoch 88; iter: 0; batch classifier loss: 0.090911; batch adversarial loss: 0.387826\n",
      "epoch 89; iter: 0; batch classifier loss: 0.078893; batch adversarial loss: 0.457860\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068575; batch adversarial loss: 0.387650\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057312; batch adversarial loss: 0.400736\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055348; batch adversarial loss: 0.464597\n",
      "epoch 93; iter: 0; batch classifier loss: 0.089465; batch adversarial loss: 0.491499\n",
      "epoch 94; iter: 0; batch classifier loss: 0.081963; batch adversarial loss: 0.421348\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071497; batch adversarial loss: 0.447612\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045926; batch adversarial loss: 0.414069\n",
      "epoch 97; iter: 0; batch classifier loss: 0.080327; batch adversarial loss: 0.481648\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052997; batch adversarial loss: 0.499095\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069317; batch adversarial loss: 0.473223\n",
      "epoch 100; iter: 0; batch classifier loss: 0.035612; batch adversarial loss: 0.495579\n",
      "epoch 101; iter: 0; batch classifier loss: 0.101777; batch adversarial loss: 0.322554\n",
      "epoch 102; iter: 0; batch classifier loss: 0.075652; batch adversarial loss: 0.440389\n",
      "epoch 103; iter: 0; batch classifier loss: 0.101839; batch adversarial loss: 0.434487\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043523; batch adversarial loss: 0.399779\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038605; batch adversarial loss: 0.475573\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054338; batch adversarial loss: 0.532092\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065884; batch adversarial loss: 0.423572\n",
      "epoch 108; iter: 0; batch classifier loss: 0.112615; batch adversarial loss: 0.408057\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045854; batch adversarial loss: 0.534040\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053539; batch adversarial loss: 0.508579\n",
      "epoch 111; iter: 0; batch classifier loss: 0.094475; batch adversarial loss: 0.450250\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025491; batch adversarial loss: 0.467249\n",
      "epoch 113; iter: 0; batch classifier loss: 0.079446; batch adversarial loss: 0.462008\n",
      "epoch 114; iter: 0; batch classifier loss: 0.016049; batch adversarial loss: 0.485647\n",
      "epoch 115; iter: 0; batch classifier loss: 0.086824; batch adversarial loss: 0.446467\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036577; batch adversarial loss: 0.475671\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046223; batch adversarial loss: 0.414281\n",
      "epoch 118; iter: 0; batch classifier loss: 0.058556; batch adversarial loss: 0.403363\n",
      "epoch 119; iter: 0; batch classifier loss: 0.016364; batch adversarial loss: 0.395642\n",
      "epoch 120; iter: 0; batch classifier loss: 0.094404; batch adversarial loss: 0.373055\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043406; batch adversarial loss: 0.490519\n",
      "epoch 122; iter: 0; batch classifier loss: 0.023079; batch adversarial loss: 0.488960\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041235; batch adversarial loss: 0.414995\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026855; batch adversarial loss: 0.458260\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040093; batch adversarial loss: 0.403821\n",
      "epoch 126; iter: 0; batch classifier loss: 0.020729; batch adversarial loss: 0.368212\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032764; batch adversarial loss: 0.517882\n",
      "epoch 128; iter: 0; batch classifier loss: 0.084910; batch adversarial loss: 0.481660\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020005; batch adversarial loss: 0.510672\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024924; batch adversarial loss: 0.572720\n",
      "epoch 131; iter: 0; batch classifier loss: 0.053365; batch adversarial loss: 0.440734\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036644; batch adversarial loss: 0.533173\n",
      "epoch 133; iter: 0; batch classifier loss: 0.011744; batch adversarial loss: 0.496521\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030284; batch adversarial loss: 0.443572\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030601; batch adversarial loss: 0.480536\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040031; batch adversarial loss: 0.478831\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024912; batch adversarial loss: 0.516516\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041635; batch adversarial loss: 0.552664\n",
      "epoch 139; iter: 0; batch classifier loss: 0.051573; batch adversarial loss: 0.490079\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035368; batch adversarial loss: 0.413572\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034471; batch adversarial loss: 0.487130\n",
      "epoch 142; iter: 0; batch classifier loss: 0.061607; batch adversarial loss: 0.425490\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042510; batch adversarial loss: 0.405221\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033987; batch adversarial loss: 0.509721\n",
      "epoch 145; iter: 0; batch classifier loss: 0.068847; batch adversarial loss: 0.505394\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037418; batch adversarial loss: 0.522461\n",
      "epoch 147; iter: 0; batch classifier loss: 0.061741; batch adversarial loss: 0.477750\n",
      "epoch 148; iter: 0; batch classifier loss: 0.010213; batch adversarial loss: 0.500889\n",
      "epoch 149; iter: 0; batch classifier loss: 0.059979; batch adversarial loss: 0.414214\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014577; batch adversarial loss: 0.455920\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012140; batch adversarial loss: 0.421510\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010163; batch adversarial loss: 0.497469\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032386; batch adversarial loss: 0.387606\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021913; batch adversarial loss: 0.415170\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025196; batch adversarial loss: 0.414163\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030711; batch adversarial loss: 0.494626\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014343; batch adversarial loss: 0.464870\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042708; batch adversarial loss: 0.552781\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017504; batch adversarial loss: 0.483163\n",
      "epoch 160; iter: 0; batch classifier loss: 0.074124; batch adversarial loss: 0.555007\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018923; batch adversarial loss: 0.410323\n",
      "epoch 162; iter: 0; batch classifier loss: 0.057684; batch adversarial loss: 0.483334\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036789; batch adversarial loss: 0.468228\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022823; batch adversarial loss: 0.506100\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019114; batch adversarial loss: 0.512936\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027327; batch adversarial loss: 0.410637\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019563; batch adversarial loss: 0.473309\n",
      "epoch 168; iter: 0; batch classifier loss: 0.055010; batch adversarial loss: 0.434052\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029912; batch adversarial loss: 0.475620\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030877; batch adversarial loss: 0.402498\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020636; batch adversarial loss: 0.441034\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019855; batch adversarial loss: 0.562594\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026186; batch adversarial loss: 0.522951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.042692; batch adversarial loss: 0.528347\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021158; batch adversarial loss: 0.475552\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034857; batch adversarial loss: 0.425723\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020385; batch adversarial loss: 0.431987\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030092; batch adversarial loss: 0.416560\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044054; batch adversarial loss: 0.346405\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028950; batch adversarial loss: 0.509017\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023817; batch adversarial loss: 0.457887\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029461; batch adversarial loss: 0.421580\n",
      "epoch 183; iter: 0; batch classifier loss: 0.003116; batch adversarial loss: 0.454853\n",
      "epoch 184; iter: 0; batch classifier loss: 0.048494; batch adversarial loss: 0.497414\n",
      "epoch 185; iter: 0; batch classifier loss: 0.005552; batch adversarial loss: 0.536782\n",
      "epoch 186; iter: 0; batch classifier loss: 0.055784; batch adversarial loss: 0.403606\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031695; batch adversarial loss: 0.473250\n",
      "epoch 188; iter: 0; batch classifier loss: 0.039674; batch adversarial loss: 0.477184\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023658; batch adversarial loss: 0.489577\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019438; batch adversarial loss: 0.436818\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016183; batch adversarial loss: 0.488228\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024677; batch adversarial loss: 0.439730\n",
      "epoch 193; iter: 0; batch classifier loss: 0.038849; batch adversarial loss: 0.408907\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010658; batch adversarial loss: 0.446505\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006487; batch adversarial loss: 0.446433\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021221; batch adversarial loss: 0.495734\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005216; batch adversarial loss: 0.526500\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018192; batch adversarial loss: 0.499888\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028397; batch adversarial loss: 0.446852\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701351; batch adversarial loss: 0.543331\n",
      "epoch 1; iter: 0; batch classifier loss: 0.386897; batch adversarial loss: 0.596545\n",
      "epoch 2; iter: 0; batch classifier loss: 0.369075; batch adversarial loss: 0.585013\n",
      "epoch 3; iter: 0; batch classifier loss: 0.369942; batch adversarial loss: 0.567838\n",
      "epoch 4; iter: 0; batch classifier loss: 0.367264; batch adversarial loss: 0.567264\n",
      "epoch 5; iter: 0; batch classifier loss: 0.397265; batch adversarial loss: 0.640278\n",
      "epoch 6; iter: 0; batch classifier loss: 0.378273; batch adversarial loss: 0.546899\n",
      "epoch 7; iter: 0; batch classifier loss: 0.307298; batch adversarial loss: 0.530640\n",
      "epoch 8; iter: 0; batch classifier loss: 0.273981; batch adversarial loss: 0.585740\n",
      "epoch 9; iter: 0; batch classifier loss: 0.342301; batch adversarial loss: 0.521992\n",
      "epoch 10; iter: 0; batch classifier loss: 0.327427; batch adversarial loss: 0.557510\n",
      "epoch 11; iter: 0; batch classifier loss: 0.330129; batch adversarial loss: 0.547430\n",
      "epoch 12; iter: 0; batch classifier loss: 0.261622; batch adversarial loss: 0.531285\n",
      "epoch 13; iter: 0; batch classifier loss: 0.373870; batch adversarial loss: 0.498998\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469957; batch adversarial loss: 0.502499\n",
      "epoch 15; iter: 0; batch classifier loss: 0.405711; batch adversarial loss: 0.487328\n",
      "epoch 16; iter: 0; batch classifier loss: 0.557631; batch adversarial loss: 0.511109\n",
      "epoch 17; iter: 0; batch classifier loss: 0.383481; batch adversarial loss: 0.495522\n",
      "epoch 18; iter: 0; batch classifier loss: 0.264690; batch adversarial loss: 0.511335\n",
      "epoch 19; iter: 0; batch classifier loss: 0.274621; batch adversarial loss: 0.498320\n",
      "epoch 20; iter: 0; batch classifier loss: 0.202503; batch adversarial loss: 0.421195\n",
      "epoch 21; iter: 0; batch classifier loss: 0.198705; batch adversarial loss: 0.383535\n",
      "epoch 22; iter: 0; batch classifier loss: 0.196814; batch adversarial loss: 0.468464\n",
      "epoch 23; iter: 0; batch classifier loss: 0.233286; batch adversarial loss: 0.503581\n",
      "epoch 24; iter: 0; batch classifier loss: 0.196642; batch adversarial loss: 0.520387\n",
      "epoch 25; iter: 0; batch classifier loss: 0.175893; batch adversarial loss: 0.390675\n",
      "epoch 26; iter: 0; batch classifier loss: 0.197903; batch adversarial loss: 0.448440\n",
      "epoch 27; iter: 0; batch classifier loss: 0.159909; batch adversarial loss: 0.430688\n",
      "epoch 28; iter: 0; batch classifier loss: 0.144766; batch adversarial loss: 0.494226\n",
      "epoch 29; iter: 0; batch classifier loss: 0.111034; batch adversarial loss: 0.430953\n",
      "epoch 30; iter: 0; batch classifier loss: 0.175716; batch adversarial loss: 0.486431\n",
      "epoch 31; iter: 0; batch classifier loss: 0.137401; batch adversarial loss: 0.469396\n",
      "epoch 32; iter: 0; batch classifier loss: 0.139961; batch adversarial loss: 0.466265\n",
      "epoch 33; iter: 0; batch classifier loss: 0.111930; batch adversarial loss: 0.349768\n",
      "epoch 34; iter: 0; batch classifier loss: 0.094230; batch adversarial loss: 0.533552\n",
      "epoch 35; iter: 0; batch classifier loss: 0.200667; batch adversarial loss: 0.511975\n",
      "epoch 36; iter: 0; batch classifier loss: 0.098885; batch adversarial loss: 0.472180\n",
      "epoch 37; iter: 0; batch classifier loss: 0.109291; batch adversarial loss: 0.404908\n",
      "epoch 38; iter: 0; batch classifier loss: 0.143337; batch adversarial loss: 0.523878\n",
      "epoch 39; iter: 0; batch classifier loss: 0.095703; batch adversarial loss: 0.405717\n",
      "epoch 40; iter: 0; batch classifier loss: 0.077322; batch adversarial loss: 0.543584\n",
      "epoch 41; iter: 0; batch classifier loss: 0.071348; batch adversarial loss: 0.526752\n",
      "epoch 42; iter: 0; batch classifier loss: 0.174308; batch adversarial loss: 0.428247\n",
      "epoch 43; iter: 0; batch classifier loss: 0.107958; batch adversarial loss: 0.435616\n",
      "epoch 44; iter: 0; batch classifier loss: 0.099619; batch adversarial loss: 0.445975\n",
      "epoch 45; iter: 0; batch classifier loss: 0.109937; batch adversarial loss: 0.456874\n",
      "epoch 46; iter: 0; batch classifier loss: 0.084038; batch adversarial loss: 0.444325\n",
      "epoch 47; iter: 0; batch classifier loss: 0.075461; batch adversarial loss: 0.480063\n",
      "epoch 48; iter: 0; batch classifier loss: 0.120203; batch adversarial loss: 0.461120\n",
      "epoch 49; iter: 0; batch classifier loss: 0.141174; batch adversarial loss: 0.451379\n",
      "epoch 50; iter: 0; batch classifier loss: 0.138627; batch adversarial loss: 0.419926\n",
      "epoch 51; iter: 0; batch classifier loss: 0.101431; batch adversarial loss: 0.482604\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082929; batch adversarial loss: 0.460020\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084193; batch adversarial loss: 0.402237\n",
      "epoch 54; iter: 0; batch classifier loss: 0.097939; batch adversarial loss: 0.500798\n",
      "epoch 55; iter: 0; batch classifier loss: 0.105000; batch adversarial loss: 0.391867\n",
      "epoch 56; iter: 0; batch classifier loss: 0.147703; batch adversarial loss: 0.371839\n",
      "epoch 57; iter: 0; batch classifier loss: 0.099735; batch adversarial loss: 0.540459\n",
      "epoch 58; iter: 0; batch classifier loss: 0.093032; batch adversarial loss: 0.434077\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083040; batch adversarial loss: 0.435044\n",
      "epoch 60; iter: 0; batch classifier loss: 0.102530; batch adversarial loss: 0.366866\n",
      "epoch 61; iter: 0; batch classifier loss: 0.082627; batch adversarial loss: 0.548685\n",
      "epoch 62; iter: 0; batch classifier loss: 0.100729; batch adversarial loss: 0.479721\n",
      "epoch 63; iter: 0; batch classifier loss: 0.091776; batch adversarial loss: 0.524764\n",
      "epoch 64; iter: 0; batch classifier loss: 0.160295; batch adversarial loss: 0.498611\n",
      "epoch 65; iter: 0; batch classifier loss: 0.137730; batch adversarial loss: 0.487259\n",
      "epoch 66; iter: 0; batch classifier loss: 0.087649; batch adversarial loss: 0.505946\n",
      "epoch 67; iter: 0; batch classifier loss: 0.130874; batch adversarial loss: 0.496185\n",
      "epoch 68; iter: 0; batch classifier loss: 0.139067; batch adversarial loss: 0.482172\n",
      "epoch 69; iter: 0; batch classifier loss: 0.117002; batch adversarial loss: 0.421391\n",
      "epoch 70; iter: 0; batch classifier loss: 0.120931; batch adversarial loss: 0.390245\n",
      "epoch 71; iter: 0; batch classifier loss: 0.130588; batch adversarial loss: 0.416591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.076357; batch adversarial loss: 0.546235\n",
      "epoch 73; iter: 0; batch classifier loss: 0.106007; batch adversarial loss: 0.430335\n",
      "epoch 74; iter: 0; batch classifier loss: 0.132393; batch adversarial loss: 0.466947\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069313; batch adversarial loss: 0.569455\n",
      "epoch 76; iter: 0; batch classifier loss: 0.080611; batch adversarial loss: 0.491464\n",
      "epoch 77; iter: 0; batch classifier loss: 0.080734; batch adversarial loss: 0.524913\n",
      "epoch 78; iter: 0; batch classifier loss: 0.126466; batch adversarial loss: 0.446419\n",
      "epoch 79; iter: 0; batch classifier loss: 0.126128; batch adversarial loss: 0.510719\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068473; batch adversarial loss: 0.516491\n",
      "epoch 81; iter: 0; batch classifier loss: 0.111263; batch adversarial loss: 0.488755\n",
      "epoch 82; iter: 0; batch classifier loss: 0.068723; batch adversarial loss: 0.380320\n",
      "epoch 83; iter: 0; batch classifier loss: 0.066381; batch adversarial loss: 0.520560\n",
      "epoch 84; iter: 0; batch classifier loss: 0.096718; batch adversarial loss: 0.435257\n",
      "epoch 85; iter: 0; batch classifier loss: 0.120057; batch adversarial loss: 0.416802\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076848; batch adversarial loss: 0.460937\n",
      "epoch 87; iter: 0; batch classifier loss: 0.085119; batch adversarial loss: 0.402187\n",
      "epoch 88; iter: 0; batch classifier loss: 0.061238; batch adversarial loss: 0.556146\n",
      "epoch 89; iter: 0; batch classifier loss: 0.086076; batch adversarial loss: 0.537435\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063783; batch adversarial loss: 0.430673\n",
      "epoch 91; iter: 0; batch classifier loss: 0.078972; batch adversarial loss: 0.424875\n",
      "epoch 92; iter: 0; batch classifier loss: 0.084414; batch adversarial loss: 0.423588\n",
      "epoch 93; iter: 0; batch classifier loss: 0.101107; batch adversarial loss: 0.386464\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056485; batch adversarial loss: 0.453778\n",
      "epoch 95; iter: 0; batch classifier loss: 0.074476; batch adversarial loss: 0.456703\n",
      "epoch 96; iter: 0; batch classifier loss: 0.078814; batch adversarial loss: 0.504112\n",
      "epoch 97; iter: 0; batch classifier loss: 0.078990; batch adversarial loss: 0.525159\n",
      "epoch 98; iter: 0; batch classifier loss: 0.101814; batch adversarial loss: 0.468435\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038888; batch adversarial loss: 0.423577\n",
      "epoch 100; iter: 0; batch classifier loss: 0.058722; batch adversarial loss: 0.469190\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056651; batch adversarial loss: 0.510513\n",
      "epoch 102; iter: 0; batch classifier loss: 0.087845; batch adversarial loss: 0.447920\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058363; batch adversarial loss: 0.520832\n",
      "epoch 104; iter: 0; batch classifier loss: 0.089241; batch adversarial loss: 0.567238\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058392; batch adversarial loss: 0.489200\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052749; batch adversarial loss: 0.441540\n",
      "epoch 107; iter: 0; batch classifier loss: 0.084553; batch adversarial loss: 0.435365\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028066; batch adversarial loss: 0.476899\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040843; batch adversarial loss: 0.518966\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049017; batch adversarial loss: 0.475213\n",
      "epoch 111; iter: 0; batch classifier loss: 0.114048; batch adversarial loss: 0.405596\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044670; batch adversarial loss: 0.493633\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038904; batch adversarial loss: 0.405194\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050225; batch adversarial loss: 0.425892\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043618; batch adversarial loss: 0.473391\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030311; batch adversarial loss: 0.409652\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044894; batch adversarial loss: 0.386428\n",
      "epoch 118; iter: 0; batch classifier loss: 0.013786; batch adversarial loss: 0.467018\n",
      "epoch 119; iter: 0; batch classifier loss: 0.070678; batch adversarial loss: 0.394131\n",
      "epoch 120; iter: 0; batch classifier loss: 0.020332; batch adversarial loss: 0.512765\n",
      "epoch 121; iter: 0; batch classifier loss: 0.023784; batch adversarial loss: 0.462433\n",
      "epoch 122; iter: 0; batch classifier loss: 0.054319; batch adversarial loss: 0.464865\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031105; batch adversarial loss: 0.485740\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027150; batch adversarial loss: 0.475468\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034808; batch adversarial loss: 0.496019\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021296; batch adversarial loss: 0.440425\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022949; batch adversarial loss: 0.518193\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022568; batch adversarial loss: 0.513737\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033756; batch adversarial loss: 0.503820\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039382; batch adversarial loss: 0.443530\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026855; batch adversarial loss: 0.433885\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053494; batch adversarial loss: 0.429712\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031596; batch adversarial loss: 0.455641\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037789; batch adversarial loss: 0.478916\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059391; batch adversarial loss: 0.450574\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013948; batch adversarial loss: 0.422820\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026223; batch adversarial loss: 0.388398\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017027; batch adversarial loss: 0.501456\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015925; batch adversarial loss: 0.502060\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019861; batch adversarial loss: 0.483489\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048200; batch adversarial loss: 0.584224\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030149; batch adversarial loss: 0.459510\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030866; batch adversarial loss: 0.504387\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028891; batch adversarial loss: 0.428787\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016166; batch adversarial loss: 0.453581\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048262; batch adversarial loss: 0.435748\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041398; batch adversarial loss: 0.568547\n",
      "epoch 148; iter: 0; batch classifier loss: 0.041863; batch adversarial loss: 0.387809\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020467; batch adversarial loss: 0.442172\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013204; batch adversarial loss: 0.493265\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023948; batch adversarial loss: 0.525815\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023302; batch adversarial loss: 0.490700\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012633; batch adversarial loss: 0.565830\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023246; batch adversarial loss: 0.492856\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038135; batch adversarial loss: 0.546675\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023001; batch adversarial loss: 0.468590\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020476; batch adversarial loss: 0.393939\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012411; batch adversarial loss: 0.475580\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024882; batch adversarial loss: 0.468680\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029145; batch adversarial loss: 0.374172\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021834; batch adversarial loss: 0.402866\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015527; batch adversarial loss: 0.529432\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006449; batch adversarial loss: 0.580295\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014793; batch adversarial loss: 0.485725\n",
      "epoch 165; iter: 0; batch classifier loss: 0.007868; batch adversarial loss: 0.416452\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031587; batch adversarial loss: 0.470932\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026138; batch adversarial loss: 0.477931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.031253; batch adversarial loss: 0.408774\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021188; batch adversarial loss: 0.416039\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022972; batch adversarial loss: 0.409304\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031862; batch adversarial loss: 0.418960\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019879; batch adversarial loss: 0.592229\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017894; batch adversarial loss: 0.522161\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009508; batch adversarial loss: 0.501568\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014775; batch adversarial loss: 0.471214\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023791; batch adversarial loss: 0.388905\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022173; batch adversarial loss: 0.380266\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011185; batch adversarial loss: 0.353620\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027749; batch adversarial loss: 0.526301\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006882; batch adversarial loss: 0.465344\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010429; batch adversarial loss: 0.501387\n",
      "epoch 182; iter: 0; batch classifier loss: 0.004298; batch adversarial loss: 0.470159\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013566; batch adversarial loss: 0.426949\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022897; batch adversarial loss: 0.469549\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028918; batch adversarial loss: 0.436085\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017176; batch adversarial loss: 0.510629\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009250; batch adversarial loss: 0.324528\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030940; batch adversarial loss: 0.498310\n",
      "epoch 189; iter: 0; batch classifier loss: 0.047129; batch adversarial loss: 0.501942\n",
      "epoch 190; iter: 0; batch classifier loss: 0.050356; batch adversarial loss: 0.391909\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026222; batch adversarial loss: 0.444815\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023685; batch adversarial loss: 0.474880\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024096; batch adversarial loss: 0.412220\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004463; batch adversarial loss: 0.518426\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008812; batch adversarial loss: 0.530825\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019300; batch adversarial loss: 0.489934\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018752; batch adversarial loss: 0.455311\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016288; batch adversarial loss: 0.429138\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022533; batch adversarial loss: 0.367695\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714817; batch adversarial loss: 0.679663\n",
      "epoch 1; iter: 0; batch classifier loss: 0.495803; batch adversarial loss: 0.637144\n",
      "epoch 2; iter: 0; batch classifier loss: 0.401703; batch adversarial loss: 0.557441\n",
      "epoch 3; iter: 0; batch classifier loss: 0.396681; batch adversarial loss: 0.557260\n",
      "epoch 4; iter: 0; batch classifier loss: 0.288252; batch adversarial loss: 0.614672\n",
      "epoch 5; iter: 0; batch classifier loss: 0.391569; batch adversarial loss: 0.603778\n",
      "epoch 6; iter: 0; batch classifier loss: 0.311596; batch adversarial loss: 0.558805\n",
      "epoch 7; iter: 0; batch classifier loss: 0.308788; batch adversarial loss: 0.529882\n",
      "epoch 8; iter: 0; batch classifier loss: 0.267820; batch adversarial loss: 0.483129\n",
      "epoch 9; iter: 0; batch classifier loss: 0.231288; batch adversarial loss: 0.485985\n",
      "epoch 10; iter: 0; batch classifier loss: 0.181995; batch adversarial loss: 0.563110\n",
      "epoch 11; iter: 0; batch classifier loss: 0.374680; batch adversarial loss: 0.582983\n",
      "epoch 12; iter: 0; batch classifier loss: 0.266654; batch adversarial loss: 0.491212\n",
      "epoch 13; iter: 0; batch classifier loss: 0.247501; batch adversarial loss: 0.497943\n",
      "epoch 14; iter: 0; batch classifier loss: 0.205497; batch adversarial loss: 0.532521\n",
      "epoch 15; iter: 0; batch classifier loss: 0.257604; batch adversarial loss: 0.532451\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222101; batch adversarial loss: 0.509119\n",
      "epoch 17; iter: 0; batch classifier loss: 0.220735; batch adversarial loss: 0.558922\n",
      "epoch 18; iter: 0; batch classifier loss: 0.239126; batch adversarial loss: 0.453748\n",
      "epoch 19; iter: 0; batch classifier loss: 0.224022; batch adversarial loss: 0.510528\n",
      "epoch 20; iter: 0; batch classifier loss: 0.184902; batch adversarial loss: 0.415492\n",
      "epoch 21; iter: 0; batch classifier loss: 0.155167; batch adversarial loss: 0.469941\n",
      "epoch 22; iter: 0; batch classifier loss: 0.145460; batch adversarial loss: 0.434241\n",
      "epoch 23; iter: 0; batch classifier loss: 0.155258; batch adversarial loss: 0.401147\n",
      "epoch 24; iter: 0; batch classifier loss: 0.159510; batch adversarial loss: 0.547286\n",
      "epoch 25; iter: 0; batch classifier loss: 0.135720; batch adversarial loss: 0.433856\n",
      "epoch 26; iter: 0; batch classifier loss: 0.143704; batch adversarial loss: 0.551920\n",
      "epoch 27; iter: 0; batch classifier loss: 0.124894; batch adversarial loss: 0.432267\n",
      "epoch 28; iter: 0; batch classifier loss: 0.122668; batch adversarial loss: 0.494636\n",
      "epoch 29; iter: 0; batch classifier loss: 0.119886; batch adversarial loss: 0.401059\n",
      "epoch 30; iter: 0; batch classifier loss: 0.142667; batch adversarial loss: 0.440536\n",
      "epoch 31; iter: 0; batch classifier loss: 0.167794; batch adversarial loss: 0.417440\n",
      "epoch 32; iter: 0; batch classifier loss: 0.121625; batch adversarial loss: 0.462189\n",
      "epoch 33; iter: 0; batch classifier loss: 0.108234; batch adversarial loss: 0.462749\n",
      "epoch 34; iter: 0; batch classifier loss: 0.133243; batch adversarial loss: 0.410942\n",
      "epoch 35; iter: 0; batch classifier loss: 0.161516; batch adversarial loss: 0.520782\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140659; batch adversarial loss: 0.453474\n",
      "epoch 37; iter: 0; batch classifier loss: 0.095715; batch adversarial loss: 0.497437\n",
      "epoch 38; iter: 0; batch classifier loss: 0.108991; batch adversarial loss: 0.446974\n",
      "epoch 39; iter: 0; batch classifier loss: 0.087911; batch adversarial loss: 0.507525\n",
      "epoch 40; iter: 0; batch classifier loss: 0.104046; batch adversarial loss: 0.434834\n",
      "epoch 41; iter: 0; batch classifier loss: 0.119758; batch adversarial loss: 0.484208\n",
      "epoch 42; iter: 0; batch classifier loss: 0.087442; batch adversarial loss: 0.447425\n",
      "epoch 43; iter: 0; batch classifier loss: 0.140757; batch adversarial loss: 0.403998\n",
      "epoch 44; iter: 0; batch classifier loss: 0.132800; batch adversarial loss: 0.467462\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089106; batch adversarial loss: 0.448398\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116461; batch adversarial loss: 0.421526\n",
      "epoch 47; iter: 0; batch classifier loss: 0.062966; batch adversarial loss: 0.490889\n",
      "epoch 48; iter: 0; batch classifier loss: 0.079713; batch adversarial loss: 0.516515\n",
      "epoch 49; iter: 0; batch classifier loss: 0.136677; batch adversarial loss: 0.479285\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098853; batch adversarial loss: 0.389966\n",
      "epoch 51; iter: 0; batch classifier loss: 0.123400; batch adversarial loss: 0.445483\n",
      "epoch 52; iter: 0; batch classifier loss: 0.077569; batch adversarial loss: 0.486525\n",
      "epoch 53; iter: 0; batch classifier loss: 0.116301; batch adversarial loss: 0.383444\n",
      "epoch 54; iter: 0; batch classifier loss: 0.111951; batch adversarial loss: 0.496476\n",
      "epoch 55; iter: 0; batch classifier loss: 0.107257; batch adversarial loss: 0.485542\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065236; batch adversarial loss: 0.437596\n",
      "epoch 57; iter: 0; batch classifier loss: 0.113088; batch adversarial loss: 0.424830\n",
      "epoch 58; iter: 0; batch classifier loss: 0.092486; batch adversarial loss: 0.509511\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084628; batch adversarial loss: 0.456697\n",
      "epoch 60; iter: 0; batch classifier loss: 0.115855; batch adversarial loss: 0.407506\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104100; batch adversarial loss: 0.485941\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092695; batch adversarial loss: 0.429527\n",
      "epoch 63; iter: 0; batch classifier loss: 0.051559; batch adversarial loss: 0.530921\n",
      "epoch 64; iter: 0; batch classifier loss: 0.079657; batch adversarial loss: 0.420955\n",
      "epoch 65; iter: 0; batch classifier loss: 0.100853; batch adversarial loss: 0.524087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.061780; batch adversarial loss: 0.413220\n",
      "epoch 67; iter: 0; batch classifier loss: 0.062478; batch adversarial loss: 0.421543\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078233; batch adversarial loss: 0.582567\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076673; batch adversarial loss: 0.530729\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078265; batch adversarial loss: 0.410972\n",
      "epoch 71; iter: 0; batch classifier loss: 0.070895; batch adversarial loss: 0.414386\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082031; batch adversarial loss: 0.400275\n",
      "epoch 73; iter: 0; batch classifier loss: 0.042220; batch adversarial loss: 0.483248\n",
      "epoch 74; iter: 0; batch classifier loss: 0.046789; batch adversarial loss: 0.576367\n",
      "epoch 75; iter: 0; batch classifier loss: 0.090887; batch adversarial loss: 0.414718\n",
      "epoch 76; iter: 0; batch classifier loss: 0.103285; batch adversarial loss: 0.486148\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045449; batch adversarial loss: 0.431939\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054644; batch adversarial loss: 0.540711\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082755; batch adversarial loss: 0.495405\n",
      "epoch 80; iter: 0; batch classifier loss: 0.066010; batch adversarial loss: 0.467392\n",
      "epoch 81; iter: 0; batch classifier loss: 0.046703; batch adversarial loss: 0.449480\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065572; batch adversarial loss: 0.431873\n",
      "epoch 83; iter: 0; batch classifier loss: 0.038455; batch adversarial loss: 0.434337\n",
      "epoch 84; iter: 0; batch classifier loss: 0.091574; batch adversarial loss: 0.450227\n",
      "epoch 85; iter: 0; batch classifier loss: 0.056846; batch adversarial loss: 0.374554\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064985; batch adversarial loss: 0.466561\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059821; batch adversarial loss: 0.470048\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076943; batch adversarial loss: 0.485814\n",
      "epoch 89; iter: 0; batch classifier loss: 0.109541; batch adversarial loss: 0.597246\n",
      "epoch 90; iter: 0; batch classifier loss: 0.087839; batch adversarial loss: 0.401393\n",
      "epoch 91; iter: 0; batch classifier loss: 0.090787; batch adversarial loss: 0.547298\n",
      "epoch 92; iter: 0; batch classifier loss: 0.092781; batch adversarial loss: 0.460728\n",
      "epoch 93; iter: 0; batch classifier loss: 0.086747; batch adversarial loss: 0.525767\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051676; batch adversarial loss: 0.486784\n",
      "epoch 95; iter: 0; batch classifier loss: 0.028570; batch adversarial loss: 0.505272\n",
      "epoch 96; iter: 0; batch classifier loss: 0.033341; batch adversarial loss: 0.431449\n",
      "epoch 97; iter: 0; batch classifier loss: 0.030081; batch adversarial loss: 0.356995\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042489; batch adversarial loss: 0.520774\n",
      "epoch 99; iter: 0; batch classifier loss: 0.060731; batch adversarial loss: 0.391421\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055983; batch adversarial loss: 0.513661\n",
      "epoch 101; iter: 0; batch classifier loss: 0.037357; batch adversarial loss: 0.510401\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062677; batch adversarial loss: 0.538633\n",
      "epoch 103; iter: 0; batch classifier loss: 0.034404; batch adversarial loss: 0.363618\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031044; batch adversarial loss: 0.450054\n",
      "epoch 105; iter: 0; batch classifier loss: 0.024015; batch adversarial loss: 0.474892\n",
      "epoch 106; iter: 0; batch classifier loss: 0.048700; batch adversarial loss: 0.438102\n",
      "epoch 107; iter: 0; batch classifier loss: 0.042999; batch adversarial loss: 0.403584\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049830; batch adversarial loss: 0.483827\n",
      "epoch 109; iter: 0; batch classifier loss: 0.025994; batch adversarial loss: 0.415076\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045936; batch adversarial loss: 0.436173\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055720; batch adversarial loss: 0.458466\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056376; batch adversarial loss: 0.378905\n",
      "epoch 113; iter: 0; batch classifier loss: 0.030546; batch adversarial loss: 0.528269\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040648; batch adversarial loss: 0.548656\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036704; batch adversarial loss: 0.461414\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054853; batch adversarial loss: 0.546449\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031054; batch adversarial loss: 0.506386\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052832; batch adversarial loss: 0.412814\n",
      "epoch 119; iter: 0; batch classifier loss: 0.028372; batch adversarial loss: 0.460569\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042277; batch adversarial loss: 0.480676\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018969; batch adversarial loss: 0.502870\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028407; batch adversarial loss: 0.585817\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029318; batch adversarial loss: 0.437265\n",
      "epoch 124; iter: 0; batch classifier loss: 0.069093; batch adversarial loss: 0.394889\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022257; batch adversarial loss: 0.505971\n",
      "epoch 126; iter: 0; batch classifier loss: 0.054003; batch adversarial loss: 0.455931\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024413; batch adversarial loss: 0.490769\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042474; batch adversarial loss: 0.455845\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018806; batch adversarial loss: 0.473463\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025150; batch adversarial loss: 0.428097\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035695; batch adversarial loss: 0.484778\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047869; batch adversarial loss: 0.478567\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035708; batch adversarial loss: 0.433716\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024208; batch adversarial loss: 0.481696\n",
      "epoch 135; iter: 0; batch classifier loss: 0.015311; batch adversarial loss: 0.475512\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024049; batch adversarial loss: 0.390044\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015960; batch adversarial loss: 0.319492\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017608; batch adversarial loss: 0.530402\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038025; batch adversarial loss: 0.465263\n",
      "epoch 140; iter: 0; batch classifier loss: 0.071143; batch adversarial loss: 0.390728\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028077; batch adversarial loss: 0.435211\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037009; batch adversarial loss: 0.472361\n",
      "epoch 143; iter: 0; batch classifier loss: 0.010593; batch adversarial loss: 0.480412\n",
      "epoch 144; iter: 0; batch classifier loss: 0.023578; batch adversarial loss: 0.458532\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029224; batch adversarial loss: 0.468763\n",
      "epoch 146; iter: 0; batch classifier loss: 0.008634; batch adversarial loss: 0.508597\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046897; batch adversarial loss: 0.506454\n",
      "epoch 148; iter: 0; batch classifier loss: 0.059740; batch adversarial loss: 0.405638\n",
      "epoch 149; iter: 0; batch classifier loss: 0.047739; batch adversarial loss: 0.455745\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016288; batch adversarial loss: 0.493685\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017572; batch adversarial loss: 0.416797\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021826; batch adversarial loss: 0.475422\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016085; batch adversarial loss: 0.514323\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033575; batch adversarial loss: 0.422672\n",
      "epoch 155; iter: 0; batch classifier loss: 0.059673; batch adversarial loss: 0.517524\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040856; batch adversarial loss: 0.525493\n",
      "epoch 157; iter: 0; batch classifier loss: 0.070926; batch adversarial loss: 0.472399\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016822; batch adversarial loss: 0.443549\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036638; batch adversarial loss: 0.371136\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044740; batch adversarial loss: 0.512367\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014797; batch adversarial loss: 0.374937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.027505; batch adversarial loss: 0.535872\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025388; batch adversarial loss: 0.528325\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018932; batch adversarial loss: 0.459567\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020542; batch adversarial loss: 0.478317\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021681; batch adversarial loss: 0.417332\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025922; batch adversarial loss: 0.436044\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034595; batch adversarial loss: 0.499382\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011458; batch adversarial loss: 0.557044\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025740; batch adversarial loss: 0.415812\n",
      "epoch 171; iter: 0; batch classifier loss: 0.046072; batch adversarial loss: 0.469729\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023636; batch adversarial loss: 0.528527\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018561; batch adversarial loss: 0.505204\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016093; batch adversarial loss: 0.479544\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022868; batch adversarial loss: 0.431102\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011861; batch adversarial loss: 0.394318\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026061; batch adversarial loss: 0.477115\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008557; batch adversarial loss: 0.464866\n",
      "epoch 179; iter: 0; batch classifier loss: 0.041317; batch adversarial loss: 0.415503\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028437; batch adversarial loss: 0.435508\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036490; batch adversarial loss: 0.451035\n",
      "epoch 182; iter: 0; batch classifier loss: 0.035148; batch adversarial loss: 0.450824\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010611; batch adversarial loss: 0.467838\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027164; batch adversarial loss: 0.479776\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016803; batch adversarial loss: 0.508731\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025679; batch adversarial loss: 0.416180\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036915; batch adversarial loss: 0.401055\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009815; batch adversarial loss: 0.420336\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017057; batch adversarial loss: 0.412739\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004645; batch adversarial loss: 0.456671\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017183; batch adversarial loss: 0.548149\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004558; batch adversarial loss: 0.455256\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005639; batch adversarial loss: 0.384682\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036730; batch adversarial loss: 0.563483\n",
      "epoch 195; iter: 0; batch classifier loss: 0.044818; batch adversarial loss: 0.399316\n",
      "epoch 196; iter: 0; batch classifier loss: 0.045014; batch adversarial loss: 0.519808\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014009; batch adversarial loss: 0.466703\n",
      "epoch 198; iter: 0; batch classifier loss: 0.033402; batch adversarial loss: 0.544999\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022564; batch adversarial loss: 0.532688\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712366; batch adversarial loss: 0.555430\n",
      "epoch 1; iter: 0; batch classifier loss: 0.413271; batch adversarial loss: 0.610586\n",
      "epoch 2; iter: 0; batch classifier loss: 0.460109; batch adversarial loss: 0.595078\n",
      "epoch 3; iter: 0; batch classifier loss: 0.417431; batch adversarial loss: 0.588903\n",
      "epoch 4; iter: 0; batch classifier loss: 0.488407; batch adversarial loss: 0.575208\n",
      "epoch 5; iter: 0; batch classifier loss: 0.493391; batch adversarial loss: 0.589815\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564908; batch adversarial loss: 0.599835\n",
      "epoch 7; iter: 0; batch classifier loss: 0.424727; batch adversarial loss: 0.538923\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534320; batch adversarial loss: 0.612855\n",
      "epoch 9; iter: 0; batch classifier loss: 0.582769; batch adversarial loss: 0.558438\n",
      "epoch 10; iter: 0; batch classifier loss: 0.480067; batch adversarial loss: 0.565075\n",
      "epoch 11; iter: 0; batch classifier loss: 0.316989; batch adversarial loss: 0.518057\n",
      "epoch 12; iter: 0; batch classifier loss: 0.364599; batch adversarial loss: 0.524145\n",
      "epoch 13; iter: 0; batch classifier loss: 0.334227; batch adversarial loss: 0.558383\n",
      "epoch 14; iter: 0; batch classifier loss: 0.316580; batch adversarial loss: 0.456459\n",
      "epoch 15; iter: 0; batch classifier loss: 0.229241; batch adversarial loss: 0.454161\n",
      "epoch 16; iter: 0; batch classifier loss: 0.310843; batch adversarial loss: 0.459876\n",
      "epoch 17; iter: 0; batch classifier loss: 0.233790; batch adversarial loss: 0.529464\n",
      "epoch 18; iter: 0; batch classifier loss: 0.249680; batch adversarial loss: 0.437186\n",
      "epoch 19; iter: 0; batch classifier loss: 0.230851; batch adversarial loss: 0.493822\n",
      "epoch 20; iter: 0; batch classifier loss: 0.276271; batch adversarial loss: 0.457283\n",
      "epoch 21; iter: 0; batch classifier loss: 0.141375; batch adversarial loss: 0.466356\n",
      "epoch 22; iter: 0; batch classifier loss: 0.171159; batch adversarial loss: 0.530424\n",
      "epoch 23; iter: 0; batch classifier loss: 0.152809; batch adversarial loss: 0.453093\n",
      "epoch 24; iter: 0; batch classifier loss: 0.193856; batch adversarial loss: 0.472006\n",
      "epoch 25; iter: 0; batch classifier loss: 0.117851; batch adversarial loss: 0.484779\n",
      "epoch 26; iter: 0; batch classifier loss: 0.168974; batch adversarial loss: 0.442701\n",
      "epoch 27; iter: 0; batch classifier loss: 0.149670; batch adversarial loss: 0.450944\n",
      "epoch 28; iter: 0; batch classifier loss: 0.128227; batch adversarial loss: 0.484044\n",
      "epoch 29; iter: 0; batch classifier loss: 0.130608; batch adversarial loss: 0.468776\n",
      "epoch 30; iter: 0; batch classifier loss: 0.139603; batch adversarial loss: 0.534521\n",
      "epoch 31; iter: 0; batch classifier loss: 0.147866; batch adversarial loss: 0.464429\n",
      "epoch 32; iter: 0; batch classifier loss: 0.191620; batch adversarial loss: 0.523381\n",
      "epoch 33; iter: 0; batch classifier loss: 0.163112; batch adversarial loss: 0.451459\n",
      "epoch 34; iter: 0; batch classifier loss: 0.172683; batch adversarial loss: 0.409261\n",
      "epoch 35; iter: 0; batch classifier loss: 0.289854; batch adversarial loss: 0.471514\n",
      "epoch 36; iter: 0; batch classifier loss: 0.154330; batch adversarial loss: 0.465493\n",
      "epoch 37; iter: 0; batch classifier loss: 0.134621; batch adversarial loss: 0.547952\n",
      "epoch 38; iter: 0; batch classifier loss: 0.131971; batch adversarial loss: 0.371096\n",
      "epoch 39; iter: 0; batch classifier loss: 0.149043; batch adversarial loss: 0.502165\n",
      "epoch 40; iter: 0; batch classifier loss: 0.196032; batch adversarial loss: 0.417265\n",
      "epoch 41; iter: 0; batch classifier loss: 0.137232; batch adversarial loss: 0.466634\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146380; batch adversarial loss: 0.458564\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104941; batch adversarial loss: 0.479903\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105832; batch adversarial loss: 0.560055\n",
      "epoch 45; iter: 0; batch classifier loss: 0.158784; batch adversarial loss: 0.499053\n",
      "epoch 46; iter: 0; batch classifier loss: 0.160645; batch adversarial loss: 0.421307\n",
      "epoch 47; iter: 0; batch classifier loss: 0.164185; batch adversarial loss: 0.465012\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125459; batch adversarial loss: 0.424140\n",
      "epoch 49; iter: 0; batch classifier loss: 0.163218; batch adversarial loss: 0.434293\n",
      "epoch 50; iter: 0; batch classifier loss: 0.161954; batch adversarial loss: 0.395249\n",
      "epoch 51; iter: 0; batch classifier loss: 0.103557; batch adversarial loss: 0.490149\n",
      "epoch 52; iter: 0; batch classifier loss: 0.132651; batch adversarial loss: 0.457643\n",
      "epoch 53; iter: 0; batch classifier loss: 0.206063; batch adversarial loss: 0.412248\n",
      "epoch 54; iter: 0; batch classifier loss: 0.175228; batch adversarial loss: 0.535703\n",
      "epoch 55; iter: 0; batch classifier loss: 0.175921; batch adversarial loss: 0.477127\n",
      "epoch 56; iter: 0; batch classifier loss: 0.123638; batch adversarial loss: 0.434040\n",
      "epoch 57; iter: 0; batch classifier loss: 0.182326; batch adversarial loss: 0.442998\n",
      "epoch 58; iter: 0; batch classifier loss: 0.150404; batch adversarial loss: 0.345798\n",
      "epoch 59; iter: 0; batch classifier loss: 0.118833; batch adversarial loss: 0.482878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.120818; batch adversarial loss: 0.534080\n",
      "epoch 61; iter: 0; batch classifier loss: 0.172473; batch adversarial loss: 0.503885\n",
      "epoch 62; iter: 0; batch classifier loss: 0.140371; batch adversarial loss: 0.557487\n",
      "epoch 63; iter: 0; batch classifier loss: 0.203226; batch adversarial loss: 0.435055\n",
      "epoch 64; iter: 0; batch classifier loss: 0.192310; batch adversarial loss: 0.533512\n",
      "epoch 65; iter: 0; batch classifier loss: 0.171719; batch adversarial loss: 0.444283\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084424; batch adversarial loss: 0.490628\n",
      "epoch 67; iter: 0; batch classifier loss: 0.151344; batch adversarial loss: 0.487759\n",
      "epoch 68; iter: 0; batch classifier loss: 0.091158; batch adversarial loss: 0.464853\n",
      "epoch 69; iter: 0; batch classifier loss: 0.126522; batch adversarial loss: 0.459748\n",
      "epoch 70; iter: 0; batch classifier loss: 0.128936; batch adversarial loss: 0.476230\n",
      "epoch 71; iter: 0; batch classifier loss: 0.210095; batch adversarial loss: 0.399310\n",
      "epoch 72; iter: 0; batch classifier loss: 0.139602; batch adversarial loss: 0.444461\n",
      "epoch 73; iter: 0; batch classifier loss: 0.095702; batch adversarial loss: 0.502730\n",
      "epoch 74; iter: 0; batch classifier loss: 0.131826; batch adversarial loss: 0.469058\n",
      "epoch 75; iter: 0; batch classifier loss: 0.211116; batch adversarial loss: 0.473811\n",
      "epoch 76; iter: 0; batch classifier loss: 0.182666; batch adversarial loss: 0.505721\n",
      "epoch 77; iter: 0; batch classifier loss: 0.154825; batch adversarial loss: 0.436787\n",
      "epoch 78; iter: 0; batch classifier loss: 0.155841; batch adversarial loss: 0.485900\n",
      "epoch 79; iter: 0; batch classifier loss: 0.166242; batch adversarial loss: 0.444630\n",
      "epoch 80; iter: 0; batch classifier loss: 0.147503; batch adversarial loss: 0.434558\n",
      "epoch 81; iter: 0; batch classifier loss: 0.134466; batch adversarial loss: 0.444460\n",
      "epoch 82; iter: 0; batch classifier loss: 0.166208; batch adversarial loss: 0.427571\n",
      "epoch 83; iter: 0; batch classifier loss: 0.109699; batch adversarial loss: 0.386410\n",
      "epoch 84; iter: 0; batch classifier loss: 0.144379; batch adversarial loss: 0.380014\n",
      "epoch 85; iter: 0; batch classifier loss: 0.169858; batch adversarial loss: 0.507827\n",
      "epoch 86; iter: 0; batch classifier loss: 0.144221; batch adversarial loss: 0.450203\n",
      "epoch 87; iter: 0; batch classifier loss: 0.094118; batch adversarial loss: 0.513917\n",
      "epoch 88; iter: 0; batch classifier loss: 0.104783; batch adversarial loss: 0.470808\n",
      "epoch 89; iter: 0; batch classifier loss: 0.144203; batch adversarial loss: 0.453537\n",
      "epoch 90; iter: 0; batch classifier loss: 0.170910; batch adversarial loss: 0.478751\n",
      "epoch 91; iter: 0; batch classifier loss: 0.195287; batch adversarial loss: 0.420938\n",
      "epoch 92; iter: 0; batch classifier loss: 0.130372; batch adversarial loss: 0.509426\n",
      "epoch 93; iter: 0; batch classifier loss: 0.161184; batch adversarial loss: 0.394812\n",
      "epoch 94; iter: 0; batch classifier loss: 0.100151; batch adversarial loss: 0.453117\n",
      "epoch 95; iter: 0; batch classifier loss: 0.155848; batch adversarial loss: 0.498771\n",
      "epoch 96; iter: 0; batch classifier loss: 0.180239; batch adversarial loss: 0.416561\n",
      "epoch 97; iter: 0; batch classifier loss: 0.108800; batch adversarial loss: 0.430207\n",
      "epoch 98; iter: 0; batch classifier loss: 0.174955; batch adversarial loss: 0.471418\n",
      "epoch 99; iter: 0; batch classifier loss: 0.199532; batch adversarial loss: 0.454629\n",
      "epoch 100; iter: 0; batch classifier loss: 0.167171; batch adversarial loss: 0.418232\n",
      "epoch 101; iter: 0; batch classifier loss: 0.098371; batch adversarial loss: 0.480987\n",
      "epoch 102; iter: 0; batch classifier loss: 0.137705; batch adversarial loss: 0.538591\n",
      "epoch 103; iter: 0; batch classifier loss: 0.195952; batch adversarial loss: 0.421022\n",
      "epoch 104; iter: 0; batch classifier loss: 0.163848; batch adversarial loss: 0.435878\n",
      "epoch 105; iter: 0; batch classifier loss: 0.121682; batch adversarial loss: 0.495266\n",
      "epoch 106; iter: 0; batch classifier loss: 0.192819; batch adversarial loss: 0.486029\n",
      "epoch 107; iter: 0; batch classifier loss: 0.138456; batch adversarial loss: 0.462260\n",
      "epoch 108; iter: 0; batch classifier loss: 0.129434; batch adversarial loss: 0.494888\n",
      "epoch 109; iter: 0; batch classifier loss: 0.140365; batch adversarial loss: 0.407100\n",
      "epoch 110; iter: 0; batch classifier loss: 0.143076; batch adversarial loss: 0.516043\n",
      "epoch 111; iter: 0; batch classifier loss: 0.171103; batch adversarial loss: 0.455221\n",
      "epoch 112; iter: 0; batch classifier loss: 0.170262; batch adversarial loss: 0.445645\n",
      "epoch 113; iter: 0; batch classifier loss: 0.168810; batch adversarial loss: 0.454462\n",
      "epoch 114; iter: 0; batch classifier loss: 0.108310; batch adversarial loss: 0.451707\n",
      "epoch 115; iter: 0; batch classifier loss: 0.182598; batch adversarial loss: 0.404235\n",
      "epoch 116; iter: 0; batch classifier loss: 0.128830; batch adversarial loss: 0.456591\n",
      "epoch 117; iter: 0; batch classifier loss: 0.113757; batch adversarial loss: 0.504377\n",
      "epoch 118; iter: 0; batch classifier loss: 0.169242; batch adversarial loss: 0.470871\n",
      "epoch 119; iter: 0; batch classifier loss: 0.136887; batch adversarial loss: 0.457636\n",
      "epoch 120; iter: 0; batch classifier loss: 0.189709; batch adversarial loss: 0.517252\n",
      "epoch 121; iter: 0; batch classifier loss: 0.121030; batch adversarial loss: 0.456396\n",
      "epoch 122; iter: 0; batch classifier loss: 0.191388; batch adversarial loss: 0.478960\n",
      "epoch 123; iter: 0; batch classifier loss: 0.225462; batch adversarial loss: 0.441411\n",
      "epoch 124; iter: 0; batch classifier loss: 0.091469; batch adversarial loss: 0.447964\n",
      "epoch 125; iter: 0; batch classifier loss: 0.151187; batch adversarial loss: 0.446946\n",
      "epoch 126; iter: 0; batch classifier loss: 0.151345; batch adversarial loss: 0.472095\n",
      "epoch 127; iter: 0; batch classifier loss: 0.153880; batch adversarial loss: 0.487299\n",
      "epoch 128; iter: 0; batch classifier loss: 0.163659; batch adversarial loss: 0.445887\n",
      "epoch 129; iter: 0; batch classifier loss: 0.187405; batch adversarial loss: 0.536512\n",
      "epoch 130; iter: 0; batch classifier loss: 0.159715; batch adversarial loss: 0.436490\n",
      "epoch 131; iter: 0; batch classifier loss: 0.156398; batch adversarial loss: 0.434199\n",
      "epoch 132; iter: 0; batch classifier loss: 0.209726; batch adversarial loss: 0.449177\n",
      "epoch 133; iter: 0; batch classifier loss: 0.120188; batch adversarial loss: 0.499668\n",
      "epoch 134; iter: 0; batch classifier loss: 0.128581; batch adversarial loss: 0.428532\n",
      "epoch 135; iter: 0; batch classifier loss: 0.138360; batch adversarial loss: 0.528716\n",
      "epoch 136; iter: 0; batch classifier loss: 0.117184; batch adversarial loss: 0.456588\n",
      "epoch 137; iter: 0; batch classifier loss: 0.175234; batch adversarial loss: 0.465447\n",
      "epoch 138; iter: 0; batch classifier loss: 0.120714; batch adversarial loss: 0.503413\n",
      "epoch 139; iter: 0; batch classifier loss: 0.126884; batch adversarial loss: 0.505790\n",
      "epoch 140; iter: 0; batch classifier loss: 0.126415; batch adversarial loss: 0.446991\n",
      "epoch 141; iter: 0; batch classifier loss: 0.222533; batch adversarial loss: 0.586522\n",
      "epoch 142; iter: 0; batch classifier loss: 0.141410; batch adversarial loss: 0.515447\n",
      "epoch 143; iter: 0; batch classifier loss: 0.165118; batch adversarial loss: 0.456987\n",
      "epoch 144; iter: 0; batch classifier loss: 0.175342; batch adversarial loss: 0.400858\n",
      "epoch 145; iter: 0; batch classifier loss: 0.149299; batch adversarial loss: 0.433273\n",
      "epoch 146; iter: 0; batch classifier loss: 0.203351; batch adversarial loss: 0.498299\n",
      "epoch 147; iter: 0; batch classifier loss: 0.090858; batch adversarial loss: 0.578436\n",
      "epoch 148; iter: 0; batch classifier loss: 0.140081; batch adversarial loss: 0.454495\n",
      "epoch 149; iter: 0; batch classifier loss: 0.157965; batch adversarial loss: 0.501131\n",
      "epoch 150; iter: 0; batch classifier loss: 0.095441; batch adversarial loss: 0.487503\n",
      "epoch 151; iter: 0; batch classifier loss: 0.127551; batch adversarial loss: 0.499530\n",
      "epoch 152; iter: 0; batch classifier loss: 0.108503; batch adversarial loss: 0.356794\n",
      "epoch 153; iter: 0; batch classifier loss: 0.114464; batch adversarial loss: 0.501225\n",
      "epoch 154; iter: 0; batch classifier loss: 0.114933; batch adversarial loss: 0.461809\n",
      "epoch 155; iter: 0; batch classifier loss: 0.096950; batch adversarial loss: 0.458109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.105527; batch adversarial loss: 0.409998\n",
      "epoch 157; iter: 0; batch classifier loss: 0.103540; batch adversarial loss: 0.458891\n",
      "epoch 158; iter: 0; batch classifier loss: 0.099993; batch adversarial loss: 0.501669\n",
      "epoch 159; iter: 0; batch classifier loss: 0.083486; batch adversarial loss: 0.430918\n",
      "epoch 160; iter: 0; batch classifier loss: 0.108528; batch adversarial loss: 0.446092\n",
      "epoch 161; iter: 0; batch classifier loss: 0.096992; batch adversarial loss: 0.419690\n",
      "epoch 162; iter: 0; batch classifier loss: 0.067636; batch adversarial loss: 0.457476\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040019; batch adversarial loss: 0.494854\n",
      "epoch 164; iter: 0; batch classifier loss: 0.067376; batch adversarial loss: 0.479036\n",
      "epoch 165; iter: 0; batch classifier loss: 0.069428; batch adversarial loss: 0.441866\n",
      "epoch 166; iter: 0; batch classifier loss: 0.044118; batch adversarial loss: 0.474199\n",
      "epoch 167; iter: 0; batch classifier loss: 0.078338; batch adversarial loss: 0.454150\n",
      "epoch 168; iter: 0; batch classifier loss: 0.039923; batch adversarial loss: 0.464694\n",
      "epoch 169; iter: 0; batch classifier loss: 0.045623; batch adversarial loss: 0.449966\n",
      "epoch 170; iter: 0; batch classifier loss: 0.058478; batch adversarial loss: 0.438652\n",
      "epoch 171; iter: 0; batch classifier loss: 0.035139; batch adversarial loss: 0.452914\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030688; batch adversarial loss: 0.463299\n",
      "epoch 173; iter: 0; batch classifier loss: 0.052899; batch adversarial loss: 0.494751\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037038; batch adversarial loss: 0.578532\n",
      "epoch 175; iter: 0; batch classifier loss: 0.046998; batch adversarial loss: 0.489017\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027384; batch adversarial loss: 0.387440\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028529; batch adversarial loss: 0.455535\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026666; batch adversarial loss: 0.480969\n",
      "epoch 179; iter: 0; batch classifier loss: 0.045931; batch adversarial loss: 0.384453\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026198; batch adversarial loss: 0.548364\n",
      "epoch 181; iter: 0; batch classifier loss: 0.042187; batch adversarial loss: 0.382333\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032522; batch adversarial loss: 0.423422\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032927; batch adversarial loss: 0.413073\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030281; batch adversarial loss: 0.498348\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010860; batch adversarial loss: 0.455829\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023345; batch adversarial loss: 0.478422\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020201; batch adversarial loss: 0.415626\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019900; batch adversarial loss: 0.532968\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028595; batch adversarial loss: 0.402164\n",
      "epoch 190; iter: 0; batch classifier loss: 0.038414; batch adversarial loss: 0.546280\n",
      "epoch 191; iter: 0; batch classifier loss: 0.038481; batch adversarial loss: 0.483794\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020262; batch adversarial loss: 0.473783\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026700; batch adversarial loss: 0.404217\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034639; batch adversarial loss: 0.502400\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013198; batch adversarial loss: 0.506316\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026450; batch adversarial loss: 0.471277\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012604; batch adversarial loss: 0.511092\n",
      "epoch 198; iter: 0; batch classifier loss: 0.042412; batch adversarial loss: 0.380794\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016519; batch adversarial loss: 0.479363\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717665; batch adversarial loss: 0.999543\n",
      "epoch 1; iter: 0; batch classifier loss: 0.758166; batch adversarial loss: 1.027698\n",
      "epoch 2; iter: 0; batch classifier loss: 0.943936; batch adversarial loss: 1.042690\n",
      "epoch 3; iter: 0; batch classifier loss: 0.855063; batch adversarial loss: 0.917128\n",
      "epoch 4; iter: 0; batch classifier loss: 1.034232; batch adversarial loss: 0.850034\n",
      "epoch 5; iter: 0; batch classifier loss: 1.137526; batch adversarial loss: 0.775583\n",
      "epoch 6; iter: 0; batch classifier loss: 0.984391; batch adversarial loss: 0.698548\n",
      "epoch 7; iter: 0; batch classifier loss: 0.822672; batch adversarial loss: 0.622655\n",
      "epoch 8; iter: 0; batch classifier loss: 0.712309; batch adversarial loss: 0.599884\n",
      "epoch 9; iter: 0; batch classifier loss: 0.466412; batch adversarial loss: 0.574735\n",
      "epoch 10; iter: 0; batch classifier loss: 0.347939; batch adversarial loss: 0.530867\n",
      "epoch 11; iter: 0; batch classifier loss: 0.248746; batch adversarial loss: 0.537098\n",
      "epoch 12; iter: 0; batch classifier loss: 0.255009; batch adversarial loss: 0.554539\n",
      "epoch 13; iter: 0; batch classifier loss: 0.330508; batch adversarial loss: 0.501712\n",
      "epoch 14; iter: 0; batch classifier loss: 0.274929; batch adversarial loss: 0.577096\n",
      "epoch 15; iter: 0; batch classifier loss: 0.371809; batch adversarial loss: 0.494791\n",
      "epoch 16; iter: 0; batch classifier loss: 0.319138; batch adversarial loss: 0.503637\n",
      "epoch 17; iter: 0; batch classifier loss: 0.281034; batch adversarial loss: 0.500772\n",
      "epoch 18; iter: 0; batch classifier loss: 0.272420; batch adversarial loss: 0.516380\n",
      "epoch 19; iter: 0; batch classifier loss: 0.192282; batch adversarial loss: 0.485661\n",
      "epoch 20; iter: 0; batch classifier loss: 0.236354; batch adversarial loss: 0.490109\n",
      "epoch 21; iter: 0; batch classifier loss: 0.229578; batch adversarial loss: 0.488693\n",
      "epoch 22; iter: 0; batch classifier loss: 0.227846; batch adversarial loss: 0.483455\n",
      "epoch 23; iter: 0; batch classifier loss: 0.194990; batch adversarial loss: 0.506965\n",
      "epoch 24; iter: 0; batch classifier loss: 0.227540; batch adversarial loss: 0.483173\n",
      "epoch 25; iter: 0; batch classifier loss: 0.183939; batch adversarial loss: 0.496660\n",
      "epoch 26; iter: 0; batch classifier loss: 0.161762; batch adversarial loss: 0.496551\n",
      "epoch 27; iter: 0; batch classifier loss: 0.192062; batch adversarial loss: 0.505726\n",
      "epoch 28; iter: 0; batch classifier loss: 0.191721; batch adversarial loss: 0.478864\n",
      "epoch 29; iter: 0; batch classifier loss: 0.185053; batch adversarial loss: 0.542990\n",
      "epoch 30; iter: 0; batch classifier loss: 0.178030; batch adversarial loss: 0.433780\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178040; batch adversarial loss: 0.442371\n",
      "epoch 32; iter: 0; batch classifier loss: 0.166633; batch adversarial loss: 0.509188\n",
      "epoch 33; iter: 0; batch classifier loss: 0.185382; batch adversarial loss: 0.480673\n",
      "epoch 34; iter: 0; batch classifier loss: 0.215920; batch adversarial loss: 0.429104\n",
      "epoch 35; iter: 0; batch classifier loss: 0.141197; batch adversarial loss: 0.394828\n",
      "epoch 36; iter: 0; batch classifier loss: 0.165503; batch adversarial loss: 0.443817\n",
      "epoch 37; iter: 0; batch classifier loss: 0.165957; batch adversarial loss: 0.450959\n",
      "epoch 38; iter: 0; batch classifier loss: 0.167873; batch adversarial loss: 0.450214\n",
      "epoch 39; iter: 0; batch classifier loss: 0.200429; batch adversarial loss: 0.502629\n",
      "epoch 40; iter: 0; batch classifier loss: 0.205293; batch adversarial loss: 0.425805\n",
      "epoch 41; iter: 0; batch classifier loss: 0.170506; batch adversarial loss: 0.442916\n",
      "epoch 42; iter: 0; batch classifier loss: 0.144972; batch adversarial loss: 0.469150\n",
      "epoch 43; iter: 0; batch classifier loss: 0.147289; batch adversarial loss: 0.495302\n",
      "epoch 44; iter: 0; batch classifier loss: 0.137860; batch adversarial loss: 0.421484\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117144; batch adversarial loss: 0.472157\n",
      "epoch 46; iter: 0; batch classifier loss: 0.142241; batch adversarial loss: 0.347682\n",
      "epoch 47; iter: 0; batch classifier loss: 0.080828; batch adversarial loss: 0.389275\n",
      "epoch 48; iter: 0; batch classifier loss: 0.112988; batch adversarial loss: 0.564856\n",
      "epoch 49; iter: 0; batch classifier loss: 0.165337; batch adversarial loss: 0.447794\n",
      "epoch 50; iter: 0; batch classifier loss: 0.111756; batch adversarial loss: 0.476030\n",
      "epoch 51; iter: 0; batch classifier loss: 0.104395; batch adversarial loss: 0.449327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.125956; batch adversarial loss: 0.467161\n",
      "epoch 53; iter: 0; batch classifier loss: 0.112748; batch adversarial loss: 0.475380\n",
      "epoch 54; iter: 0; batch classifier loss: 0.129730; batch adversarial loss: 0.468839\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117226; batch adversarial loss: 0.502837\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067353; batch adversarial loss: 0.468432\n",
      "epoch 57; iter: 0; batch classifier loss: 0.071708; batch adversarial loss: 0.463383\n",
      "epoch 58; iter: 0; batch classifier loss: 0.113870; batch adversarial loss: 0.382263\n",
      "epoch 59; iter: 0; batch classifier loss: 0.097642; batch adversarial loss: 0.448122\n",
      "epoch 60; iter: 0; batch classifier loss: 0.119573; batch adversarial loss: 0.425264\n",
      "epoch 61; iter: 0; batch classifier loss: 0.086525; batch adversarial loss: 0.516073\n",
      "epoch 62; iter: 0; batch classifier loss: 0.103452; batch adversarial loss: 0.479362\n",
      "epoch 63; iter: 0; batch classifier loss: 0.080145; batch adversarial loss: 0.429227\n",
      "epoch 64; iter: 0; batch classifier loss: 0.127176; batch adversarial loss: 0.487908\n",
      "epoch 65; iter: 0; batch classifier loss: 0.121478; batch adversarial loss: 0.453577\n",
      "epoch 66; iter: 0; batch classifier loss: 0.131760; batch adversarial loss: 0.429256\n",
      "epoch 67; iter: 0; batch classifier loss: 0.149065; batch adversarial loss: 0.461014\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076547; batch adversarial loss: 0.479433\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078044; batch adversarial loss: 0.293902\n",
      "epoch 70; iter: 0; batch classifier loss: 0.085912; batch adversarial loss: 0.419927\n",
      "epoch 71; iter: 0; batch classifier loss: 0.094803; batch adversarial loss: 0.356458\n",
      "epoch 72; iter: 0; batch classifier loss: 0.093272; batch adversarial loss: 0.478368\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083330; batch adversarial loss: 0.470776\n",
      "epoch 74; iter: 0; batch classifier loss: 0.073963; batch adversarial loss: 0.492024\n",
      "epoch 75; iter: 0; batch classifier loss: 0.085799; batch adversarial loss: 0.416228\n",
      "epoch 76; iter: 0; batch classifier loss: 0.140752; batch adversarial loss: 0.445098\n",
      "epoch 77; iter: 0; batch classifier loss: 0.138609; batch adversarial loss: 0.433042\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071329; batch adversarial loss: 0.502425\n",
      "epoch 79; iter: 0; batch classifier loss: 0.077663; batch adversarial loss: 0.539107\n",
      "epoch 80; iter: 0; batch classifier loss: 0.092555; batch adversarial loss: 0.455658\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068844; batch adversarial loss: 0.498917\n",
      "epoch 82; iter: 0; batch classifier loss: 0.082682; batch adversarial loss: 0.437950\n",
      "epoch 83; iter: 0; batch classifier loss: 0.051383; batch adversarial loss: 0.461871\n",
      "epoch 84; iter: 0; batch classifier loss: 0.044063; batch adversarial loss: 0.477807\n",
      "epoch 85; iter: 0; batch classifier loss: 0.092261; batch adversarial loss: 0.393233\n",
      "epoch 86; iter: 0; batch classifier loss: 0.049184; batch adversarial loss: 0.413832\n",
      "epoch 87; iter: 0; batch classifier loss: 0.093432; batch adversarial loss: 0.431877\n",
      "epoch 88; iter: 0; batch classifier loss: 0.080662; batch adversarial loss: 0.351425\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060717; batch adversarial loss: 0.426316\n",
      "epoch 90; iter: 0; batch classifier loss: 0.032641; batch adversarial loss: 0.382932\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059833; batch adversarial loss: 0.386143\n",
      "epoch 92; iter: 0; batch classifier loss: 0.047110; batch adversarial loss: 0.417194\n",
      "epoch 93; iter: 0; batch classifier loss: 0.075582; batch adversarial loss: 0.482391\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061263; batch adversarial loss: 0.555238\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071667; batch adversarial loss: 0.399843\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058588; batch adversarial loss: 0.478465\n",
      "epoch 97; iter: 0; batch classifier loss: 0.096021; batch adversarial loss: 0.437419\n",
      "epoch 98; iter: 0; batch classifier loss: 0.043492; batch adversarial loss: 0.447932\n",
      "epoch 99; iter: 0; batch classifier loss: 0.091107; batch adversarial loss: 0.401276\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062502; batch adversarial loss: 0.417105\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049236; batch adversarial loss: 0.442648\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042485; batch adversarial loss: 0.462713\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057832; batch adversarial loss: 0.348427\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058581; batch adversarial loss: 0.398121\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048718; batch adversarial loss: 0.421739\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054108; batch adversarial loss: 0.464948\n",
      "epoch 107; iter: 0; batch classifier loss: 0.030704; batch adversarial loss: 0.387668\n",
      "epoch 108; iter: 0; batch classifier loss: 0.089872; batch adversarial loss: 0.456404\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057229; batch adversarial loss: 0.392451\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060931; batch adversarial loss: 0.439762\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044236; batch adversarial loss: 0.455946\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051040; batch adversarial loss: 0.381119\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047242; batch adversarial loss: 0.474811\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040056; batch adversarial loss: 0.493151\n",
      "epoch 115; iter: 0; batch classifier loss: 0.016485; batch adversarial loss: 0.460171\n",
      "epoch 116; iter: 0; batch classifier loss: 0.058240; batch adversarial loss: 0.498435\n",
      "epoch 117; iter: 0; batch classifier loss: 0.074168; batch adversarial loss: 0.415079\n",
      "epoch 118; iter: 0; batch classifier loss: 0.017241; batch adversarial loss: 0.435576\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023801; batch adversarial loss: 0.436171\n",
      "epoch 120; iter: 0; batch classifier loss: 0.058188; batch adversarial loss: 0.511964\n",
      "epoch 121; iter: 0; batch classifier loss: 0.020860; batch adversarial loss: 0.425893\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043368; batch adversarial loss: 0.355584\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032240; batch adversarial loss: 0.469691\n",
      "epoch 124; iter: 0; batch classifier loss: 0.012450; batch adversarial loss: 0.384059\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068690; batch adversarial loss: 0.435919\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032608; batch adversarial loss: 0.533045\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043616; batch adversarial loss: 0.402920\n",
      "epoch 128; iter: 0; batch classifier loss: 0.064164; batch adversarial loss: 0.499381\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036639; batch adversarial loss: 0.461915\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028895; batch adversarial loss: 0.444525\n",
      "epoch 131; iter: 0; batch classifier loss: 0.014126; batch adversarial loss: 0.473022\n",
      "epoch 132; iter: 0; batch classifier loss: 0.082340; batch adversarial loss: 0.490500\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052277; batch adversarial loss: 0.463887\n",
      "epoch 134; iter: 0; batch classifier loss: 0.057266; batch adversarial loss: 0.441170\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031434; batch adversarial loss: 0.519801\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039640; batch adversarial loss: 0.370446\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027048; batch adversarial loss: 0.440487\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029990; batch adversarial loss: 0.502671\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043981; batch adversarial loss: 0.506555\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025563; batch adversarial loss: 0.518280\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020554; batch adversarial loss: 0.444752\n",
      "epoch 142; iter: 0; batch classifier loss: 0.047923; batch adversarial loss: 0.335085\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024347; batch adversarial loss: 0.583291\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029747; batch adversarial loss: 0.466937\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018306; batch adversarial loss: 0.442912\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027871; batch adversarial loss: 0.571223\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023141; batch adversarial loss: 0.449111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.022710; batch adversarial loss: 0.462042\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035492; batch adversarial loss: 0.497287\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015971; batch adversarial loss: 0.434955\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028917; batch adversarial loss: 0.466118\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032135; batch adversarial loss: 0.473511\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022044; batch adversarial loss: 0.504524\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035884; batch adversarial loss: 0.394017\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025325; batch adversarial loss: 0.354093\n",
      "epoch 156; iter: 0; batch classifier loss: 0.046708; batch adversarial loss: 0.426372\n",
      "epoch 157; iter: 0; batch classifier loss: 0.051682; batch adversarial loss: 0.438622\n",
      "epoch 158; iter: 0; batch classifier loss: 0.059587; batch adversarial loss: 0.484170\n",
      "epoch 159; iter: 0; batch classifier loss: 0.005488; batch adversarial loss: 0.504083\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022574; batch adversarial loss: 0.459644\n",
      "epoch 161; iter: 0; batch classifier loss: 0.041454; batch adversarial loss: 0.377051\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029601; batch adversarial loss: 0.491560\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019588; batch adversarial loss: 0.445013\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034685; batch adversarial loss: 0.434383\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034784; batch adversarial loss: 0.563470\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012779; batch adversarial loss: 0.429200\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015210; batch adversarial loss: 0.398166\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005124; batch adversarial loss: 0.475888\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013156; batch adversarial loss: 0.446571\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032330; batch adversarial loss: 0.516601\n",
      "epoch 171; iter: 0; batch classifier loss: 0.004925; batch adversarial loss: 0.458519\n",
      "epoch 172; iter: 0; batch classifier loss: 0.049072; batch adversarial loss: 0.500834\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027762; batch adversarial loss: 0.564441\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011489; batch adversarial loss: 0.497356\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012759; batch adversarial loss: 0.419696\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007684; batch adversarial loss: 0.485444\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008916; batch adversarial loss: 0.415216\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007262; batch adversarial loss: 0.361388\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026697; batch adversarial loss: 0.549095\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014881; batch adversarial loss: 0.527671\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013337; batch adversarial loss: 0.561636\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020231; batch adversarial loss: 0.416849\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012384; batch adversarial loss: 0.461424\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030506; batch adversarial loss: 0.429758\n",
      "epoch 185; iter: 0; batch classifier loss: 0.065052; batch adversarial loss: 0.485373\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018796; batch adversarial loss: 0.487307\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019100; batch adversarial loss: 0.448821\n",
      "epoch 188; iter: 0; batch classifier loss: 0.038941; batch adversarial loss: 0.429378\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009505; batch adversarial loss: 0.498741\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035347; batch adversarial loss: 0.441524\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033588; batch adversarial loss: 0.434593\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024388; batch adversarial loss: 0.418561\n",
      "epoch 193; iter: 0; batch classifier loss: 0.053491; batch adversarial loss: 0.373503\n",
      "epoch 194; iter: 0; batch classifier loss: 0.038257; batch adversarial loss: 0.399572\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024463; batch adversarial loss: 0.410446\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029263; batch adversarial loss: 0.568438\n",
      "epoch 197; iter: 0; batch classifier loss: 0.047195; batch adversarial loss: 0.389599\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012123; batch adversarial loss: 0.382464\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030804; batch adversarial loss: 0.527342\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710994; batch adversarial loss: 0.567533\n",
      "epoch 1; iter: 0; batch classifier loss: 0.512602; batch adversarial loss: 0.591701\n",
      "epoch 2; iter: 0; batch classifier loss: 0.413592; batch adversarial loss: 0.592926\n",
      "epoch 3; iter: 0; batch classifier loss: 0.314090; batch adversarial loss: 0.629039\n",
      "epoch 4; iter: 0; batch classifier loss: 0.403855; batch adversarial loss: 0.616638\n",
      "epoch 5; iter: 0; batch classifier loss: 0.365147; batch adversarial loss: 0.586979\n",
      "epoch 6; iter: 0; batch classifier loss: 0.339717; batch adversarial loss: 0.537159\n",
      "epoch 7; iter: 0; batch classifier loss: 0.396046; batch adversarial loss: 0.613421\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564937; batch adversarial loss: 0.547226\n",
      "epoch 9; iter: 0; batch classifier loss: 0.469254; batch adversarial loss: 0.549184\n",
      "epoch 10; iter: 0; batch classifier loss: 0.431633; batch adversarial loss: 0.555670\n",
      "epoch 11; iter: 0; batch classifier loss: 0.378948; batch adversarial loss: 0.505635\n",
      "epoch 12; iter: 0; batch classifier loss: 0.307577; batch adversarial loss: 0.513672\n",
      "epoch 13; iter: 0; batch classifier loss: 0.288253; batch adversarial loss: 0.508959\n",
      "epoch 14; iter: 0; batch classifier loss: 0.334652; batch adversarial loss: 0.509504\n",
      "epoch 15; iter: 0; batch classifier loss: 0.226588; batch adversarial loss: 0.445113\n",
      "epoch 16; iter: 0; batch classifier loss: 0.206283; batch adversarial loss: 0.430415\n",
      "epoch 17; iter: 0; batch classifier loss: 0.201120; batch adversarial loss: 0.440496\n",
      "epoch 18; iter: 0; batch classifier loss: 0.219278; batch adversarial loss: 0.421362\n",
      "epoch 19; iter: 0; batch classifier loss: 0.207978; batch adversarial loss: 0.503549\n",
      "epoch 20; iter: 0; batch classifier loss: 0.224294; batch adversarial loss: 0.394702\n",
      "epoch 21; iter: 0; batch classifier loss: 0.166639; batch adversarial loss: 0.472107\n",
      "epoch 22; iter: 0; batch classifier loss: 0.215844; batch adversarial loss: 0.451724\n",
      "epoch 23; iter: 0; batch classifier loss: 0.173984; batch adversarial loss: 0.457374\n",
      "epoch 24; iter: 0; batch classifier loss: 0.168819; batch adversarial loss: 0.431995\n",
      "epoch 25; iter: 0; batch classifier loss: 0.129187; batch adversarial loss: 0.523982\n",
      "epoch 26; iter: 0; batch classifier loss: 0.164657; batch adversarial loss: 0.438919\n",
      "epoch 27; iter: 0; batch classifier loss: 0.177814; batch adversarial loss: 0.442158\n",
      "epoch 28; iter: 0; batch classifier loss: 0.174983; batch adversarial loss: 0.438842\n",
      "epoch 29; iter: 0; batch classifier loss: 0.132816; batch adversarial loss: 0.450440\n",
      "epoch 30; iter: 0; batch classifier loss: 0.176479; batch adversarial loss: 0.361936\n",
      "epoch 31; iter: 0; batch classifier loss: 0.202203; batch adversarial loss: 0.440099\n",
      "epoch 32; iter: 0; batch classifier loss: 0.163051; batch adversarial loss: 0.458994\n",
      "epoch 33; iter: 0; batch classifier loss: 0.179667; batch adversarial loss: 0.471085\n",
      "epoch 34; iter: 0; batch classifier loss: 0.133940; batch adversarial loss: 0.439716\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142199; batch adversarial loss: 0.483624\n",
      "epoch 36; iter: 0; batch classifier loss: 0.130044; batch adversarial loss: 0.378995\n",
      "epoch 37; iter: 0; batch classifier loss: 0.164018; batch adversarial loss: 0.454855\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117627; batch adversarial loss: 0.459102\n",
      "epoch 39; iter: 0; batch classifier loss: 0.135909; batch adversarial loss: 0.441447\n",
      "epoch 40; iter: 0; batch classifier loss: 0.179914; batch adversarial loss: 0.405818\n",
      "epoch 41; iter: 0; batch classifier loss: 0.144402; batch adversarial loss: 0.468321\n",
      "epoch 42; iter: 0; batch classifier loss: 0.169876; batch adversarial loss: 0.436051\n",
      "epoch 43; iter: 0; batch classifier loss: 0.165026; batch adversarial loss: 0.426701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.146653; batch adversarial loss: 0.416604\n",
      "epoch 45; iter: 0; batch classifier loss: 0.170696; batch adversarial loss: 0.437127\n",
      "epoch 46; iter: 0; batch classifier loss: 0.135754; batch adversarial loss: 0.423857\n",
      "epoch 47; iter: 0; batch classifier loss: 0.126917; batch adversarial loss: 0.401372\n",
      "epoch 48; iter: 0; batch classifier loss: 0.094985; batch adversarial loss: 0.469863\n",
      "epoch 49; iter: 0; batch classifier loss: 0.135690; batch adversarial loss: 0.468778\n",
      "epoch 50; iter: 0; batch classifier loss: 0.077322; batch adversarial loss: 0.392745\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121765; batch adversarial loss: 0.366903\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112313; batch adversarial loss: 0.461409\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095207; batch adversarial loss: 0.383862\n",
      "epoch 54; iter: 0; batch classifier loss: 0.069918; batch adversarial loss: 0.520198\n",
      "epoch 55; iter: 0; batch classifier loss: 0.103544; batch adversarial loss: 0.456800\n",
      "epoch 56; iter: 0; batch classifier loss: 0.143947; batch adversarial loss: 0.375166\n",
      "epoch 57; iter: 0; batch classifier loss: 0.103070; batch adversarial loss: 0.475700\n",
      "epoch 58; iter: 0; batch classifier loss: 0.125269; batch adversarial loss: 0.443764\n",
      "epoch 59; iter: 0; batch classifier loss: 0.160069; batch adversarial loss: 0.362329\n",
      "epoch 60; iter: 0; batch classifier loss: 0.151324; batch adversarial loss: 0.438677\n",
      "epoch 61; iter: 0; batch classifier loss: 0.166718; batch adversarial loss: 0.403130\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104054; batch adversarial loss: 0.443208\n",
      "epoch 63; iter: 0; batch classifier loss: 0.079904; batch adversarial loss: 0.361134\n",
      "epoch 64; iter: 0; batch classifier loss: 0.141104; batch adversarial loss: 0.522971\n",
      "epoch 65; iter: 0; batch classifier loss: 0.096635; batch adversarial loss: 0.376111\n",
      "epoch 66; iter: 0; batch classifier loss: 0.131643; batch adversarial loss: 0.409307\n",
      "epoch 67; iter: 0; batch classifier loss: 0.135520; batch adversarial loss: 0.548255\n",
      "epoch 68; iter: 0; batch classifier loss: 0.086958; batch adversarial loss: 0.439784\n",
      "epoch 69; iter: 0; batch classifier loss: 0.106390; batch adversarial loss: 0.457971\n",
      "epoch 70; iter: 0; batch classifier loss: 0.122759; batch adversarial loss: 0.295365\n",
      "epoch 71; iter: 0; batch classifier loss: 0.138970; batch adversarial loss: 0.420880\n",
      "epoch 72; iter: 0; batch classifier loss: 0.118475; batch adversarial loss: 0.562097\n",
      "epoch 73; iter: 0; batch classifier loss: 0.178589; batch adversarial loss: 0.375115\n",
      "epoch 74; iter: 0; batch classifier loss: 0.146902; batch adversarial loss: 0.412452\n",
      "epoch 75; iter: 0; batch classifier loss: 0.103081; batch adversarial loss: 0.426521\n",
      "epoch 76; iter: 0; batch classifier loss: 0.156876; batch adversarial loss: 0.458185\n",
      "epoch 77; iter: 0; batch classifier loss: 0.111268; batch adversarial loss: 0.468811\n",
      "epoch 78; iter: 0; batch classifier loss: 0.087422; batch adversarial loss: 0.460466\n",
      "epoch 79; iter: 0; batch classifier loss: 0.110827; batch adversarial loss: 0.422911\n",
      "epoch 80; iter: 0; batch classifier loss: 0.132906; batch adversarial loss: 0.467266\n",
      "epoch 81; iter: 0; batch classifier loss: 0.128939; batch adversarial loss: 0.331689\n",
      "epoch 82; iter: 0; batch classifier loss: 0.088376; batch adversarial loss: 0.388630\n",
      "epoch 83; iter: 0; batch classifier loss: 0.101203; batch adversarial loss: 0.480486\n",
      "epoch 84; iter: 0; batch classifier loss: 0.129458; batch adversarial loss: 0.477650\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059448; batch adversarial loss: 0.411866\n",
      "epoch 86; iter: 0; batch classifier loss: 0.096639; batch adversarial loss: 0.514745\n",
      "epoch 87; iter: 0; batch classifier loss: 0.086494; batch adversarial loss: 0.418894\n",
      "epoch 88; iter: 0; batch classifier loss: 0.096600; batch adversarial loss: 0.359341\n",
      "epoch 89; iter: 0; batch classifier loss: 0.113569; batch adversarial loss: 0.502273\n",
      "epoch 90; iter: 0; batch classifier loss: 0.114671; batch adversarial loss: 0.413945\n",
      "epoch 91; iter: 0; batch classifier loss: 0.128090; batch adversarial loss: 0.433270\n",
      "epoch 92; iter: 0; batch classifier loss: 0.117027; batch adversarial loss: 0.381388\n",
      "epoch 93; iter: 0; batch classifier loss: 0.073645; batch adversarial loss: 0.465743\n",
      "epoch 94; iter: 0; batch classifier loss: 0.089574; batch adversarial loss: 0.420922\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070925; batch adversarial loss: 0.439419\n",
      "epoch 96; iter: 0; batch classifier loss: 0.087544; batch adversarial loss: 0.417510\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060562; batch adversarial loss: 0.372058\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035967; batch adversarial loss: 0.579571\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046155; batch adversarial loss: 0.484107\n",
      "epoch 100; iter: 0; batch classifier loss: 0.103874; batch adversarial loss: 0.351984\n",
      "epoch 101; iter: 0; batch classifier loss: 0.088294; batch adversarial loss: 0.370461\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068645; batch adversarial loss: 0.504577\n",
      "epoch 103; iter: 0; batch classifier loss: 0.074337; batch adversarial loss: 0.392909\n",
      "epoch 104; iter: 0; batch classifier loss: 0.078936; batch adversarial loss: 0.414645\n",
      "epoch 105; iter: 0; batch classifier loss: 0.087634; batch adversarial loss: 0.403563\n",
      "epoch 106; iter: 0; batch classifier loss: 0.048263; batch adversarial loss: 0.448229\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063209; batch adversarial loss: 0.439723\n",
      "epoch 108; iter: 0; batch classifier loss: 0.091666; batch adversarial loss: 0.385499\n",
      "epoch 109; iter: 0; batch classifier loss: 0.065944; batch adversarial loss: 0.413521\n",
      "epoch 110; iter: 0; batch classifier loss: 0.062604; batch adversarial loss: 0.437549\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045417; batch adversarial loss: 0.523175\n",
      "epoch 112; iter: 0; batch classifier loss: 0.064272; batch adversarial loss: 0.441147\n",
      "epoch 113; iter: 0; batch classifier loss: 0.060555; batch adversarial loss: 0.461833\n",
      "epoch 114; iter: 0; batch classifier loss: 0.080079; batch adversarial loss: 0.378953\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043121; batch adversarial loss: 0.379118\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043411; batch adversarial loss: 0.506328\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044540; batch adversarial loss: 0.525129\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042278; batch adversarial loss: 0.454544\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029433; batch adversarial loss: 0.475677\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033089; batch adversarial loss: 0.384212\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030242; batch adversarial loss: 0.426366\n",
      "epoch 122; iter: 0; batch classifier loss: 0.098189; batch adversarial loss: 0.360759\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027152; batch adversarial loss: 0.505669\n",
      "epoch 124; iter: 0; batch classifier loss: 0.068083; batch adversarial loss: 0.333558\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029477; batch adversarial loss: 0.511613\n",
      "epoch 126; iter: 0; batch classifier loss: 0.076668; batch adversarial loss: 0.473468\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033350; batch adversarial loss: 0.440928\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031021; batch adversarial loss: 0.491043\n",
      "epoch 129; iter: 0; batch classifier loss: 0.068487; batch adversarial loss: 0.493303\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023829; batch adversarial loss: 0.439463\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022872; batch adversarial loss: 0.350172\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041577; batch adversarial loss: 0.472489\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043053; batch adversarial loss: 0.423915\n",
      "epoch 134; iter: 0; batch classifier loss: 0.044220; batch adversarial loss: 0.493576\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024881; batch adversarial loss: 0.517146\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026802; batch adversarial loss: 0.408207\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046071; batch adversarial loss: 0.432469\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031212; batch adversarial loss: 0.532590\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035839; batch adversarial loss: 0.465803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.049693; batch adversarial loss: 0.441536\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043664; batch adversarial loss: 0.587281\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049824; batch adversarial loss: 0.434790\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022231; batch adversarial loss: 0.465669\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040030; batch adversarial loss: 0.336104\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035863; batch adversarial loss: 0.533680\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032448; batch adversarial loss: 0.505988\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024185; batch adversarial loss: 0.387363\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034059; batch adversarial loss: 0.478754\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027598; batch adversarial loss: 0.498920\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013414; batch adversarial loss: 0.533876\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032426; batch adversarial loss: 0.405543\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020504; batch adversarial loss: 0.562716\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040882; batch adversarial loss: 0.509912\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034131; batch adversarial loss: 0.390150\n",
      "epoch 155; iter: 0; batch classifier loss: 0.043051; batch adversarial loss: 0.437881\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025249; batch adversarial loss: 0.403431\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023621; batch adversarial loss: 0.422945\n",
      "epoch 158; iter: 0; batch classifier loss: 0.047884; batch adversarial loss: 0.494183\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038729; batch adversarial loss: 0.400378\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013987; batch adversarial loss: 0.441979\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014051; batch adversarial loss: 0.446206\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038194; batch adversarial loss: 0.421197\n",
      "epoch 163; iter: 0; batch classifier loss: 0.045175; batch adversarial loss: 0.466030\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013472; batch adversarial loss: 0.437660\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023101; batch adversarial loss: 0.388582\n",
      "epoch 166; iter: 0; batch classifier loss: 0.008801; batch adversarial loss: 0.370269\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028891; batch adversarial loss: 0.422207\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032869; batch adversarial loss: 0.449232\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019153; batch adversarial loss: 0.451421\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028701; batch adversarial loss: 0.485233\n",
      "epoch 171; iter: 0; batch classifier loss: 0.054881; batch adversarial loss: 0.408306\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024953; batch adversarial loss: 0.439567\n",
      "epoch 173; iter: 0; batch classifier loss: 0.058473; batch adversarial loss: 0.356127\n",
      "epoch 174; iter: 0; batch classifier loss: 0.055409; batch adversarial loss: 0.454603\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023759; batch adversarial loss: 0.389755\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023526; batch adversarial loss: 0.463068\n",
      "epoch 177; iter: 0; batch classifier loss: 0.057487; batch adversarial loss: 0.505381\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019269; batch adversarial loss: 0.375077\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032412; batch adversarial loss: 0.371271\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039510; batch adversarial loss: 0.458492\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037169; batch adversarial loss: 0.468767\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023844; batch adversarial loss: 0.406461\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028755; batch adversarial loss: 0.480397\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031755; batch adversarial loss: 0.450396\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017732; batch adversarial loss: 0.477776\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027325; batch adversarial loss: 0.468704\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031815; batch adversarial loss: 0.500601\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016351; batch adversarial loss: 0.417276\n",
      "epoch 189; iter: 0; batch classifier loss: 0.046536; batch adversarial loss: 0.419870\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004734; batch adversarial loss: 0.540209\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020432; batch adversarial loss: 0.507368\n",
      "epoch 192; iter: 0; batch classifier loss: 0.039120; batch adversarial loss: 0.422783\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035792; batch adversarial loss: 0.563992\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012493; batch adversarial loss: 0.469569\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018968; batch adversarial loss: 0.465689\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018388; batch adversarial loss: 0.473866\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021580; batch adversarial loss: 0.397181\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013965; batch adversarial loss: 0.423084\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033687; batch adversarial loss: 0.562949\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674209; batch adversarial loss: 0.560992\n",
      "epoch 1; iter: 0; batch classifier loss: 0.413888; batch adversarial loss: 0.605992\n",
      "epoch 2; iter: 0; batch classifier loss: 0.406558; batch adversarial loss: 0.587828\n",
      "epoch 3; iter: 0; batch classifier loss: 0.396852; batch adversarial loss: 0.628723\n",
      "epoch 4; iter: 0; batch classifier loss: 0.352730; batch adversarial loss: 0.598546\n",
      "epoch 5; iter: 0; batch classifier loss: 0.392606; batch adversarial loss: 0.583528\n",
      "epoch 6; iter: 0; batch classifier loss: 0.361751; batch adversarial loss: 0.588998\n",
      "epoch 7; iter: 0; batch classifier loss: 0.483453; batch adversarial loss: 0.598879\n",
      "epoch 8; iter: 0; batch classifier loss: 0.500167; batch adversarial loss: 0.586473\n",
      "epoch 9; iter: 0; batch classifier loss: 0.623730; batch adversarial loss: 0.565982\n",
      "epoch 10; iter: 0; batch classifier loss: 0.654331; batch adversarial loss: 0.509711\n",
      "epoch 11; iter: 0; batch classifier loss: 0.454797; batch adversarial loss: 0.600715\n",
      "epoch 12; iter: 0; batch classifier loss: 0.341812; batch adversarial loss: 0.510253\n",
      "epoch 13; iter: 0; batch classifier loss: 0.274680; batch adversarial loss: 0.477366\n",
      "epoch 14; iter: 0; batch classifier loss: 0.238386; batch adversarial loss: 0.501166\n",
      "epoch 15; iter: 0; batch classifier loss: 0.260341; batch adversarial loss: 0.463015\n",
      "epoch 16; iter: 0; batch classifier loss: 0.248944; batch adversarial loss: 0.440821\n",
      "epoch 17; iter: 0; batch classifier loss: 0.205127; batch adversarial loss: 0.439272\n",
      "epoch 18; iter: 0; batch classifier loss: 0.180242; batch adversarial loss: 0.543033\n",
      "epoch 19; iter: 0; batch classifier loss: 0.217098; batch adversarial loss: 0.505062\n",
      "epoch 20; iter: 0; batch classifier loss: 0.206975; batch adversarial loss: 0.557454\n",
      "epoch 21; iter: 0; batch classifier loss: 0.219401; batch adversarial loss: 0.433864\n",
      "epoch 22; iter: 0; batch classifier loss: 0.162550; batch adversarial loss: 0.534495\n",
      "epoch 23; iter: 0; batch classifier loss: 0.223462; batch adversarial loss: 0.431263\n",
      "epoch 24; iter: 0; batch classifier loss: 0.203036; batch adversarial loss: 0.398207\n",
      "epoch 25; iter: 0; batch classifier loss: 0.137756; batch adversarial loss: 0.397848\n",
      "epoch 26; iter: 0; batch classifier loss: 0.144133; batch adversarial loss: 0.488849\n",
      "epoch 27; iter: 0; batch classifier loss: 0.167940; batch adversarial loss: 0.482805\n",
      "epoch 28; iter: 0; batch classifier loss: 0.159043; batch adversarial loss: 0.599324\n",
      "epoch 29; iter: 0; batch classifier loss: 0.111214; batch adversarial loss: 0.432123\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138356; batch adversarial loss: 0.478128\n",
      "epoch 31; iter: 0; batch classifier loss: 0.120417; batch adversarial loss: 0.449470\n",
      "epoch 32; iter: 0; batch classifier loss: 0.064732; batch adversarial loss: 0.532981\n",
      "epoch 33; iter: 0; batch classifier loss: 0.183122; batch adversarial loss: 0.455842\n",
      "epoch 34; iter: 0; batch classifier loss: 0.174053; batch adversarial loss: 0.481250\n",
      "epoch 35; iter: 0; batch classifier loss: 0.116177; batch adversarial loss: 0.515956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.125148; batch adversarial loss: 0.462466\n",
      "epoch 37; iter: 0; batch classifier loss: 0.133658; batch adversarial loss: 0.445568\n",
      "epoch 38; iter: 0; batch classifier loss: 0.176326; batch adversarial loss: 0.458734\n",
      "epoch 39; iter: 0; batch classifier loss: 0.124829; batch adversarial loss: 0.426217\n",
      "epoch 40; iter: 0; batch classifier loss: 0.086419; batch adversarial loss: 0.476922\n",
      "epoch 41; iter: 0; batch classifier loss: 0.077970; batch adversarial loss: 0.539829\n",
      "epoch 42; iter: 0; batch classifier loss: 0.135473; batch adversarial loss: 0.472459\n",
      "epoch 43; iter: 0; batch classifier loss: 0.085102; batch adversarial loss: 0.490419\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124525; batch adversarial loss: 0.421325\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104451; batch adversarial loss: 0.602343\n",
      "epoch 46; iter: 0; batch classifier loss: 0.135952; batch adversarial loss: 0.500966\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114101; batch adversarial loss: 0.460509\n",
      "epoch 48; iter: 0; batch classifier loss: 0.089028; batch adversarial loss: 0.576875\n",
      "epoch 49; iter: 0; batch classifier loss: 0.072027; batch adversarial loss: 0.395398\n",
      "epoch 50; iter: 0; batch classifier loss: 0.121953; batch adversarial loss: 0.389134\n",
      "epoch 51; iter: 0; batch classifier loss: 0.086095; batch adversarial loss: 0.427363\n",
      "epoch 52; iter: 0; batch classifier loss: 0.060391; batch adversarial loss: 0.606447\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096384; batch adversarial loss: 0.423379\n",
      "epoch 54; iter: 0; batch classifier loss: 0.093306; batch adversarial loss: 0.489349\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117741; batch adversarial loss: 0.461755\n",
      "epoch 56; iter: 0; batch classifier loss: 0.150563; batch adversarial loss: 0.456749\n",
      "epoch 57; iter: 0; batch classifier loss: 0.188837; batch adversarial loss: 0.502099\n",
      "epoch 58; iter: 0; batch classifier loss: 0.168806; batch adversarial loss: 0.422710\n",
      "epoch 59; iter: 0; batch classifier loss: 0.115425; batch adversarial loss: 0.552914\n",
      "epoch 60; iter: 0; batch classifier loss: 0.168217; batch adversarial loss: 0.468121\n",
      "epoch 61; iter: 0; batch classifier loss: 0.111489; batch adversarial loss: 0.476420\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092317; batch adversarial loss: 0.438218\n",
      "epoch 63; iter: 0; batch classifier loss: 0.126810; batch adversarial loss: 0.399052\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078590; batch adversarial loss: 0.478547\n",
      "epoch 65; iter: 0; batch classifier loss: 0.072502; batch adversarial loss: 0.491248\n",
      "epoch 66; iter: 0; batch classifier loss: 0.119790; batch adversarial loss: 0.421364\n",
      "epoch 67; iter: 0; batch classifier loss: 0.089642; batch adversarial loss: 0.506243\n",
      "epoch 68; iter: 0; batch classifier loss: 0.134673; batch adversarial loss: 0.495062\n",
      "epoch 69; iter: 0; batch classifier loss: 0.108083; batch adversarial loss: 0.502081\n",
      "epoch 70; iter: 0; batch classifier loss: 0.061735; batch adversarial loss: 0.478608\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089380; batch adversarial loss: 0.388256\n",
      "epoch 72; iter: 0; batch classifier loss: 0.103415; batch adversarial loss: 0.422867\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075437; batch adversarial loss: 0.378933\n",
      "epoch 74; iter: 0; batch classifier loss: 0.113448; batch adversarial loss: 0.410194\n",
      "epoch 75; iter: 0; batch classifier loss: 0.095068; batch adversarial loss: 0.389852\n",
      "epoch 76; iter: 0; batch classifier loss: 0.121881; batch adversarial loss: 0.431264\n",
      "epoch 77; iter: 0; batch classifier loss: 0.073868; batch adversarial loss: 0.477845\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082914; batch adversarial loss: 0.429194\n",
      "epoch 79; iter: 0; batch classifier loss: 0.097375; batch adversarial loss: 0.461101\n",
      "epoch 80; iter: 0; batch classifier loss: 0.121418; batch adversarial loss: 0.426188\n",
      "epoch 81; iter: 0; batch classifier loss: 0.093061; batch adversarial loss: 0.464126\n",
      "epoch 82; iter: 0; batch classifier loss: 0.048491; batch adversarial loss: 0.427558\n",
      "epoch 83; iter: 0; batch classifier loss: 0.087633; batch adversarial loss: 0.426720\n",
      "epoch 84; iter: 0; batch classifier loss: 0.043072; batch adversarial loss: 0.447223\n",
      "epoch 85; iter: 0; batch classifier loss: 0.119839; batch adversarial loss: 0.455570\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072300; batch adversarial loss: 0.425329\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054671; batch adversarial loss: 0.376948\n",
      "epoch 88; iter: 0; batch classifier loss: 0.107707; batch adversarial loss: 0.433859\n",
      "epoch 89; iter: 0; batch classifier loss: 0.085977; batch adversarial loss: 0.437673\n",
      "epoch 90; iter: 0; batch classifier loss: 0.078503; batch adversarial loss: 0.398825\n",
      "epoch 91; iter: 0; batch classifier loss: 0.069565; batch adversarial loss: 0.489159\n",
      "epoch 92; iter: 0; batch classifier loss: 0.112978; batch adversarial loss: 0.444234\n",
      "epoch 93; iter: 0; batch classifier loss: 0.038949; batch adversarial loss: 0.370110\n",
      "epoch 94; iter: 0; batch classifier loss: 0.091167; batch adversarial loss: 0.414560\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052262; batch adversarial loss: 0.427136\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043647; batch adversarial loss: 0.461528\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044840; batch adversarial loss: 0.569707\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074963; batch adversarial loss: 0.403232\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055408; batch adversarial loss: 0.493556\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054969; batch adversarial loss: 0.423192\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040173; batch adversarial loss: 0.536904\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067512; batch adversarial loss: 0.403344\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050875; batch adversarial loss: 0.526073\n",
      "epoch 104; iter: 0; batch classifier loss: 0.076061; batch adversarial loss: 0.446985\n",
      "epoch 105; iter: 0; batch classifier loss: 0.067711; batch adversarial loss: 0.540972\n",
      "epoch 106; iter: 0; batch classifier loss: 0.032366; batch adversarial loss: 0.473237\n",
      "epoch 107; iter: 0; batch classifier loss: 0.020743; batch adversarial loss: 0.447323\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043669; batch adversarial loss: 0.411668\n",
      "epoch 109; iter: 0; batch classifier loss: 0.077574; batch adversarial loss: 0.514483\n",
      "epoch 110; iter: 0; batch classifier loss: 0.088651; batch adversarial loss: 0.458223\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058410; batch adversarial loss: 0.432602\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051424; batch adversarial loss: 0.517089\n",
      "epoch 113; iter: 0; batch classifier loss: 0.064537; batch adversarial loss: 0.490735\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026096; batch adversarial loss: 0.520528\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039483; batch adversarial loss: 0.471321\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024708; batch adversarial loss: 0.438271\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041133; batch adversarial loss: 0.400921\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029468; batch adversarial loss: 0.519016\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044041; batch adversarial loss: 0.445274\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032185; batch adversarial loss: 0.418807\n",
      "epoch 121; iter: 0; batch classifier loss: 0.010175; batch adversarial loss: 0.502107\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025815; batch adversarial loss: 0.441941\n",
      "epoch 123; iter: 0; batch classifier loss: 0.017804; batch adversarial loss: 0.472519\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046061; batch adversarial loss: 0.432787\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025283; batch adversarial loss: 0.469954\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026800; batch adversarial loss: 0.439087\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053364; batch adversarial loss: 0.436210\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038087; batch adversarial loss: 0.431603\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033599; batch adversarial loss: 0.414431\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029357; batch adversarial loss: 0.453849\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026872; batch adversarial loss: 0.488720\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027034; batch adversarial loss: 0.386602\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031049; batch adversarial loss: 0.489556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.031354; batch adversarial loss: 0.488271\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027186; batch adversarial loss: 0.422309\n",
      "epoch 136; iter: 0; batch classifier loss: 0.077180; batch adversarial loss: 0.660013\n",
      "epoch 137; iter: 0; batch classifier loss: 0.011304; batch adversarial loss: 0.602532\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020209; batch adversarial loss: 0.508763\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015753; batch adversarial loss: 0.413456\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040092; batch adversarial loss: 0.482116\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020507; batch adversarial loss: 0.459587\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031424; batch adversarial loss: 0.505429\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030466; batch adversarial loss: 0.369946\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019794; batch adversarial loss: 0.511960\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035164; batch adversarial loss: 0.494453\n",
      "epoch 146; iter: 0; batch classifier loss: 0.008872; batch adversarial loss: 0.492019\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024261; batch adversarial loss: 0.491557\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012416; batch adversarial loss: 0.440748\n",
      "epoch 149; iter: 0; batch classifier loss: 0.048062; batch adversarial loss: 0.495333\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020076; batch adversarial loss: 0.399654\n",
      "epoch 151; iter: 0; batch classifier loss: 0.058450; batch adversarial loss: 0.399203\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039256; batch adversarial loss: 0.371758\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016441; batch adversarial loss: 0.459261\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016923; batch adversarial loss: 0.463259\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032268; batch adversarial loss: 0.421755\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029319; batch adversarial loss: 0.405838\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010834; batch adversarial loss: 0.455102\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034231; batch adversarial loss: 0.395938\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033842; batch adversarial loss: 0.494083\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021221; batch adversarial loss: 0.400328\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034163; batch adversarial loss: 0.316898\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019130; batch adversarial loss: 0.497280\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015006; batch adversarial loss: 0.519388\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033933; batch adversarial loss: 0.423402\n",
      "epoch 165; iter: 0; batch classifier loss: 0.098607; batch adversarial loss: 0.376988\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013873; batch adversarial loss: 0.404561\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023610; batch adversarial loss: 0.482584\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015581; batch adversarial loss: 0.370678\n",
      "epoch 169; iter: 0; batch classifier loss: 0.057351; batch adversarial loss: 0.436736\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012674; batch adversarial loss: 0.424569\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008199; batch adversarial loss: 0.435310\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030355; batch adversarial loss: 0.534351\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028497; batch adversarial loss: 0.327110\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020919; batch adversarial loss: 0.435991\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036027; batch adversarial loss: 0.479646\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022041; batch adversarial loss: 0.458335\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016302; batch adversarial loss: 0.419442\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020352; batch adversarial loss: 0.406852\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028498; batch adversarial loss: 0.441385\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026557; batch adversarial loss: 0.494898\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021074; batch adversarial loss: 0.478121\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008754; batch adversarial loss: 0.421419\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021463; batch adversarial loss: 0.399658\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026505; batch adversarial loss: 0.455444\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011850; batch adversarial loss: 0.485016\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033064; batch adversarial loss: 0.473443\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021678; batch adversarial loss: 0.547055\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007944; batch adversarial loss: 0.423987\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029219; batch adversarial loss: 0.412618\n",
      "epoch 190; iter: 0; batch classifier loss: 0.043246; batch adversarial loss: 0.378283\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011833; batch adversarial loss: 0.437787\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023052; batch adversarial loss: 0.465504\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026978; batch adversarial loss: 0.460027\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010701; batch adversarial loss: 0.499648\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005583; batch adversarial loss: 0.549305\n",
      "epoch 196; iter: 0; batch classifier loss: 0.003992; batch adversarial loss: 0.411010\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027508; batch adversarial loss: 0.469909\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018512; batch adversarial loss: 0.474934\n",
      "epoch 199; iter: 0; batch classifier loss: 0.034127; batch adversarial loss: 0.414701\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718731; batch adversarial loss: 0.591345\n",
      "epoch 1; iter: 0; batch classifier loss: 0.456014; batch adversarial loss: 0.573906\n",
      "epoch 2; iter: 0; batch classifier loss: 0.323202; batch adversarial loss: 0.565694\n",
      "epoch 3; iter: 0; batch classifier loss: 0.343390; batch adversarial loss: 0.623593\n",
      "epoch 4; iter: 0; batch classifier loss: 0.464367; batch adversarial loss: 0.578558\n",
      "epoch 5; iter: 0; batch classifier loss: 0.317892; batch adversarial loss: 0.509280\n",
      "epoch 6; iter: 0; batch classifier loss: 0.314482; batch adversarial loss: 0.625315\n",
      "epoch 7; iter: 0; batch classifier loss: 0.321511; batch adversarial loss: 0.496123\n",
      "epoch 8; iter: 0; batch classifier loss: 0.343801; batch adversarial loss: 0.546614\n",
      "epoch 9; iter: 0; batch classifier loss: 0.405759; batch adversarial loss: 0.599445\n",
      "epoch 10; iter: 0; batch classifier loss: 0.335971; batch adversarial loss: 0.545865\n",
      "epoch 11; iter: 0; batch classifier loss: 0.331166; batch adversarial loss: 0.578641\n",
      "epoch 12; iter: 0; batch classifier loss: 0.310931; batch adversarial loss: 0.514609\n",
      "epoch 13; iter: 0; batch classifier loss: 0.348411; batch adversarial loss: 0.509015\n",
      "epoch 14; iter: 0; batch classifier loss: 0.308483; batch adversarial loss: 0.478473\n",
      "epoch 15; iter: 0; batch classifier loss: 0.435838; batch adversarial loss: 0.551547\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454969; batch adversarial loss: 0.500785\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474094; batch adversarial loss: 0.517850\n",
      "epoch 18; iter: 0; batch classifier loss: 0.325102; batch adversarial loss: 0.484765\n",
      "epoch 19; iter: 0; batch classifier loss: 0.197765; batch adversarial loss: 0.472989\n",
      "epoch 20; iter: 0; batch classifier loss: 0.275510; batch adversarial loss: 0.380999\n",
      "epoch 21; iter: 0; batch classifier loss: 0.192669; batch adversarial loss: 0.505290\n",
      "epoch 22; iter: 0; batch classifier loss: 0.217617; batch adversarial loss: 0.502343\n",
      "epoch 23; iter: 0; batch classifier loss: 0.110214; batch adversarial loss: 0.491178\n",
      "epoch 24; iter: 0; batch classifier loss: 0.178061; batch adversarial loss: 0.495873\n",
      "epoch 25; iter: 0; batch classifier loss: 0.159099; batch adversarial loss: 0.490079\n",
      "epoch 26; iter: 0; batch classifier loss: 0.196533; batch adversarial loss: 0.488988\n",
      "epoch 27; iter: 0; batch classifier loss: 0.121786; batch adversarial loss: 0.410935\n",
      "epoch 28; iter: 0; batch classifier loss: 0.155907; batch adversarial loss: 0.489570\n",
      "epoch 29; iter: 0; batch classifier loss: 0.132196; batch adversarial loss: 0.490398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.166319; batch adversarial loss: 0.469350\n",
      "epoch 31; iter: 0; batch classifier loss: 0.099762; batch adversarial loss: 0.525152\n",
      "epoch 32; iter: 0; batch classifier loss: 0.100331; batch adversarial loss: 0.528351\n",
      "epoch 33; iter: 0; batch classifier loss: 0.128463; batch adversarial loss: 0.435661\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148005; batch adversarial loss: 0.442561\n",
      "epoch 35; iter: 0; batch classifier loss: 0.101974; batch adversarial loss: 0.467057\n",
      "epoch 36; iter: 0; batch classifier loss: 0.093615; batch adversarial loss: 0.491381\n",
      "epoch 37; iter: 0; batch classifier loss: 0.106222; batch adversarial loss: 0.476758\n",
      "epoch 38; iter: 0; batch classifier loss: 0.131824; batch adversarial loss: 0.423098\n",
      "epoch 39; iter: 0; batch classifier loss: 0.089343; batch adversarial loss: 0.427662\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124373; batch adversarial loss: 0.361287\n",
      "epoch 41; iter: 0; batch classifier loss: 0.101491; batch adversarial loss: 0.433366\n",
      "epoch 42; iter: 0; batch classifier loss: 0.102836; batch adversarial loss: 0.461100\n",
      "epoch 43; iter: 0; batch classifier loss: 0.096989; batch adversarial loss: 0.534224\n",
      "epoch 44; iter: 0; batch classifier loss: 0.099597; batch adversarial loss: 0.459114\n",
      "epoch 45; iter: 0; batch classifier loss: 0.076520; batch adversarial loss: 0.652847\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102527; batch adversarial loss: 0.383968\n",
      "epoch 47; iter: 0; batch classifier loss: 0.082415; batch adversarial loss: 0.502441\n",
      "epoch 48; iter: 0; batch classifier loss: 0.080820; batch adversarial loss: 0.381928\n",
      "epoch 49; iter: 0; batch classifier loss: 0.095934; batch adversarial loss: 0.496469\n",
      "epoch 50; iter: 0; batch classifier loss: 0.095971; batch adversarial loss: 0.489692\n",
      "epoch 51; iter: 0; batch classifier loss: 0.115746; batch adversarial loss: 0.540657\n",
      "epoch 52; iter: 0; batch classifier loss: 0.059652; batch adversarial loss: 0.445129\n",
      "epoch 53; iter: 0; batch classifier loss: 0.091124; batch adversarial loss: 0.389955\n",
      "epoch 54; iter: 0; batch classifier loss: 0.048951; batch adversarial loss: 0.432008\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096180; batch adversarial loss: 0.441507\n",
      "epoch 56; iter: 0; batch classifier loss: 0.132988; batch adversarial loss: 0.561341\n",
      "epoch 57; iter: 0; batch classifier loss: 0.046970; batch adversarial loss: 0.452771\n",
      "epoch 58; iter: 0; batch classifier loss: 0.092765; batch adversarial loss: 0.570055\n",
      "epoch 59; iter: 0; batch classifier loss: 0.124539; batch adversarial loss: 0.471075\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076770; batch adversarial loss: 0.430748\n",
      "epoch 61; iter: 0; batch classifier loss: 0.064313; batch adversarial loss: 0.431621\n",
      "epoch 62; iter: 0; batch classifier loss: 0.086051; batch adversarial loss: 0.480681\n",
      "epoch 63; iter: 0; batch classifier loss: 0.067926; batch adversarial loss: 0.502409\n",
      "epoch 64; iter: 0; batch classifier loss: 0.089833; batch adversarial loss: 0.363858\n",
      "epoch 65; iter: 0; batch classifier loss: 0.076579; batch adversarial loss: 0.591058\n",
      "epoch 66; iter: 0; batch classifier loss: 0.058386; batch adversarial loss: 0.512715\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059539; batch adversarial loss: 0.512208\n",
      "epoch 68; iter: 0; batch classifier loss: 0.064517; batch adversarial loss: 0.347056\n",
      "epoch 69; iter: 0; batch classifier loss: 0.084453; batch adversarial loss: 0.386194\n",
      "epoch 70; iter: 0; batch classifier loss: 0.121286; batch adversarial loss: 0.518906\n",
      "epoch 71; iter: 0; batch classifier loss: 0.096531; batch adversarial loss: 0.506952\n",
      "epoch 72; iter: 0; batch classifier loss: 0.034745; batch adversarial loss: 0.500970\n",
      "epoch 73; iter: 0; batch classifier loss: 0.100966; batch adversarial loss: 0.411491\n",
      "epoch 74; iter: 0; batch classifier loss: 0.088571; batch adversarial loss: 0.422999\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076723; batch adversarial loss: 0.444400\n",
      "epoch 76; iter: 0; batch classifier loss: 0.090567; batch adversarial loss: 0.487738\n",
      "epoch 77; iter: 0; batch classifier loss: 0.133569; batch adversarial loss: 0.372258\n",
      "epoch 78; iter: 0; batch classifier loss: 0.105621; batch adversarial loss: 0.455589\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057001; batch adversarial loss: 0.394468\n",
      "epoch 80; iter: 0; batch classifier loss: 0.071121; batch adversarial loss: 0.437060\n",
      "epoch 81; iter: 0; batch classifier loss: 0.085991; batch adversarial loss: 0.418048\n",
      "epoch 82; iter: 0; batch classifier loss: 0.044279; batch adversarial loss: 0.535695\n",
      "epoch 83; iter: 0; batch classifier loss: 0.060022; batch adversarial loss: 0.542715\n",
      "epoch 84; iter: 0; batch classifier loss: 0.094240; batch adversarial loss: 0.420730\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084563; batch adversarial loss: 0.401681\n",
      "epoch 86; iter: 0; batch classifier loss: 0.028478; batch adversarial loss: 0.458769\n",
      "epoch 87; iter: 0; batch classifier loss: 0.051992; batch adversarial loss: 0.393547\n",
      "epoch 88; iter: 0; batch classifier loss: 0.047555; batch adversarial loss: 0.409746\n",
      "epoch 89; iter: 0; batch classifier loss: 0.111943; batch adversarial loss: 0.507024\n",
      "epoch 90; iter: 0; batch classifier loss: 0.041341; batch adversarial loss: 0.477586\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057299; batch adversarial loss: 0.472487\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068368; batch adversarial loss: 0.535478\n",
      "epoch 93; iter: 0; batch classifier loss: 0.031030; batch adversarial loss: 0.390837\n",
      "epoch 94; iter: 0; batch classifier loss: 0.096003; batch adversarial loss: 0.494836\n",
      "epoch 95; iter: 0; batch classifier loss: 0.107142; batch adversarial loss: 0.469014\n",
      "epoch 96; iter: 0; batch classifier loss: 0.071146; batch adversarial loss: 0.538986\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055708; batch adversarial loss: 0.479948\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072992; batch adversarial loss: 0.486678\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041104; batch adversarial loss: 0.464753\n",
      "epoch 100; iter: 0; batch classifier loss: 0.040483; batch adversarial loss: 0.432632\n",
      "epoch 101; iter: 0; batch classifier loss: 0.097781; batch adversarial loss: 0.435532\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060191; batch adversarial loss: 0.555128\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038595; batch adversarial loss: 0.423365\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060579; batch adversarial loss: 0.465562\n",
      "epoch 105; iter: 0; batch classifier loss: 0.070709; batch adversarial loss: 0.440314\n",
      "epoch 106; iter: 0; batch classifier loss: 0.029339; batch adversarial loss: 0.508204\n",
      "epoch 107; iter: 0; batch classifier loss: 0.026135; batch adversarial loss: 0.499276\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058185; batch adversarial loss: 0.417127\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043221; batch adversarial loss: 0.535493\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069513; batch adversarial loss: 0.513994\n",
      "epoch 111; iter: 0; batch classifier loss: 0.068802; batch adversarial loss: 0.450075\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059423; batch adversarial loss: 0.415281\n",
      "epoch 113; iter: 0; batch classifier loss: 0.077535; batch adversarial loss: 0.471535\n",
      "epoch 114; iter: 0; batch classifier loss: 0.072917; batch adversarial loss: 0.445401\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033271; batch adversarial loss: 0.503998\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027629; batch adversarial loss: 0.480614\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051771; batch adversarial loss: 0.415597\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069178; batch adversarial loss: 0.454261\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025559; batch adversarial loss: 0.452136\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048607; batch adversarial loss: 0.409940\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041925; batch adversarial loss: 0.444981\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026512; batch adversarial loss: 0.537417\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025422; batch adversarial loss: 0.569944\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022233; batch adversarial loss: 0.482043\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035228; batch adversarial loss: 0.510417\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037726; batch adversarial loss: 0.447627\n",
      "epoch 127; iter: 0; batch classifier loss: 0.038174; batch adversarial loss: 0.405742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.038904; batch adversarial loss: 0.471775\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029827; batch adversarial loss: 0.441181\n",
      "epoch 130; iter: 0; batch classifier loss: 0.058390; batch adversarial loss: 0.519020\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043150; batch adversarial loss: 0.546104\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044135; batch adversarial loss: 0.521288\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060966; batch adversarial loss: 0.538009\n",
      "epoch 134; iter: 0; batch classifier loss: 0.065151; batch adversarial loss: 0.454507\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043218; batch adversarial loss: 0.516479\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027279; batch adversarial loss: 0.326512\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037078; batch adversarial loss: 0.502723\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013505; batch adversarial loss: 0.439502\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037812; batch adversarial loss: 0.421394\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020110; batch adversarial loss: 0.473492\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044356; batch adversarial loss: 0.416064\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019739; batch adversarial loss: 0.478013\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016943; batch adversarial loss: 0.470990\n",
      "epoch 144; iter: 0; batch classifier loss: 0.075184; batch adversarial loss: 0.465818\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042139; batch adversarial loss: 0.517878\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021518; batch adversarial loss: 0.531639\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038619; batch adversarial loss: 0.459958\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031420; batch adversarial loss: 0.456821\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029405; batch adversarial loss: 0.554022\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035608; batch adversarial loss: 0.552179\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019288; batch adversarial loss: 0.401725\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025547; batch adversarial loss: 0.433212\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015346; batch adversarial loss: 0.459718\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023547; batch adversarial loss: 0.428857\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011092; batch adversarial loss: 0.516125\n",
      "epoch 156; iter: 0; batch classifier loss: 0.061434; batch adversarial loss: 0.604715\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021190; batch adversarial loss: 0.502133\n",
      "epoch 158; iter: 0; batch classifier loss: 0.058864; batch adversarial loss: 0.463948\n",
      "epoch 159; iter: 0; batch classifier loss: 0.041825; batch adversarial loss: 0.469710\n",
      "epoch 160; iter: 0; batch classifier loss: 0.043686; batch adversarial loss: 0.492373\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028491; batch adversarial loss: 0.410755\n",
      "epoch 162; iter: 0; batch classifier loss: 0.051832; batch adversarial loss: 0.435845\n",
      "epoch 163; iter: 0; batch classifier loss: 0.053286; batch adversarial loss: 0.455622\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026203; batch adversarial loss: 0.450054\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014752; batch adversarial loss: 0.549541\n",
      "epoch 166; iter: 0; batch classifier loss: 0.048864; batch adversarial loss: 0.478238\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029079; batch adversarial loss: 0.367415\n",
      "epoch 168; iter: 0; batch classifier loss: 0.042683; batch adversarial loss: 0.515432\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012020; batch adversarial loss: 0.482786\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024969; batch adversarial loss: 0.376586\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027793; batch adversarial loss: 0.441535\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020506; batch adversarial loss: 0.474931\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007121; batch adversarial loss: 0.371776\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029020; batch adversarial loss: 0.437781\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025212; batch adversarial loss: 0.426787\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016146; batch adversarial loss: 0.570132\n",
      "epoch 177; iter: 0; batch classifier loss: 0.040775; batch adversarial loss: 0.396395\n",
      "epoch 178; iter: 0; batch classifier loss: 0.048700; batch adversarial loss: 0.555488\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038536; batch adversarial loss: 0.376371\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026685; batch adversarial loss: 0.502267\n",
      "epoch 181; iter: 0; batch classifier loss: 0.046306; batch adversarial loss: 0.571911\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015802; batch adversarial loss: 0.523291\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022922; batch adversarial loss: 0.399653\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013804; batch adversarial loss: 0.453157\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010604; batch adversarial loss: 0.517568\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019462; batch adversarial loss: 0.462871\n",
      "epoch 187; iter: 0; batch classifier loss: 0.050934; batch adversarial loss: 0.459531\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006863; batch adversarial loss: 0.536197\n",
      "epoch 189; iter: 0; batch classifier loss: 0.038161; batch adversarial loss: 0.360292\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020853; batch adversarial loss: 0.426975\n",
      "epoch 191; iter: 0; batch classifier loss: 0.078770; batch adversarial loss: 0.504146\n",
      "epoch 192; iter: 0; batch classifier loss: 0.002378; batch adversarial loss: 0.483056\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014603; batch adversarial loss: 0.469932\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016034; batch adversarial loss: 0.408887\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018673; batch adversarial loss: 0.410946\n",
      "epoch 196; iter: 0; batch classifier loss: 0.040530; batch adversarial loss: 0.511415\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010130; batch adversarial loss: 0.437109\n",
      "epoch 198; iter: 0; batch classifier loss: 0.046926; batch adversarial loss: 0.499630\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028590; batch adversarial loss: 0.475348\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709920; batch adversarial loss: 0.640641\n",
      "epoch 1; iter: 0; batch classifier loss: 0.506617; batch adversarial loss: 0.644789\n",
      "epoch 2; iter: 0; batch classifier loss: 0.360973; batch adversarial loss: 0.592617\n",
      "epoch 3; iter: 0; batch classifier loss: 0.446849; batch adversarial loss: 0.564522\n",
      "epoch 4; iter: 0; batch classifier loss: 0.400720; batch adversarial loss: 0.600754\n",
      "epoch 5; iter: 0; batch classifier loss: 0.367276; batch adversarial loss: 0.613433\n",
      "epoch 6; iter: 0; batch classifier loss: 0.321621; batch adversarial loss: 0.505580\n",
      "epoch 7; iter: 0; batch classifier loss: 0.236367; batch adversarial loss: 0.492518\n",
      "epoch 8; iter: 0; batch classifier loss: 0.331795; batch adversarial loss: 0.524831\n",
      "epoch 9; iter: 0; batch classifier loss: 0.280490; batch adversarial loss: 0.534451\n",
      "epoch 10; iter: 0; batch classifier loss: 0.233494; batch adversarial loss: 0.487838\n",
      "epoch 11; iter: 0; batch classifier loss: 0.328845; batch adversarial loss: 0.544251\n",
      "epoch 12; iter: 0; batch classifier loss: 0.333932; batch adversarial loss: 0.492243\n",
      "epoch 13; iter: 0; batch classifier loss: 0.255567; batch adversarial loss: 0.524224\n",
      "epoch 14; iter: 0; batch classifier loss: 0.224360; batch adversarial loss: 0.406129\n",
      "epoch 15; iter: 0; batch classifier loss: 0.166281; batch adversarial loss: 0.481787\n",
      "epoch 16; iter: 0; batch classifier loss: 0.180988; batch adversarial loss: 0.517259\n",
      "epoch 17; iter: 0; batch classifier loss: 0.185131; batch adversarial loss: 0.454046\n",
      "epoch 18; iter: 0; batch classifier loss: 0.264875; batch adversarial loss: 0.518241\n",
      "epoch 19; iter: 0; batch classifier loss: 0.188784; batch adversarial loss: 0.574185\n",
      "epoch 20; iter: 0; batch classifier loss: 0.205798; batch adversarial loss: 0.453463\n",
      "epoch 21; iter: 0; batch classifier loss: 0.207215; batch adversarial loss: 0.503651\n",
      "epoch 22; iter: 0; batch classifier loss: 0.181559; batch adversarial loss: 0.436669\n",
      "epoch 23; iter: 0; batch classifier loss: 0.234479; batch adversarial loss: 0.472594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.136973; batch adversarial loss: 0.445046\n",
      "epoch 25; iter: 0; batch classifier loss: 0.130442; batch adversarial loss: 0.596364\n",
      "epoch 26; iter: 0; batch classifier loss: 0.174190; batch adversarial loss: 0.497144\n",
      "epoch 27; iter: 0; batch classifier loss: 0.151312; batch adversarial loss: 0.460940\n",
      "epoch 28; iter: 0; batch classifier loss: 0.105784; batch adversarial loss: 0.517540\n",
      "epoch 29; iter: 0; batch classifier loss: 0.114799; batch adversarial loss: 0.483651\n",
      "epoch 30; iter: 0; batch classifier loss: 0.146097; batch adversarial loss: 0.423415\n",
      "epoch 31; iter: 0; batch classifier loss: 0.191505; batch adversarial loss: 0.485862\n",
      "epoch 32; iter: 0; batch classifier loss: 0.131180; batch adversarial loss: 0.500378\n",
      "epoch 33; iter: 0; batch classifier loss: 0.129551; batch adversarial loss: 0.503598\n",
      "epoch 34; iter: 0; batch classifier loss: 0.107514; batch adversarial loss: 0.524983\n",
      "epoch 35; iter: 0; batch classifier loss: 0.098836; batch adversarial loss: 0.484202\n",
      "epoch 36; iter: 0; batch classifier loss: 0.131435; batch adversarial loss: 0.473240\n",
      "epoch 37; iter: 0; batch classifier loss: 0.189371; batch adversarial loss: 0.474157\n",
      "epoch 38; iter: 0; batch classifier loss: 0.103469; batch adversarial loss: 0.461675\n",
      "epoch 39; iter: 0; batch classifier loss: 0.136080; batch adversarial loss: 0.467838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.158265; batch adversarial loss: 0.568842\n",
      "epoch 41; iter: 0; batch classifier loss: 0.146989; batch adversarial loss: 0.491590\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103519; batch adversarial loss: 0.488674\n",
      "epoch 43; iter: 0; batch classifier loss: 0.107082; batch adversarial loss: 0.404032\n",
      "epoch 44; iter: 0; batch classifier loss: 0.115493; batch adversarial loss: 0.481368\n",
      "epoch 45; iter: 0; batch classifier loss: 0.115852; batch adversarial loss: 0.527691\n",
      "epoch 46; iter: 0; batch classifier loss: 0.148806; batch adversarial loss: 0.457192\n",
      "epoch 47; iter: 0; batch classifier loss: 0.097268; batch adversarial loss: 0.449697\n",
      "epoch 48; iter: 0; batch classifier loss: 0.134083; batch adversarial loss: 0.553017\n",
      "epoch 49; iter: 0; batch classifier loss: 0.108251; batch adversarial loss: 0.355470\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091772; batch adversarial loss: 0.565585\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081592; batch adversarial loss: 0.587177\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100430; batch adversarial loss: 0.450680\n",
      "epoch 53; iter: 0; batch classifier loss: 0.133373; batch adversarial loss: 0.435437\n",
      "epoch 54; iter: 0; batch classifier loss: 0.121111; batch adversarial loss: 0.441782\n",
      "epoch 55; iter: 0; batch classifier loss: 0.082436; batch adversarial loss: 0.595910\n",
      "epoch 56; iter: 0; batch classifier loss: 0.057688; batch adversarial loss: 0.438758\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107649; batch adversarial loss: 0.436403\n",
      "epoch 58; iter: 0; batch classifier loss: 0.113020; batch adversarial loss: 0.472640\n",
      "epoch 59; iter: 0; batch classifier loss: 0.112700; batch adversarial loss: 0.491100\n",
      "epoch 60; iter: 0; batch classifier loss: 0.114324; batch adversarial loss: 0.419859\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104149; batch adversarial loss: 0.388871\n",
      "epoch 62; iter: 0; batch classifier loss: 0.047540; batch adversarial loss: 0.530513\n",
      "epoch 63; iter: 0; batch classifier loss: 0.140454; batch adversarial loss: 0.462100\n",
      "epoch 64; iter: 0; batch classifier loss: 0.071423; batch adversarial loss: 0.438481\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077795; batch adversarial loss: 0.366953\n",
      "epoch 66; iter: 0; batch classifier loss: 0.087249; batch adversarial loss: 0.472805\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059343; batch adversarial loss: 0.547506\n",
      "epoch 68; iter: 0; batch classifier loss: 0.128619; batch adversarial loss: 0.468944\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076465; batch adversarial loss: 0.493980\n",
      "epoch 70; iter: 0; batch classifier loss: 0.113947; batch adversarial loss: 0.571830\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071273; batch adversarial loss: 0.547904\n",
      "epoch 72; iter: 0; batch classifier loss: 0.078206; batch adversarial loss: 0.498066\n",
      "epoch 73; iter: 0; batch classifier loss: 0.064316; batch adversarial loss: 0.423329\n",
      "epoch 74; iter: 0; batch classifier loss: 0.080495; batch adversarial loss: 0.445455\n",
      "epoch 75; iter: 0; batch classifier loss: 0.092771; batch adversarial loss: 0.458312\n",
      "epoch 76; iter: 0; batch classifier loss: 0.092120; batch adversarial loss: 0.444742\n",
      "epoch 77; iter: 0; batch classifier loss: 0.100949; batch adversarial loss: 0.508425\n",
      "epoch 78; iter: 0; batch classifier loss: 0.093137; batch adversarial loss: 0.455897\n",
      "epoch 79; iter: 0; batch classifier loss: 0.088076; batch adversarial loss: 0.458705\n",
      "epoch 80; iter: 0; batch classifier loss: 0.118767; batch adversarial loss: 0.465229\n",
      "epoch 81; iter: 0; batch classifier loss: 0.121895; batch adversarial loss: 0.471000\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067412; batch adversarial loss: 0.487698\n",
      "epoch 83; iter: 0; batch classifier loss: 0.111073; batch adversarial loss: 0.467046\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082877; batch adversarial loss: 0.449625\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051777; batch adversarial loss: 0.502939\n",
      "epoch 86; iter: 0; batch classifier loss: 0.091073; batch adversarial loss: 0.479390\n",
      "epoch 87; iter: 0; batch classifier loss: 0.102164; batch adversarial loss: 0.484358\n",
      "epoch 88; iter: 0; batch classifier loss: 0.036436; batch adversarial loss: 0.383715\n",
      "epoch 89; iter: 0; batch classifier loss: 0.070887; batch adversarial loss: 0.448001\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051601; batch adversarial loss: 0.527979\n",
      "epoch 91; iter: 0; batch classifier loss: 0.079075; batch adversarial loss: 0.515128\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066558; batch adversarial loss: 0.466081\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052355; batch adversarial loss: 0.495432\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044617; batch adversarial loss: 0.481397\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063452; batch adversarial loss: 0.493415\n",
      "epoch 96; iter: 0; batch classifier loss: 0.071967; batch adversarial loss: 0.456961\n",
      "epoch 97; iter: 0; batch classifier loss: 0.070938; batch adversarial loss: 0.486224\n",
      "epoch 98; iter: 0; batch classifier loss: 0.043122; batch adversarial loss: 0.423820\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044081; batch adversarial loss: 0.381621\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054383; batch adversarial loss: 0.472490\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071795; batch adversarial loss: 0.388841\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029082; batch adversarial loss: 0.429489\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076536; batch adversarial loss: 0.391824\n",
      "epoch 104; iter: 0; batch classifier loss: 0.026141; batch adversarial loss: 0.462379\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059632; batch adversarial loss: 0.457143\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046609; batch adversarial loss: 0.463016\n",
      "epoch 107; iter: 0; batch classifier loss: 0.012520; batch adversarial loss: 0.533505\n",
      "epoch 108; iter: 0; batch classifier loss: 0.095618; batch adversarial loss: 0.419845\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026269; batch adversarial loss: 0.490194\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050818; batch adversarial loss: 0.444063\n",
      "epoch 111; iter: 0; batch classifier loss: 0.017442; batch adversarial loss: 0.546326\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042516; batch adversarial loss: 0.407009\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034131; batch adversarial loss: 0.551918\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053321; batch adversarial loss: 0.482068\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038649; batch adversarial loss: 0.504337\n",
      "epoch 116; iter: 0; batch classifier loss: 0.014283; batch adversarial loss: 0.512985\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028149; batch adversarial loss: 0.447319\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032992; batch adversarial loss: 0.439212\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054215; batch adversarial loss: 0.491447\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039441; batch adversarial loss: 0.421262\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026383; batch adversarial loss: 0.479760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.038132; batch adversarial loss: 0.511702\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025431; batch adversarial loss: 0.660919\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048901; batch adversarial loss: 0.446965\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037868; batch adversarial loss: 0.471543\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042270; batch adversarial loss: 0.470410\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026884; batch adversarial loss: 0.464304\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033593; batch adversarial loss: 0.594822\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020055; batch adversarial loss: 0.447902\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040527; batch adversarial loss: 0.481955\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033671; batch adversarial loss: 0.461874\n",
      "epoch 132; iter: 0; batch classifier loss: 0.014491; batch adversarial loss: 0.496769\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022597; batch adversarial loss: 0.418235\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019532; batch adversarial loss: 0.568841\n",
      "epoch 135; iter: 0; batch classifier loss: 0.088950; batch adversarial loss: 0.385369\n",
      "epoch 136; iter: 0; batch classifier loss: 0.048609; batch adversarial loss: 0.435092\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025963; batch adversarial loss: 0.548427\n",
      "epoch 138; iter: 0; batch classifier loss: 0.068494; batch adversarial loss: 0.438807\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015179; batch adversarial loss: 0.459603\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013899; batch adversarial loss: 0.473351\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017327; batch adversarial loss: 0.499779\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019444; batch adversarial loss: 0.493146\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033926; batch adversarial loss: 0.423065\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031031; batch adversarial loss: 0.477649\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026824; batch adversarial loss: 0.455400\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028795; batch adversarial loss: 0.458190\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044292; batch adversarial loss: 0.464532\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027698; batch adversarial loss: 0.502485\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024716; batch adversarial loss: 0.413453\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020649; batch adversarial loss: 0.491487\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021346; batch adversarial loss: 0.435264\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027568; batch adversarial loss: 0.477777\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034493; batch adversarial loss: 0.479062\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020974; batch adversarial loss: 0.479515\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027655; batch adversarial loss: 0.406433\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018856; batch adversarial loss: 0.481292\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012668; batch adversarial loss: 0.482221\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018466; batch adversarial loss: 0.438764\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010033; batch adversarial loss: 0.499891\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014974; batch adversarial loss: 0.584316\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011790; batch adversarial loss: 0.556885\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024588; batch adversarial loss: 0.386602\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018183; batch adversarial loss: 0.511172\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013421; batch adversarial loss: 0.481948\n",
      "epoch 165; iter: 0; batch classifier loss: 0.006164; batch adversarial loss: 0.405277\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046143; batch adversarial loss: 0.434631\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022483; batch adversarial loss: 0.508655\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045976; batch adversarial loss: 0.471886\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027361; batch adversarial loss: 0.431846\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015023; batch adversarial loss: 0.563402\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020649; batch adversarial loss: 0.412291\n",
      "epoch 172; iter: 0; batch classifier loss: 0.038055; batch adversarial loss: 0.432068\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030270; batch adversarial loss: 0.468260\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021144; batch adversarial loss: 0.443845\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017320; batch adversarial loss: 0.455390\n",
      "epoch 176; iter: 0; batch classifier loss: 0.006166; batch adversarial loss: 0.431079\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032031; batch adversarial loss: 0.519405\n",
      "epoch 178; iter: 0; batch classifier loss: 0.005621; batch adversarial loss: 0.336764\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019035; batch adversarial loss: 0.412602\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031060; batch adversarial loss: 0.526986\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026935; batch adversarial loss: 0.484767\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018358; batch adversarial loss: 0.479587\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014823; batch adversarial loss: 0.500594\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015949; batch adversarial loss: 0.521141\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016324; batch adversarial loss: 0.486165\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026182; batch adversarial loss: 0.470938\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029812; batch adversarial loss: 0.446325\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019918; batch adversarial loss: 0.429195\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017522; batch adversarial loss: 0.482970\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020595; batch adversarial loss: 0.460750\n",
      "epoch 191; iter: 0; batch classifier loss: 0.003936; batch adversarial loss: 0.445746\n",
      "epoch 192; iter: 0; batch classifier loss: 0.002352; batch adversarial loss: 0.439829\n",
      "epoch 193; iter: 0; batch classifier loss: 0.056092; batch adversarial loss: 0.503673\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026932; batch adversarial loss: 0.454586\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011969; batch adversarial loss: 0.471172\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024267; batch adversarial loss: 0.505602\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020907; batch adversarial loss: 0.446853\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020357; batch adversarial loss: 0.390438\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005791; batch adversarial loss: 0.434291\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688881; batch adversarial loss: 0.656585\n",
      "epoch 1; iter: 0; batch classifier loss: 0.437676; batch adversarial loss: 0.653936\n",
      "epoch 2; iter: 0; batch classifier loss: 0.441004; batch adversarial loss: 0.628665\n",
      "epoch 3; iter: 0; batch classifier loss: 0.456825; batch adversarial loss: 0.608602\n",
      "epoch 4; iter: 0; batch classifier loss: 0.555786; batch adversarial loss: 0.587675\n",
      "epoch 5; iter: 0; batch classifier loss: 0.483132; batch adversarial loss: 0.588777\n",
      "epoch 6; iter: 0; batch classifier loss: 0.504000; batch adversarial loss: 0.623596\n",
      "epoch 7; iter: 0; batch classifier loss: 0.460013; batch adversarial loss: 0.586840\n",
      "epoch 8; iter: 0; batch classifier loss: 0.435020; batch adversarial loss: 0.559814\n",
      "epoch 9; iter: 0; batch classifier loss: 0.352906; batch adversarial loss: 0.570504\n",
      "epoch 10; iter: 0; batch classifier loss: 0.426018; batch adversarial loss: 0.530751\n",
      "epoch 11; iter: 0; batch classifier loss: 0.327111; batch adversarial loss: 0.599768\n",
      "epoch 12; iter: 0; batch classifier loss: 0.435155; batch adversarial loss: 0.527964\n",
      "epoch 13; iter: 0; batch classifier loss: 0.377358; batch adversarial loss: 0.579560\n",
      "epoch 14; iter: 0; batch classifier loss: 0.284880; batch adversarial loss: 0.504305\n",
      "epoch 15; iter: 0; batch classifier loss: 0.372626; batch adversarial loss: 0.474085\n",
      "epoch 16; iter: 0; batch classifier loss: 0.322201; batch adversarial loss: 0.462005\n",
      "epoch 17; iter: 0; batch classifier loss: 0.283682; batch adversarial loss: 0.552072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.259916; batch adversarial loss: 0.491071\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236486; batch adversarial loss: 0.463458\n",
      "epoch 20; iter: 0; batch classifier loss: 0.286300; batch adversarial loss: 0.510380\n",
      "epoch 21; iter: 0; batch classifier loss: 0.250814; batch adversarial loss: 0.540768\n",
      "epoch 22; iter: 0; batch classifier loss: 0.298236; batch adversarial loss: 0.397983\n",
      "epoch 23; iter: 0; batch classifier loss: 0.302021; batch adversarial loss: 0.464321\n",
      "epoch 24; iter: 0; batch classifier loss: 0.294219; batch adversarial loss: 0.540481\n",
      "epoch 25; iter: 0; batch classifier loss: 0.327056; batch adversarial loss: 0.453509\n",
      "epoch 26; iter: 0; batch classifier loss: 0.293810; batch adversarial loss: 0.449604\n",
      "epoch 27; iter: 0; batch classifier loss: 0.231386; batch adversarial loss: 0.484440\n",
      "epoch 28; iter: 0; batch classifier loss: 0.237884; batch adversarial loss: 0.554459\n",
      "epoch 29; iter: 0; batch classifier loss: 0.271346; batch adversarial loss: 0.433602\n",
      "epoch 30; iter: 0; batch classifier loss: 0.223427; batch adversarial loss: 0.502216\n",
      "epoch 31; iter: 0; batch classifier loss: 0.243352; batch adversarial loss: 0.498314\n",
      "epoch 32; iter: 0; batch classifier loss: 0.264959; batch adversarial loss: 0.409014\n",
      "epoch 33; iter: 0; batch classifier loss: 0.234552; batch adversarial loss: 0.570118\n",
      "epoch 34; iter: 0; batch classifier loss: 0.228857; batch adversarial loss: 0.471041\n",
      "epoch 35; iter: 0; batch classifier loss: 0.306924; batch adversarial loss: 0.428270\n",
      "epoch 36; iter: 0; batch classifier loss: 0.202270; batch adversarial loss: 0.505126\n",
      "epoch 37; iter: 0; batch classifier loss: 0.253472; batch adversarial loss: 0.415984\n",
      "epoch 38; iter: 0; batch classifier loss: 0.270468; batch adversarial loss: 0.451149\n",
      "epoch 39; iter: 0; batch classifier loss: 0.235070; batch adversarial loss: 0.392547\n",
      "epoch 40; iter: 0; batch classifier loss: 0.253204; batch adversarial loss: 0.483147\n",
      "epoch 41; iter: 0; batch classifier loss: 0.240102; batch adversarial loss: 0.496256\n",
      "epoch 42; iter: 0; batch classifier loss: 0.347663; batch adversarial loss: 0.506217\n",
      "epoch 43; iter: 0; batch classifier loss: 0.215732; batch adversarial loss: 0.474512\n",
      "epoch 44; iter: 0; batch classifier loss: 0.192314; batch adversarial loss: 0.559293\n",
      "epoch 45; iter: 0; batch classifier loss: 0.313983; batch adversarial loss: 0.390772\n",
      "epoch 46; iter: 0; batch classifier loss: 0.258290; batch adversarial loss: 0.412063\n",
      "epoch 47; iter: 0; batch classifier loss: 0.252208; batch adversarial loss: 0.494060\n",
      "epoch 48; iter: 0; batch classifier loss: 0.186397; batch adversarial loss: 0.367915\n",
      "epoch 49; iter: 0; batch classifier loss: 0.321412; batch adversarial loss: 0.459661\n",
      "epoch 50; iter: 0; batch classifier loss: 0.220970; batch adversarial loss: 0.482709\n",
      "epoch 51; iter: 0; batch classifier loss: 0.267158; batch adversarial loss: 0.401294\n",
      "epoch 52; iter: 0; batch classifier loss: 0.293449; batch adversarial loss: 0.412493\n",
      "epoch 53; iter: 0; batch classifier loss: 0.134793; batch adversarial loss: 0.386131\n",
      "epoch 54; iter: 0; batch classifier loss: 0.076970; batch adversarial loss: 0.530010\n",
      "epoch 55; iter: 0; batch classifier loss: 0.055217; batch adversarial loss: 0.453510\n",
      "epoch 56; iter: 0; batch classifier loss: 0.072807; batch adversarial loss: 0.442155\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073646; batch adversarial loss: 0.479157\n",
      "epoch 58; iter: 0; batch classifier loss: 0.056839; batch adversarial loss: 0.452294\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070032; batch adversarial loss: 0.428097\n",
      "epoch 60; iter: 0; batch classifier loss: 0.098065; batch adversarial loss: 0.484292\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071385; batch adversarial loss: 0.343680\n",
      "epoch 62; iter: 0; batch classifier loss: 0.051216; batch adversarial loss: 0.458390\n",
      "epoch 63; iter: 0; batch classifier loss: 0.063932; batch adversarial loss: 0.557392\n",
      "epoch 64; iter: 0; batch classifier loss: 0.050768; batch adversarial loss: 0.502175\n",
      "epoch 65; iter: 0; batch classifier loss: 0.044692; batch adversarial loss: 0.464063\n",
      "epoch 66; iter: 0; batch classifier loss: 0.059709; batch adversarial loss: 0.477340\n",
      "epoch 67; iter: 0; batch classifier loss: 0.039506; batch adversarial loss: 0.435133\n",
      "epoch 68; iter: 0; batch classifier loss: 0.056656; batch adversarial loss: 0.413656\n",
      "epoch 69; iter: 0; batch classifier loss: 0.027447; batch adversarial loss: 0.418948\n",
      "epoch 70; iter: 0; batch classifier loss: 0.069941; batch adversarial loss: 0.455505\n",
      "epoch 71; iter: 0; batch classifier loss: 0.032309; batch adversarial loss: 0.412390\n",
      "epoch 72; iter: 0; batch classifier loss: 0.060857; batch adversarial loss: 0.411597\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068307; batch adversarial loss: 0.489058\n",
      "epoch 74; iter: 0; batch classifier loss: 0.060920; batch adversarial loss: 0.376044\n",
      "epoch 75; iter: 0; batch classifier loss: 0.036534; batch adversarial loss: 0.434340\n",
      "epoch 76; iter: 0; batch classifier loss: 0.074273; batch adversarial loss: 0.473058\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050447; batch adversarial loss: 0.395439\n",
      "epoch 78; iter: 0; batch classifier loss: 0.065964; batch adversarial loss: 0.532800\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075718; batch adversarial loss: 0.327089\n",
      "epoch 80; iter: 0; batch classifier loss: 0.057763; batch adversarial loss: 0.408924\n",
      "epoch 81; iter: 0; batch classifier loss: 0.043228; batch adversarial loss: 0.446066\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083524; batch adversarial loss: 0.496553\n",
      "epoch 83; iter: 0; batch classifier loss: 0.050649; batch adversarial loss: 0.468678\n",
      "epoch 84; iter: 0; batch classifier loss: 0.047890; batch adversarial loss: 0.442327\n",
      "epoch 85; iter: 0; batch classifier loss: 0.049107; batch adversarial loss: 0.440866\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054310; batch adversarial loss: 0.399261\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053967; batch adversarial loss: 0.379324\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067041; batch adversarial loss: 0.603878\n",
      "epoch 89; iter: 0; batch classifier loss: 0.041391; batch adversarial loss: 0.419435\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061506; batch adversarial loss: 0.388488\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059604; batch adversarial loss: 0.390176\n",
      "epoch 92; iter: 0; batch classifier loss: 0.037980; batch adversarial loss: 0.468742\n",
      "epoch 93; iter: 0; batch classifier loss: 0.060268; batch adversarial loss: 0.529221\n",
      "epoch 94; iter: 0; batch classifier loss: 0.067162; batch adversarial loss: 0.368223\n",
      "epoch 95; iter: 0; batch classifier loss: 0.086046; batch adversarial loss: 0.478096\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059103; batch adversarial loss: 0.424128\n",
      "epoch 97; iter: 0; batch classifier loss: 0.067098; batch adversarial loss: 0.423375\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052050; batch adversarial loss: 0.369911\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038997; batch adversarial loss: 0.470631\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055926; batch adversarial loss: 0.452134\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051692; batch adversarial loss: 0.406976\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047322; batch adversarial loss: 0.407763\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053258; batch adversarial loss: 0.515269\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027469; batch adversarial loss: 0.350350\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059294; batch adversarial loss: 0.433430\n",
      "epoch 106; iter: 0; batch classifier loss: 0.113385; batch adversarial loss: 0.443402\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035928; batch adversarial loss: 0.496437\n",
      "epoch 108; iter: 0; batch classifier loss: 0.034854; batch adversarial loss: 0.513630\n",
      "epoch 109; iter: 0; batch classifier loss: 0.085246; batch adversarial loss: 0.573329\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067017; batch adversarial loss: 0.407076\n",
      "epoch 111; iter: 0; batch classifier loss: 0.078159; batch adversarial loss: 0.558843\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055802; batch adversarial loss: 0.474596\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054851; batch adversarial loss: 0.456360\n",
      "epoch 114; iter: 0; batch classifier loss: 0.064868; batch adversarial loss: 0.424474\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052540; batch adversarial loss: 0.415990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.088703; batch adversarial loss: 0.409261\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047620; batch adversarial loss: 0.422255\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044509; batch adversarial loss: 0.452359\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055759; batch adversarial loss: 0.436621\n",
      "epoch 120; iter: 0; batch classifier loss: 0.064959; batch adversarial loss: 0.466359\n",
      "epoch 121; iter: 0; batch classifier loss: 0.063002; batch adversarial loss: 0.471734\n",
      "epoch 122; iter: 0; batch classifier loss: 0.054834; batch adversarial loss: 0.459374\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050100; batch adversarial loss: 0.463873\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044645; batch adversarial loss: 0.430966\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058852; batch adversarial loss: 0.474495\n",
      "epoch 126; iter: 0; batch classifier loss: 0.078275; batch adversarial loss: 0.507692\n",
      "epoch 127; iter: 0; batch classifier loss: 0.063517; batch adversarial loss: 0.506186\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045394; batch adversarial loss: 0.399317\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048337; batch adversarial loss: 0.396755\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043170; batch adversarial loss: 0.438583\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034602; batch adversarial loss: 0.507296\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041957; batch adversarial loss: 0.430142\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041939; batch adversarial loss: 0.402052\n",
      "epoch 134; iter: 0; batch classifier loss: 0.070103; batch adversarial loss: 0.393057\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043269; batch adversarial loss: 0.421040\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054869; batch adversarial loss: 0.418353\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036980; batch adversarial loss: 0.425021\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034407; batch adversarial loss: 0.398173\n",
      "epoch 139; iter: 0; batch classifier loss: 0.055298; batch adversarial loss: 0.583391\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038805; batch adversarial loss: 0.409912\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031257; batch adversarial loss: 0.399000\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033447; batch adversarial loss: 0.430600\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037650; batch adversarial loss: 0.391330\n",
      "epoch 144; iter: 0; batch classifier loss: 0.055695; batch adversarial loss: 0.443745\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044726; batch adversarial loss: 0.416875\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032340; batch adversarial loss: 0.469900\n",
      "epoch 147; iter: 0; batch classifier loss: 0.048566; batch adversarial loss: 0.499961\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027281; batch adversarial loss: 0.489875\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028456; batch adversarial loss: 0.500271\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023323; batch adversarial loss: 0.449364\n",
      "epoch 151; iter: 0; batch classifier loss: 0.054470; batch adversarial loss: 0.531063\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017950; batch adversarial loss: 0.523607\n",
      "epoch 153; iter: 0; batch classifier loss: 0.044244; batch adversarial loss: 0.452508\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038504; batch adversarial loss: 0.449765\n",
      "epoch 155; iter: 0; batch classifier loss: 0.053340; batch adversarial loss: 0.439391\n",
      "epoch 156; iter: 0; batch classifier loss: 0.070739; batch adversarial loss: 0.423331\n",
      "epoch 157; iter: 0; batch classifier loss: 0.043480; batch adversarial loss: 0.435077\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025373; batch adversarial loss: 0.387486\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031396; batch adversarial loss: 0.531069\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028903; batch adversarial loss: 0.463087\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035170; batch adversarial loss: 0.456479\n",
      "epoch 162; iter: 0; batch classifier loss: 0.064703; batch adversarial loss: 0.393757\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018461; batch adversarial loss: 0.444332\n",
      "epoch 164; iter: 0; batch classifier loss: 0.047234; batch adversarial loss: 0.388263\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026723; batch adversarial loss: 0.458276\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034921; batch adversarial loss: 0.409389\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021792; batch adversarial loss: 0.412052\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022069; batch adversarial loss: 0.434367\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027522; batch adversarial loss: 0.464102\n",
      "epoch 170; iter: 0; batch classifier loss: 0.064570; batch adversarial loss: 0.545502\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009838; batch adversarial loss: 0.430673\n",
      "epoch 172; iter: 0; batch classifier loss: 0.054054; batch adversarial loss: 0.407299\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020118; batch adversarial loss: 0.494449\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027674; batch adversarial loss: 0.482019\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020648; batch adversarial loss: 0.486792\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010630; batch adversarial loss: 0.538618\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034923; batch adversarial loss: 0.405494\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029241; batch adversarial loss: 0.430415\n",
      "epoch 179; iter: 0; batch classifier loss: 0.051878; batch adversarial loss: 0.376859\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032006; batch adversarial loss: 0.397243\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020441; batch adversarial loss: 0.383497\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032792; batch adversarial loss: 0.531578\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014007; batch adversarial loss: 0.425152\n",
      "epoch 184; iter: 0; batch classifier loss: 0.054685; batch adversarial loss: 0.448155\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036976; batch adversarial loss: 0.396521\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020211; batch adversarial loss: 0.445435\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015148; batch adversarial loss: 0.501574\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032191; batch adversarial loss: 0.469253\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014575; batch adversarial loss: 0.480352\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031698; batch adversarial loss: 0.499881\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013384; batch adversarial loss: 0.500514\n",
      "epoch 192; iter: 0; batch classifier loss: 0.052943; batch adversarial loss: 0.522063\n",
      "epoch 193; iter: 0; batch classifier loss: 0.034127; batch adversarial loss: 0.331330\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033982; batch adversarial loss: 0.421590\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036704; batch adversarial loss: 0.395375\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031439; batch adversarial loss: 0.362974\n",
      "epoch 197; iter: 0; batch classifier loss: 0.058869; batch adversarial loss: 0.430215\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006638; batch adversarial loss: 0.432093\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031205; batch adversarial loss: 0.413905\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720542; batch adversarial loss: 0.771947\n",
      "epoch 1; iter: 0; batch classifier loss: 0.471022; batch adversarial loss: 0.721159\n",
      "epoch 2; iter: 0; batch classifier loss: 0.529643; batch adversarial loss: 0.678944\n",
      "epoch 3; iter: 0; batch classifier loss: 0.585918; batch adversarial loss: 0.642257\n",
      "epoch 4; iter: 0; batch classifier loss: 0.409268; batch adversarial loss: 0.611827\n",
      "epoch 5; iter: 0; batch classifier loss: 0.352129; batch adversarial loss: 0.605833\n",
      "epoch 6; iter: 0; batch classifier loss: 0.310412; batch adversarial loss: 0.572244\n",
      "epoch 7; iter: 0; batch classifier loss: 0.379649; batch adversarial loss: 0.587802\n",
      "epoch 8; iter: 0; batch classifier loss: 0.397118; batch adversarial loss: 0.548136\n",
      "epoch 9; iter: 0; batch classifier loss: 0.327546; batch adversarial loss: 0.504365\n",
      "epoch 10; iter: 0; batch classifier loss: 0.392047; batch adversarial loss: 0.572055\n",
      "epoch 11; iter: 0; batch classifier loss: 0.407314; batch adversarial loss: 0.565709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.400817; batch adversarial loss: 0.575661\n",
      "epoch 13; iter: 0; batch classifier loss: 0.497435; batch adversarial loss: 0.487215\n",
      "epoch 14; iter: 0; batch classifier loss: 0.394001; batch adversarial loss: 0.521611\n",
      "epoch 15; iter: 0; batch classifier loss: 0.395046; batch adversarial loss: 0.467182\n",
      "epoch 16; iter: 0; batch classifier loss: 0.308644; batch adversarial loss: 0.455371\n",
      "epoch 17; iter: 0; batch classifier loss: 0.312128; batch adversarial loss: 0.457207\n",
      "epoch 18; iter: 0; batch classifier loss: 0.328516; batch adversarial loss: 0.515200\n",
      "epoch 19; iter: 0; batch classifier loss: 0.322190; batch adversarial loss: 0.422356\n",
      "epoch 20; iter: 0; batch classifier loss: 0.351220; batch adversarial loss: 0.504264\n",
      "epoch 21; iter: 0; batch classifier loss: 0.327739; batch adversarial loss: 0.476637\n",
      "epoch 22; iter: 0; batch classifier loss: 0.357320; batch adversarial loss: 0.431905\n",
      "epoch 23; iter: 0; batch classifier loss: 0.313145; batch adversarial loss: 0.486473\n",
      "epoch 24; iter: 0; batch classifier loss: 0.348284; batch adversarial loss: 0.388414\n",
      "epoch 25; iter: 0; batch classifier loss: 0.228507; batch adversarial loss: 0.470723\n",
      "epoch 26; iter: 0; batch classifier loss: 0.252375; batch adversarial loss: 0.574875\n",
      "epoch 27; iter: 0; batch classifier loss: 0.220735; batch adversarial loss: 0.540207\n",
      "epoch 28; iter: 0; batch classifier loss: 0.249362; batch adversarial loss: 0.430445\n",
      "epoch 29; iter: 0; batch classifier loss: 0.217071; batch adversarial loss: 0.438545\n",
      "epoch 30; iter: 0; batch classifier loss: 0.182181; batch adversarial loss: 0.462318\n",
      "epoch 31; iter: 0; batch classifier loss: 0.217546; batch adversarial loss: 0.480577\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181126; batch adversarial loss: 0.418174\n",
      "epoch 33; iter: 0; batch classifier loss: 0.154898; batch adversarial loss: 0.545752\n",
      "epoch 34; iter: 0; batch classifier loss: 0.258756; batch adversarial loss: 0.420639\n",
      "epoch 35; iter: 0; batch classifier loss: 0.243026; batch adversarial loss: 0.538522\n",
      "epoch 36; iter: 0; batch classifier loss: 0.236961; batch adversarial loss: 0.361449\n",
      "epoch 37; iter: 0; batch classifier loss: 0.260804; batch adversarial loss: 0.454531\n",
      "epoch 38; iter: 0; batch classifier loss: 0.227241; batch adversarial loss: 0.475762\n",
      "epoch 39; iter: 0; batch classifier loss: 0.273760; batch adversarial loss: 0.472482\n",
      "epoch 40; iter: 0; batch classifier loss: 0.281582; batch adversarial loss: 0.514461\n",
      "epoch 41; iter: 0; batch classifier loss: 0.144013; batch adversarial loss: 0.524178\n",
      "epoch 42; iter: 0; batch classifier loss: 0.298562; batch adversarial loss: 0.392184\n",
      "epoch 43; iter: 0; batch classifier loss: 0.194147; batch adversarial loss: 0.539421\n",
      "epoch 44; iter: 0; batch classifier loss: 0.270383; batch adversarial loss: 0.429629\n",
      "epoch 45; iter: 0; batch classifier loss: 0.206660; batch adversarial loss: 0.520520\n",
      "epoch 46; iter: 0; batch classifier loss: 0.123108; batch adversarial loss: 0.510676\n",
      "epoch 47; iter: 0; batch classifier loss: 0.209580; batch adversarial loss: 0.458114\n",
      "epoch 48; iter: 0; batch classifier loss: 0.308820; batch adversarial loss: 0.429402\n",
      "epoch 49; iter: 0; batch classifier loss: 0.231695; batch adversarial loss: 0.543105\n",
      "epoch 50; iter: 0; batch classifier loss: 0.245909; batch adversarial loss: 0.532384\n",
      "epoch 51; iter: 0; batch classifier loss: 0.162185; batch adversarial loss: 0.550158\n",
      "epoch 52; iter: 0; batch classifier loss: 0.185517; batch adversarial loss: 0.376315\n",
      "epoch 53; iter: 0; batch classifier loss: 0.226136; batch adversarial loss: 0.449725\n",
      "epoch 54; iter: 0; batch classifier loss: 0.232391; batch adversarial loss: 0.471637\n",
      "epoch 55; iter: 0; batch classifier loss: 0.183254; batch adversarial loss: 0.412439\n",
      "epoch 56; iter: 0; batch classifier loss: 0.135640; batch adversarial loss: 0.433546\n",
      "epoch 57; iter: 0; batch classifier loss: 0.173955; batch adversarial loss: 0.412143\n",
      "epoch 58; iter: 0; batch classifier loss: 0.131571; batch adversarial loss: 0.498229\n",
      "epoch 59; iter: 0; batch classifier loss: 0.230692; batch adversarial loss: 0.448869\n",
      "epoch 60; iter: 0; batch classifier loss: 0.143704; batch adversarial loss: 0.459988\n",
      "epoch 61; iter: 0; batch classifier loss: 0.255818; batch adversarial loss: 0.445395\n",
      "epoch 62; iter: 0; batch classifier loss: 0.193641; batch adversarial loss: 0.542131\n",
      "epoch 63; iter: 0; batch classifier loss: 0.208368; batch adversarial loss: 0.492049\n",
      "epoch 64; iter: 0; batch classifier loss: 0.161414; batch adversarial loss: 0.570781\n",
      "epoch 65; iter: 0; batch classifier loss: 0.194792; batch adversarial loss: 0.471339\n",
      "epoch 66; iter: 0; batch classifier loss: 0.177193; batch adversarial loss: 0.453537\n",
      "epoch 67; iter: 0; batch classifier loss: 0.123593; batch adversarial loss: 0.498442\n",
      "epoch 68; iter: 0; batch classifier loss: 0.193328; batch adversarial loss: 0.426753\n",
      "epoch 69; iter: 0; batch classifier loss: 0.175913; batch adversarial loss: 0.493153\n",
      "epoch 70; iter: 0; batch classifier loss: 0.230809; batch adversarial loss: 0.448288\n",
      "epoch 71; iter: 0; batch classifier loss: 0.179713; batch adversarial loss: 0.377365\n",
      "epoch 72; iter: 0; batch classifier loss: 0.144960; batch adversarial loss: 0.439764\n",
      "epoch 73; iter: 0; batch classifier loss: 0.096184; batch adversarial loss: 0.443515\n",
      "epoch 74; iter: 0; batch classifier loss: 0.130213; batch adversarial loss: 0.359922\n",
      "epoch 75; iter: 0; batch classifier loss: 0.089265; batch adversarial loss: 0.465641\n",
      "epoch 76; iter: 0; batch classifier loss: 0.108722; batch adversarial loss: 0.425361\n",
      "epoch 77; iter: 0; batch classifier loss: 0.109171; batch adversarial loss: 0.509504\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085006; batch adversarial loss: 0.522456\n",
      "epoch 79; iter: 0; batch classifier loss: 0.052844; batch adversarial loss: 0.499351\n",
      "epoch 80; iter: 0; batch classifier loss: 0.074785; batch adversarial loss: 0.448225\n",
      "epoch 81; iter: 0; batch classifier loss: 0.080881; batch adversarial loss: 0.490294\n",
      "epoch 82; iter: 0; batch classifier loss: 0.121011; batch adversarial loss: 0.495896\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074356; batch adversarial loss: 0.420006\n",
      "epoch 84; iter: 0; batch classifier loss: 0.121734; batch adversarial loss: 0.463874\n",
      "epoch 85; iter: 0; batch classifier loss: 0.056398; batch adversarial loss: 0.485096\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064398; batch adversarial loss: 0.467074\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059376; batch adversarial loss: 0.360794\n",
      "epoch 88; iter: 0; batch classifier loss: 0.029737; batch adversarial loss: 0.424847\n",
      "epoch 89; iter: 0; batch classifier loss: 0.086153; batch adversarial loss: 0.446873\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039522; batch adversarial loss: 0.504650\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056714; batch adversarial loss: 0.504185\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041462; batch adversarial loss: 0.461208\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044386; batch adversarial loss: 0.494429\n",
      "epoch 94; iter: 0; batch classifier loss: 0.031480; batch adversarial loss: 0.530450\n",
      "epoch 95; iter: 0; batch classifier loss: 0.044140; batch adversarial loss: 0.426675\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036945; batch adversarial loss: 0.501652\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046850; batch adversarial loss: 0.446861\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072412; batch adversarial loss: 0.431296\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078489; batch adversarial loss: 0.486579\n",
      "epoch 100; iter: 0; batch classifier loss: 0.024948; batch adversarial loss: 0.352612\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041855; batch adversarial loss: 0.424654\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036688; batch adversarial loss: 0.509845\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041702; batch adversarial loss: 0.395479\n",
      "epoch 104; iter: 0; batch classifier loss: 0.025774; batch adversarial loss: 0.445078\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041018; batch adversarial loss: 0.488917\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059745; batch adversarial loss: 0.471351\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038608; batch adversarial loss: 0.433000\n",
      "epoch 108; iter: 0; batch classifier loss: 0.015835; batch adversarial loss: 0.517757\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026373; batch adversarial loss: 0.404028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.038934; batch adversarial loss: 0.358128\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034985; batch adversarial loss: 0.517128\n",
      "epoch 112; iter: 0; batch classifier loss: 0.012104; batch adversarial loss: 0.373934\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043529; batch adversarial loss: 0.402076\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037183; batch adversarial loss: 0.359885\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039827; batch adversarial loss: 0.460443\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024857; batch adversarial loss: 0.402290\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026611; batch adversarial loss: 0.420118\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063835; batch adversarial loss: 0.415891\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037594; batch adversarial loss: 0.467960\n",
      "epoch 120; iter: 0; batch classifier loss: 0.014923; batch adversarial loss: 0.494271\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036455; batch adversarial loss: 0.415690\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017973; batch adversarial loss: 0.434244\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027395; batch adversarial loss: 0.381067\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029530; batch adversarial loss: 0.503067\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020782; batch adversarial loss: 0.427568\n",
      "epoch 126; iter: 0; batch classifier loss: 0.012740; batch adversarial loss: 0.446847\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040959; batch adversarial loss: 0.451930\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021844; batch adversarial loss: 0.499290\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046387; batch adversarial loss: 0.459313\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022337; batch adversarial loss: 0.516783\n",
      "epoch 131; iter: 0; batch classifier loss: 0.006813; batch adversarial loss: 0.535284\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026944; batch adversarial loss: 0.438376\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022439; batch adversarial loss: 0.529305\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033244; batch adversarial loss: 0.464561\n",
      "epoch 135; iter: 0; batch classifier loss: 0.055137; batch adversarial loss: 0.493544\n",
      "epoch 136; iter: 0; batch classifier loss: 0.011677; batch adversarial loss: 0.346501\n",
      "epoch 137; iter: 0; batch classifier loss: 0.014326; batch adversarial loss: 0.418334\n",
      "epoch 138; iter: 0; batch classifier loss: 0.015693; batch adversarial loss: 0.486308\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025554; batch adversarial loss: 0.467400\n",
      "epoch 140; iter: 0; batch classifier loss: 0.056408; batch adversarial loss: 0.492995\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042768; batch adversarial loss: 0.451342\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031349; batch adversarial loss: 0.525170\n",
      "epoch 143; iter: 0; batch classifier loss: 0.003701; batch adversarial loss: 0.484537\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019919; batch adversarial loss: 0.417681\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027815; batch adversarial loss: 0.425567\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013692; batch adversarial loss: 0.403459\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041509; batch adversarial loss: 0.447001\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026629; batch adversarial loss: 0.491070\n",
      "epoch 149; iter: 0; batch classifier loss: 0.060451; batch adversarial loss: 0.516726\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013165; batch adversarial loss: 0.475676\n",
      "epoch 151; iter: 0; batch classifier loss: 0.006566; batch adversarial loss: 0.503327\n",
      "epoch 152; iter: 0; batch classifier loss: 0.004559; batch adversarial loss: 0.382410\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008202; batch adversarial loss: 0.475627\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014634; batch adversarial loss: 0.458856\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038406; batch adversarial loss: 0.481797\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035959; batch adversarial loss: 0.417354\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023904; batch adversarial loss: 0.593810\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032847; batch adversarial loss: 0.516352\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014770; batch adversarial loss: 0.511152\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029322; batch adversarial loss: 0.429723\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009371; batch adversarial loss: 0.496583\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009899; batch adversarial loss: 0.561780\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010332; batch adversarial loss: 0.399431\n",
      "epoch 164; iter: 0; batch classifier loss: 0.004859; batch adversarial loss: 0.451082\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021473; batch adversarial loss: 0.447321\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015928; batch adversarial loss: 0.479203\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034164; batch adversarial loss: 0.424260\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012939; batch adversarial loss: 0.415680\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010230; batch adversarial loss: 0.526659\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028166; batch adversarial loss: 0.425257\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010987; batch adversarial loss: 0.507189\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008089; batch adversarial loss: 0.549536\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013422; batch adversarial loss: 0.436306\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013221; batch adversarial loss: 0.435507\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015984; batch adversarial loss: 0.441009\n",
      "epoch 176; iter: 0; batch classifier loss: 0.001961; batch adversarial loss: 0.319168\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011436; batch adversarial loss: 0.461913\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012519; batch adversarial loss: 0.414376\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016326; batch adversarial loss: 0.462037\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014277; batch adversarial loss: 0.489814\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012760; batch adversarial loss: 0.411008\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009921; batch adversarial loss: 0.359365\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023144; batch adversarial loss: 0.442370\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009159; batch adversarial loss: 0.425324\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021335; batch adversarial loss: 0.475134\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013881; batch adversarial loss: 0.444828\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007297; batch adversarial loss: 0.394845\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026726; batch adversarial loss: 0.483953\n",
      "epoch 189; iter: 0; batch classifier loss: 0.057650; batch adversarial loss: 0.471408\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037261; batch adversarial loss: 0.403003\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029205; batch adversarial loss: 0.451910\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008467; batch adversarial loss: 0.502214\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015230; batch adversarial loss: 0.438367\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019679; batch adversarial loss: 0.510833\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019022; batch adversarial loss: 0.356460\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029397; batch adversarial loss: 0.405108\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026294; batch adversarial loss: 0.514560\n",
      "epoch 198; iter: 0; batch classifier loss: 0.036439; batch adversarial loss: 0.443063\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017184; batch adversarial loss: 0.399604\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705883; batch adversarial loss: 0.604465\n",
      "epoch 1; iter: 0; batch classifier loss: 0.505992; batch adversarial loss: 0.612245\n",
      "epoch 2; iter: 0; batch classifier loss: 0.356880; batch adversarial loss: 0.604150\n",
      "epoch 3; iter: 0; batch classifier loss: 0.305611; batch adversarial loss: 0.567786\n",
      "epoch 4; iter: 0; batch classifier loss: 0.324042; batch adversarial loss: 0.547707\n",
      "epoch 5; iter: 0; batch classifier loss: 0.286424; batch adversarial loss: 0.552860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.291156; batch adversarial loss: 0.535480\n",
      "epoch 7; iter: 0; batch classifier loss: 0.328245; batch adversarial loss: 0.472756\n",
      "epoch 8; iter: 0; batch classifier loss: 0.238014; batch adversarial loss: 0.511156\n",
      "epoch 9; iter: 0; batch classifier loss: 0.323467; batch adversarial loss: 0.487711\n",
      "epoch 10; iter: 0; batch classifier loss: 0.250319; batch adversarial loss: 0.459906\n",
      "epoch 11; iter: 0; batch classifier loss: 0.219238; batch adversarial loss: 0.495498\n",
      "epoch 12; iter: 0; batch classifier loss: 0.211874; batch adversarial loss: 0.492072\n",
      "epoch 13; iter: 0; batch classifier loss: 0.249889; batch adversarial loss: 0.514742\n",
      "epoch 14; iter: 0; batch classifier loss: 0.204968; batch adversarial loss: 0.499407\n",
      "epoch 15; iter: 0; batch classifier loss: 0.235009; batch adversarial loss: 0.478733\n",
      "epoch 16; iter: 0; batch classifier loss: 0.258771; batch adversarial loss: 0.460555\n",
      "epoch 17; iter: 0; batch classifier loss: 0.226919; batch adversarial loss: 0.501222\n",
      "epoch 18; iter: 0; batch classifier loss: 0.268434; batch adversarial loss: 0.580515\n",
      "epoch 19; iter: 0; batch classifier loss: 0.270461; batch adversarial loss: 0.556625\n",
      "epoch 20; iter: 0; batch classifier loss: 0.266171; batch adversarial loss: 0.462778\n",
      "epoch 21; iter: 0; batch classifier loss: 0.338427; batch adversarial loss: 0.546105\n",
      "epoch 22; iter: 0; batch classifier loss: 0.361352; batch adversarial loss: 0.516589\n",
      "epoch 23; iter: 0; batch classifier loss: 0.470185; batch adversarial loss: 0.485499\n",
      "epoch 24; iter: 0; batch classifier loss: 0.286686; batch adversarial loss: 0.522740\n",
      "epoch 25; iter: 0; batch classifier loss: 0.191334; batch adversarial loss: 0.508416\n",
      "epoch 26; iter: 0; batch classifier loss: 0.177836; batch adversarial loss: 0.451124\n",
      "epoch 27; iter: 0; batch classifier loss: 0.118063; batch adversarial loss: 0.519417\n",
      "epoch 28; iter: 0; batch classifier loss: 0.150060; batch adversarial loss: 0.439541\n",
      "epoch 29; iter: 0; batch classifier loss: 0.092870; batch adversarial loss: 0.509520\n",
      "epoch 30; iter: 0; batch classifier loss: 0.101029; batch adversarial loss: 0.511740\n",
      "epoch 31; iter: 0; batch classifier loss: 0.124394; batch adversarial loss: 0.379943\n",
      "epoch 32; iter: 0; batch classifier loss: 0.119543; batch adversarial loss: 0.443111\n",
      "epoch 33; iter: 0; batch classifier loss: 0.133835; batch adversarial loss: 0.390563\n",
      "epoch 34; iter: 0; batch classifier loss: 0.116782; batch adversarial loss: 0.414272\n",
      "epoch 35; iter: 0; batch classifier loss: 0.131466; batch adversarial loss: 0.371618\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150900; batch adversarial loss: 0.403371\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111988; batch adversarial loss: 0.506857\n",
      "epoch 38; iter: 0; batch classifier loss: 0.108268; batch adversarial loss: 0.410957\n",
      "epoch 39; iter: 0; batch classifier loss: 0.111044; batch adversarial loss: 0.481650\n",
      "epoch 40; iter: 0; batch classifier loss: 0.117032; batch adversarial loss: 0.466820\n",
      "epoch 41; iter: 0; batch classifier loss: 0.081925; batch adversarial loss: 0.421813\n",
      "epoch 42; iter: 0; batch classifier loss: 0.054771; batch adversarial loss: 0.438097\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110453; batch adversarial loss: 0.543238\n",
      "epoch 44; iter: 0; batch classifier loss: 0.072160; batch adversarial loss: 0.437632\n",
      "epoch 45; iter: 0; batch classifier loss: 0.072866; batch adversarial loss: 0.419374\n",
      "epoch 46; iter: 0; batch classifier loss: 0.095359; batch adversarial loss: 0.393768\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119658; batch adversarial loss: 0.521308\n",
      "epoch 48; iter: 0; batch classifier loss: 0.087688; batch adversarial loss: 0.389236\n",
      "epoch 49; iter: 0; batch classifier loss: 0.082101; batch adversarial loss: 0.431705\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091112; batch adversarial loss: 0.528296\n",
      "epoch 51; iter: 0; batch classifier loss: 0.077919; batch adversarial loss: 0.462806\n",
      "epoch 52; iter: 0; batch classifier loss: 0.093199; batch adversarial loss: 0.362389\n",
      "epoch 53; iter: 0; batch classifier loss: 0.052936; batch adversarial loss: 0.457518\n",
      "epoch 54; iter: 0; batch classifier loss: 0.083688; batch adversarial loss: 0.512343\n",
      "epoch 55; iter: 0; batch classifier loss: 0.051560; batch adversarial loss: 0.605387\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084121; batch adversarial loss: 0.519686\n",
      "epoch 57; iter: 0; batch classifier loss: 0.062797; batch adversarial loss: 0.466178\n",
      "epoch 58; iter: 0; batch classifier loss: 0.087328; batch adversarial loss: 0.462389\n",
      "epoch 59; iter: 0; batch classifier loss: 0.078612; batch adversarial loss: 0.368481\n",
      "epoch 60; iter: 0; batch classifier loss: 0.090666; batch adversarial loss: 0.422558\n",
      "epoch 61; iter: 0; batch classifier loss: 0.134033; batch adversarial loss: 0.504591\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093033; batch adversarial loss: 0.426680\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092872; batch adversarial loss: 0.453249\n",
      "epoch 64; iter: 0; batch classifier loss: 0.111241; batch adversarial loss: 0.466856\n",
      "epoch 65; iter: 0; batch classifier loss: 0.080307; batch adversarial loss: 0.419679\n",
      "epoch 66; iter: 0; batch classifier loss: 0.125108; batch adversarial loss: 0.483258\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100368; batch adversarial loss: 0.450566\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076847; batch adversarial loss: 0.540765\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103034; batch adversarial loss: 0.426823\n",
      "epoch 70; iter: 0; batch classifier loss: 0.075819; batch adversarial loss: 0.549149\n",
      "epoch 71; iter: 0; batch classifier loss: 0.080637; batch adversarial loss: 0.531549\n",
      "epoch 72; iter: 0; batch classifier loss: 0.109387; batch adversarial loss: 0.444588\n",
      "epoch 73; iter: 0; batch classifier loss: 0.059999; batch adversarial loss: 0.425121\n",
      "epoch 74; iter: 0; batch classifier loss: 0.049277; batch adversarial loss: 0.485789\n",
      "epoch 75; iter: 0; batch classifier loss: 0.086048; batch adversarial loss: 0.470372\n",
      "epoch 76; iter: 0; batch classifier loss: 0.099959; batch adversarial loss: 0.412762\n",
      "epoch 77; iter: 0; batch classifier loss: 0.159979; batch adversarial loss: 0.341951\n",
      "epoch 78; iter: 0; batch classifier loss: 0.112789; batch adversarial loss: 0.590244\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068830; batch adversarial loss: 0.574692\n",
      "epoch 80; iter: 0; batch classifier loss: 0.064581; batch adversarial loss: 0.425005\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074379; batch adversarial loss: 0.480947\n",
      "epoch 82; iter: 0; batch classifier loss: 0.125146; batch adversarial loss: 0.470905\n",
      "epoch 83; iter: 0; batch classifier loss: 0.099623; batch adversarial loss: 0.493940\n",
      "epoch 84; iter: 0; batch classifier loss: 0.086374; batch adversarial loss: 0.464202\n",
      "epoch 85; iter: 0; batch classifier loss: 0.137101; batch adversarial loss: 0.450239\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076046; batch adversarial loss: 0.445300\n",
      "epoch 87; iter: 0; batch classifier loss: 0.123604; batch adversarial loss: 0.435988\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064402; batch adversarial loss: 0.487495\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068547; batch adversarial loss: 0.436131\n",
      "epoch 90; iter: 0; batch classifier loss: 0.079273; batch adversarial loss: 0.481767\n",
      "epoch 91; iter: 0; batch classifier loss: 0.092022; batch adversarial loss: 0.452230\n",
      "epoch 92; iter: 0; batch classifier loss: 0.067555; batch adversarial loss: 0.472409\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063099; batch adversarial loss: 0.508082\n",
      "epoch 94; iter: 0; batch classifier loss: 0.065337; batch adversarial loss: 0.393814\n",
      "epoch 95; iter: 0; batch classifier loss: 0.086674; batch adversarial loss: 0.482944\n",
      "epoch 96; iter: 0; batch classifier loss: 0.117995; batch adversarial loss: 0.398367\n",
      "epoch 97; iter: 0; batch classifier loss: 0.087878; batch adversarial loss: 0.439925\n",
      "epoch 98; iter: 0; batch classifier loss: 0.060838; batch adversarial loss: 0.488269\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065519; batch adversarial loss: 0.479816\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050518; batch adversarial loss: 0.454127\n",
      "epoch 101; iter: 0; batch classifier loss: 0.069927; batch adversarial loss: 0.416627\n",
      "epoch 102; iter: 0; batch classifier loss: 0.089632; batch adversarial loss: 0.514230\n",
      "epoch 103; iter: 0; batch classifier loss: 0.074228; batch adversarial loss: 0.484403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.042563; batch adversarial loss: 0.350940\n",
      "epoch 105; iter: 0; batch classifier loss: 0.036391; batch adversarial loss: 0.516911\n",
      "epoch 106; iter: 0; batch classifier loss: 0.074362; batch adversarial loss: 0.408143\n",
      "epoch 107; iter: 0; batch classifier loss: 0.098841; batch adversarial loss: 0.536752\n",
      "epoch 108; iter: 0; batch classifier loss: 0.083900; batch adversarial loss: 0.472089\n",
      "epoch 109; iter: 0; batch classifier loss: 0.123577; batch adversarial loss: 0.484806\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069826; batch adversarial loss: 0.417554\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069586; batch adversarial loss: 0.463151\n",
      "epoch 112; iter: 0; batch classifier loss: 0.048207; batch adversarial loss: 0.500676\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035778; batch adversarial loss: 0.404859\n",
      "epoch 114; iter: 0; batch classifier loss: 0.063786; batch adversarial loss: 0.503262\n",
      "epoch 115; iter: 0; batch classifier loss: 0.074804; batch adversarial loss: 0.467343\n",
      "epoch 116; iter: 0; batch classifier loss: 0.064235; batch adversarial loss: 0.370003\n",
      "epoch 117; iter: 0; batch classifier loss: 0.063665; batch adversarial loss: 0.499332\n",
      "epoch 118; iter: 0; batch classifier loss: 0.070033; batch adversarial loss: 0.321101\n",
      "epoch 119; iter: 0; batch classifier loss: 0.071135; batch adversarial loss: 0.486572\n",
      "epoch 120; iter: 0; batch classifier loss: 0.064487; batch adversarial loss: 0.438707\n",
      "epoch 121; iter: 0; batch classifier loss: 0.108093; batch adversarial loss: 0.422404\n",
      "epoch 122; iter: 0; batch classifier loss: 0.076501; batch adversarial loss: 0.515996\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047990; batch adversarial loss: 0.473731\n",
      "epoch 124; iter: 0; batch classifier loss: 0.058973; batch adversarial loss: 0.441612\n",
      "epoch 125; iter: 0; batch classifier loss: 0.021615; batch adversarial loss: 0.455738\n",
      "epoch 126; iter: 0; batch classifier loss: 0.091376; batch adversarial loss: 0.456659\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022896; batch adversarial loss: 0.378354\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036541; batch adversarial loss: 0.491273\n",
      "epoch 129; iter: 0; batch classifier loss: 0.058925; batch adversarial loss: 0.542288\n",
      "epoch 130; iter: 0; batch classifier loss: 0.074941; batch adversarial loss: 0.431389\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028481; batch adversarial loss: 0.493865\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032977; batch adversarial loss: 0.468582\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014135; batch adversarial loss: 0.478342\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045844; batch adversarial loss: 0.434103\n",
      "epoch 135; iter: 0; batch classifier loss: 0.054792; batch adversarial loss: 0.397741\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041499; batch adversarial loss: 0.433494\n",
      "epoch 137; iter: 0; batch classifier loss: 0.068410; batch adversarial loss: 0.408752\n",
      "epoch 138; iter: 0; batch classifier loss: 0.065866; batch adversarial loss: 0.416694\n",
      "epoch 139; iter: 0; batch classifier loss: 0.063775; batch adversarial loss: 0.408514\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053450; batch adversarial loss: 0.456444\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021419; batch adversarial loss: 0.493950\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044859; batch adversarial loss: 0.422437\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046162; batch adversarial loss: 0.479388\n",
      "epoch 144; iter: 0; batch classifier loss: 0.061196; batch adversarial loss: 0.466129\n",
      "epoch 145; iter: 0; batch classifier loss: 0.086039; batch adversarial loss: 0.490472\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027077; batch adversarial loss: 0.467729\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020111; batch adversarial loss: 0.457197\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054760; batch adversarial loss: 0.465950\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034520; batch adversarial loss: 0.485347\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026635; batch adversarial loss: 0.458354\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023020; batch adversarial loss: 0.426632\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025533; batch adversarial loss: 0.548112\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039132; batch adversarial loss: 0.459766\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031394; batch adversarial loss: 0.457283\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035238; batch adversarial loss: 0.383838\n",
      "epoch 156; iter: 0; batch classifier loss: 0.049827; batch adversarial loss: 0.376588\n",
      "epoch 157; iter: 0; batch classifier loss: 0.049940; batch adversarial loss: 0.544975\n",
      "epoch 158; iter: 0; batch classifier loss: 0.047085; batch adversarial loss: 0.453355\n",
      "epoch 159; iter: 0; batch classifier loss: 0.057551; batch adversarial loss: 0.421354\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026789; batch adversarial loss: 0.431798\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016665; batch adversarial loss: 0.472566\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039398; batch adversarial loss: 0.410996\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025238; batch adversarial loss: 0.449033\n",
      "epoch 164; iter: 0; batch classifier loss: 0.051861; batch adversarial loss: 0.485187\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014418; batch adversarial loss: 0.396304\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012556; batch adversarial loss: 0.472703\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022681; batch adversarial loss: 0.337584\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009174; batch adversarial loss: 0.390491\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031949; batch adversarial loss: 0.340579\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025453; batch adversarial loss: 0.453351\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024629; batch adversarial loss: 0.438138\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028146; batch adversarial loss: 0.403979\n",
      "epoch 173; iter: 0; batch classifier loss: 0.054907; batch adversarial loss: 0.432454\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020083; batch adversarial loss: 0.529431\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017720; batch adversarial loss: 0.419941\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008932; batch adversarial loss: 0.476651\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031134; batch adversarial loss: 0.477343\n",
      "epoch 178; iter: 0; batch classifier loss: 0.057889; batch adversarial loss: 0.457493\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023805; batch adversarial loss: 0.405391\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015324; batch adversarial loss: 0.412811\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009453; batch adversarial loss: 0.461615\n",
      "epoch 182; iter: 0; batch classifier loss: 0.044958; batch adversarial loss: 0.422303\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008824; batch adversarial loss: 0.460028\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019216; batch adversarial loss: 0.476880\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022156; batch adversarial loss: 0.416557\n",
      "epoch 186; iter: 0; batch classifier loss: 0.038377; batch adversarial loss: 0.359336\n",
      "epoch 187; iter: 0; batch classifier loss: 0.066528; batch adversarial loss: 0.452017\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017829; batch adversarial loss: 0.402828\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010798; batch adversarial loss: 0.430146\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028805; batch adversarial loss: 0.377936\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020701; batch adversarial loss: 0.495505\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021648; batch adversarial loss: 0.438622\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031312; batch adversarial loss: 0.476623\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020781; batch adversarial loss: 0.475908\n",
      "epoch 195; iter: 0; batch classifier loss: 0.033399; batch adversarial loss: 0.452531\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028491; batch adversarial loss: 0.413272\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011065; batch adversarial loss: 0.461235\n",
      "epoch 198; iter: 0; batch classifier loss: 0.051956; batch adversarial loss: 0.489404\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007442; batch adversarial loss: 0.469622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.691107; batch adversarial loss: 0.740070\n",
      "epoch 1; iter: 0; batch classifier loss: 0.436855; batch adversarial loss: 0.708798\n",
      "epoch 2; iter: 0; batch classifier loss: 0.368514; batch adversarial loss: 0.724955\n",
      "epoch 3; iter: 0; batch classifier loss: 0.367359; batch adversarial loss: 0.672747\n",
      "epoch 4; iter: 0; batch classifier loss: 0.334392; batch adversarial loss: 0.620077\n",
      "epoch 5; iter: 0; batch classifier loss: 0.355202; batch adversarial loss: 0.568255\n",
      "epoch 6; iter: 0; batch classifier loss: 0.296725; batch adversarial loss: 0.581116\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338154; batch adversarial loss: 0.536482\n",
      "epoch 8; iter: 0; batch classifier loss: 0.277274; batch adversarial loss: 0.555887\n",
      "epoch 9; iter: 0; batch classifier loss: 0.192359; batch adversarial loss: 0.493499\n",
      "epoch 10; iter: 0; batch classifier loss: 0.249026; batch adversarial loss: 0.480010\n",
      "epoch 11; iter: 0; batch classifier loss: 0.275671; batch adversarial loss: 0.482332\n",
      "epoch 12; iter: 0; batch classifier loss: 0.186705; batch adversarial loss: 0.461300\n",
      "epoch 13; iter: 0; batch classifier loss: 0.223167; batch adversarial loss: 0.442197\n",
      "epoch 14; iter: 0; batch classifier loss: 0.164521; batch adversarial loss: 0.462242\n",
      "epoch 15; iter: 0; batch classifier loss: 0.185191; batch adversarial loss: 0.400974\n",
      "epoch 16; iter: 0; batch classifier loss: 0.189230; batch adversarial loss: 0.413011\n",
      "epoch 17; iter: 0; batch classifier loss: 0.171668; batch adversarial loss: 0.566992\n",
      "epoch 18; iter: 0; batch classifier loss: 0.195593; batch adversarial loss: 0.484476\n",
      "epoch 19; iter: 0; batch classifier loss: 0.153558; batch adversarial loss: 0.453387\n",
      "epoch 20; iter: 0; batch classifier loss: 0.132645; batch adversarial loss: 0.480751\n",
      "epoch 21; iter: 0; batch classifier loss: 0.151100; batch adversarial loss: 0.483709\n",
      "epoch 22; iter: 0; batch classifier loss: 0.152766; batch adversarial loss: 0.518390\n",
      "epoch 23; iter: 0; batch classifier loss: 0.121242; batch adversarial loss: 0.514637\n",
      "epoch 24; iter: 0; batch classifier loss: 0.089337; batch adversarial loss: 0.548257\n",
      "epoch 25; iter: 0; batch classifier loss: 0.098786; batch adversarial loss: 0.420020\n",
      "epoch 26; iter: 0; batch classifier loss: 0.074665; batch adversarial loss: 0.386900\n",
      "epoch 27; iter: 0; batch classifier loss: 0.114005; batch adversarial loss: 0.504563\n",
      "epoch 28; iter: 0; batch classifier loss: 0.146346; batch adversarial loss: 0.446720\n",
      "epoch 29; iter: 0; batch classifier loss: 0.237563; batch adversarial loss: 0.546428\n",
      "epoch 30; iter: 0; batch classifier loss: 0.152455; batch adversarial loss: 0.453714\n",
      "epoch 31; iter: 0; batch classifier loss: 0.164508; batch adversarial loss: 0.477038\n",
      "epoch 32; iter: 0; batch classifier loss: 0.183744; batch adversarial loss: 0.540687\n",
      "epoch 33; iter: 0; batch classifier loss: 0.235293; batch adversarial loss: 0.497989\n",
      "epoch 34; iter: 0; batch classifier loss: 0.169876; batch adversarial loss: 0.557810\n",
      "epoch 35; iter: 0; batch classifier loss: 0.139569; batch adversarial loss: 0.535788\n",
      "epoch 36; iter: 0; batch classifier loss: 0.122138; batch adversarial loss: 0.436344\n",
      "epoch 37; iter: 0; batch classifier loss: 0.225995; batch adversarial loss: 0.558199\n",
      "epoch 38; iter: 0; batch classifier loss: 0.198482; batch adversarial loss: 0.562923\n",
      "epoch 39; iter: 0; batch classifier loss: 0.177603; batch adversarial loss: 0.468816\n",
      "epoch 40; iter: 0; batch classifier loss: 0.165016; batch adversarial loss: 0.427956\n",
      "epoch 41; iter: 0; batch classifier loss: 0.242538; batch adversarial loss: 0.525408\n",
      "epoch 42; iter: 0; batch classifier loss: 0.129147; batch adversarial loss: 0.494081\n",
      "epoch 43; iter: 0; batch classifier loss: 0.095445; batch adversarial loss: 0.464319\n",
      "epoch 44; iter: 0; batch classifier loss: 0.082159; batch adversarial loss: 0.521687\n",
      "epoch 45; iter: 0; batch classifier loss: 0.068406; batch adversarial loss: 0.451585\n",
      "epoch 46; iter: 0; batch classifier loss: 0.067009; batch adversarial loss: 0.461386\n",
      "epoch 47; iter: 0; batch classifier loss: 0.039980; batch adversarial loss: 0.381638\n",
      "epoch 48; iter: 0; batch classifier loss: 0.129367; batch adversarial loss: 0.418543\n",
      "epoch 49; iter: 0; batch classifier loss: 0.104925; batch adversarial loss: 0.424839\n",
      "epoch 50; iter: 0; batch classifier loss: 0.107660; batch adversarial loss: 0.440904\n",
      "epoch 51; iter: 0; batch classifier loss: 0.055978; batch adversarial loss: 0.380078\n",
      "epoch 52; iter: 0; batch classifier loss: 0.051860; batch adversarial loss: 0.538382\n",
      "epoch 53; iter: 0; batch classifier loss: 0.060186; batch adversarial loss: 0.447350\n",
      "epoch 54; iter: 0; batch classifier loss: 0.048361; batch adversarial loss: 0.402386\n",
      "epoch 55; iter: 0; batch classifier loss: 0.074046; batch adversarial loss: 0.414199\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082230; batch adversarial loss: 0.469307\n",
      "epoch 57; iter: 0; batch classifier loss: 0.059613; batch adversarial loss: 0.466486\n",
      "epoch 58; iter: 0; batch classifier loss: 0.067121; batch adversarial loss: 0.407533\n",
      "epoch 59; iter: 0; batch classifier loss: 0.068172; batch adversarial loss: 0.421622\n",
      "epoch 60; iter: 0; batch classifier loss: 0.061206; batch adversarial loss: 0.329093\n",
      "epoch 61; iter: 0; batch classifier loss: 0.058958; batch adversarial loss: 0.538064\n",
      "epoch 62; iter: 0; batch classifier loss: 0.061652; batch adversarial loss: 0.503115\n",
      "epoch 63; iter: 0; batch classifier loss: 0.064698; batch adversarial loss: 0.419904\n",
      "epoch 64; iter: 0; batch classifier loss: 0.065056; batch adversarial loss: 0.404952\n",
      "epoch 65; iter: 0; batch classifier loss: 0.063942; batch adversarial loss: 0.477158\n",
      "epoch 66; iter: 0; batch classifier loss: 0.063977; batch adversarial loss: 0.400094\n",
      "epoch 67; iter: 0; batch classifier loss: 0.037980; batch adversarial loss: 0.527121\n",
      "epoch 68; iter: 0; batch classifier loss: 0.043983; batch adversarial loss: 0.425683\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061988; batch adversarial loss: 0.397380\n",
      "epoch 70; iter: 0; batch classifier loss: 0.076050; batch adversarial loss: 0.501959\n",
      "epoch 71; iter: 0; batch classifier loss: 0.076666; batch adversarial loss: 0.473648\n",
      "epoch 72; iter: 0; batch classifier loss: 0.103148; batch adversarial loss: 0.489229\n",
      "epoch 73; iter: 0; batch classifier loss: 0.042897; batch adversarial loss: 0.429009\n",
      "epoch 74; iter: 0; batch classifier loss: 0.058017; batch adversarial loss: 0.404977\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067194; batch adversarial loss: 0.381426\n",
      "epoch 76; iter: 0; batch classifier loss: 0.050611; batch adversarial loss: 0.432824\n",
      "epoch 77; iter: 0; batch classifier loss: 0.128102; batch adversarial loss: 0.461910\n",
      "epoch 78; iter: 0; batch classifier loss: 0.039874; batch adversarial loss: 0.499717\n",
      "epoch 79; iter: 0; batch classifier loss: 0.035253; batch adversarial loss: 0.443685\n",
      "epoch 80; iter: 0; batch classifier loss: 0.043818; batch adversarial loss: 0.430269\n",
      "epoch 81; iter: 0; batch classifier loss: 0.061021; batch adversarial loss: 0.451792\n",
      "epoch 82; iter: 0; batch classifier loss: 0.045759; batch adversarial loss: 0.411473\n",
      "epoch 83; iter: 0; batch classifier loss: 0.038968; batch adversarial loss: 0.498478\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085367; batch adversarial loss: 0.606431\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051166; batch adversarial loss: 0.440111\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053606; batch adversarial loss: 0.512354\n",
      "epoch 87; iter: 0; batch classifier loss: 0.088219; batch adversarial loss: 0.471657\n",
      "epoch 88; iter: 0; batch classifier loss: 0.047907; batch adversarial loss: 0.511121\n",
      "epoch 89; iter: 0; batch classifier loss: 0.037855; batch adversarial loss: 0.439178\n",
      "epoch 90; iter: 0; batch classifier loss: 0.043523; batch adversarial loss: 0.461422\n",
      "epoch 91; iter: 0; batch classifier loss: 0.047624; batch adversarial loss: 0.576134\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069961; batch adversarial loss: 0.381910\n",
      "epoch 93; iter: 0; batch classifier loss: 0.101214; batch adversarial loss: 0.518740\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062619; batch adversarial loss: 0.414071\n",
      "epoch 95; iter: 0; batch classifier loss: 0.094327; batch adversarial loss: 0.447006\n",
      "epoch 96; iter: 0; batch classifier loss: 0.080959; batch adversarial loss: 0.464195\n",
      "epoch 97; iter: 0; batch classifier loss: 0.095204; batch adversarial loss: 0.532344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.036505; batch adversarial loss: 0.460652\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038721; batch adversarial loss: 0.410664\n",
      "epoch 100; iter: 0; batch classifier loss: 0.122907; batch adversarial loss: 0.529605\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061425; batch adversarial loss: 0.425126\n",
      "epoch 102; iter: 0; batch classifier loss: 0.073396; batch adversarial loss: 0.377311\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061964; batch adversarial loss: 0.492373\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038267; batch adversarial loss: 0.456155\n",
      "epoch 105; iter: 0; batch classifier loss: 0.031620; batch adversarial loss: 0.445678\n",
      "epoch 106; iter: 0; batch classifier loss: 0.021998; batch adversarial loss: 0.501796\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053290; batch adversarial loss: 0.491080\n",
      "epoch 108; iter: 0; batch classifier loss: 0.072999; batch adversarial loss: 0.424520\n",
      "epoch 109; iter: 0; batch classifier loss: 0.028471; batch adversarial loss: 0.409145\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043922; batch adversarial loss: 0.469455\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040212; batch adversarial loss: 0.529023\n",
      "epoch 112; iter: 0; batch classifier loss: 0.064339; batch adversarial loss: 0.481926\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043457; batch adversarial loss: 0.483397\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035122; batch adversarial loss: 0.423409\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063959; batch adversarial loss: 0.427079\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030341; batch adversarial loss: 0.575904\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037879; batch adversarial loss: 0.495462\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051649; batch adversarial loss: 0.435255\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040751; batch adversarial loss: 0.501822\n",
      "epoch 120; iter: 0; batch classifier loss: 0.059753; batch adversarial loss: 0.487192\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045573; batch adversarial loss: 0.417201\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026598; batch adversarial loss: 0.467622\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024285; batch adversarial loss: 0.478882\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044517; batch adversarial loss: 0.450665\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042340; batch adversarial loss: 0.550427\n",
      "epoch 126; iter: 0; batch classifier loss: 0.054804; batch adversarial loss: 0.475200\n",
      "epoch 127; iter: 0; batch classifier loss: 0.064113; batch adversarial loss: 0.460978\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030112; batch adversarial loss: 0.433001\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037197; batch adversarial loss: 0.449586\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023270; batch adversarial loss: 0.549882\n",
      "epoch 131; iter: 0; batch classifier loss: 0.066683; batch adversarial loss: 0.446516\n",
      "epoch 132; iter: 0; batch classifier loss: 0.018875; batch adversarial loss: 0.409785\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026650; batch adversarial loss: 0.490001\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030961; batch adversarial loss: 0.523847\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022715; batch adversarial loss: 0.469474\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022800; batch adversarial loss: 0.493241\n",
      "epoch 137; iter: 0; batch classifier loss: 0.081802; batch adversarial loss: 0.476331\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049482; batch adversarial loss: 0.455869\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030517; batch adversarial loss: 0.478482\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019018; batch adversarial loss: 0.507975\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049888; batch adversarial loss: 0.426452\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023346; batch adversarial loss: 0.479159\n",
      "epoch 143; iter: 0; batch classifier loss: 0.053575; batch adversarial loss: 0.416924\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018663; batch adversarial loss: 0.453874\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031483; batch adversarial loss: 0.470749\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039836; batch adversarial loss: 0.464740\n",
      "epoch 147; iter: 0; batch classifier loss: 0.055541; batch adversarial loss: 0.364167\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033669; batch adversarial loss: 0.449916\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044029; batch adversarial loss: 0.481334\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032520; batch adversarial loss: 0.422591\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018857; batch adversarial loss: 0.427857\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015365; batch adversarial loss: 0.426404\n",
      "epoch 153; iter: 0; batch classifier loss: 0.073579; batch adversarial loss: 0.464474\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028656; batch adversarial loss: 0.397332\n",
      "epoch 155; iter: 0; batch classifier loss: 0.045359; batch adversarial loss: 0.430651\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024909; batch adversarial loss: 0.395338\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017364; batch adversarial loss: 0.502406\n",
      "epoch 158; iter: 0; batch classifier loss: 0.041741; batch adversarial loss: 0.466164\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012817; batch adversarial loss: 0.375141\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029069; batch adversarial loss: 0.434827\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017040; batch adversarial loss: 0.558098\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034213; batch adversarial loss: 0.427725\n",
      "epoch 163; iter: 0; batch classifier loss: 0.044539; batch adversarial loss: 0.458215\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018002; batch adversarial loss: 0.446496\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032621; batch adversarial loss: 0.439791\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022421; batch adversarial loss: 0.434753\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029546; batch adversarial loss: 0.483162\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037133; batch adversarial loss: 0.467482\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038023; batch adversarial loss: 0.485577\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020630; batch adversarial loss: 0.501542\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012550; batch adversarial loss: 0.454302\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019796; batch adversarial loss: 0.512033\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023632; batch adversarial loss: 0.384853\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018140; batch adversarial loss: 0.362922\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030124; batch adversarial loss: 0.496957\n",
      "epoch 176; iter: 0; batch classifier loss: 0.067669; batch adversarial loss: 0.415706\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030349; batch adversarial loss: 0.517761\n",
      "epoch 178; iter: 0; batch classifier loss: 0.004535; batch adversarial loss: 0.468152\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014130; batch adversarial loss: 0.465337\n",
      "epoch 180; iter: 0; batch classifier loss: 0.004931; batch adversarial loss: 0.445085\n",
      "epoch 181; iter: 0; batch classifier loss: 0.003277; batch adversarial loss: 0.454749\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010745; batch adversarial loss: 0.410570\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013622; batch adversarial loss: 0.446265\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015364; batch adversarial loss: 0.430973\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015097; batch adversarial loss: 0.472432\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035491; batch adversarial loss: 0.375329\n",
      "epoch 187; iter: 0; batch classifier loss: 0.070610; batch adversarial loss: 0.458108\n",
      "epoch 188; iter: 0; batch classifier loss: 0.057928; batch adversarial loss: 0.382336\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025886; batch adversarial loss: 0.387454\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004803; batch adversarial loss: 0.458167\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023328; batch adversarial loss: 0.497738\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004752; batch adversarial loss: 0.425773\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022942; batch adversarial loss: 0.481075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.037911; batch adversarial loss: 0.423701\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012885; batch adversarial loss: 0.447262\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010260; batch adversarial loss: 0.431869\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007287; batch adversarial loss: 0.435144\n",
      "epoch 198; iter: 0; batch classifier loss: 0.047680; batch adversarial loss: 0.447151\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004123; batch adversarial loss: 0.479801\n",
      "epoch 0; iter: 0; batch classifier loss: 0.739510; batch adversarial loss: 0.901013\n",
      "epoch 1; iter: 0; batch classifier loss: 0.510748; batch adversarial loss: 0.965392\n",
      "epoch 2; iter: 0; batch classifier loss: 0.490354; batch adversarial loss: 0.900321\n",
      "epoch 3; iter: 0; batch classifier loss: 0.625641; batch adversarial loss: 0.825983\n",
      "epoch 4; iter: 0; batch classifier loss: 0.531534; batch adversarial loss: 0.758773\n",
      "epoch 5; iter: 0; batch classifier loss: 0.404266; batch adversarial loss: 0.696371\n",
      "epoch 6; iter: 0; batch classifier loss: 0.333831; batch adversarial loss: 0.639372\n",
      "epoch 7; iter: 0; batch classifier loss: 0.303035; batch adversarial loss: 0.619160\n",
      "epoch 8; iter: 0; batch classifier loss: 0.333709; batch adversarial loss: 0.566169\n",
      "epoch 9; iter: 0; batch classifier loss: 0.324879; batch adversarial loss: 0.577663\n",
      "epoch 10; iter: 0; batch classifier loss: 0.221648; batch adversarial loss: 0.588508\n",
      "epoch 11; iter: 0; batch classifier loss: 0.231054; batch adversarial loss: 0.538763\n",
      "epoch 12; iter: 0; batch classifier loss: 0.190137; batch adversarial loss: 0.527036\n",
      "epoch 13; iter: 0; batch classifier loss: 0.286332; batch adversarial loss: 0.514670\n",
      "epoch 14; iter: 0; batch classifier loss: 0.247526; batch adversarial loss: 0.508258\n",
      "epoch 15; iter: 0; batch classifier loss: 0.300990; batch adversarial loss: 0.423385\n",
      "epoch 16; iter: 0; batch classifier loss: 0.286971; batch adversarial loss: 0.462540\n",
      "epoch 17; iter: 0; batch classifier loss: 0.222988; batch adversarial loss: 0.471843\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243465; batch adversarial loss: 0.458324\n",
      "epoch 19; iter: 0; batch classifier loss: 0.196242; batch adversarial loss: 0.498548\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220079; batch adversarial loss: 0.477303\n",
      "epoch 21; iter: 0; batch classifier loss: 0.179977; batch adversarial loss: 0.486882\n",
      "epoch 22; iter: 0; batch classifier loss: 0.223456; batch adversarial loss: 0.391142\n",
      "epoch 23; iter: 0; batch classifier loss: 0.200308; batch adversarial loss: 0.518115\n",
      "epoch 24; iter: 0; batch classifier loss: 0.147648; batch adversarial loss: 0.448646\n",
      "epoch 25; iter: 0; batch classifier loss: 0.131620; batch adversarial loss: 0.496341\n",
      "epoch 26; iter: 0; batch classifier loss: 0.164497; batch adversarial loss: 0.412132\n",
      "epoch 27; iter: 0; batch classifier loss: 0.169144; batch adversarial loss: 0.505842\n",
      "epoch 28; iter: 0; batch classifier loss: 0.119452; batch adversarial loss: 0.493320\n",
      "epoch 29; iter: 0; batch classifier loss: 0.138460; batch adversarial loss: 0.414523\n",
      "epoch 30; iter: 0; batch classifier loss: 0.163422; batch adversarial loss: 0.410013\n",
      "epoch 31; iter: 0; batch classifier loss: 0.108816; batch adversarial loss: 0.453895\n",
      "epoch 32; iter: 0; batch classifier loss: 0.095863; batch adversarial loss: 0.430223\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143978; batch adversarial loss: 0.389107\n",
      "epoch 34; iter: 0; batch classifier loss: 0.188027; batch adversarial loss: 0.428756\n",
      "epoch 35; iter: 0; batch classifier loss: 0.092708; batch adversarial loss: 0.469162\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128655; batch adversarial loss: 0.454971\n",
      "epoch 37; iter: 0; batch classifier loss: 0.150864; batch adversarial loss: 0.376169\n",
      "epoch 38; iter: 0; batch classifier loss: 0.113059; batch adversarial loss: 0.448069\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125510; batch adversarial loss: 0.383655\n",
      "epoch 40; iter: 0; batch classifier loss: 0.107170; batch adversarial loss: 0.398757\n",
      "epoch 41; iter: 0; batch classifier loss: 0.128503; batch adversarial loss: 0.519643\n",
      "epoch 42; iter: 0; batch classifier loss: 0.108940; batch adversarial loss: 0.392164\n",
      "epoch 43; iter: 0; batch classifier loss: 0.063556; batch adversarial loss: 0.398251\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085581; batch adversarial loss: 0.462841\n",
      "epoch 45; iter: 0; batch classifier loss: 0.092302; batch adversarial loss: 0.499667\n",
      "epoch 46; iter: 0; batch classifier loss: 0.068242; batch adversarial loss: 0.531599\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095897; batch adversarial loss: 0.481520\n",
      "epoch 48; iter: 0; batch classifier loss: 0.073377; batch adversarial loss: 0.404017\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113988; batch adversarial loss: 0.423541\n",
      "epoch 50; iter: 0; batch classifier loss: 0.092182; batch adversarial loss: 0.411968\n",
      "epoch 51; iter: 0; batch classifier loss: 0.052563; batch adversarial loss: 0.451277\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082306; batch adversarial loss: 0.386447\n",
      "epoch 53; iter: 0; batch classifier loss: 0.105497; batch adversarial loss: 0.462961\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095461; batch adversarial loss: 0.410603\n",
      "epoch 55; iter: 0; batch classifier loss: 0.080473; batch adversarial loss: 0.398355\n",
      "epoch 56; iter: 0; batch classifier loss: 0.068420; batch adversarial loss: 0.456623\n",
      "epoch 57; iter: 0; batch classifier loss: 0.083629; batch adversarial loss: 0.525754\n",
      "epoch 58; iter: 0; batch classifier loss: 0.085495; batch adversarial loss: 0.435932\n",
      "epoch 59; iter: 0; batch classifier loss: 0.074203; batch adversarial loss: 0.443941\n",
      "epoch 60; iter: 0; batch classifier loss: 0.083157; batch adversarial loss: 0.469090\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087291; batch adversarial loss: 0.495076\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081428; batch adversarial loss: 0.488528\n",
      "epoch 63; iter: 0; batch classifier loss: 0.049696; batch adversarial loss: 0.382950\n",
      "epoch 64; iter: 0; batch classifier loss: 0.096207; batch adversarial loss: 0.422253\n",
      "epoch 65; iter: 0; batch classifier loss: 0.062383; batch adversarial loss: 0.443212\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062852; batch adversarial loss: 0.509820\n",
      "epoch 67; iter: 0; batch classifier loss: 0.077270; batch adversarial loss: 0.497611\n",
      "epoch 68; iter: 0; batch classifier loss: 0.079565; batch adversarial loss: 0.464845\n",
      "epoch 69; iter: 0; batch classifier loss: 0.100719; batch adversarial loss: 0.448499\n",
      "epoch 70; iter: 0; batch classifier loss: 0.102743; batch adversarial loss: 0.522792\n",
      "epoch 71; iter: 0; batch classifier loss: 0.054265; batch adversarial loss: 0.335694\n",
      "epoch 72; iter: 0; batch classifier loss: 0.040989; batch adversarial loss: 0.516917\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069866; batch adversarial loss: 0.446862\n",
      "epoch 74; iter: 0; batch classifier loss: 0.078254; batch adversarial loss: 0.427946\n",
      "epoch 75; iter: 0; batch classifier loss: 0.065477; batch adversarial loss: 0.475945\n",
      "epoch 76; iter: 0; batch classifier loss: 0.057359; batch adversarial loss: 0.459854\n",
      "epoch 77; iter: 0; batch classifier loss: 0.100743; batch adversarial loss: 0.449039\n",
      "epoch 78; iter: 0; batch classifier loss: 0.042701; batch adversarial loss: 0.433601\n",
      "epoch 79; iter: 0; batch classifier loss: 0.048088; batch adversarial loss: 0.372703\n",
      "epoch 80; iter: 0; batch classifier loss: 0.057514; batch adversarial loss: 0.447257\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067256; batch adversarial loss: 0.434310\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062658; batch adversarial loss: 0.360687\n",
      "epoch 83; iter: 0; batch classifier loss: 0.041640; batch adversarial loss: 0.548977\n",
      "epoch 84; iter: 0; batch classifier loss: 0.073910; batch adversarial loss: 0.417146\n",
      "epoch 85; iter: 0; batch classifier loss: 0.085836; batch adversarial loss: 0.427677\n",
      "epoch 86; iter: 0; batch classifier loss: 0.041039; batch adversarial loss: 0.356506\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082993; batch adversarial loss: 0.445940\n",
      "epoch 88; iter: 0; batch classifier loss: 0.044776; batch adversarial loss: 0.418178\n",
      "epoch 89; iter: 0; batch classifier loss: 0.082480; batch adversarial loss: 0.469890\n",
      "epoch 90; iter: 0; batch classifier loss: 0.088131; batch adversarial loss: 0.443453\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052942; batch adversarial loss: 0.379383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.044460; batch adversarial loss: 0.375566\n",
      "epoch 93; iter: 0; batch classifier loss: 0.030184; batch adversarial loss: 0.455297\n",
      "epoch 94; iter: 0; batch classifier loss: 0.103260; batch adversarial loss: 0.436506\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038308; batch adversarial loss: 0.472324\n",
      "epoch 96; iter: 0; batch classifier loss: 0.039413; batch adversarial loss: 0.379367\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073352; batch adversarial loss: 0.433410\n",
      "epoch 98; iter: 0; batch classifier loss: 0.105895; batch adversarial loss: 0.407458\n",
      "epoch 99; iter: 0; batch classifier loss: 0.031124; batch adversarial loss: 0.350586\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059875; batch adversarial loss: 0.397695\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040596; batch adversarial loss: 0.401159\n",
      "epoch 102; iter: 0; batch classifier loss: 0.045133; batch adversarial loss: 0.467100\n",
      "epoch 103; iter: 0; batch classifier loss: 0.068966; batch adversarial loss: 0.510809\n",
      "epoch 104; iter: 0; batch classifier loss: 0.067585; batch adversarial loss: 0.547990\n",
      "epoch 105; iter: 0; batch classifier loss: 0.074039; batch adversarial loss: 0.428451\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054812; batch adversarial loss: 0.426807\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061932; batch adversarial loss: 0.418704\n",
      "epoch 108; iter: 0; batch classifier loss: 0.083119; batch adversarial loss: 0.495920\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050582; batch adversarial loss: 0.443399\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059471; batch adversarial loss: 0.457300\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059302; batch adversarial loss: 0.403379\n",
      "epoch 112; iter: 0; batch classifier loss: 0.100476; batch adversarial loss: 0.513690\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041786; batch adversarial loss: 0.390359\n",
      "epoch 114; iter: 0; batch classifier loss: 0.064643; batch adversarial loss: 0.364258\n",
      "epoch 115; iter: 0; batch classifier loss: 0.107294; batch adversarial loss: 0.471310\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039134; batch adversarial loss: 0.459968\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051797; batch adversarial loss: 0.491871\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050185; batch adversarial loss: 0.444369\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049246; batch adversarial loss: 0.509104\n",
      "epoch 120; iter: 0; batch classifier loss: 0.058393; batch adversarial loss: 0.420875\n",
      "epoch 121; iter: 0; batch classifier loss: 0.056754; batch adversarial loss: 0.436168\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050082; batch adversarial loss: 0.452120\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051402; batch adversarial loss: 0.388369\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067068; batch adversarial loss: 0.495194\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057451; batch adversarial loss: 0.445369\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038723; batch adversarial loss: 0.392862\n",
      "epoch 127; iter: 0; batch classifier loss: 0.052265; batch adversarial loss: 0.485272\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038821; batch adversarial loss: 0.416511\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046136; batch adversarial loss: 0.556588\n",
      "epoch 130; iter: 0; batch classifier loss: 0.086306; batch adversarial loss: 0.464544\n",
      "epoch 131; iter: 0; batch classifier loss: 0.064018; batch adversarial loss: 0.468177\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038901; batch adversarial loss: 0.455353\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034141; batch adversarial loss: 0.374512\n",
      "epoch 134; iter: 0; batch classifier loss: 0.041999; batch adversarial loss: 0.463455\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051858; batch adversarial loss: 0.472800\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034105; batch adversarial loss: 0.482467\n",
      "epoch 137; iter: 0; batch classifier loss: 0.069135; batch adversarial loss: 0.404664\n",
      "epoch 138; iter: 0; batch classifier loss: 0.071872; batch adversarial loss: 0.442439\n",
      "epoch 139; iter: 0; batch classifier loss: 0.047392; batch adversarial loss: 0.504371\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035024; batch adversarial loss: 0.424750\n",
      "epoch 141; iter: 0; batch classifier loss: 0.050759; batch adversarial loss: 0.458870\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050222; batch adversarial loss: 0.536703\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041694; batch adversarial loss: 0.410224\n",
      "epoch 144; iter: 0; batch classifier loss: 0.046456; batch adversarial loss: 0.490992\n",
      "epoch 145; iter: 0; batch classifier loss: 0.050185; batch adversarial loss: 0.367312\n",
      "epoch 146; iter: 0; batch classifier loss: 0.056906; batch adversarial loss: 0.435109\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034052; batch adversarial loss: 0.433409\n",
      "epoch 148; iter: 0; batch classifier loss: 0.055443; batch adversarial loss: 0.450396\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023899; batch adversarial loss: 0.450867\n",
      "epoch 150; iter: 0; batch classifier loss: 0.059084; batch adversarial loss: 0.516494\n",
      "epoch 151; iter: 0; batch classifier loss: 0.084035; batch adversarial loss: 0.438767\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044537; batch adversarial loss: 0.448151\n",
      "epoch 153; iter: 0; batch classifier loss: 0.057833; batch adversarial loss: 0.436011\n",
      "epoch 154; iter: 0; batch classifier loss: 0.052817; batch adversarial loss: 0.455497\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046603; batch adversarial loss: 0.447050\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034491; batch adversarial loss: 0.446534\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046772; batch adversarial loss: 0.374741\n",
      "epoch 158; iter: 0; batch classifier loss: 0.047289; batch adversarial loss: 0.490345\n",
      "epoch 159; iter: 0; batch classifier loss: 0.050867; batch adversarial loss: 0.420740\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024463; batch adversarial loss: 0.446258\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042722; batch adversarial loss: 0.453968\n",
      "epoch 162; iter: 0; batch classifier loss: 0.055576; batch adversarial loss: 0.525201\n",
      "epoch 163; iter: 0; batch classifier loss: 0.041366; batch adversarial loss: 0.429308\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036162; batch adversarial loss: 0.409439\n",
      "epoch 165; iter: 0; batch classifier loss: 0.043543; batch adversarial loss: 0.389739\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025424; batch adversarial loss: 0.516718\n",
      "epoch 167; iter: 0; batch classifier loss: 0.053657; batch adversarial loss: 0.390663\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019473; batch adversarial loss: 0.465162\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034547; batch adversarial loss: 0.395903\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039428; batch adversarial loss: 0.474746\n",
      "epoch 171; iter: 0; batch classifier loss: 0.053814; batch adversarial loss: 0.429901\n",
      "epoch 172; iter: 0; batch classifier loss: 0.038175; batch adversarial loss: 0.474708\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034898; batch adversarial loss: 0.503518\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021578; batch adversarial loss: 0.494135\n",
      "epoch 175; iter: 0; batch classifier loss: 0.045882; batch adversarial loss: 0.405260\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029892; batch adversarial loss: 0.385806\n",
      "epoch 177; iter: 0; batch classifier loss: 0.045193; batch adversarial loss: 0.398969\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038701; batch adversarial loss: 0.475713\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033212; batch adversarial loss: 0.435644\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023172; batch adversarial loss: 0.407858\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028590; batch adversarial loss: 0.524583\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019435; batch adversarial loss: 0.480362\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042054; batch adversarial loss: 0.479851\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036875; batch adversarial loss: 0.450119\n",
      "epoch 185; iter: 0; batch classifier loss: 0.046880; batch adversarial loss: 0.474883\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040656; batch adversarial loss: 0.443511\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032352; batch adversarial loss: 0.449334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.043997; batch adversarial loss: 0.459662\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025484; batch adversarial loss: 0.445711\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022189; batch adversarial loss: 0.609010\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028634; batch adversarial loss: 0.452025\n",
      "epoch 192; iter: 0; batch classifier loss: 0.039934; batch adversarial loss: 0.527602\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030515; batch adversarial loss: 0.447274\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020844; batch adversarial loss: 0.514907\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014720; batch adversarial loss: 0.471509\n",
      "epoch 196; iter: 0; batch classifier loss: 0.038635; batch adversarial loss: 0.490835\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016366; batch adversarial loss: 0.427965\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017904; batch adversarial loss: 0.455767\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014706; batch adversarial loss: 0.532062\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687561; batch adversarial loss: 0.578756\n",
      "epoch 1; iter: 0; batch classifier loss: 0.491897; batch adversarial loss: 0.623794\n",
      "epoch 2; iter: 0; batch classifier loss: 0.487344; batch adversarial loss: 0.574340\n",
      "epoch 3; iter: 0; batch classifier loss: 0.380615; batch adversarial loss: 0.580150\n",
      "epoch 4; iter: 0; batch classifier loss: 0.316122; batch adversarial loss: 0.575013\n",
      "epoch 5; iter: 0; batch classifier loss: 0.310646; batch adversarial loss: 0.547368\n",
      "epoch 6; iter: 0; batch classifier loss: 0.313185; batch adversarial loss: 0.522630\n",
      "epoch 7; iter: 0; batch classifier loss: 0.221330; batch adversarial loss: 0.533731\n",
      "epoch 8; iter: 0; batch classifier loss: 0.248766; batch adversarial loss: 0.486867\n",
      "epoch 9; iter: 0; batch classifier loss: 0.287326; batch adversarial loss: 0.574526\n",
      "epoch 10; iter: 0; batch classifier loss: 0.239993; batch adversarial loss: 0.533285\n",
      "epoch 11; iter: 0; batch classifier loss: 0.251298; batch adversarial loss: 0.492465\n",
      "epoch 12; iter: 0; batch classifier loss: 0.242248; batch adversarial loss: 0.564768\n",
      "epoch 13; iter: 0; batch classifier loss: 0.265466; batch adversarial loss: 0.490683\n",
      "epoch 14; iter: 0; batch classifier loss: 0.273921; batch adversarial loss: 0.500854\n",
      "epoch 15; iter: 0; batch classifier loss: 0.254060; batch adversarial loss: 0.476463\n",
      "epoch 16; iter: 0; batch classifier loss: 0.339588; batch adversarial loss: 0.466403\n",
      "epoch 17; iter: 0; batch classifier loss: 0.278711; batch adversarial loss: 0.560148\n",
      "epoch 18; iter: 0; batch classifier loss: 0.313974; batch adversarial loss: 0.480126\n",
      "epoch 19; iter: 0; batch classifier loss: 0.368872; batch adversarial loss: 0.516187\n",
      "epoch 20; iter: 0; batch classifier loss: 0.437017; batch adversarial loss: 0.490444\n",
      "epoch 21; iter: 0; batch classifier loss: 0.269639; batch adversarial loss: 0.531637\n",
      "epoch 22; iter: 0; batch classifier loss: 0.276473; batch adversarial loss: 0.521840\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171268; batch adversarial loss: 0.422248\n",
      "epoch 24; iter: 0; batch classifier loss: 0.173899; batch adversarial loss: 0.496003\n",
      "epoch 25; iter: 0; batch classifier loss: 0.128327; batch adversarial loss: 0.559279\n",
      "epoch 26; iter: 0; batch classifier loss: 0.179501; batch adversarial loss: 0.457526\n",
      "epoch 27; iter: 0; batch classifier loss: 0.148432; batch adversarial loss: 0.569654\n",
      "epoch 28; iter: 0; batch classifier loss: 0.178445; batch adversarial loss: 0.466850\n",
      "epoch 29; iter: 0; batch classifier loss: 0.117283; batch adversarial loss: 0.393195\n",
      "epoch 30; iter: 0; batch classifier loss: 0.158174; batch adversarial loss: 0.467257\n",
      "epoch 31; iter: 0; batch classifier loss: 0.127469; batch adversarial loss: 0.399915\n",
      "epoch 32; iter: 0; batch classifier loss: 0.172132; batch adversarial loss: 0.523246\n",
      "epoch 33; iter: 0; batch classifier loss: 0.150614; batch adversarial loss: 0.468846\n",
      "epoch 34; iter: 0; batch classifier loss: 0.108630; batch adversarial loss: 0.580366\n",
      "epoch 35; iter: 0; batch classifier loss: 0.127993; batch adversarial loss: 0.459495\n",
      "epoch 36; iter: 0; batch classifier loss: 0.129846; batch adversarial loss: 0.474613\n",
      "epoch 37; iter: 0; batch classifier loss: 0.094059; batch adversarial loss: 0.417908\n",
      "epoch 38; iter: 0; batch classifier loss: 0.106371; batch adversarial loss: 0.437299\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126278; batch adversarial loss: 0.429673\n",
      "epoch 40; iter: 0; batch classifier loss: 0.098107; batch adversarial loss: 0.425247\n",
      "epoch 41; iter: 0; batch classifier loss: 0.124305; batch adversarial loss: 0.411790\n",
      "epoch 42; iter: 0; batch classifier loss: 0.112285; batch adversarial loss: 0.519709\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117441; batch adversarial loss: 0.472725\n",
      "epoch 44; iter: 0; batch classifier loss: 0.094818; batch adversarial loss: 0.381545\n",
      "epoch 45; iter: 0; batch classifier loss: 0.132479; batch adversarial loss: 0.468243\n",
      "epoch 46; iter: 0; batch classifier loss: 0.134004; batch adversarial loss: 0.462663\n",
      "epoch 47; iter: 0; batch classifier loss: 0.138441; batch adversarial loss: 0.381839\n",
      "epoch 48; iter: 0; batch classifier loss: 0.137558; batch adversarial loss: 0.335566\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113373; batch adversarial loss: 0.425111\n",
      "epoch 50; iter: 0; batch classifier loss: 0.137393; batch adversarial loss: 0.554725\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098449; batch adversarial loss: 0.459055\n",
      "epoch 52; iter: 0; batch classifier loss: 0.144578; batch adversarial loss: 0.383914\n",
      "epoch 53; iter: 0; batch classifier loss: 0.130335; batch adversarial loss: 0.454293\n",
      "epoch 54; iter: 0; batch classifier loss: 0.092971; batch adversarial loss: 0.448517\n",
      "epoch 55; iter: 0; batch classifier loss: 0.141868; batch adversarial loss: 0.476288\n",
      "epoch 56; iter: 0; batch classifier loss: 0.109144; batch adversarial loss: 0.426019\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086645; batch adversarial loss: 0.541793\n",
      "epoch 58; iter: 0; batch classifier loss: 0.129179; batch adversarial loss: 0.539227\n",
      "epoch 59; iter: 0; batch classifier loss: 0.155776; batch adversarial loss: 0.395742\n",
      "epoch 60; iter: 0; batch classifier loss: 0.084684; batch adversarial loss: 0.535720\n",
      "epoch 61; iter: 0; batch classifier loss: 0.065818; batch adversarial loss: 0.559621\n",
      "epoch 62; iter: 0; batch classifier loss: 0.065475; batch adversarial loss: 0.458925\n",
      "epoch 63; iter: 0; batch classifier loss: 0.143106; batch adversarial loss: 0.480783\n",
      "epoch 64; iter: 0; batch classifier loss: 0.089482; batch adversarial loss: 0.493818\n",
      "epoch 65; iter: 0; batch classifier loss: 0.091431; batch adversarial loss: 0.403326\n",
      "epoch 66; iter: 0; batch classifier loss: 0.065902; batch adversarial loss: 0.476314\n",
      "epoch 67; iter: 0; batch classifier loss: 0.143301; batch adversarial loss: 0.478694\n",
      "epoch 68; iter: 0; batch classifier loss: 0.193509; batch adversarial loss: 0.522962\n",
      "epoch 69; iter: 0; batch classifier loss: 0.122247; batch adversarial loss: 0.446386\n",
      "epoch 70; iter: 0; batch classifier loss: 0.169417; batch adversarial loss: 0.521272\n",
      "epoch 71; iter: 0; batch classifier loss: 0.163060; batch adversarial loss: 0.413456\n",
      "epoch 72; iter: 0; batch classifier loss: 0.110432; batch adversarial loss: 0.378161\n",
      "epoch 73; iter: 0; batch classifier loss: 0.164691; batch adversarial loss: 0.507929\n",
      "epoch 74; iter: 0; batch classifier loss: 0.091691; batch adversarial loss: 0.465439\n",
      "epoch 75; iter: 0; batch classifier loss: 0.128000; batch adversarial loss: 0.496897\n",
      "epoch 76; iter: 0; batch classifier loss: 0.109118; batch adversarial loss: 0.524358\n",
      "epoch 77; iter: 0; batch classifier loss: 0.093526; batch adversarial loss: 0.476682\n",
      "epoch 78; iter: 0; batch classifier loss: 0.138381; batch adversarial loss: 0.460533\n",
      "epoch 79; iter: 0; batch classifier loss: 0.078040; batch adversarial loss: 0.474708\n",
      "epoch 80; iter: 0; batch classifier loss: 0.087940; batch adversarial loss: 0.432509\n",
      "epoch 81; iter: 0; batch classifier loss: 0.051845; batch adversarial loss: 0.470865\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091332; batch adversarial loss: 0.490445\n",
      "epoch 83; iter: 0; batch classifier loss: 0.154014; batch adversarial loss: 0.454570\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079129; batch adversarial loss: 0.396513\n",
      "epoch 85; iter: 0; batch classifier loss: 0.102250; batch adversarial loss: 0.430624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.091444; batch adversarial loss: 0.469165\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082505; batch adversarial loss: 0.426462\n",
      "epoch 88; iter: 0; batch classifier loss: 0.099006; batch adversarial loss: 0.387685\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081837; batch adversarial loss: 0.464327\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064261; batch adversarial loss: 0.406629\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083356; batch adversarial loss: 0.498462\n",
      "epoch 92; iter: 0; batch classifier loss: 0.089671; batch adversarial loss: 0.439654\n",
      "epoch 93; iter: 0; batch classifier loss: 0.135145; batch adversarial loss: 0.447844\n",
      "epoch 94; iter: 0; batch classifier loss: 0.076699; batch adversarial loss: 0.476994\n",
      "epoch 95; iter: 0; batch classifier loss: 0.104374; batch adversarial loss: 0.482876\n",
      "epoch 96; iter: 0; batch classifier loss: 0.092515; batch adversarial loss: 0.471194\n",
      "epoch 97; iter: 0; batch classifier loss: 0.053257; batch adversarial loss: 0.471363\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074172; batch adversarial loss: 0.438195\n",
      "epoch 99; iter: 0; batch classifier loss: 0.095036; batch adversarial loss: 0.453423\n",
      "epoch 100; iter: 0; batch classifier loss: 0.083399; batch adversarial loss: 0.450597\n",
      "epoch 101; iter: 0; batch classifier loss: 0.065551; batch adversarial loss: 0.517634\n",
      "epoch 102; iter: 0; batch classifier loss: 0.090089; batch adversarial loss: 0.475833\n",
      "epoch 103; iter: 0; batch classifier loss: 0.084883; batch adversarial loss: 0.423114\n",
      "epoch 104; iter: 0; batch classifier loss: 0.100714; batch adversarial loss: 0.418012\n",
      "epoch 105; iter: 0; batch classifier loss: 0.067105; batch adversarial loss: 0.549529\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057992; batch adversarial loss: 0.542294\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049392; batch adversarial loss: 0.504440\n",
      "epoch 108; iter: 0; batch classifier loss: 0.088456; batch adversarial loss: 0.419014\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060341; batch adversarial loss: 0.455880\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051837; batch adversarial loss: 0.396705\n",
      "epoch 111; iter: 0; batch classifier loss: 0.101110; batch adversarial loss: 0.483126\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063844; batch adversarial loss: 0.495877\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055559; batch adversarial loss: 0.445162\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028969; batch adversarial loss: 0.409717\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060033; batch adversarial loss: 0.456546\n",
      "epoch 116; iter: 0; batch classifier loss: 0.077689; batch adversarial loss: 0.450567\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036633; batch adversarial loss: 0.476527\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045074; batch adversarial loss: 0.458743\n",
      "epoch 119; iter: 0; batch classifier loss: 0.062858; batch adversarial loss: 0.402621\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044008; batch adversarial loss: 0.493733\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052966; batch adversarial loss: 0.514534\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038686; batch adversarial loss: 0.448477\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051125; batch adversarial loss: 0.416113\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037648; batch adversarial loss: 0.515399\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033884; batch adversarial loss: 0.423207\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032147; batch adversarial loss: 0.495764\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034007; batch adversarial loss: 0.493728\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054732; batch adversarial loss: 0.571388\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020048; batch adversarial loss: 0.385694\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043413; batch adversarial loss: 0.364623\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028580; batch adversarial loss: 0.410606\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042689; batch adversarial loss: 0.431025\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045713; batch adversarial loss: 0.501926\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052129; batch adversarial loss: 0.433701\n",
      "epoch 135; iter: 0; batch classifier loss: 0.077135; batch adversarial loss: 0.480175\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025655; batch adversarial loss: 0.396141\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041752; batch adversarial loss: 0.522869\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056245; batch adversarial loss: 0.414062\n",
      "epoch 139; iter: 0; batch classifier loss: 0.048570; batch adversarial loss: 0.374386\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029228; batch adversarial loss: 0.461675\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053002; batch adversarial loss: 0.404569\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049545; batch adversarial loss: 0.424722\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042298; batch adversarial loss: 0.430622\n",
      "epoch 144; iter: 0; batch classifier loss: 0.042781; batch adversarial loss: 0.408263\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032985; batch adversarial loss: 0.401053\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016258; batch adversarial loss: 0.454439\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020164; batch adversarial loss: 0.470356\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035729; batch adversarial loss: 0.441665\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038114; batch adversarial loss: 0.525387\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028845; batch adversarial loss: 0.481097\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011482; batch adversarial loss: 0.473892\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025890; batch adversarial loss: 0.500258\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019860; batch adversarial loss: 0.532138\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023824; batch adversarial loss: 0.520306\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031951; batch adversarial loss: 0.387615\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028254; batch adversarial loss: 0.488777\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016215; batch adversarial loss: 0.528048\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035587; batch adversarial loss: 0.410323\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030007; batch adversarial loss: 0.463188\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023769; batch adversarial loss: 0.498115\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018229; batch adversarial loss: 0.503208\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036268; batch adversarial loss: 0.566710\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035519; batch adversarial loss: 0.482980\n",
      "epoch 164; iter: 0; batch classifier loss: 0.039445; batch adversarial loss: 0.510889\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040360; batch adversarial loss: 0.420812\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010967; batch adversarial loss: 0.442685\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021910; batch adversarial loss: 0.511771\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031560; batch adversarial loss: 0.483752\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009662; batch adversarial loss: 0.431854\n",
      "epoch 170; iter: 0; batch classifier loss: 0.052971; batch adversarial loss: 0.418907\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047967; batch adversarial loss: 0.474258\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026533; batch adversarial loss: 0.452330\n",
      "epoch 173; iter: 0; batch classifier loss: 0.061915; batch adversarial loss: 0.443018\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025280; batch adversarial loss: 0.418142\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009285; batch adversarial loss: 0.482163\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016062; batch adversarial loss: 0.481649\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016891; batch adversarial loss: 0.454597\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037674; batch adversarial loss: 0.418650\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010978; batch adversarial loss: 0.562176\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014042; batch adversarial loss: 0.424066\n",
      "epoch 181; iter: 0; batch classifier loss: 0.054906; batch adversarial loss: 0.458584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.033731; batch adversarial loss: 0.423085\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010485; batch adversarial loss: 0.444134\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038079; batch adversarial loss: 0.351162\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035881; batch adversarial loss: 0.480265\n",
      "epoch 186; iter: 0; batch classifier loss: 0.052290; batch adversarial loss: 0.498877\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020266; batch adversarial loss: 0.396332\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024432; batch adversarial loss: 0.563096\n",
      "epoch 189; iter: 0; batch classifier loss: 0.037863; batch adversarial loss: 0.539808\n",
      "epoch 190; iter: 0; batch classifier loss: 0.044579; batch adversarial loss: 0.433624\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010053; batch adversarial loss: 0.481600\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026669; batch adversarial loss: 0.430384\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028618; batch adversarial loss: 0.458989\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008088; batch adversarial loss: 0.521903\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006546; batch adversarial loss: 0.461518\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021095; batch adversarial loss: 0.427927\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010773; batch adversarial loss: 0.391544\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012023; batch adversarial loss: 0.441587\n",
      "epoch 199; iter: 0; batch classifier loss: 0.049484; batch adversarial loss: 0.555887\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692596; batch adversarial loss: 0.994078\n",
      "epoch 1; iter: 0; batch classifier loss: 0.656405; batch adversarial loss: 1.101259\n",
      "epoch 2; iter: 0; batch classifier loss: 0.564850; batch adversarial loss: 1.138376\n",
      "epoch 3; iter: 0; batch classifier loss: 0.823704; batch adversarial loss: 1.060897\n",
      "epoch 4; iter: 0; batch classifier loss: 0.807983; batch adversarial loss: 0.965687\n",
      "epoch 5; iter: 0; batch classifier loss: 0.747355; batch adversarial loss: 0.877198\n",
      "epoch 6; iter: 0; batch classifier loss: 0.699313; batch adversarial loss: 0.789462\n",
      "epoch 7; iter: 0; batch classifier loss: 0.460316; batch adversarial loss: 0.714828\n",
      "epoch 8; iter: 0; batch classifier loss: 0.292084; batch adversarial loss: 0.626644\n",
      "epoch 9; iter: 0; batch classifier loss: 0.289144; batch adversarial loss: 0.618654\n",
      "epoch 10; iter: 0; batch classifier loss: 0.324592; batch adversarial loss: 0.564662\n",
      "epoch 11; iter: 0; batch classifier loss: 0.226000; batch adversarial loss: 0.578610\n",
      "epoch 12; iter: 0; batch classifier loss: 0.320625; batch adversarial loss: 0.546092\n",
      "epoch 13; iter: 0; batch classifier loss: 0.270525; batch adversarial loss: 0.513991\n",
      "epoch 14; iter: 0; batch classifier loss: 0.222573; batch adversarial loss: 0.533722\n",
      "epoch 15; iter: 0; batch classifier loss: 0.194359; batch adversarial loss: 0.550277\n",
      "epoch 16; iter: 0; batch classifier loss: 0.271836; batch adversarial loss: 0.548508\n",
      "epoch 17; iter: 0; batch classifier loss: 0.277944; batch adversarial loss: 0.541241\n",
      "epoch 18; iter: 0; batch classifier loss: 0.239080; batch adversarial loss: 0.498589\n",
      "epoch 19; iter: 0; batch classifier loss: 0.221815; batch adversarial loss: 0.480165\n",
      "epoch 20; iter: 0; batch classifier loss: 0.212772; batch adversarial loss: 0.462000\n",
      "epoch 21; iter: 0; batch classifier loss: 0.157245; batch adversarial loss: 0.514276\n",
      "epoch 22; iter: 0; batch classifier loss: 0.187297; batch adversarial loss: 0.540463\n",
      "epoch 23; iter: 0; batch classifier loss: 0.149036; batch adversarial loss: 0.544588\n",
      "epoch 24; iter: 0; batch classifier loss: 0.220148; batch adversarial loss: 0.446758\n",
      "epoch 25; iter: 0; batch classifier loss: 0.270541; batch adversarial loss: 0.488957\n",
      "epoch 26; iter: 0; batch classifier loss: 0.232193; batch adversarial loss: 0.459423\n",
      "epoch 27; iter: 0; batch classifier loss: 0.147570; batch adversarial loss: 0.455691\n",
      "epoch 28; iter: 0; batch classifier loss: 0.178739; batch adversarial loss: 0.490419\n",
      "epoch 29; iter: 0; batch classifier loss: 0.166375; batch adversarial loss: 0.441736\n",
      "epoch 30; iter: 0; batch classifier loss: 0.180455; batch adversarial loss: 0.423029\n",
      "epoch 31; iter: 0; batch classifier loss: 0.151331; batch adversarial loss: 0.477186\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126299; batch adversarial loss: 0.475143\n",
      "epoch 33; iter: 0; batch classifier loss: 0.124986; batch adversarial loss: 0.525285\n",
      "epoch 34; iter: 0; batch classifier loss: 0.103662; batch adversarial loss: 0.431342\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129996; batch adversarial loss: 0.365170\n",
      "epoch 36; iter: 0; batch classifier loss: 0.123008; batch adversarial loss: 0.399677\n",
      "epoch 37; iter: 0; batch classifier loss: 0.156252; batch adversarial loss: 0.442035\n",
      "epoch 38; iter: 0; batch classifier loss: 0.097792; batch adversarial loss: 0.478063\n",
      "epoch 39; iter: 0; batch classifier loss: 0.069194; batch adversarial loss: 0.450401\n",
      "epoch 40; iter: 0; batch classifier loss: 0.136588; batch adversarial loss: 0.422219\n",
      "epoch 41; iter: 0; batch classifier loss: 0.075475; batch adversarial loss: 0.450663\n",
      "epoch 42; iter: 0; batch classifier loss: 0.107205; batch adversarial loss: 0.448072\n",
      "epoch 43; iter: 0; batch classifier loss: 0.097413; batch adversarial loss: 0.419925\n",
      "epoch 44; iter: 0; batch classifier loss: 0.109056; batch adversarial loss: 0.368153\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103142; batch adversarial loss: 0.429827\n",
      "epoch 46; iter: 0; batch classifier loss: 0.064003; batch adversarial loss: 0.370255\n",
      "epoch 47; iter: 0; batch classifier loss: 0.056296; batch adversarial loss: 0.457050\n",
      "epoch 48; iter: 0; batch classifier loss: 0.103615; batch adversarial loss: 0.441920\n",
      "epoch 49; iter: 0; batch classifier loss: 0.042175; batch adversarial loss: 0.529192\n",
      "epoch 50; iter: 0; batch classifier loss: 0.069134; batch adversarial loss: 0.479352\n",
      "epoch 51; iter: 0; batch classifier loss: 0.103881; batch adversarial loss: 0.497779\n",
      "epoch 52; iter: 0; batch classifier loss: 0.069521; batch adversarial loss: 0.407129\n",
      "epoch 53; iter: 0; batch classifier loss: 0.073036; batch adversarial loss: 0.520559\n",
      "epoch 54; iter: 0; batch classifier loss: 0.080047; batch adversarial loss: 0.497039\n",
      "epoch 55; iter: 0; batch classifier loss: 0.082231; batch adversarial loss: 0.363093\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103308; batch adversarial loss: 0.468944\n",
      "epoch 57; iter: 0; batch classifier loss: 0.059941; batch adversarial loss: 0.385378\n",
      "epoch 58; iter: 0; batch classifier loss: 0.075963; batch adversarial loss: 0.467122\n",
      "epoch 59; iter: 0; batch classifier loss: 0.076001; batch adversarial loss: 0.440510\n",
      "epoch 60; iter: 0; batch classifier loss: 0.089767; batch adversarial loss: 0.536849\n",
      "epoch 61; iter: 0; batch classifier loss: 0.073899; batch adversarial loss: 0.414244\n",
      "epoch 62; iter: 0; batch classifier loss: 0.075657; batch adversarial loss: 0.453398\n",
      "epoch 63; iter: 0; batch classifier loss: 0.073578; batch adversarial loss: 0.320464\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080555; batch adversarial loss: 0.475732\n",
      "epoch 65; iter: 0; batch classifier loss: 0.053127; batch adversarial loss: 0.423904\n",
      "epoch 66; iter: 0; batch classifier loss: 0.080016; batch adversarial loss: 0.413020\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073494; batch adversarial loss: 0.442733\n",
      "epoch 68; iter: 0; batch classifier loss: 0.083716; batch adversarial loss: 0.380316\n",
      "epoch 69; iter: 0; batch classifier loss: 0.055672; batch adversarial loss: 0.445597\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065537; batch adversarial loss: 0.543289\n",
      "epoch 71; iter: 0; batch classifier loss: 0.050413; batch adversarial loss: 0.383038\n",
      "epoch 72; iter: 0; batch classifier loss: 0.048273; batch adversarial loss: 0.463078\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067110; batch adversarial loss: 0.438133\n",
      "epoch 74; iter: 0; batch classifier loss: 0.064250; batch adversarial loss: 0.471654\n",
      "epoch 75; iter: 0; batch classifier loss: 0.052056; batch adversarial loss: 0.455120\n",
      "epoch 76; iter: 0; batch classifier loss: 0.059970; batch adversarial loss: 0.411584\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062411; batch adversarial loss: 0.373150\n",
      "epoch 78; iter: 0; batch classifier loss: 0.070885; batch adversarial loss: 0.360823\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068590; batch adversarial loss: 0.483062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.031771; batch adversarial loss: 0.339864\n",
      "epoch 81; iter: 0; batch classifier loss: 0.041343; batch adversarial loss: 0.376781\n",
      "epoch 82; iter: 0; batch classifier loss: 0.064605; batch adversarial loss: 0.387338\n",
      "epoch 83; iter: 0; batch classifier loss: 0.067051; batch adversarial loss: 0.447068\n",
      "epoch 84; iter: 0; batch classifier loss: 0.050537; batch adversarial loss: 0.408035\n",
      "epoch 85; iter: 0; batch classifier loss: 0.050223; batch adversarial loss: 0.421771\n",
      "epoch 86; iter: 0; batch classifier loss: 0.033136; batch adversarial loss: 0.453337\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057000; batch adversarial loss: 0.462502\n",
      "epoch 88; iter: 0; batch classifier loss: 0.104278; batch adversarial loss: 0.441762\n",
      "epoch 89; iter: 0; batch classifier loss: 0.047542; batch adversarial loss: 0.428820\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065913; batch adversarial loss: 0.438801\n",
      "epoch 91; iter: 0; batch classifier loss: 0.047142; batch adversarial loss: 0.414138\n",
      "epoch 92; iter: 0; batch classifier loss: 0.085730; batch adversarial loss: 0.569324\n",
      "epoch 93; iter: 0; batch classifier loss: 0.031990; batch adversarial loss: 0.407007\n",
      "epoch 94; iter: 0; batch classifier loss: 0.067958; batch adversarial loss: 0.435025\n",
      "epoch 95; iter: 0; batch classifier loss: 0.037798; batch adversarial loss: 0.423463\n",
      "epoch 96; iter: 0; batch classifier loss: 0.081122; batch adversarial loss: 0.469729\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046408; batch adversarial loss: 0.374128\n",
      "epoch 98; iter: 0; batch classifier loss: 0.099553; batch adversarial loss: 0.432398\n",
      "epoch 99; iter: 0; batch classifier loss: 0.080864; batch adversarial loss: 0.449222\n",
      "epoch 100; iter: 0; batch classifier loss: 0.052048; batch adversarial loss: 0.348032\n",
      "epoch 101; iter: 0; batch classifier loss: 0.059565; batch adversarial loss: 0.378073\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059404; batch adversarial loss: 0.398310\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039700; batch adversarial loss: 0.451044\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033875; batch adversarial loss: 0.407306\n",
      "epoch 105; iter: 0; batch classifier loss: 0.097605; batch adversarial loss: 0.437448\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037094; batch adversarial loss: 0.361945\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063694; batch adversarial loss: 0.470052\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028216; batch adversarial loss: 0.471948\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037166; batch adversarial loss: 0.406832\n",
      "epoch 110; iter: 0; batch classifier loss: 0.062502; batch adversarial loss: 0.437145\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045844; batch adversarial loss: 0.445250\n",
      "epoch 112; iter: 0; batch classifier loss: 0.062245; batch adversarial loss: 0.416984\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046734; batch adversarial loss: 0.451738\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057172; batch adversarial loss: 0.380940\n",
      "epoch 115; iter: 0; batch classifier loss: 0.061019; batch adversarial loss: 0.490681\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032342; batch adversarial loss: 0.377713\n",
      "epoch 117; iter: 0; batch classifier loss: 0.065081; batch adversarial loss: 0.466527\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056708; batch adversarial loss: 0.336648\n",
      "epoch 119; iter: 0; batch classifier loss: 0.075146; batch adversarial loss: 0.498564\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055233; batch adversarial loss: 0.457319\n",
      "epoch 121; iter: 0; batch classifier loss: 0.078676; batch adversarial loss: 0.444158\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040234; batch adversarial loss: 0.375221\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045102; batch adversarial loss: 0.416671\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044812; batch adversarial loss: 0.454525\n",
      "epoch 125; iter: 0; batch classifier loss: 0.066771; batch adversarial loss: 0.363626\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050767; batch adversarial loss: 0.416534\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037265; batch adversarial loss: 0.465331\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035642; batch adversarial loss: 0.483389\n",
      "epoch 129; iter: 0; batch classifier loss: 0.068183; batch adversarial loss: 0.461091\n",
      "epoch 130; iter: 0; batch classifier loss: 0.072197; batch adversarial loss: 0.447836\n",
      "epoch 131; iter: 0; batch classifier loss: 0.062246; batch adversarial loss: 0.519814\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035885; batch adversarial loss: 0.405855\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027150; batch adversarial loss: 0.370371\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020861; batch adversarial loss: 0.388770\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057872; batch adversarial loss: 0.523133\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043309; batch adversarial loss: 0.463107\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042169; batch adversarial loss: 0.408145\n",
      "epoch 138; iter: 0; batch classifier loss: 0.065533; batch adversarial loss: 0.381809\n",
      "epoch 139; iter: 0; batch classifier loss: 0.059503; batch adversarial loss: 0.413642\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035286; batch adversarial loss: 0.440158\n",
      "epoch 141; iter: 0; batch classifier loss: 0.060314; batch adversarial loss: 0.501122\n",
      "epoch 142; iter: 0; batch classifier loss: 0.053582; batch adversarial loss: 0.425034\n",
      "epoch 143; iter: 0; batch classifier loss: 0.055895; batch adversarial loss: 0.481201\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029868; batch adversarial loss: 0.468360\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036595; batch adversarial loss: 0.427134\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042675; batch adversarial loss: 0.434281\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018500; batch adversarial loss: 0.460333\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031182; batch adversarial loss: 0.345628\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040993; batch adversarial loss: 0.432429\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038720; batch adversarial loss: 0.413211\n",
      "epoch 151; iter: 0; batch classifier loss: 0.074929; batch adversarial loss: 0.500153\n",
      "epoch 152; iter: 0; batch classifier loss: 0.061075; batch adversarial loss: 0.372556\n",
      "epoch 153; iter: 0; batch classifier loss: 0.049213; batch adversarial loss: 0.358424\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020220; batch adversarial loss: 0.345960\n",
      "epoch 155; iter: 0; batch classifier loss: 0.043102; batch adversarial loss: 0.504872\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037376; batch adversarial loss: 0.439577\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031364; batch adversarial loss: 0.365726\n",
      "epoch 158; iter: 0; batch classifier loss: 0.039803; batch adversarial loss: 0.386116\n",
      "epoch 159; iter: 0; batch classifier loss: 0.053991; batch adversarial loss: 0.357210\n",
      "epoch 160; iter: 0; batch classifier loss: 0.040447; batch adversarial loss: 0.465008\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038533; batch adversarial loss: 0.491514\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036977; batch adversarial loss: 0.363423\n",
      "epoch 163; iter: 0; batch classifier loss: 0.043700; batch adversarial loss: 0.396110\n",
      "epoch 164; iter: 0; batch classifier loss: 0.043704; batch adversarial loss: 0.410178\n",
      "epoch 165; iter: 0; batch classifier loss: 0.055110; batch adversarial loss: 0.426632\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045142; batch adversarial loss: 0.414025\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036606; batch adversarial loss: 0.429974\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027258; batch adversarial loss: 0.354397\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040417; batch adversarial loss: 0.465891\n",
      "epoch 170; iter: 0; batch classifier loss: 0.044827; batch adversarial loss: 0.478872\n",
      "epoch 171; iter: 0; batch classifier loss: 0.052021; batch adversarial loss: 0.503230\n",
      "epoch 172; iter: 0; batch classifier loss: 0.043093; batch adversarial loss: 0.502241\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032357; batch adversarial loss: 0.475641\n",
      "epoch 174; iter: 0; batch classifier loss: 0.049988; batch adversarial loss: 0.425100\n",
      "epoch 175; iter: 0; batch classifier loss: 0.068856; batch adversarial loss: 0.449368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.065878; batch adversarial loss: 0.375906\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019878; batch adversarial loss: 0.435288\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027036; batch adversarial loss: 0.382093\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037621; batch adversarial loss: 0.371986\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024525; batch adversarial loss: 0.563453\n",
      "epoch 181; iter: 0; batch classifier loss: 0.071161; batch adversarial loss: 0.443597\n",
      "epoch 182; iter: 0; batch classifier loss: 0.052901; batch adversarial loss: 0.433706\n",
      "epoch 183; iter: 0; batch classifier loss: 0.040953; batch adversarial loss: 0.351397\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025082; batch adversarial loss: 0.429896\n",
      "epoch 185; iter: 0; batch classifier loss: 0.066079; batch adversarial loss: 0.434474\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029173; batch adversarial loss: 0.441025\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023637; batch adversarial loss: 0.410944\n",
      "epoch 188; iter: 0; batch classifier loss: 0.079504; batch adversarial loss: 0.491076\n",
      "epoch 189; iter: 0; batch classifier loss: 0.055694; batch adversarial loss: 0.410827\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034749; batch adversarial loss: 0.505549\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021016; batch adversarial loss: 0.420684\n",
      "epoch 192; iter: 0; batch classifier loss: 0.034388; batch adversarial loss: 0.466734\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029367; batch adversarial loss: 0.435435\n",
      "epoch 194; iter: 0; batch classifier loss: 0.037007; batch adversarial loss: 0.420667\n",
      "epoch 195; iter: 0; batch classifier loss: 0.046601; batch adversarial loss: 0.401389\n",
      "epoch 196; iter: 0; batch classifier loss: 0.034017; batch adversarial loss: 0.407642\n",
      "epoch 197; iter: 0; batch classifier loss: 0.042982; batch adversarial loss: 0.419299\n",
      "epoch 198; iter: 0; batch classifier loss: 0.049108; batch adversarial loss: 0.496108\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020032; batch adversarial loss: 0.396296\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692415; batch adversarial loss: 0.672546\n",
      "epoch 1; iter: 0; batch classifier loss: 0.489871; batch adversarial loss: 0.645955\n",
      "epoch 2; iter: 0; batch classifier loss: 0.386421; batch adversarial loss: 0.640382\n",
      "epoch 3; iter: 0; batch classifier loss: 0.339275; batch adversarial loss: 0.625250\n",
      "epoch 4; iter: 0; batch classifier loss: 0.348808; batch adversarial loss: 0.567975\n",
      "epoch 5; iter: 0; batch classifier loss: 0.321199; batch adversarial loss: 0.550388\n",
      "epoch 6; iter: 0; batch classifier loss: 0.326088; batch adversarial loss: 0.578328\n",
      "epoch 7; iter: 0; batch classifier loss: 0.271583; batch adversarial loss: 0.508043\n",
      "epoch 8; iter: 0; batch classifier loss: 0.257625; batch adversarial loss: 0.487921\n",
      "epoch 9; iter: 0; batch classifier loss: 0.225312; batch adversarial loss: 0.489001\n",
      "epoch 10; iter: 0; batch classifier loss: 0.295974; batch adversarial loss: 0.462946\n",
      "epoch 11; iter: 0; batch classifier loss: 0.315964; batch adversarial loss: 0.404677\n",
      "epoch 12; iter: 0; batch classifier loss: 0.208069; batch adversarial loss: 0.500435\n",
      "epoch 13; iter: 0; batch classifier loss: 0.157365; batch adversarial loss: 0.448006\n",
      "epoch 14; iter: 0; batch classifier loss: 0.203461; batch adversarial loss: 0.448065\n",
      "epoch 15; iter: 0; batch classifier loss: 0.185029; batch adversarial loss: 0.443217\n",
      "epoch 16; iter: 0; batch classifier loss: 0.206699; batch adversarial loss: 0.469754\n",
      "epoch 17; iter: 0; batch classifier loss: 0.208825; batch adversarial loss: 0.480693\n",
      "epoch 18; iter: 0; batch classifier loss: 0.207320; batch adversarial loss: 0.491167\n",
      "epoch 19; iter: 0; batch classifier loss: 0.160898; batch adversarial loss: 0.472846\n",
      "epoch 20; iter: 0; batch classifier loss: 0.154001; batch adversarial loss: 0.524196\n",
      "epoch 21; iter: 0; batch classifier loss: 0.137407; batch adversarial loss: 0.467645\n",
      "epoch 22; iter: 0; batch classifier loss: 0.154660; batch adversarial loss: 0.480155\n",
      "epoch 23; iter: 0; batch classifier loss: 0.132203; batch adversarial loss: 0.489863\n",
      "epoch 24; iter: 0; batch classifier loss: 0.177053; batch adversarial loss: 0.519228\n",
      "epoch 25; iter: 0; batch classifier loss: 0.184008; batch adversarial loss: 0.544314\n",
      "epoch 26; iter: 0; batch classifier loss: 0.270329; batch adversarial loss: 0.548885\n",
      "epoch 27; iter: 0; batch classifier loss: 0.191775; batch adversarial loss: 0.416063\n",
      "epoch 28; iter: 0; batch classifier loss: 0.194716; batch adversarial loss: 0.480387\n",
      "epoch 29; iter: 0; batch classifier loss: 0.181612; batch adversarial loss: 0.460359\n",
      "epoch 30; iter: 0; batch classifier loss: 0.212142; batch adversarial loss: 0.467677\n",
      "epoch 31; iter: 0; batch classifier loss: 0.224078; batch adversarial loss: 0.499523\n",
      "epoch 32; iter: 0; batch classifier loss: 0.218416; batch adversarial loss: 0.514182\n",
      "epoch 33; iter: 0; batch classifier loss: 0.237743; batch adversarial loss: 0.582456\n",
      "epoch 34; iter: 0; batch classifier loss: 0.260511; batch adversarial loss: 0.518044\n",
      "epoch 35; iter: 0; batch classifier loss: 0.270794; batch adversarial loss: 0.478706\n",
      "epoch 36; iter: 0; batch classifier loss: 0.262913; batch adversarial loss: 0.438618\n",
      "epoch 37; iter: 0; batch classifier loss: 0.221462; batch adversarial loss: 0.395398\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099117; batch adversarial loss: 0.492648\n",
      "epoch 39; iter: 0; batch classifier loss: 0.081734; batch adversarial loss: 0.484010\n",
      "epoch 40; iter: 0; batch classifier loss: 0.065758; batch adversarial loss: 0.463584\n",
      "epoch 41; iter: 0; batch classifier loss: 0.096675; batch adversarial loss: 0.445810\n",
      "epoch 42; iter: 0; batch classifier loss: 0.075838; batch adversarial loss: 0.339865\n",
      "epoch 43; iter: 0; batch classifier loss: 0.099821; batch adversarial loss: 0.472318\n",
      "epoch 44; iter: 0; batch classifier loss: 0.091994; batch adversarial loss: 0.432524\n",
      "epoch 45; iter: 0; batch classifier loss: 0.064027; batch adversarial loss: 0.373709\n",
      "epoch 46; iter: 0; batch classifier loss: 0.041057; batch adversarial loss: 0.488071\n",
      "epoch 47; iter: 0; batch classifier loss: 0.085332; batch adversarial loss: 0.448748\n",
      "epoch 48; iter: 0; batch classifier loss: 0.064280; batch adversarial loss: 0.463813\n",
      "epoch 49; iter: 0; batch classifier loss: 0.068347; batch adversarial loss: 0.446543\n",
      "epoch 50; iter: 0; batch classifier loss: 0.063027; batch adversarial loss: 0.559470\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083466; batch adversarial loss: 0.358398\n",
      "epoch 52; iter: 0; batch classifier loss: 0.098046; batch adversarial loss: 0.489229\n",
      "epoch 53; iter: 0; batch classifier loss: 0.080855; batch adversarial loss: 0.460295\n",
      "epoch 54; iter: 0; batch classifier loss: 0.058526; batch adversarial loss: 0.517886\n",
      "epoch 55; iter: 0; batch classifier loss: 0.048506; batch adversarial loss: 0.377691\n",
      "epoch 56; iter: 0; batch classifier loss: 0.083510; batch adversarial loss: 0.511343\n",
      "epoch 57; iter: 0; batch classifier loss: 0.053536; batch adversarial loss: 0.462651\n",
      "epoch 58; iter: 0; batch classifier loss: 0.071524; batch adversarial loss: 0.475903\n",
      "epoch 59; iter: 0; batch classifier loss: 0.069169; batch adversarial loss: 0.484328\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076587; batch adversarial loss: 0.502565\n",
      "epoch 61; iter: 0; batch classifier loss: 0.148316; batch adversarial loss: 0.529398\n",
      "epoch 62; iter: 0; batch classifier loss: 0.079631; batch adversarial loss: 0.409264\n",
      "epoch 63; iter: 0; batch classifier loss: 0.087944; batch adversarial loss: 0.451845\n",
      "epoch 64; iter: 0; batch classifier loss: 0.088612; batch adversarial loss: 0.472008\n",
      "epoch 65; iter: 0; batch classifier loss: 0.092921; batch adversarial loss: 0.529642\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073873; batch adversarial loss: 0.403553\n",
      "epoch 67; iter: 0; batch classifier loss: 0.159559; batch adversarial loss: 0.384920\n",
      "epoch 68; iter: 0; batch classifier loss: 0.052751; batch adversarial loss: 0.524363\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075131; batch adversarial loss: 0.512051\n",
      "epoch 70; iter: 0; batch classifier loss: 0.077128; batch adversarial loss: 0.407325\n",
      "epoch 71; iter: 0; batch classifier loss: 0.111233; batch adversarial loss: 0.484050\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080401; batch adversarial loss: 0.526014\n",
      "epoch 73; iter: 0; batch classifier loss: 0.074946; batch adversarial loss: 0.440604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.075941; batch adversarial loss: 0.524649\n",
      "epoch 75; iter: 0; batch classifier loss: 0.058889; batch adversarial loss: 0.398575\n",
      "epoch 76; iter: 0; batch classifier loss: 0.117524; batch adversarial loss: 0.485240\n",
      "epoch 77; iter: 0; batch classifier loss: 0.116644; batch adversarial loss: 0.433632\n",
      "epoch 78; iter: 0; batch classifier loss: 0.106755; batch adversarial loss: 0.497094\n",
      "epoch 79; iter: 0; batch classifier loss: 0.123185; batch adversarial loss: 0.407724\n",
      "epoch 80; iter: 0; batch classifier loss: 0.064449; batch adversarial loss: 0.521963\n",
      "epoch 81; iter: 0; batch classifier loss: 0.116928; batch adversarial loss: 0.399329\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090941; batch adversarial loss: 0.461439\n",
      "epoch 83; iter: 0; batch classifier loss: 0.107894; batch adversarial loss: 0.414626\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085999; batch adversarial loss: 0.523406\n",
      "epoch 85; iter: 0; batch classifier loss: 0.054415; batch adversarial loss: 0.397395\n",
      "epoch 86; iter: 0; batch classifier loss: 0.092186; batch adversarial loss: 0.382406\n",
      "epoch 87; iter: 0; batch classifier loss: 0.092957; batch adversarial loss: 0.482939\n",
      "epoch 88; iter: 0; batch classifier loss: 0.110252; batch adversarial loss: 0.422334\n",
      "epoch 89; iter: 0; batch classifier loss: 0.126805; batch adversarial loss: 0.384150\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066631; batch adversarial loss: 0.492348\n",
      "epoch 91; iter: 0; batch classifier loss: 0.111979; batch adversarial loss: 0.423116\n",
      "epoch 92; iter: 0; batch classifier loss: 0.145065; batch adversarial loss: 0.523001\n",
      "epoch 93; iter: 0; batch classifier loss: 0.094601; batch adversarial loss: 0.395313\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072483; batch adversarial loss: 0.542740\n",
      "epoch 95; iter: 0; batch classifier loss: 0.096647; batch adversarial loss: 0.407178\n",
      "epoch 96; iter: 0; batch classifier loss: 0.060645; batch adversarial loss: 0.503336\n",
      "epoch 97; iter: 0; batch classifier loss: 0.105997; batch adversarial loss: 0.420153\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079164; batch adversarial loss: 0.525682\n",
      "epoch 99; iter: 0; batch classifier loss: 0.087722; batch adversarial loss: 0.453112\n",
      "epoch 100; iter: 0; batch classifier loss: 0.094350; batch adversarial loss: 0.428687\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057902; batch adversarial loss: 0.523469\n",
      "epoch 102; iter: 0; batch classifier loss: 0.093432; batch adversarial loss: 0.412612\n",
      "epoch 103; iter: 0; batch classifier loss: 0.086345; batch adversarial loss: 0.464482\n",
      "epoch 104; iter: 0; batch classifier loss: 0.090765; batch adversarial loss: 0.388211\n",
      "epoch 105; iter: 0; batch classifier loss: 0.106026; batch adversarial loss: 0.430383\n",
      "epoch 106; iter: 0; batch classifier loss: 0.092672; batch adversarial loss: 0.422851\n",
      "epoch 107; iter: 0; batch classifier loss: 0.091211; batch adversarial loss: 0.455545\n",
      "epoch 108; iter: 0; batch classifier loss: 0.079297; batch adversarial loss: 0.444362\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058428; batch adversarial loss: 0.363910\n",
      "epoch 110; iter: 0; batch classifier loss: 0.063558; batch adversarial loss: 0.517288\n",
      "epoch 111; iter: 0; batch classifier loss: 0.072633; batch adversarial loss: 0.496411\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046325; batch adversarial loss: 0.508269\n",
      "epoch 113; iter: 0; batch classifier loss: 0.073867; batch adversarial loss: 0.386307\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052432; batch adversarial loss: 0.561835\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049380; batch adversarial loss: 0.507448\n",
      "epoch 116; iter: 0; batch classifier loss: 0.068920; batch adversarial loss: 0.487719\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030506; batch adversarial loss: 0.394761\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039265; batch adversarial loss: 0.445179\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057511; batch adversarial loss: 0.382707\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047571; batch adversarial loss: 0.431363\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058304; batch adversarial loss: 0.473870\n",
      "epoch 122; iter: 0; batch classifier loss: 0.053550; batch adversarial loss: 0.379757\n",
      "epoch 123; iter: 0; batch classifier loss: 0.054666; batch adversarial loss: 0.475015\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038660; batch adversarial loss: 0.480607\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062802; batch adversarial loss: 0.384629\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038384; batch adversarial loss: 0.409652\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051823; batch adversarial loss: 0.510549\n",
      "epoch 128; iter: 0; batch classifier loss: 0.085345; batch adversarial loss: 0.477533\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032555; batch adversarial loss: 0.475975\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027860; batch adversarial loss: 0.383332\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040475; batch adversarial loss: 0.459468\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042127; batch adversarial loss: 0.423531\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033855; batch adversarial loss: 0.520518\n",
      "epoch 134; iter: 0; batch classifier loss: 0.064247; batch adversarial loss: 0.410284\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033933; batch adversarial loss: 0.566651\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056464; batch adversarial loss: 0.389659\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028917; batch adversarial loss: 0.496608\n",
      "epoch 138; iter: 0; batch classifier loss: 0.060585; batch adversarial loss: 0.399437\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039859; batch adversarial loss: 0.437583\n",
      "epoch 140; iter: 0; batch classifier loss: 0.039327; batch adversarial loss: 0.463337\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032014; batch adversarial loss: 0.481423\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043350; batch adversarial loss: 0.410184\n",
      "epoch 143; iter: 0; batch classifier loss: 0.045982; batch adversarial loss: 0.482010\n",
      "epoch 144; iter: 0; batch classifier loss: 0.063616; batch adversarial loss: 0.484400\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045759; batch adversarial loss: 0.393996\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031560; batch adversarial loss: 0.432458\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018775; batch adversarial loss: 0.410649\n",
      "epoch 148; iter: 0; batch classifier loss: 0.055382; batch adversarial loss: 0.480063\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038935; batch adversarial loss: 0.449666\n",
      "epoch 150; iter: 0; batch classifier loss: 0.056949; batch adversarial loss: 0.459863\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027745; batch adversarial loss: 0.532503\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016349; batch adversarial loss: 0.430966\n",
      "epoch 153; iter: 0; batch classifier loss: 0.033277; batch adversarial loss: 0.439696\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019091; batch adversarial loss: 0.460290\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041156; batch adversarial loss: 0.513770\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019927; batch adversarial loss: 0.540504\n",
      "epoch 157; iter: 0; batch classifier loss: 0.049204; batch adversarial loss: 0.411249\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024970; batch adversarial loss: 0.425672\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019415; batch adversarial loss: 0.408710\n",
      "epoch 160; iter: 0; batch classifier loss: 0.072698; batch adversarial loss: 0.496443\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037663; batch adversarial loss: 0.424419\n",
      "epoch 162; iter: 0; batch classifier loss: 0.055242; batch adversarial loss: 0.608505\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028884; batch adversarial loss: 0.534764\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015589; batch adversarial loss: 0.396453\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029583; batch adversarial loss: 0.412960\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038019; batch adversarial loss: 0.502246\n",
      "epoch 167; iter: 0; batch classifier loss: 0.057353; batch adversarial loss: 0.462119\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024366; batch adversarial loss: 0.495759\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017039; batch adversarial loss: 0.544937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.026552; batch adversarial loss: 0.404705\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008147; batch adversarial loss: 0.526337\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017433; batch adversarial loss: 0.329098\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010180; batch adversarial loss: 0.426162\n",
      "epoch 174; iter: 0; batch classifier loss: 0.049730; batch adversarial loss: 0.416869\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035735; batch adversarial loss: 0.434421\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040645; batch adversarial loss: 0.367583\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046759; batch adversarial loss: 0.514096\n",
      "epoch 178; iter: 0; batch classifier loss: 0.042380; batch adversarial loss: 0.443758\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016057; batch adversarial loss: 0.432102\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009147; batch adversarial loss: 0.366913\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011181; batch adversarial loss: 0.517220\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020739; batch adversarial loss: 0.401229\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006657; batch adversarial loss: 0.366820\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024381; batch adversarial loss: 0.379695\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010630; batch adversarial loss: 0.500866\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007896; batch adversarial loss: 0.455689\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010785; batch adversarial loss: 0.489013\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013064; batch adversarial loss: 0.407339\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009972; batch adversarial loss: 0.516190\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037143; batch adversarial loss: 0.483056\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007703; batch adversarial loss: 0.431062\n",
      "epoch 192; iter: 0; batch classifier loss: 0.038025; batch adversarial loss: 0.376260\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009431; batch adversarial loss: 0.518371\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015253; batch adversarial loss: 0.481851\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021987; batch adversarial loss: 0.488707\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026459; batch adversarial loss: 0.477416\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014436; batch adversarial loss: 0.500509\n",
      "epoch 198; iter: 0; batch classifier loss: 0.035540; batch adversarial loss: 0.401523\n",
      "epoch 199; iter: 0; batch classifier loss: 0.039433; batch adversarial loss: 0.518001\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681873; batch adversarial loss: 0.888065\n",
      "epoch 1; iter: 0; batch classifier loss: 0.555191; batch adversarial loss: 0.842205\n",
      "epoch 2; iter: 0; batch classifier loss: 0.860156; batch adversarial loss: 0.929957\n",
      "epoch 3; iter: 0; batch classifier loss: 0.859136; batch adversarial loss: 0.832613\n",
      "epoch 4; iter: 0; batch classifier loss: 0.749347; batch adversarial loss: 0.732082\n",
      "epoch 5; iter: 0; batch classifier loss: 0.665075; batch adversarial loss: 0.670364\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572003; batch adversarial loss: 0.638479\n",
      "epoch 7; iter: 0; batch classifier loss: 0.505630; batch adversarial loss: 0.599255\n",
      "epoch 8; iter: 0; batch classifier loss: 0.403020; batch adversarial loss: 0.573796\n",
      "epoch 9; iter: 0; batch classifier loss: 0.326039; batch adversarial loss: 0.557662\n",
      "epoch 10; iter: 0; batch classifier loss: 0.257251; batch adversarial loss: 0.573551\n",
      "epoch 11; iter: 0; batch classifier loss: 0.287735; batch adversarial loss: 0.482559\n",
      "epoch 12; iter: 0; batch classifier loss: 0.310263; batch adversarial loss: 0.510342\n",
      "epoch 13; iter: 0; batch classifier loss: 0.335669; batch adversarial loss: 0.542747\n",
      "epoch 14; iter: 0; batch classifier loss: 0.223558; batch adversarial loss: 0.524743\n",
      "epoch 15; iter: 0; batch classifier loss: 0.206873; batch adversarial loss: 0.538950\n",
      "epoch 16; iter: 0; batch classifier loss: 0.267308; batch adversarial loss: 0.503304\n",
      "epoch 17; iter: 0; batch classifier loss: 0.210026; batch adversarial loss: 0.455437\n",
      "epoch 18; iter: 0; batch classifier loss: 0.261982; batch adversarial loss: 0.565392\n",
      "epoch 19; iter: 0; batch classifier loss: 0.191115; batch adversarial loss: 0.444126\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222920; batch adversarial loss: 0.478441\n",
      "epoch 21; iter: 0; batch classifier loss: 0.215016; batch adversarial loss: 0.534344\n",
      "epoch 22; iter: 0; batch classifier loss: 0.172701; batch adversarial loss: 0.529290\n",
      "epoch 23; iter: 0; batch classifier loss: 0.236259; batch adversarial loss: 0.484739\n",
      "epoch 24; iter: 0; batch classifier loss: 0.133155; batch adversarial loss: 0.504535\n",
      "epoch 25; iter: 0; batch classifier loss: 0.146266; batch adversarial loss: 0.497823\n",
      "epoch 26; iter: 0; batch classifier loss: 0.142405; batch adversarial loss: 0.518953\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162241; batch adversarial loss: 0.517052\n",
      "epoch 28; iter: 0; batch classifier loss: 0.174181; batch adversarial loss: 0.465032\n",
      "epoch 29; iter: 0; batch classifier loss: 0.145118; batch adversarial loss: 0.463920\n",
      "epoch 30; iter: 0; batch classifier loss: 0.185066; batch adversarial loss: 0.531341\n",
      "epoch 31; iter: 0; batch classifier loss: 0.102210; batch adversarial loss: 0.415022\n",
      "epoch 32; iter: 0; batch classifier loss: 0.141294; batch adversarial loss: 0.516218\n",
      "epoch 33; iter: 0; batch classifier loss: 0.101612; batch adversarial loss: 0.518454\n",
      "epoch 34; iter: 0; batch classifier loss: 0.127633; batch adversarial loss: 0.450046\n",
      "epoch 35; iter: 0; batch classifier loss: 0.132974; batch adversarial loss: 0.509398\n",
      "epoch 36; iter: 0; batch classifier loss: 0.169274; batch adversarial loss: 0.403105\n",
      "epoch 37; iter: 0; batch classifier loss: 0.077398; batch adversarial loss: 0.520031\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148376; batch adversarial loss: 0.427408\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125135; batch adversarial loss: 0.377251\n",
      "epoch 40; iter: 0; batch classifier loss: 0.122304; batch adversarial loss: 0.391387\n",
      "epoch 41; iter: 0; batch classifier loss: 0.109415; batch adversarial loss: 0.459883\n",
      "epoch 42; iter: 0; batch classifier loss: 0.122697; batch adversarial loss: 0.410541\n",
      "epoch 43; iter: 0; batch classifier loss: 0.082839; batch adversarial loss: 0.521841\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112907; batch adversarial loss: 0.459101\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117293; batch adversarial loss: 0.526645\n",
      "epoch 46; iter: 0; batch classifier loss: 0.060933; batch adversarial loss: 0.450510\n",
      "epoch 47; iter: 0; batch classifier loss: 0.138790; batch adversarial loss: 0.489711\n",
      "epoch 48; iter: 0; batch classifier loss: 0.105118; batch adversarial loss: 0.466607\n",
      "epoch 49; iter: 0; batch classifier loss: 0.100334; batch adversarial loss: 0.493082\n",
      "epoch 50; iter: 0; batch classifier loss: 0.115415; batch adversarial loss: 0.499260\n",
      "epoch 51; iter: 0; batch classifier loss: 0.120322; batch adversarial loss: 0.464326\n",
      "epoch 52; iter: 0; batch classifier loss: 0.070203; batch adversarial loss: 0.436789\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096679; batch adversarial loss: 0.452846\n",
      "epoch 54; iter: 0; batch classifier loss: 0.104277; batch adversarial loss: 0.360314\n",
      "epoch 55; iter: 0; batch classifier loss: 0.067358; batch adversarial loss: 0.491157\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082268; batch adversarial loss: 0.455278\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061534; batch adversarial loss: 0.460035\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072349; batch adversarial loss: 0.562087\n",
      "epoch 59; iter: 0; batch classifier loss: 0.066622; batch adversarial loss: 0.497337\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079028; batch adversarial loss: 0.466974\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090033; batch adversarial loss: 0.578856\n",
      "epoch 62; iter: 0; batch classifier loss: 0.043478; batch adversarial loss: 0.412384\n",
      "epoch 63; iter: 0; batch classifier loss: 0.091675; batch adversarial loss: 0.514571\n",
      "epoch 64; iter: 0; batch classifier loss: 0.048811; batch adversarial loss: 0.441134\n",
      "epoch 65; iter: 0; batch classifier loss: 0.066749; batch adversarial loss: 0.516651\n",
      "epoch 66; iter: 0; batch classifier loss: 0.070467; batch adversarial loss: 0.550486\n",
      "epoch 67; iter: 0; batch classifier loss: 0.047877; batch adversarial loss: 0.406726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.056793; batch adversarial loss: 0.361080\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095774; batch adversarial loss: 0.436259\n",
      "epoch 70; iter: 0; batch classifier loss: 0.042655; batch adversarial loss: 0.457778\n",
      "epoch 71; iter: 0; batch classifier loss: 0.032855; batch adversarial loss: 0.372888\n",
      "epoch 72; iter: 0; batch classifier loss: 0.089792; batch adversarial loss: 0.455571\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067906; batch adversarial loss: 0.418199\n",
      "epoch 74; iter: 0; batch classifier loss: 0.027739; batch adversarial loss: 0.380396\n",
      "epoch 75; iter: 0; batch classifier loss: 0.040499; batch adversarial loss: 0.452619\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082966; batch adversarial loss: 0.540327\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065031; batch adversarial loss: 0.456777\n",
      "epoch 78; iter: 0; batch classifier loss: 0.063141; batch adversarial loss: 0.523979\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044974; batch adversarial loss: 0.423108\n",
      "epoch 80; iter: 0; batch classifier loss: 0.063797; batch adversarial loss: 0.417021\n",
      "epoch 81; iter: 0; batch classifier loss: 0.077932; batch adversarial loss: 0.438630\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062779; batch adversarial loss: 0.449094\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086533; batch adversarial loss: 0.449332\n",
      "epoch 84; iter: 0; batch classifier loss: 0.040389; batch adversarial loss: 0.480704\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084042; batch adversarial loss: 0.408070\n",
      "epoch 86; iter: 0; batch classifier loss: 0.048106; batch adversarial loss: 0.429450\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047172; batch adversarial loss: 0.369445\n",
      "epoch 88; iter: 0; batch classifier loss: 0.043890; batch adversarial loss: 0.456147\n",
      "epoch 89; iter: 0; batch classifier loss: 0.033005; batch adversarial loss: 0.460854\n",
      "epoch 90; iter: 0; batch classifier loss: 0.117691; batch adversarial loss: 0.411128\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068920; batch adversarial loss: 0.401225\n",
      "epoch 92; iter: 0; batch classifier loss: 0.031507; batch adversarial loss: 0.414304\n",
      "epoch 93; iter: 0; batch classifier loss: 0.070686; batch adversarial loss: 0.542414\n",
      "epoch 94; iter: 0; batch classifier loss: 0.027760; batch adversarial loss: 0.541148\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068287; batch adversarial loss: 0.488224\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045332; batch adversarial loss: 0.386068\n",
      "epoch 97; iter: 0; batch classifier loss: 0.021967; batch adversarial loss: 0.376601\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054956; batch adversarial loss: 0.511635\n",
      "epoch 99; iter: 0; batch classifier loss: 0.035379; batch adversarial loss: 0.486577\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036470; batch adversarial loss: 0.514842\n",
      "epoch 101; iter: 0; batch classifier loss: 0.053943; batch adversarial loss: 0.443775\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038391; batch adversarial loss: 0.498496\n",
      "epoch 103; iter: 0; batch classifier loss: 0.031884; batch adversarial loss: 0.505339\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034557; batch adversarial loss: 0.471314\n",
      "epoch 105; iter: 0; batch classifier loss: 0.039526; batch adversarial loss: 0.472322\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067938; batch adversarial loss: 0.438943\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044461; batch adversarial loss: 0.454873\n",
      "epoch 108; iter: 0; batch classifier loss: 0.062274; batch adversarial loss: 0.386341\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048188; batch adversarial loss: 0.537522\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058375; batch adversarial loss: 0.468411\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060418; batch adversarial loss: 0.588483\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033090; batch adversarial loss: 0.541591\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037392; batch adversarial loss: 0.514462\n",
      "epoch 114; iter: 0; batch classifier loss: 0.017191; batch adversarial loss: 0.393403\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031548; batch adversarial loss: 0.609560\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042642; batch adversarial loss: 0.455224\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023346; batch adversarial loss: 0.471609\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028465; batch adversarial loss: 0.504405\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040428; batch adversarial loss: 0.487998\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044595; batch adversarial loss: 0.392331\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038133; batch adversarial loss: 0.462808\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043824; batch adversarial loss: 0.386599\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046944; batch adversarial loss: 0.481984\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027486; batch adversarial loss: 0.514224\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034514; batch adversarial loss: 0.470564\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030040; batch adversarial loss: 0.426943\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039829; batch adversarial loss: 0.475946\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018864; batch adversarial loss: 0.452745\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046812; batch adversarial loss: 0.484239\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040838; batch adversarial loss: 0.496934\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022056; batch adversarial loss: 0.489025\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035512; batch adversarial loss: 0.382246\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029101; batch adversarial loss: 0.518462\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016264; batch adversarial loss: 0.476580\n",
      "epoch 135; iter: 0; batch classifier loss: 0.013905; batch adversarial loss: 0.442745\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043595; batch adversarial loss: 0.439101\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036531; batch adversarial loss: 0.394163\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023989; batch adversarial loss: 0.561153\n",
      "epoch 139; iter: 0; batch classifier loss: 0.051759; batch adversarial loss: 0.422918\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030782; batch adversarial loss: 0.446327\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016982; batch adversarial loss: 0.639379\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024704; batch adversarial loss: 0.572591\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032733; batch adversarial loss: 0.453497\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013410; batch adversarial loss: 0.460140\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029289; batch adversarial loss: 0.517410\n",
      "epoch 146; iter: 0; batch classifier loss: 0.092659; batch adversarial loss: 0.496039\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010350; batch adversarial loss: 0.428957\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022622; batch adversarial loss: 0.425706\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038536; batch adversarial loss: 0.372637\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011559; batch adversarial loss: 0.428387\n",
      "epoch 151; iter: 0; batch classifier loss: 0.007406; batch adversarial loss: 0.460623\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045267; batch adversarial loss: 0.440267\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023174; batch adversarial loss: 0.433757\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016577; batch adversarial loss: 0.442657\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042943; batch adversarial loss: 0.592844\n",
      "epoch 156; iter: 0; batch classifier loss: 0.008196; batch adversarial loss: 0.556833\n",
      "epoch 157; iter: 0; batch classifier loss: 0.004726; batch adversarial loss: 0.469423\n",
      "epoch 158; iter: 0; batch classifier loss: 0.075273; batch adversarial loss: 0.437743\n",
      "epoch 159; iter: 0; batch classifier loss: 0.006272; batch adversarial loss: 0.427473\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018593; batch adversarial loss: 0.514356\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008117; batch adversarial loss: 0.489007\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029518; batch adversarial loss: 0.377119\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038938; batch adversarial loss: 0.454950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.022116; batch adversarial loss: 0.365855\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016444; batch adversarial loss: 0.477206\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026921; batch adversarial loss: 0.548790\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008172; batch adversarial loss: 0.398358\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045453; batch adversarial loss: 0.383205\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018478; batch adversarial loss: 0.537533\n",
      "epoch 170; iter: 0; batch classifier loss: 0.007082; batch adversarial loss: 0.427797\n",
      "epoch 171; iter: 0; batch classifier loss: 0.003443; batch adversarial loss: 0.484291\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031162; batch adversarial loss: 0.475134\n",
      "epoch 173; iter: 0; batch classifier loss: 0.003953; batch adversarial loss: 0.519365\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010738; batch adversarial loss: 0.478925\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035924; batch adversarial loss: 0.489708\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016894; batch adversarial loss: 0.387251\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038421; batch adversarial loss: 0.472719\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025135; batch adversarial loss: 0.503313\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010472; batch adversarial loss: 0.508874\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026124; batch adversarial loss: 0.503238\n",
      "epoch 181; iter: 0; batch classifier loss: 0.041524; batch adversarial loss: 0.408651\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015538; batch adversarial loss: 0.379985\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014165; batch adversarial loss: 0.353623\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014204; batch adversarial loss: 0.520882\n",
      "epoch 185; iter: 0; batch classifier loss: 0.046241; batch adversarial loss: 0.524788\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009209; batch adversarial loss: 0.395015\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034186; batch adversarial loss: 0.466265\n",
      "epoch 188; iter: 0; batch classifier loss: 0.003420; batch adversarial loss: 0.424533\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014727; batch adversarial loss: 0.425207\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031669; batch adversarial loss: 0.459553\n",
      "epoch 191; iter: 0; batch classifier loss: 0.002839; batch adversarial loss: 0.558037\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007227; batch adversarial loss: 0.481040\n",
      "epoch 193; iter: 0; batch classifier loss: 0.002874; batch adversarial loss: 0.470907\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010239; batch adversarial loss: 0.391283\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034440; batch adversarial loss: 0.447348\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014706; batch adversarial loss: 0.348209\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020197; batch adversarial loss: 0.433778\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010284; batch adversarial loss: 0.613222\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027052; batch adversarial loss: 0.535189\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699746; batch adversarial loss: 0.874372\n",
      "epoch 1; iter: 0; batch classifier loss: 0.562475; batch adversarial loss: 0.902433\n",
      "epoch 2; iter: 0; batch classifier loss: 0.754249; batch adversarial loss: 0.946427\n",
      "epoch 3; iter: 0; batch classifier loss: 0.840748; batch adversarial loss: 0.883666\n",
      "epoch 4; iter: 0; batch classifier loss: 0.930007; batch adversarial loss: 0.790790\n",
      "epoch 5; iter: 0; batch classifier loss: 1.012149; batch adversarial loss: 0.729614\n",
      "epoch 6; iter: 0; batch classifier loss: 0.989722; batch adversarial loss: 0.648145\n",
      "epoch 7; iter: 0; batch classifier loss: 0.833271; batch adversarial loss: 0.623563\n",
      "epoch 8; iter: 0; batch classifier loss: 0.512191; batch adversarial loss: 0.558994\n",
      "epoch 9; iter: 0; batch classifier loss: 0.299677; batch adversarial loss: 0.561025\n",
      "epoch 10; iter: 0; batch classifier loss: 0.428018; batch adversarial loss: 0.547966\n",
      "epoch 11; iter: 0; batch classifier loss: 0.353957; batch adversarial loss: 0.506004\n",
      "epoch 12; iter: 0; batch classifier loss: 0.337878; batch adversarial loss: 0.555933\n",
      "epoch 13; iter: 0; batch classifier loss: 0.309467; batch adversarial loss: 0.529581\n",
      "epoch 14; iter: 0; batch classifier loss: 0.242471; batch adversarial loss: 0.546265\n",
      "epoch 15; iter: 0; batch classifier loss: 0.289793; batch adversarial loss: 0.533324\n",
      "epoch 16; iter: 0; batch classifier loss: 0.299802; batch adversarial loss: 0.474598\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269129; batch adversarial loss: 0.496539\n",
      "epoch 18; iter: 0; batch classifier loss: 0.325473; batch adversarial loss: 0.453979\n",
      "epoch 19; iter: 0; batch classifier loss: 0.308754; batch adversarial loss: 0.435575\n",
      "epoch 20; iter: 0; batch classifier loss: 0.316303; batch adversarial loss: 0.468924\n",
      "epoch 21; iter: 0; batch classifier loss: 0.285925; batch adversarial loss: 0.440767\n",
      "epoch 22; iter: 0; batch classifier loss: 0.249455; batch adversarial loss: 0.449402\n",
      "epoch 23; iter: 0; batch classifier loss: 0.313099; batch adversarial loss: 0.434670\n",
      "epoch 24; iter: 0; batch classifier loss: 0.296295; batch adversarial loss: 0.457939\n",
      "epoch 25; iter: 0; batch classifier loss: 0.327803; batch adversarial loss: 0.472740\n",
      "epoch 26; iter: 0; batch classifier loss: 0.315771; batch adversarial loss: 0.539500\n",
      "epoch 27; iter: 0; batch classifier loss: 0.348052; batch adversarial loss: 0.434998\n",
      "epoch 28; iter: 0; batch classifier loss: 0.248992; batch adversarial loss: 0.503126\n",
      "epoch 29; iter: 0; batch classifier loss: 0.297980; batch adversarial loss: 0.434062\n",
      "epoch 30; iter: 0; batch classifier loss: 0.230517; batch adversarial loss: 0.480834\n",
      "epoch 31; iter: 0; batch classifier loss: 0.183658; batch adversarial loss: 0.577381\n",
      "epoch 32; iter: 0; batch classifier loss: 0.284929; batch adversarial loss: 0.467437\n",
      "epoch 33; iter: 0; batch classifier loss: 0.327138; batch adversarial loss: 0.457060\n",
      "epoch 34; iter: 0; batch classifier loss: 0.242909; batch adversarial loss: 0.518570\n",
      "epoch 35; iter: 0; batch classifier loss: 0.206182; batch adversarial loss: 0.457715\n",
      "epoch 36; iter: 0; batch classifier loss: 0.233919; batch adversarial loss: 0.423914\n",
      "epoch 37; iter: 0; batch classifier loss: 0.271410; batch adversarial loss: 0.352329\n",
      "epoch 38; iter: 0; batch classifier loss: 0.211825; batch adversarial loss: 0.556901\n",
      "epoch 39; iter: 0; batch classifier loss: 0.221867; batch adversarial loss: 0.414800\n",
      "epoch 40; iter: 0; batch classifier loss: 0.255310; batch adversarial loss: 0.449067\n",
      "epoch 41; iter: 0; batch classifier loss: 0.202291; batch adversarial loss: 0.436129\n",
      "epoch 42; iter: 0; batch classifier loss: 0.214578; batch adversarial loss: 0.492911\n",
      "epoch 43; iter: 0; batch classifier loss: 0.171475; batch adversarial loss: 0.502472\n",
      "epoch 44; iter: 0; batch classifier loss: 0.221429; batch adversarial loss: 0.490463\n",
      "epoch 45; iter: 0; batch classifier loss: 0.199058; batch adversarial loss: 0.485506\n",
      "epoch 46; iter: 0; batch classifier loss: 0.196445; batch adversarial loss: 0.465072\n",
      "epoch 47; iter: 0; batch classifier loss: 0.149137; batch adversarial loss: 0.474003\n",
      "epoch 48; iter: 0; batch classifier loss: 0.180699; batch adversarial loss: 0.399693\n",
      "epoch 49; iter: 0; batch classifier loss: 0.218520; batch adversarial loss: 0.379088\n",
      "epoch 50; iter: 0; batch classifier loss: 0.189527; batch adversarial loss: 0.372338\n",
      "epoch 51; iter: 0; batch classifier loss: 0.131543; batch adversarial loss: 0.452622\n",
      "epoch 52; iter: 0; batch classifier loss: 0.135763; batch adversarial loss: 0.476170\n",
      "epoch 53; iter: 0; batch classifier loss: 0.192715; batch adversarial loss: 0.492401\n",
      "epoch 54; iter: 0; batch classifier loss: 0.154404; batch adversarial loss: 0.532844\n",
      "epoch 55; iter: 0; batch classifier loss: 0.171615; batch adversarial loss: 0.505989\n",
      "epoch 56; iter: 0; batch classifier loss: 0.169022; batch adversarial loss: 0.505734\n",
      "epoch 57; iter: 0; batch classifier loss: 0.162316; batch adversarial loss: 0.544493\n",
      "epoch 58; iter: 0; batch classifier loss: 0.154443; batch adversarial loss: 0.398277\n",
      "epoch 59; iter: 0; batch classifier loss: 0.134954; batch adversarial loss: 0.443444\n",
      "epoch 60; iter: 0; batch classifier loss: 0.224919; batch adversarial loss: 0.418506\n",
      "epoch 61; iter: 0; batch classifier loss: 0.191294; batch adversarial loss: 0.499785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.163560; batch adversarial loss: 0.470910\n",
      "epoch 63; iter: 0; batch classifier loss: 0.149791; batch adversarial loss: 0.392933\n",
      "epoch 64; iter: 0; batch classifier loss: 0.228127; batch adversarial loss: 0.473732\n",
      "epoch 65; iter: 0; batch classifier loss: 0.139375; batch adversarial loss: 0.583304\n",
      "epoch 66; iter: 0; batch classifier loss: 0.119381; batch adversarial loss: 0.475708\n",
      "epoch 67; iter: 0; batch classifier loss: 0.156212; batch adversarial loss: 0.482274\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071634; batch adversarial loss: 0.528915\n",
      "epoch 69; iter: 0; batch classifier loss: 0.127514; batch adversarial loss: 0.445808\n",
      "epoch 70; iter: 0; batch classifier loss: 0.159291; batch adversarial loss: 0.404067\n",
      "epoch 71; iter: 0; batch classifier loss: 0.137066; batch adversarial loss: 0.429852\n",
      "epoch 72; iter: 0; batch classifier loss: 0.118727; batch adversarial loss: 0.479918\n",
      "epoch 73; iter: 0; batch classifier loss: 0.148690; batch adversarial loss: 0.371475\n",
      "epoch 74; iter: 0; batch classifier loss: 0.168626; batch adversarial loss: 0.451949\n",
      "epoch 75; iter: 0; batch classifier loss: 0.141790; batch adversarial loss: 0.492373\n",
      "epoch 76; iter: 0; batch classifier loss: 0.174326; batch adversarial loss: 0.420967\n",
      "epoch 77; iter: 0; batch classifier loss: 0.148185; batch adversarial loss: 0.501890\n",
      "epoch 78; iter: 0; batch classifier loss: 0.113026; batch adversarial loss: 0.439835\n",
      "epoch 79; iter: 0; batch classifier loss: 0.150055; batch adversarial loss: 0.451077\n",
      "epoch 80; iter: 0; batch classifier loss: 0.165199; batch adversarial loss: 0.395272\n",
      "epoch 81; iter: 0; batch classifier loss: 0.128488; batch adversarial loss: 0.532157\n",
      "epoch 82; iter: 0; batch classifier loss: 0.107330; batch adversarial loss: 0.429746\n",
      "epoch 83; iter: 0; batch classifier loss: 0.090757; batch adversarial loss: 0.437553\n",
      "epoch 84; iter: 0; batch classifier loss: 0.128605; batch adversarial loss: 0.443139\n",
      "epoch 85; iter: 0; batch classifier loss: 0.113728; batch adversarial loss: 0.446915\n",
      "epoch 86; iter: 0; batch classifier loss: 0.141314; batch adversarial loss: 0.359421\n",
      "epoch 87; iter: 0; batch classifier loss: 0.119501; batch adversarial loss: 0.487480\n",
      "epoch 88; iter: 0; batch classifier loss: 0.095542; batch adversarial loss: 0.451094\n",
      "epoch 89; iter: 0; batch classifier loss: 0.114958; batch adversarial loss: 0.455064\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067460; batch adversarial loss: 0.427224\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077963; batch adversarial loss: 0.508235\n",
      "epoch 92; iter: 0; batch classifier loss: 0.163306; batch adversarial loss: 0.436048\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077338; batch adversarial loss: 0.341984\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083024; batch adversarial loss: 0.502033\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080809; batch adversarial loss: 0.468036\n",
      "epoch 96; iter: 0; batch classifier loss: 0.105546; batch adversarial loss: 0.406903\n",
      "epoch 97; iter: 0; batch classifier loss: 0.100124; batch adversarial loss: 0.581970\n",
      "epoch 98; iter: 0; batch classifier loss: 0.110359; batch adversarial loss: 0.478928\n",
      "epoch 99; iter: 0; batch classifier loss: 0.102966; batch adversarial loss: 0.434613\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064929; batch adversarial loss: 0.519888\n",
      "epoch 101; iter: 0; batch classifier loss: 0.034636; batch adversarial loss: 0.464738\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067462; batch adversarial loss: 0.427665\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061272; batch adversarial loss: 0.486533\n",
      "epoch 104; iter: 0; batch classifier loss: 0.091204; batch adversarial loss: 0.447761\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053698; batch adversarial loss: 0.513526\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059854; batch adversarial loss: 0.405490\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039224; batch adversarial loss: 0.361541\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041843; batch adversarial loss: 0.379266\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044237; batch adversarial loss: 0.489368\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058523; batch adversarial loss: 0.428293\n",
      "epoch 111; iter: 0; batch classifier loss: 0.072678; batch adversarial loss: 0.380891\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030381; batch adversarial loss: 0.454693\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027767; batch adversarial loss: 0.433842\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050393; batch adversarial loss: 0.398616\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049677; batch adversarial loss: 0.446443\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038521; batch adversarial loss: 0.491625\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040376; batch adversarial loss: 0.512085\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039695; batch adversarial loss: 0.462699\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031488; batch adversarial loss: 0.490530\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032832; batch adversarial loss: 0.502046\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038290; batch adversarial loss: 0.489263\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033952; batch adversarial loss: 0.322331\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043358; batch adversarial loss: 0.362264\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038104; batch adversarial loss: 0.481847\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028891; batch adversarial loss: 0.478538\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027207; batch adversarial loss: 0.393849\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051569; batch adversarial loss: 0.360659\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047129; batch adversarial loss: 0.405131\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037895; batch adversarial loss: 0.323437\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048805; batch adversarial loss: 0.433811\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021834; batch adversarial loss: 0.375388\n",
      "epoch 132; iter: 0; batch classifier loss: 0.018391; batch adversarial loss: 0.511649\n",
      "epoch 133; iter: 0; batch classifier loss: 0.059973; batch adversarial loss: 0.518339\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029995; batch adversarial loss: 0.540510\n",
      "epoch 135; iter: 0; batch classifier loss: 0.010045; batch adversarial loss: 0.473456\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016739; batch adversarial loss: 0.329809\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024336; batch adversarial loss: 0.509802\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026390; batch adversarial loss: 0.436394\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013785; batch adversarial loss: 0.496402\n",
      "epoch 140; iter: 0; batch classifier loss: 0.012131; batch adversarial loss: 0.448944\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016519; batch adversarial loss: 0.415983\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036655; batch adversarial loss: 0.472857\n",
      "epoch 143; iter: 0; batch classifier loss: 0.038186; batch adversarial loss: 0.354799\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028843; batch adversarial loss: 0.503951\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014186; batch adversarial loss: 0.410753\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032849; batch adversarial loss: 0.471308\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025319; batch adversarial loss: 0.476386\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018169; batch adversarial loss: 0.511530\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029274; batch adversarial loss: 0.514623\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030543; batch adversarial loss: 0.518634\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030702; batch adversarial loss: 0.383488\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017799; batch adversarial loss: 0.388547\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029125; batch adversarial loss: 0.443508\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016897; batch adversarial loss: 0.370311\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013018; batch adversarial loss: 0.476788\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020328; batch adversarial loss: 0.451985\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023470; batch adversarial loss: 0.414563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.004480; batch adversarial loss: 0.377598\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040073; batch adversarial loss: 0.442448\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009847; batch adversarial loss: 0.431672\n",
      "epoch 161; iter: 0; batch classifier loss: 0.004774; batch adversarial loss: 0.449220\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020879; batch adversarial loss: 0.444483\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023233; batch adversarial loss: 0.457999\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022431; batch adversarial loss: 0.494398\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016650; batch adversarial loss: 0.444645\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022997; batch adversarial loss: 0.448458\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011785; batch adversarial loss: 0.493905\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018706; batch adversarial loss: 0.424906\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026085; batch adversarial loss: 0.444856\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020660; batch adversarial loss: 0.321354\n",
      "epoch 171; iter: 0; batch classifier loss: 0.004545; batch adversarial loss: 0.390697\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028472; batch adversarial loss: 0.402493\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013629; batch adversarial loss: 0.403763\n",
      "epoch 174; iter: 0; batch classifier loss: 0.004318; batch adversarial loss: 0.593880\n",
      "epoch 175; iter: 0; batch classifier loss: 0.004576; batch adversarial loss: 0.414092\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027312; batch adversarial loss: 0.449820\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014450; batch adversarial loss: 0.397511\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029853; batch adversarial loss: 0.483604\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012005; batch adversarial loss: 0.501933\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006272; batch adversarial loss: 0.506573\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024325; batch adversarial loss: 0.439217\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027279; batch adversarial loss: 0.392467\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017441; batch adversarial loss: 0.470247\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015196; batch adversarial loss: 0.387605\n",
      "epoch 185; iter: 0; batch classifier loss: 0.039099; batch adversarial loss: 0.524186\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028234; batch adversarial loss: 0.376950\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006349; batch adversarial loss: 0.370859\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016310; batch adversarial loss: 0.429079\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013656; batch adversarial loss: 0.427612\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005089; batch adversarial loss: 0.496989\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021620; batch adversarial loss: 0.481704\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020383; batch adversarial loss: 0.408508\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014733; batch adversarial loss: 0.440442\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009566; batch adversarial loss: 0.444268\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028358; batch adversarial loss: 0.461443\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005648; batch adversarial loss: 0.287821\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020449; batch adversarial loss: 0.452488\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011014; batch adversarial loss: 0.432091\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007818; batch adversarial loss: 0.417312\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713536; batch adversarial loss: 1.205861\n",
      "epoch 1; iter: 0; batch classifier loss: 0.777613; batch adversarial loss: 1.520919\n",
      "epoch 2; iter: 0; batch classifier loss: 1.089612; batch adversarial loss: 1.510392\n",
      "epoch 3; iter: 0; batch classifier loss: 1.057066; batch adversarial loss: 1.394055\n",
      "epoch 4; iter: 0; batch classifier loss: 1.021916; batch adversarial loss: 1.283248\n",
      "epoch 5; iter: 0; batch classifier loss: 1.315554; batch adversarial loss: 1.202689\n",
      "epoch 6; iter: 0; batch classifier loss: 1.287174; batch adversarial loss: 1.081456\n",
      "epoch 7; iter: 0; batch classifier loss: 1.320788; batch adversarial loss: 0.996978\n",
      "epoch 8; iter: 0; batch classifier loss: 1.308975; batch adversarial loss: 0.911095\n",
      "epoch 9; iter: 0; batch classifier loss: 1.183244; batch adversarial loss: 0.841987\n",
      "epoch 10; iter: 0; batch classifier loss: 1.117921; batch adversarial loss: 0.763395\n",
      "epoch 11; iter: 0; batch classifier loss: 1.333760; batch adversarial loss: 0.707344\n",
      "epoch 12; iter: 0; batch classifier loss: 1.234364; batch adversarial loss: 0.684326\n",
      "epoch 13; iter: 0; batch classifier loss: 1.202111; batch adversarial loss: 0.613297\n",
      "epoch 14; iter: 0; batch classifier loss: 0.982858; batch adversarial loss: 0.578358\n",
      "epoch 15; iter: 0; batch classifier loss: 1.020389; batch adversarial loss: 0.567019\n",
      "epoch 16; iter: 0; batch classifier loss: 0.629236; batch adversarial loss: 0.540395\n",
      "epoch 17; iter: 0; batch classifier loss: 0.552338; batch adversarial loss: 0.501817\n",
      "epoch 18; iter: 0; batch classifier loss: 0.347493; batch adversarial loss: 0.523464\n",
      "epoch 19; iter: 0; batch classifier loss: 0.267776; batch adversarial loss: 0.534792\n",
      "epoch 20; iter: 0; batch classifier loss: 0.330702; batch adversarial loss: 0.500130\n",
      "epoch 21; iter: 0; batch classifier loss: 0.259705; batch adversarial loss: 0.508597\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226357; batch adversarial loss: 0.527345\n",
      "epoch 23; iter: 0; batch classifier loss: 0.229686; batch adversarial loss: 0.496110\n",
      "epoch 24; iter: 0; batch classifier loss: 0.210071; batch adversarial loss: 0.443370\n",
      "epoch 25; iter: 0; batch classifier loss: 0.164529; batch adversarial loss: 0.536262\n",
      "epoch 26; iter: 0; batch classifier loss: 0.196848; batch adversarial loss: 0.456631\n",
      "epoch 27; iter: 0; batch classifier loss: 0.164400; batch adversarial loss: 0.512701\n",
      "epoch 28; iter: 0; batch classifier loss: 0.169570; batch adversarial loss: 0.538207\n",
      "epoch 29; iter: 0; batch classifier loss: 0.152410; batch adversarial loss: 0.496267\n",
      "epoch 30; iter: 0; batch classifier loss: 0.239761; batch adversarial loss: 0.475133\n",
      "epoch 31; iter: 0; batch classifier loss: 0.201532; batch adversarial loss: 0.449341\n",
      "epoch 32; iter: 0; batch classifier loss: 0.210522; batch adversarial loss: 0.526135\n",
      "epoch 33; iter: 0; batch classifier loss: 0.138503; batch adversarial loss: 0.439660\n",
      "epoch 34; iter: 0; batch classifier loss: 0.180203; batch adversarial loss: 0.442175\n",
      "epoch 35; iter: 0; batch classifier loss: 0.177946; batch adversarial loss: 0.529060\n",
      "epoch 36; iter: 0; batch classifier loss: 0.156217; batch adversarial loss: 0.535162\n",
      "epoch 37; iter: 0; batch classifier loss: 0.205962; batch adversarial loss: 0.431327\n",
      "epoch 38; iter: 0; batch classifier loss: 0.229681; batch adversarial loss: 0.424414\n",
      "epoch 39; iter: 0; batch classifier loss: 0.224242; batch adversarial loss: 0.485056\n",
      "epoch 40; iter: 0; batch classifier loss: 0.184501; batch adversarial loss: 0.489926\n",
      "epoch 41; iter: 0; batch classifier loss: 0.141271; batch adversarial loss: 0.570861\n",
      "epoch 42; iter: 0; batch classifier loss: 0.190356; batch adversarial loss: 0.484352\n",
      "epoch 43; iter: 0; batch classifier loss: 0.183101; batch adversarial loss: 0.539218\n",
      "epoch 44; iter: 0; batch classifier loss: 0.114954; batch adversarial loss: 0.498502\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124268; batch adversarial loss: 0.599806\n",
      "epoch 46; iter: 0; batch classifier loss: 0.178943; batch adversarial loss: 0.431770\n",
      "epoch 47; iter: 0; batch classifier loss: 0.194254; batch adversarial loss: 0.422617\n",
      "epoch 48; iter: 0; batch classifier loss: 0.158977; batch adversarial loss: 0.426518\n",
      "epoch 49; iter: 0; batch classifier loss: 0.170738; batch adversarial loss: 0.414384\n",
      "epoch 50; iter: 0; batch classifier loss: 0.152687; batch adversarial loss: 0.455350\n",
      "epoch 51; iter: 0; batch classifier loss: 0.199237; batch adversarial loss: 0.470031\n",
      "epoch 52; iter: 0; batch classifier loss: 0.125497; batch adversarial loss: 0.405722\n",
      "epoch 53; iter: 0; batch classifier loss: 0.115400; batch adversarial loss: 0.473127\n",
      "epoch 54; iter: 0; batch classifier loss: 0.193206; batch adversarial loss: 0.475113\n",
      "epoch 55; iter: 0; batch classifier loss: 0.115929; batch adversarial loss: 0.497754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.102498; batch adversarial loss: 0.483993\n",
      "epoch 57; iter: 0; batch classifier loss: 0.146636; batch adversarial loss: 0.426111\n",
      "epoch 58; iter: 0; batch classifier loss: 0.153243; batch adversarial loss: 0.522956\n",
      "epoch 59; iter: 0; batch classifier loss: 0.130455; batch adversarial loss: 0.485286\n",
      "epoch 60; iter: 0; batch classifier loss: 0.142353; batch adversarial loss: 0.498335\n",
      "epoch 61; iter: 0; batch classifier loss: 0.141288; batch adversarial loss: 0.539405\n",
      "epoch 62; iter: 0; batch classifier loss: 0.135882; batch adversarial loss: 0.486146\n",
      "epoch 63; iter: 0; batch classifier loss: 0.170848; batch adversarial loss: 0.505739\n",
      "epoch 64; iter: 0; batch classifier loss: 0.120120; batch adversarial loss: 0.403628\n",
      "epoch 65; iter: 0; batch classifier loss: 0.138113; batch adversarial loss: 0.514882\n",
      "epoch 66; iter: 0; batch classifier loss: 0.177058; batch adversarial loss: 0.506722\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171407; batch adversarial loss: 0.516253\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082723; batch adversarial loss: 0.487919\n",
      "epoch 69; iter: 0; batch classifier loss: 0.145667; batch adversarial loss: 0.351450\n",
      "epoch 70; iter: 0; batch classifier loss: 0.157982; batch adversarial loss: 0.492997\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115929; batch adversarial loss: 0.535834\n",
      "epoch 72; iter: 0; batch classifier loss: 0.151537; batch adversarial loss: 0.386421\n",
      "epoch 73; iter: 0; batch classifier loss: 0.175318; batch adversarial loss: 0.451626\n",
      "epoch 74; iter: 0; batch classifier loss: 0.148924; batch adversarial loss: 0.518341\n",
      "epoch 75; iter: 0; batch classifier loss: 0.140877; batch adversarial loss: 0.463513\n",
      "epoch 76; iter: 0; batch classifier loss: 0.158661; batch adversarial loss: 0.371134\n",
      "epoch 77; iter: 0; batch classifier loss: 0.106546; batch adversarial loss: 0.391238\n",
      "epoch 78; iter: 0; batch classifier loss: 0.200791; batch adversarial loss: 0.384386\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082479; batch adversarial loss: 0.485740\n",
      "epoch 80; iter: 0; batch classifier loss: 0.097074; batch adversarial loss: 0.566061\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083669; batch adversarial loss: 0.464212\n",
      "epoch 82; iter: 0; batch classifier loss: 0.093603; batch adversarial loss: 0.447411\n",
      "epoch 83; iter: 0; batch classifier loss: 0.096011; batch adversarial loss: 0.529359\n",
      "epoch 84; iter: 0; batch classifier loss: 0.136507; batch adversarial loss: 0.488798\n",
      "epoch 85; iter: 0; batch classifier loss: 0.098054; batch adversarial loss: 0.537415\n",
      "epoch 86; iter: 0; batch classifier loss: 0.124191; batch adversarial loss: 0.360648\n",
      "epoch 87; iter: 0; batch classifier loss: 0.111842; batch adversarial loss: 0.441773\n",
      "epoch 88; iter: 0; batch classifier loss: 0.132045; batch adversarial loss: 0.497599\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098907; batch adversarial loss: 0.397110\n",
      "epoch 90; iter: 0; batch classifier loss: 0.084760; batch adversarial loss: 0.503382\n",
      "epoch 91; iter: 0; batch classifier loss: 0.127192; batch adversarial loss: 0.486262\n",
      "epoch 92; iter: 0; batch classifier loss: 0.160594; batch adversarial loss: 0.525956\n",
      "epoch 93; iter: 0; batch classifier loss: 0.106018; batch adversarial loss: 0.425475\n",
      "epoch 94; iter: 0; batch classifier loss: 0.110200; batch adversarial loss: 0.461827\n",
      "epoch 95; iter: 0; batch classifier loss: 0.171913; batch adversarial loss: 0.471485\n",
      "epoch 96; iter: 0; batch classifier loss: 0.104052; batch adversarial loss: 0.541140\n",
      "epoch 97; iter: 0; batch classifier loss: 0.116382; batch adversarial loss: 0.596140\n",
      "epoch 98; iter: 0; batch classifier loss: 0.117903; batch adversarial loss: 0.446743\n",
      "epoch 99; iter: 0; batch classifier loss: 0.099546; batch adversarial loss: 0.437055\n",
      "epoch 100; iter: 0; batch classifier loss: 0.103854; batch adversarial loss: 0.433313\n",
      "epoch 101; iter: 0; batch classifier loss: 0.102489; batch adversarial loss: 0.454957\n",
      "epoch 102; iter: 0; batch classifier loss: 0.164342; batch adversarial loss: 0.459846\n",
      "epoch 103; iter: 0; batch classifier loss: 0.145358; batch adversarial loss: 0.486805\n",
      "epoch 104; iter: 0; batch classifier loss: 0.076206; batch adversarial loss: 0.533023\n",
      "epoch 105; iter: 0; batch classifier loss: 0.142790; batch adversarial loss: 0.437180\n",
      "epoch 106; iter: 0; batch classifier loss: 0.154273; batch adversarial loss: 0.576599\n",
      "epoch 107; iter: 0; batch classifier loss: 0.097454; batch adversarial loss: 0.466754\n",
      "epoch 108; iter: 0; batch classifier loss: 0.123530; batch adversarial loss: 0.495219\n",
      "epoch 109; iter: 0; batch classifier loss: 0.102111; batch adversarial loss: 0.412354\n",
      "epoch 110; iter: 0; batch classifier loss: 0.141994; batch adversarial loss: 0.432328\n",
      "epoch 111; iter: 0; batch classifier loss: 0.134358; batch adversarial loss: 0.448382\n",
      "epoch 112; iter: 0; batch classifier loss: 0.095961; batch adversarial loss: 0.515200\n",
      "epoch 113; iter: 0; batch classifier loss: 0.110281; batch adversarial loss: 0.443195\n",
      "epoch 114; iter: 0; batch classifier loss: 0.143911; batch adversarial loss: 0.484324\n",
      "epoch 115; iter: 0; batch classifier loss: 0.096652; batch adversarial loss: 0.454378\n",
      "epoch 116; iter: 0; batch classifier loss: 0.120907; batch adversarial loss: 0.337725\n",
      "epoch 117; iter: 0; batch classifier loss: 0.230582; batch adversarial loss: 0.433413\n",
      "epoch 118; iter: 0; batch classifier loss: 0.098973; batch adversarial loss: 0.372336\n",
      "epoch 119; iter: 0; batch classifier loss: 0.134833; batch adversarial loss: 0.512490\n",
      "epoch 120; iter: 0; batch classifier loss: 0.128368; batch adversarial loss: 0.408960\n",
      "epoch 121; iter: 0; batch classifier loss: 0.094815; batch adversarial loss: 0.545971\n",
      "epoch 122; iter: 0; batch classifier loss: 0.101575; batch adversarial loss: 0.443191\n",
      "epoch 123; iter: 0; batch classifier loss: 0.082734; batch adversarial loss: 0.453093\n",
      "epoch 124; iter: 0; batch classifier loss: 0.136759; batch adversarial loss: 0.373487\n",
      "epoch 125; iter: 0; batch classifier loss: 0.079972; batch adversarial loss: 0.507778\n",
      "epoch 126; iter: 0; batch classifier loss: 0.110300; batch adversarial loss: 0.475080\n",
      "epoch 127; iter: 0; batch classifier loss: 0.101948; batch adversarial loss: 0.391123\n",
      "epoch 128; iter: 0; batch classifier loss: 0.118144; batch adversarial loss: 0.432350\n",
      "epoch 129; iter: 0; batch classifier loss: 0.101293; batch adversarial loss: 0.394566\n",
      "epoch 130; iter: 0; batch classifier loss: 0.113137; batch adversarial loss: 0.467039\n",
      "epoch 131; iter: 0; batch classifier loss: 0.122271; batch adversarial loss: 0.487472\n",
      "epoch 132; iter: 0; batch classifier loss: 0.122621; batch adversarial loss: 0.431704\n",
      "epoch 133; iter: 0; batch classifier loss: 0.161776; batch adversarial loss: 0.438211\n",
      "epoch 134; iter: 0; batch classifier loss: 0.153974; batch adversarial loss: 0.508595\n",
      "epoch 135; iter: 0; batch classifier loss: 0.083663; batch adversarial loss: 0.510181\n",
      "epoch 136; iter: 0; batch classifier loss: 0.168225; batch adversarial loss: 0.509526\n",
      "epoch 137; iter: 0; batch classifier loss: 0.140772; batch adversarial loss: 0.426260\n",
      "epoch 138; iter: 0; batch classifier loss: 0.140955; batch adversarial loss: 0.533807\n",
      "epoch 139; iter: 0; batch classifier loss: 0.123281; batch adversarial loss: 0.428314\n",
      "epoch 140; iter: 0; batch classifier loss: 0.142306; batch adversarial loss: 0.490090\n",
      "epoch 141; iter: 0; batch classifier loss: 0.115108; batch adversarial loss: 0.547755\n",
      "epoch 142; iter: 0; batch classifier loss: 0.135175; batch adversarial loss: 0.426255\n",
      "epoch 143; iter: 0; batch classifier loss: 0.193462; batch adversarial loss: 0.464790\n",
      "epoch 144; iter: 0; batch classifier loss: 0.099706; batch adversarial loss: 0.569635\n",
      "epoch 145; iter: 0; batch classifier loss: 0.085643; batch adversarial loss: 0.519681\n",
      "epoch 146; iter: 0; batch classifier loss: 0.104528; batch adversarial loss: 0.471428\n",
      "epoch 147; iter: 0; batch classifier loss: 0.105795; batch adversarial loss: 0.464418\n",
      "epoch 148; iter: 0; batch classifier loss: 0.117648; batch adversarial loss: 0.521471\n",
      "epoch 149; iter: 0; batch classifier loss: 0.114117; batch adversarial loss: 0.527047\n",
      "epoch 150; iter: 0; batch classifier loss: 0.159861; batch adversarial loss: 0.460703\n",
      "epoch 151; iter: 0; batch classifier loss: 0.123703; batch adversarial loss: 0.499519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.106779; batch adversarial loss: 0.452098\n",
      "epoch 153; iter: 0; batch classifier loss: 0.135326; batch adversarial loss: 0.463004\n",
      "epoch 154; iter: 0; batch classifier loss: 0.136970; batch adversarial loss: 0.507988\n",
      "epoch 155; iter: 0; batch classifier loss: 0.087699; batch adversarial loss: 0.456321\n",
      "epoch 156; iter: 0; batch classifier loss: 0.157578; batch adversarial loss: 0.497650\n",
      "epoch 157; iter: 0; batch classifier loss: 0.089477; batch adversarial loss: 0.462838\n",
      "epoch 158; iter: 0; batch classifier loss: 0.267826; batch adversarial loss: 0.414730\n",
      "epoch 159; iter: 0; batch classifier loss: 0.114976; batch adversarial loss: 0.436862\n",
      "epoch 160; iter: 0; batch classifier loss: 0.177772; batch adversarial loss: 0.489606\n",
      "epoch 161; iter: 0; batch classifier loss: 0.224961; batch adversarial loss: 0.387378\n",
      "epoch 162; iter: 0; batch classifier loss: 0.171907; batch adversarial loss: 0.435623\n",
      "epoch 163; iter: 0; batch classifier loss: 0.163507; batch adversarial loss: 0.412482\n",
      "epoch 164; iter: 0; batch classifier loss: 0.122903; batch adversarial loss: 0.519787\n",
      "epoch 165; iter: 0; batch classifier loss: 0.191587; batch adversarial loss: 0.482491\n",
      "epoch 166; iter: 0; batch classifier loss: 0.221988; batch adversarial loss: 0.437961\n",
      "epoch 167; iter: 0; batch classifier loss: 0.161601; batch adversarial loss: 0.517076\n",
      "epoch 168; iter: 0; batch classifier loss: 0.167992; batch adversarial loss: 0.516158\n",
      "epoch 169; iter: 0; batch classifier loss: 0.202840; batch adversarial loss: 0.482736\n",
      "epoch 170; iter: 0; batch classifier loss: 0.183086; batch adversarial loss: 0.447399\n",
      "epoch 171; iter: 0; batch classifier loss: 0.284811; batch adversarial loss: 0.457994\n",
      "epoch 172; iter: 0; batch classifier loss: 0.223286; batch adversarial loss: 0.483674\n",
      "epoch 173; iter: 0; batch classifier loss: 0.155305; batch adversarial loss: 0.493865\n",
      "epoch 174; iter: 0; batch classifier loss: 0.239432; batch adversarial loss: 0.411947\n",
      "epoch 175; iter: 0; batch classifier loss: 0.078486; batch adversarial loss: 0.423624\n",
      "epoch 176; iter: 0; batch classifier loss: 0.048990; batch adversarial loss: 0.515032\n",
      "epoch 177; iter: 0; batch classifier loss: 0.057353; batch adversarial loss: 0.457420\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025523; batch adversarial loss: 0.512531\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028412; batch adversarial loss: 0.477986\n",
      "epoch 180; iter: 0; batch classifier loss: 0.059257; batch adversarial loss: 0.472899\n",
      "epoch 181; iter: 0; batch classifier loss: 0.082074; batch adversarial loss: 0.452263\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042960; batch adversarial loss: 0.436750\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030632; batch adversarial loss: 0.491634\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025396; batch adversarial loss: 0.444295\n",
      "epoch 185; iter: 0; batch classifier loss: 0.045429; batch adversarial loss: 0.450243\n",
      "epoch 186; iter: 0; batch classifier loss: 0.053786; batch adversarial loss: 0.464338\n",
      "epoch 187; iter: 0; batch classifier loss: 0.075203; batch adversarial loss: 0.460133\n",
      "epoch 188; iter: 0; batch classifier loss: 0.090422; batch adversarial loss: 0.454682\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035154; batch adversarial loss: 0.423589\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026507; batch adversarial loss: 0.503657\n",
      "epoch 191; iter: 0; batch classifier loss: 0.056479; batch adversarial loss: 0.408162\n",
      "epoch 192; iter: 0; batch classifier loss: 0.062748; batch adversarial loss: 0.463915\n",
      "epoch 193; iter: 0; batch classifier loss: 0.040792; batch adversarial loss: 0.470553\n",
      "epoch 194; iter: 0; batch classifier loss: 0.055976; batch adversarial loss: 0.484131\n",
      "epoch 195; iter: 0; batch classifier loss: 0.055903; batch adversarial loss: 0.481656\n",
      "epoch 196; iter: 0; batch classifier loss: 0.057530; batch adversarial loss: 0.350958\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039886; batch adversarial loss: 0.515750\n",
      "epoch 198; iter: 0; batch classifier loss: 0.068757; batch adversarial loss: 0.441709\n",
      "epoch 199; iter: 0; batch classifier loss: 0.049183; batch adversarial loss: 0.452199\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708172; batch adversarial loss: 0.550733\n",
      "epoch 1; iter: 0; batch classifier loss: 0.466652; batch adversarial loss: 0.646873\n",
      "epoch 2; iter: 0; batch classifier loss: 0.369002; batch adversarial loss: 0.587073\n",
      "epoch 3; iter: 0; batch classifier loss: 0.384483; batch adversarial loss: 0.566760\n",
      "epoch 4; iter: 0; batch classifier loss: 0.349168; batch adversarial loss: 0.648719\n",
      "epoch 5; iter: 0; batch classifier loss: 0.413863; batch adversarial loss: 0.597163\n",
      "epoch 6; iter: 0; batch classifier loss: 0.468128; batch adversarial loss: 0.558470\n",
      "epoch 7; iter: 0; batch classifier loss: 0.440194; batch adversarial loss: 0.580677\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559697; batch adversarial loss: 0.575886\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573354; batch adversarial loss: 0.586528\n",
      "epoch 10; iter: 0; batch classifier loss: 0.528568; batch adversarial loss: 0.549360\n",
      "epoch 11; iter: 0; batch classifier loss: 0.446920; batch adversarial loss: 0.521797\n",
      "epoch 12; iter: 0; batch classifier loss: 0.317035; batch adversarial loss: 0.528577\n",
      "epoch 13; iter: 0; batch classifier loss: 0.279863; batch adversarial loss: 0.492739\n",
      "epoch 14; iter: 0; batch classifier loss: 0.277840; batch adversarial loss: 0.448102\n",
      "epoch 15; iter: 0; batch classifier loss: 0.277168; batch adversarial loss: 0.450569\n",
      "epoch 16; iter: 0; batch classifier loss: 0.220153; batch adversarial loss: 0.468295\n",
      "epoch 17; iter: 0; batch classifier loss: 0.257885; batch adversarial loss: 0.541014\n",
      "epoch 18; iter: 0; batch classifier loss: 0.205984; batch adversarial loss: 0.520775\n",
      "epoch 19; iter: 0; batch classifier loss: 0.201635; batch adversarial loss: 0.496931\n",
      "epoch 20; iter: 0; batch classifier loss: 0.197239; batch adversarial loss: 0.455780\n",
      "epoch 21; iter: 0; batch classifier loss: 0.189610; batch adversarial loss: 0.518374\n",
      "epoch 22; iter: 0; batch classifier loss: 0.183889; batch adversarial loss: 0.456482\n",
      "epoch 23; iter: 0; batch classifier loss: 0.203155; batch adversarial loss: 0.552441\n",
      "epoch 24; iter: 0; batch classifier loss: 0.246631; batch adversarial loss: 0.423166\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215689; batch adversarial loss: 0.473431\n",
      "epoch 26; iter: 0; batch classifier loss: 0.166081; batch adversarial loss: 0.460318\n",
      "epoch 27; iter: 0; batch classifier loss: 0.120714; batch adversarial loss: 0.561794\n",
      "epoch 28; iter: 0; batch classifier loss: 0.161940; batch adversarial loss: 0.476537\n",
      "epoch 29; iter: 0; batch classifier loss: 0.154062; batch adversarial loss: 0.439900\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138531; batch adversarial loss: 0.432454\n",
      "epoch 31; iter: 0; batch classifier loss: 0.130330; batch adversarial loss: 0.483816\n",
      "epoch 32; iter: 0; batch classifier loss: 0.167545; batch adversarial loss: 0.415875\n",
      "epoch 33; iter: 0; batch classifier loss: 0.178157; batch adversarial loss: 0.438609\n",
      "epoch 34; iter: 0; batch classifier loss: 0.150922; batch adversarial loss: 0.413083\n",
      "epoch 35; iter: 0; batch classifier loss: 0.083941; batch adversarial loss: 0.432708\n",
      "epoch 36; iter: 0; batch classifier loss: 0.166261; batch adversarial loss: 0.421287\n",
      "epoch 37; iter: 0; batch classifier loss: 0.179563; batch adversarial loss: 0.422092\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115673; batch adversarial loss: 0.518902\n",
      "epoch 39; iter: 0; batch classifier loss: 0.115240; batch adversarial loss: 0.499911\n",
      "epoch 40; iter: 0; batch classifier loss: 0.172086; batch adversarial loss: 0.427094\n",
      "epoch 41; iter: 0; batch classifier loss: 0.142679; batch adversarial loss: 0.499371\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103583; batch adversarial loss: 0.543830\n",
      "epoch 43; iter: 0; batch classifier loss: 0.138527; batch adversarial loss: 0.471710\n",
      "epoch 44; iter: 0; batch classifier loss: 0.111759; batch adversarial loss: 0.506786\n",
      "epoch 45; iter: 0; batch classifier loss: 0.116286; batch adversarial loss: 0.467850\n",
      "epoch 46; iter: 0; batch classifier loss: 0.111270; batch adversarial loss: 0.437082\n",
      "epoch 47; iter: 0; batch classifier loss: 0.150532; batch adversarial loss: 0.452985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.147022; batch adversarial loss: 0.374609\n",
      "epoch 49; iter: 0; batch classifier loss: 0.134243; batch adversarial loss: 0.432705\n",
      "epoch 50; iter: 0; batch classifier loss: 0.158325; batch adversarial loss: 0.483751\n",
      "epoch 51; iter: 0; batch classifier loss: 0.141874; batch adversarial loss: 0.403655\n",
      "epoch 52; iter: 0; batch classifier loss: 0.201447; batch adversarial loss: 0.425408\n",
      "epoch 53; iter: 0; batch classifier loss: 0.127542; batch adversarial loss: 0.396664\n",
      "epoch 54; iter: 0; batch classifier loss: 0.077017; batch adversarial loss: 0.531561\n",
      "epoch 55; iter: 0; batch classifier loss: 0.130837; batch adversarial loss: 0.529348\n",
      "epoch 56; iter: 0; batch classifier loss: 0.127210; batch adversarial loss: 0.506287\n",
      "epoch 57; iter: 0; batch classifier loss: 0.129478; batch adversarial loss: 0.477755\n",
      "epoch 58; iter: 0; batch classifier loss: 0.107748; batch adversarial loss: 0.511356\n",
      "epoch 59; iter: 0; batch classifier loss: 0.097908; batch adversarial loss: 0.399330\n",
      "epoch 60; iter: 0; batch classifier loss: 0.149833; batch adversarial loss: 0.563328\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114367; batch adversarial loss: 0.458091\n",
      "epoch 62; iter: 0; batch classifier loss: 0.072951; batch adversarial loss: 0.494804\n",
      "epoch 63; iter: 0; batch classifier loss: 0.129998; batch adversarial loss: 0.482452\n",
      "epoch 64; iter: 0; batch classifier loss: 0.132035; batch adversarial loss: 0.458882\n",
      "epoch 65; iter: 0; batch classifier loss: 0.162099; batch adversarial loss: 0.483681\n",
      "epoch 66; iter: 0; batch classifier loss: 0.113177; batch adversarial loss: 0.410019\n",
      "epoch 67; iter: 0; batch classifier loss: 0.165747; batch adversarial loss: 0.407639\n",
      "epoch 68; iter: 0; batch classifier loss: 0.103686; batch adversarial loss: 0.534444\n",
      "epoch 69; iter: 0; batch classifier loss: 0.136677; batch adversarial loss: 0.402605\n",
      "epoch 70; iter: 0; batch classifier loss: 0.138498; batch adversarial loss: 0.564175\n",
      "epoch 71; iter: 0; batch classifier loss: 0.145600; batch adversarial loss: 0.508233\n",
      "epoch 72; iter: 0; batch classifier loss: 0.159160; batch adversarial loss: 0.485196\n",
      "epoch 73; iter: 0; batch classifier loss: 0.144740; batch adversarial loss: 0.442428\n",
      "epoch 74; iter: 0; batch classifier loss: 0.172943; batch adversarial loss: 0.383723\n",
      "epoch 75; iter: 0; batch classifier loss: 0.090568; batch adversarial loss: 0.531892\n",
      "epoch 76; iter: 0; batch classifier loss: 0.142461; batch adversarial loss: 0.521249\n",
      "epoch 77; iter: 0; batch classifier loss: 0.185302; batch adversarial loss: 0.469158\n",
      "epoch 78; iter: 0; batch classifier loss: 0.106329; batch adversarial loss: 0.395754\n",
      "epoch 79; iter: 0; batch classifier loss: 0.172141; batch adversarial loss: 0.421459\n",
      "epoch 80; iter: 0; batch classifier loss: 0.116011; batch adversarial loss: 0.481927\n",
      "epoch 81; iter: 0; batch classifier loss: 0.137887; batch adversarial loss: 0.498999\n",
      "epoch 82; iter: 0; batch classifier loss: 0.109560; batch adversarial loss: 0.434384\n",
      "epoch 83; iter: 0; batch classifier loss: 0.144064; batch adversarial loss: 0.431922\n",
      "epoch 84; iter: 0; batch classifier loss: 0.150485; batch adversarial loss: 0.372144\n",
      "epoch 85; iter: 0; batch classifier loss: 0.160317; batch adversarial loss: 0.459674\n",
      "epoch 86; iter: 0; batch classifier loss: 0.103639; batch adversarial loss: 0.481903\n",
      "epoch 87; iter: 0; batch classifier loss: 0.070176; batch adversarial loss: 0.509596\n",
      "epoch 88; iter: 0; batch classifier loss: 0.124522; batch adversarial loss: 0.492553\n",
      "epoch 89; iter: 0; batch classifier loss: 0.142512; batch adversarial loss: 0.433964\n",
      "epoch 90; iter: 0; batch classifier loss: 0.127317; batch adversarial loss: 0.448508\n",
      "epoch 91; iter: 0; batch classifier loss: 0.142064; batch adversarial loss: 0.445413\n",
      "epoch 92; iter: 0; batch classifier loss: 0.100474; batch adversarial loss: 0.423114\n",
      "epoch 93; iter: 0; batch classifier loss: 0.215950; batch adversarial loss: 0.409150\n",
      "epoch 94; iter: 0; batch classifier loss: 0.144358; batch adversarial loss: 0.406058\n",
      "epoch 95; iter: 0; batch classifier loss: 0.145366; batch adversarial loss: 0.372073\n",
      "epoch 96; iter: 0; batch classifier loss: 0.100050; batch adversarial loss: 0.421773\n",
      "epoch 97; iter: 0; batch classifier loss: 0.094339; batch adversarial loss: 0.492787\n",
      "epoch 98; iter: 0; batch classifier loss: 0.147287; batch adversarial loss: 0.447955\n",
      "epoch 99; iter: 0; batch classifier loss: 0.103836; batch adversarial loss: 0.433227\n",
      "epoch 100; iter: 0; batch classifier loss: 0.141134; batch adversarial loss: 0.344490\n",
      "epoch 101; iter: 0; batch classifier loss: 0.155053; batch adversarial loss: 0.422468\n",
      "epoch 102; iter: 0; batch classifier loss: 0.090199; batch adversarial loss: 0.446548\n",
      "epoch 103; iter: 0; batch classifier loss: 0.115897; batch adversarial loss: 0.440531\n",
      "epoch 104; iter: 0; batch classifier loss: 0.120991; batch adversarial loss: 0.371281\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055640; batch adversarial loss: 0.459945\n",
      "epoch 106; iter: 0; batch classifier loss: 0.109626; batch adversarial loss: 0.431061\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072985; batch adversarial loss: 0.425626\n",
      "epoch 108; iter: 0; batch classifier loss: 0.126404; batch adversarial loss: 0.596395\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051244; batch adversarial loss: 0.496160\n",
      "epoch 110; iter: 0; batch classifier loss: 0.078818; batch adversarial loss: 0.391453\n",
      "epoch 111; iter: 0; batch classifier loss: 0.071833; batch adversarial loss: 0.354947\n",
      "epoch 112; iter: 0; batch classifier loss: 0.105223; batch adversarial loss: 0.409000\n",
      "epoch 113; iter: 0; batch classifier loss: 0.102593; batch adversarial loss: 0.392346\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050681; batch adversarial loss: 0.491946\n",
      "epoch 115; iter: 0; batch classifier loss: 0.081335; batch adversarial loss: 0.444937\n",
      "epoch 116; iter: 0; batch classifier loss: 0.076477; batch adversarial loss: 0.458697\n",
      "epoch 117; iter: 0; batch classifier loss: 0.065549; batch adversarial loss: 0.451250\n",
      "epoch 118; iter: 0; batch classifier loss: 0.067689; batch adversarial loss: 0.399540\n",
      "epoch 119; iter: 0; batch classifier loss: 0.095522; batch adversarial loss: 0.407424\n",
      "epoch 120; iter: 0; batch classifier loss: 0.076621; batch adversarial loss: 0.468889\n",
      "epoch 121; iter: 0; batch classifier loss: 0.070233; batch adversarial loss: 0.405160\n",
      "epoch 122; iter: 0; batch classifier loss: 0.081693; batch adversarial loss: 0.492020\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064546; batch adversarial loss: 0.476317\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029045; batch adversarial loss: 0.509749\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058921; batch adversarial loss: 0.446167\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036542; batch adversarial loss: 0.480830\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026404; batch adversarial loss: 0.505318\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036425; batch adversarial loss: 0.476194\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056602; batch adversarial loss: 0.463416\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057697; batch adversarial loss: 0.446283\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047996; batch adversarial loss: 0.448287\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031297; batch adversarial loss: 0.389060\n",
      "epoch 133; iter: 0; batch classifier loss: 0.016698; batch adversarial loss: 0.402714\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040675; batch adversarial loss: 0.391792\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024689; batch adversarial loss: 0.407066\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034390; batch adversarial loss: 0.459668\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023171; batch adversarial loss: 0.562789\n",
      "epoch 138; iter: 0; batch classifier loss: 0.050164; batch adversarial loss: 0.524504\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034292; batch adversarial loss: 0.394040\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032290; batch adversarial loss: 0.467486\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027483; batch adversarial loss: 0.462383\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030539; batch adversarial loss: 0.426992\n",
      "epoch 143; iter: 0; batch classifier loss: 0.048206; batch adversarial loss: 0.449000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.030158; batch adversarial loss: 0.440050\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032199; batch adversarial loss: 0.462784\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031609; batch adversarial loss: 0.489126\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032761; batch adversarial loss: 0.482896\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013121; batch adversarial loss: 0.512357\n",
      "epoch 149; iter: 0; batch classifier loss: 0.049640; batch adversarial loss: 0.425946\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026236; batch adversarial loss: 0.474506\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015323; batch adversarial loss: 0.552517\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045280; batch adversarial loss: 0.492446\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022568; batch adversarial loss: 0.478047\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014943; batch adversarial loss: 0.497116\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019311; batch adversarial loss: 0.367613\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014810; batch adversarial loss: 0.469605\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032204; batch adversarial loss: 0.497961\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013688; batch adversarial loss: 0.563957\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037179; batch adversarial loss: 0.413433\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025805; batch adversarial loss: 0.465861\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019446; batch adversarial loss: 0.410053\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029164; batch adversarial loss: 0.402967\n",
      "epoch 163; iter: 0; batch classifier loss: 0.048782; batch adversarial loss: 0.420283\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034205; batch adversarial loss: 0.420808\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026799; batch adversarial loss: 0.564792\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018900; batch adversarial loss: 0.450817\n",
      "epoch 167; iter: 0; batch classifier loss: 0.040919; batch adversarial loss: 0.479644\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025853; batch adversarial loss: 0.448618\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037403; batch adversarial loss: 0.479863\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017674; batch adversarial loss: 0.403533\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015180; batch adversarial loss: 0.464835\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017922; batch adversarial loss: 0.403834\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029314; batch adversarial loss: 0.421105\n",
      "epoch 174; iter: 0; batch classifier loss: 0.034789; batch adversarial loss: 0.444091\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010749; batch adversarial loss: 0.418969\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007963; batch adversarial loss: 0.457914\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021989; batch adversarial loss: 0.449124\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010432; batch adversarial loss: 0.479874\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006901; batch adversarial loss: 0.480580\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035511; batch adversarial loss: 0.455601\n",
      "epoch 181; iter: 0; batch classifier loss: 0.043614; batch adversarial loss: 0.386286\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019135; batch adversarial loss: 0.369830\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008953; batch adversarial loss: 0.418707\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012700; batch adversarial loss: 0.577905\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013919; batch adversarial loss: 0.428056\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011728; batch adversarial loss: 0.440182\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006245; batch adversarial loss: 0.320845\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008876; batch adversarial loss: 0.488156\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013222; batch adversarial loss: 0.589877\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011160; batch adversarial loss: 0.402857\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014881; batch adversarial loss: 0.405218\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015887; batch adversarial loss: 0.445230\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010446; batch adversarial loss: 0.550977\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011579; batch adversarial loss: 0.358968\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024230; batch adversarial loss: 0.495069\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008765; batch adversarial loss: 0.483287\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009884; batch adversarial loss: 0.442568\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025042; batch adversarial loss: 0.454957\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014127; batch adversarial loss: 0.417278\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701003; batch adversarial loss: 0.486905\n",
      "epoch 1; iter: 0; batch classifier loss: 0.427433; batch adversarial loss: 0.589077\n",
      "epoch 2; iter: 0; batch classifier loss: 0.300721; batch adversarial loss: 0.537793\n",
      "epoch 3; iter: 0; batch classifier loss: 0.371763; batch adversarial loss: 0.543828\n",
      "epoch 4; iter: 0; batch classifier loss: 0.309765; batch adversarial loss: 0.564634\n",
      "epoch 5; iter: 0; batch classifier loss: 0.419271; batch adversarial loss: 0.520994\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340514; batch adversarial loss: 0.548622\n",
      "epoch 7; iter: 0; batch classifier loss: 0.319730; batch adversarial loss: 0.517267\n",
      "epoch 8; iter: 0; batch classifier loss: 0.237228; batch adversarial loss: 0.565663\n",
      "epoch 9; iter: 0; batch classifier loss: 0.349964; batch adversarial loss: 0.593044\n",
      "epoch 10; iter: 0; batch classifier loss: 0.349726; batch adversarial loss: 0.527799\n",
      "epoch 11; iter: 0; batch classifier loss: 0.365681; batch adversarial loss: 0.563977\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251608; batch adversarial loss: 0.527524\n",
      "epoch 13; iter: 0; batch classifier loss: 0.380825; batch adversarial loss: 0.585113\n",
      "epoch 14; iter: 0; batch classifier loss: 0.531883; batch adversarial loss: 0.453848\n",
      "epoch 15; iter: 0; batch classifier loss: 0.468560; batch adversarial loss: 0.543458\n",
      "epoch 16; iter: 0; batch classifier loss: 0.455315; batch adversarial loss: 0.487145\n",
      "epoch 17; iter: 0; batch classifier loss: 0.333737; batch adversarial loss: 0.486820\n",
      "epoch 18; iter: 0; batch classifier loss: 0.259924; batch adversarial loss: 0.436676\n",
      "epoch 19; iter: 0; batch classifier loss: 0.204281; batch adversarial loss: 0.445743\n",
      "epoch 20; iter: 0; batch classifier loss: 0.189055; batch adversarial loss: 0.413887\n",
      "epoch 21; iter: 0; batch classifier loss: 0.147796; batch adversarial loss: 0.480751\n",
      "epoch 22; iter: 0; batch classifier loss: 0.183441; batch adversarial loss: 0.453386\n",
      "epoch 23; iter: 0; batch classifier loss: 0.170614; batch adversarial loss: 0.532247\n",
      "epoch 24; iter: 0; batch classifier loss: 0.157785; batch adversarial loss: 0.408284\n",
      "epoch 25; iter: 0; batch classifier loss: 0.143436; batch adversarial loss: 0.522226\n",
      "epoch 26; iter: 0; batch classifier loss: 0.162103; batch adversarial loss: 0.503625\n",
      "epoch 27; iter: 0; batch classifier loss: 0.119533; batch adversarial loss: 0.438997\n",
      "epoch 28; iter: 0; batch classifier loss: 0.169634; batch adversarial loss: 0.423470\n",
      "epoch 29; iter: 0; batch classifier loss: 0.117097; batch adversarial loss: 0.487389\n",
      "epoch 30; iter: 0; batch classifier loss: 0.175922; batch adversarial loss: 0.423058\n",
      "epoch 31; iter: 0; batch classifier loss: 0.125288; batch adversarial loss: 0.442968\n",
      "epoch 32; iter: 0; batch classifier loss: 0.092470; batch adversarial loss: 0.512203\n",
      "epoch 33; iter: 0; batch classifier loss: 0.080045; batch adversarial loss: 0.528071\n",
      "epoch 34; iter: 0; batch classifier loss: 0.084464; batch adversarial loss: 0.416929\n",
      "epoch 35; iter: 0; batch classifier loss: 0.108179; batch adversarial loss: 0.464213\n",
      "epoch 36; iter: 0; batch classifier loss: 0.142267; batch adversarial loss: 0.399511\n",
      "epoch 37; iter: 0; batch classifier loss: 0.094948; batch adversarial loss: 0.391907\n",
      "epoch 38; iter: 0; batch classifier loss: 0.104381; batch adversarial loss: 0.461150\n",
      "epoch 39; iter: 0; batch classifier loss: 0.101878; batch adversarial loss: 0.463572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.159444; batch adversarial loss: 0.516836\n",
      "epoch 41; iter: 0; batch classifier loss: 0.142790; batch adversarial loss: 0.411325\n",
      "epoch 42; iter: 0; batch classifier loss: 0.075569; batch adversarial loss: 0.439794\n",
      "epoch 43; iter: 0; batch classifier loss: 0.107186; batch adversarial loss: 0.460314\n",
      "epoch 44; iter: 0; batch classifier loss: 0.072887; batch adversarial loss: 0.503711\n",
      "epoch 45; iter: 0; batch classifier loss: 0.096982; batch adversarial loss: 0.450852\n",
      "epoch 46; iter: 0; batch classifier loss: 0.119998; batch adversarial loss: 0.468459\n",
      "epoch 47; iter: 0; batch classifier loss: 0.097565; batch adversarial loss: 0.442391\n",
      "epoch 48; iter: 0; batch classifier loss: 0.094953; batch adversarial loss: 0.441240\n",
      "epoch 49; iter: 0; batch classifier loss: 0.086269; batch adversarial loss: 0.415052\n",
      "epoch 50; iter: 0; batch classifier loss: 0.130443; batch adversarial loss: 0.450944\n",
      "epoch 51; iter: 0; batch classifier loss: 0.126311; batch adversarial loss: 0.470658\n",
      "epoch 52; iter: 0; batch classifier loss: 0.091692; batch adversarial loss: 0.594380\n",
      "epoch 53; iter: 0; batch classifier loss: 0.104196; batch adversarial loss: 0.486186\n",
      "epoch 54; iter: 0; batch classifier loss: 0.172080; batch adversarial loss: 0.473852\n",
      "epoch 55; iter: 0; batch classifier loss: 0.081178; batch adversarial loss: 0.539498\n",
      "epoch 56; iter: 0; batch classifier loss: 0.134614; batch adversarial loss: 0.423175\n",
      "epoch 57; iter: 0; batch classifier loss: 0.115473; batch adversarial loss: 0.487748\n",
      "epoch 58; iter: 0; batch classifier loss: 0.148941; batch adversarial loss: 0.452018\n",
      "epoch 59; iter: 0; batch classifier loss: 0.097425; batch adversarial loss: 0.444887\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097159; batch adversarial loss: 0.514845\n",
      "epoch 61; iter: 0; batch classifier loss: 0.130250; batch adversarial loss: 0.408093\n",
      "epoch 62; iter: 0; batch classifier loss: 0.107368; batch adversarial loss: 0.510482\n",
      "epoch 63; iter: 0; batch classifier loss: 0.121863; batch adversarial loss: 0.464292\n",
      "epoch 64; iter: 0; batch classifier loss: 0.127758; batch adversarial loss: 0.400060\n",
      "epoch 65; iter: 0; batch classifier loss: 0.095864; batch adversarial loss: 0.519894\n",
      "epoch 66; iter: 0; batch classifier loss: 0.149973; batch adversarial loss: 0.454067\n",
      "epoch 67; iter: 0; batch classifier loss: 0.119146; batch adversarial loss: 0.402454\n",
      "epoch 68; iter: 0; batch classifier loss: 0.125304; batch adversarial loss: 0.332396\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095555; batch adversarial loss: 0.454143\n",
      "epoch 70; iter: 0; batch classifier loss: 0.146438; batch adversarial loss: 0.545276\n",
      "epoch 71; iter: 0; batch classifier loss: 0.166602; batch adversarial loss: 0.477573\n",
      "epoch 72; iter: 0; batch classifier loss: 0.108105; batch adversarial loss: 0.523576\n",
      "epoch 73; iter: 0; batch classifier loss: 0.094300; batch adversarial loss: 0.334337\n",
      "epoch 74; iter: 0; batch classifier loss: 0.087943; batch adversarial loss: 0.503417\n",
      "epoch 75; iter: 0; batch classifier loss: 0.136035; batch adversarial loss: 0.412503\n",
      "epoch 76; iter: 0; batch classifier loss: 0.123286; batch adversarial loss: 0.459972\n",
      "epoch 77; iter: 0; batch classifier loss: 0.093744; batch adversarial loss: 0.501423\n",
      "epoch 78; iter: 0; batch classifier loss: 0.118652; batch adversarial loss: 0.561944\n",
      "epoch 79; iter: 0; batch classifier loss: 0.134238; batch adversarial loss: 0.406030\n",
      "epoch 80; iter: 0; batch classifier loss: 0.137479; batch adversarial loss: 0.541584\n",
      "epoch 81; iter: 0; batch classifier loss: 0.122314; batch adversarial loss: 0.424104\n",
      "epoch 82; iter: 0; batch classifier loss: 0.124699; batch adversarial loss: 0.392886\n",
      "epoch 83; iter: 0; batch classifier loss: 0.114857; batch adversarial loss: 0.420017\n",
      "epoch 84; iter: 0; batch classifier loss: 0.103451; batch adversarial loss: 0.426318\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068968; batch adversarial loss: 0.410407\n",
      "epoch 86; iter: 0; batch classifier loss: 0.075300; batch adversarial loss: 0.447035\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072845; batch adversarial loss: 0.502441\n",
      "epoch 88; iter: 0; batch classifier loss: 0.082603; batch adversarial loss: 0.509526\n",
      "epoch 89; iter: 0; batch classifier loss: 0.124121; batch adversarial loss: 0.391191\n",
      "epoch 90; iter: 0; batch classifier loss: 0.097405; batch adversarial loss: 0.407402\n",
      "epoch 91; iter: 0; batch classifier loss: 0.102620; batch adversarial loss: 0.402091\n",
      "epoch 92; iter: 0; batch classifier loss: 0.116948; batch adversarial loss: 0.456927\n",
      "epoch 93; iter: 0; batch classifier loss: 0.123120; batch adversarial loss: 0.512998\n",
      "epoch 94; iter: 0; batch classifier loss: 0.102806; batch adversarial loss: 0.490722\n",
      "epoch 95; iter: 0; batch classifier loss: 0.088063; batch adversarial loss: 0.484351\n",
      "epoch 96; iter: 0; batch classifier loss: 0.081212; batch adversarial loss: 0.516779\n",
      "epoch 97; iter: 0; batch classifier loss: 0.088510; batch adversarial loss: 0.455774\n",
      "epoch 98; iter: 0; batch classifier loss: 0.098548; batch adversarial loss: 0.456308\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056794; batch adversarial loss: 0.524115\n",
      "epoch 100; iter: 0; batch classifier loss: 0.108832; batch adversarial loss: 0.452526\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055434; batch adversarial loss: 0.383484\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047835; batch adversarial loss: 0.347315\n",
      "epoch 103; iter: 0; batch classifier loss: 0.085244; batch adversarial loss: 0.532185\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041991; batch adversarial loss: 0.364441\n",
      "epoch 105; iter: 0; batch classifier loss: 0.092891; batch adversarial loss: 0.416837\n",
      "epoch 106; iter: 0; batch classifier loss: 0.070082; batch adversarial loss: 0.444132\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046897; batch adversarial loss: 0.488557\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037550; batch adversarial loss: 0.358700\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049689; batch adversarial loss: 0.449268\n",
      "epoch 110; iter: 0; batch classifier loss: 0.086977; batch adversarial loss: 0.398148\n",
      "epoch 111; iter: 0; batch classifier loss: 0.067456; batch adversarial loss: 0.497359\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042463; batch adversarial loss: 0.466804\n",
      "epoch 113; iter: 0; batch classifier loss: 0.083308; batch adversarial loss: 0.575964\n",
      "epoch 114; iter: 0; batch classifier loss: 0.088257; batch adversarial loss: 0.502392\n",
      "epoch 115; iter: 0; batch classifier loss: 0.056470; batch adversarial loss: 0.473172\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036558; batch adversarial loss: 0.507843\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041316; batch adversarial loss: 0.473012\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054132; batch adversarial loss: 0.457577\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055402; batch adversarial loss: 0.415296\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044320; batch adversarial loss: 0.397593\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039803; batch adversarial loss: 0.398755\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039877; batch adversarial loss: 0.509391\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046113; batch adversarial loss: 0.505168\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038536; batch adversarial loss: 0.482084\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056569; batch adversarial loss: 0.484005\n",
      "epoch 126; iter: 0; batch classifier loss: 0.081764; batch adversarial loss: 0.387196\n",
      "epoch 127; iter: 0; batch classifier loss: 0.062040; batch adversarial loss: 0.455286\n",
      "epoch 128; iter: 0; batch classifier loss: 0.061568; batch adversarial loss: 0.456701\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041317; batch adversarial loss: 0.424078\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040950; batch adversarial loss: 0.506784\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025465; batch adversarial loss: 0.534427\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022609; batch adversarial loss: 0.506281\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022435; batch adversarial loss: 0.494675\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036675; batch adversarial loss: 0.534269\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050166; batch adversarial loss: 0.486382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.029472; batch adversarial loss: 0.486444\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045581; batch adversarial loss: 0.464561\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023288; batch adversarial loss: 0.473705\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041792; batch adversarial loss: 0.391404\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017786; batch adversarial loss: 0.466391\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020294; batch adversarial loss: 0.449008\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032970; batch adversarial loss: 0.451618\n",
      "epoch 143; iter: 0; batch classifier loss: 0.038236; batch adversarial loss: 0.500922\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041978; batch adversarial loss: 0.456221\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044773; batch adversarial loss: 0.438008\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015355; batch adversarial loss: 0.390190\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032307; batch adversarial loss: 0.456666\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031278; batch adversarial loss: 0.414446\n",
      "epoch 149; iter: 0; batch classifier loss: 0.041543; batch adversarial loss: 0.430423\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025088; batch adversarial loss: 0.466682\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026805; batch adversarial loss: 0.372062\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023950; batch adversarial loss: 0.479125\n",
      "epoch 153; iter: 0; batch classifier loss: 0.046560; batch adversarial loss: 0.465927\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035678; batch adversarial loss: 0.416710\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044552; batch adversarial loss: 0.500349\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018779; batch adversarial loss: 0.565761\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036971; batch adversarial loss: 0.382725\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010134; batch adversarial loss: 0.473162\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022550; batch adversarial loss: 0.510083\n",
      "epoch 160; iter: 0; batch classifier loss: 0.049322; batch adversarial loss: 0.466126\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030021; batch adversarial loss: 0.442098\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021921; batch adversarial loss: 0.524640\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020495; batch adversarial loss: 0.484744\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025083; batch adversarial loss: 0.525832\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040479; batch adversarial loss: 0.391898\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025003; batch adversarial loss: 0.414553\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014452; batch adversarial loss: 0.436263\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029955; batch adversarial loss: 0.438359\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030057; batch adversarial loss: 0.424373\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019392; batch adversarial loss: 0.451146\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025209; batch adversarial loss: 0.547935\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032576; batch adversarial loss: 0.525294\n",
      "epoch 173; iter: 0; batch classifier loss: 0.039014; batch adversarial loss: 0.491730\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011357; batch adversarial loss: 0.507976\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016502; batch adversarial loss: 0.550120\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025621; batch adversarial loss: 0.461284\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033260; batch adversarial loss: 0.466944\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010756; batch adversarial loss: 0.368571\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021656; batch adversarial loss: 0.471845\n",
      "epoch 180; iter: 0; batch classifier loss: 0.051868; batch adversarial loss: 0.492642\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015164; batch adversarial loss: 0.557032\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018370; batch adversarial loss: 0.420884\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021620; batch adversarial loss: 0.480861\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007581; batch adversarial loss: 0.436886\n",
      "epoch 185; iter: 0; batch classifier loss: 0.034567; batch adversarial loss: 0.407346\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015964; batch adversarial loss: 0.434869\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018493; batch adversarial loss: 0.559251\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028210; batch adversarial loss: 0.415340\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020224; batch adversarial loss: 0.494998\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009777; batch adversarial loss: 0.446497\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020042; batch adversarial loss: 0.503080\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029097; batch adversarial loss: 0.459248\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007130; batch adversarial loss: 0.498468\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036026; batch adversarial loss: 0.498805\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010241; batch adversarial loss: 0.532467\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033432; batch adversarial loss: 0.507636\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012424; batch adversarial loss: 0.442863\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011296; batch adversarial loss: 0.483039\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020305; batch adversarial loss: 0.500774\n",
      "epoch 0; iter: 0; batch classifier loss: 0.623400; batch adversarial loss: 0.925299\n",
      "epoch 1; iter: 0; batch classifier loss: 0.621603; batch adversarial loss: 1.110631\n",
      "epoch 2; iter: 0; batch classifier loss: 0.898388; batch adversarial loss: 1.162179\n",
      "epoch 3; iter: 0; batch classifier loss: 1.020749; batch adversarial loss: 1.075282\n",
      "epoch 4; iter: 0; batch classifier loss: 0.942826; batch adversarial loss: 0.961793\n",
      "epoch 5; iter: 0; batch classifier loss: 1.022616; batch adversarial loss: 0.883246\n",
      "epoch 6; iter: 0; batch classifier loss: 1.084440; batch adversarial loss: 0.789511\n",
      "epoch 7; iter: 0; batch classifier loss: 0.954183; batch adversarial loss: 0.727364\n",
      "epoch 8; iter: 0; batch classifier loss: 1.200126; batch adversarial loss: 0.677420\n",
      "epoch 9; iter: 0; batch classifier loss: 0.862864; batch adversarial loss: 0.636267\n",
      "epoch 10; iter: 0; batch classifier loss: 0.716913; batch adversarial loss: 0.556899\n",
      "epoch 11; iter: 0; batch classifier loss: 0.574778; batch adversarial loss: 0.542176\n",
      "epoch 12; iter: 0; batch classifier loss: 0.357479; batch adversarial loss: 0.481109\n",
      "epoch 13; iter: 0; batch classifier loss: 0.301841; batch adversarial loss: 0.535397\n",
      "epoch 14; iter: 0; batch classifier loss: 0.312099; batch adversarial loss: 0.502945\n",
      "epoch 15; iter: 0; batch classifier loss: 0.258310; batch adversarial loss: 0.476816\n",
      "epoch 16; iter: 0; batch classifier loss: 0.231292; batch adversarial loss: 0.493884\n",
      "epoch 17; iter: 0; batch classifier loss: 0.183900; batch adversarial loss: 0.512016\n",
      "epoch 18; iter: 0; batch classifier loss: 0.200248; batch adversarial loss: 0.501070\n",
      "epoch 19; iter: 0; batch classifier loss: 0.266086; batch adversarial loss: 0.514321\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222397; batch adversarial loss: 0.435942\n",
      "epoch 21; iter: 0; batch classifier loss: 0.189142; batch adversarial loss: 0.502241\n",
      "epoch 22; iter: 0; batch classifier loss: 0.230877; batch adversarial loss: 0.501021\n",
      "epoch 23; iter: 0; batch classifier loss: 0.287987; batch adversarial loss: 0.475754\n",
      "epoch 24; iter: 0; batch classifier loss: 0.240411; batch adversarial loss: 0.531068\n",
      "epoch 25; iter: 0; batch classifier loss: 0.209038; batch adversarial loss: 0.509403\n",
      "epoch 26; iter: 0; batch classifier loss: 0.139436; batch adversarial loss: 0.524963\n",
      "epoch 27; iter: 0; batch classifier loss: 0.228747; batch adversarial loss: 0.451688\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184620; batch adversarial loss: 0.448238\n",
      "epoch 29; iter: 0; batch classifier loss: 0.220097; batch adversarial loss: 0.419722\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151787; batch adversarial loss: 0.473975\n",
      "epoch 31; iter: 0; batch classifier loss: 0.183606; batch adversarial loss: 0.436363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.117380; batch adversarial loss: 0.464406\n",
      "epoch 33; iter: 0; batch classifier loss: 0.196824; batch adversarial loss: 0.473793\n",
      "epoch 34; iter: 0; batch classifier loss: 0.190670; batch adversarial loss: 0.470113\n",
      "epoch 35; iter: 0; batch classifier loss: 0.117458; batch adversarial loss: 0.471425\n",
      "epoch 36; iter: 0; batch classifier loss: 0.182514; batch adversarial loss: 0.453742\n",
      "epoch 37; iter: 0; batch classifier loss: 0.158821; batch adversarial loss: 0.529272\n",
      "epoch 38; iter: 0; batch classifier loss: 0.179903; batch adversarial loss: 0.590356\n",
      "epoch 39; iter: 0; batch classifier loss: 0.190349; batch adversarial loss: 0.463130\n",
      "epoch 40; iter: 0; batch classifier loss: 0.177251; batch adversarial loss: 0.498345\n",
      "epoch 41; iter: 0; batch classifier loss: 0.157321; batch adversarial loss: 0.393405\n",
      "epoch 42; iter: 0; batch classifier loss: 0.201207; batch adversarial loss: 0.439918\n",
      "epoch 43; iter: 0; batch classifier loss: 0.130783; batch adversarial loss: 0.563329\n",
      "epoch 44; iter: 0; batch classifier loss: 0.212572; batch adversarial loss: 0.465967\n",
      "epoch 45; iter: 0; batch classifier loss: 0.172985; batch adversarial loss: 0.474460\n",
      "epoch 46; iter: 0; batch classifier loss: 0.233681; batch adversarial loss: 0.413756\n",
      "epoch 47; iter: 0; batch classifier loss: 0.170328; batch adversarial loss: 0.516706\n",
      "epoch 48; iter: 0; batch classifier loss: 0.175345; batch adversarial loss: 0.523368\n",
      "epoch 49; iter: 0; batch classifier loss: 0.168079; batch adversarial loss: 0.587442\n",
      "epoch 50; iter: 0; batch classifier loss: 0.207336; batch adversarial loss: 0.459569\n",
      "epoch 51; iter: 0; batch classifier loss: 0.096476; batch adversarial loss: 0.486968\n",
      "epoch 52; iter: 0; batch classifier loss: 0.234023; batch adversarial loss: 0.536325\n",
      "epoch 53; iter: 0; batch classifier loss: 0.141958; batch adversarial loss: 0.501772\n",
      "epoch 54; iter: 0; batch classifier loss: 0.162358; batch adversarial loss: 0.403713\n",
      "epoch 55; iter: 0; batch classifier loss: 0.226715; batch adversarial loss: 0.497876\n",
      "epoch 56; iter: 0; batch classifier loss: 0.162013; batch adversarial loss: 0.391482\n",
      "epoch 57; iter: 0; batch classifier loss: 0.195215; batch adversarial loss: 0.481815\n",
      "epoch 58; iter: 0; batch classifier loss: 0.150148; batch adversarial loss: 0.567190\n",
      "epoch 59; iter: 0; batch classifier loss: 0.095379; batch adversarial loss: 0.633764\n",
      "epoch 60; iter: 0; batch classifier loss: 0.177133; batch adversarial loss: 0.493137\n",
      "epoch 61; iter: 0; batch classifier loss: 0.143544; batch adversarial loss: 0.468121\n",
      "epoch 62; iter: 0; batch classifier loss: 0.185532; batch adversarial loss: 0.507100\n",
      "epoch 63; iter: 0; batch classifier loss: 0.194847; batch adversarial loss: 0.438095\n",
      "epoch 64; iter: 0; batch classifier loss: 0.141829; batch adversarial loss: 0.514239\n",
      "epoch 65; iter: 0; batch classifier loss: 0.155328; batch adversarial loss: 0.542334\n",
      "epoch 66; iter: 0; batch classifier loss: 0.225552; batch adversarial loss: 0.377545\n",
      "epoch 67; iter: 0; batch classifier loss: 0.160259; batch adversarial loss: 0.386434\n",
      "epoch 68; iter: 0; batch classifier loss: 0.185113; batch adversarial loss: 0.519690\n",
      "epoch 69; iter: 0; batch classifier loss: 0.181628; batch adversarial loss: 0.355590\n",
      "epoch 70; iter: 0; batch classifier loss: 0.178984; batch adversarial loss: 0.504134\n",
      "epoch 71; iter: 0; batch classifier loss: 0.178471; batch adversarial loss: 0.483634\n",
      "epoch 72; iter: 0; batch classifier loss: 0.175835; batch adversarial loss: 0.468092\n",
      "epoch 73; iter: 0; batch classifier loss: 0.187731; batch adversarial loss: 0.505158\n",
      "epoch 74; iter: 0; batch classifier loss: 0.119202; batch adversarial loss: 0.579936\n",
      "epoch 75; iter: 0; batch classifier loss: 0.205742; batch adversarial loss: 0.412273\n",
      "epoch 76; iter: 0; batch classifier loss: 0.244184; batch adversarial loss: 0.483173\n",
      "epoch 77; iter: 0; batch classifier loss: 0.134910; batch adversarial loss: 0.464136\n",
      "epoch 78; iter: 0; batch classifier loss: 0.160176; batch adversarial loss: 0.455065\n",
      "epoch 79; iter: 0; batch classifier loss: 0.184050; batch adversarial loss: 0.372534\n",
      "epoch 80; iter: 0; batch classifier loss: 0.169635; batch adversarial loss: 0.447337\n",
      "epoch 81; iter: 0; batch classifier loss: 0.179211; batch adversarial loss: 0.504283\n",
      "epoch 82; iter: 0; batch classifier loss: 0.218083; batch adversarial loss: 0.539671\n",
      "epoch 83; iter: 0; batch classifier loss: 0.187541; batch adversarial loss: 0.411603\n",
      "epoch 84; iter: 0; batch classifier loss: 0.130677; batch adversarial loss: 0.480473\n",
      "epoch 85; iter: 0; batch classifier loss: 0.161324; batch adversarial loss: 0.516806\n",
      "epoch 86; iter: 0; batch classifier loss: 0.128004; batch adversarial loss: 0.461032\n",
      "epoch 87; iter: 0; batch classifier loss: 0.176255; batch adversarial loss: 0.460341\n",
      "epoch 88; iter: 0; batch classifier loss: 0.204826; batch adversarial loss: 0.459501\n",
      "epoch 89; iter: 0; batch classifier loss: 0.220165; batch adversarial loss: 0.553755\n",
      "epoch 90; iter: 0; batch classifier loss: 0.145331; batch adversarial loss: 0.457544\n",
      "epoch 91; iter: 0; batch classifier loss: 0.140604; batch adversarial loss: 0.483780\n",
      "epoch 92; iter: 0; batch classifier loss: 0.202416; batch adversarial loss: 0.575756\n",
      "epoch 93; iter: 0; batch classifier loss: 0.245098; batch adversarial loss: 0.470065\n",
      "epoch 94; iter: 0; batch classifier loss: 0.171419; batch adversarial loss: 0.458996\n",
      "epoch 95; iter: 0; batch classifier loss: 0.154510; batch adversarial loss: 0.505831\n",
      "epoch 96; iter: 0; batch classifier loss: 0.183367; batch adversarial loss: 0.457035\n",
      "epoch 97; iter: 0; batch classifier loss: 0.185137; batch adversarial loss: 0.457228\n",
      "epoch 98; iter: 0; batch classifier loss: 0.184631; batch adversarial loss: 0.448638\n",
      "epoch 99; iter: 0; batch classifier loss: 0.223247; batch adversarial loss: 0.412025\n",
      "epoch 100; iter: 0; batch classifier loss: 0.183085; batch adversarial loss: 0.410616\n",
      "epoch 101; iter: 0; batch classifier loss: 0.112834; batch adversarial loss: 0.506811\n",
      "epoch 102; iter: 0; batch classifier loss: 0.168960; batch adversarial loss: 0.446777\n",
      "epoch 103; iter: 0; batch classifier loss: 0.169136; batch adversarial loss: 0.422003\n",
      "epoch 104; iter: 0; batch classifier loss: 0.204165; batch adversarial loss: 0.448010\n",
      "epoch 105; iter: 0; batch classifier loss: 0.162983; batch adversarial loss: 0.389805\n",
      "epoch 106; iter: 0; batch classifier loss: 0.181068; batch adversarial loss: 0.482211\n",
      "epoch 107; iter: 0; batch classifier loss: 0.205105; batch adversarial loss: 0.422958\n",
      "epoch 108; iter: 0; batch classifier loss: 0.170065; batch adversarial loss: 0.577885\n",
      "epoch 109; iter: 0; batch classifier loss: 0.242728; batch adversarial loss: 0.495140\n",
      "epoch 110; iter: 0; batch classifier loss: 0.187338; batch adversarial loss: 0.518471\n",
      "epoch 111; iter: 0; batch classifier loss: 0.074987; batch adversarial loss: 0.482391\n",
      "epoch 112; iter: 0; batch classifier loss: 0.157663; batch adversarial loss: 0.423368\n",
      "epoch 113; iter: 0; batch classifier loss: 0.189356; batch adversarial loss: 0.410578\n",
      "epoch 114; iter: 0; batch classifier loss: 0.192032; batch adversarial loss: 0.482382\n",
      "epoch 115; iter: 0; batch classifier loss: 0.133384; batch adversarial loss: 0.543800\n",
      "epoch 116; iter: 0; batch classifier loss: 0.204698; batch adversarial loss: 0.482573\n",
      "epoch 117; iter: 0; batch classifier loss: 0.167420; batch adversarial loss: 0.508985\n",
      "epoch 118; iter: 0; batch classifier loss: 0.213316; batch adversarial loss: 0.506275\n",
      "epoch 119; iter: 0; batch classifier loss: 0.141024; batch adversarial loss: 0.411526\n",
      "epoch 120; iter: 0; batch classifier loss: 0.247839; batch adversarial loss: 0.470741\n",
      "epoch 121; iter: 0; batch classifier loss: 0.201200; batch adversarial loss: 0.458739\n",
      "epoch 122; iter: 0; batch classifier loss: 0.151320; batch adversarial loss: 0.483081\n",
      "epoch 123; iter: 0; batch classifier loss: 0.209499; batch adversarial loss: 0.447173\n",
      "epoch 124; iter: 0; batch classifier loss: 0.076739; batch adversarial loss: 0.482355\n",
      "epoch 125; iter: 0; batch classifier loss: 0.077519; batch adversarial loss: 0.410574\n",
      "epoch 126; iter: 0; batch classifier loss: 0.089345; batch adversarial loss: 0.515268\n",
      "epoch 127; iter: 0; batch classifier loss: 0.077306; batch adversarial loss: 0.508201\n",
      "epoch 128; iter: 0; batch classifier loss: 0.152256; batch adversarial loss: 0.470091\n",
      "epoch 129; iter: 0; batch classifier loss: 0.213941; batch adversarial loss: 0.508840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.182753; batch adversarial loss: 0.516397\n",
      "epoch 131; iter: 0; batch classifier loss: 0.148973; batch adversarial loss: 0.565031\n",
      "epoch 132; iter: 0; batch classifier loss: 0.182256; batch adversarial loss: 0.517124\n",
      "epoch 133; iter: 0; batch classifier loss: 0.168234; batch adversarial loss: 0.533132\n",
      "epoch 134; iter: 0; batch classifier loss: 0.181660; batch adversarial loss: 0.460426\n",
      "epoch 135; iter: 0; batch classifier loss: 0.248917; batch adversarial loss: 0.493770\n",
      "epoch 136; iter: 0; batch classifier loss: 0.178965; batch adversarial loss: 0.519633\n",
      "epoch 137; iter: 0; batch classifier loss: 0.185327; batch adversarial loss: 0.435701\n",
      "epoch 138; iter: 0; batch classifier loss: 0.160358; batch adversarial loss: 0.459261\n",
      "epoch 139; iter: 0; batch classifier loss: 0.190425; batch adversarial loss: 0.458246\n",
      "epoch 140; iter: 0; batch classifier loss: 0.222846; batch adversarial loss: 0.377401\n",
      "epoch 141; iter: 0; batch classifier loss: 0.246219; batch adversarial loss: 0.423624\n",
      "epoch 142; iter: 0; batch classifier loss: 0.235933; batch adversarial loss: 0.471087\n",
      "epoch 143; iter: 0; batch classifier loss: 0.165693; batch adversarial loss: 0.482725\n",
      "epoch 144; iter: 0; batch classifier loss: 0.063606; batch adversarial loss: 0.529403\n",
      "epoch 145; iter: 0; batch classifier loss: 0.052532; batch adversarial loss: 0.412368\n",
      "epoch 146; iter: 0; batch classifier loss: 0.123383; batch adversarial loss: 0.555319\n",
      "epoch 147; iter: 0; batch classifier loss: 0.178240; batch adversarial loss: 0.494101\n",
      "epoch 148; iter: 0; batch classifier loss: 0.150354; batch adversarial loss: 0.469058\n",
      "epoch 149; iter: 0; batch classifier loss: 0.158775; batch adversarial loss: 0.458175\n",
      "epoch 150; iter: 0; batch classifier loss: 0.207145; batch adversarial loss: 0.445866\n",
      "epoch 151; iter: 0; batch classifier loss: 0.158410; batch adversarial loss: 0.531472\n",
      "epoch 152; iter: 0; batch classifier loss: 0.184748; batch adversarial loss: 0.458846\n",
      "epoch 153; iter: 0; batch classifier loss: 0.214731; batch adversarial loss: 0.434918\n",
      "epoch 154; iter: 0; batch classifier loss: 0.163923; batch adversarial loss: 0.472618\n",
      "epoch 155; iter: 0; batch classifier loss: 0.190879; batch adversarial loss: 0.482385\n",
      "epoch 156; iter: 0; batch classifier loss: 0.184354; batch adversarial loss: 0.492322\n",
      "epoch 157; iter: 0; batch classifier loss: 0.163368; batch adversarial loss: 0.327501\n",
      "epoch 158; iter: 0; batch classifier loss: 0.200397; batch adversarial loss: 0.459804\n",
      "epoch 159; iter: 0; batch classifier loss: 0.146524; batch adversarial loss: 0.541443\n",
      "epoch 160; iter: 0; batch classifier loss: 0.208360; batch adversarial loss: 0.482864\n",
      "epoch 161; iter: 0; batch classifier loss: 0.219652; batch adversarial loss: 0.376384\n",
      "epoch 162; iter: 0; batch classifier loss: 0.176516; batch adversarial loss: 0.528349\n",
      "epoch 163; iter: 0; batch classifier loss: 0.269017; batch adversarial loss: 0.458272\n",
      "epoch 164; iter: 0; batch classifier loss: 0.158297; batch adversarial loss: 0.424010\n",
      "epoch 165; iter: 0; batch classifier loss: 0.200247; batch adversarial loss: 0.517393\n",
      "epoch 166; iter: 0; batch classifier loss: 0.102736; batch adversarial loss: 0.435163\n",
      "epoch 167; iter: 0; batch classifier loss: 0.187259; batch adversarial loss: 0.459720\n",
      "epoch 168; iter: 0; batch classifier loss: 0.142064; batch adversarial loss: 0.435861\n",
      "epoch 169; iter: 0; batch classifier loss: 0.232791; batch adversarial loss: 0.387774\n",
      "epoch 170; iter: 0; batch classifier loss: 0.247658; batch adversarial loss: 0.483009\n",
      "epoch 171; iter: 0; batch classifier loss: 0.147361; batch adversarial loss: 0.375890\n",
      "epoch 172; iter: 0; batch classifier loss: 0.186437; batch adversarial loss: 0.411714\n",
      "epoch 173; iter: 0; batch classifier loss: 0.167641; batch adversarial loss: 0.423768\n",
      "epoch 174; iter: 0; batch classifier loss: 0.098330; batch adversarial loss: 0.520031\n",
      "epoch 175; iter: 0; batch classifier loss: 0.146702; batch adversarial loss: 0.460287\n",
      "epoch 176; iter: 0; batch classifier loss: 0.198749; batch adversarial loss: 0.518730\n",
      "epoch 177; iter: 0; batch classifier loss: 0.165546; batch adversarial loss: 0.470689\n",
      "epoch 178; iter: 0; batch classifier loss: 0.140735; batch adversarial loss: 0.519322\n",
      "epoch 179; iter: 0; batch classifier loss: 0.146577; batch adversarial loss: 0.494880\n",
      "epoch 180; iter: 0; batch classifier loss: 0.128034; batch adversarial loss: 0.422868\n",
      "epoch 181; iter: 0; batch classifier loss: 0.088349; batch adversarial loss: 0.541553\n",
      "epoch 182; iter: 0; batch classifier loss: 0.116025; batch adversarial loss: 0.433737\n",
      "epoch 183; iter: 0; batch classifier loss: 0.158651; batch adversarial loss: 0.528342\n",
      "epoch 184; iter: 0; batch classifier loss: 0.151868; batch adversarial loss: 0.421383\n",
      "epoch 185; iter: 0; batch classifier loss: 0.169486; batch adversarial loss: 0.470498\n",
      "epoch 186; iter: 0; batch classifier loss: 0.171087; batch adversarial loss: 0.530734\n",
      "epoch 187; iter: 0; batch classifier loss: 0.117896; batch adversarial loss: 0.529860\n",
      "epoch 188; iter: 0; batch classifier loss: 0.136668; batch adversarial loss: 0.491902\n",
      "epoch 189; iter: 0; batch classifier loss: 0.151127; batch adversarial loss: 0.518262\n",
      "epoch 190; iter: 0; batch classifier loss: 0.173883; batch adversarial loss: 0.478646\n",
      "epoch 191; iter: 0; batch classifier loss: 0.080827; batch adversarial loss: 0.614381\n",
      "epoch 192; iter: 0; batch classifier loss: 0.155235; batch adversarial loss: 0.445483\n",
      "epoch 193; iter: 0; batch classifier loss: 0.105436; batch adversarial loss: 0.434408\n",
      "epoch 194; iter: 0; batch classifier loss: 0.103707; batch adversarial loss: 0.394093\n",
      "epoch 195; iter: 0; batch classifier loss: 0.080390; batch adversarial loss: 0.495295\n",
      "epoch 196; iter: 0; batch classifier loss: 0.068945; batch adversarial loss: 0.533145\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024695; batch adversarial loss: 0.456394\n",
      "epoch 198; iter: 0; batch classifier loss: 0.039569; batch adversarial loss: 0.479173\n",
      "epoch 199; iter: 0; batch classifier loss: 0.049883; batch adversarial loss: 0.416016\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705848; batch adversarial loss: 0.591864\n",
      "epoch 1; iter: 0; batch classifier loss: 0.539477; batch adversarial loss: 0.622872\n",
      "epoch 2; iter: 0; batch classifier loss: 0.367599; batch adversarial loss: 0.610818\n",
      "epoch 3; iter: 0; batch classifier loss: 0.503259; batch adversarial loss: 0.612814\n",
      "epoch 4; iter: 0; batch classifier loss: 0.401259; batch adversarial loss: 0.596672\n",
      "epoch 5; iter: 0; batch classifier loss: 0.577154; batch adversarial loss: 0.631251\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549740; batch adversarial loss: 0.571129\n",
      "epoch 7; iter: 0; batch classifier loss: 0.482193; batch adversarial loss: 0.589514\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560133; batch adversarial loss: 0.567747\n",
      "epoch 9; iter: 0; batch classifier loss: 0.397575; batch adversarial loss: 0.522803\n",
      "epoch 10; iter: 0; batch classifier loss: 0.364233; batch adversarial loss: 0.579221\n",
      "epoch 11; iter: 0; batch classifier loss: 0.365050; batch adversarial loss: 0.562371\n",
      "epoch 12; iter: 0; batch classifier loss: 0.382303; batch adversarial loss: 0.502782\n",
      "epoch 13; iter: 0; batch classifier loss: 0.346051; batch adversarial loss: 0.562459\n",
      "epoch 14; iter: 0; batch classifier loss: 0.340311; batch adversarial loss: 0.552087\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364886; batch adversarial loss: 0.524390\n",
      "epoch 16; iter: 0; batch classifier loss: 0.462608; batch adversarial loss: 0.454459\n",
      "epoch 17; iter: 0; batch classifier loss: 0.309451; batch adversarial loss: 0.503129\n",
      "epoch 18; iter: 0; batch classifier loss: 0.285288; batch adversarial loss: 0.532382\n",
      "epoch 19; iter: 0; batch classifier loss: 0.218930; batch adversarial loss: 0.564163\n",
      "epoch 20; iter: 0; batch classifier loss: 0.283132; batch adversarial loss: 0.493635\n",
      "epoch 21; iter: 0; batch classifier loss: 0.283478; batch adversarial loss: 0.450523\n",
      "epoch 22; iter: 0; batch classifier loss: 0.267269; batch adversarial loss: 0.484591\n",
      "epoch 23; iter: 0; batch classifier loss: 0.225822; batch adversarial loss: 0.469862\n",
      "epoch 24; iter: 0; batch classifier loss: 0.260587; batch adversarial loss: 0.475200\n",
      "epoch 25; iter: 0; batch classifier loss: 0.284863; batch adversarial loss: 0.446324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.286936; batch adversarial loss: 0.489723\n",
      "epoch 27; iter: 0; batch classifier loss: 0.253723; batch adversarial loss: 0.513270\n",
      "epoch 28; iter: 0; batch classifier loss: 0.266912; batch adversarial loss: 0.451917\n",
      "epoch 29; iter: 0; batch classifier loss: 0.241321; batch adversarial loss: 0.492108\n",
      "epoch 30; iter: 0; batch classifier loss: 0.305496; batch adversarial loss: 0.522704\n",
      "epoch 31; iter: 0; batch classifier loss: 0.288654; batch adversarial loss: 0.507151\n",
      "epoch 32; iter: 0; batch classifier loss: 0.225080; batch adversarial loss: 0.462448\n",
      "epoch 33; iter: 0; batch classifier loss: 0.233482; batch adversarial loss: 0.492023\n",
      "epoch 34; iter: 0; batch classifier loss: 0.205418; batch adversarial loss: 0.465884\n",
      "epoch 35; iter: 0; batch classifier loss: 0.227128; batch adversarial loss: 0.412460\n",
      "epoch 36; iter: 0; batch classifier loss: 0.220135; batch adversarial loss: 0.593424\n",
      "epoch 37; iter: 0; batch classifier loss: 0.248003; batch adversarial loss: 0.445153\n",
      "epoch 38; iter: 0; batch classifier loss: 0.219391; batch adversarial loss: 0.524546\n",
      "epoch 39; iter: 0; batch classifier loss: 0.234276; batch adversarial loss: 0.484521\n",
      "epoch 40; iter: 0; batch classifier loss: 0.200048; batch adversarial loss: 0.550851\n",
      "epoch 41; iter: 0; batch classifier loss: 0.325510; batch adversarial loss: 0.512868\n",
      "epoch 42; iter: 0; batch classifier loss: 0.301482; batch adversarial loss: 0.437219\n",
      "epoch 43; iter: 0; batch classifier loss: 0.188496; batch adversarial loss: 0.709413\n",
      "epoch 44; iter: 0; batch classifier loss: 0.254719; batch adversarial loss: 0.504281\n",
      "epoch 45; iter: 0; batch classifier loss: 0.257146; batch adversarial loss: 0.437195\n",
      "epoch 46; iter: 0; batch classifier loss: 0.279639; batch adversarial loss: 0.505690\n",
      "epoch 47; iter: 0; batch classifier loss: 0.172314; batch adversarial loss: 0.528139\n",
      "epoch 48; iter: 0; batch classifier loss: 0.141846; batch adversarial loss: 0.458102\n",
      "epoch 49; iter: 0; batch classifier loss: 0.204371; batch adversarial loss: 0.435066\n",
      "epoch 50; iter: 0; batch classifier loss: 0.274412; batch adversarial loss: 0.436826\n",
      "epoch 51; iter: 0; batch classifier loss: 0.134746; batch adversarial loss: 0.493522\n",
      "epoch 52; iter: 0; batch classifier loss: 0.164722; batch adversarial loss: 0.507949\n",
      "epoch 53; iter: 0; batch classifier loss: 0.281077; batch adversarial loss: 0.517457\n",
      "epoch 54; iter: 0; batch classifier loss: 0.131343; batch adversarial loss: 0.505708\n",
      "epoch 55; iter: 0; batch classifier loss: 0.140356; batch adversarial loss: 0.425156\n",
      "epoch 56; iter: 0; batch classifier loss: 0.304484; batch adversarial loss: 0.445633\n",
      "epoch 57; iter: 0; batch classifier loss: 0.147519; batch adversarial loss: 0.480455\n",
      "epoch 58; iter: 0; batch classifier loss: 0.181300; batch adversarial loss: 0.362696\n",
      "epoch 59; iter: 0; batch classifier loss: 0.176601; batch adversarial loss: 0.422315\n",
      "epoch 60; iter: 0; batch classifier loss: 0.220272; batch adversarial loss: 0.460041\n",
      "epoch 61; iter: 0; batch classifier loss: 0.136673; batch adversarial loss: 0.422112\n",
      "epoch 62; iter: 0; batch classifier loss: 0.187407; batch adversarial loss: 0.435830\n",
      "epoch 63; iter: 0; batch classifier loss: 0.232024; batch adversarial loss: 0.470772\n",
      "epoch 64; iter: 0; batch classifier loss: 0.234053; batch adversarial loss: 0.461357\n",
      "epoch 65; iter: 0; batch classifier loss: 0.155154; batch adversarial loss: 0.424395\n",
      "epoch 66; iter: 0; batch classifier loss: 0.168318; batch adversarial loss: 0.436502\n",
      "epoch 67; iter: 0; batch classifier loss: 0.277346; batch adversarial loss: 0.470890\n",
      "epoch 68; iter: 0; batch classifier loss: 0.139248; batch adversarial loss: 0.493437\n",
      "epoch 69; iter: 0; batch classifier loss: 0.157986; batch adversarial loss: 0.423744\n",
      "epoch 70; iter: 0; batch classifier loss: 0.202695; batch adversarial loss: 0.483491\n",
      "epoch 71; iter: 0; batch classifier loss: 0.243416; batch adversarial loss: 0.400846\n",
      "epoch 72; iter: 0; batch classifier loss: 0.179475; batch adversarial loss: 0.517502\n",
      "epoch 73; iter: 0; batch classifier loss: 0.210541; batch adversarial loss: 0.435680\n",
      "epoch 74; iter: 0; batch classifier loss: 0.185692; batch adversarial loss: 0.423223\n",
      "epoch 75; iter: 0; batch classifier loss: 0.147909; batch adversarial loss: 0.459174\n",
      "epoch 76; iter: 0; batch classifier loss: 0.118562; batch adversarial loss: 0.504447\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102919; batch adversarial loss: 0.518376\n",
      "epoch 78; iter: 0; batch classifier loss: 0.221119; batch adversarial loss: 0.527824\n",
      "epoch 79; iter: 0; batch classifier loss: 0.230317; batch adversarial loss: 0.483152\n",
      "epoch 80; iter: 0; batch classifier loss: 0.212648; batch adversarial loss: 0.469687\n",
      "epoch 81; iter: 0; batch classifier loss: 0.187777; batch adversarial loss: 0.528265\n",
      "epoch 82; iter: 0; batch classifier loss: 0.191420; batch adversarial loss: 0.483062\n",
      "epoch 83; iter: 0; batch classifier loss: 0.200921; batch adversarial loss: 0.459579\n",
      "epoch 84; iter: 0; batch classifier loss: 0.181541; batch adversarial loss: 0.530177\n",
      "epoch 85; iter: 0; batch classifier loss: 0.247348; batch adversarial loss: 0.493920\n",
      "epoch 86; iter: 0; batch classifier loss: 0.127269; batch adversarial loss: 0.505592\n",
      "epoch 87; iter: 0; batch classifier loss: 0.168793; batch adversarial loss: 0.482249\n",
      "epoch 88; iter: 0; batch classifier loss: 0.124238; batch adversarial loss: 0.496049\n",
      "epoch 89; iter: 0; batch classifier loss: 0.259319; batch adversarial loss: 0.364467\n",
      "epoch 90; iter: 0; batch classifier loss: 0.155960; batch adversarial loss: 0.483777\n",
      "epoch 91; iter: 0; batch classifier loss: 0.167054; batch adversarial loss: 0.434648\n",
      "epoch 92; iter: 0; batch classifier loss: 0.225195; batch adversarial loss: 0.445591\n",
      "epoch 93; iter: 0; batch classifier loss: 0.207610; batch adversarial loss: 0.447555\n",
      "epoch 94; iter: 0; batch classifier loss: 0.261551; batch adversarial loss: 0.412088\n",
      "epoch 95; iter: 0; batch classifier loss: 0.145186; batch adversarial loss: 0.447177\n",
      "epoch 96; iter: 0; batch classifier loss: 0.245209; batch adversarial loss: 0.587435\n",
      "epoch 97; iter: 0; batch classifier loss: 0.260475; batch adversarial loss: 0.399927\n",
      "epoch 98; iter: 0; batch classifier loss: 0.129520; batch adversarial loss: 0.388655\n",
      "epoch 99; iter: 0; batch classifier loss: 0.186104; batch adversarial loss: 0.447676\n",
      "epoch 100; iter: 0; batch classifier loss: 0.148247; batch adversarial loss: 0.433284\n",
      "epoch 101; iter: 0; batch classifier loss: 0.273663; batch adversarial loss: 0.434227\n",
      "epoch 102; iter: 0; batch classifier loss: 0.137375; batch adversarial loss: 0.576391\n",
      "epoch 103; iter: 0; batch classifier loss: 0.169545; batch adversarial loss: 0.530078\n",
      "epoch 104; iter: 0; batch classifier loss: 0.239000; batch adversarial loss: 0.470777\n",
      "epoch 105; iter: 0; batch classifier loss: 0.216456; batch adversarial loss: 0.435458\n",
      "epoch 106; iter: 0; batch classifier loss: 0.173658; batch adversarial loss: 0.470437\n",
      "epoch 107; iter: 0; batch classifier loss: 0.155717; batch adversarial loss: 0.482132\n",
      "epoch 108; iter: 0; batch classifier loss: 0.152365; batch adversarial loss: 0.599112\n",
      "epoch 109; iter: 0; batch classifier loss: 0.191230; batch adversarial loss: 0.446586\n",
      "epoch 110; iter: 0; batch classifier loss: 0.198088; batch adversarial loss: 0.412069\n",
      "epoch 111; iter: 0; batch classifier loss: 0.239653; batch adversarial loss: 0.460681\n",
      "epoch 112; iter: 0; batch classifier loss: 0.203501; batch adversarial loss: 0.564672\n",
      "epoch 113; iter: 0; batch classifier loss: 0.166838; batch adversarial loss: 0.527466\n",
      "epoch 114; iter: 0; batch classifier loss: 0.164348; batch adversarial loss: 0.400248\n",
      "epoch 115; iter: 0; batch classifier loss: 0.209519; batch adversarial loss: 0.458950\n",
      "epoch 116; iter: 0; batch classifier loss: 0.219401; batch adversarial loss: 0.565518\n",
      "epoch 117; iter: 0; batch classifier loss: 0.198340; batch adversarial loss: 0.399335\n",
      "epoch 118; iter: 0; batch classifier loss: 0.195288; batch adversarial loss: 0.540916\n",
      "epoch 119; iter: 0; batch classifier loss: 0.155556; batch adversarial loss: 0.507689\n",
      "epoch 120; iter: 0; batch classifier loss: 0.174550; batch adversarial loss: 0.434412\n",
      "epoch 121; iter: 0; batch classifier loss: 0.259817; batch adversarial loss: 0.377419\n",
      "epoch 122; iter: 0; batch classifier loss: 0.171216; batch adversarial loss: 0.473075\n",
      "epoch 123; iter: 0; batch classifier loss: 0.182581; batch adversarial loss: 0.433134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.089011; batch adversarial loss: 0.445922\n",
      "epoch 125; iter: 0; batch classifier loss: 0.085504; batch adversarial loss: 0.473009\n",
      "epoch 126; iter: 0; batch classifier loss: 0.103980; batch adversarial loss: 0.438415\n",
      "epoch 127; iter: 0; batch classifier loss: 0.065508; batch adversarial loss: 0.410410\n",
      "epoch 128; iter: 0; batch classifier loss: 0.081169; batch adversarial loss: 0.441499\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056884; batch adversarial loss: 0.499289\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037682; batch adversarial loss: 0.428209\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041820; batch adversarial loss: 0.510231\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048443; batch adversarial loss: 0.369929\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022801; batch adversarial loss: 0.418826\n",
      "epoch 134; iter: 0; batch classifier loss: 0.046219; batch adversarial loss: 0.476779\n",
      "epoch 135; iter: 0; batch classifier loss: 0.073278; batch adversarial loss: 0.420003\n",
      "epoch 136; iter: 0; batch classifier loss: 0.012386; batch adversarial loss: 0.467295\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030149; batch adversarial loss: 0.393148\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026794; batch adversarial loss: 0.481293\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028743; batch adversarial loss: 0.428656\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024884; batch adversarial loss: 0.481964\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017493; batch adversarial loss: 0.457982\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029455; batch adversarial loss: 0.471478\n",
      "epoch 143; iter: 0; batch classifier loss: 0.017217; batch adversarial loss: 0.520982\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025844; batch adversarial loss: 0.458909\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034673; batch adversarial loss: 0.467300\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031001; batch adversarial loss: 0.475474\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040554; batch adversarial loss: 0.417740\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025851; batch adversarial loss: 0.412729\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020739; batch adversarial loss: 0.437988\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043128; batch adversarial loss: 0.487321\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020409; batch adversarial loss: 0.513153\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026793; batch adversarial loss: 0.603517\n",
      "epoch 153; iter: 0; batch classifier loss: 0.041642; batch adversarial loss: 0.436162\n",
      "epoch 154; iter: 0; batch classifier loss: 0.052392; batch adversarial loss: 0.499428\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014457; batch adversarial loss: 0.387160\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030015; batch adversarial loss: 0.426054\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038612; batch adversarial loss: 0.417131\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018594; batch adversarial loss: 0.483935\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037764; batch adversarial loss: 0.511611\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009440; batch adversarial loss: 0.451411\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017105; batch adversarial loss: 0.435385\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012369; batch adversarial loss: 0.463566\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016315; batch adversarial loss: 0.520721\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038603; batch adversarial loss: 0.413641\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010239; batch adversarial loss: 0.541760\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040650; batch adversarial loss: 0.446998\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013449; batch adversarial loss: 0.373310\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021376; batch adversarial loss: 0.482924\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021367; batch adversarial loss: 0.438534\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019129; batch adversarial loss: 0.522806\n",
      "epoch 171; iter: 0; batch classifier loss: 0.041191; batch adversarial loss: 0.453805\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036477; batch adversarial loss: 0.528669\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038816; batch adversarial loss: 0.399356\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021620; batch adversarial loss: 0.540029\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031778; batch adversarial loss: 0.435459\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019605; batch adversarial loss: 0.410724\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030731; batch adversarial loss: 0.382632\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021174; batch adversarial loss: 0.492352\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029817; batch adversarial loss: 0.494581\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014818; batch adversarial loss: 0.399573\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017835; batch adversarial loss: 0.511340\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016417; batch adversarial loss: 0.452948\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034516; batch adversarial loss: 0.409817\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015517; batch adversarial loss: 0.437909\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008981; batch adversarial loss: 0.464492\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019748; batch adversarial loss: 0.533643\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019964; batch adversarial loss: 0.497454\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013307; batch adversarial loss: 0.421313\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025368; batch adversarial loss: 0.383021\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016308; batch adversarial loss: 0.445276\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027502; batch adversarial loss: 0.510784\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014177; batch adversarial loss: 0.408090\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022463; batch adversarial loss: 0.431370\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020295; batch adversarial loss: 0.420474\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009144; batch adversarial loss: 0.481789\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013268; batch adversarial loss: 0.468483\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029013; batch adversarial loss: 0.506268\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018915; batch adversarial loss: 0.475463\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018722; batch adversarial loss: 0.488795\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679098; batch adversarial loss: 0.731525\n",
      "epoch 1; iter: 0; batch classifier loss: 0.488481; batch adversarial loss: 0.686996\n",
      "epoch 2; iter: 0; batch classifier loss: 0.339192; batch adversarial loss: 0.630040\n",
      "epoch 3; iter: 0; batch classifier loss: 0.350718; batch adversarial loss: 0.616155\n",
      "epoch 4; iter: 0; batch classifier loss: 0.386358; batch adversarial loss: 0.602675\n",
      "epoch 5; iter: 0; batch classifier loss: 0.488949; batch adversarial loss: 0.581492\n",
      "epoch 6; iter: 0; batch classifier loss: 0.378868; batch adversarial loss: 0.543972\n",
      "epoch 7; iter: 0; batch classifier loss: 0.420967; batch adversarial loss: 0.548418\n",
      "epoch 8; iter: 0; batch classifier loss: 0.326802; batch adversarial loss: 0.528525\n",
      "epoch 9; iter: 0; batch classifier loss: 0.377941; batch adversarial loss: 0.520725\n",
      "epoch 10; iter: 0; batch classifier loss: 0.272064; batch adversarial loss: 0.557343\n",
      "epoch 11; iter: 0; batch classifier loss: 0.309719; batch adversarial loss: 0.516520\n",
      "epoch 12; iter: 0; batch classifier loss: 0.351103; batch adversarial loss: 0.529409\n",
      "epoch 13; iter: 0; batch classifier loss: 0.357924; batch adversarial loss: 0.578243\n",
      "epoch 14; iter: 0; batch classifier loss: 0.357619; batch adversarial loss: 0.517756\n",
      "epoch 15; iter: 0; batch classifier loss: 0.346441; batch adversarial loss: 0.524151\n",
      "epoch 16; iter: 0; batch classifier loss: 0.288530; batch adversarial loss: 0.498689\n",
      "epoch 17; iter: 0; batch classifier loss: 0.297870; batch adversarial loss: 0.502145\n",
      "epoch 18; iter: 0; batch classifier loss: 0.327589; batch adversarial loss: 0.512329\n",
      "epoch 19; iter: 0; batch classifier loss: 0.305967; batch adversarial loss: 0.472167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.204015; batch adversarial loss: 0.521750\n",
      "epoch 21; iter: 0; batch classifier loss: 0.247427; batch adversarial loss: 0.522639\n",
      "epoch 22; iter: 0; batch classifier loss: 0.253022; batch adversarial loss: 0.475706\n",
      "epoch 23; iter: 0; batch classifier loss: 0.230397; batch adversarial loss: 0.530615\n",
      "epoch 24; iter: 0; batch classifier loss: 0.249168; batch adversarial loss: 0.485406\n",
      "epoch 25; iter: 0; batch classifier loss: 0.204259; batch adversarial loss: 0.460877\n",
      "epoch 26; iter: 0; batch classifier loss: 0.268880; batch adversarial loss: 0.554356\n",
      "epoch 27; iter: 0; batch classifier loss: 0.244738; batch adversarial loss: 0.425147\n",
      "epoch 28; iter: 0; batch classifier loss: 0.180527; batch adversarial loss: 0.568341\n",
      "epoch 29; iter: 0; batch classifier loss: 0.205403; batch adversarial loss: 0.470617\n",
      "epoch 30; iter: 0; batch classifier loss: 0.180936; batch adversarial loss: 0.475123\n",
      "epoch 31; iter: 0; batch classifier loss: 0.193951; batch adversarial loss: 0.405014\n",
      "epoch 32; iter: 0; batch classifier loss: 0.227756; batch adversarial loss: 0.506542\n",
      "epoch 33; iter: 0; batch classifier loss: 0.190114; batch adversarial loss: 0.498780\n",
      "epoch 34; iter: 0; batch classifier loss: 0.168280; batch adversarial loss: 0.456968\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140120; batch adversarial loss: 0.464067\n",
      "epoch 36; iter: 0; batch classifier loss: 0.120294; batch adversarial loss: 0.357660\n",
      "epoch 37; iter: 0; batch classifier loss: 0.125516; batch adversarial loss: 0.503613\n",
      "epoch 38; iter: 0; batch classifier loss: 0.149212; batch adversarial loss: 0.335482\n",
      "epoch 39; iter: 0; batch classifier loss: 0.115535; batch adversarial loss: 0.502798\n",
      "epoch 40; iter: 0; batch classifier loss: 0.142631; batch adversarial loss: 0.434237\n",
      "epoch 41; iter: 0; batch classifier loss: 0.153316; batch adversarial loss: 0.425830\n",
      "epoch 42; iter: 0; batch classifier loss: 0.151380; batch adversarial loss: 0.409340\n",
      "epoch 43; iter: 0; batch classifier loss: 0.159010; batch adversarial loss: 0.464687\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105111; batch adversarial loss: 0.486696\n",
      "epoch 45; iter: 0; batch classifier loss: 0.119408; batch adversarial loss: 0.339042\n",
      "epoch 46; iter: 0; batch classifier loss: 0.151161; batch adversarial loss: 0.402064\n",
      "epoch 47; iter: 0; batch classifier loss: 0.076311; batch adversarial loss: 0.477358\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081370; batch adversarial loss: 0.377835\n",
      "epoch 49; iter: 0; batch classifier loss: 0.089191; batch adversarial loss: 0.473621\n",
      "epoch 50; iter: 0; batch classifier loss: 0.133311; batch adversarial loss: 0.499816\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121332; batch adversarial loss: 0.467923\n",
      "epoch 52; iter: 0; batch classifier loss: 0.081927; batch adversarial loss: 0.406249\n",
      "epoch 53; iter: 0; batch classifier loss: 0.092882; batch adversarial loss: 0.414142\n",
      "epoch 54; iter: 0; batch classifier loss: 0.087901; batch adversarial loss: 0.583105\n",
      "epoch 55; iter: 0; batch classifier loss: 0.070328; batch adversarial loss: 0.494517\n",
      "epoch 56; iter: 0; batch classifier loss: 0.072097; batch adversarial loss: 0.478771\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072556; batch adversarial loss: 0.408582\n",
      "epoch 58; iter: 0; batch classifier loss: 0.075213; batch adversarial loss: 0.465613\n",
      "epoch 59; iter: 0; batch classifier loss: 0.117462; batch adversarial loss: 0.393565\n",
      "epoch 60; iter: 0; batch classifier loss: 0.103532; batch adversarial loss: 0.458623\n",
      "epoch 61; iter: 0; batch classifier loss: 0.118367; batch adversarial loss: 0.531737\n",
      "epoch 62; iter: 0; batch classifier loss: 0.054590; batch adversarial loss: 0.446205\n",
      "epoch 63; iter: 0; batch classifier loss: 0.049352; batch adversarial loss: 0.469865\n",
      "epoch 64; iter: 0; batch classifier loss: 0.059983; batch adversarial loss: 0.443427\n",
      "epoch 65; iter: 0; batch classifier loss: 0.091688; batch adversarial loss: 0.437187\n",
      "epoch 66; iter: 0; batch classifier loss: 0.069419; batch adversarial loss: 0.526773\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061912; batch adversarial loss: 0.437791\n",
      "epoch 68; iter: 0; batch classifier loss: 0.050023; batch adversarial loss: 0.402263\n",
      "epoch 69; iter: 0; batch classifier loss: 0.050563; batch adversarial loss: 0.419295\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066260; batch adversarial loss: 0.444551\n",
      "epoch 71; iter: 0; batch classifier loss: 0.066212; batch adversarial loss: 0.390829\n",
      "epoch 72; iter: 0; batch classifier loss: 0.090783; batch adversarial loss: 0.500313\n",
      "epoch 73; iter: 0; batch classifier loss: 0.050534; batch adversarial loss: 0.436319\n",
      "epoch 74; iter: 0; batch classifier loss: 0.061862; batch adversarial loss: 0.452779\n",
      "epoch 75; iter: 0; batch classifier loss: 0.066635; batch adversarial loss: 0.443194\n",
      "epoch 76; iter: 0; batch classifier loss: 0.041870; batch adversarial loss: 0.440047\n",
      "epoch 77; iter: 0; batch classifier loss: 0.068753; batch adversarial loss: 0.515955\n",
      "epoch 78; iter: 0; batch classifier loss: 0.068833; batch adversarial loss: 0.397265\n",
      "epoch 79; iter: 0; batch classifier loss: 0.066253; batch adversarial loss: 0.379286\n",
      "epoch 80; iter: 0; batch classifier loss: 0.033156; batch adversarial loss: 0.642870\n",
      "epoch 81; iter: 0; batch classifier loss: 0.028135; batch adversarial loss: 0.485422\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053163; batch adversarial loss: 0.439019\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062633; batch adversarial loss: 0.439199\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046066; batch adversarial loss: 0.494410\n",
      "epoch 85; iter: 0; batch classifier loss: 0.072365; batch adversarial loss: 0.423245\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051038; batch adversarial loss: 0.405128\n",
      "epoch 87; iter: 0; batch classifier loss: 0.032319; batch adversarial loss: 0.427013\n",
      "epoch 88; iter: 0; batch classifier loss: 0.038488; batch adversarial loss: 0.484943\n",
      "epoch 89; iter: 0; batch classifier loss: 0.026243; batch adversarial loss: 0.375939\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039364; batch adversarial loss: 0.502731\n",
      "epoch 91; iter: 0; batch classifier loss: 0.037131; batch adversarial loss: 0.482231\n",
      "epoch 92; iter: 0; batch classifier loss: 0.076527; batch adversarial loss: 0.502997\n",
      "epoch 93; iter: 0; batch classifier loss: 0.060456; batch adversarial loss: 0.387044\n",
      "epoch 94; iter: 0; batch classifier loss: 0.067414; batch adversarial loss: 0.436241\n",
      "epoch 95; iter: 0; batch classifier loss: 0.036745; batch adversarial loss: 0.367103\n",
      "epoch 96; iter: 0; batch classifier loss: 0.085033; batch adversarial loss: 0.505201\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037095; batch adversarial loss: 0.420239\n",
      "epoch 98; iter: 0; batch classifier loss: 0.030298; batch adversarial loss: 0.452246\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045379; batch adversarial loss: 0.358843\n",
      "epoch 100; iter: 0; batch classifier loss: 0.063914; batch adversarial loss: 0.379585\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040298; batch adversarial loss: 0.400403\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031843; batch adversarial loss: 0.464024\n",
      "epoch 103; iter: 0; batch classifier loss: 0.029274; batch adversarial loss: 0.425128\n",
      "epoch 104; iter: 0; batch classifier loss: 0.040241; batch adversarial loss: 0.372780\n",
      "epoch 105; iter: 0; batch classifier loss: 0.010831; batch adversarial loss: 0.438090\n",
      "epoch 106; iter: 0; batch classifier loss: 0.028197; batch adversarial loss: 0.466967\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035192; batch adversarial loss: 0.473815\n",
      "epoch 108; iter: 0; batch classifier loss: 0.013815; batch adversarial loss: 0.431761\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053227; batch adversarial loss: 0.571813\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026334; batch adversarial loss: 0.496076\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030616; batch adversarial loss: 0.475392\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026114; batch adversarial loss: 0.389714\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052836; batch adversarial loss: 0.467762\n",
      "epoch 114; iter: 0; batch classifier loss: 0.024638; batch adversarial loss: 0.377686\n",
      "epoch 115; iter: 0; batch classifier loss: 0.025894; batch adversarial loss: 0.441085\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029758; batch adversarial loss: 0.409373\n",
      "epoch 117; iter: 0; batch classifier loss: 0.021905; batch adversarial loss: 0.441734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.024048; batch adversarial loss: 0.422558\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042039; batch adversarial loss: 0.381917\n",
      "epoch 120; iter: 0; batch classifier loss: 0.016628; batch adversarial loss: 0.520434\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036918; batch adversarial loss: 0.469907\n",
      "epoch 122; iter: 0; batch classifier loss: 0.021636; batch adversarial loss: 0.449646\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029784; batch adversarial loss: 0.472647\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052830; batch adversarial loss: 0.467741\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039074; batch adversarial loss: 0.558370\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039390; batch adversarial loss: 0.409907\n",
      "epoch 127; iter: 0; batch classifier loss: 0.020375; batch adversarial loss: 0.382808\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030804; batch adversarial loss: 0.385491\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017242; batch adversarial loss: 0.376352\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018326; batch adversarial loss: 0.517518\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018823; batch adversarial loss: 0.422176\n",
      "epoch 132; iter: 0; batch classifier loss: 0.009421; batch adversarial loss: 0.371065\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018539; batch adversarial loss: 0.492007\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029168; batch adversarial loss: 0.509411\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034838; batch adversarial loss: 0.395124\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020540; batch adversarial loss: 0.574804\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017416; batch adversarial loss: 0.421393\n",
      "epoch 138; iter: 0; batch classifier loss: 0.042910; batch adversarial loss: 0.429113\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024637; batch adversarial loss: 0.453871\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028959; batch adversarial loss: 0.487555\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016781; batch adversarial loss: 0.427987\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023148; batch adversarial loss: 0.564164\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013158; batch adversarial loss: 0.468534\n",
      "epoch 144; iter: 0; batch classifier loss: 0.010366; batch adversarial loss: 0.442115\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020027; batch adversarial loss: 0.529857\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031294; batch adversarial loss: 0.425482\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018294; batch adversarial loss: 0.415393\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024800; batch adversarial loss: 0.403855\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023138; batch adversarial loss: 0.436787\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011005; batch adversarial loss: 0.568851\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017544; batch adversarial loss: 0.368874\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015610; batch adversarial loss: 0.420977\n",
      "epoch 153; iter: 0; batch classifier loss: 0.006945; batch adversarial loss: 0.471703\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018273; batch adversarial loss: 0.481593\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014271; batch adversarial loss: 0.495386\n",
      "epoch 156; iter: 0; batch classifier loss: 0.008098; batch adversarial loss: 0.407498\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026729; batch adversarial loss: 0.408222\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017788; batch adversarial loss: 0.488000\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025222; batch adversarial loss: 0.568795\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021499; batch adversarial loss: 0.487418\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040428; batch adversarial loss: 0.479709\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024197; batch adversarial loss: 0.405068\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021260; batch adversarial loss: 0.474678\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016751; batch adversarial loss: 0.493799\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016543; batch adversarial loss: 0.484782\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022775; batch adversarial loss: 0.382890\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006026; batch adversarial loss: 0.396019\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015717; batch adversarial loss: 0.435747\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012129; batch adversarial loss: 0.427226\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025467; batch adversarial loss: 0.442443\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033535; batch adversarial loss: 0.547570\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018693; batch adversarial loss: 0.528524\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009978; batch adversarial loss: 0.477224\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013203; batch adversarial loss: 0.454468\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020817; batch adversarial loss: 0.388547\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015349; batch adversarial loss: 0.478820\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008828; batch adversarial loss: 0.392830\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012422; batch adversarial loss: 0.386331\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012461; batch adversarial loss: 0.406226\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020091; batch adversarial loss: 0.432050\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016254; batch adversarial loss: 0.516735\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006950; batch adversarial loss: 0.380860\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027212; batch adversarial loss: 0.487021\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004680; batch adversarial loss: 0.522684\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015942; batch adversarial loss: 0.441932\n",
      "epoch 186; iter: 0; batch classifier loss: 0.002820; batch adversarial loss: 0.454128\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024620; batch adversarial loss: 0.417403\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006094; batch adversarial loss: 0.459630\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017101; batch adversarial loss: 0.505314\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015162; batch adversarial loss: 0.471863\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017767; batch adversarial loss: 0.472886\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014565; batch adversarial loss: 0.456928\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007328; batch adversarial loss: 0.526286\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015363; batch adversarial loss: 0.442190\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020642; batch adversarial loss: 0.390103\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010436; batch adversarial loss: 0.430075\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004658; batch adversarial loss: 0.471442\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027101; batch adversarial loss: 0.539602\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020795; batch adversarial loss: 0.487023\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691539; batch adversarial loss: 0.666771\n",
      "epoch 1; iter: 0; batch classifier loss: 0.431743; batch adversarial loss: 0.640595\n",
      "epoch 2; iter: 0; batch classifier loss: 0.355838; batch adversarial loss: 0.603230\n",
      "epoch 3; iter: 0; batch classifier loss: 0.394974; batch adversarial loss: 0.605453\n",
      "epoch 4; iter: 0; batch classifier loss: 0.370671; batch adversarial loss: 0.552653\n",
      "epoch 5; iter: 0; batch classifier loss: 0.240769; batch adversarial loss: 0.543764\n",
      "epoch 6; iter: 0; batch classifier loss: 0.298948; batch adversarial loss: 0.526593\n",
      "epoch 7; iter: 0; batch classifier loss: 0.249883; batch adversarial loss: 0.531593\n",
      "epoch 8; iter: 0; batch classifier loss: 0.220681; batch adversarial loss: 0.558099\n",
      "epoch 9; iter: 0; batch classifier loss: 0.249306; batch adversarial loss: 0.498549\n",
      "epoch 10; iter: 0; batch classifier loss: 0.297969; batch adversarial loss: 0.461303\n",
      "epoch 11; iter: 0; batch classifier loss: 0.244508; batch adversarial loss: 0.458533\n",
      "epoch 12; iter: 0; batch classifier loss: 0.211260; batch adversarial loss: 0.477306\n",
      "epoch 13; iter: 0; batch classifier loss: 0.213268; batch adversarial loss: 0.440870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.189841; batch adversarial loss: 0.501372\n",
      "epoch 15; iter: 0; batch classifier loss: 0.220726; batch adversarial loss: 0.417281\n",
      "epoch 16; iter: 0; batch classifier loss: 0.197522; batch adversarial loss: 0.411842\n",
      "epoch 17; iter: 0; batch classifier loss: 0.189068; batch adversarial loss: 0.504335\n",
      "epoch 18; iter: 0; batch classifier loss: 0.204774; batch adversarial loss: 0.561563\n",
      "epoch 19; iter: 0; batch classifier loss: 0.143854; batch adversarial loss: 0.534922\n",
      "epoch 20; iter: 0; batch classifier loss: 0.230391; batch adversarial loss: 0.565660\n",
      "epoch 21; iter: 0; batch classifier loss: 0.208400; batch adversarial loss: 0.645635\n",
      "epoch 22; iter: 0; batch classifier loss: 0.162845; batch adversarial loss: 0.541975\n",
      "epoch 23; iter: 0; batch classifier loss: 0.225918; batch adversarial loss: 0.497161\n",
      "epoch 24; iter: 0; batch classifier loss: 0.227586; batch adversarial loss: 0.478995\n",
      "epoch 25; iter: 0; batch classifier loss: 0.259646; batch adversarial loss: 0.483901\n",
      "epoch 26; iter: 0; batch classifier loss: 0.233487; batch adversarial loss: 0.457980\n",
      "epoch 27; iter: 0; batch classifier loss: 0.267966; batch adversarial loss: 0.511829\n",
      "epoch 28; iter: 0; batch classifier loss: 0.268870; batch adversarial loss: 0.495585\n",
      "epoch 29; iter: 0; batch classifier loss: 0.428732; batch adversarial loss: 0.426988\n",
      "epoch 30; iter: 0; batch classifier loss: 0.241672; batch adversarial loss: 0.452143\n",
      "epoch 31; iter: 0; batch classifier loss: 0.157815; batch adversarial loss: 0.401133\n",
      "epoch 32; iter: 0; batch classifier loss: 0.110598; batch adversarial loss: 0.469890\n",
      "epoch 33; iter: 0; batch classifier loss: 0.098783; batch adversarial loss: 0.521179\n",
      "epoch 34; iter: 0; batch classifier loss: 0.096017; batch adversarial loss: 0.367992\n",
      "epoch 35; iter: 0; batch classifier loss: 0.083348; batch adversarial loss: 0.483204\n",
      "epoch 36; iter: 0; batch classifier loss: 0.096237; batch adversarial loss: 0.446108\n",
      "epoch 37; iter: 0; batch classifier loss: 0.096353; batch adversarial loss: 0.418388\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099717; batch adversarial loss: 0.454863\n",
      "epoch 39; iter: 0; batch classifier loss: 0.070942; batch adversarial loss: 0.466477\n",
      "epoch 40; iter: 0; batch classifier loss: 0.092606; batch adversarial loss: 0.394684\n",
      "epoch 41; iter: 0; batch classifier loss: 0.068338; batch adversarial loss: 0.470589\n",
      "epoch 42; iter: 0; batch classifier loss: 0.084844; batch adversarial loss: 0.386761\n",
      "epoch 43; iter: 0; batch classifier loss: 0.131631; batch adversarial loss: 0.457904\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085655; batch adversarial loss: 0.467386\n",
      "epoch 45; iter: 0; batch classifier loss: 0.079276; batch adversarial loss: 0.505960\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116189; batch adversarial loss: 0.320761\n",
      "epoch 47; iter: 0; batch classifier loss: 0.091804; batch adversarial loss: 0.438766\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100861; batch adversarial loss: 0.508731\n",
      "epoch 49; iter: 0; batch classifier loss: 0.142215; batch adversarial loss: 0.431582\n",
      "epoch 50; iter: 0; batch classifier loss: 0.105095; batch adversarial loss: 0.425385\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073227; batch adversarial loss: 0.537634\n",
      "epoch 52; iter: 0; batch classifier loss: 0.065963; batch adversarial loss: 0.434472\n",
      "epoch 53; iter: 0; batch classifier loss: 0.091267; batch adversarial loss: 0.398655\n",
      "epoch 54; iter: 0; batch classifier loss: 0.102153; batch adversarial loss: 0.354049\n",
      "epoch 55; iter: 0; batch classifier loss: 0.059569; batch adversarial loss: 0.492080\n",
      "epoch 56; iter: 0; batch classifier loss: 0.064215; batch adversarial loss: 0.421599\n",
      "epoch 57; iter: 0; batch classifier loss: 0.092991; batch adversarial loss: 0.463845\n",
      "epoch 58; iter: 0; batch classifier loss: 0.073457; batch adversarial loss: 0.530059\n",
      "epoch 59; iter: 0; batch classifier loss: 0.041838; batch adversarial loss: 0.463302\n",
      "epoch 60; iter: 0; batch classifier loss: 0.084750; batch adversarial loss: 0.464409\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090787; batch adversarial loss: 0.428464\n",
      "epoch 62; iter: 0; batch classifier loss: 0.106429; batch adversarial loss: 0.432119\n",
      "epoch 63; iter: 0; batch classifier loss: 0.061065; batch adversarial loss: 0.446234\n",
      "epoch 64; iter: 0; batch classifier loss: 0.105736; batch adversarial loss: 0.529243\n",
      "epoch 65; iter: 0; batch classifier loss: 0.107546; batch adversarial loss: 0.404606\n",
      "epoch 66; iter: 0; batch classifier loss: 0.103100; batch adversarial loss: 0.470688\n",
      "epoch 67; iter: 0; batch classifier loss: 0.108372; batch adversarial loss: 0.428415\n",
      "epoch 68; iter: 0; batch classifier loss: 0.050097; batch adversarial loss: 0.540606\n",
      "epoch 69; iter: 0; batch classifier loss: 0.041120; batch adversarial loss: 0.474355\n",
      "epoch 70; iter: 0; batch classifier loss: 0.082918; batch adversarial loss: 0.523331\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063336; batch adversarial loss: 0.560960\n",
      "epoch 72; iter: 0; batch classifier loss: 0.052290; batch adversarial loss: 0.428916\n",
      "epoch 73; iter: 0; batch classifier loss: 0.054877; batch adversarial loss: 0.443308\n",
      "epoch 74; iter: 0; batch classifier loss: 0.109082; batch adversarial loss: 0.501081\n",
      "epoch 75; iter: 0; batch classifier loss: 0.089722; batch adversarial loss: 0.513834\n",
      "epoch 76; iter: 0; batch classifier loss: 0.046382; batch adversarial loss: 0.341247\n",
      "epoch 77; iter: 0; batch classifier loss: 0.144240; batch adversarial loss: 0.370479\n",
      "epoch 78; iter: 0; batch classifier loss: 0.101816; batch adversarial loss: 0.539167\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070947; batch adversarial loss: 0.420649\n",
      "epoch 80; iter: 0; batch classifier loss: 0.096518; batch adversarial loss: 0.454146\n",
      "epoch 81; iter: 0; batch classifier loss: 0.048024; batch adversarial loss: 0.558315\n",
      "epoch 82; iter: 0; batch classifier loss: 0.088958; batch adversarial loss: 0.448666\n",
      "epoch 83; iter: 0; batch classifier loss: 0.058472; batch adversarial loss: 0.635661\n",
      "epoch 84; iter: 0; batch classifier loss: 0.033817; batch adversarial loss: 0.490119\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088907; batch adversarial loss: 0.503115\n",
      "epoch 86; iter: 0; batch classifier loss: 0.093404; batch adversarial loss: 0.468411\n",
      "epoch 87; iter: 0; batch classifier loss: 0.108646; batch adversarial loss: 0.453023\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041600; batch adversarial loss: 0.520723\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053629; batch adversarial loss: 0.441715\n",
      "epoch 90; iter: 0; batch classifier loss: 0.070053; batch adversarial loss: 0.403389\n",
      "epoch 91; iter: 0; batch classifier loss: 0.079158; batch adversarial loss: 0.590825\n",
      "epoch 92; iter: 0; batch classifier loss: 0.054362; batch adversarial loss: 0.450455\n",
      "epoch 93; iter: 0; batch classifier loss: 0.027304; batch adversarial loss: 0.451651\n",
      "epoch 94; iter: 0; batch classifier loss: 0.100840; batch adversarial loss: 0.413326\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060275; batch adversarial loss: 0.495050\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057376; batch adversarial loss: 0.501882\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071112; batch adversarial loss: 0.415183\n",
      "epoch 98; iter: 0; batch classifier loss: 0.026495; batch adversarial loss: 0.480426\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055515; batch adversarial loss: 0.522783\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067106; batch adversarial loss: 0.532532\n",
      "epoch 101; iter: 0; batch classifier loss: 0.052295; batch adversarial loss: 0.456342\n",
      "epoch 102; iter: 0; batch classifier loss: 0.080219; batch adversarial loss: 0.498132\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038294; batch adversarial loss: 0.405780\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066321; batch adversarial loss: 0.432302\n",
      "epoch 105; iter: 0; batch classifier loss: 0.107591; batch adversarial loss: 0.451725\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036188; batch adversarial loss: 0.503279\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063059; batch adversarial loss: 0.430839\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065668; batch adversarial loss: 0.394073\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046579; batch adversarial loss: 0.472358\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057246; batch adversarial loss: 0.444060\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045712; batch adversarial loss: 0.458106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.054201; batch adversarial loss: 0.368084\n",
      "epoch 113; iter: 0; batch classifier loss: 0.018337; batch adversarial loss: 0.460347\n",
      "epoch 114; iter: 0; batch classifier loss: 0.031161; batch adversarial loss: 0.424630\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034528; batch adversarial loss: 0.435405\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030457; batch adversarial loss: 0.506620\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050819; batch adversarial loss: 0.471060\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028902; batch adversarial loss: 0.434004\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054416; batch adversarial loss: 0.424098\n",
      "epoch 120; iter: 0; batch classifier loss: 0.066352; batch adversarial loss: 0.382367\n",
      "epoch 121; iter: 0; batch classifier loss: 0.109392; batch adversarial loss: 0.392091\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045108; batch adversarial loss: 0.340225\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041186; batch adversarial loss: 0.497425\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033784; batch adversarial loss: 0.557823\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035995; batch adversarial loss: 0.588385\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033218; batch adversarial loss: 0.410859\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031933; batch adversarial loss: 0.501073\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040592; batch adversarial loss: 0.521894\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029696; batch adversarial loss: 0.443355\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037369; batch adversarial loss: 0.396873\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052587; batch adversarial loss: 0.466392\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041441; batch adversarial loss: 0.402749\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043928; batch adversarial loss: 0.375652\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031585; batch adversarial loss: 0.440712\n",
      "epoch 135; iter: 0; batch classifier loss: 0.078160; batch adversarial loss: 0.437343\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016219; batch adversarial loss: 0.436309\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037593; batch adversarial loss: 0.400474\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016941; batch adversarial loss: 0.403696\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029793; batch adversarial loss: 0.504775\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044127; batch adversarial loss: 0.406153\n",
      "epoch 141; iter: 0; batch classifier loss: 0.015217; batch adversarial loss: 0.506381\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027439; batch adversarial loss: 0.450257\n",
      "epoch 143; iter: 0; batch classifier loss: 0.060869; batch adversarial loss: 0.518212\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039885; batch adversarial loss: 0.450377\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026367; batch adversarial loss: 0.422217\n",
      "epoch 146; iter: 0; batch classifier loss: 0.036033; batch adversarial loss: 0.420622\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035602; batch adversarial loss: 0.325267\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033413; batch adversarial loss: 0.545775\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028918; batch adversarial loss: 0.522485\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043276; batch adversarial loss: 0.399500\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044023; batch adversarial loss: 0.493936\n",
      "epoch 152; iter: 0; batch classifier loss: 0.061316; batch adversarial loss: 0.515062\n",
      "epoch 153; iter: 0; batch classifier loss: 0.067525; batch adversarial loss: 0.443227\n",
      "epoch 154; iter: 0; batch classifier loss: 0.058940; batch adversarial loss: 0.465806\n",
      "epoch 155; iter: 0; batch classifier loss: 0.068847; batch adversarial loss: 0.457341\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020660; batch adversarial loss: 0.407796\n",
      "epoch 157; iter: 0; batch classifier loss: 0.056450; batch adversarial loss: 0.438690\n",
      "epoch 158; iter: 0; batch classifier loss: 0.054268; batch adversarial loss: 0.534523\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030752; batch adversarial loss: 0.444288\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020011; batch adversarial loss: 0.456276\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014303; batch adversarial loss: 0.515279\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027617; batch adversarial loss: 0.423180\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027860; batch adversarial loss: 0.454922\n",
      "epoch 164; iter: 0; batch classifier loss: 0.063722; batch adversarial loss: 0.551104\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036671; batch adversarial loss: 0.420287\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023144; batch adversarial loss: 0.429913\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012038; batch adversarial loss: 0.384916\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022666; batch adversarial loss: 0.437638\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017200; batch adversarial loss: 0.469607\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026990; batch adversarial loss: 0.472457\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007023; batch adversarial loss: 0.519994\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026729; batch adversarial loss: 0.417518\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029264; batch adversarial loss: 0.560734\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018392; batch adversarial loss: 0.410729\n",
      "epoch 175; iter: 0; batch classifier loss: 0.054730; batch adversarial loss: 0.398053\n",
      "epoch 176; iter: 0; batch classifier loss: 0.036023; batch adversarial loss: 0.539660\n",
      "epoch 177; iter: 0; batch classifier loss: 0.035780; batch adversarial loss: 0.478410\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014166; batch adversarial loss: 0.401032\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028519; batch adversarial loss: 0.555796\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029512; batch adversarial loss: 0.498673\n",
      "epoch 181; iter: 0; batch classifier loss: 0.038125; batch adversarial loss: 0.456780\n",
      "epoch 182; iter: 0; batch classifier loss: 0.052417; batch adversarial loss: 0.392839\n",
      "epoch 183; iter: 0; batch classifier loss: 0.053364; batch adversarial loss: 0.472449\n",
      "epoch 184; iter: 0; batch classifier loss: 0.054908; batch adversarial loss: 0.516975\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017295; batch adversarial loss: 0.368784\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011095; batch adversarial loss: 0.409467\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025725; batch adversarial loss: 0.492136\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033934; batch adversarial loss: 0.400404\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019737; batch adversarial loss: 0.460513\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021505; batch adversarial loss: 0.489030\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033903; batch adversarial loss: 0.350103\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026657; batch adversarial loss: 0.452628\n",
      "epoch 193; iter: 0; batch classifier loss: 0.003542; batch adversarial loss: 0.468418\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027022; batch adversarial loss: 0.441768\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010447; batch adversarial loss: 0.487851\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016336; batch adversarial loss: 0.557197\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024378; batch adversarial loss: 0.489004\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014761; batch adversarial loss: 0.490608\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032416; batch adversarial loss: 0.447173\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685875; batch adversarial loss: 0.743758\n",
      "epoch 1; iter: 0; batch classifier loss: 0.517149; batch adversarial loss: 0.701076\n",
      "epoch 2; iter: 0; batch classifier loss: 0.391492; batch adversarial loss: 0.667807\n",
      "epoch 3; iter: 0; batch classifier loss: 0.408587; batch adversarial loss: 0.643293\n",
      "epoch 4; iter: 0; batch classifier loss: 0.368138; batch adversarial loss: 0.585022\n",
      "epoch 5; iter: 0; batch classifier loss: 0.286668; batch adversarial loss: 0.581968\n",
      "epoch 6; iter: 0; batch classifier loss: 0.303021; batch adversarial loss: 0.531705\n",
      "epoch 7; iter: 0; batch classifier loss: 0.249967; batch adversarial loss: 0.541218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.294010; batch adversarial loss: 0.513083\n",
      "epoch 9; iter: 0; batch classifier loss: 0.293448; batch adversarial loss: 0.516072\n",
      "epoch 10; iter: 0; batch classifier loss: 0.209097; batch adversarial loss: 0.497542\n",
      "epoch 11; iter: 0; batch classifier loss: 0.194279; batch adversarial loss: 0.453490\n",
      "epoch 12; iter: 0; batch classifier loss: 0.211921; batch adversarial loss: 0.531237\n",
      "epoch 13; iter: 0; batch classifier loss: 0.192277; batch adversarial loss: 0.467854\n",
      "epoch 14; iter: 0; batch classifier loss: 0.184497; batch adversarial loss: 0.407092\n",
      "epoch 15; iter: 0; batch classifier loss: 0.200968; batch adversarial loss: 0.470893\n",
      "epoch 16; iter: 0; batch classifier loss: 0.148334; batch adversarial loss: 0.427577\n",
      "epoch 17; iter: 0; batch classifier loss: 0.117987; batch adversarial loss: 0.460161\n",
      "epoch 18; iter: 0; batch classifier loss: 0.201484; batch adversarial loss: 0.416573\n",
      "epoch 19; iter: 0; batch classifier loss: 0.146524; batch adversarial loss: 0.419450\n",
      "epoch 20; iter: 0; batch classifier loss: 0.127683; batch adversarial loss: 0.406765\n",
      "epoch 21; iter: 0; batch classifier loss: 0.187182; batch adversarial loss: 0.391280\n",
      "epoch 22; iter: 0; batch classifier loss: 0.155566; batch adversarial loss: 0.461834\n",
      "epoch 23; iter: 0; batch classifier loss: 0.122526; batch adversarial loss: 0.487163\n",
      "epoch 24; iter: 0; batch classifier loss: 0.146002; batch adversarial loss: 0.523092\n",
      "epoch 25; iter: 0; batch classifier loss: 0.129483; batch adversarial loss: 0.499212\n",
      "epoch 26; iter: 0; batch classifier loss: 0.102263; batch adversarial loss: 0.505361\n",
      "epoch 27; iter: 0; batch classifier loss: 0.180319; batch adversarial loss: 0.545630\n",
      "epoch 28; iter: 0; batch classifier loss: 0.156987; batch adversarial loss: 0.554922\n",
      "epoch 29; iter: 0; batch classifier loss: 0.244777; batch adversarial loss: 0.402051\n",
      "epoch 30; iter: 0; batch classifier loss: 0.221098; batch adversarial loss: 0.523425\n",
      "epoch 31; iter: 0; batch classifier loss: 0.226910; batch adversarial loss: 0.471388\n",
      "epoch 32; iter: 0; batch classifier loss: 0.285211; batch adversarial loss: 0.438592\n",
      "epoch 33; iter: 0; batch classifier loss: 0.185935; batch adversarial loss: 0.462306\n",
      "epoch 34; iter: 0; batch classifier loss: 0.172022; batch adversarial loss: 0.439888\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148550; batch adversarial loss: 0.481318\n",
      "epoch 36; iter: 0; batch classifier loss: 0.115179; batch adversarial loss: 0.410964\n",
      "epoch 37; iter: 0; batch classifier loss: 0.097805; batch adversarial loss: 0.416010\n",
      "epoch 38; iter: 0; batch classifier loss: 0.079270; batch adversarial loss: 0.432689\n",
      "epoch 39; iter: 0; batch classifier loss: 0.078741; batch adversarial loss: 0.488572\n",
      "epoch 40; iter: 0; batch classifier loss: 0.155432; batch adversarial loss: 0.402589\n",
      "epoch 41; iter: 0; batch classifier loss: 0.119109; batch adversarial loss: 0.428741\n",
      "epoch 42; iter: 0; batch classifier loss: 0.061755; batch adversarial loss: 0.456224\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104851; batch adversarial loss: 0.461819\n",
      "epoch 44; iter: 0; batch classifier loss: 0.091462; batch adversarial loss: 0.522692\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091124; batch adversarial loss: 0.445100\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086492; batch adversarial loss: 0.401159\n",
      "epoch 47; iter: 0; batch classifier loss: 0.062379; batch adversarial loss: 0.430205\n",
      "epoch 48; iter: 0; batch classifier loss: 0.069084; batch adversarial loss: 0.454336\n",
      "epoch 49; iter: 0; batch classifier loss: 0.079672; batch adversarial loss: 0.436948\n",
      "epoch 50; iter: 0; batch classifier loss: 0.061176; batch adversarial loss: 0.480720\n",
      "epoch 51; iter: 0; batch classifier loss: 0.100903; batch adversarial loss: 0.429323\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100144; batch adversarial loss: 0.415690\n",
      "epoch 53; iter: 0; batch classifier loss: 0.090791; batch adversarial loss: 0.446538\n",
      "epoch 54; iter: 0; batch classifier loss: 0.129342; batch adversarial loss: 0.426335\n",
      "epoch 55; iter: 0; batch classifier loss: 0.141280; batch adversarial loss: 0.395572\n",
      "epoch 56; iter: 0; batch classifier loss: 0.126296; batch adversarial loss: 0.468593\n",
      "epoch 57; iter: 0; batch classifier loss: 0.090411; batch adversarial loss: 0.427805\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072320; batch adversarial loss: 0.416250\n",
      "epoch 59; iter: 0; batch classifier loss: 0.046428; batch adversarial loss: 0.445767\n",
      "epoch 60; iter: 0; batch classifier loss: 0.058667; batch adversarial loss: 0.444128\n",
      "epoch 61; iter: 0; batch classifier loss: 0.058474; batch adversarial loss: 0.554368\n",
      "epoch 62; iter: 0; batch classifier loss: 0.091934; batch adversarial loss: 0.400520\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085156; batch adversarial loss: 0.433712\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073253; batch adversarial loss: 0.512360\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087748; batch adversarial loss: 0.471770\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096793; batch adversarial loss: 0.516632\n",
      "epoch 67; iter: 0; batch classifier loss: 0.075407; batch adversarial loss: 0.559791\n",
      "epoch 68; iter: 0; batch classifier loss: 0.072525; batch adversarial loss: 0.365101\n",
      "epoch 69; iter: 0; batch classifier loss: 0.082468; batch adversarial loss: 0.438361\n",
      "epoch 70; iter: 0; batch classifier loss: 0.059798; batch adversarial loss: 0.473557\n",
      "epoch 71; iter: 0; batch classifier loss: 0.081483; batch adversarial loss: 0.504618\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074879; batch adversarial loss: 0.493172\n",
      "epoch 73; iter: 0; batch classifier loss: 0.073790; batch adversarial loss: 0.544122\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067176; batch adversarial loss: 0.420905\n",
      "epoch 75; iter: 0; batch classifier loss: 0.058526; batch adversarial loss: 0.473264\n",
      "epoch 76; iter: 0; batch classifier loss: 0.077181; batch adversarial loss: 0.441063\n",
      "epoch 77; iter: 0; batch classifier loss: 0.092063; batch adversarial loss: 0.477605\n",
      "epoch 78; iter: 0; batch classifier loss: 0.046174; batch adversarial loss: 0.441188\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044072; batch adversarial loss: 0.427747\n",
      "epoch 80; iter: 0; batch classifier loss: 0.059739; batch adversarial loss: 0.574359\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074815; batch adversarial loss: 0.454755\n",
      "epoch 82; iter: 0; batch classifier loss: 0.051875; batch adversarial loss: 0.432922\n",
      "epoch 83; iter: 0; batch classifier loss: 0.069743; batch adversarial loss: 0.536988\n",
      "epoch 84; iter: 0; batch classifier loss: 0.054897; batch adversarial loss: 0.428237\n",
      "epoch 85; iter: 0; batch classifier loss: 0.047967; batch adversarial loss: 0.431621\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063196; batch adversarial loss: 0.471054\n",
      "epoch 87; iter: 0; batch classifier loss: 0.087134; batch adversarial loss: 0.393822\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051663; batch adversarial loss: 0.380846\n",
      "epoch 89; iter: 0; batch classifier loss: 0.091261; batch adversarial loss: 0.491023\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060839; batch adversarial loss: 0.420371\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059915; batch adversarial loss: 0.425083\n",
      "epoch 92; iter: 0; batch classifier loss: 0.094600; batch adversarial loss: 0.470373\n",
      "epoch 93; iter: 0; batch classifier loss: 0.049084; batch adversarial loss: 0.351160\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083937; batch adversarial loss: 0.486079\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038787; batch adversarial loss: 0.476771\n",
      "epoch 96; iter: 0; batch classifier loss: 0.077184; batch adversarial loss: 0.502380\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073430; batch adversarial loss: 0.467227\n",
      "epoch 98; iter: 0; batch classifier loss: 0.041865; batch adversarial loss: 0.457879\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061160; batch adversarial loss: 0.509037\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059642; batch adversarial loss: 0.538447\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058215; batch adversarial loss: 0.502816\n",
      "epoch 102; iter: 0; batch classifier loss: 0.028081; batch adversarial loss: 0.370043\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054297; batch adversarial loss: 0.433643\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043549; batch adversarial loss: 0.450511\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062844; batch adversarial loss: 0.424562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.034957; batch adversarial loss: 0.475410\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047150; batch adversarial loss: 0.363443\n",
      "epoch 108; iter: 0; batch classifier loss: 0.068437; batch adversarial loss: 0.448009\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032964; batch adversarial loss: 0.509762\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049989; batch adversarial loss: 0.475213\n",
      "epoch 111; iter: 0; batch classifier loss: 0.091838; batch adversarial loss: 0.577312\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031560; batch adversarial loss: 0.422850\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049815; batch adversarial loss: 0.489874\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028597; batch adversarial loss: 0.463077\n",
      "epoch 115; iter: 0; batch classifier loss: 0.025255; batch adversarial loss: 0.546086\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060480; batch adversarial loss: 0.353867\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032485; batch adversarial loss: 0.436275\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046406; batch adversarial loss: 0.562441\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030117; batch adversarial loss: 0.412670\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045519; batch adversarial loss: 0.314655\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029246; batch adversarial loss: 0.463469\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044592; batch adversarial loss: 0.533543\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035201; batch adversarial loss: 0.454511\n",
      "epoch 124; iter: 0; batch classifier loss: 0.014312; batch adversarial loss: 0.417200\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035455; batch adversarial loss: 0.444337\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029330; batch adversarial loss: 0.314464\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035252; batch adversarial loss: 0.487600\n",
      "epoch 128; iter: 0; batch classifier loss: 0.020361; batch adversarial loss: 0.383834\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056761; batch adversarial loss: 0.418113\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040657; batch adversarial loss: 0.397806\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033123; batch adversarial loss: 0.446551\n",
      "epoch 132; iter: 0; batch classifier loss: 0.076424; batch adversarial loss: 0.437496\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045824; batch adversarial loss: 0.452689\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023745; batch adversarial loss: 0.527602\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018359; batch adversarial loss: 0.462894\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033946; batch adversarial loss: 0.447226\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028466; batch adversarial loss: 0.505137\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023847; batch adversarial loss: 0.384569\n",
      "epoch 139; iter: 0; batch classifier loss: 0.051053; batch adversarial loss: 0.350839\n",
      "epoch 140; iter: 0; batch classifier loss: 0.089407; batch adversarial loss: 0.417400\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018617; batch adversarial loss: 0.397649\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018970; batch adversarial loss: 0.469530\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013126; batch adversarial loss: 0.504376\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037090; batch adversarial loss: 0.490195\n",
      "epoch 145; iter: 0; batch classifier loss: 0.009511; batch adversarial loss: 0.524888\n",
      "epoch 146; iter: 0; batch classifier loss: 0.033561; batch adversarial loss: 0.403306\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042569; batch adversarial loss: 0.474356\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039781; batch adversarial loss: 0.481204\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016181; batch adversarial loss: 0.476812\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015117; batch adversarial loss: 0.491453\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030804; batch adversarial loss: 0.396236\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016189; batch adversarial loss: 0.451743\n",
      "epoch 153; iter: 0; batch classifier loss: 0.009582; batch adversarial loss: 0.479786\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038763; batch adversarial loss: 0.418811\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023145; batch adversarial loss: 0.387357\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026475; batch adversarial loss: 0.458764\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037780; batch adversarial loss: 0.490551\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016770; batch adversarial loss: 0.428845\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014304; batch adversarial loss: 0.417484\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009250; batch adversarial loss: 0.464591\n",
      "epoch 161; iter: 0; batch classifier loss: 0.065556; batch adversarial loss: 0.395901\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007635; batch adversarial loss: 0.478614\n",
      "epoch 163; iter: 0; batch classifier loss: 0.043246; batch adversarial loss: 0.433620\n",
      "epoch 164; iter: 0; batch classifier loss: 0.071633; batch adversarial loss: 0.489233\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022070; batch adversarial loss: 0.462490\n",
      "epoch 166; iter: 0; batch classifier loss: 0.006742; batch adversarial loss: 0.448387\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031351; batch adversarial loss: 0.495164\n",
      "epoch 168; iter: 0; batch classifier loss: 0.041346; batch adversarial loss: 0.387228\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027139; batch adversarial loss: 0.392103\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014069; batch adversarial loss: 0.446284\n",
      "epoch 171; iter: 0; batch classifier loss: 0.049629; batch adversarial loss: 0.414148\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015140; batch adversarial loss: 0.426631\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016288; batch adversarial loss: 0.445778\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028156; batch adversarial loss: 0.435942\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026114; batch adversarial loss: 0.472011\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014095; batch adversarial loss: 0.382175\n",
      "epoch 177; iter: 0; batch classifier loss: 0.047162; batch adversarial loss: 0.414049\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021267; batch adversarial loss: 0.473468\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015071; batch adversarial loss: 0.433297\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009759; batch adversarial loss: 0.390476\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021829; batch adversarial loss: 0.468229\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019169; batch adversarial loss: 0.375574\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017614; batch adversarial loss: 0.479036\n",
      "epoch 184; iter: 0; batch classifier loss: 0.005867; batch adversarial loss: 0.324643\n",
      "epoch 185; iter: 0; batch classifier loss: 0.063875; batch adversarial loss: 0.489184\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017284; batch adversarial loss: 0.458574\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006227; batch adversarial loss: 0.482297\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016936; batch adversarial loss: 0.487042\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007363; batch adversarial loss: 0.490878\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016708; batch adversarial loss: 0.429605\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028587; batch adversarial loss: 0.481724\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006799; batch adversarial loss: 0.497005\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014413; batch adversarial loss: 0.352635\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013601; batch adversarial loss: 0.436806\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010046; batch adversarial loss: 0.392721\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023162; batch adversarial loss: 0.379085\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005211; batch adversarial loss: 0.448372\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021191; batch adversarial loss: 0.411086\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026290; batch adversarial loss: 0.415414\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681863; batch adversarial loss: 0.776626\n",
      "epoch 1; iter: 0; batch classifier loss: 0.598687; batch adversarial loss: 0.767855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.718942; batch adversarial loss: 0.749624\n",
      "epoch 3; iter: 0; batch classifier loss: 0.646095; batch adversarial loss: 0.627418\n",
      "epoch 4; iter: 0; batch classifier loss: 0.461544; batch adversarial loss: 0.586368\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387687; batch adversarial loss: 0.553587\n",
      "epoch 6; iter: 0; batch classifier loss: 0.372686; batch adversarial loss: 0.584047\n",
      "epoch 7; iter: 0; batch classifier loss: 0.334633; batch adversarial loss: 0.530660\n",
      "epoch 8; iter: 0; batch classifier loss: 0.314082; batch adversarial loss: 0.532335\n",
      "epoch 9; iter: 0; batch classifier loss: 0.342062; batch adversarial loss: 0.532139\n",
      "epoch 10; iter: 0; batch classifier loss: 0.282582; batch adversarial loss: 0.536042\n",
      "epoch 11; iter: 0; batch classifier loss: 0.287502; batch adversarial loss: 0.485379\n",
      "epoch 12; iter: 0; batch classifier loss: 0.218342; batch adversarial loss: 0.514558\n",
      "epoch 13; iter: 0; batch classifier loss: 0.260799; batch adversarial loss: 0.520246\n",
      "epoch 14; iter: 0; batch classifier loss: 0.225199; batch adversarial loss: 0.551973\n",
      "epoch 15; iter: 0; batch classifier loss: 0.241915; batch adversarial loss: 0.478958\n",
      "epoch 16; iter: 0; batch classifier loss: 0.238411; batch adversarial loss: 0.487630\n",
      "epoch 17; iter: 0; batch classifier loss: 0.164331; batch adversarial loss: 0.465474\n",
      "epoch 18; iter: 0; batch classifier loss: 0.295535; batch adversarial loss: 0.560482\n",
      "epoch 19; iter: 0; batch classifier loss: 0.177555; batch adversarial loss: 0.414117\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204902; batch adversarial loss: 0.546423\n",
      "epoch 21; iter: 0; batch classifier loss: 0.170406; batch adversarial loss: 0.475887\n",
      "epoch 22; iter: 0; batch classifier loss: 0.171135; batch adversarial loss: 0.477630\n",
      "epoch 23; iter: 0; batch classifier loss: 0.163061; batch adversarial loss: 0.436634\n",
      "epoch 24; iter: 0; batch classifier loss: 0.210401; batch adversarial loss: 0.512257\n",
      "epoch 25; iter: 0; batch classifier loss: 0.133291; batch adversarial loss: 0.412854\n",
      "epoch 26; iter: 0; batch classifier loss: 0.169419; batch adversarial loss: 0.511545\n",
      "epoch 27; iter: 0; batch classifier loss: 0.126764; batch adversarial loss: 0.526304\n",
      "epoch 28; iter: 0; batch classifier loss: 0.169486; batch adversarial loss: 0.493337\n",
      "epoch 29; iter: 0; batch classifier loss: 0.119986; batch adversarial loss: 0.406655\n",
      "epoch 30; iter: 0; batch classifier loss: 0.125092; batch adversarial loss: 0.532614\n",
      "epoch 31; iter: 0; batch classifier loss: 0.133842; batch adversarial loss: 0.506881\n",
      "epoch 32; iter: 0; batch classifier loss: 0.091522; batch adversarial loss: 0.420350\n",
      "epoch 33; iter: 0; batch classifier loss: 0.077195; batch adversarial loss: 0.484095\n",
      "epoch 34; iter: 0; batch classifier loss: 0.146653; batch adversarial loss: 0.425955\n",
      "epoch 35; iter: 0; batch classifier loss: 0.110770; batch adversarial loss: 0.497725\n",
      "epoch 36; iter: 0; batch classifier loss: 0.118471; batch adversarial loss: 0.480224\n",
      "epoch 37; iter: 0; batch classifier loss: 0.109056; batch adversarial loss: 0.487385\n",
      "epoch 38; iter: 0; batch classifier loss: 0.112374; batch adversarial loss: 0.389366\n",
      "epoch 39; iter: 0; batch classifier loss: 0.113192; batch adversarial loss: 0.509986\n",
      "epoch 40; iter: 0; batch classifier loss: 0.076213; batch adversarial loss: 0.641141\n",
      "epoch 41; iter: 0; batch classifier loss: 0.120640; batch adversarial loss: 0.468271\n",
      "epoch 42; iter: 0; batch classifier loss: 0.097268; batch adversarial loss: 0.550921\n",
      "epoch 43; iter: 0; batch classifier loss: 0.090809; batch adversarial loss: 0.446308\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085427; batch adversarial loss: 0.429088\n",
      "epoch 45; iter: 0; batch classifier loss: 0.128397; batch adversarial loss: 0.429003\n",
      "epoch 46; iter: 0; batch classifier loss: 0.101876; batch adversarial loss: 0.419236\n",
      "epoch 47; iter: 0; batch classifier loss: 0.062575; batch adversarial loss: 0.406704\n",
      "epoch 48; iter: 0; batch classifier loss: 0.064803; batch adversarial loss: 0.385951\n",
      "epoch 49; iter: 0; batch classifier loss: 0.059876; batch adversarial loss: 0.466846\n",
      "epoch 50; iter: 0; batch classifier loss: 0.089661; batch adversarial loss: 0.424149\n",
      "epoch 51; iter: 0; batch classifier loss: 0.116852; batch adversarial loss: 0.388165\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099977; batch adversarial loss: 0.570949\n",
      "epoch 53; iter: 0; batch classifier loss: 0.050273; batch adversarial loss: 0.452977\n",
      "epoch 54; iter: 0; batch classifier loss: 0.072863; batch adversarial loss: 0.411674\n",
      "epoch 55; iter: 0; batch classifier loss: 0.112987; batch adversarial loss: 0.525032\n",
      "epoch 56; iter: 0; batch classifier loss: 0.056968; batch adversarial loss: 0.567249\n",
      "epoch 57; iter: 0; batch classifier loss: 0.080936; batch adversarial loss: 0.574485\n",
      "epoch 58; iter: 0; batch classifier loss: 0.046476; batch adversarial loss: 0.578906\n",
      "epoch 59; iter: 0; batch classifier loss: 0.064405; batch adversarial loss: 0.415836\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079053; batch adversarial loss: 0.455326\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078934; batch adversarial loss: 0.485893\n",
      "epoch 62; iter: 0; batch classifier loss: 0.036909; batch adversarial loss: 0.514175\n",
      "epoch 63; iter: 0; batch classifier loss: 0.054349; batch adversarial loss: 0.428078\n",
      "epoch 64; iter: 0; batch classifier loss: 0.060309; batch adversarial loss: 0.462900\n",
      "epoch 65; iter: 0; batch classifier loss: 0.053832; batch adversarial loss: 0.440961\n",
      "epoch 66; iter: 0; batch classifier loss: 0.087348; batch adversarial loss: 0.348236\n",
      "epoch 67; iter: 0; batch classifier loss: 0.105947; batch adversarial loss: 0.438587\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076303; batch adversarial loss: 0.426475\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071749; batch adversarial loss: 0.412553\n",
      "epoch 70; iter: 0; batch classifier loss: 0.098638; batch adversarial loss: 0.501364\n",
      "epoch 71; iter: 0; batch classifier loss: 0.106309; batch adversarial loss: 0.447183\n",
      "epoch 72; iter: 0; batch classifier loss: 0.090328; batch adversarial loss: 0.454767\n",
      "epoch 73; iter: 0; batch classifier loss: 0.053142; batch adversarial loss: 0.557584\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069376; batch adversarial loss: 0.461141\n",
      "epoch 75; iter: 0; batch classifier loss: 0.103082; batch adversarial loss: 0.471228\n",
      "epoch 76; iter: 0; batch classifier loss: 0.032554; batch adversarial loss: 0.480251\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063896; batch adversarial loss: 0.499995\n",
      "epoch 78; iter: 0; batch classifier loss: 0.039110; batch adversarial loss: 0.474005\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072342; batch adversarial loss: 0.529230\n",
      "epoch 80; iter: 0; batch classifier loss: 0.074351; batch adversarial loss: 0.484546\n",
      "epoch 81; iter: 0; batch classifier loss: 0.034364; batch adversarial loss: 0.397777\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052186; batch adversarial loss: 0.457588\n",
      "epoch 83; iter: 0; batch classifier loss: 0.029122; batch adversarial loss: 0.450158\n",
      "epoch 84; iter: 0; batch classifier loss: 0.032828; batch adversarial loss: 0.421839\n",
      "epoch 85; iter: 0; batch classifier loss: 0.056569; batch adversarial loss: 0.545320\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058221; batch adversarial loss: 0.427738\n",
      "epoch 87; iter: 0; batch classifier loss: 0.125710; batch adversarial loss: 0.477860\n",
      "epoch 88; iter: 0; batch classifier loss: 0.028023; batch adversarial loss: 0.444165\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042867; batch adversarial loss: 0.429832\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039503; batch adversarial loss: 0.444450\n",
      "epoch 91; iter: 0; batch classifier loss: 0.034950; batch adversarial loss: 0.551875\n",
      "epoch 92; iter: 0; batch classifier loss: 0.024940; batch adversarial loss: 0.438459\n",
      "epoch 93; iter: 0; batch classifier loss: 0.029211; batch adversarial loss: 0.395776\n",
      "epoch 94; iter: 0; batch classifier loss: 0.036341; batch adversarial loss: 0.509641\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056450; batch adversarial loss: 0.496935\n",
      "epoch 96; iter: 0; batch classifier loss: 0.039772; batch adversarial loss: 0.443707\n",
      "epoch 97; iter: 0; batch classifier loss: 0.016437; batch adversarial loss: 0.511313\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054570; batch adversarial loss: 0.509452\n",
      "epoch 99; iter: 0; batch classifier loss: 0.051682; batch adversarial loss: 0.540698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.025239; batch adversarial loss: 0.419240\n",
      "epoch 101; iter: 0; batch classifier loss: 0.038810; batch adversarial loss: 0.434732\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029757; batch adversarial loss: 0.316492\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038130; batch adversarial loss: 0.454348\n",
      "epoch 104; iter: 0; batch classifier loss: 0.054907; batch adversarial loss: 0.465017\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044315; batch adversarial loss: 0.525264\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058838; batch adversarial loss: 0.369414\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051709; batch adversarial loss: 0.492969\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038506; batch adversarial loss: 0.542727\n",
      "epoch 109; iter: 0; batch classifier loss: 0.028922; batch adversarial loss: 0.461114\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048100; batch adversarial loss: 0.513647\n",
      "epoch 111; iter: 0; batch classifier loss: 0.026011; batch adversarial loss: 0.556094\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024060; batch adversarial loss: 0.352208\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027660; batch adversarial loss: 0.468357\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061027; batch adversarial loss: 0.534026\n",
      "epoch 115; iter: 0; batch classifier loss: 0.018429; batch adversarial loss: 0.523705\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040550; batch adversarial loss: 0.449228\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047331; batch adversarial loss: 0.518137\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036654; batch adversarial loss: 0.406456\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026699; batch adversarial loss: 0.492963\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051225; batch adversarial loss: 0.481765\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027760; batch adversarial loss: 0.485564\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062076; batch adversarial loss: 0.472701\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030595; batch adversarial loss: 0.534520\n",
      "epoch 124; iter: 0; batch classifier loss: 0.068689; batch adversarial loss: 0.437953\n",
      "epoch 125; iter: 0; batch classifier loss: 0.014008; batch adversarial loss: 0.448125\n",
      "epoch 126; iter: 0; batch classifier loss: 0.018671; batch adversarial loss: 0.476858\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032852; batch adversarial loss: 0.444431\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025851; batch adversarial loss: 0.472046\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032008; batch adversarial loss: 0.473728\n",
      "epoch 130; iter: 0; batch classifier loss: 0.008910; batch adversarial loss: 0.434827\n",
      "epoch 131; iter: 0; batch classifier loss: 0.012753; batch adversarial loss: 0.421138\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057705; batch adversarial loss: 0.436831\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025374; batch adversarial loss: 0.562927\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034424; batch adversarial loss: 0.368412\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026864; batch adversarial loss: 0.381353\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049310; batch adversarial loss: 0.347615\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018090; batch adversarial loss: 0.575774\n",
      "epoch 138; iter: 0; batch classifier loss: 0.042502; batch adversarial loss: 0.480046\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024506; batch adversarial loss: 0.481816\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035385; batch adversarial loss: 0.392113\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027181; batch adversarial loss: 0.467714\n",
      "epoch 142; iter: 0; batch classifier loss: 0.010721; batch adversarial loss: 0.422193\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021649; batch adversarial loss: 0.546244\n",
      "epoch 144; iter: 0; batch classifier loss: 0.023201; batch adversarial loss: 0.436610\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046987; batch adversarial loss: 0.510702\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045808; batch adversarial loss: 0.438866\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038485; batch adversarial loss: 0.466368\n",
      "epoch 148; iter: 0; batch classifier loss: 0.050195; batch adversarial loss: 0.495813\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032528; batch adversarial loss: 0.389843\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037629; batch adversarial loss: 0.441030\n",
      "epoch 151; iter: 0; batch classifier loss: 0.009751; batch adversarial loss: 0.523222\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045830; batch adversarial loss: 0.447698\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023171; batch adversarial loss: 0.472333\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029398; batch adversarial loss: 0.417150\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024868; batch adversarial loss: 0.434813\n",
      "epoch 156; iter: 0; batch classifier loss: 0.009173; batch adversarial loss: 0.503519\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030124; batch adversarial loss: 0.493964\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014155; batch adversarial loss: 0.475777\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021429; batch adversarial loss: 0.503974\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028596; batch adversarial loss: 0.426080\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022568; batch adversarial loss: 0.537431\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021146; batch adversarial loss: 0.462514\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025160; batch adversarial loss: 0.459508\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020739; batch adversarial loss: 0.467371\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028550; batch adversarial loss: 0.562745\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038669; batch adversarial loss: 0.385423\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034303; batch adversarial loss: 0.539140\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016965; batch adversarial loss: 0.439040\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025045; batch adversarial loss: 0.572237\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022968; batch adversarial loss: 0.427360\n",
      "epoch 171; iter: 0; batch classifier loss: 0.046293; batch adversarial loss: 0.429543\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028212; batch adversarial loss: 0.596601\n",
      "epoch 173; iter: 0; batch classifier loss: 0.053702; batch adversarial loss: 0.550210\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041557; batch adversarial loss: 0.390864\n",
      "epoch 175; iter: 0; batch classifier loss: 0.043741; batch adversarial loss: 0.441455\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009643; batch adversarial loss: 0.520395\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025200; batch adversarial loss: 0.486915\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013182; batch adversarial loss: 0.492687\n",
      "epoch 179; iter: 0; batch classifier loss: 0.002811; batch adversarial loss: 0.560537\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034217; batch adversarial loss: 0.514321\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006113; batch adversarial loss: 0.526332\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034021; batch adversarial loss: 0.416348\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005636; batch adversarial loss: 0.492848\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033221; batch adversarial loss: 0.423155\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022580; batch adversarial loss: 0.479824\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012242; batch adversarial loss: 0.390031\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017434; batch adversarial loss: 0.473371\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015093; batch adversarial loss: 0.382326\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023626; batch adversarial loss: 0.498141\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024461; batch adversarial loss: 0.534730\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016969; batch adversarial loss: 0.521095\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010075; batch adversarial loss: 0.503237\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007911; batch adversarial loss: 0.429269\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008932; batch adversarial loss: 0.334506\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020201; batch adversarial loss: 0.455486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.038655; batch adversarial loss: 0.560556\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016277; batch adversarial loss: 0.483227\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007273; batch adversarial loss: 0.464393\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016817; batch adversarial loss: 0.432369\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680565; batch adversarial loss: 0.763123\n",
      "epoch 1; iter: 0; batch classifier loss: 0.477364; batch adversarial loss: 0.687338\n",
      "epoch 2; iter: 0; batch classifier loss: 0.405329; batch adversarial loss: 0.625634\n",
      "epoch 3; iter: 0; batch classifier loss: 0.308785; batch adversarial loss: 0.596473\n",
      "epoch 4; iter: 0; batch classifier loss: 0.357215; batch adversarial loss: 0.603849\n",
      "epoch 5; iter: 0; batch classifier loss: 0.307007; batch adversarial loss: 0.519777\n",
      "epoch 6; iter: 0; batch classifier loss: 0.252468; batch adversarial loss: 0.582555\n",
      "epoch 7; iter: 0; batch classifier loss: 0.271897; batch adversarial loss: 0.549814\n",
      "epoch 8; iter: 0; batch classifier loss: 0.305654; batch adversarial loss: 0.546883\n",
      "epoch 9; iter: 0; batch classifier loss: 0.314015; batch adversarial loss: 0.508067\n",
      "epoch 10; iter: 0; batch classifier loss: 0.258002; batch adversarial loss: 0.489570\n",
      "epoch 11; iter: 0; batch classifier loss: 0.275073; batch adversarial loss: 0.501298\n",
      "epoch 12; iter: 0; batch classifier loss: 0.277624; batch adversarial loss: 0.523174\n",
      "epoch 13; iter: 0; batch classifier loss: 0.230888; batch adversarial loss: 0.521359\n",
      "epoch 14; iter: 0; batch classifier loss: 0.238966; batch adversarial loss: 0.451539\n",
      "epoch 15; iter: 0; batch classifier loss: 0.280223; batch adversarial loss: 0.560867\n",
      "epoch 16; iter: 0; batch classifier loss: 0.225822; batch adversarial loss: 0.513806\n",
      "epoch 17; iter: 0; batch classifier loss: 0.267859; batch adversarial loss: 0.524083\n",
      "epoch 18; iter: 0; batch classifier loss: 0.213749; batch adversarial loss: 0.475768\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223043; batch adversarial loss: 0.441103\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220791; batch adversarial loss: 0.441995\n",
      "epoch 21; iter: 0; batch classifier loss: 0.240185; batch adversarial loss: 0.523248\n",
      "epoch 22; iter: 0; batch classifier loss: 0.197473; batch adversarial loss: 0.451839\n",
      "epoch 23; iter: 0; batch classifier loss: 0.217451; batch adversarial loss: 0.536617\n",
      "epoch 24; iter: 0; batch classifier loss: 0.230890; batch adversarial loss: 0.466224\n",
      "epoch 25; iter: 0; batch classifier loss: 0.189934; batch adversarial loss: 0.427077\n",
      "epoch 26; iter: 0; batch classifier loss: 0.230096; batch adversarial loss: 0.440498\n",
      "epoch 27; iter: 0; batch classifier loss: 0.191380; batch adversarial loss: 0.438914\n",
      "epoch 28; iter: 0; batch classifier loss: 0.189155; batch adversarial loss: 0.532089\n",
      "epoch 29; iter: 0; batch classifier loss: 0.155068; batch adversarial loss: 0.379159\n",
      "epoch 30; iter: 0; batch classifier loss: 0.175484; batch adversarial loss: 0.441536\n",
      "epoch 31; iter: 0; batch classifier loss: 0.192330; batch adversarial loss: 0.380514\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140107; batch adversarial loss: 0.447753\n",
      "epoch 33; iter: 0; batch classifier loss: 0.152495; batch adversarial loss: 0.469024\n",
      "epoch 34; iter: 0; batch classifier loss: 0.140163; batch adversarial loss: 0.522356\n",
      "epoch 35; iter: 0; batch classifier loss: 0.175289; batch adversarial loss: 0.486039\n",
      "epoch 36; iter: 0; batch classifier loss: 0.146008; batch adversarial loss: 0.398372\n",
      "epoch 37; iter: 0; batch classifier loss: 0.160904; batch adversarial loss: 0.467139\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115785; batch adversarial loss: 0.516692\n",
      "epoch 39; iter: 0; batch classifier loss: 0.139195; batch adversarial loss: 0.524571\n",
      "epoch 40; iter: 0; batch classifier loss: 0.161827; batch adversarial loss: 0.518548\n",
      "epoch 41; iter: 0; batch classifier loss: 0.072430; batch adversarial loss: 0.443557\n",
      "epoch 42; iter: 0; batch classifier loss: 0.109048; batch adversarial loss: 0.381683\n",
      "epoch 43; iter: 0; batch classifier loss: 0.085192; batch adversarial loss: 0.581125\n",
      "epoch 44; iter: 0; batch classifier loss: 0.146064; batch adversarial loss: 0.469669\n",
      "epoch 45; iter: 0; batch classifier loss: 0.135251; batch adversarial loss: 0.513207\n",
      "epoch 46; iter: 0; batch classifier loss: 0.104033; batch adversarial loss: 0.425730\n",
      "epoch 47; iter: 0; batch classifier loss: 0.104107; batch adversarial loss: 0.492374\n",
      "epoch 48; iter: 0; batch classifier loss: 0.166139; batch adversarial loss: 0.349346\n",
      "epoch 49; iter: 0; batch classifier loss: 0.121251; batch adversarial loss: 0.383058\n",
      "epoch 50; iter: 0; batch classifier loss: 0.084248; batch adversarial loss: 0.390289\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070355; batch adversarial loss: 0.387308\n",
      "epoch 52; iter: 0; batch classifier loss: 0.126869; batch adversarial loss: 0.443410\n",
      "epoch 53; iter: 0; batch classifier loss: 0.119911; batch adversarial loss: 0.443666\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110970; batch adversarial loss: 0.512243\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091527; batch adversarial loss: 0.472959\n",
      "epoch 56; iter: 0; batch classifier loss: 0.080030; batch adversarial loss: 0.443784\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073033; batch adversarial loss: 0.344714\n",
      "epoch 58; iter: 0; batch classifier loss: 0.088194; batch adversarial loss: 0.478239\n",
      "epoch 59; iter: 0; batch classifier loss: 0.089813; batch adversarial loss: 0.403414\n",
      "epoch 60; iter: 0; batch classifier loss: 0.121387; batch adversarial loss: 0.427185\n",
      "epoch 61; iter: 0; batch classifier loss: 0.086625; batch adversarial loss: 0.572927\n",
      "epoch 62; iter: 0; batch classifier loss: 0.098585; batch adversarial loss: 0.372240\n",
      "epoch 63; iter: 0; batch classifier loss: 0.101168; batch adversarial loss: 0.461244\n",
      "epoch 64; iter: 0; batch classifier loss: 0.069118; batch adversarial loss: 0.478010\n",
      "epoch 65; iter: 0; batch classifier loss: 0.064323; batch adversarial loss: 0.562586\n",
      "epoch 66; iter: 0; batch classifier loss: 0.053554; batch adversarial loss: 0.445027\n",
      "epoch 67; iter: 0; batch classifier loss: 0.076935; batch adversarial loss: 0.477089\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081227; batch adversarial loss: 0.479575\n",
      "epoch 69; iter: 0; batch classifier loss: 0.074608; batch adversarial loss: 0.501007\n",
      "epoch 70; iter: 0; batch classifier loss: 0.059328; batch adversarial loss: 0.525388\n",
      "epoch 71; iter: 0; batch classifier loss: 0.043482; batch adversarial loss: 0.460106\n",
      "epoch 72; iter: 0; batch classifier loss: 0.067514; batch adversarial loss: 0.477224\n",
      "epoch 73; iter: 0; batch classifier loss: 0.100321; batch adversarial loss: 0.478752\n",
      "epoch 74; iter: 0; batch classifier loss: 0.127208; batch adversarial loss: 0.315084\n",
      "epoch 75; iter: 0; batch classifier loss: 0.057131; batch adversarial loss: 0.454157\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075119; batch adversarial loss: 0.504638\n",
      "epoch 77; iter: 0; batch classifier loss: 0.044177; batch adversarial loss: 0.380306\n",
      "epoch 78; iter: 0; batch classifier loss: 0.056025; batch adversarial loss: 0.506171\n",
      "epoch 79; iter: 0; batch classifier loss: 0.041749; batch adversarial loss: 0.393417\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060133; batch adversarial loss: 0.530701\n",
      "epoch 81; iter: 0; batch classifier loss: 0.060922; batch adversarial loss: 0.431408\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046483; batch adversarial loss: 0.568018\n",
      "epoch 83; iter: 0; batch classifier loss: 0.041389; batch adversarial loss: 0.424258\n",
      "epoch 84; iter: 0; batch classifier loss: 0.100024; batch adversarial loss: 0.490941\n",
      "epoch 85; iter: 0; batch classifier loss: 0.043149; batch adversarial loss: 0.549668\n",
      "epoch 86; iter: 0; batch classifier loss: 0.060162; batch adversarial loss: 0.370046\n",
      "epoch 87; iter: 0; batch classifier loss: 0.038857; batch adversarial loss: 0.402674\n",
      "epoch 88; iter: 0; batch classifier loss: 0.047365; batch adversarial loss: 0.466689\n",
      "epoch 89; iter: 0; batch classifier loss: 0.055244; batch adversarial loss: 0.386201\n",
      "epoch 90; iter: 0; batch classifier loss: 0.043060; batch adversarial loss: 0.457939\n",
      "epoch 91; iter: 0; batch classifier loss: 0.035985; batch adversarial loss: 0.586136\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074187; batch adversarial loss: 0.430385\n",
      "epoch 93; iter: 0; batch classifier loss: 0.049293; batch adversarial loss: 0.314595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.039314; batch adversarial loss: 0.465213\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053187; batch adversarial loss: 0.462589\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048488; batch adversarial loss: 0.367538\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059312; batch adversarial loss: 0.454645\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042141; batch adversarial loss: 0.454154\n",
      "epoch 99; iter: 0; batch classifier loss: 0.028710; batch adversarial loss: 0.509954\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045138; batch adversarial loss: 0.470331\n",
      "epoch 101; iter: 0; batch classifier loss: 0.064932; batch adversarial loss: 0.525768\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037728; batch adversarial loss: 0.503311\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041593; batch adversarial loss: 0.370646\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039286; batch adversarial loss: 0.393673\n",
      "epoch 105; iter: 0; batch classifier loss: 0.028122; batch adversarial loss: 0.497476\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030219; batch adversarial loss: 0.442713\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053788; batch adversarial loss: 0.387261\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040801; batch adversarial loss: 0.451354\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032406; batch adversarial loss: 0.520296\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028367; batch adversarial loss: 0.454779\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051211; batch adversarial loss: 0.391366\n",
      "epoch 112; iter: 0; batch classifier loss: 0.062442; batch adversarial loss: 0.397843\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042618; batch adversarial loss: 0.469553\n",
      "epoch 114; iter: 0; batch classifier loss: 0.065077; batch adversarial loss: 0.456507\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049500; batch adversarial loss: 0.439043\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040636; batch adversarial loss: 0.316065\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040304; batch adversarial loss: 0.441277\n",
      "epoch 118; iter: 0; batch classifier loss: 0.013055; batch adversarial loss: 0.483723\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050107; batch adversarial loss: 0.376743\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027222; batch adversarial loss: 0.481658\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024856; batch adversarial loss: 0.464600\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067452; batch adversarial loss: 0.436837\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024159; batch adversarial loss: 0.484127\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023487; batch adversarial loss: 0.508726\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032276; batch adversarial loss: 0.424436\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029986; batch adversarial loss: 0.400351\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028281; batch adversarial loss: 0.467943\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029801; batch adversarial loss: 0.426840\n",
      "epoch 129; iter: 0; batch classifier loss: 0.013775; batch adversarial loss: 0.353581\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034045; batch adversarial loss: 0.441320\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029595; batch adversarial loss: 0.435458\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027381; batch adversarial loss: 0.334951\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025579; batch adversarial loss: 0.419151\n",
      "epoch 134; iter: 0; batch classifier loss: 0.071551; batch adversarial loss: 0.471838\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024529; batch adversarial loss: 0.453585\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038279; batch adversarial loss: 0.432322\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038896; batch adversarial loss: 0.398060\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025116; batch adversarial loss: 0.470009\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021529; batch adversarial loss: 0.440255\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044062; batch adversarial loss: 0.422089\n",
      "epoch 141; iter: 0; batch classifier loss: 0.004162; batch adversarial loss: 0.469200\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049756; batch adversarial loss: 0.440063\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033765; batch adversarial loss: 0.390981\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020357; batch adversarial loss: 0.458673\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023606; batch adversarial loss: 0.490880\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015281; batch adversarial loss: 0.469698\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030306; batch adversarial loss: 0.387953\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013663; batch adversarial loss: 0.433254\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020028; batch adversarial loss: 0.465357\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022424; batch adversarial loss: 0.419583\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031223; batch adversarial loss: 0.461568\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014300; batch adversarial loss: 0.428350\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034739; batch adversarial loss: 0.372705\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015548; batch adversarial loss: 0.475773\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035858; batch adversarial loss: 0.512634\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017695; batch adversarial loss: 0.356237\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025122; batch adversarial loss: 0.387720\n",
      "epoch 158; iter: 0; batch classifier loss: 0.052623; batch adversarial loss: 0.498728\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025759; batch adversarial loss: 0.458119\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041661; batch adversarial loss: 0.431373\n",
      "epoch 161; iter: 0; batch classifier loss: 0.051759; batch adversarial loss: 0.455470\n",
      "epoch 162; iter: 0; batch classifier loss: 0.048834; batch adversarial loss: 0.371682\n",
      "epoch 163; iter: 0; batch classifier loss: 0.045901; batch adversarial loss: 0.477754\n",
      "epoch 164; iter: 0; batch classifier loss: 0.070718; batch adversarial loss: 0.466588\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015928; batch adversarial loss: 0.476919\n",
      "epoch 166; iter: 0; batch classifier loss: 0.008317; batch adversarial loss: 0.442568\n",
      "epoch 167; iter: 0; batch classifier loss: 0.053715; batch adversarial loss: 0.469366\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005317; batch adversarial loss: 0.431090\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006371; batch adversarial loss: 0.440544\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032791; batch adversarial loss: 0.422243\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010124; batch adversarial loss: 0.451032\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020674; batch adversarial loss: 0.545085\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040876; batch adversarial loss: 0.510252\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013868; batch adversarial loss: 0.456858\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026034; batch adversarial loss: 0.506910\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035903; batch adversarial loss: 0.434226\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014444; batch adversarial loss: 0.500165\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014323; batch adversarial loss: 0.410521\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020583; batch adversarial loss: 0.364464\n",
      "epoch 180; iter: 0; batch classifier loss: 0.067119; batch adversarial loss: 0.456124\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013744; batch adversarial loss: 0.401354\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010492; batch adversarial loss: 0.400195\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023785; batch adversarial loss: 0.559236\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012960; batch adversarial loss: 0.422770\n",
      "epoch 185; iter: 0; batch classifier loss: 0.044428; batch adversarial loss: 0.400463\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026035; batch adversarial loss: 0.412771\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021810; batch adversarial loss: 0.479535\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008317; batch adversarial loss: 0.526631\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007159; batch adversarial loss: 0.494773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.011177; batch adversarial loss: 0.377804\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032924; batch adversarial loss: 0.447742\n",
      "epoch 192; iter: 0; batch classifier loss: 0.039518; batch adversarial loss: 0.435983\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026108; batch adversarial loss: 0.477808\n",
      "epoch 194; iter: 0; batch classifier loss: 0.003897; batch adversarial loss: 0.453105\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023237; batch adversarial loss: 0.283311\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014091; batch adversarial loss: 0.583176\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012391; batch adversarial loss: 0.533382\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026481; batch adversarial loss: 0.531088\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015168; batch adversarial loss: 0.386064\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668518; batch adversarial loss: 0.696053\n",
      "epoch 1; iter: 0; batch classifier loss: 0.504364; batch adversarial loss: 0.642713\n",
      "epoch 2; iter: 0; batch classifier loss: 0.380570; batch adversarial loss: 0.595102\n",
      "epoch 3; iter: 0; batch classifier loss: 0.339788; batch adversarial loss: 0.565051\n",
      "epoch 4; iter: 0; batch classifier loss: 0.303173; batch adversarial loss: 0.600355\n",
      "epoch 5; iter: 0; batch classifier loss: 0.378397; batch adversarial loss: 0.495262\n",
      "epoch 6; iter: 0; batch classifier loss: 0.255147; batch adversarial loss: 0.567700\n",
      "epoch 7; iter: 0; batch classifier loss: 0.303004; batch adversarial loss: 0.568717\n",
      "epoch 8; iter: 0; batch classifier loss: 0.317020; batch adversarial loss: 0.486344\n",
      "epoch 9; iter: 0; batch classifier loss: 0.330252; batch adversarial loss: 0.475734\n",
      "epoch 10; iter: 0; batch classifier loss: 0.223151; batch adversarial loss: 0.517522\n",
      "epoch 11; iter: 0; batch classifier loss: 0.283686; batch adversarial loss: 0.466073\n",
      "epoch 12; iter: 0; batch classifier loss: 0.279248; batch adversarial loss: 0.506983\n",
      "epoch 13; iter: 0; batch classifier loss: 0.260448; batch adversarial loss: 0.443855\n",
      "epoch 14; iter: 0; batch classifier loss: 0.207325; batch adversarial loss: 0.471014\n",
      "epoch 15; iter: 0; batch classifier loss: 0.230608; batch adversarial loss: 0.512237\n",
      "epoch 16; iter: 0; batch classifier loss: 0.205784; batch adversarial loss: 0.514947\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241678; batch adversarial loss: 0.470398\n",
      "epoch 18; iter: 0; batch classifier loss: 0.194276; batch adversarial loss: 0.524677\n",
      "epoch 19; iter: 0; batch classifier loss: 0.176687; batch adversarial loss: 0.535127\n",
      "epoch 20; iter: 0; batch classifier loss: 0.149890; batch adversarial loss: 0.510725\n",
      "epoch 21; iter: 0; batch classifier loss: 0.154210; batch adversarial loss: 0.548137\n",
      "epoch 22; iter: 0; batch classifier loss: 0.204088; batch adversarial loss: 0.478909\n",
      "epoch 23; iter: 0; batch classifier loss: 0.123142; batch adversarial loss: 0.481893\n",
      "epoch 24; iter: 0; batch classifier loss: 0.191626; batch adversarial loss: 0.534117\n",
      "epoch 25; iter: 0; batch classifier loss: 0.154870; batch adversarial loss: 0.472695\n",
      "epoch 26; iter: 0; batch classifier loss: 0.124955; batch adversarial loss: 0.467061\n",
      "epoch 27; iter: 0; batch classifier loss: 0.194607; batch adversarial loss: 0.494636\n",
      "epoch 28; iter: 0; batch classifier loss: 0.113150; batch adversarial loss: 0.372183\n",
      "epoch 29; iter: 0; batch classifier loss: 0.161250; batch adversarial loss: 0.485475\n",
      "epoch 30; iter: 0; batch classifier loss: 0.184223; batch adversarial loss: 0.399903\n",
      "epoch 31; iter: 0; batch classifier loss: 0.116997; batch adversarial loss: 0.465836\n",
      "epoch 32; iter: 0; batch classifier loss: 0.119959; batch adversarial loss: 0.507851\n",
      "epoch 33; iter: 0; batch classifier loss: 0.177047; batch adversarial loss: 0.419684\n",
      "epoch 34; iter: 0; batch classifier loss: 0.112975; batch adversarial loss: 0.468596\n",
      "epoch 35; iter: 0; batch classifier loss: 0.108674; batch adversarial loss: 0.473408\n",
      "epoch 36; iter: 0; batch classifier loss: 0.137249; batch adversarial loss: 0.456577\n",
      "epoch 37; iter: 0; batch classifier loss: 0.089277; batch adversarial loss: 0.396642\n",
      "epoch 38; iter: 0; batch classifier loss: 0.156837; batch adversarial loss: 0.467935\n",
      "epoch 39; iter: 0; batch classifier loss: 0.082965; batch adversarial loss: 0.422039\n",
      "epoch 40; iter: 0; batch classifier loss: 0.104711; batch adversarial loss: 0.462274\n",
      "epoch 41; iter: 0; batch classifier loss: 0.116119; batch adversarial loss: 0.591476\n",
      "epoch 42; iter: 0; batch classifier loss: 0.113974; batch adversarial loss: 0.402772\n",
      "epoch 43; iter: 0; batch classifier loss: 0.101639; batch adversarial loss: 0.401701\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105888; batch adversarial loss: 0.450995\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086428; batch adversarial loss: 0.451812\n",
      "epoch 46; iter: 0; batch classifier loss: 0.144376; batch adversarial loss: 0.432141\n",
      "epoch 47; iter: 0; batch classifier loss: 0.094917; batch adversarial loss: 0.439496\n",
      "epoch 48; iter: 0; batch classifier loss: 0.138422; batch adversarial loss: 0.568385\n",
      "epoch 49; iter: 0; batch classifier loss: 0.115390; batch adversarial loss: 0.414107\n",
      "epoch 50; iter: 0; batch classifier loss: 0.100388; batch adversarial loss: 0.530569\n",
      "epoch 51; iter: 0; batch classifier loss: 0.112268; batch adversarial loss: 0.377592\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071772; batch adversarial loss: 0.548501\n",
      "epoch 53; iter: 0; batch classifier loss: 0.110070; batch adversarial loss: 0.419257\n",
      "epoch 54; iter: 0; batch classifier loss: 0.070584; batch adversarial loss: 0.464974\n",
      "epoch 55; iter: 0; batch classifier loss: 0.120615; batch adversarial loss: 0.516723\n",
      "epoch 56; iter: 0; batch classifier loss: 0.060692; batch adversarial loss: 0.467772\n",
      "epoch 57; iter: 0; batch classifier loss: 0.169668; batch adversarial loss: 0.508588\n",
      "epoch 58; iter: 0; batch classifier loss: 0.067106; batch adversarial loss: 0.456836\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088165; batch adversarial loss: 0.414945\n",
      "epoch 60; iter: 0; batch classifier loss: 0.093568; batch adversarial loss: 0.376663\n",
      "epoch 61; iter: 0; batch classifier loss: 0.062550; batch adversarial loss: 0.467362\n",
      "epoch 62; iter: 0; batch classifier loss: 0.091418; batch adversarial loss: 0.502295\n",
      "epoch 63; iter: 0; batch classifier loss: 0.048701; batch adversarial loss: 0.518356\n",
      "epoch 64; iter: 0; batch classifier loss: 0.092684; batch adversarial loss: 0.401617\n",
      "epoch 65; iter: 0; batch classifier loss: 0.084948; batch adversarial loss: 0.465345\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062544; batch adversarial loss: 0.417861\n",
      "epoch 67; iter: 0; batch classifier loss: 0.081921; batch adversarial loss: 0.413055\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096218; batch adversarial loss: 0.436787\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081044; batch adversarial loss: 0.413378\n",
      "epoch 70; iter: 0; batch classifier loss: 0.064332; batch adversarial loss: 0.450563\n",
      "epoch 71; iter: 0; batch classifier loss: 0.087235; batch adversarial loss: 0.476341\n",
      "epoch 72; iter: 0; batch classifier loss: 0.059567; batch adversarial loss: 0.411957\n",
      "epoch 73; iter: 0; batch classifier loss: 0.123529; batch adversarial loss: 0.412372\n",
      "epoch 74; iter: 0; batch classifier loss: 0.113816; batch adversarial loss: 0.552891\n",
      "epoch 75; iter: 0; batch classifier loss: 0.053344; batch adversarial loss: 0.449642\n",
      "epoch 76; iter: 0; batch classifier loss: 0.049877; batch adversarial loss: 0.459814\n",
      "epoch 77; iter: 0; batch classifier loss: 0.068984; batch adversarial loss: 0.485408\n",
      "epoch 78; iter: 0; batch classifier loss: 0.053536; batch adversarial loss: 0.476867\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044499; batch adversarial loss: 0.502753\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070287; batch adversarial loss: 0.442871\n",
      "epoch 81; iter: 0; batch classifier loss: 0.046989; batch adversarial loss: 0.441665\n",
      "epoch 82; iter: 0; batch classifier loss: 0.076906; batch adversarial loss: 0.562860\n",
      "epoch 83; iter: 0; batch classifier loss: 0.097963; batch adversarial loss: 0.408894\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067009; batch adversarial loss: 0.488980\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046525; batch adversarial loss: 0.409761\n",
      "epoch 86; iter: 0; batch classifier loss: 0.039656; batch adversarial loss: 0.472102\n",
      "epoch 87; iter: 0; batch classifier loss: 0.074606; batch adversarial loss: 0.425459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.081815; batch adversarial loss: 0.398029\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066337; batch adversarial loss: 0.461375\n",
      "epoch 90; iter: 0; batch classifier loss: 0.049693; batch adversarial loss: 0.401447\n",
      "epoch 91; iter: 0; batch classifier loss: 0.039990; batch adversarial loss: 0.384565\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050601; batch adversarial loss: 0.401483\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077718; batch adversarial loss: 0.426747\n",
      "epoch 94; iter: 0; batch classifier loss: 0.085399; batch adversarial loss: 0.529144\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047768; batch adversarial loss: 0.491669\n",
      "epoch 96; iter: 0; batch classifier loss: 0.077047; batch adversarial loss: 0.396178\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043524; batch adversarial loss: 0.398676\n",
      "epoch 98; iter: 0; batch classifier loss: 0.069844; batch adversarial loss: 0.484454\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069167; batch adversarial loss: 0.434893\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075116; batch adversarial loss: 0.519640\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051411; batch adversarial loss: 0.482778\n",
      "epoch 102; iter: 0; batch classifier loss: 0.064414; batch adversarial loss: 0.386527\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048261; batch adversarial loss: 0.472440\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046711; batch adversarial loss: 0.410411\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035128; batch adversarial loss: 0.398792\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058811; batch adversarial loss: 0.522584\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024897; batch adversarial loss: 0.406061\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041895; batch adversarial loss: 0.453728\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042745; batch adversarial loss: 0.407147\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043975; batch adversarial loss: 0.396966\n",
      "epoch 111; iter: 0; batch classifier loss: 0.023258; batch adversarial loss: 0.491369\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026623; batch adversarial loss: 0.481791\n",
      "epoch 113; iter: 0; batch classifier loss: 0.017887; batch adversarial loss: 0.485528\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026071; batch adversarial loss: 0.525977\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036422; batch adversarial loss: 0.416363\n",
      "epoch 116; iter: 0; batch classifier loss: 0.023578; batch adversarial loss: 0.464905\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023770; batch adversarial loss: 0.443131\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024504; batch adversarial loss: 0.566495\n",
      "epoch 119; iter: 0; batch classifier loss: 0.020451; batch adversarial loss: 0.444927\n",
      "epoch 120; iter: 0; batch classifier loss: 0.029769; batch adversarial loss: 0.409515\n",
      "epoch 121; iter: 0; batch classifier loss: 0.023251; batch adversarial loss: 0.525940\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042590; batch adversarial loss: 0.411624\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031152; batch adversarial loss: 0.442488\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038495; batch adversarial loss: 0.390891\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061201; batch adversarial loss: 0.434177\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027194; batch adversarial loss: 0.450483\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023916; batch adversarial loss: 0.418064\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040911; batch adversarial loss: 0.478137\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047949; batch adversarial loss: 0.455742\n",
      "epoch 130; iter: 0; batch classifier loss: 0.060676; batch adversarial loss: 0.487247\n",
      "epoch 131; iter: 0; batch classifier loss: 0.013964; batch adversarial loss: 0.502602\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022050; batch adversarial loss: 0.435735\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026253; batch adversarial loss: 0.494153\n",
      "epoch 134; iter: 0; batch classifier loss: 0.044471; batch adversarial loss: 0.443847\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011690; batch adversarial loss: 0.495568\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019412; batch adversarial loss: 0.415705\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049478; batch adversarial loss: 0.448776\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011597; batch adversarial loss: 0.451299\n",
      "epoch 139; iter: 0; batch classifier loss: 0.061821; batch adversarial loss: 0.456971\n",
      "epoch 140; iter: 0; batch classifier loss: 0.055754; batch adversarial loss: 0.450215\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043984; batch adversarial loss: 0.511440\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020497; batch adversarial loss: 0.529230\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050554; batch adversarial loss: 0.397520\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016142; batch adversarial loss: 0.499084\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014711; batch adversarial loss: 0.525097\n",
      "epoch 146; iter: 0; batch classifier loss: 0.009360; batch adversarial loss: 0.431689\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010210; batch adversarial loss: 0.485464\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049550; batch adversarial loss: 0.483774\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012372; batch adversarial loss: 0.513282\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022957; batch adversarial loss: 0.446830\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020387; batch adversarial loss: 0.519022\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035696; batch adversarial loss: 0.493259\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030069; batch adversarial loss: 0.443288\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019569; batch adversarial loss: 0.412709\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016743; batch adversarial loss: 0.440651\n",
      "epoch 156; iter: 0; batch classifier loss: 0.067016; batch adversarial loss: 0.471059\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009131; batch adversarial loss: 0.432969\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020244; batch adversarial loss: 0.440942\n",
      "epoch 159; iter: 0; batch classifier loss: 0.052772; batch adversarial loss: 0.388725\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044789; batch adversarial loss: 0.511236\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031961; batch adversarial loss: 0.521782\n",
      "epoch 162; iter: 0; batch classifier loss: 0.056434; batch adversarial loss: 0.493398\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016779; batch adversarial loss: 0.426481\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010615; batch adversarial loss: 0.415185\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020846; batch adversarial loss: 0.411006\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010054; batch adversarial loss: 0.434597\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017318; batch adversarial loss: 0.469198\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020339; batch adversarial loss: 0.341945\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012859; batch adversarial loss: 0.425826\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038379; batch adversarial loss: 0.411019\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017398; batch adversarial loss: 0.557416\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013571; batch adversarial loss: 0.443995\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021867; batch adversarial loss: 0.444936\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040081; batch adversarial loss: 0.428315\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032282; batch adversarial loss: 0.484068\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028982; batch adversarial loss: 0.406329\n",
      "epoch 177; iter: 0; batch classifier loss: 0.043803; batch adversarial loss: 0.438001\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008521; batch adversarial loss: 0.538353\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037332; batch adversarial loss: 0.470629\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018647; batch adversarial loss: 0.392279\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023879; batch adversarial loss: 0.425477\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031075; batch adversarial loss: 0.461449\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005420; batch adversarial loss: 0.405169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.020551; batch adversarial loss: 0.535027\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006869; batch adversarial loss: 0.408500\n",
      "epoch 186; iter: 0; batch classifier loss: 0.039913; batch adversarial loss: 0.550166\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027747; batch adversarial loss: 0.472738\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016979; batch adversarial loss: 0.378296\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017322; batch adversarial loss: 0.473707\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030881; batch adversarial loss: 0.364976\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034285; batch adversarial loss: 0.505932\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022246; batch adversarial loss: 0.449476\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015423; batch adversarial loss: 0.459489\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024774; batch adversarial loss: 0.435700\n",
      "epoch 195; iter: 0; batch classifier loss: 0.032577; batch adversarial loss: 0.466689\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017799; batch adversarial loss: 0.426368\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028211; batch adversarial loss: 0.370950\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018418; batch adversarial loss: 0.457536\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025312; batch adversarial loss: 0.376449\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688890; batch adversarial loss: 0.734670\n",
      "epoch 1; iter: 0; batch classifier loss: 0.527623; batch adversarial loss: 0.695837\n",
      "epoch 2; iter: 0; batch classifier loss: 0.400887; batch adversarial loss: 0.625235\n",
      "epoch 3; iter: 0; batch classifier loss: 0.368819; batch adversarial loss: 0.609527\n",
      "epoch 4; iter: 0; batch classifier loss: 0.247288; batch adversarial loss: 0.589779\n",
      "epoch 5; iter: 0; batch classifier loss: 0.413605; batch adversarial loss: 0.561910\n",
      "epoch 6; iter: 0; batch classifier loss: 0.380479; batch adversarial loss: 0.567496\n",
      "epoch 7; iter: 0; batch classifier loss: 0.329552; batch adversarial loss: 0.525799\n",
      "epoch 8; iter: 0; batch classifier loss: 0.297737; batch adversarial loss: 0.550534\n",
      "epoch 9; iter: 0; batch classifier loss: 0.330160; batch adversarial loss: 0.548075\n",
      "epoch 10; iter: 0; batch classifier loss: 0.335071; batch adversarial loss: 0.523830\n",
      "epoch 11; iter: 0; batch classifier loss: 0.249553; batch adversarial loss: 0.541377\n",
      "epoch 12; iter: 0; batch classifier loss: 0.382517; batch adversarial loss: 0.470222\n",
      "epoch 13; iter: 0; batch classifier loss: 0.236835; batch adversarial loss: 0.485670\n",
      "epoch 14; iter: 0; batch classifier loss: 0.279370; batch adversarial loss: 0.518729\n",
      "epoch 15; iter: 0; batch classifier loss: 0.289783; batch adversarial loss: 0.529892\n",
      "epoch 16; iter: 0; batch classifier loss: 0.308542; batch adversarial loss: 0.498317\n",
      "epoch 17; iter: 0; batch classifier loss: 0.284513; batch adversarial loss: 0.529899\n",
      "epoch 18; iter: 0; batch classifier loss: 0.284793; batch adversarial loss: 0.467440\n",
      "epoch 19; iter: 0; batch classifier loss: 0.267464; batch adversarial loss: 0.537030\n",
      "epoch 20; iter: 0; batch classifier loss: 0.258968; batch adversarial loss: 0.537232\n",
      "epoch 21; iter: 0; batch classifier loss: 0.262358; batch adversarial loss: 0.553520\n",
      "epoch 22; iter: 0; batch classifier loss: 0.193071; batch adversarial loss: 0.476224\n",
      "epoch 23; iter: 0; batch classifier loss: 0.213512; batch adversarial loss: 0.422465\n",
      "epoch 24; iter: 0; batch classifier loss: 0.216830; batch adversarial loss: 0.461255\n",
      "epoch 25; iter: 0; batch classifier loss: 0.258491; batch adversarial loss: 0.465234\n",
      "epoch 26; iter: 0; batch classifier loss: 0.221458; batch adversarial loss: 0.490847\n",
      "epoch 27; iter: 0; batch classifier loss: 0.221962; batch adversarial loss: 0.519069\n",
      "epoch 28; iter: 0; batch classifier loss: 0.171036; batch adversarial loss: 0.486980\n",
      "epoch 29; iter: 0; batch classifier loss: 0.200295; batch adversarial loss: 0.512854\n",
      "epoch 30; iter: 0; batch classifier loss: 0.185586; batch adversarial loss: 0.436972\n",
      "epoch 31; iter: 0; batch classifier loss: 0.196664; batch adversarial loss: 0.433704\n",
      "epoch 32; iter: 0; batch classifier loss: 0.129810; batch adversarial loss: 0.394547\n",
      "epoch 33; iter: 0; batch classifier loss: 0.209971; batch adversarial loss: 0.481577\n",
      "epoch 34; iter: 0; batch classifier loss: 0.166965; batch adversarial loss: 0.408489\n",
      "epoch 35; iter: 0; batch classifier loss: 0.179433; batch adversarial loss: 0.444644\n",
      "epoch 36; iter: 0; batch classifier loss: 0.146924; batch adversarial loss: 0.461983\n",
      "epoch 37; iter: 0; batch classifier loss: 0.163247; batch adversarial loss: 0.430581\n",
      "epoch 38; iter: 0; batch classifier loss: 0.116935; batch adversarial loss: 0.387325\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126700; batch adversarial loss: 0.480741\n",
      "epoch 40; iter: 0; batch classifier loss: 0.134899; batch adversarial loss: 0.557052\n",
      "epoch 41; iter: 0; batch classifier loss: 0.158946; batch adversarial loss: 0.454745\n",
      "epoch 42; iter: 0; batch classifier loss: 0.087412; batch adversarial loss: 0.418305\n",
      "epoch 43; iter: 0; batch classifier loss: 0.106255; batch adversarial loss: 0.394611\n",
      "epoch 44; iter: 0; batch classifier loss: 0.106645; batch adversarial loss: 0.498886\n",
      "epoch 45; iter: 0; batch classifier loss: 0.151928; batch adversarial loss: 0.440202\n",
      "epoch 46; iter: 0; batch classifier loss: 0.114369; batch adversarial loss: 0.405671\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114895; batch adversarial loss: 0.592856\n",
      "epoch 48; iter: 0; batch classifier loss: 0.128961; batch adversarial loss: 0.455950\n",
      "epoch 49; iter: 0; batch classifier loss: 0.093289; batch adversarial loss: 0.565569\n",
      "epoch 50; iter: 0; batch classifier loss: 0.120242; batch adversarial loss: 0.407223\n",
      "epoch 51; iter: 0; batch classifier loss: 0.144876; batch adversarial loss: 0.403587\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103606; batch adversarial loss: 0.485178\n",
      "epoch 53; iter: 0; batch classifier loss: 0.091546; batch adversarial loss: 0.454106\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095697; batch adversarial loss: 0.465820\n",
      "epoch 55; iter: 0; batch classifier loss: 0.082458; batch adversarial loss: 0.391116\n",
      "epoch 56; iter: 0; batch classifier loss: 0.076678; batch adversarial loss: 0.406891\n",
      "epoch 57; iter: 0; batch classifier loss: 0.070348; batch adversarial loss: 0.488093\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077411; batch adversarial loss: 0.536408\n",
      "epoch 59; iter: 0; batch classifier loss: 0.080165; batch adversarial loss: 0.520199\n",
      "epoch 60; iter: 0; batch classifier loss: 0.063246; batch adversarial loss: 0.513933\n",
      "epoch 61; iter: 0; batch classifier loss: 0.062840; batch adversarial loss: 0.446059\n",
      "epoch 62; iter: 0; batch classifier loss: 0.107771; batch adversarial loss: 0.406249\n",
      "epoch 63; iter: 0; batch classifier loss: 0.050891; batch adversarial loss: 0.489553\n",
      "epoch 64; iter: 0; batch classifier loss: 0.096213; batch adversarial loss: 0.424023\n",
      "epoch 65; iter: 0; batch classifier loss: 0.089118; batch adversarial loss: 0.456909\n",
      "epoch 66; iter: 0; batch classifier loss: 0.077249; batch adversarial loss: 0.477724\n",
      "epoch 67; iter: 0; batch classifier loss: 0.088286; batch adversarial loss: 0.478407\n",
      "epoch 68; iter: 0; batch classifier loss: 0.064420; batch adversarial loss: 0.460124\n",
      "epoch 69; iter: 0; batch classifier loss: 0.045577; batch adversarial loss: 0.435463\n",
      "epoch 70; iter: 0; batch classifier loss: 0.045619; batch adversarial loss: 0.528734\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092497; batch adversarial loss: 0.433446\n",
      "epoch 72; iter: 0; batch classifier loss: 0.079975; batch adversarial loss: 0.461813\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047342; batch adversarial loss: 0.452425\n",
      "epoch 74; iter: 0; batch classifier loss: 0.073367; batch adversarial loss: 0.467252\n",
      "epoch 75; iter: 0; batch classifier loss: 0.081145; batch adversarial loss: 0.515403\n",
      "epoch 76; iter: 0; batch classifier loss: 0.062713; batch adversarial loss: 0.496873\n",
      "epoch 77; iter: 0; batch classifier loss: 0.058505; batch adversarial loss: 0.506519\n",
      "epoch 78; iter: 0; batch classifier loss: 0.049521; batch adversarial loss: 0.485686\n",
      "epoch 79; iter: 0; batch classifier loss: 0.034676; batch adversarial loss: 0.479120\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056186; batch adversarial loss: 0.404855\n",
      "epoch 81; iter: 0; batch classifier loss: 0.077472; batch adversarial loss: 0.474476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.040820; batch adversarial loss: 0.419255\n",
      "epoch 83; iter: 0; batch classifier loss: 0.048421; batch adversarial loss: 0.452019\n",
      "epoch 84; iter: 0; batch classifier loss: 0.040925; batch adversarial loss: 0.478358\n",
      "epoch 85; iter: 0; batch classifier loss: 0.034470; batch adversarial loss: 0.474064\n",
      "epoch 86; iter: 0; batch classifier loss: 0.039208; batch adversarial loss: 0.435372\n",
      "epoch 87; iter: 0; batch classifier loss: 0.063882; batch adversarial loss: 0.394620\n",
      "epoch 88; iter: 0; batch classifier loss: 0.037946; batch adversarial loss: 0.428676\n",
      "epoch 89; iter: 0; batch classifier loss: 0.028192; batch adversarial loss: 0.527493\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052458; batch adversarial loss: 0.501659\n",
      "epoch 91; iter: 0; batch classifier loss: 0.084220; batch adversarial loss: 0.485860\n",
      "epoch 92; iter: 0; batch classifier loss: 0.032118; batch adversarial loss: 0.530061\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064642; batch adversarial loss: 0.351629\n",
      "epoch 94; iter: 0; batch classifier loss: 0.081538; batch adversarial loss: 0.499802\n",
      "epoch 95; iter: 0; batch classifier loss: 0.018609; batch adversarial loss: 0.395601\n",
      "epoch 96; iter: 0; batch classifier loss: 0.029190; batch adversarial loss: 0.500300\n",
      "epoch 97; iter: 0; batch classifier loss: 0.034932; batch adversarial loss: 0.396461\n",
      "epoch 98; iter: 0; batch classifier loss: 0.060845; batch adversarial loss: 0.469782\n",
      "epoch 99; iter: 0; batch classifier loss: 0.036740; batch adversarial loss: 0.479273\n",
      "epoch 100; iter: 0; batch classifier loss: 0.019310; batch adversarial loss: 0.532964\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049249; batch adversarial loss: 0.421045\n",
      "epoch 102; iter: 0; batch classifier loss: 0.026324; batch adversarial loss: 0.512959\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053472; batch adversarial loss: 0.479524\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036703; batch adversarial loss: 0.436302\n",
      "epoch 105; iter: 0; batch classifier loss: 0.036734; batch adversarial loss: 0.510479\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025288; batch adversarial loss: 0.412546\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033815; batch adversarial loss: 0.452403\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064625; batch adversarial loss: 0.431493\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044809; batch adversarial loss: 0.383689\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025937; batch adversarial loss: 0.492580\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045891; batch adversarial loss: 0.535365\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045120; batch adversarial loss: 0.424638\n",
      "epoch 113; iter: 0; batch classifier loss: 0.016991; batch adversarial loss: 0.438073\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039554; batch adversarial loss: 0.419317\n",
      "epoch 115; iter: 0; batch classifier loss: 0.090734; batch adversarial loss: 0.373055\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035892; batch adversarial loss: 0.443921\n",
      "epoch 117; iter: 0; batch classifier loss: 0.018685; batch adversarial loss: 0.442765\n",
      "epoch 118; iter: 0; batch classifier loss: 0.023716; batch adversarial loss: 0.533890\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037297; batch adversarial loss: 0.518809\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032489; batch adversarial loss: 0.522216\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042900; batch adversarial loss: 0.453669\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059763; batch adversarial loss: 0.463864\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031204; batch adversarial loss: 0.512670\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036973; batch adversarial loss: 0.450650\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044417; batch adversarial loss: 0.415807\n",
      "epoch 126; iter: 0; batch classifier loss: 0.012911; batch adversarial loss: 0.473146\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023287; batch adversarial loss: 0.499027\n",
      "epoch 128; iter: 0; batch classifier loss: 0.015781; batch adversarial loss: 0.463927\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029308; batch adversarial loss: 0.582381\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047581; batch adversarial loss: 0.430128\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015430; batch adversarial loss: 0.483063\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038313; batch adversarial loss: 0.531660\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045732; batch adversarial loss: 0.402561\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036713; batch adversarial loss: 0.498591\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012820; batch adversarial loss: 0.386566\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034391; batch adversarial loss: 0.435106\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034717; batch adversarial loss: 0.552294\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020565; batch adversarial loss: 0.420016\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022065; batch adversarial loss: 0.456915\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036598; batch adversarial loss: 0.477307\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020047; batch adversarial loss: 0.322995\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035043; batch adversarial loss: 0.446450\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021925; batch adversarial loss: 0.375979\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022507; batch adversarial loss: 0.434101\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034513; batch adversarial loss: 0.457600\n",
      "epoch 146; iter: 0; batch classifier loss: 0.011725; batch adversarial loss: 0.361696\n",
      "epoch 147; iter: 0; batch classifier loss: 0.047618; batch adversarial loss: 0.447605\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018063; batch adversarial loss: 0.469785\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021933; batch adversarial loss: 0.423691\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032922; batch adversarial loss: 0.393855\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020933; batch adversarial loss: 0.430567\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044733; batch adversarial loss: 0.463695\n",
      "epoch 153; iter: 0; batch classifier loss: 0.033401; batch adversarial loss: 0.499327\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025714; batch adversarial loss: 0.508152\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026568; batch adversarial loss: 0.459627\n",
      "epoch 156; iter: 0; batch classifier loss: 0.009081; batch adversarial loss: 0.445615\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039558; batch adversarial loss: 0.464883\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022705; batch adversarial loss: 0.448681\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035906; batch adversarial loss: 0.640269\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010021; batch adversarial loss: 0.486590\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020523; batch adversarial loss: 0.425580\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015386; batch adversarial loss: 0.488174\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027584; batch adversarial loss: 0.413212\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024345; batch adversarial loss: 0.400170\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011513; batch adversarial loss: 0.436937\n",
      "epoch 166; iter: 0; batch classifier loss: 0.009243; batch adversarial loss: 0.458076\n",
      "epoch 167; iter: 0; batch classifier loss: 0.047019; batch adversarial loss: 0.404778\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020789; batch adversarial loss: 0.447745\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011305; batch adversarial loss: 0.379048\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034068; batch adversarial loss: 0.539609\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030478; batch adversarial loss: 0.453701\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016316; batch adversarial loss: 0.430564\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008952; batch adversarial loss: 0.436080\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028459; batch adversarial loss: 0.547397\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030899; batch adversarial loss: 0.472608\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013540; batch adversarial loss: 0.426109\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008354; batch adversarial loss: 0.439750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.034756; batch adversarial loss: 0.496778\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037499; batch adversarial loss: 0.379743\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027838; batch adversarial loss: 0.396073\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021117; batch adversarial loss: 0.466083\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011735; batch adversarial loss: 0.509646\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015125; batch adversarial loss: 0.503542\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017916; batch adversarial loss: 0.381268\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036646; batch adversarial loss: 0.518379\n",
      "epoch 186; iter: 0; batch classifier loss: 0.004537; batch adversarial loss: 0.470898\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012708; batch adversarial loss: 0.391635\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014258; batch adversarial loss: 0.440029\n",
      "epoch 189; iter: 0; batch classifier loss: 0.005575; batch adversarial loss: 0.465439\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017584; batch adversarial loss: 0.430661\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017030; batch adversarial loss: 0.443452\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030547; batch adversarial loss: 0.504172\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013707; batch adversarial loss: 0.500018\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019194; batch adversarial loss: 0.533976\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015903; batch adversarial loss: 0.441602\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015488; batch adversarial loss: 0.398181\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007606; batch adversarial loss: 0.436897\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016086; batch adversarial loss: 0.532418\n",
      "epoch 199; iter: 0; batch classifier loss: 0.037362; batch adversarial loss: 0.437906\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690830; batch adversarial loss: 0.650756\n",
      "epoch 1; iter: 0; batch classifier loss: 0.513332; batch adversarial loss: 0.656285\n",
      "epoch 2; iter: 0; batch classifier loss: 0.383888; batch adversarial loss: 0.606088\n",
      "epoch 3; iter: 0; batch classifier loss: 0.460415; batch adversarial loss: 0.592903\n",
      "epoch 4; iter: 0; batch classifier loss: 0.399790; batch adversarial loss: 0.601659\n",
      "epoch 5; iter: 0; batch classifier loss: 0.380452; batch adversarial loss: 0.560990\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520056; batch adversarial loss: 0.542568\n",
      "epoch 7; iter: 0; batch classifier loss: 0.416898; batch adversarial loss: 0.553782\n",
      "epoch 8; iter: 0; batch classifier loss: 0.417775; batch adversarial loss: 0.551280\n",
      "epoch 9; iter: 0; batch classifier loss: 0.443410; batch adversarial loss: 0.515675\n",
      "epoch 10; iter: 0; batch classifier loss: 0.492038; batch adversarial loss: 0.563349\n",
      "epoch 11; iter: 0; batch classifier loss: 0.459735; batch adversarial loss: 0.518415\n",
      "epoch 12; iter: 0; batch classifier loss: 0.417647; batch adversarial loss: 0.461748\n",
      "epoch 13; iter: 0; batch classifier loss: 0.327582; batch adversarial loss: 0.518727\n",
      "epoch 14; iter: 0; batch classifier loss: 0.368229; batch adversarial loss: 0.485981\n",
      "epoch 15; iter: 0; batch classifier loss: 0.279915; batch adversarial loss: 0.571712\n",
      "epoch 16; iter: 0; batch classifier loss: 0.354535; batch adversarial loss: 0.508428\n",
      "epoch 17; iter: 0; batch classifier loss: 0.256759; batch adversarial loss: 0.483276\n",
      "epoch 18; iter: 0; batch classifier loss: 0.433834; batch adversarial loss: 0.536633\n",
      "epoch 19; iter: 0; batch classifier loss: 0.294654; batch adversarial loss: 0.444523\n",
      "epoch 20; iter: 0; batch classifier loss: 0.395380; batch adversarial loss: 0.468742\n",
      "epoch 21; iter: 0; batch classifier loss: 0.267738; batch adversarial loss: 0.474954\n",
      "epoch 22; iter: 0; batch classifier loss: 0.322294; batch adversarial loss: 0.538225\n",
      "epoch 23; iter: 0; batch classifier loss: 0.310869; batch adversarial loss: 0.429664\n",
      "epoch 24; iter: 0; batch classifier loss: 0.265044; batch adversarial loss: 0.519706\n",
      "epoch 25; iter: 0; batch classifier loss: 0.286244; batch adversarial loss: 0.484278\n",
      "epoch 26; iter: 0; batch classifier loss: 0.302220; batch adversarial loss: 0.468696\n",
      "epoch 27; iter: 0; batch classifier loss: 0.254537; batch adversarial loss: 0.515998\n",
      "epoch 28; iter: 0; batch classifier loss: 0.286199; batch adversarial loss: 0.481275\n",
      "epoch 29; iter: 0; batch classifier loss: 0.261194; batch adversarial loss: 0.383004\n",
      "epoch 30; iter: 0; batch classifier loss: 0.293397; batch adversarial loss: 0.480656\n",
      "epoch 31; iter: 0; batch classifier loss: 0.218845; batch adversarial loss: 0.458449\n",
      "epoch 32; iter: 0; batch classifier loss: 0.245903; batch adversarial loss: 0.439630\n",
      "epoch 33; iter: 0; batch classifier loss: 0.230110; batch adversarial loss: 0.429074\n",
      "epoch 34; iter: 0; batch classifier loss: 0.232072; batch adversarial loss: 0.412092\n",
      "epoch 35; iter: 0; batch classifier loss: 0.270765; batch adversarial loss: 0.532585\n",
      "epoch 36; iter: 0; batch classifier loss: 0.206039; batch adversarial loss: 0.466075\n",
      "epoch 37; iter: 0; batch classifier loss: 0.224826; batch adversarial loss: 0.422906\n",
      "epoch 38; iter: 0; batch classifier loss: 0.182705; batch adversarial loss: 0.447132\n",
      "epoch 39; iter: 0; batch classifier loss: 0.255660; batch adversarial loss: 0.489392\n",
      "epoch 40; iter: 0; batch classifier loss: 0.213215; batch adversarial loss: 0.416447\n",
      "epoch 41; iter: 0; batch classifier loss: 0.226344; batch adversarial loss: 0.435241\n",
      "epoch 42; iter: 0; batch classifier loss: 0.267733; batch adversarial loss: 0.437735\n",
      "epoch 43; iter: 0; batch classifier loss: 0.210525; batch adversarial loss: 0.509856\n",
      "epoch 44; iter: 0; batch classifier loss: 0.221714; batch adversarial loss: 0.434053\n",
      "epoch 45; iter: 0; batch classifier loss: 0.166666; batch adversarial loss: 0.589847\n",
      "epoch 46; iter: 0; batch classifier loss: 0.285640; batch adversarial loss: 0.453151\n",
      "epoch 47; iter: 0; batch classifier loss: 0.219325; batch adversarial loss: 0.460166\n",
      "epoch 48; iter: 0; batch classifier loss: 0.278174; batch adversarial loss: 0.387560\n",
      "epoch 49; iter: 0; batch classifier loss: 0.214747; batch adversarial loss: 0.484612\n",
      "epoch 50; iter: 0; batch classifier loss: 0.197934; batch adversarial loss: 0.554724\n",
      "epoch 51; iter: 0; batch classifier loss: 0.238061; batch adversarial loss: 0.483542\n",
      "epoch 52; iter: 0; batch classifier loss: 0.244889; batch adversarial loss: 0.434540\n",
      "epoch 53; iter: 0; batch classifier loss: 0.179477; batch adversarial loss: 0.461382\n",
      "epoch 54; iter: 0; batch classifier loss: 0.271091; batch adversarial loss: 0.458579\n",
      "epoch 55; iter: 0; batch classifier loss: 0.192779; batch adversarial loss: 0.518702\n",
      "epoch 56; iter: 0; batch classifier loss: 0.206330; batch adversarial loss: 0.470081\n",
      "epoch 57; iter: 0; batch classifier loss: 0.214705; batch adversarial loss: 0.531752\n",
      "epoch 58; iter: 0; batch classifier loss: 0.214047; batch adversarial loss: 0.422515\n",
      "epoch 59; iter: 0; batch classifier loss: 0.261380; batch adversarial loss: 0.422578\n",
      "epoch 60; iter: 0; batch classifier loss: 0.099585; batch adversarial loss: 0.507090\n",
      "epoch 61; iter: 0; batch classifier loss: 0.155467; batch adversarial loss: 0.358636\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101298; batch adversarial loss: 0.420114\n",
      "epoch 63; iter: 0; batch classifier loss: 0.251314; batch adversarial loss: 0.445039\n",
      "epoch 64; iter: 0; batch classifier loss: 0.194158; batch adversarial loss: 0.449648\n",
      "epoch 65; iter: 0; batch classifier loss: 0.155444; batch adversarial loss: 0.520849\n",
      "epoch 66; iter: 0; batch classifier loss: 0.178200; batch adversarial loss: 0.471667\n",
      "epoch 67; iter: 0; batch classifier loss: 0.254218; batch adversarial loss: 0.445107\n",
      "epoch 68; iter: 0; batch classifier loss: 0.185877; batch adversarial loss: 0.408391\n",
      "epoch 69; iter: 0; batch classifier loss: 0.198390; batch adversarial loss: 0.456672\n",
      "epoch 70; iter: 0; batch classifier loss: 0.175726; batch adversarial loss: 0.419927\n",
      "epoch 71; iter: 0; batch classifier loss: 0.194601; batch adversarial loss: 0.456702\n",
      "epoch 72; iter: 0; batch classifier loss: 0.210502; batch adversarial loss: 0.484146\n",
      "epoch 73; iter: 0; batch classifier loss: 0.202872; batch adversarial loss: 0.383698\n",
      "epoch 74; iter: 0; batch classifier loss: 0.220859; batch adversarial loss: 0.445906\n",
      "epoch 75; iter: 0; batch classifier loss: 0.172063; batch adversarial loss: 0.482498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.196915; batch adversarial loss: 0.423269\n",
      "epoch 77; iter: 0; batch classifier loss: 0.163864; batch adversarial loss: 0.546765\n",
      "epoch 78; iter: 0; batch classifier loss: 0.182546; batch adversarial loss: 0.520547\n",
      "epoch 79; iter: 0; batch classifier loss: 0.199261; batch adversarial loss: 0.497122\n",
      "epoch 80; iter: 0; batch classifier loss: 0.170954; batch adversarial loss: 0.459435\n",
      "epoch 81; iter: 0; batch classifier loss: 0.196391; batch adversarial loss: 0.483212\n",
      "epoch 82; iter: 0; batch classifier loss: 0.224986; batch adversarial loss: 0.422640\n",
      "epoch 83; iter: 0; batch classifier loss: 0.214733; batch adversarial loss: 0.471255\n",
      "epoch 84; iter: 0; batch classifier loss: 0.214090; batch adversarial loss: 0.408541\n",
      "epoch 85; iter: 0; batch classifier loss: 0.181066; batch adversarial loss: 0.346737\n",
      "epoch 86; iter: 0; batch classifier loss: 0.156661; batch adversarial loss: 0.384490\n",
      "epoch 87; iter: 0; batch classifier loss: 0.236046; batch adversarial loss: 0.420750\n",
      "epoch 88; iter: 0; batch classifier loss: 0.240925; batch adversarial loss: 0.433085\n",
      "epoch 89; iter: 0; batch classifier loss: 0.235933; batch adversarial loss: 0.395101\n",
      "epoch 90; iter: 0; batch classifier loss: 0.156379; batch adversarial loss: 0.370826\n",
      "epoch 91; iter: 0; batch classifier loss: 0.197664; batch adversarial loss: 0.432102\n",
      "epoch 92; iter: 0; batch classifier loss: 0.214834; batch adversarial loss: 0.468724\n",
      "epoch 93; iter: 0; batch classifier loss: 0.183779; batch adversarial loss: 0.444699\n",
      "epoch 94; iter: 0; batch classifier loss: 0.238966; batch adversarial loss: 0.484991\n",
      "epoch 95; iter: 0; batch classifier loss: 0.155778; batch adversarial loss: 0.409652\n",
      "epoch 96; iter: 0; batch classifier loss: 0.188486; batch adversarial loss: 0.408228\n",
      "epoch 97; iter: 0; batch classifier loss: 0.165248; batch adversarial loss: 0.432318\n",
      "epoch 98; iter: 0; batch classifier loss: 0.144615; batch adversarial loss: 0.531611\n",
      "epoch 99; iter: 0; batch classifier loss: 0.175392; batch adversarial loss: 0.460162\n",
      "epoch 100; iter: 0; batch classifier loss: 0.091595; batch adversarial loss: 0.443338\n",
      "epoch 101; iter: 0; batch classifier loss: 0.095302; batch adversarial loss: 0.459141\n",
      "epoch 102; iter: 0; batch classifier loss: 0.081425; batch adversarial loss: 0.416791\n",
      "epoch 103; iter: 0; batch classifier loss: 0.088701; batch adversarial loss: 0.480065\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061198; batch adversarial loss: 0.465043\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054663; batch adversarial loss: 0.523145\n",
      "epoch 106; iter: 0; batch classifier loss: 0.078850; batch adversarial loss: 0.380676\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066553; batch adversarial loss: 0.409168\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052915; batch adversarial loss: 0.461883\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044190; batch adversarial loss: 0.484380\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053151; batch adversarial loss: 0.437736\n",
      "epoch 111; iter: 0; batch classifier loss: 0.070002; batch adversarial loss: 0.509106\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031963; batch adversarial loss: 0.491443\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053694; batch adversarial loss: 0.519716\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051236; batch adversarial loss: 0.478757\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042323; batch adversarial loss: 0.424997\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046594; batch adversarial loss: 0.471993\n",
      "epoch 117; iter: 0; batch classifier loss: 0.057131; batch adversarial loss: 0.403315\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069231; batch adversarial loss: 0.471980\n",
      "epoch 119; iter: 0; batch classifier loss: 0.104226; batch adversarial loss: 0.470918\n",
      "epoch 120; iter: 0; batch classifier loss: 0.026535; batch adversarial loss: 0.445089\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029417; batch adversarial loss: 0.462816\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051809; batch adversarial loss: 0.375844\n",
      "epoch 123; iter: 0; batch classifier loss: 0.054201; batch adversarial loss: 0.400577\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031413; batch adversarial loss: 0.496601\n",
      "epoch 125; iter: 0; batch classifier loss: 0.016045; batch adversarial loss: 0.456248\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050358; batch adversarial loss: 0.353880\n",
      "epoch 127; iter: 0; batch classifier loss: 0.064886; batch adversarial loss: 0.431496\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032944; batch adversarial loss: 0.392701\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030324; batch adversarial loss: 0.477732\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033303; batch adversarial loss: 0.468320\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031741; batch adversarial loss: 0.359588\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022602; batch adversarial loss: 0.379376\n",
      "epoch 133; iter: 0; batch classifier loss: 0.082209; batch adversarial loss: 0.446663\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034863; batch adversarial loss: 0.413335\n",
      "epoch 135; iter: 0; batch classifier loss: 0.053592; batch adversarial loss: 0.431237\n",
      "epoch 136; iter: 0; batch classifier loss: 0.060365; batch adversarial loss: 0.472461\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035678; batch adversarial loss: 0.545819\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020282; batch adversarial loss: 0.393751\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033423; batch adversarial loss: 0.464941\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018226; batch adversarial loss: 0.463613\n",
      "epoch 141; iter: 0; batch classifier loss: 0.010047; batch adversarial loss: 0.466436\n",
      "epoch 142; iter: 0; batch classifier loss: 0.052808; batch adversarial loss: 0.405731\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016405; batch adversarial loss: 0.509441\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014439; batch adversarial loss: 0.384594\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026984; batch adversarial loss: 0.444859\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013116; batch adversarial loss: 0.401835\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029517; batch adversarial loss: 0.432270\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026293; batch adversarial loss: 0.348426\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013221; batch adversarial loss: 0.489396\n",
      "epoch 150; iter: 0; batch classifier loss: 0.063627; batch adversarial loss: 0.497053\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041880; batch adversarial loss: 0.414851\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041145; batch adversarial loss: 0.503781\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017289; batch adversarial loss: 0.501126\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024631; batch adversarial loss: 0.463205\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038474; batch adversarial loss: 0.517914\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022088; batch adversarial loss: 0.539940\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023403; batch adversarial loss: 0.540306\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029941; batch adversarial loss: 0.506895\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016494; batch adversarial loss: 0.381732\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013598; batch adversarial loss: 0.468976\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025810; batch adversarial loss: 0.509238\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012607; batch adversarial loss: 0.440066\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036593; batch adversarial loss: 0.494886\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027250; batch adversarial loss: 0.450746\n",
      "epoch 165; iter: 0; batch classifier loss: 0.050381; batch adversarial loss: 0.408112\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031244; batch adversarial loss: 0.466217\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010381; batch adversarial loss: 0.457274\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017491; batch adversarial loss: 0.408136\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007594; batch adversarial loss: 0.426025\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013049; batch adversarial loss: 0.417626\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014004; batch adversarial loss: 0.361591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.007987; batch adversarial loss: 0.532073\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020299; batch adversarial loss: 0.409553\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020281; batch adversarial loss: 0.438666\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014148; batch adversarial loss: 0.589468\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034534; batch adversarial loss: 0.461622\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011031; batch adversarial loss: 0.345906\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018442; batch adversarial loss: 0.416290\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007958; batch adversarial loss: 0.396468\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035114; batch adversarial loss: 0.445781\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023847; batch adversarial loss: 0.487205\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028811; batch adversarial loss: 0.338218\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007630; batch adversarial loss: 0.482444\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029686; batch adversarial loss: 0.426079\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019218; batch adversarial loss: 0.423205\n",
      "epoch 186; iter: 0; batch classifier loss: 0.047764; batch adversarial loss: 0.476935\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012967; batch adversarial loss: 0.491888\n",
      "epoch 188; iter: 0; batch classifier loss: 0.003548; batch adversarial loss: 0.399286\n",
      "epoch 189; iter: 0; batch classifier loss: 0.003590; batch adversarial loss: 0.492675\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030741; batch adversarial loss: 0.435870\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033759; batch adversarial loss: 0.428833\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005407; batch adversarial loss: 0.383342\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020777; batch adversarial loss: 0.384362\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004175; batch adversarial loss: 0.456905\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021240; batch adversarial loss: 0.384667\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019989; batch adversarial loss: 0.467794\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012930; batch adversarial loss: 0.474944\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011437; batch adversarial loss: 0.445037\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020679; batch adversarial loss: 0.451335\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709674; batch adversarial loss: 0.692761\n",
      "epoch 1; iter: 0; batch classifier loss: 0.457162; batch adversarial loss: 0.636235\n",
      "epoch 2; iter: 0; batch classifier loss: 0.411546; batch adversarial loss: 0.609155\n",
      "epoch 3; iter: 0; batch classifier loss: 0.436732; batch adversarial loss: 0.577536\n",
      "epoch 4; iter: 0; batch classifier loss: 0.378787; batch adversarial loss: 0.554200\n",
      "epoch 5; iter: 0; batch classifier loss: 0.243322; batch adversarial loss: 0.545224\n",
      "epoch 6; iter: 0; batch classifier loss: 0.353720; batch adversarial loss: 0.533731\n",
      "epoch 7; iter: 0; batch classifier loss: 0.242013; batch adversarial loss: 0.549736\n",
      "epoch 8; iter: 0; batch classifier loss: 0.227290; batch adversarial loss: 0.553219\n",
      "epoch 9; iter: 0; batch classifier loss: 0.337501; batch adversarial loss: 0.574317\n",
      "epoch 10; iter: 0; batch classifier loss: 0.249359; batch adversarial loss: 0.530314\n",
      "epoch 11; iter: 0; batch classifier loss: 0.224372; batch adversarial loss: 0.512699\n",
      "epoch 12; iter: 0; batch classifier loss: 0.248035; batch adversarial loss: 0.481959\n",
      "epoch 13; iter: 0; batch classifier loss: 0.285846; batch adversarial loss: 0.480345\n",
      "epoch 14; iter: 0; batch classifier loss: 0.192239; batch adversarial loss: 0.480331\n",
      "epoch 15; iter: 0; batch classifier loss: 0.213993; batch adversarial loss: 0.437901\n",
      "epoch 16; iter: 0; batch classifier loss: 0.213174; batch adversarial loss: 0.463971\n",
      "epoch 17; iter: 0; batch classifier loss: 0.212156; batch adversarial loss: 0.437459\n",
      "epoch 18; iter: 0; batch classifier loss: 0.200502; batch adversarial loss: 0.559434\n",
      "epoch 19; iter: 0; batch classifier loss: 0.206954; batch adversarial loss: 0.463310\n",
      "epoch 20; iter: 0; batch classifier loss: 0.188370; batch adversarial loss: 0.475057\n",
      "epoch 21; iter: 0; batch classifier loss: 0.174661; batch adversarial loss: 0.522359\n",
      "epoch 22; iter: 0; batch classifier loss: 0.211572; batch adversarial loss: 0.399466\n",
      "epoch 23; iter: 0; batch classifier loss: 0.186339; batch adversarial loss: 0.575640\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192612; batch adversarial loss: 0.417789\n",
      "epoch 25; iter: 0; batch classifier loss: 0.152403; batch adversarial loss: 0.599571\n",
      "epoch 26; iter: 0; batch classifier loss: 0.190494; batch adversarial loss: 0.585308\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162595; batch adversarial loss: 0.436010\n",
      "epoch 28; iter: 0; batch classifier loss: 0.162134; batch adversarial loss: 0.515364\n",
      "epoch 29; iter: 0; batch classifier loss: 0.196300; batch adversarial loss: 0.470781\n",
      "epoch 30; iter: 0; batch classifier loss: 0.106367; batch adversarial loss: 0.551703\n",
      "epoch 31; iter: 0; batch classifier loss: 0.179000; batch adversarial loss: 0.419364\n",
      "epoch 32; iter: 0; batch classifier loss: 0.162212; batch adversarial loss: 0.492805\n",
      "epoch 33; iter: 0; batch classifier loss: 0.208682; batch adversarial loss: 0.433593\n",
      "epoch 34; iter: 0; batch classifier loss: 0.158710; batch adversarial loss: 0.391049\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140142; batch adversarial loss: 0.518572\n",
      "epoch 36; iter: 0; batch classifier loss: 0.164549; batch adversarial loss: 0.425408\n",
      "epoch 37; iter: 0; batch classifier loss: 0.138048; batch adversarial loss: 0.495338\n",
      "epoch 38; iter: 0; batch classifier loss: 0.144285; batch adversarial loss: 0.498806\n",
      "epoch 39; iter: 0; batch classifier loss: 0.178845; batch adversarial loss: 0.512211\n",
      "epoch 40; iter: 0; batch classifier loss: 0.151430; batch adversarial loss: 0.492513\n",
      "epoch 41; iter: 0; batch classifier loss: 0.133981; batch adversarial loss: 0.509596\n",
      "epoch 42; iter: 0; batch classifier loss: 0.144286; batch adversarial loss: 0.506551\n",
      "epoch 43; iter: 0; batch classifier loss: 0.136944; batch adversarial loss: 0.581950\n",
      "epoch 44; iter: 0; batch classifier loss: 0.147676; batch adversarial loss: 0.436894\n",
      "epoch 45; iter: 0; batch classifier loss: 0.207520; batch adversarial loss: 0.428177\n",
      "epoch 46; iter: 0; batch classifier loss: 0.161772; batch adversarial loss: 0.464441\n",
      "epoch 47; iter: 0; batch classifier loss: 0.140865; batch adversarial loss: 0.454991\n",
      "epoch 48; iter: 0; batch classifier loss: 0.148606; batch adversarial loss: 0.532517\n",
      "epoch 49; iter: 0; batch classifier loss: 0.112668; batch adversarial loss: 0.480248\n",
      "epoch 50; iter: 0; batch classifier loss: 0.164194; batch adversarial loss: 0.565093\n",
      "epoch 51; iter: 0; batch classifier loss: 0.134210; batch adversarial loss: 0.507273\n",
      "epoch 52; iter: 0; batch classifier loss: 0.146010; batch adversarial loss: 0.566681\n",
      "epoch 53; iter: 0; batch classifier loss: 0.111790; batch adversarial loss: 0.514534\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116518; batch adversarial loss: 0.449700\n",
      "epoch 55; iter: 0; batch classifier loss: 0.143842; batch adversarial loss: 0.539750\n",
      "epoch 56; iter: 0; batch classifier loss: 0.107235; batch adversarial loss: 0.509117\n",
      "epoch 57; iter: 0; batch classifier loss: 0.160223; batch adversarial loss: 0.548729\n",
      "epoch 58; iter: 0; batch classifier loss: 0.145935; batch adversarial loss: 0.540990\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081610; batch adversarial loss: 0.555343\n",
      "epoch 60; iter: 0; batch classifier loss: 0.151539; batch adversarial loss: 0.440263\n",
      "epoch 61; iter: 0; batch classifier loss: 0.185205; batch adversarial loss: 0.478173\n",
      "epoch 62; iter: 0; batch classifier loss: 0.158342; batch adversarial loss: 0.482901\n",
      "epoch 63; iter: 0; batch classifier loss: 0.134730; batch adversarial loss: 0.535407\n",
      "epoch 64; iter: 0; batch classifier loss: 0.150887; batch adversarial loss: 0.470963\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118171; batch adversarial loss: 0.469436\n",
      "epoch 66; iter: 0; batch classifier loss: 0.154681; batch adversarial loss: 0.391823\n",
      "epoch 67; iter: 0; batch classifier loss: 0.211210; batch adversarial loss: 0.469334\n",
      "epoch 68; iter: 0; batch classifier loss: 0.124246; batch adversarial loss: 0.342580\n",
      "epoch 69; iter: 0; batch classifier loss: 0.187390; batch adversarial loss: 0.412279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.144480; batch adversarial loss: 0.454157\n",
      "epoch 71; iter: 0; batch classifier loss: 0.103350; batch adversarial loss: 0.420921\n",
      "epoch 72; iter: 0; batch classifier loss: 0.130435; batch adversarial loss: 0.469984\n",
      "epoch 73; iter: 0; batch classifier loss: 0.163852; batch adversarial loss: 0.431784\n",
      "epoch 74; iter: 0; batch classifier loss: 0.146594; batch adversarial loss: 0.496568\n",
      "epoch 75; iter: 0; batch classifier loss: 0.151000; batch adversarial loss: 0.412961\n",
      "epoch 76; iter: 0; batch classifier loss: 0.145412; batch adversarial loss: 0.421648\n",
      "epoch 77; iter: 0; batch classifier loss: 0.129202; batch adversarial loss: 0.527938\n",
      "epoch 78; iter: 0; batch classifier loss: 0.179501; batch adversarial loss: 0.421338\n",
      "epoch 79; iter: 0; batch classifier loss: 0.136815; batch adversarial loss: 0.468649\n",
      "epoch 80; iter: 0; batch classifier loss: 0.161020; batch adversarial loss: 0.490714\n",
      "epoch 81; iter: 0; batch classifier loss: 0.109952; batch adversarial loss: 0.375111\n",
      "epoch 82; iter: 0; batch classifier loss: 0.153812; batch adversarial loss: 0.500554\n",
      "epoch 83; iter: 0; batch classifier loss: 0.109728; batch adversarial loss: 0.568710\n",
      "epoch 84; iter: 0; batch classifier loss: 0.086585; batch adversarial loss: 0.474336\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076569; batch adversarial loss: 0.490379\n",
      "epoch 86; iter: 0; batch classifier loss: 0.095967; batch adversarial loss: 0.542518\n",
      "epoch 87; iter: 0; batch classifier loss: 0.118174; batch adversarial loss: 0.355537\n",
      "epoch 88; iter: 0; batch classifier loss: 0.129390; batch adversarial loss: 0.397635\n",
      "epoch 89; iter: 0; batch classifier loss: 0.134020; batch adversarial loss: 0.522189\n",
      "epoch 90; iter: 0; batch classifier loss: 0.103289; batch adversarial loss: 0.485418\n",
      "epoch 91; iter: 0; batch classifier loss: 0.088744; batch adversarial loss: 0.475206\n",
      "epoch 92; iter: 0; batch classifier loss: 0.130073; batch adversarial loss: 0.435901\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052930; batch adversarial loss: 0.433596\n",
      "epoch 94; iter: 0; batch classifier loss: 0.074188; batch adversarial loss: 0.465065\n",
      "epoch 95; iter: 0; batch classifier loss: 0.082645; batch adversarial loss: 0.426779\n",
      "epoch 96; iter: 0; batch classifier loss: 0.075403; batch adversarial loss: 0.485056\n",
      "epoch 97; iter: 0; batch classifier loss: 0.079833; batch adversarial loss: 0.539230\n",
      "epoch 98; iter: 0; batch classifier loss: 0.066952; batch adversarial loss: 0.524496\n",
      "epoch 99; iter: 0; batch classifier loss: 0.029415; batch adversarial loss: 0.528824\n",
      "epoch 100; iter: 0; batch classifier loss: 0.073168; batch adversarial loss: 0.383194\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056693; batch adversarial loss: 0.473646\n",
      "epoch 102; iter: 0; batch classifier loss: 0.030005; batch adversarial loss: 0.443419\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044695; batch adversarial loss: 0.453185\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033923; batch adversarial loss: 0.429645\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062153; batch adversarial loss: 0.456250\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040504; batch adversarial loss: 0.461718\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039807; batch adversarial loss: 0.454424\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046947; batch adversarial loss: 0.523241\n",
      "epoch 109; iter: 0; batch classifier loss: 0.073976; batch adversarial loss: 0.385039\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058466; batch adversarial loss: 0.463961\n",
      "epoch 111; iter: 0; batch classifier loss: 0.026821; batch adversarial loss: 0.548528\n",
      "epoch 112; iter: 0; batch classifier loss: 0.065739; batch adversarial loss: 0.428623\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041082; batch adversarial loss: 0.422254\n",
      "epoch 114; iter: 0; batch classifier loss: 0.017813; batch adversarial loss: 0.472026\n",
      "epoch 115; iter: 0; batch classifier loss: 0.016771; batch adversarial loss: 0.446211\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024598; batch adversarial loss: 0.400105\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026736; batch adversarial loss: 0.495288\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030796; batch adversarial loss: 0.473466\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030376; batch adversarial loss: 0.429502\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047930; batch adversarial loss: 0.415607\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050531; batch adversarial loss: 0.478196\n",
      "epoch 122; iter: 0; batch classifier loss: 0.019813; batch adversarial loss: 0.486624\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031872; batch adversarial loss: 0.486684\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039427; batch adversarial loss: 0.405863\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036344; batch adversarial loss: 0.433852\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022550; batch adversarial loss: 0.495935\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030516; batch adversarial loss: 0.632010\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019407; batch adversarial loss: 0.555269\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040374; batch adversarial loss: 0.511156\n",
      "epoch 130; iter: 0; batch classifier loss: 0.015143; batch adversarial loss: 0.429865\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045747; batch adversarial loss: 0.464960\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040856; batch adversarial loss: 0.545405\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014528; batch adversarial loss: 0.480889\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027292; batch adversarial loss: 0.422520\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033034; batch adversarial loss: 0.531640\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038965; batch adversarial loss: 0.421311\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033557; batch adversarial loss: 0.441720\n",
      "epoch 138; iter: 0; batch classifier loss: 0.055093; batch adversarial loss: 0.485294\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021909; batch adversarial loss: 0.442125\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024367; batch adversarial loss: 0.487018\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020557; batch adversarial loss: 0.498916\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020550; batch adversarial loss: 0.538529\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019716; batch adversarial loss: 0.462524\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020422; batch adversarial loss: 0.468446\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020138; batch adversarial loss: 0.521210\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010629; batch adversarial loss: 0.542014\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024816; batch adversarial loss: 0.481368\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027431; batch adversarial loss: 0.487717\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022963; batch adversarial loss: 0.486516\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020614; batch adversarial loss: 0.502102\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025414; batch adversarial loss: 0.494848\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028777; batch adversarial loss: 0.473572\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025092; batch adversarial loss: 0.425578\n",
      "epoch 154; iter: 0; batch classifier loss: 0.062893; batch adversarial loss: 0.375599\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017743; batch adversarial loss: 0.413961\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026851; batch adversarial loss: 0.528053\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016399; batch adversarial loss: 0.528734\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028774; batch adversarial loss: 0.532332\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026293; batch adversarial loss: 0.435173\n",
      "epoch 160; iter: 0; batch classifier loss: 0.011939; batch adversarial loss: 0.465724\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017431; batch adversarial loss: 0.506793\n",
      "epoch 162; iter: 0; batch classifier loss: 0.006140; batch adversarial loss: 0.434457\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015497; batch adversarial loss: 0.342312\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009624; batch adversarial loss: 0.441355\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041360; batch adversarial loss: 0.475166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.012967; batch adversarial loss: 0.515751\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032471; batch adversarial loss: 0.412824\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045054; batch adversarial loss: 0.408804\n",
      "epoch 169; iter: 0; batch classifier loss: 0.048689; batch adversarial loss: 0.372797\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009139; batch adversarial loss: 0.488081\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010399; batch adversarial loss: 0.462432\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034717; batch adversarial loss: 0.353069\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013326; batch adversarial loss: 0.536942\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008772; batch adversarial loss: 0.612973\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015524; batch adversarial loss: 0.392928\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030419; batch adversarial loss: 0.457550\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021186; batch adversarial loss: 0.347156\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025340; batch adversarial loss: 0.498138\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017784; batch adversarial loss: 0.464880\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010488; batch adversarial loss: 0.460261\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034321; batch adversarial loss: 0.452911\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013394; batch adversarial loss: 0.407908\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016700; batch adversarial loss: 0.441671\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022327; batch adversarial loss: 0.460275\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013277; batch adversarial loss: 0.415453\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014487; batch adversarial loss: 0.481097\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005506; batch adversarial loss: 0.502806\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027487; batch adversarial loss: 0.462632\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013700; batch adversarial loss: 0.524324\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024984; batch adversarial loss: 0.410914\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017211; batch adversarial loss: 0.421247\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020977; batch adversarial loss: 0.522746\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028082; batch adversarial loss: 0.551654\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034467; batch adversarial loss: 0.449436\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024445; batch adversarial loss: 0.497960\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016193; batch adversarial loss: 0.412258\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026294; batch adversarial loss: 0.506408\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024517; batch adversarial loss: 0.437453\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011534; batch adversarial loss: 0.486838\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704654; batch adversarial loss: 0.694178\n",
      "epoch 1; iter: 0; batch classifier loss: 0.483057; batch adversarial loss: 0.661782\n",
      "epoch 2; iter: 0; batch classifier loss: 0.385829; batch adversarial loss: 0.624573\n",
      "epoch 3; iter: 0; batch classifier loss: 0.429432; batch adversarial loss: 0.569690\n",
      "epoch 4; iter: 0; batch classifier loss: 0.295393; batch adversarial loss: 0.574367\n",
      "epoch 5; iter: 0; batch classifier loss: 0.298679; batch adversarial loss: 0.533935\n",
      "epoch 6; iter: 0; batch classifier loss: 0.319122; batch adversarial loss: 0.555284\n",
      "epoch 7; iter: 0; batch classifier loss: 0.252292; batch adversarial loss: 0.483428\n",
      "epoch 8; iter: 0; batch classifier loss: 0.246607; batch adversarial loss: 0.524616\n",
      "epoch 9; iter: 0; batch classifier loss: 0.220940; batch adversarial loss: 0.452387\n",
      "epoch 10; iter: 0; batch classifier loss: 0.238391; batch adversarial loss: 0.511474\n",
      "epoch 11; iter: 0; batch classifier loss: 0.220325; batch adversarial loss: 0.484813\n",
      "epoch 12; iter: 0; batch classifier loss: 0.164785; batch adversarial loss: 0.461608\n",
      "epoch 13; iter: 0; batch classifier loss: 0.198618; batch adversarial loss: 0.467807\n",
      "epoch 14; iter: 0; batch classifier loss: 0.158195; batch adversarial loss: 0.490129\n",
      "epoch 15; iter: 0; batch classifier loss: 0.190077; batch adversarial loss: 0.485905\n",
      "epoch 16; iter: 0; batch classifier loss: 0.153449; batch adversarial loss: 0.415198\n",
      "epoch 17; iter: 0; batch classifier loss: 0.208015; batch adversarial loss: 0.378051\n",
      "epoch 18; iter: 0; batch classifier loss: 0.191400; batch adversarial loss: 0.366223\n",
      "epoch 19; iter: 0; batch classifier loss: 0.172301; batch adversarial loss: 0.482528\n",
      "epoch 20; iter: 0; batch classifier loss: 0.152168; batch adversarial loss: 0.474470\n",
      "epoch 21; iter: 0; batch classifier loss: 0.173899; batch adversarial loss: 0.549769\n",
      "epoch 22; iter: 0; batch classifier loss: 0.137010; batch adversarial loss: 0.484102\n",
      "epoch 23; iter: 0; batch classifier loss: 0.162667; batch adversarial loss: 0.458147\n",
      "epoch 24; iter: 0; batch classifier loss: 0.129058; batch adversarial loss: 0.465303\n",
      "epoch 25; iter: 0; batch classifier loss: 0.149172; batch adversarial loss: 0.504893\n",
      "epoch 26; iter: 0; batch classifier loss: 0.163941; batch adversarial loss: 0.462963\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154771; batch adversarial loss: 0.388323\n",
      "epoch 28; iter: 0; batch classifier loss: 0.252431; batch adversarial loss: 0.521864\n",
      "epoch 29; iter: 0; batch classifier loss: 0.220271; batch adversarial loss: 0.475930\n",
      "epoch 30; iter: 0; batch classifier loss: 0.193850; batch adversarial loss: 0.486277\n",
      "epoch 31; iter: 0; batch classifier loss: 0.107902; batch adversarial loss: 0.445403\n",
      "epoch 32; iter: 0; batch classifier loss: 0.260547; batch adversarial loss: 0.490211\n",
      "epoch 33; iter: 0; batch classifier loss: 0.259751; batch adversarial loss: 0.490112\n",
      "epoch 34; iter: 0; batch classifier loss: 0.331756; batch adversarial loss: 0.506060\n",
      "epoch 35; iter: 0; batch classifier loss: 0.303643; batch adversarial loss: 0.459560\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140400; batch adversarial loss: 0.457865\n",
      "epoch 37; iter: 0; batch classifier loss: 0.120515; batch adversarial loss: 0.365139\n",
      "epoch 38; iter: 0; batch classifier loss: 0.110681; batch adversarial loss: 0.476350\n",
      "epoch 39; iter: 0; batch classifier loss: 0.066978; batch adversarial loss: 0.496795\n",
      "epoch 40; iter: 0; batch classifier loss: 0.108373; batch adversarial loss: 0.467940\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098596; batch adversarial loss: 0.400257\n",
      "epoch 42; iter: 0; batch classifier loss: 0.104592; batch adversarial loss: 0.418393\n",
      "epoch 43; iter: 0; batch classifier loss: 0.130550; batch adversarial loss: 0.520536\n",
      "epoch 44; iter: 0; batch classifier loss: 0.077483; batch adversarial loss: 0.442285\n",
      "epoch 45; iter: 0; batch classifier loss: 0.077796; batch adversarial loss: 0.443181\n",
      "epoch 46; iter: 0; batch classifier loss: 0.055562; batch adversarial loss: 0.449819\n",
      "epoch 47; iter: 0; batch classifier loss: 0.056545; batch adversarial loss: 0.499441\n",
      "epoch 48; iter: 0; batch classifier loss: 0.069531; batch adversarial loss: 0.460122\n",
      "epoch 49; iter: 0; batch classifier loss: 0.110088; batch adversarial loss: 0.450452\n",
      "epoch 50; iter: 0; batch classifier loss: 0.055734; batch adversarial loss: 0.523819\n",
      "epoch 51; iter: 0; batch classifier loss: 0.075825; batch adversarial loss: 0.515081\n",
      "epoch 52; iter: 0; batch classifier loss: 0.067603; batch adversarial loss: 0.555768\n",
      "epoch 53; iter: 0; batch classifier loss: 0.080128; batch adversarial loss: 0.419741\n",
      "epoch 54; iter: 0; batch classifier loss: 0.045363; batch adversarial loss: 0.436726\n",
      "epoch 55; iter: 0; batch classifier loss: 0.095985; batch adversarial loss: 0.550945\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082560; batch adversarial loss: 0.574677\n",
      "epoch 57; iter: 0; batch classifier loss: 0.068250; batch adversarial loss: 0.518162\n",
      "epoch 58; iter: 0; batch classifier loss: 0.046205; batch adversarial loss: 0.407507\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102476; batch adversarial loss: 0.464900\n",
      "epoch 60; iter: 0; batch classifier loss: 0.042591; batch adversarial loss: 0.443828\n",
      "epoch 61; iter: 0; batch classifier loss: 0.054855; batch adversarial loss: 0.540537\n",
      "epoch 62; iter: 0; batch classifier loss: 0.087589; batch adversarial loss: 0.385250\n",
      "epoch 63; iter: 0; batch classifier loss: 0.039521; batch adversarial loss: 0.332751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.052442; batch adversarial loss: 0.465510\n",
      "epoch 65; iter: 0; batch classifier loss: 0.038805; batch adversarial loss: 0.470485\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088506; batch adversarial loss: 0.396693\n",
      "epoch 67; iter: 0; batch classifier loss: 0.050299; batch adversarial loss: 0.499707\n",
      "epoch 68; iter: 0; batch classifier loss: 0.074485; batch adversarial loss: 0.445732\n",
      "epoch 69; iter: 0; batch classifier loss: 0.051402; batch adversarial loss: 0.521184\n",
      "epoch 70; iter: 0; batch classifier loss: 0.031780; batch adversarial loss: 0.447567\n",
      "epoch 71; iter: 0; batch classifier loss: 0.070183; batch adversarial loss: 0.455868\n",
      "epoch 72; iter: 0; batch classifier loss: 0.092271; batch adversarial loss: 0.485600\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075794; batch adversarial loss: 0.386499\n",
      "epoch 74; iter: 0; batch classifier loss: 0.090002; batch adversarial loss: 0.559081\n",
      "epoch 75; iter: 0; batch classifier loss: 0.055270; batch adversarial loss: 0.444458\n",
      "epoch 76; iter: 0; batch classifier loss: 0.049172; batch adversarial loss: 0.489027\n",
      "epoch 77; iter: 0; batch classifier loss: 0.057474; batch adversarial loss: 0.536554\n",
      "epoch 78; iter: 0; batch classifier loss: 0.078402; batch adversarial loss: 0.467308\n",
      "epoch 79; iter: 0; batch classifier loss: 0.086615; batch adversarial loss: 0.479852\n",
      "epoch 80; iter: 0; batch classifier loss: 0.085658; batch adversarial loss: 0.445996\n",
      "epoch 81; iter: 0; batch classifier loss: 0.110144; batch adversarial loss: 0.456119\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065382; batch adversarial loss: 0.438414\n",
      "epoch 83; iter: 0; batch classifier loss: 0.146208; batch adversarial loss: 0.423977\n",
      "epoch 84; iter: 0; batch classifier loss: 0.058180; batch adversarial loss: 0.433749\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083012; batch adversarial loss: 0.489391\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062144; batch adversarial loss: 0.592201\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053634; batch adversarial loss: 0.389503\n",
      "epoch 88; iter: 0; batch classifier loss: 0.030871; batch adversarial loss: 0.480423\n",
      "epoch 89; iter: 0; batch classifier loss: 0.033327; batch adversarial loss: 0.517683\n",
      "epoch 90; iter: 0; batch classifier loss: 0.029633; batch adversarial loss: 0.479983\n",
      "epoch 91; iter: 0; batch classifier loss: 0.031469; batch adversarial loss: 0.488901\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074950; batch adversarial loss: 0.437197\n",
      "epoch 93; iter: 0; batch classifier loss: 0.049060; batch adversarial loss: 0.396428\n",
      "epoch 94; iter: 0; batch classifier loss: 0.032527; batch adversarial loss: 0.591422\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054004; batch adversarial loss: 0.442492\n",
      "epoch 96; iter: 0; batch classifier loss: 0.032037; batch adversarial loss: 0.465163\n",
      "epoch 97; iter: 0; batch classifier loss: 0.097963; batch adversarial loss: 0.300935\n",
      "epoch 98; iter: 0; batch classifier loss: 0.064948; batch adversarial loss: 0.346826\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041108; batch adversarial loss: 0.496847\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060722; batch adversarial loss: 0.451766\n",
      "epoch 101; iter: 0; batch classifier loss: 0.030247; batch adversarial loss: 0.410389\n",
      "epoch 102; iter: 0; batch classifier loss: 0.064090; batch adversarial loss: 0.510678\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033914; batch adversarial loss: 0.476522\n",
      "epoch 104; iter: 0; batch classifier loss: 0.022987; batch adversarial loss: 0.468862\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037768; batch adversarial loss: 0.462580\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054150; batch adversarial loss: 0.444735\n",
      "epoch 107; iter: 0; batch classifier loss: 0.019958; batch adversarial loss: 0.598575\n",
      "epoch 108; iter: 0; batch classifier loss: 0.016143; batch adversarial loss: 0.413564\n",
      "epoch 109; iter: 0; batch classifier loss: 0.052500; batch adversarial loss: 0.558750\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061650; batch adversarial loss: 0.496268\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040970; batch adversarial loss: 0.464723\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044984; batch adversarial loss: 0.511195\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046997; batch adversarial loss: 0.521517\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060745; batch adversarial loss: 0.471270\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044242; batch adversarial loss: 0.434895\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052745; batch adversarial loss: 0.408195\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044621; batch adversarial loss: 0.491306\n",
      "epoch 118; iter: 0; batch classifier loss: 0.017706; batch adversarial loss: 0.488746\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026182; batch adversarial loss: 0.352737\n",
      "epoch 120; iter: 0; batch classifier loss: 0.056827; batch adversarial loss: 0.402293\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026839; batch adversarial loss: 0.467622\n",
      "epoch 122; iter: 0; batch classifier loss: 0.019389; batch adversarial loss: 0.360816\n",
      "epoch 123; iter: 0; batch classifier loss: 0.082672; batch adversarial loss: 0.557727\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026426; batch adversarial loss: 0.340522\n",
      "epoch 125; iter: 0; batch classifier loss: 0.010771; batch adversarial loss: 0.458411\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017657; batch adversarial loss: 0.428568\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029713; batch adversarial loss: 0.334896\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030122; batch adversarial loss: 0.400939\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026909; batch adversarial loss: 0.489289\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034254; batch adversarial loss: 0.467274\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047072; batch adversarial loss: 0.402854\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033056; batch adversarial loss: 0.484557\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035029; batch adversarial loss: 0.465618\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032536; batch adversarial loss: 0.446280\n",
      "epoch 135; iter: 0; batch classifier loss: 0.071052; batch adversarial loss: 0.433154\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036074; batch adversarial loss: 0.388717\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027881; batch adversarial loss: 0.456312\n",
      "epoch 138; iter: 0; batch classifier loss: 0.064375; batch adversarial loss: 0.412871\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042001; batch adversarial loss: 0.429746\n",
      "epoch 140; iter: 0; batch classifier loss: 0.058846; batch adversarial loss: 0.358368\n",
      "epoch 141; iter: 0; batch classifier loss: 0.051435; batch adversarial loss: 0.484900\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021826; batch adversarial loss: 0.514618\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024336; batch adversarial loss: 0.471100\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048088; batch adversarial loss: 0.453407\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015667; batch adversarial loss: 0.450376\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013163; batch adversarial loss: 0.414651\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022728; batch adversarial loss: 0.431478\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045449; batch adversarial loss: 0.447715\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014935; batch adversarial loss: 0.443428\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030389; batch adversarial loss: 0.400831\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042060; batch adversarial loss: 0.450063\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010106; batch adversarial loss: 0.483151\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014153; batch adversarial loss: 0.522946\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025776; batch adversarial loss: 0.377859\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009073; batch adversarial loss: 0.403675\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038424; batch adversarial loss: 0.462952\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023605; batch adversarial loss: 0.603720\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026318; batch adversarial loss: 0.496597\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021732; batch adversarial loss: 0.464972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.025357; batch adversarial loss: 0.369828\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026149; batch adversarial loss: 0.436657\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016108; batch adversarial loss: 0.410746\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023346; batch adversarial loss: 0.540576\n",
      "epoch 164; iter: 0; batch classifier loss: 0.058661; batch adversarial loss: 0.429176\n",
      "epoch 165; iter: 0; batch classifier loss: 0.053075; batch adversarial loss: 0.450951\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032309; batch adversarial loss: 0.488514\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015179; batch adversarial loss: 0.400861\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033885; batch adversarial loss: 0.367780\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017568; batch adversarial loss: 0.463669\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015783; batch adversarial loss: 0.417446\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026233; batch adversarial loss: 0.347028\n",
      "epoch 172; iter: 0; batch classifier loss: 0.035182; batch adversarial loss: 0.365318\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028564; batch adversarial loss: 0.455229\n",
      "epoch 174; iter: 0; batch classifier loss: 0.042900; batch adversarial loss: 0.455468\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008455; batch adversarial loss: 0.487494\n",
      "epoch 176; iter: 0; batch classifier loss: 0.043050; batch adversarial loss: 0.416507\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027683; batch adversarial loss: 0.460042\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023204; batch adversarial loss: 0.401999\n",
      "epoch 179; iter: 0; batch classifier loss: 0.042306; batch adversarial loss: 0.434783\n",
      "epoch 180; iter: 0; batch classifier loss: 0.100427; batch adversarial loss: 0.353316\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013985; batch adversarial loss: 0.413716\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029478; batch adversarial loss: 0.390578\n",
      "epoch 183; iter: 0; batch classifier loss: 0.037833; batch adversarial loss: 0.563087\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017017; batch adversarial loss: 0.510332\n",
      "epoch 185; iter: 0; batch classifier loss: 0.044787; batch adversarial loss: 0.396520\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014879; batch adversarial loss: 0.483388\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008200; batch adversarial loss: 0.398283\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014737; batch adversarial loss: 0.392599\n",
      "epoch 189; iter: 0; batch classifier loss: 0.037453; batch adversarial loss: 0.498024\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008695; batch adversarial loss: 0.489891\n",
      "epoch 191; iter: 0; batch classifier loss: 0.035990; batch adversarial loss: 0.519025\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007223; batch adversarial loss: 0.339657\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004913; batch adversarial loss: 0.462245\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019726; batch adversarial loss: 0.425536\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031825; batch adversarial loss: 0.418076\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019763; batch adversarial loss: 0.408838\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012710; batch adversarial loss: 0.440278\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015916; batch adversarial loss: 0.469675\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023208; batch adversarial loss: 0.517908\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730921; batch adversarial loss: 0.535124\n",
      "epoch 1; iter: 0; batch classifier loss: 0.385115; batch adversarial loss: 0.579250\n",
      "epoch 2; iter: 0; batch classifier loss: 0.376003; batch adversarial loss: 0.564505\n",
      "epoch 3; iter: 0; batch classifier loss: 0.300610; batch adversarial loss: 0.601776\n",
      "epoch 4; iter: 0; batch classifier loss: 0.276570; batch adversarial loss: 0.533711\n",
      "epoch 5; iter: 0; batch classifier loss: 0.355757; batch adversarial loss: 0.566819\n",
      "epoch 6; iter: 0; batch classifier loss: 0.338823; batch adversarial loss: 0.535985\n",
      "epoch 7; iter: 0; batch classifier loss: 0.392243; batch adversarial loss: 0.585303\n",
      "epoch 8; iter: 0; batch classifier loss: 0.294864; batch adversarial loss: 0.562244\n",
      "epoch 9; iter: 0; batch classifier loss: 0.309000; batch adversarial loss: 0.569387\n",
      "epoch 10; iter: 0; batch classifier loss: 0.378087; batch adversarial loss: 0.546926\n",
      "epoch 11; iter: 0; batch classifier loss: 0.427494; batch adversarial loss: 0.546218\n",
      "epoch 12; iter: 0; batch classifier loss: 0.434314; batch adversarial loss: 0.512479\n",
      "epoch 13; iter: 0; batch classifier loss: 0.580646; batch adversarial loss: 0.556676\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477866; batch adversarial loss: 0.532745\n",
      "epoch 15; iter: 0; batch classifier loss: 0.439423; batch adversarial loss: 0.528346\n",
      "epoch 16; iter: 0; batch classifier loss: 0.248186; batch adversarial loss: 0.547191\n",
      "epoch 17; iter: 0; batch classifier loss: 0.276273; batch adversarial loss: 0.407168\n",
      "epoch 18; iter: 0; batch classifier loss: 0.177875; batch adversarial loss: 0.558297\n",
      "epoch 19; iter: 0; batch classifier loss: 0.217360; batch adversarial loss: 0.365941\n",
      "epoch 20; iter: 0; batch classifier loss: 0.182052; batch adversarial loss: 0.493457\n",
      "epoch 21; iter: 0; batch classifier loss: 0.159022; batch adversarial loss: 0.495108\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226708; batch adversarial loss: 0.464121\n",
      "epoch 23; iter: 0; batch classifier loss: 0.170484; batch adversarial loss: 0.414984\n",
      "epoch 24; iter: 0; batch classifier loss: 0.141370; batch adversarial loss: 0.521726\n",
      "epoch 25; iter: 0; batch classifier loss: 0.148047; batch adversarial loss: 0.581676\n",
      "epoch 26; iter: 0; batch classifier loss: 0.192390; batch adversarial loss: 0.462399\n",
      "epoch 27; iter: 0; batch classifier loss: 0.222799; batch adversarial loss: 0.475748\n",
      "epoch 28; iter: 0; batch classifier loss: 0.137162; batch adversarial loss: 0.444553\n",
      "epoch 29; iter: 0; batch classifier loss: 0.180073; batch adversarial loss: 0.430693\n",
      "epoch 30; iter: 0; batch classifier loss: 0.113987; batch adversarial loss: 0.518861\n",
      "epoch 31; iter: 0; batch classifier loss: 0.122578; batch adversarial loss: 0.464746\n",
      "epoch 32; iter: 0; batch classifier loss: 0.101566; batch adversarial loss: 0.495311\n",
      "epoch 33; iter: 0; batch classifier loss: 0.174633; batch adversarial loss: 0.488162\n",
      "epoch 34; iter: 0; batch classifier loss: 0.133524; batch adversarial loss: 0.477889\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125713; batch adversarial loss: 0.445963\n",
      "epoch 36; iter: 0; batch classifier loss: 0.160533; batch adversarial loss: 0.480503\n",
      "epoch 37; iter: 0; batch classifier loss: 0.080205; batch adversarial loss: 0.458841\n",
      "epoch 38; iter: 0; batch classifier loss: 0.100599; batch adversarial loss: 0.475897\n",
      "epoch 39; iter: 0; batch classifier loss: 0.159181; batch adversarial loss: 0.432078\n",
      "epoch 40; iter: 0; batch classifier loss: 0.080288; batch adversarial loss: 0.487864\n",
      "epoch 41; iter: 0; batch classifier loss: 0.115227; batch adversarial loss: 0.418598\n",
      "epoch 42; iter: 0; batch classifier loss: 0.136783; batch adversarial loss: 0.419443\n",
      "epoch 43; iter: 0; batch classifier loss: 0.118217; batch adversarial loss: 0.448129\n",
      "epoch 44; iter: 0; batch classifier loss: 0.120691; batch adversarial loss: 0.453344\n",
      "epoch 45; iter: 0; batch classifier loss: 0.092981; batch adversarial loss: 0.490892\n",
      "epoch 46; iter: 0; batch classifier loss: 0.159176; batch adversarial loss: 0.459473\n",
      "epoch 47; iter: 0; batch classifier loss: 0.152012; batch adversarial loss: 0.324750\n",
      "epoch 48; iter: 0; batch classifier loss: 0.093079; batch adversarial loss: 0.454000\n",
      "epoch 49; iter: 0; batch classifier loss: 0.127530; batch adversarial loss: 0.417721\n",
      "epoch 50; iter: 0; batch classifier loss: 0.130599; batch adversarial loss: 0.481598\n",
      "epoch 51; iter: 0; batch classifier loss: 0.116209; batch adversarial loss: 0.470921\n",
      "epoch 52; iter: 0; batch classifier loss: 0.120029; batch adversarial loss: 0.503186\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098375; batch adversarial loss: 0.498504\n",
      "epoch 54; iter: 0; batch classifier loss: 0.107151; batch adversarial loss: 0.427297\n",
      "epoch 55; iter: 0; batch classifier loss: 0.159785; batch adversarial loss: 0.463762\n",
      "epoch 56; iter: 0; batch classifier loss: 0.080871; batch adversarial loss: 0.460466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57; iter: 0; batch classifier loss: 0.101694; batch adversarial loss: 0.453379\n",
      "epoch 58; iter: 0; batch classifier loss: 0.111086; batch adversarial loss: 0.517241\n",
      "epoch 59; iter: 0; batch classifier loss: 0.071182; batch adversarial loss: 0.443084\n",
      "epoch 60; iter: 0; batch classifier loss: 0.102403; batch adversarial loss: 0.470205\n",
      "epoch 61; iter: 0; batch classifier loss: 0.122586; batch adversarial loss: 0.399459\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092929; batch adversarial loss: 0.415939\n",
      "epoch 63; iter: 0; batch classifier loss: 0.127805; batch adversarial loss: 0.452348\n",
      "epoch 64; iter: 0; batch classifier loss: 0.097748; batch adversarial loss: 0.452502\n",
      "epoch 65; iter: 0; batch classifier loss: 0.093447; batch adversarial loss: 0.473675\n",
      "epoch 66; iter: 0; batch classifier loss: 0.113551; batch adversarial loss: 0.436795\n",
      "epoch 67; iter: 0; batch classifier loss: 0.129792; batch adversarial loss: 0.465915\n",
      "epoch 68; iter: 0; batch classifier loss: 0.095649; batch adversarial loss: 0.330844\n",
      "epoch 69; iter: 0; batch classifier loss: 0.183692; batch adversarial loss: 0.412483\n",
      "epoch 70; iter: 0; batch classifier loss: 0.088216; batch adversarial loss: 0.436414\n",
      "epoch 71; iter: 0; batch classifier loss: 0.131459; batch adversarial loss: 0.374336\n",
      "epoch 72; iter: 0; batch classifier loss: 0.070194; batch adversarial loss: 0.457963\n",
      "epoch 73; iter: 0; batch classifier loss: 0.087471; batch adversarial loss: 0.405370\n",
      "epoch 74; iter: 0; batch classifier loss: 0.166842; batch adversarial loss: 0.416367\n",
      "epoch 75; iter: 0; batch classifier loss: 0.109259; batch adversarial loss: 0.500296\n",
      "epoch 76; iter: 0; batch classifier loss: 0.138213; batch adversarial loss: 0.481991\n",
      "epoch 77; iter: 0; batch classifier loss: 0.093847; batch adversarial loss: 0.463780\n",
      "epoch 78; iter: 0; batch classifier loss: 0.125111; batch adversarial loss: 0.424578\n",
      "epoch 79; iter: 0; batch classifier loss: 0.096543; batch adversarial loss: 0.420358\n",
      "epoch 80; iter: 0; batch classifier loss: 0.124954; batch adversarial loss: 0.521104\n",
      "epoch 81; iter: 0; batch classifier loss: 0.116433; batch adversarial loss: 0.470270\n",
      "epoch 82; iter: 0; batch classifier loss: 0.103145; batch adversarial loss: 0.500433\n",
      "epoch 83; iter: 0; batch classifier loss: 0.075563; batch adversarial loss: 0.435467\n",
      "epoch 84; iter: 0; batch classifier loss: 0.103283; batch adversarial loss: 0.504361\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064689; batch adversarial loss: 0.449760\n",
      "epoch 86; iter: 0; batch classifier loss: 0.079093; batch adversarial loss: 0.487003\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066914; batch adversarial loss: 0.408367\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055321; batch adversarial loss: 0.522446\n",
      "epoch 89; iter: 0; batch classifier loss: 0.082653; batch adversarial loss: 0.422757\n",
      "epoch 90; iter: 0; batch classifier loss: 0.083986; batch adversarial loss: 0.524519\n",
      "epoch 91; iter: 0; batch classifier loss: 0.081253; batch adversarial loss: 0.455347\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065004; batch adversarial loss: 0.448122\n",
      "epoch 93; iter: 0; batch classifier loss: 0.122343; batch adversarial loss: 0.454106\n",
      "epoch 94; iter: 0; batch classifier loss: 0.092673; batch adversarial loss: 0.424903\n",
      "epoch 95; iter: 0; batch classifier loss: 0.099049; batch adversarial loss: 0.457813\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096050; batch adversarial loss: 0.431908\n",
      "epoch 97; iter: 0; batch classifier loss: 0.112560; batch adversarial loss: 0.522389\n",
      "epoch 98; iter: 0; batch classifier loss: 0.087717; batch adversarial loss: 0.458872\n",
      "epoch 99; iter: 0; batch classifier loss: 0.085575; batch adversarial loss: 0.439998\n",
      "epoch 100; iter: 0; batch classifier loss: 0.072553; batch adversarial loss: 0.486753\n",
      "epoch 101; iter: 0; batch classifier loss: 0.100130; batch adversarial loss: 0.502612\n",
      "epoch 102; iter: 0; batch classifier loss: 0.087781; batch adversarial loss: 0.499080\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037712; batch adversarial loss: 0.463523\n",
      "epoch 104; iter: 0; batch classifier loss: 0.068923; batch adversarial loss: 0.443800\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066865; batch adversarial loss: 0.460467\n",
      "epoch 106; iter: 0; batch classifier loss: 0.082065; batch adversarial loss: 0.525362\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052185; batch adversarial loss: 0.394038\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046380; batch adversarial loss: 0.395137\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058351; batch adversarial loss: 0.511256\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037856; batch adversarial loss: 0.521880\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058058; batch adversarial loss: 0.434047\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075525; batch adversarial loss: 0.499170\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045112; batch adversarial loss: 0.512050\n",
      "epoch 114; iter: 0; batch classifier loss: 0.070882; batch adversarial loss: 0.559235\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060922; batch adversarial loss: 0.403778\n",
      "epoch 116; iter: 0; batch classifier loss: 0.066882; batch adversarial loss: 0.420952\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044909; batch adversarial loss: 0.527492\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037463; batch adversarial loss: 0.617165\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048882; batch adversarial loss: 0.462023\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037235; batch adversarial loss: 0.416611\n",
      "epoch 121; iter: 0; batch classifier loss: 0.067058; batch adversarial loss: 0.487403\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028405; batch adversarial loss: 0.560216\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045981; batch adversarial loss: 0.531515\n",
      "epoch 124; iter: 0; batch classifier loss: 0.061263; batch adversarial loss: 0.458637\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039074; batch adversarial loss: 0.491621\n",
      "epoch 126; iter: 0; batch classifier loss: 0.062200; batch adversarial loss: 0.376218\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042035; batch adversarial loss: 0.528550\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034312; batch adversarial loss: 0.449344\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045671; batch adversarial loss: 0.495741\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046114; batch adversarial loss: 0.478583\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020744; batch adversarial loss: 0.457377\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045309; batch adversarial loss: 0.411692\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038290; batch adversarial loss: 0.502382\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025133; batch adversarial loss: 0.469998\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028584; batch adversarial loss: 0.491958\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033086; batch adversarial loss: 0.472202\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022794; batch adversarial loss: 0.453299\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037095; batch adversarial loss: 0.414931\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029867; batch adversarial loss: 0.519238\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034610; batch adversarial loss: 0.365315\n",
      "epoch 141; iter: 0; batch classifier loss: 0.050060; batch adversarial loss: 0.486898\n",
      "epoch 142; iter: 0; batch classifier loss: 0.015160; batch adversarial loss: 0.462505\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034248; batch adversarial loss: 0.495669\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033719; batch adversarial loss: 0.460598\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019891; batch adversarial loss: 0.477548\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030260; batch adversarial loss: 0.479618\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043546; batch adversarial loss: 0.407480\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032821; batch adversarial loss: 0.440503\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019954; batch adversarial loss: 0.399214\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023829; batch adversarial loss: 0.426065\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041563; batch adversarial loss: 0.435484\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034101; batch adversarial loss: 0.432602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 153; iter: 0; batch classifier loss: 0.026364; batch adversarial loss: 0.440799\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030372; batch adversarial loss: 0.482135\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044695; batch adversarial loss: 0.475253\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030724; batch adversarial loss: 0.414909\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030088; batch adversarial loss: 0.403809\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036656; batch adversarial loss: 0.446685\n",
      "epoch 159; iter: 0; batch classifier loss: 0.059844; batch adversarial loss: 0.469069\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024130; batch adversarial loss: 0.566253\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014424; batch adversarial loss: 0.525818\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012867; batch adversarial loss: 0.548341\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012097; batch adversarial loss: 0.493839\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031980; batch adversarial loss: 0.440597\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029281; batch adversarial loss: 0.510957\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017023; batch adversarial loss: 0.487328\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012911; batch adversarial loss: 0.413239\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031961; batch adversarial loss: 0.530308\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016376; batch adversarial loss: 0.425909\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017499; batch adversarial loss: 0.584171\n",
      "epoch 171; iter: 0; batch classifier loss: 0.050849; batch adversarial loss: 0.414640\n",
      "epoch 172; iter: 0; batch classifier loss: 0.047610; batch adversarial loss: 0.507990\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007854; batch adversarial loss: 0.452752\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024267; batch adversarial loss: 0.471020\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006359; batch adversarial loss: 0.451991\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019260; batch adversarial loss: 0.524536\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031008; batch adversarial loss: 0.492923\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037994; batch adversarial loss: 0.449169\n",
      "epoch 179; iter: 0; batch classifier loss: 0.003774; batch adversarial loss: 0.448120\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011079; batch adversarial loss: 0.429198\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016315; batch adversarial loss: 0.462447\n",
      "epoch 182; iter: 0; batch classifier loss: 0.049160; batch adversarial loss: 0.414515\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024016; batch adversarial loss: 0.478907\n",
      "epoch 184; iter: 0; batch classifier loss: 0.044845; batch adversarial loss: 0.479664\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027660; batch adversarial loss: 0.448831\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010002; batch adversarial loss: 0.387031\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008553; batch adversarial loss: 0.436443\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017601; batch adversarial loss: 0.511116\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014131; batch adversarial loss: 0.480992\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012540; batch adversarial loss: 0.440881\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026978; batch adversarial loss: 0.527883\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005266; batch adversarial loss: 0.508583\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012971; batch adversarial loss: 0.466065\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009113; batch adversarial loss: 0.519280\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005943; batch adversarial loss: 0.416595\n",
      "epoch 196; iter: 0; batch classifier loss: 0.003604; batch adversarial loss: 0.500824\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022056; batch adversarial loss: 0.441249\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012658; batch adversarial loss: 0.475965\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014384; batch adversarial loss: 0.358288\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670846; batch adversarial loss: 0.703249\n",
      "epoch 1; iter: 0; batch classifier loss: 0.522094; batch adversarial loss: 0.644525\n",
      "epoch 2; iter: 0; batch classifier loss: 0.407300; batch adversarial loss: 0.630847\n",
      "epoch 3; iter: 0; batch classifier loss: 0.476468; batch adversarial loss: 0.622631\n",
      "epoch 4; iter: 0; batch classifier loss: 0.490535; batch adversarial loss: 0.602004\n",
      "epoch 5; iter: 0; batch classifier loss: 0.356133; batch adversarial loss: 0.599676\n",
      "epoch 6; iter: 0; batch classifier loss: 0.396612; batch adversarial loss: 0.563621\n",
      "epoch 7; iter: 0; batch classifier loss: 0.357895; batch adversarial loss: 0.585143\n",
      "epoch 8; iter: 0; batch classifier loss: 0.383405; batch adversarial loss: 0.540197\n",
      "epoch 9; iter: 0; batch classifier loss: 0.383759; batch adversarial loss: 0.569011\n",
      "epoch 10; iter: 0; batch classifier loss: 0.378080; batch adversarial loss: 0.513914\n",
      "epoch 11; iter: 0; batch classifier loss: 0.437658; batch adversarial loss: 0.534393\n",
      "epoch 12; iter: 0; batch classifier loss: 0.412074; batch adversarial loss: 0.510371\n",
      "epoch 13; iter: 0; batch classifier loss: 0.473005; batch adversarial loss: 0.494803\n",
      "epoch 14; iter: 0; batch classifier loss: 0.327092; batch adversarial loss: 0.466617\n",
      "epoch 15; iter: 0; batch classifier loss: 0.279016; batch adversarial loss: 0.583663\n",
      "epoch 16; iter: 0; batch classifier loss: 0.337515; batch adversarial loss: 0.484610\n",
      "epoch 17; iter: 0; batch classifier loss: 0.299181; batch adversarial loss: 0.521514\n",
      "epoch 18; iter: 0; batch classifier loss: 0.349310; batch adversarial loss: 0.482693\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261077; batch adversarial loss: 0.550069\n",
      "epoch 20; iter: 0; batch classifier loss: 0.299092; batch adversarial loss: 0.484022\n",
      "epoch 21; iter: 0; batch classifier loss: 0.334781; batch adversarial loss: 0.479635\n",
      "epoch 22; iter: 0; batch classifier loss: 0.267457; batch adversarial loss: 0.493181\n",
      "epoch 23; iter: 0; batch classifier loss: 0.308527; batch adversarial loss: 0.436983\n",
      "epoch 24; iter: 0; batch classifier loss: 0.292042; batch adversarial loss: 0.417622\n",
      "epoch 25; iter: 0; batch classifier loss: 0.264140; batch adversarial loss: 0.451184\n",
      "epoch 26; iter: 0; batch classifier loss: 0.232144; batch adversarial loss: 0.433351\n",
      "epoch 27; iter: 0; batch classifier loss: 0.276559; batch adversarial loss: 0.427210\n",
      "epoch 28; iter: 0; batch classifier loss: 0.337717; batch adversarial loss: 0.596058\n",
      "epoch 29; iter: 0; batch classifier loss: 0.250287; batch adversarial loss: 0.474938\n",
      "epoch 30; iter: 0; batch classifier loss: 0.232250; batch adversarial loss: 0.477109\n",
      "epoch 31; iter: 0; batch classifier loss: 0.274608; batch adversarial loss: 0.540475\n",
      "epoch 32; iter: 0; batch classifier loss: 0.230807; batch adversarial loss: 0.560708\n",
      "epoch 33; iter: 0; batch classifier loss: 0.231392; batch adversarial loss: 0.505342\n",
      "epoch 34; iter: 0; batch classifier loss: 0.329191; batch adversarial loss: 0.479349\n",
      "epoch 35; iter: 0; batch classifier loss: 0.294448; batch adversarial loss: 0.408100\n",
      "epoch 36; iter: 0; batch classifier loss: 0.288369; batch adversarial loss: 0.471384\n",
      "epoch 37; iter: 0; batch classifier loss: 0.259514; batch adversarial loss: 0.396651\n",
      "epoch 38; iter: 0; batch classifier loss: 0.237771; batch adversarial loss: 0.449106\n",
      "epoch 39; iter: 0; batch classifier loss: 0.272709; batch adversarial loss: 0.417703\n",
      "epoch 40; iter: 0; batch classifier loss: 0.255936; batch adversarial loss: 0.461226\n",
      "epoch 41; iter: 0; batch classifier loss: 0.222064; batch adversarial loss: 0.494880\n",
      "epoch 42; iter: 0; batch classifier loss: 0.222267; batch adversarial loss: 0.514874\n",
      "epoch 43; iter: 0; batch classifier loss: 0.198321; batch adversarial loss: 0.401632\n",
      "epoch 44; iter: 0; batch classifier loss: 0.244243; batch adversarial loss: 0.459685\n",
      "epoch 45; iter: 0; batch classifier loss: 0.200052; batch adversarial loss: 0.484181\n",
      "epoch 46; iter: 0; batch classifier loss: 0.184474; batch adversarial loss: 0.540978\n",
      "epoch 47; iter: 0; batch classifier loss: 0.296936; batch adversarial loss: 0.423731\n",
      "epoch 48; iter: 0; batch classifier loss: 0.173726; batch adversarial loss: 0.471877\n",
      "epoch 49; iter: 0; batch classifier loss: 0.263264; batch adversarial loss: 0.424269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.148536; batch adversarial loss: 0.447258\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073141; batch adversarial loss: 0.468836\n",
      "epoch 52; iter: 0; batch classifier loss: 0.086735; batch adversarial loss: 0.345237\n",
      "epoch 53; iter: 0; batch classifier loss: 0.086276; batch adversarial loss: 0.430237\n",
      "epoch 54; iter: 0; batch classifier loss: 0.126352; batch adversarial loss: 0.435638\n",
      "epoch 55; iter: 0; batch classifier loss: 0.060279; batch adversarial loss: 0.464070\n",
      "epoch 56; iter: 0; batch classifier loss: 0.161570; batch adversarial loss: 0.434379\n",
      "epoch 57; iter: 0; batch classifier loss: 0.167053; batch adversarial loss: 0.519567\n",
      "epoch 58; iter: 0; batch classifier loss: 0.159557; batch adversarial loss: 0.490187\n",
      "epoch 59; iter: 0; batch classifier loss: 0.140594; batch adversarial loss: 0.413166\n",
      "epoch 60; iter: 0; batch classifier loss: 0.139698; batch adversarial loss: 0.463507\n",
      "epoch 61; iter: 0; batch classifier loss: 0.111117; batch adversarial loss: 0.470397\n",
      "epoch 62; iter: 0; batch classifier loss: 0.119464; batch adversarial loss: 0.418757\n",
      "epoch 63; iter: 0; batch classifier loss: 0.124538; batch adversarial loss: 0.468983\n",
      "epoch 64; iter: 0; batch classifier loss: 0.199767; batch adversarial loss: 0.460435\n",
      "epoch 65; iter: 0; batch classifier loss: 0.133807; batch adversarial loss: 0.520528\n",
      "epoch 66; iter: 0; batch classifier loss: 0.169356; batch adversarial loss: 0.520949\n",
      "epoch 67; iter: 0; batch classifier loss: 0.147209; batch adversarial loss: 0.411551\n",
      "epoch 68; iter: 0; batch classifier loss: 0.163004; batch adversarial loss: 0.481015\n",
      "epoch 69; iter: 0; batch classifier loss: 0.154687; batch adversarial loss: 0.489738\n",
      "epoch 70; iter: 0; batch classifier loss: 0.151248; batch adversarial loss: 0.470484\n",
      "epoch 71; iter: 0; batch classifier loss: 0.127533; batch adversarial loss: 0.406062\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064898; batch adversarial loss: 0.476428\n",
      "epoch 73; iter: 0; batch classifier loss: 0.096345; batch adversarial loss: 0.502424\n",
      "epoch 74; iter: 0; batch classifier loss: 0.118882; batch adversarial loss: 0.454738\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077249; batch adversarial loss: 0.533619\n",
      "epoch 76; iter: 0; batch classifier loss: 0.050978; batch adversarial loss: 0.427123\n",
      "epoch 77; iter: 0; batch classifier loss: 0.058239; batch adversarial loss: 0.420137\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064299; batch adversarial loss: 0.504975\n",
      "epoch 79; iter: 0; batch classifier loss: 0.079230; batch adversarial loss: 0.414646\n",
      "epoch 80; iter: 0; batch classifier loss: 0.100101; batch adversarial loss: 0.411909\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066271; batch adversarial loss: 0.358931\n",
      "epoch 82; iter: 0; batch classifier loss: 0.087684; batch adversarial loss: 0.404165\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068928; batch adversarial loss: 0.474011\n",
      "epoch 84; iter: 0; batch classifier loss: 0.061554; batch adversarial loss: 0.515656\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061069; batch adversarial loss: 0.441195\n",
      "epoch 86; iter: 0; batch classifier loss: 0.059113; batch adversarial loss: 0.558706\n",
      "epoch 87; iter: 0; batch classifier loss: 0.081449; batch adversarial loss: 0.432618\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064214; batch adversarial loss: 0.465450\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066304; batch adversarial loss: 0.442399\n",
      "epoch 90; iter: 0; batch classifier loss: 0.079688; batch adversarial loss: 0.478843\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067305; batch adversarial loss: 0.452568\n",
      "epoch 92; iter: 0; batch classifier loss: 0.036400; batch adversarial loss: 0.499158\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069864; batch adversarial loss: 0.431420\n",
      "epoch 94; iter: 0; batch classifier loss: 0.035741; batch adversarial loss: 0.383688\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038749; batch adversarial loss: 0.461206\n",
      "epoch 96; iter: 0; batch classifier loss: 0.052966; batch adversarial loss: 0.403395\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047628; batch adversarial loss: 0.449856\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061460; batch adversarial loss: 0.506310\n",
      "epoch 99; iter: 0; batch classifier loss: 0.025941; batch adversarial loss: 0.424486\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057259; batch adversarial loss: 0.414474\n",
      "epoch 101; iter: 0; batch classifier loss: 0.038352; batch adversarial loss: 0.445734\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057500; batch adversarial loss: 0.465715\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035793; batch adversarial loss: 0.442519\n",
      "epoch 104; iter: 0; batch classifier loss: 0.030967; batch adversarial loss: 0.459613\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043139; batch adversarial loss: 0.401749\n",
      "epoch 106; iter: 0; batch classifier loss: 0.061657; batch adversarial loss: 0.429767\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044413; batch adversarial loss: 0.463356\n",
      "epoch 108; iter: 0; batch classifier loss: 0.024854; batch adversarial loss: 0.486491\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042945; batch adversarial loss: 0.385090\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028720; batch adversarial loss: 0.498151\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028951; batch adversarial loss: 0.524389\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047589; batch adversarial loss: 0.483732\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038194; batch adversarial loss: 0.461164\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047747; batch adversarial loss: 0.418294\n",
      "epoch 115; iter: 0; batch classifier loss: 0.026405; batch adversarial loss: 0.422806\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040397; batch adversarial loss: 0.359602\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037655; batch adversarial loss: 0.550097\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031600; batch adversarial loss: 0.482732\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049607; batch adversarial loss: 0.432628\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047904; batch adversarial loss: 0.411017\n",
      "epoch 121; iter: 0; batch classifier loss: 0.014055; batch adversarial loss: 0.568185\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034142; batch adversarial loss: 0.438322\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064335; batch adversarial loss: 0.427428\n",
      "epoch 124; iter: 0; batch classifier loss: 0.017800; batch adversarial loss: 0.538939\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037857; batch adversarial loss: 0.506698\n",
      "epoch 126; iter: 0; batch classifier loss: 0.020099; batch adversarial loss: 0.489861\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046075; batch adversarial loss: 0.544620\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027454; batch adversarial loss: 0.422670\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020010; batch adversarial loss: 0.451197\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027000; batch adversarial loss: 0.425182\n",
      "epoch 131; iter: 0; batch classifier loss: 0.010375; batch adversarial loss: 0.445909\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023972; batch adversarial loss: 0.344445\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039265; batch adversarial loss: 0.521637\n",
      "epoch 134; iter: 0; batch classifier loss: 0.011867; batch adversarial loss: 0.451925\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024642; batch adversarial loss: 0.437326\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028216; batch adversarial loss: 0.574299\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023731; batch adversarial loss: 0.473927\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017330; batch adversarial loss: 0.456280\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046179; batch adversarial loss: 0.369681\n",
      "epoch 140; iter: 0; batch classifier loss: 0.010257; batch adversarial loss: 0.485029\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044598; batch adversarial loss: 0.359783\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031840; batch adversarial loss: 0.583283\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042799; batch adversarial loss: 0.399175\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014704; batch adversarial loss: 0.418316\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045063; batch adversarial loss: 0.451609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.025498; batch adversarial loss: 0.582531\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022161; batch adversarial loss: 0.537577\n",
      "epoch 148; iter: 0; batch classifier loss: 0.010554; batch adversarial loss: 0.459905\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029788; batch adversarial loss: 0.491881\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024530; batch adversarial loss: 0.426572\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019498; batch adversarial loss: 0.435853\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034714; batch adversarial loss: 0.495691\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032016; batch adversarial loss: 0.412175\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024259; batch adversarial loss: 0.520015\n",
      "epoch 155; iter: 0; batch classifier loss: 0.007386; batch adversarial loss: 0.464662\n",
      "epoch 156; iter: 0; batch classifier loss: 0.009911; batch adversarial loss: 0.419166\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029948; batch adversarial loss: 0.524511\n",
      "epoch 158; iter: 0; batch classifier loss: 0.006644; batch adversarial loss: 0.416928\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018963; batch adversarial loss: 0.473408\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026275; batch adversarial loss: 0.458904\n",
      "epoch 161; iter: 0; batch classifier loss: 0.045247; batch adversarial loss: 0.469779\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022414; batch adversarial loss: 0.427056\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017575; batch adversarial loss: 0.450270\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013807; batch adversarial loss: 0.491467\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011894; batch adversarial loss: 0.452604\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012166; batch adversarial loss: 0.383919\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010597; batch adversarial loss: 0.493933\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035860; batch adversarial loss: 0.428931\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015672; batch adversarial loss: 0.437404\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011873; batch adversarial loss: 0.488809\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024223; batch adversarial loss: 0.448886\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014553; batch adversarial loss: 0.499037\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027909; batch adversarial loss: 0.525570\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018754; batch adversarial loss: 0.474982\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025430; batch adversarial loss: 0.471075\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018077; batch adversarial loss: 0.503421\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009820; batch adversarial loss: 0.400845\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019675; batch adversarial loss: 0.404055\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023047; batch adversarial loss: 0.437350\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006008; batch adversarial loss: 0.444691\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007692; batch adversarial loss: 0.476687\n",
      "epoch 182; iter: 0; batch classifier loss: 0.002524; batch adversarial loss: 0.501196\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024753; batch adversarial loss: 0.518917\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016835; batch adversarial loss: 0.407033\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010742; batch adversarial loss: 0.487381\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007527; batch adversarial loss: 0.457684\n",
      "epoch 187; iter: 0; batch classifier loss: 0.003757; batch adversarial loss: 0.477849\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018180; batch adversarial loss: 0.471155\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033587; batch adversarial loss: 0.453341\n",
      "epoch 190; iter: 0; batch classifier loss: 0.003025; batch adversarial loss: 0.521062\n",
      "epoch 191; iter: 0; batch classifier loss: 0.041016; batch adversarial loss: 0.489201\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015931; batch adversarial loss: 0.400561\n",
      "epoch 193; iter: 0; batch classifier loss: 0.036012; batch adversarial loss: 0.376201\n",
      "epoch 194; iter: 0; batch classifier loss: 0.037549; batch adversarial loss: 0.440050\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008587; batch adversarial loss: 0.404350\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027163; batch adversarial loss: 0.493387\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008396; batch adversarial loss: 0.422913\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017137; batch adversarial loss: 0.534212\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028644; batch adversarial loss: 0.480081\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698830; batch adversarial loss: 0.932012\n",
      "epoch 1; iter: 0; batch classifier loss: 0.614047; batch adversarial loss: 1.015145\n",
      "epoch 2; iter: 0; batch classifier loss: 0.950794; batch adversarial loss: 1.065155\n",
      "epoch 3; iter: 0; batch classifier loss: 1.053366; batch adversarial loss: 0.965666\n",
      "epoch 4; iter: 0; batch classifier loss: 1.001348; batch adversarial loss: 0.866037\n",
      "epoch 5; iter: 0; batch classifier loss: 1.066958; batch adversarial loss: 0.790629\n",
      "epoch 6; iter: 0; batch classifier loss: 1.078020; batch adversarial loss: 0.737957\n",
      "epoch 7; iter: 0; batch classifier loss: 0.945999; batch adversarial loss: 0.659641\n",
      "epoch 8; iter: 0; batch classifier loss: 0.730699; batch adversarial loss: 0.590636\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532813; batch adversarial loss: 0.573905\n",
      "epoch 10; iter: 0; batch classifier loss: 0.458664; batch adversarial loss: 0.512821\n",
      "epoch 11; iter: 0; batch classifier loss: 0.305660; batch adversarial loss: 0.540340\n",
      "epoch 12; iter: 0; batch classifier loss: 0.286606; batch adversarial loss: 0.526524\n",
      "epoch 13; iter: 0; batch classifier loss: 0.290239; batch adversarial loss: 0.478521\n",
      "epoch 14; iter: 0; batch classifier loss: 0.370614; batch adversarial loss: 0.507320\n",
      "epoch 15; iter: 0; batch classifier loss: 0.293203; batch adversarial loss: 0.509253\n",
      "epoch 16; iter: 0; batch classifier loss: 0.238124; batch adversarial loss: 0.489309\n",
      "epoch 17; iter: 0; batch classifier loss: 0.353944; batch adversarial loss: 0.510815\n",
      "epoch 18; iter: 0; batch classifier loss: 0.258120; batch adversarial loss: 0.473765\n",
      "epoch 19; iter: 0; batch classifier loss: 0.240688; batch adversarial loss: 0.488232\n",
      "epoch 20; iter: 0; batch classifier loss: 0.227453; batch adversarial loss: 0.451118\n",
      "epoch 21; iter: 0; batch classifier loss: 0.183528; batch adversarial loss: 0.464155\n",
      "epoch 22; iter: 0; batch classifier loss: 0.321268; batch adversarial loss: 0.479817\n",
      "epoch 23; iter: 0; batch classifier loss: 0.200050; batch adversarial loss: 0.515068\n",
      "epoch 24; iter: 0; batch classifier loss: 0.224120; batch adversarial loss: 0.464618\n",
      "epoch 25; iter: 0; batch classifier loss: 0.189317; batch adversarial loss: 0.547213\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180502; batch adversarial loss: 0.489173\n",
      "epoch 27; iter: 0; batch classifier loss: 0.259191; batch adversarial loss: 0.404135\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185702; batch adversarial loss: 0.480038\n",
      "epoch 29; iter: 0; batch classifier loss: 0.243381; batch adversarial loss: 0.464064\n",
      "epoch 30; iter: 0; batch classifier loss: 0.279656; batch adversarial loss: 0.444268\n",
      "epoch 31; iter: 0; batch classifier loss: 0.232709; batch adversarial loss: 0.404924\n",
      "epoch 32; iter: 0; batch classifier loss: 0.196411; batch adversarial loss: 0.405827\n",
      "epoch 33; iter: 0; batch classifier loss: 0.226549; batch adversarial loss: 0.510940\n",
      "epoch 34; iter: 0; batch classifier loss: 0.199182; batch adversarial loss: 0.465200\n",
      "epoch 35; iter: 0; batch classifier loss: 0.183393; batch adversarial loss: 0.476130\n",
      "epoch 36; iter: 0; batch classifier loss: 0.179079; batch adversarial loss: 0.435182\n",
      "epoch 37; iter: 0; batch classifier loss: 0.191402; batch adversarial loss: 0.468682\n",
      "epoch 38; iter: 0; batch classifier loss: 0.177313; batch adversarial loss: 0.472273\n",
      "epoch 39; iter: 0; batch classifier loss: 0.170425; batch adversarial loss: 0.536989\n",
      "epoch 40; iter: 0; batch classifier loss: 0.218554; batch adversarial loss: 0.406930\n",
      "epoch 41; iter: 0; batch classifier loss: 0.227779; batch adversarial loss: 0.491125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.172153; batch adversarial loss: 0.422474\n",
      "epoch 43; iter: 0; batch classifier loss: 0.116943; batch adversarial loss: 0.500489\n",
      "epoch 44; iter: 0; batch classifier loss: 0.222280; batch adversarial loss: 0.430113\n",
      "epoch 45; iter: 0; batch classifier loss: 0.208298; batch adversarial loss: 0.406766\n",
      "epoch 46; iter: 0; batch classifier loss: 0.207242; batch adversarial loss: 0.386235\n",
      "epoch 47; iter: 0; batch classifier loss: 0.168936; batch adversarial loss: 0.433466\n",
      "epoch 48; iter: 0; batch classifier loss: 0.120849; batch adversarial loss: 0.428641\n",
      "epoch 49; iter: 0; batch classifier loss: 0.185196; batch adversarial loss: 0.400289\n",
      "epoch 50; iter: 0; batch classifier loss: 0.131049; batch adversarial loss: 0.511389\n",
      "epoch 51; iter: 0; batch classifier loss: 0.181543; batch adversarial loss: 0.433152\n",
      "epoch 52; iter: 0; batch classifier loss: 0.136947; batch adversarial loss: 0.392439\n",
      "epoch 53; iter: 0; batch classifier loss: 0.148798; batch adversarial loss: 0.462459\n",
      "epoch 54; iter: 0; batch classifier loss: 0.150827; batch adversarial loss: 0.425584\n",
      "epoch 55; iter: 0; batch classifier loss: 0.161174; batch adversarial loss: 0.379229\n",
      "epoch 56; iter: 0; batch classifier loss: 0.124563; batch adversarial loss: 0.477399\n",
      "epoch 57; iter: 0; batch classifier loss: 0.171877; batch adversarial loss: 0.457512\n",
      "epoch 58; iter: 0; batch classifier loss: 0.131235; batch adversarial loss: 0.474361\n",
      "epoch 59; iter: 0; batch classifier loss: 0.139995; batch adversarial loss: 0.482445\n",
      "epoch 60; iter: 0; batch classifier loss: 0.129340; batch adversarial loss: 0.445458\n",
      "epoch 61; iter: 0; batch classifier loss: 0.157192; batch adversarial loss: 0.453441\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090967; batch adversarial loss: 0.501537\n",
      "epoch 63; iter: 0; batch classifier loss: 0.168346; batch adversarial loss: 0.378551\n",
      "epoch 64; iter: 0; batch classifier loss: 0.162106; batch adversarial loss: 0.402261\n",
      "epoch 65; iter: 0; batch classifier loss: 0.116383; batch adversarial loss: 0.466075\n",
      "epoch 66; iter: 0; batch classifier loss: 0.133269; batch adversarial loss: 0.437807\n",
      "epoch 67; iter: 0; batch classifier loss: 0.126847; batch adversarial loss: 0.441183\n",
      "epoch 68; iter: 0; batch classifier loss: 0.111677; batch adversarial loss: 0.475065\n",
      "epoch 69; iter: 0; batch classifier loss: 0.120299; batch adversarial loss: 0.510955\n",
      "epoch 70; iter: 0; batch classifier loss: 0.084405; batch adversarial loss: 0.427231\n",
      "epoch 71; iter: 0; batch classifier loss: 0.117393; batch adversarial loss: 0.440496\n",
      "epoch 72; iter: 0; batch classifier loss: 0.153951; batch adversarial loss: 0.400759\n",
      "epoch 73; iter: 0; batch classifier loss: 0.148964; batch adversarial loss: 0.384824\n",
      "epoch 74; iter: 0; batch classifier loss: 0.097215; batch adversarial loss: 0.392142\n",
      "epoch 75; iter: 0; batch classifier loss: 0.090920; batch adversarial loss: 0.426174\n",
      "epoch 76; iter: 0; batch classifier loss: 0.158805; batch adversarial loss: 0.435755\n",
      "epoch 77; iter: 0; batch classifier loss: 0.107294; batch adversarial loss: 0.454418\n",
      "epoch 78; iter: 0; batch classifier loss: 0.065305; batch adversarial loss: 0.537668\n",
      "epoch 79; iter: 0; batch classifier loss: 0.112822; batch adversarial loss: 0.484368\n",
      "epoch 80; iter: 0; batch classifier loss: 0.107139; batch adversarial loss: 0.400468\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120650; batch adversarial loss: 0.500474\n",
      "epoch 82; iter: 0; batch classifier loss: 0.108359; batch adversarial loss: 0.397602\n",
      "epoch 83; iter: 0; batch classifier loss: 0.110938; batch adversarial loss: 0.354924\n",
      "epoch 84; iter: 0; batch classifier loss: 0.113649; batch adversarial loss: 0.451680\n",
      "epoch 85; iter: 0; batch classifier loss: 0.122222; batch adversarial loss: 0.432727\n",
      "epoch 86; iter: 0; batch classifier loss: 0.094314; batch adversarial loss: 0.352699\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071700; batch adversarial loss: 0.446552\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062967; batch adversarial loss: 0.413991\n",
      "epoch 89; iter: 0; batch classifier loss: 0.128052; batch adversarial loss: 0.407649\n",
      "epoch 90; iter: 0; batch classifier loss: 0.133993; batch adversarial loss: 0.511845\n",
      "epoch 91; iter: 0; batch classifier loss: 0.091056; batch adversarial loss: 0.399969\n",
      "epoch 92; iter: 0; batch classifier loss: 0.111132; batch adversarial loss: 0.389048\n",
      "epoch 93; iter: 0; batch classifier loss: 0.101765; batch adversarial loss: 0.459739\n",
      "epoch 94; iter: 0; batch classifier loss: 0.116069; batch adversarial loss: 0.432906\n",
      "epoch 95; iter: 0; batch classifier loss: 0.104802; batch adversarial loss: 0.382569\n",
      "epoch 96; iter: 0; batch classifier loss: 0.099600; batch adversarial loss: 0.377917\n",
      "epoch 97; iter: 0; batch classifier loss: 0.100716; batch adversarial loss: 0.406141\n",
      "epoch 98; iter: 0; batch classifier loss: 0.073248; batch adversarial loss: 0.447453\n",
      "epoch 99; iter: 0; batch classifier loss: 0.085319; batch adversarial loss: 0.391023\n",
      "epoch 100; iter: 0; batch classifier loss: 0.172615; batch adversarial loss: 0.407508\n",
      "epoch 101; iter: 0; batch classifier loss: 0.080254; batch adversarial loss: 0.432700\n",
      "epoch 102; iter: 0; batch classifier loss: 0.112254; batch adversarial loss: 0.420696\n",
      "epoch 103; iter: 0; batch classifier loss: 0.124579; batch adversarial loss: 0.497081\n",
      "epoch 104; iter: 0; batch classifier loss: 0.055810; batch adversarial loss: 0.468090\n",
      "epoch 105; iter: 0; batch classifier loss: 0.072782; batch adversarial loss: 0.402806\n",
      "epoch 106; iter: 0; batch classifier loss: 0.105138; batch adversarial loss: 0.426705\n",
      "epoch 107; iter: 0; batch classifier loss: 0.070754; batch adversarial loss: 0.563935\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046936; batch adversarial loss: 0.539883\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062458; batch adversarial loss: 0.449024\n",
      "epoch 110; iter: 0; batch classifier loss: 0.079969; batch adversarial loss: 0.437844\n",
      "epoch 111; iter: 0; batch classifier loss: 0.092119; batch adversarial loss: 0.421839\n",
      "epoch 112; iter: 0; batch classifier loss: 0.104779; batch adversarial loss: 0.431193\n",
      "epoch 113; iter: 0; batch classifier loss: 0.061478; batch adversarial loss: 0.422143\n",
      "epoch 114; iter: 0; batch classifier loss: 0.117412; batch adversarial loss: 0.462223\n",
      "epoch 115; iter: 0; batch classifier loss: 0.061337; batch adversarial loss: 0.475524\n",
      "epoch 116; iter: 0; batch classifier loss: 0.118747; batch adversarial loss: 0.448436\n",
      "epoch 117; iter: 0; batch classifier loss: 0.075144; batch adversarial loss: 0.458483\n",
      "epoch 118; iter: 0; batch classifier loss: 0.075374; batch adversarial loss: 0.386158\n",
      "epoch 119; iter: 0; batch classifier loss: 0.105532; batch adversarial loss: 0.436653\n",
      "epoch 120; iter: 0; batch classifier loss: 0.102479; batch adversarial loss: 0.490301\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052999; batch adversarial loss: 0.431840\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052251; batch adversarial loss: 0.416859\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040488; batch adversarial loss: 0.464527\n",
      "epoch 124; iter: 0; batch classifier loss: 0.060530; batch adversarial loss: 0.465566\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034562; batch adversarial loss: 0.365904\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040993; batch adversarial loss: 0.461079\n",
      "epoch 127; iter: 0; batch classifier loss: 0.052932; batch adversarial loss: 0.437414\n",
      "epoch 128; iter: 0; batch classifier loss: 0.115377; batch adversarial loss: 0.464904\n",
      "epoch 129; iter: 0; batch classifier loss: 0.106131; batch adversarial loss: 0.386356\n",
      "epoch 130; iter: 0; batch classifier loss: 0.102612; batch adversarial loss: 0.437714\n",
      "epoch 131; iter: 0; batch classifier loss: 0.064228; batch adversarial loss: 0.560920\n",
      "epoch 132; iter: 0; batch classifier loss: 0.066281; batch adversarial loss: 0.483463\n",
      "epoch 133; iter: 0; batch classifier loss: 0.096790; batch adversarial loss: 0.454843\n",
      "epoch 134; iter: 0; batch classifier loss: 0.054524; batch adversarial loss: 0.421903\n",
      "epoch 135; iter: 0; batch classifier loss: 0.090525; batch adversarial loss: 0.411516\n",
      "epoch 136; iter: 0; batch classifier loss: 0.063066; batch adversarial loss: 0.446039\n",
      "epoch 137; iter: 0; batch classifier loss: 0.085302; batch adversarial loss: 0.458740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.066552; batch adversarial loss: 0.460421\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041429; batch adversarial loss: 0.527503\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026986; batch adversarial loss: 0.506538\n",
      "epoch 141; iter: 0; batch classifier loss: 0.079507; batch adversarial loss: 0.403641\n",
      "epoch 142; iter: 0; batch classifier loss: 0.053133; batch adversarial loss: 0.420013\n",
      "epoch 143; iter: 0; batch classifier loss: 0.065475; batch adversarial loss: 0.352609\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032040; batch adversarial loss: 0.411708\n",
      "epoch 145; iter: 0; batch classifier loss: 0.063878; batch adversarial loss: 0.382054\n",
      "epoch 146; iter: 0; batch classifier loss: 0.081078; batch adversarial loss: 0.454357\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037509; batch adversarial loss: 0.499565\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019122; batch adversarial loss: 0.459512\n",
      "epoch 149; iter: 0; batch classifier loss: 0.045486; batch adversarial loss: 0.512613\n",
      "epoch 150; iter: 0; batch classifier loss: 0.046036; batch adversarial loss: 0.465619\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033961; batch adversarial loss: 0.514319\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041951; batch adversarial loss: 0.440173\n",
      "epoch 153; iter: 0; batch classifier loss: 0.063900; batch adversarial loss: 0.424566\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034115; batch adversarial loss: 0.422680\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014144; batch adversarial loss: 0.413512\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022419; batch adversarial loss: 0.559966\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020604; batch adversarial loss: 0.502561\n",
      "epoch 158; iter: 0; batch classifier loss: 0.031957; batch adversarial loss: 0.507984\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018278; batch adversarial loss: 0.486535\n",
      "epoch 160; iter: 0; batch classifier loss: 0.040633; batch adversarial loss: 0.539733\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019036; batch adversarial loss: 0.452588\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016349; batch adversarial loss: 0.477190\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019800; batch adversarial loss: 0.435563\n",
      "epoch 164; iter: 0; batch classifier loss: 0.059059; batch adversarial loss: 0.399805\n",
      "epoch 165; iter: 0; batch classifier loss: 0.039926; batch adversarial loss: 0.391996\n",
      "epoch 166; iter: 0; batch classifier loss: 0.060601; batch adversarial loss: 0.468038\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036545; batch adversarial loss: 0.476684\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012178; batch adversarial loss: 0.408639\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019785; batch adversarial loss: 0.540623\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034364; batch adversarial loss: 0.456230\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025302; batch adversarial loss: 0.464341\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014610; batch adversarial loss: 0.485190\n",
      "epoch 173; iter: 0; batch classifier loss: 0.003221; batch adversarial loss: 0.411151\n",
      "epoch 174; iter: 0; batch classifier loss: 0.036401; batch adversarial loss: 0.486523\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013997; batch adversarial loss: 0.395758\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032217; batch adversarial loss: 0.581134\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033583; batch adversarial loss: 0.392936\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014023; batch adversarial loss: 0.400476\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014216; batch adversarial loss: 0.347312\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025922; batch adversarial loss: 0.405111\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008340; batch adversarial loss: 0.534960\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013383; batch adversarial loss: 0.511952\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027008; batch adversarial loss: 0.410595\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015518; batch adversarial loss: 0.385901\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023432; batch adversarial loss: 0.459070\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010721; batch adversarial loss: 0.440806\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007104; batch adversarial loss: 0.542536\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022541; batch adversarial loss: 0.465692\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018366; batch adversarial loss: 0.424107\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016807; batch adversarial loss: 0.513308\n",
      "epoch 191; iter: 0; batch classifier loss: 0.004402; batch adversarial loss: 0.332255\n",
      "epoch 192; iter: 0; batch classifier loss: 0.002735; batch adversarial loss: 0.448470\n",
      "epoch 193; iter: 0; batch classifier loss: 0.002683; batch adversarial loss: 0.411564\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008870; batch adversarial loss: 0.461213\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014676; batch adversarial loss: 0.418504\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006196; batch adversarial loss: 0.450747\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010212; batch adversarial loss: 0.375917\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021200; batch adversarial loss: 0.430927\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022357; batch adversarial loss: 0.375938\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702322; batch adversarial loss: 0.531466\n",
      "epoch 1; iter: 0; batch classifier loss: 0.445972; batch adversarial loss: 0.602553\n",
      "epoch 2; iter: 0; batch classifier loss: 0.330751; batch adversarial loss: 0.585644\n",
      "epoch 3; iter: 0; batch classifier loss: 0.469935; batch adversarial loss: 0.603048\n",
      "epoch 4; iter: 0; batch classifier loss: 0.407127; batch adversarial loss: 0.571267\n",
      "epoch 5; iter: 0; batch classifier loss: 0.279658; batch adversarial loss: 0.564155\n",
      "epoch 6; iter: 0; batch classifier loss: 0.326514; batch adversarial loss: 0.530868\n",
      "epoch 7; iter: 0; batch classifier loss: 0.274434; batch adversarial loss: 0.519483\n",
      "epoch 8; iter: 0; batch classifier loss: 0.350424; batch adversarial loss: 0.544674\n",
      "epoch 9; iter: 0; batch classifier loss: 0.381948; batch adversarial loss: 0.561827\n",
      "epoch 10; iter: 0; batch classifier loss: 0.433279; batch adversarial loss: 0.563895\n",
      "epoch 11; iter: 0; batch classifier loss: 0.299423; batch adversarial loss: 0.525130\n",
      "epoch 12; iter: 0; batch classifier loss: 0.330612; batch adversarial loss: 0.573382\n",
      "epoch 13; iter: 0; batch classifier loss: 0.357866; batch adversarial loss: 0.547671\n",
      "epoch 14; iter: 0; batch classifier loss: 0.508310; batch adversarial loss: 0.535172\n",
      "epoch 15; iter: 0; batch classifier loss: 0.471161; batch adversarial loss: 0.486611\n",
      "epoch 16; iter: 0; batch classifier loss: 0.347442; batch adversarial loss: 0.483905\n",
      "epoch 17; iter: 0; batch classifier loss: 0.294803; batch adversarial loss: 0.487154\n",
      "epoch 18; iter: 0; batch classifier loss: 0.212530; batch adversarial loss: 0.489308\n",
      "epoch 19; iter: 0; batch classifier loss: 0.213761; batch adversarial loss: 0.501009\n",
      "epoch 20; iter: 0; batch classifier loss: 0.176697; batch adversarial loss: 0.499826\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149504; batch adversarial loss: 0.417545\n",
      "epoch 22; iter: 0; batch classifier loss: 0.220979; batch adversarial loss: 0.422402\n",
      "epoch 23; iter: 0; batch classifier loss: 0.159508; batch adversarial loss: 0.426402\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182533; batch adversarial loss: 0.485758\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174401; batch adversarial loss: 0.418992\n",
      "epoch 26; iter: 0; batch classifier loss: 0.142467; batch adversarial loss: 0.474532\n",
      "epoch 27; iter: 0; batch classifier loss: 0.142298; batch adversarial loss: 0.455426\n",
      "epoch 28; iter: 0; batch classifier loss: 0.121994; batch adversarial loss: 0.548908\n",
      "epoch 29; iter: 0; batch classifier loss: 0.145283; batch adversarial loss: 0.495092\n",
      "epoch 30; iter: 0; batch classifier loss: 0.170468; batch adversarial loss: 0.471260\n",
      "epoch 31; iter: 0; batch classifier loss: 0.109731; batch adversarial loss: 0.507786\n",
      "epoch 32; iter: 0; batch classifier loss: 0.124372; batch adversarial loss: 0.445344\n",
      "epoch 33; iter: 0; batch classifier loss: 0.101138; batch adversarial loss: 0.559191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.129181; batch adversarial loss: 0.496299\n",
      "epoch 35; iter: 0; batch classifier loss: 0.113312; batch adversarial loss: 0.431939\n",
      "epoch 36; iter: 0; batch classifier loss: 0.084503; batch adversarial loss: 0.414386\n",
      "epoch 37; iter: 0; batch classifier loss: 0.088611; batch adversarial loss: 0.519901\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107287; batch adversarial loss: 0.404114\n",
      "epoch 39; iter: 0; batch classifier loss: 0.089153; batch adversarial loss: 0.487292\n",
      "epoch 40; iter: 0; batch classifier loss: 0.119056; batch adversarial loss: 0.492084\n",
      "epoch 41; iter: 0; batch classifier loss: 0.067822; batch adversarial loss: 0.540095\n",
      "epoch 42; iter: 0; batch classifier loss: 0.068585; batch adversarial loss: 0.494961\n",
      "epoch 43; iter: 0; batch classifier loss: 0.082432; batch adversarial loss: 0.453123\n",
      "epoch 44; iter: 0; batch classifier loss: 0.068135; batch adversarial loss: 0.495606\n",
      "epoch 45; iter: 0; batch classifier loss: 0.066614; batch adversarial loss: 0.432370\n",
      "epoch 46; iter: 0; batch classifier loss: 0.106752; batch adversarial loss: 0.410652\n",
      "epoch 47; iter: 0; batch classifier loss: 0.091650; batch adversarial loss: 0.476431\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081924; batch adversarial loss: 0.487116\n",
      "epoch 49; iter: 0; batch classifier loss: 0.170456; batch adversarial loss: 0.428993\n",
      "epoch 50; iter: 0; batch classifier loss: 0.124643; batch adversarial loss: 0.489660\n",
      "epoch 51; iter: 0; batch classifier loss: 0.085270; batch adversarial loss: 0.491374\n",
      "epoch 52; iter: 0; batch classifier loss: 0.086614; batch adversarial loss: 0.539417\n",
      "epoch 53; iter: 0; batch classifier loss: 0.129395; batch adversarial loss: 0.497075\n",
      "epoch 54; iter: 0; batch classifier loss: 0.071587; batch adversarial loss: 0.424343\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084330; batch adversarial loss: 0.535655\n",
      "epoch 56; iter: 0; batch classifier loss: 0.083990; batch adversarial loss: 0.505979\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079721; batch adversarial loss: 0.476927\n",
      "epoch 58; iter: 0; batch classifier loss: 0.141625; batch adversarial loss: 0.383262\n",
      "epoch 59; iter: 0; batch classifier loss: 0.103684; batch adversarial loss: 0.481175\n",
      "epoch 60; iter: 0; batch classifier loss: 0.134734; batch adversarial loss: 0.382615\n",
      "epoch 61; iter: 0; batch classifier loss: 0.082917; batch adversarial loss: 0.480740\n",
      "epoch 62; iter: 0; batch classifier loss: 0.135892; batch adversarial loss: 0.423651\n",
      "epoch 63; iter: 0; batch classifier loss: 0.115047; batch adversarial loss: 0.413580\n",
      "epoch 64; iter: 0; batch classifier loss: 0.101778; batch adversarial loss: 0.450416\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088561; batch adversarial loss: 0.531530\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078896; batch adversarial loss: 0.521852\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061961; batch adversarial loss: 0.474263\n",
      "epoch 68; iter: 0; batch classifier loss: 0.102740; batch adversarial loss: 0.414823\n",
      "epoch 69; iter: 0; batch classifier loss: 0.123527; batch adversarial loss: 0.482739\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079463; batch adversarial loss: 0.509641\n",
      "epoch 71; iter: 0; batch classifier loss: 0.110257; batch adversarial loss: 0.423333\n",
      "epoch 72; iter: 0; batch classifier loss: 0.061043; batch adversarial loss: 0.443880\n",
      "epoch 73; iter: 0; batch classifier loss: 0.124831; batch adversarial loss: 0.483658\n",
      "epoch 74; iter: 0; batch classifier loss: 0.084935; batch adversarial loss: 0.454717\n",
      "epoch 75; iter: 0; batch classifier loss: 0.098480; batch adversarial loss: 0.394799\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082426; batch adversarial loss: 0.527195\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064345; batch adversarial loss: 0.461564\n",
      "epoch 78; iter: 0; batch classifier loss: 0.093855; batch adversarial loss: 0.491706\n",
      "epoch 79; iter: 0; batch classifier loss: 0.095161; batch adversarial loss: 0.450819\n",
      "epoch 80; iter: 0; batch classifier loss: 0.074091; batch adversarial loss: 0.386196\n",
      "epoch 81; iter: 0; batch classifier loss: 0.063083; batch adversarial loss: 0.444979\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062768; batch adversarial loss: 0.414047\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071660; batch adversarial loss: 0.538013\n",
      "epoch 84; iter: 0; batch classifier loss: 0.058114; batch adversarial loss: 0.442844\n",
      "epoch 85; iter: 0; batch classifier loss: 0.098390; batch adversarial loss: 0.527708\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081719; batch adversarial loss: 0.347574\n",
      "epoch 87; iter: 0; batch classifier loss: 0.061927; batch adversarial loss: 0.449612\n",
      "epoch 88; iter: 0; batch classifier loss: 0.096692; batch adversarial loss: 0.511769\n",
      "epoch 89; iter: 0; batch classifier loss: 0.115683; batch adversarial loss: 0.562198\n",
      "epoch 90; iter: 0; batch classifier loss: 0.078639; batch adversarial loss: 0.401489\n",
      "epoch 91; iter: 0; batch classifier loss: 0.076607; batch adversarial loss: 0.412858\n",
      "epoch 92; iter: 0; batch classifier loss: 0.120620; batch adversarial loss: 0.418457\n",
      "epoch 93; iter: 0; batch classifier loss: 0.116642; batch adversarial loss: 0.478556\n",
      "epoch 94; iter: 0; batch classifier loss: 0.097309; batch adversarial loss: 0.463634\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048622; batch adversarial loss: 0.503189\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043290; batch adversarial loss: 0.555396\n",
      "epoch 97; iter: 0; batch classifier loss: 0.070556; batch adversarial loss: 0.479088\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067640; batch adversarial loss: 0.545188\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059637; batch adversarial loss: 0.493678\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049015; batch adversarial loss: 0.412098\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046646; batch adversarial loss: 0.525539\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051707; batch adversarial loss: 0.420133\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066790; batch adversarial loss: 0.474966\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071067; batch adversarial loss: 0.413233\n",
      "epoch 105; iter: 0; batch classifier loss: 0.155350; batch adversarial loss: 0.494190\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035461; batch adversarial loss: 0.527088\n",
      "epoch 107; iter: 0; batch classifier loss: 0.082905; batch adversarial loss: 0.470890\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048977; batch adversarial loss: 0.464639\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064406; batch adversarial loss: 0.478164\n",
      "epoch 110; iter: 0; batch classifier loss: 0.065739; batch adversarial loss: 0.493841\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030894; batch adversarial loss: 0.602308\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044241; batch adversarial loss: 0.583589\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037407; batch adversarial loss: 0.588956\n",
      "epoch 114; iter: 0; batch classifier loss: 0.038554; batch adversarial loss: 0.451003\n",
      "epoch 115; iter: 0; batch classifier loss: 0.071730; batch adversarial loss: 0.392365\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038234; batch adversarial loss: 0.486445\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037421; batch adversarial loss: 0.535999\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060266; batch adversarial loss: 0.394587\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046652; batch adversarial loss: 0.533251\n",
      "epoch 120; iter: 0; batch classifier loss: 0.029355; batch adversarial loss: 0.536917\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053435; batch adversarial loss: 0.529036\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045837; batch adversarial loss: 0.497897\n",
      "epoch 123; iter: 0; batch classifier loss: 0.022038; batch adversarial loss: 0.571230\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046344; batch adversarial loss: 0.475139\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062532; batch adversarial loss: 0.451930\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043099; batch adversarial loss: 0.464303\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053544; batch adversarial loss: 0.559028\n",
      "epoch 128; iter: 0; batch classifier loss: 0.067526; batch adversarial loss: 0.479277\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043400; batch adversarial loss: 0.437316\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040943; batch adversarial loss: 0.475026\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023584; batch adversarial loss: 0.417766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.021401; batch adversarial loss: 0.440848\n",
      "epoch 133; iter: 0; batch classifier loss: 0.057432; batch adversarial loss: 0.442328\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028309; batch adversarial loss: 0.457727\n",
      "epoch 135; iter: 0; batch classifier loss: 0.060832; batch adversarial loss: 0.507800\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041004; batch adversarial loss: 0.447896\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030703; batch adversarial loss: 0.365889\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027673; batch adversarial loss: 0.561946\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035680; batch adversarial loss: 0.477972\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041573; batch adversarial loss: 0.486482\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046545; batch adversarial loss: 0.431526\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037282; batch adversarial loss: 0.446852\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039839; batch adversarial loss: 0.541800\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022937; batch adversarial loss: 0.407258\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031545; batch adversarial loss: 0.574065\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031075; batch adversarial loss: 0.588031\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021163; batch adversarial loss: 0.480146\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033749; batch adversarial loss: 0.464567\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040187; batch adversarial loss: 0.477805\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037528; batch adversarial loss: 0.469273\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014560; batch adversarial loss: 0.517661\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025138; batch adversarial loss: 0.483928\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028088; batch adversarial loss: 0.516335\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041792; batch adversarial loss: 0.503034\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052469; batch adversarial loss: 0.374261\n",
      "epoch 156; iter: 0; batch classifier loss: 0.060651; batch adversarial loss: 0.473971\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012417; batch adversarial loss: 0.508122\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022241; batch adversarial loss: 0.454154\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022156; batch adversarial loss: 0.454589\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027126; batch adversarial loss: 0.381612\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043672; batch adversarial loss: 0.570162\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032472; batch adversarial loss: 0.500121\n",
      "epoch 163; iter: 0; batch classifier loss: 0.075295; batch adversarial loss: 0.529501\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020508; batch adversarial loss: 0.473214\n",
      "epoch 165; iter: 0; batch classifier loss: 0.056665; batch adversarial loss: 0.435978\n",
      "epoch 166; iter: 0; batch classifier loss: 0.043348; batch adversarial loss: 0.482407\n",
      "epoch 167; iter: 0; batch classifier loss: 0.037250; batch adversarial loss: 0.430406\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020418; batch adversarial loss: 0.470492\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013886; batch adversarial loss: 0.425568\n",
      "epoch 170; iter: 0; batch classifier loss: 0.054937; batch adversarial loss: 0.493641\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047223; batch adversarial loss: 0.374173\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029564; batch adversarial loss: 0.535977\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020088; batch adversarial loss: 0.411621\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012948; batch adversarial loss: 0.514135\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028421; batch adversarial loss: 0.462258\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026412; batch adversarial loss: 0.448278\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026619; batch adversarial loss: 0.467445\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023405; batch adversarial loss: 0.513546\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029204; batch adversarial loss: 0.465725\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009457; batch adversarial loss: 0.490833\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027707; batch adversarial loss: 0.518278\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006067; batch adversarial loss: 0.521605\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042495; batch adversarial loss: 0.530483\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024481; batch adversarial loss: 0.485053\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028834; batch adversarial loss: 0.419136\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010638; batch adversarial loss: 0.483519\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024444; batch adversarial loss: 0.442990\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032985; batch adversarial loss: 0.443764\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018677; batch adversarial loss: 0.452271\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036626; batch adversarial loss: 0.383507\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011496; batch adversarial loss: 0.510517\n",
      "epoch 192; iter: 0; batch classifier loss: 0.050235; batch adversarial loss: 0.368221\n",
      "epoch 193; iter: 0; batch classifier loss: 0.072361; batch adversarial loss: 0.421359\n",
      "epoch 194; iter: 0; batch classifier loss: 0.029922; batch adversarial loss: 0.465518\n",
      "epoch 195; iter: 0; batch classifier loss: 0.041130; batch adversarial loss: 0.377183\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018416; batch adversarial loss: 0.409398\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010135; batch adversarial loss: 0.453942\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017894; batch adversarial loss: 0.462092\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031690; batch adversarial loss: 0.538934\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704791; batch adversarial loss: 0.626651\n",
      "epoch 1; iter: 0; batch classifier loss: 0.321928; batch adversarial loss: 0.627237\n",
      "epoch 2; iter: 0; batch classifier loss: 0.361230; batch adversarial loss: 0.607856\n",
      "epoch 3; iter: 0; batch classifier loss: 0.371422; batch adversarial loss: 0.574595\n",
      "epoch 4; iter: 0; batch classifier loss: 0.310844; batch adversarial loss: 0.555700\n",
      "epoch 5; iter: 0; batch classifier loss: 0.372360; batch adversarial loss: 0.540761\n",
      "epoch 6; iter: 0; batch classifier loss: 0.358190; batch adversarial loss: 0.565354\n",
      "epoch 7; iter: 0; batch classifier loss: 0.321119; batch adversarial loss: 0.598717\n",
      "epoch 8; iter: 0; batch classifier loss: 0.350579; batch adversarial loss: 0.568556\n",
      "epoch 9; iter: 0; batch classifier loss: 0.470665; batch adversarial loss: 0.584207\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552443; batch adversarial loss: 0.648421\n",
      "epoch 11; iter: 0; batch classifier loss: 0.648279; batch adversarial loss: 0.550660\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542246; batch adversarial loss: 0.535718\n",
      "epoch 13; iter: 0; batch classifier loss: 0.420341; batch adversarial loss: 0.481822\n",
      "epoch 14; iter: 0; batch classifier loss: 0.301914; batch adversarial loss: 0.528819\n",
      "epoch 15; iter: 0; batch classifier loss: 0.292720; batch adversarial loss: 0.451525\n",
      "epoch 16; iter: 0; batch classifier loss: 0.280404; batch adversarial loss: 0.495810\n",
      "epoch 17; iter: 0; batch classifier loss: 0.273821; batch adversarial loss: 0.475649\n",
      "epoch 18; iter: 0; batch classifier loss: 0.204393; batch adversarial loss: 0.483616\n",
      "epoch 19; iter: 0; batch classifier loss: 0.241129; batch adversarial loss: 0.469436\n",
      "epoch 20; iter: 0; batch classifier loss: 0.260548; batch adversarial loss: 0.443473\n",
      "epoch 21; iter: 0; batch classifier loss: 0.243405; batch adversarial loss: 0.382360\n",
      "epoch 22; iter: 0; batch classifier loss: 0.181274; batch adversarial loss: 0.477384\n",
      "epoch 23; iter: 0; batch classifier loss: 0.163628; batch adversarial loss: 0.430957\n",
      "epoch 24; iter: 0; batch classifier loss: 0.208202; batch adversarial loss: 0.498318\n",
      "epoch 25; iter: 0; batch classifier loss: 0.231774; batch adversarial loss: 0.492551\n",
      "epoch 26; iter: 0; batch classifier loss: 0.185319; batch adversarial loss: 0.453144\n",
      "epoch 27; iter: 0; batch classifier loss: 0.156632; batch adversarial loss: 0.510791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.164996; batch adversarial loss: 0.435322\n",
      "epoch 29; iter: 0; batch classifier loss: 0.145094; batch adversarial loss: 0.449642\n",
      "epoch 30; iter: 0; batch classifier loss: 0.174608; batch adversarial loss: 0.425847\n",
      "epoch 31; iter: 0; batch classifier loss: 0.187613; batch adversarial loss: 0.440615\n",
      "epoch 32; iter: 0; batch classifier loss: 0.093147; batch adversarial loss: 0.501635\n",
      "epoch 33; iter: 0; batch classifier loss: 0.195105; batch adversarial loss: 0.447426\n",
      "epoch 34; iter: 0; batch classifier loss: 0.168165; batch adversarial loss: 0.378694\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122178; batch adversarial loss: 0.502693\n",
      "epoch 36; iter: 0; batch classifier loss: 0.158504; batch adversarial loss: 0.390651\n",
      "epoch 37; iter: 0; batch classifier loss: 0.130499; batch adversarial loss: 0.393758\n",
      "epoch 38; iter: 0; batch classifier loss: 0.163509; batch adversarial loss: 0.441413\n",
      "epoch 39; iter: 0; batch classifier loss: 0.118939; batch adversarial loss: 0.486201\n",
      "epoch 40; iter: 0; batch classifier loss: 0.152176; batch adversarial loss: 0.386854\n",
      "epoch 41; iter: 0; batch classifier loss: 0.096827; batch adversarial loss: 0.442838\n",
      "epoch 42; iter: 0; batch classifier loss: 0.132934; batch adversarial loss: 0.442015\n",
      "epoch 43; iter: 0; batch classifier loss: 0.171293; batch adversarial loss: 0.468196\n",
      "epoch 44; iter: 0; batch classifier loss: 0.153866; batch adversarial loss: 0.474812\n",
      "epoch 45; iter: 0; batch classifier loss: 0.147441; batch adversarial loss: 0.363665\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102709; batch adversarial loss: 0.436224\n",
      "epoch 47; iter: 0; batch classifier loss: 0.105581; batch adversarial loss: 0.437718\n",
      "epoch 48; iter: 0; batch classifier loss: 0.133084; batch adversarial loss: 0.463744\n",
      "epoch 49; iter: 0; batch classifier loss: 0.126138; batch adversarial loss: 0.437638\n",
      "epoch 50; iter: 0; batch classifier loss: 0.117829; batch adversarial loss: 0.381628\n",
      "epoch 51; iter: 0; batch classifier loss: 0.135897; batch adversarial loss: 0.480919\n",
      "epoch 52; iter: 0; batch classifier loss: 0.179399; batch adversarial loss: 0.457292\n",
      "epoch 53; iter: 0; batch classifier loss: 0.179312; batch adversarial loss: 0.425090\n",
      "epoch 54; iter: 0; batch classifier loss: 0.093225; batch adversarial loss: 0.437956\n",
      "epoch 55; iter: 0; batch classifier loss: 0.139281; batch adversarial loss: 0.402858\n",
      "epoch 56; iter: 0; batch classifier loss: 0.172630; batch adversarial loss: 0.444477\n",
      "epoch 57; iter: 0; batch classifier loss: 0.131991; batch adversarial loss: 0.466939\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090962; batch adversarial loss: 0.595047\n",
      "epoch 59; iter: 0; batch classifier loss: 0.109278; batch adversarial loss: 0.478885\n",
      "epoch 60; iter: 0; batch classifier loss: 0.165801; batch adversarial loss: 0.457043\n",
      "epoch 61; iter: 0; batch classifier loss: 0.188886; batch adversarial loss: 0.379032\n",
      "epoch 62; iter: 0; batch classifier loss: 0.126075; batch adversarial loss: 0.383939\n",
      "epoch 63; iter: 0; batch classifier loss: 0.116945; batch adversarial loss: 0.485418\n",
      "epoch 64; iter: 0; batch classifier loss: 0.112121; batch adversarial loss: 0.491786\n",
      "epoch 65; iter: 0; batch classifier loss: 0.140813; batch adversarial loss: 0.420582\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084498; batch adversarial loss: 0.408426\n",
      "epoch 67; iter: 0; batch classifier loss: 0.141308; batch adversarial loss: 0.469270\n",
      "epoch 68; iter: 0; batch classifier loss: 0.125440; batch adversarial loss: 0.453197\n",
      "epoch 69; iter: 0; batch classifier loss: 0.139585; batch adversarial loss: 0.368200\n",
      "epoch 70; iter: 0; batch classifier loss: 0.173425; batch adversarial loss: 0.372948\n",
      "epoch 71; iter: 0; batch classifier loss: 0.154892; batch adversarial loss: 0.360210\n",
      "epoch 72; iter: 0; batch classifier loss: 0.112955; batch adversarial loss: 0.431025\n",
      "epoch 73; iter: 0; batch classifier loss: 0.099695; batch adversarial loss: 0.369086\n",
      "epoch 74; iter: 0; batch classifier loss: 0.118559; batch adversarial loss: 0.423905\n",
      "epoch 75; iter: 0; batch classifier loss: 0.157242; batch adversarial loss: 0.348362\n",
      "epoch 76; iter: 0; batch classifier loss: 0.152829; batch adversarial loss: 0.459747\n",
      "epoch 77; iter: 0; batch classifier loss: 0.104247; batch adversarial loss: 0.504399\n",
      "epoch 78; iter: 0; batch classifier loss: 0.117381; batch adversarial loss: 0.430545\n",
      "epoch 79; iter: 0; batch classifier loss: 0.120111; batch adversarial loss: 0.401159\n",
      "epoch 80; iter: 0; batch classifier loss: 0.080737; batch adversarial loss: 0.521519\n",
      "epoch 81; iter: 0; batch classifier loss: 0.121185; batch adversarial loss: 0.395638\n",
      "epoch 82; iter: 0; batch classifier loss: 0.154722; batch adversarial loss: 0.495638\n",
      "epoch 83; iter: 0; batch classifier loss: 0.122746; batch adversarial loss: 0.322317\n",
      "epoch 84; iter: 0; batch classifier loss: 0.162384; batch adversarial loss: 0.379971\n",
      "epoch 85; iter: 0; batch classifier loss: 0.103251; batch adversarial loss: 0.406481\n",
      "epoch 86; iter: 0; batch classifier loss: 0.137188; batch adversarial loss: 0.429442\n",
      "epoch 87; iter: 0; batch classifier loss: 0.095795; batch adversarial loss: 0.381396\n",
      "epoch 88; iter: 0; batch classifier loss: 0.116407; batch adversarial loss: 0.444209\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068520; batch adversarial loss: 0.496080\n",
      "epoch 90; iter: 0; batch classifier loss: 0.117931; batch adversarial loss: 0.396491\n",
      "epoch 91; iter: 0; batch classifier loss: 0.092065; batch adversarial loss: 0.458364\n",
      "epoch 92; iter: 0; batch classifier loss: 0.090464; batch adversarial loss: 0.408564\n",
      "epoch 93; iter: 0; batch classifier loss: 0.115601; batch adversarial loss: 0.526461\n",
      "epoch 94; iter: 0; batch classifier loss: 0.110043; batch adversarial loss: 0.488844\n",
      "epoch 95; iter: 0; batch classifier loss: 0.125198; batch adversarial loss: 0.369401\n",
      "epoch 96; iter: 0; batch classifier loss: 0.160869; batch adversarial loss: 0.417774\n",
      "epoch 97; iter: 0; batch classifier loss: 0.061897; batch adversarial loss: 0.597930\n",
      "epoch 98; iter: 0; batch classifier loss: 0.082059; batch adversarial loss: 0.397203\n",
      "epoch 99; iter: 0; batch classifier loss: 0.095613; batch adversarial loss: 0.419184\n",
      "epoch 100; iter: 0; batch classifier loss: 0.100149; batch adversarial loss: 0.486072\n",
      "epoch 101; iter: 0; batch classifier loss: 0.090253; batch adversarial loss: 0.420171\n",
      "epoch 102; iter: 0; batch classifier loss: 0.118398; batch adversarial loss: 0.446919\n",
      "epoch 103; iter: 0; batch classifier loss: 0.116800; batch adversarial loss: 0.408073\n",
      "epoch 104; iter: 0; batch classifier loss: 0.081614; batch adversarial loss: 0.375817\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047583; batch adversarial loss: 0.474823\n",
      "epoch 106; iter: 0; batch classifier loss: 0.102684; batch adversarial loss: 0.540365\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052859; batch adversarial loss: 0.476386\n",
      "epoch 108; iter: 0; batch classifier loss: 0.090411; batch adversarial loss: 0.398812\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046736; batch adversarial loss: 0.487331\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049966; batch adversarial loss: 0.414729\n",
      "epoch 111; iter: 0; batch classifier loss: 0.085172; batch adversarial loss: 0.503662\n",
      "epoch 112; iter: 0; batch classifier loss: 0.077346; batch adversarial loss: 0.454919\n",
      "epoch 113; iter: 0; batch classifier loss: 0.086771; batch adversarial loss: 0.407173\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060936; batch adversarial loss: 0.473266\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053367; batch adversarial loss: 0.503615\n",
      "epoch 116; iter: 0; batch classifier loss: 0.066009; batch adversarial loss: 0.395968\n",
      "epoch 117; iter: 0; batch classifier loss: 0.071247; batch adversarial loss: 0.573054\n",
      "epoch 118; iter: 0; batch classifier loss: 0.065829; batch adversarial loss: 0.477640\n",
      "epoch 119; iter: 0; batch classifier loss: 0.068655; batch adversarial loss: 0.438583\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031489; batch adversarial loss: 0.401457\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031513; batch adversarial loss: 0.528253\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033860; batch adversarial loss: 0.517458\n",
      "epoch 123; iter: 0; batch classifier loss: 0.017001; batch adversarial loss: 0.551446\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033082; batch adversarial loss: 0.425597\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034000; batch adversarial loss: 0.409930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.056955; batch adversarial loss: 0.476330\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028029; batch adversarial loss: 0.422527\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032616; batch adversarial loss: 0.361123\n",
      "epoch 129; iter: 0; batch classifier loss: 0.064686; batch adversarial loss: 0.354488\n",
      "epoch 130; iter: 0; batch classifier loss: 0.086309; batch adversarial loss: 0.470851\n",
      "epoch 131; iter: 0; batch classifier loss: 0.057969; batch adversarial loss: 0.455894\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046838; batch adversarial loss: 0.462280\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039085; batch adversarial loss: 0.398004\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027427; batch adversarial loss: 0.468057\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045876; batch adversarial loss: 0.452232\n",
      "epoch 136; iter: 0; batch classifier loss: 0.061798; batch adversarial loss: 0.428689\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032290; batch adversarial loss: 0.392264\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037834; batch adversarial loss: 0.505380\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015787; batch adversarial loss: 0.412491\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047380; batch adversarial loss: 0.457050\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042694; batch adversarial loss: 0.450543\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028781; batch adversarial loss: 0.434302\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015044; batch adversarial loss: 0.413688\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017392; batch adversarial loss: 0.421437\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021138; batch adversarial loss: 0.402178\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021906; batch adversarial loss: 0.449481\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028461; batch adversarial loss: 0.417141\n",
      "epoch 148; iter: 0; batch classifier loss: 0.037202; batch adversarial loss: 0.468043\n",
      "epoch 149; iter: 0; batch classifier loss: 0.006470; batch adversarial loss: 0.480471\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018928; batch adversarial loss: 0.457557\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026702; batch adversarial loss: 0.413331\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034872; batch adversarial loss: 0.495353\n",
      "epoch 153; iter: 0; batch classifier loss: 0.053884; batch adversarial loss: 0.607856\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041440; batch adversarial loss: 0.389428\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009698; batch adversarial loss: 0.480755\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029696; batch adversarial loss: 0.375988\n",
      "epoch 157; iter: 0; batch classifier loss: 0.007806; batch adversarial loss: 0.507771\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044045; batch adversarial loss: 0.493284\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010228; batch adversarial loss: 0.398944\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012206; batch adversarial loss: 0.502568\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029488; batch adversarial loss: 0.395426\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022929; batch adversarial loss: 0.436143\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042143; batch adversarial loss: 0.463144\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024548; batch adversarial loss: 0.440972\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037544; batch adversarial loss: 0.432107\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016891; batch adversarial loss: 0.441078\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008330; batch adversarial loss: 0.481117\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007938; batch adversarial loss: 0.452375\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021122; batch adversarial loss: 0.423016\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018882; batch adversarial loss: 0.438689\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013217; batch adversarial loss: 0.405149\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034796; batch adversarial loss: 0.402376\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030348; batch adversarial loss: 0.472024\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016929; batch adversarial loss: 0.340821\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024932; batch adversarial loss: 0.429308\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034386; batch adversarial loss: 0.367411\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033288; batch adversarial loss: 0.497405\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021489; batch adversarial loss: 0.516923\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021853; batch adversarial loss: 0.433192\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016997; batch adversarial loss: 0.453866\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018542; batch adversarial loss: 0.395106\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018739; batch adversarial loss: 0.458944\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025910; batch adversarial loss: 0.384801\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011470; batch adversarial loss: 0.568553\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011408; batch adversarial loss: 0.515085\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027725; batch adversarial loss: 0.380834\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008343; batch adversarial loss: 0.515713\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014467; batch adversarial loss: 0.526662\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010267; batch adversarial loss: 0.452776\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012756; batch adversarial loss: 0.604648\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020867; batch adversarial loss: 0.383302\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027036; batch adversarial loss: 0.430554\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018926; batch adversarial loss: 0.549441\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013695; batch adversarial loss: 0.320300\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005704; batch adversarial loss: 0.409712\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021675; batch adversarial loss: 0.421908\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016131; batch adversarial loss: 0.378486\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012803; batch adversarial loss: 0.549736\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015935; batch adversarial loss: 0.421968\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690660; batch adversarial loss: 0.735931\n",
      "epoch 1; iter: 0; batch classifier loss: 0.542853; batch adversarial loss: 0.700060\n",
      "epoch 2; iter: 0; batch classifier loss: 0.468606; batch adversarial loss: 0.676069\n",
      "epoch 3; iter: 0; batch classifier loss: 0.367601; batch adversarial loss: 0.636766\n",
      "epoch 4; iter: 0; batch classifier loss: 0.320812; batch adversarial loss: 0.596805\n",
      "epoch 5; iter: 0; batch classifier loss: 0.274189; batch adversarial loss: 0.574433\n",
      "epoch 6; iter: 0; batch classifier loss: 0.349931; batch adversarial loss: 0.535357\n",
      "epoch 7; iter: 0; batch classifier loss: 0.288579; batch adversarial loss: 0.511511\n",
      "epoch 8; iter: 0; batch classifier loss: 0.296710; batch adversarial loss: 0.490722\n",
      "epoch 9; iter: 0; batch classifier loss: 0.237625; batch adversarial loss: 0.492060\n",
      "epoch 10; iter: 0; batch classifier loss: 0.296102; batch adversarial loss: 0.459339\n",
      "epoch 11; iter: 0; batch classifier loss: 0.245484; batch adversarial loss: 0.439703\n",
      "epoch 12; iter: 0; batch classifier loss: 0.163203; batch adversarial loss: 0.513147\n",
      "epoch 13; iter: 0; batch classifier loss: 0.170275; batch adversarial loss: 0.463495\n",
      "epoch 14; iter: 0; batch classifier loss: 0.158272; batch adversarial loss: 0.422118\n",
      "epoch 15; iter: 0; batch classifier loss: 0.216155; batch adversarial loss: 0.520026\n",
      "epoch 16; iter: 0; batch classifier loss: 0.189343; batch adversarial loss: 0.399614\n",
      "epoch 17; iter: 0; batch classifier loss: 0.150059; batch adversarial loss: 0.525989\n",
      "epoch 18; iter: 0; batch classifier loss: 0.143918; batch adversarial loss: 0.407506\n",
      "epoch 19; iter: 0; batch classifier loss: 0.169194; batch adversarial loss: 0.427414\n",
      "epoch 20; iter: 0; batch classifier loss: 0.138470; batch adversarial loss: 0.440645\n",
      "epoch 21; iter: 0; batch classifier loss: 0.174577; batch adversarial loss: 0.406179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.149829; batch adversarial loss: 0.416266\n",
      "epoch 23; iter: 0; batch classifier loss: 0.180459; batch adversarial loss: 0.399489\n",
      "epoch 24; iter: 0; batch classifier loss: 0.097880; batch adversarial loss: 0.468632\n",
      "epoch 25; iter: 0; batch classifier loss: 0.117752; batch adversarial loss: 0.398997\n",
      "epoch 26; iter: 0; batch classifier loss: 0.107886; batch adversarial loss: 0.366551\n",
      "epoch 27; iter: 0; batch classifier loss: 0.132476; batch adversarial loss: 0.401898\n",
      "epoch 28; iter: 0; batch classifier loss: 0.162544; batch adversarial loss: 0.494043\n",
      "epoch 29; iter: 0; batch classifier loss: 0.107285; batch adversarial loss: 0.409977\n",
      "epoch 30; iter: 0; batch classifier loss: 0.143207; batch adversarial loss: 0.378287\n",
      "epoch 31; iter: 0; batch classifier loss: 0.136137; batch adversarial loss: 0.375452\n",
      "epoch 32; iter: 0; batch classifier loss: 0.171086; batch adversarial loss: 0.310100\n",
      "epoch 33; iter: 0; batch classifier loss: 0.097577; batch adversarial loss: 0.407537\n",
      "epoch 34; iter: 0; batch classifier loss: 0.169067; batch adversarial loss: 0.422245\n",
      "epoch 35; iter: 0; batch classifier loss: 0.132514; batch adversarial loss: 0.416185\n",
      "epoch 36; iter: 0; batch classifier loss: 0.118603; batch adversarial loss: 0.344855\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111431; batch adversarial loss: 0.486121\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107342; batch adversarial loss: 0.481508\n",
      "epoch 39; iter: 0; batch classifier loss: 0.079756; batch adversarial loss: 0.375056\n",
      "epoch 40; iter: 0; batch classifier loss: 0.084555; batch adversarial loss: 0.506736\n",
      "epoch 41; iter: 0; batch classifier loss: 0.113258; batch adversarial loss: 0.356372\n",
      "epoch 42; iter: 0; batch classifier loss: 0.108691; batch adversarial loss: 0.390972\n",
      "epoch 43; iter: 0; batch classifier loss: 0.105542; batch adversarial loss: 0.403744\n",
      "epoch 44; iter: 0; batch classifier loss: 0.129637; batch adversarial loss: 0.428420\n",
      "epoch 45; iter: 0; batch classifier loss: 0.149173; batch adversarial loss: 0.431638\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086703; batch adversarial loss: 0.476706\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095271; batch adversarial loss: 0.422473\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100713; batch adversarial loss: 0.373727\n",
      "epoch 49; iter: 0; batch classifier loss: 0.097536; batch adversarial loss: 0.334554\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074425; batch adversarial loss: 0.392265\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098656; batch adversarial loss: 0.415997\n",
      "epoch 52; iter: 0; batch classifier loss: 0.128336; batch adversarial loss: 0.405635\n",
      "epoch 53; iter: 0; batch classifier loss: 0.068214; batch adversarial loss: 0.411082\n",
      "epoch 54; iter: 0; batch classifier loss: 0.061512; batch adversarial loss: 0.362558\n",
      "epoch 55; iter: 0; batch classifier loss: 0.141257; batch adversarial loss: 0.434493\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081048; batch adversarial loss: 0.486641\n",
      "epoch 57; iter: 0; batch classifier loss: 0.046313; batch adversarial loss: 0.415759\n",
      "epoch 58; iter: 0; batch classifier loss: 0.070367; batch adversarial loss: 0.415971\n",
      "epoch 59; iter: 0; batch classifier loss: 0.069362; batch adversarial loss: 0.399703\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081858; batch adversarial loss: 0.393959\n",
      "epoch 61; iter: 0; batch classifier loss: 0.060105; batch adversarial loss: 0.394287\n",
      "epoch 62; iter: 0; batch classifier loss: 0.117428; batch adversarial loss: 0.373944\n",
      "epoch 63; iter: 0; batch classifier loss: 0.066427; batch adversarial loss: 0.398350\n",
      "epoch 64; iter: 0; batch classifier loss: 0.087571; batch adversarial loss: 0.396018\n",
      "epoch 65; iter: 0; batch classifier loss: 0.069794; batch adversarial loss: 0.402241\n",
      "epoch 66; iter: 0; batch classifier loss: 0.059014; batch adversarial loss: 0.413762\n",
      "epoch 67; iter: 0; batch classifier loss: 0.037133; batch adversarial loss: 0.358237\n",
      "epoch 68; iter: 0; batch classifier loss: 0.063235; batch adversarial loss: 0.382850\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078288; batch adversarial loss: 0.349450\n",
      "epoch 70; iter: 0; batch classifier loss: 0.051396; batch adversarial loss: 0.407504\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115142; batch adversarial loss: 0.396831\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062009; batch adversarial loss: 0.360007\n",
      "epoch 73; iter: 0; batch classifier loss: 0.057330; batch adversarial loss: 0.398049\n",
      "epoch 74; iter: 0; batch classifier loss: 0.070454; batch adversarial loss: 0.437477\n",
      "epoch 75; iter: 0; batch classifier loss: 0.034317; batch adversarial loss: 0.384928\n",
      "epoch 76; iter: 0; batch classifier loss: 0.066180; batch adversarial loss: 0.403867\n",
      "epoch 77; iter: 0; batch classifier loss: 0.083281; batch adversarial loss: 0.394748\n",
      "epoch 78; iter: 0; batch classifier loss: 0.089037; batch adversarial loss: 0.354286\n",
      "epoch 79; iter: 0; batch classifier loss: 0.066353; batch adversarial loss: 0.448672\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054563; batch adversarial loss: 0.427026\n",
      "epoch 81; iter: 0; batch classifier loss: 0.089477; batch adversarial loss: 0.394981\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060155; batch adversarial loss: 0.420137\n",
      "epoch 83; iter: 0; batch classifier loss: 0.044685; batch adversarial loss: 0.419615\n",
      "epoch 84; iter: 0; batch classifier loss: 0.049386; batch adversarial loss: 0.379048\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051249; batch adversarial loss: 0.419161\n",
      "epoch 86; iter: 0; batch classifier loss: 0.050789; batch adversarial loss: 0.381284\n",
      "epoch 87; iter: 0; batch classifier loss: 0.052592; batch adversarial loss: 0.471806\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078152; batch adversarial loss: 0.496969\n",
      "epoch 89; iter: 0; batch classifier loss: 0.062292; batch adversarial loss: 0.503505\n",
      "epoch 90; iter: 0; batch classifier loss: 0.045950; batch adversarial loss: 0.463977\n",
      "epoch 91; iter: 0; batch classifier loss: 0.038306; batch adversarial loss: 0.378195\n",
      "epoch 92; iter: 0; batch classifier loss: 0.053667; batch adversarial loss: 0.356686\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062858; batch adversarial loss: 0.398315\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050723; batch adversarial loss: 0.402294\n",
      "epoch 95; iter: 0; batch classifier loss: 0.030102; batch adversarial loss: 0.542982\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041014; batch adversarial loss: 0.561382\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046852; batch adversarial loss: 0.374972\n",
      "epoch 98; iter: 0; batch classifier loss: 0.033104; batch adversarial loss: 0.392712\n",
      "epoch 99; iter: 0; batch classifier loss: 0.028770; batch adversarial loss: 0.416623\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045203; batch adversarial loss: 0.404608\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043022; batch adversarial loss: 0.573414\n",
      "epoch 102; iter: 0; batch classifier loss: 0.024483; batch adversarial loss: 0.532938\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040508; batch adversarial loss: 0.381176\n",
      "epoch 104; iter: 0; batch classifier loss: 0.048783; batch adversarial loss: 0.492969\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041179; batch adversarial loss: 0.521729\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042052; batch adversarial loss: 0.468891\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041493; batch adversarial loss: 0.350722\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033293; batch adversarial loss: 0.463800\n",
      "epoch 109; iter: 0; batch classifier loss: 0.055566; batch adversarial loss: 0.424666\n",
      "epoch 110; iter: 0; batch classifier loss: 0.019359; batch adversarial loss: 0.380986\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030535; batch adversarial loss: 0.514338\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041202; batch adversarial loss: 0.437703\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029516; batch adversarial loss: 0.363785\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034677; batch adversarial loss: 0.382261\n",
      "epoch 115; iter: 0; batch classifier loss: 0.009477; batch adversarial loss: 0.347478\n",
      "epoch 116; iter: 0; batch classifier loss: 0.010749; batch adversarial loss: 0.486772\n",
      "epoch 117; iter: 0; batch classifier loss: 0.012965; batch adversarial loss: 0.459682\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033650; batch adversarial loss: 0.344020\n",
      "epoch 119; iter: 0; batch classifier loss: 0.013497; batch adversarial loss: 0.406511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.009924; batch adversarial loss: 0.444139\n",
      "epoch 121; iter: 0; batch classifier loss: 0.023265; batch adversarial loss: 0.432563\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026066; batch adversarial loss: 0.386928\n",
      "epoch 123; iter: 0; batch classifier loss: 0.011257; batch adversarial loss: 0.486044\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023676; batch adversarial loss: 0.423840\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033323; batch adversarial loss: 0.511023\n",
      "epoch 126; iter: 0; batch classifier loss: 0.118961; batch adversarial loss: 0.549246\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033634; batch adversarial loss: 0.515223\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056662; batch adversarial loss: 0.419056\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029019; batch adversarial loss: 0.419470\n",
      "epoch 130; iter: 0; batch classifier loss: 0.068258; batch adversarial loss: 0.521430\n",
      "epoch 131; iter: 0; batch classifier loss: 0.072673; batch adversarial loss: 0.579026\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035177; batch adversarial loss: 0.485994\n",
      "epoch 133; iter: 0; batch classifier loss: 0.054332; batch adversarial loss: 0.499290\n",
      "epoch 134; iter: 0; batch classifier loss: 0.223395; batch adversarial loss: 0.913736\n",
      "epoch 135; iter: 0; batch classifier loss: 0.152194; batch adversarial loss: 0.660051\n",
      "epoch 136; iter: 0; batch classifier loss: 0.110879; batch adversarial loss: 0.728648\n",
      "epoch 137; iter: 0; batch classifier loss: 0.103460; batch adversarial loss: 0.586680\n",
      "epoch 138; iter: 0; batch classifier loss: 0.078259; batch adversarial loss: 0.409592\n",
      "epoch 139; iter: 0; batch classifier loss: 0.216141; batch adversarial loss: 0.737468\n",
      "epoch 140; iter: 0; batch classifier loss: 0.109944; batch adversarial loss: 0.562394\n",
      "epoch 141; iter: 0; batch classifier loss: 0.092271; batch adversarial loss: 0.449283\n",
      "epoch 142; iter: 0; batch classifier loss: 0.078867; batch adversarial loss: 0.521298\n",
      "epoch 143; iter: 0; batch classifier loss: 0.142974; batch adversarial loss: 0.624794\n",
      "epoch 144; iter: 0; batch classifier loss: 0.164532; batch adversarial loss: 0.711958\n",
      "epoch 145; iter: 0; batch classifier loss: 0.202943; batch adversarial loss: 0.701369\n",
      "epoch 146; iter: 0; batch classifier loss: 0.186405; batch adversarial loss: 0.584640\n",
      "epoch 147; iter: 0; batch classifier loss: 0.169011; batch adversarial loss: 0.647185\n",
      "epoch 148; iter: 0; batch classifier loss: 0.208286; batch adversarial loss: 0.624611\n",
      "epoch 149; iter: 0; batch classifier loss: 0.163508; batch adversarial loss: 0.608135\n",
      "epoch 150; iter: 0; batch classifier loss: 0.147026; batch adversarial loss: 0.559431\n",
      "epoch 151; iter: 0; batch classifier loss: 0.132761; batch adversarial loss: 0.577326\n",
      "epoch 152; iter: 0; batch classifier loss: 0.207910; batch adversarial loss: 0.556896\n",
      "epoch 153; iter: 0; batch classifier loss: 0.152860; batch adversarial loss: 0.595610\n",
      "epoch 154; iter: 0; batch classifier loss: 0.065939; batch adversarial loss: 0.453017\n",
      "epoch 155; iter: 0; batch classifier loss: 0.149175; batch adversarial loss: 0.503528\n",
      "epoch 156; iter: 0; batch classifier loss: 0.169538; batch adversarial loss: 0.583019\n",
      "epoch 157; iter: 0; batch classifier loss: 0.229942; batch adversarial loss: 0.630976\n",
      "epoch 158; iter: 0; batch classifier loss: 0.089546; batch adversarial loss: 0.543049\n",
      "epoch 159; iter: 0; batch classifier loss: 0.124452; batch adversarial loss: 0.455672\n",
      "epoch 160; iter: 0; batch classifier loss: 0.110465; batch adversarial loss: 0.511641\n",
      "epoch 161; iter: 0; batch classifier loss: 0.096067; batch adversarial loss: 0.403661\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046336; batch adversarial loss: 0.418703\n",
      "epoch 163; iter: 0; batch classifier loss: 0.149644; batch adversarial loss: 0.434158\n",
      "epoch 164; iter: 0; batch classifier loss: 0.120365; batch adversarial loss: 0.510738\n",
      "epoch 165; iter: 0; batch classifier loss: 0.076547; batch adversarial loss: 0.462286\n",
      "epoch 166; iter: 0; batch classifier loss: 0.178858; batch adversarial loss: 0.559558\n",
      "epoch 167; iter: 0; batch classifier loss: 0.101821; batch adversarial loss: 0.513052\n",
      "epoch 168; iter: 0; batch classifier loss: 0.128682; batch adversarial loss: 0.525045\n",
      "epoch 169; iter: 0; batch classifier loss: 0.099974; batch adversarial loss: 0.452645\n",
      "epoch 170; iter: 0; batch classifier loss: 0.067354; batch adversarial loss: 0.424852\n",
      "epoch 171; iter: 0; batch classifier loss: 0.117102; batch adversarial loss: 0.474698\n",
      "epoch 172; iter: 0; batch classifier loss: 0.081946; batch adversarial loss: 0.443635\n",
      "epoch 173; iter: 0; batch classifier loss: 0.078167; batch adversarial loss: 0.427742\n",
      "epoch 174; iter: 0; batch classifier loss: 0.115319; batch adversarial loss: 0.523700\n",
      "epoch 175; iter: 0; batch classifier loss: 0.123064; batch adversarial loss: 0.556873\n",
      "epoch 176; iter: 0; batch classifier loss: 0.109343; batch adversarial loss: 0.472230\n",
      "epoch 177; iter: 0; batch classifier loss: 0.063451; batch adversarial loss: 0.502972\n",
      "epoch 178; iter: 0; batch classifier loss: 0.046632; batch adversarial loss: 0.467111\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043344; batch adversarial loss: 0.483500\n",
      "epoch 180; iter: 0; batch classifier loss: 0.033115; batch adversarial loss: 0.409202\n",
      "epoch 181; iter: 0; batch classifier loss: 0.040532; batch adversarial loss: 0.416069\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027296; batch adversarial loss: 0.450043\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042960; batch adversarial loss: 0.422394\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027516; batch adversarial loss: 0.463355\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029141; batch adversarial loss: 0.393170\n",
      "epoch 186; iter: 0; batch classifier loss: 0.043174; batch adversarial loss: 0.471412\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025209; batch adversarial loss: 0.373910\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033496; batch adversarial loss: 0.519623\n",
      "epoch 189; iter: 0; batch classifier loss: 0.046221; batch adversarial loss: 0.481910\n",
      "epoch 190; iter: 0; batch classifier loss: 0.070676; batch adversarial loss: 0.449853\n",
      "epoch 191; iter: 0; batch classifier loss: 0.111494; batch adversarial loss: 0.462514\n",
      "epoch 192; iter: 0; batch classifier loss: 0.090474; batch adversarial loss: 0.442854\n",
      "epoch 193; iter: 0; batch classifier loss: 0.049360; batch adversarial loss: 0.392501\n",
      "epoch 194; iter: 0; batch classifier loss: 0.078471; batch adversarial loss: 0.453227\n",
      "epoch 195; iter: 0; batch classifier loss: 0.051910; batch adversarial loss: 0.494716\n",
      "epoch 196; iter: 0; batch classifier loss: 0.086373; batch adversarial loss: 0.406020\n",
      "epoch 197; iter: 0; batch classifier loss: 0.091394; batch adversarial loss: 0.467128\n",
      "epoch 198; iter: 0; batch classifier loss: 0.075251; batch adversarial loss: 0.419971\n",
      "epoch 199; iter: 0; batch classifier loss: 0.073300; batch adversarial loss: 0.514458\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688965; batch adversarial loss: 0.626732\n",
      "epoch 1; iter: 0; batch classifier loss: 0.428064; batch adversarial loss: 0.631034\n",
      "epoch 2; iter: 0; batch classifier loss: 0.284219; batch adversarial loss: 0.606285\n",
      "epoch 3; iter: 0; batch classifier loss: 0.354466; batch adversarial loss: 0.579862\n",
      "epoch 4; iter: 0; batch classifier loss: 0.389755; batch adversarial loss: 0.543469\n",
      "epoch 5; iter: 0; batch classifier loss: 0.313615; batch adversarial loss: 0.541010\n",
      "epoch 6; iter: 0; batch classifier loss: 0.281362; batch adversarial loss: 0.536257\n",
      "epoch 7; iter: 0; batch classifier loss: 0.287174; batch adversarial loss: 0.531343\n",
      "epoch 8; iter: 0; batch classifier loss: 0.353644; batch adversarial loss: 0.551829\n",
      "epoch 9; iter: 0; batch classifier loss: 0.278383; batch adversarial loss: 0.528582\n",
      "epoch 10; iter: 0; batch classifier loss: 0.234484; batch adversarial loss: 0.436665\n",
      "epoch 11; iter: 0; batch classifier loss: 0.239656; batch adversarial loss: 0.509651\n",
      "epoch 12; iter: 0; batch classifier loss: 0.192955; batch adversarial loss: 0.501903\n",
      "epoch 13; iter: 0; batch classifier loss: 0.205891; batch adversarial loss: 0.502890\n",
      "epoch 14; iter: 0; batch classifier loss: 0.230268; batch adversarial loss: 0.454150\n",
      "epoch 15; iter: 0; batch classifier loss: 0.260213; batch adversarial loss: 0.555085\n",
      "epoch 16; iter: 0; batch classifier loss: 0.221462; batch adversarial loss: 0.511026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.263325; batch adversarial loss: 0.553536\n",
      "epoch 18; iter: 0; batch classifier loss: 0.319437; batch adversarial loss: 0.500707\n",
      "epoch 19; iter: 0; batch classifier loss: 0.303000; batch adversarial loss: 0.475827\n",
      "epoch 20; iter: 0; batch classifier loss: 0.462061; batch adversarial loss: 0.545199\n",
      "epoch 21; iter: 0; batch classifier loss: 0.553980; batch adversarial loss: 0.424927\n",
      "epoch 22; iter: 0; batch classifier loss: 0.291433; batch adversarial loss: 0.489910\n",
      "epoch 23; iter: 0; batch classifier loss: 0.232997; batch adversarial loss: 0.517429\n",
      "epoch 24; iter: 0; batch classifier loss: 0.147881; batch adversarial loss: 0.496981\n",
      "epoch 25; iter: 0; batch classifier loss: 0.184138; batch adversarial loss: 0.400983\n",
      "epoch 26; iter: 0; batch classifier loss: 0.221900; batch adversarial loss: 0.495897\n",
      "epoch 27; iter: 0; batch classifier loss: 0.206175; batch adversarial loss: 0.494813\n",
      "epoch 28; iter: 0; batch classifier loss: 0.157138; batch adversarial loss: 0.490984\n",
      "epoch 29; iter: 0; batch classifier loss: 0.181833; batch adversarial loss: 0.422213\n",
      "epoch 30; iter: 0; batch classifier loss: 0.160360; batch adversarial loss: 0.497271\n",
      "epoch 31; iter: 0; batch classifier loss: 0.121251; batch adversarial loss: 0.456789\n",
      "epoch 32; iter: 0; batch classifier loss: 0.147815; batch adversarial loss: 0.470321\n",
      "epoch 33; iter: 0; batch classifier loss: 0.149163; batch adversarial loss: 0.412086\n",
      "epoch 34; iter: 0; batch classifier loss: 0.167641; batch adversarial loss: 0.486778\n",
      "epoch 35; iter: 0; batch classifier loss: 0.083305; batch adversarial loss: 0.449023\n",
      "epoch 36; iter: 0; batch classifier loss: 0.164209; batch adversarial loss: 0.446643\n",
      "epoch 37; iter: 0; batch classifier loss: 0.115931; batch adversarial loss: 0.504053\n",
      "epoch 38; iter: 0; batch classifier loss: 0.090954; batch adversarial loss: 0.542152\n",
      "epoch 39; iter: 0; batch classifier loss: 0.103246; batch adversarial loss: 0.521369\n",
      "epoch 40; iter: 0; batch classifier loss: 0.098778; batch adversarial loss: 0.405016\n",
      "epoch 41; iter: 0; batch classifier loss: 0.145861; batch adversarial loss: 0.367264\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110393; batch adversarial loss: 0.452717\n",
      "epoch 43; iter: 0; batch classifier loss: 0.141018; batch adversarial loss: 0.488229\n",
      "epoch 44; iter: 0; batch classifier loss: 0.109094; batch adversarial loss: 0.373317\n",
      "epoch 45; iter: 0; batch classifier loss: 0.171377; batch adversarial loss: 0.474950\n",
      "epoch 46; iter: 0; batch classifier loss: 0.101097; batch adversarial loss: 0.542280\n",
      "epoch 47; iter: 0; batch classifier loss: 0.089574; batch adversarial loss: 0.460311\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081368; batch adversarial loss: 0.473535\n",
      "epoch 49; iter: 0; batch classifier loss: 0.126606; batch adversarial loss: 0.489302\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096689; batch adversarial loss: 0.452978\n",
      "epoch 51; iter: 0; batch classifier loss: 0.079496; batch adversarial loss: 0.514053\n",
      "epoch 52; iter: 0; batch classifier loss: 0.128354; batch adversarial loss: 0.457489\n",
      "epoch 53; iter: 0; batch classifier loss: 0.113104; batch adversarial loss: 0.426150\n",
      "epoch 54; iter: 0; batch classifier loss: 0.148049; batch adversarial loss: 0.411366\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087751; batch adversarial loss: 0.476515\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081771; batch adversarial loss: 0.463242\n",
      "epoch 57; iter: 0; batch classifier loss: 0.110378; batch adversarial loss: 0.360999\n",
      "epoch 58; iter: 0; batch classifier loss: 0.062426; batch adversarial loss: 0.442058\n",
      "epoch 59; iter: 0; batch classifier loss: 0.152776; batch adversarial loss: 0.425229\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065984; batch adversarial loss: 0.489145\n",
      "epoch 61; iter: 0; batch classifier loss: 0.099984; batch adversarial loss: 0.469550\n",
      "epoch 62; iter: 0; batch classifier loss: 0.166547; batch adversarial loss: 0.431053\n",
      "epoch 63; iter: 0; batch classifier loss: 0.078911; batch adversarial loss: 0.463878\n",
      "epoch 64; iter: 0; batch classifier loss: 0.097813; batch adversarial loss: 0.409400\n",
      "epoch 65; iter: 0; batch classifier loss: 0.115649; batch adversarial loss: 0.410933\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060552; batch adversarial loss: 0.428988\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079948; batch adversarial loss: 0.587683\n",
      "epoch 68; iter: 0; batch classifier loss: 0.108367; batch adversarial loss: 0.489195\n",
      "epoch 69; iter: 0; batch classifier loss: 0.125052; batch adversarial loss: 0.555737\n",
      "epoch 70; iter: 0; batch classifier loss: 0.124756; batch adversarial loss: 0.398437\n",
      "epoch 71; iter: 0; batch classifier loss: 0.125502; batch adversarial loss: 0.373212\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077731; batch adversarial loss: 0.490197\n",
      "epoch 73; iter: 0; batch classifier loss: 0.155969; batch adversarial loss: 0.478981\n",
      "epoch 74; iter: 0; batch classifier loss: 0.121351; batch adversarial loss: 0.423203\n",
      "epoch 75; iter: 0; batch classifier loss: 0.118590; batch adversarial loss: 0.453075\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075123; batch adversarial loss: 0.447188\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045987; batch adversarial loss: 0.469083\n",
      "epoch 78; iter: 0; batch classifier loss: 0.058857; batch adversarial loss: 0.524797\n",
      "epoch 79; iter: 0; batch classifier loss: 0.079655; batch adversarial loss: 0.501176\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060954; batch adversarial loss: 0.498946\n",
      "epoch 81; iter: 0; batch classifier loss: 0.058397; batch adversarial loss: 0.524098\n",
      "epoch 82; iter: 0; batch classifier loss: 0.084628; batch adversarial loss: 0.529803\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086820; batch adversarial loss: 0.445007\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070792; batch adversarial loss: 0.515664\n",
      "epoch 85; iter: 0; batch classifier loss: 0.117887; batch adversarial loss: 0.365372\n",
      "epoch 86; iter: 0; batch classifier loss: 0.091266; batch adversarial loss: 0.413560\n",
      "epoch 87; iter: 0; batch classifier loss: 0.093998; batch adversarial loss: 0.520564\n",
      "epoch 88; iter: 0; batch classifier loss: 0.134915; batch adversarial loss: 0.444589\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073855; batch adversarial loss: 0.488486\n",
      "epoch 90; iter: 0; batch classifier loss: 0.074453; batch adversarial loss: 0.495993\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064423; batch adversarial loss: 0.443323\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079842; batch adversarial loss: 0.407419\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046409; batch adversarial loss: 0.447078\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041105; batch adversarial loss: 0.406539\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087737; batch adversarial loss: 0.497310\n",
      "epoch 96; iter: 0; batch classifier loss: 0.033828; batch adversarial loss: 0.452259\n",
      "epoch 97; iter: 0; batch classifier loss: 0.110899; batch adversarial loss: 0.391360\n",
      "epoch 98; iter: 0; batch classifier loss: 0.064639; batch adversarial loss: 0.442745\n",
      "epoch 99; iter: 0; batch classifier loss: 0.079691; batch adversarial loss: 0.466322\n",
      "epoch 100; iter: 0; batch classifier loss: 0.030362; batch adversarial loss: 0.466932\n",
      "epoch 101; iter: 0; batch classifier loss: 0.077366; batch adversarial loss: 0.405686\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066096; batch adversarial loss: 0.492064\n",
      "epoch 103; iter: 0; batch classifier loss: 0.121334; batch adversarial loss: 0.393769\n",
      "epoch 104; iter: 0; batch classifier loss: 0.054738; batch adversarial loss: 0.493769\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034805; batch adversarial loss: 0.523560\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047598; batch adversarial loss: 0.424433\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033465; batch adversarial loss: 0.537116\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051280; batch adversarial loss: 0.484277\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050053; batch adversarial loss: 0.359648\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069719; batch adversarial loss: 0.427296\n",
      "epoch 111; iter: 0; batch classifier loss: 0.097851; batch adversarial loss: 0.554290\n",
      "epoch 112; iter: 0; batch classifier loss: 0.018459; batch adversarial loss: 0.460114\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052840; batch adversarial loss: 0.362229\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068625; batch adversarial loss: 0.430625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 115; iter: 0; batch classifier loss: 0.075861; batch adversarial loss: 0.422666\n",
      "epoch 116; iter: 0; batch classifier loss: 0.072150; batch adversarial loss: 0.545996\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051380; batch adversarial loss: 0.473287\n",
      "epoch 118; iter: 0; batch classifier loss: 0.058767; batch adversarial loss: 0.500106\n",
      "epoch 119; iter: 0; batch classifier loss: 0.095132; batch adversarial loss: 0.476962\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043232; batch adversarial loss: 0.501735\n",
      "epoch 121; iter: 0; batch classifier loss: 0.066440; batch adversarial loss: 0.416268\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039272; batch adversarial loss: 0.436093\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030069; batch adversarial loss: 0.441106\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039802; batch adversarial loss: 0.368227\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040398; batch adversarial loss: 0.534675\n",
      "epoch 126; iter: 0; batch classifier loss: 0.080045; batch adversarial loss: 0.507840\n",
      "epoch 127; iter: 0; batch classifier loss: 0.041695; batch adversarial loss: 0.525813\n",
      "epoch 128; iter: 0; batch classifier loss: 0.128274; batch adversarial loss: 0.361317\n",
      "epoch 129; iter: 0; batch classifier loss: 0.070370; batch adversarial loss: 0.405322\n",
      "epoch 130; iter: 0; batch classifier loss: 0.086224; batch adversarial loss: 0.410960\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046793; batch adversarial loss: 0.457772\n",
      "epoch 132; iter: 0; batch classifier loss: 0.063461; batch adversarial loss: 0.441762\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038692; batch adversarial loss: 0.528019\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028541; batch adversarial loss: 0.372620\n",
      "epoch 135; iter: 0; batch classifier loss: 0.060045; batch adversarial loss: 0.441173\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043540; batch adversarial loss: 0.417736\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028690; batch adversarial loss: 0.425690\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049406; batch adversarial loss: 0.393064\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042503; batch adversarial loss: 0.478352\n",
      "epoch 140; iter: 0; batch classifier loss: 0.042787; batch adversarial loss: 0.488937\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029244; batch adversarial loss: 0.450769\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037580; batch adversarial loss: 0.506437\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019539; batch adversarial loss: 0.430351\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021370; batch adversarial loss: 0.459633\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041476; batch adversarial loss: 0.486300\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017249; batch adversarial loss: 0.490299\n",
      "epoch 147; iter: 0; batch classifier loss: 0.045624; batch adversarial loss: 0.502067\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042358; batch adversarial loss: 0.427272\n",
      "epoch 149; iter: 0; batch classifier loss: 0.056406; batch adversarial loss: 0.469123\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033394; batch adversarial loss: 0.497021\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023082; batch adversarial loss: 0.488038\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039841; batch adversarial loss: 0.362260\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042940; batch adversarial loss: 0.421489\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017848; batch adversarial loss: 0.416555\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046610; batch adversarial loss: 0.513147\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030863; batch adversarial loss: 0.520907\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012449; batch adversarial loss: 0.496536\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026841; batch adversarial loss: 0.497310\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027260; batch adversarial loss: 0.367340\n",
      "epoch 160; iter: 0; batch classifier loss: 0.050500; batch adversarial loss: 0.384389\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018171; batch adversarial loss: 0.435852\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022993; batch adversarial loss: 0.427413\n",
      "epoch 163; iter: 0; batch classifier loss: 0.046301; batch adversarial loss: 0.505671\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023081; batch adversarial loss: 0.464208\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026564; batch adversarial loss: 0.503806\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024496; batch adversarial loss: 0.391086\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013876; batch adversarial loss: 0.468918\n",
      "epoch 168; iter: 0; batch classifier loss: 0.060635; batch adversarial loss: 0.394636\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024267; batch adversarial loss: 0.467333\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013333; batch adversarial loss: 0.485659\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038233; batch adversarial loss: 0.379598\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032748; batch adversarial loss: 0.505286\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026261; batch adversarial loss: 0.513050\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030326; batch adversarial loss: 0.444468\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029341; batch adversarial loss: 0.475464\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026848; batch adversarial loss: 0.420476\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037723; batch adversarial loss: 0.484577\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023825; batch adversarial loss: 0.365251\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013222; batch adversarial loss: 0.440099\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008268; batch adversarial loss: 0.418638\n",
      "epoch 181; iter: 0; batch classifier loss: 0.005975; batch adversarial loss: 0.439414\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027703; batch adversarial loss: 0.484377\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036790; batch adversarial loss: 0.420930\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011267; batch adversarial loss: 0.400129\n",
      "epoch 185; iter: 0; batch classifier loss: 0.034762; batch adversarial loss: 0.474434\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012124; batch adversarial loss: 0.513637\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024335; batch adversarial loss: 0.500378\n",
      "epoch 188; iter: 0; batch classifier loss: 0.051696; batch adversarial loss: 0.431084\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036799; batch adversarial loss: 0.502095\n",
      "epoch 190; iter: 0; batch classifier loss: 0.054745; batch adversarial loss: 0.466599\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032397; batch adversarial loss: 0.432782\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029263; batch adversarial loss: 0.424486\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021371; batch adversarial loss: 0.405384\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016045; batch adversarial loss: 0.410749\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017950; batch adversarial loss: 0.373254\n",
      "epoch 196; iter: 0; batch classifier loss: 0.039120; batch adversarial loss: 0.465017\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033465; batch adversarial loss: 0.406878\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019535; batch adversarial loss: 0.442852\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014571; batch adversarial loss: 0.437775\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681108; batch adversarial loss: 0.733570\n",
      "epoch 1; iter: 0; batch classifier loss: 0.546826; batch adversarial loss: 0.657010\n",
      "epoch 2; iter: 0; batch classifier loss: 0.343206; batch adversarial loss: 0.592782\n",
      "epoch 3; iter: 0; batch classifier loss: 0.423960; batch adversarial loss: 0.595021\n",
      "epoch 4; iter: 0; batch classifier loss: 0.294512; batch adversarial loss: 0.586608\n",
      "epoch 5; iter: 0; batch classifier loss: 0.400061; batch adversarial loss: 0.544369\n",
      "epoch 6; iter: 0; batch classifier loss: 0.289553; batch adversarial loss: 0.532686\n",
      "epoch 7; iter: 0; batch classifier loss: 0.377656; batch adversarial loss: 0.489648\n",
      "epoch 8; iter: 0; batch classifier loss: 0.200979; batch adversarial loss: 0.543919\n",
      "epoch 9; iter: 0; batch classifier loss: 0.311124; batch adversarial loss: 0.511667\n",
      "epoch 10; iter: 0; batch classifier loss: 0.272990; batch adversarial loss: 0.486607\n",
      "epoch 11; iter: 0; batch classifier loss: 0.291562; batch adversarial loss: 0.460713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.297435; batch adversarial loss: 0.475439\n",
      "epoch 13; iter: 0; batch classifier loss: 0.221857; batch adversarial loss: 0.468605\n",
      "epoch 14; iter: 0; batch classifier loss: 0.327574; batch adversarial loss: 0.459798\n",
      "epoch 15; iter: 0; batch classifier loss: 0.273864; batch adversarial loss: 0.513450\n",
      "epoch 16; iter: 0; batch classifier loss: 0.153934; batch adversarial loss: 0.473735\n",
      "epoch 17; iter: 0; batch classifier loss: 0.213447; batch adversarial loss: 0.476497\n",
      "epoch 18; iter: 0; batch classifier loss: 0.198031; batch adversarial loss: 0.519443\n",
      "epoch 19; iter: 0; batch classifier loss: 0.208915; batch adversarial loss: 0.427636\n",
      "epoch 20; iter: 0; batch classifier loss: 0.211731; batch adversarial loss: 0.403102\n",
      "epoch 21; iter: 0; batch classifier loss: 0.194270; batch adversarial loss: 0.424097\n",
      "epoch 22; iter: 0; batch classifier loss: 0.215002; batch adversarial loss: 0.429928\n",
      "epoch 23; iter: 0; batch classifier loss: 0.137969; batch adversarial loss: 0.482564\n",
      "epoch 24; iter: 0; batch classifier loss: 0.196740; batch adversarial loss: 0.448193\n",
      "epoch 25; iter: 0; batch classifier loss: 0.200816; batch adversarial loss: 0.443184\n",
      "epoch 26; iter: 0; batch classifier loss: 0.131778; batch adversarial loss: 0.425300\n",
      "epoch 27; iter: 0; batch classifier loss: 0.153665; batch adversarial loss: 0.504280\n",
      "epoch 28; iter: 0; batch classifier loss: 0.219040; batch adversarial loss: 0.450838\n",
      "epoch 29; iter: 0; batch classifier loss: 0.128623; batch adversarial loss: 0.418913\n",
      "epoch 30; iter: 0; batch classifier loss: 0.156711; batch adversarial loss: 0.449257\n",
      "epoch 31; iter: 0; batch classifier loss: 0.152085; batch adversarial loss: 0.491416\n",
      "epoch 32; iter: 0; batch classifier loss: 0.144908; batch adversarial loss: 0.462896\n",
      "epoch 33; iter: 0; batch classifier loss: 0.092384; batch adversarial loss: 0.456299\n",
      "epoch 34; iter: 0; batch classifier loss: 0.140546; batch adversarial loss: 0.518182\n",
      "epoch 35; iter: 0; batch classifier loss: 0.120622; batch adversarial loss: 0.414736\n",
      "epoch 36; iter: 0; batch classifier loss: 0.146504; batch adversarial loss: 0.438835\n",
      "epoch 37; iter: 0; batch classifier loss: 0.178349; batch adversarial loss: 0.596436\n",
      "epoch 38; iter: 0; batch classifier loss: 0.100848; batch adversarial loss: 0.396477\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106759; batch adversarial loss: 0.341334\n",
      "epoch 40; iter: 0; batch classifier loss: 0.137691; batch adversarial loss: 0.446619\n",
      "epoch 41; iter: 0; batch classifier loss: 0.137526; batch adversarial loss: 0.467803\n",
      "epoch 42; iter: 0; batch classifier loss: 0.109933; batch adversarial loss: 0.408720\n",
      "epoch 43; iter: 0; batch classifier loss: 0.090336; batch adversarial loss: 0.503822\n",
      "epoch 44; iter: 0; batch classifier loss: 0.125803; batch adversarial loss: 0.426734\n",
      "epoch 45; iter: 0; batch classifier loss: 0.087547; batch adversarial loss: 0.359695\n",
      "epoch 46; iter: 0; batch classifier loss: 0.129360; batch adversarial loss: 0.403818\n",
      "epoch 47; iter: 0; batch classifier loss: 0.085145; batch adversarial loss: 0.469294\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099968; batch adversarial loss: 0.371986\n",
      "epoch 49; iter: 0; batch classifier loss: 0.112641; batch adversarial loss: 0.424664\n",
      "epoch 50; iter: 0; batch classifier loss: 0.076517; batch adversarial loss: 0.307615\n",
      "epoch 51; iter: 0; batch classifier loss: 0.082104; batch adversarial loss: 0.397290\n",
      "epoch 52; iter: 0; batch classifier loss: 0.110229; batch adversarial loss: 0.404529\n",
      "epoch 53; iter: 0; batch classifier loss: 0.121352; batch adversarial loss: 0.434173\n",
      "epoch 54; iter: 0; batch classifier loss: 0.091629; batch adversarial loss: 0.421377\n",
      "epoch 55; iter: 0; batch classifier loss: 0.126617; batch adversarial loss: 0.527687\n",
      "epoch 56; iter: 0; batch classifier loss: 0.111181; batch adversarial loss: 0.560230\n",
      "epoch 57; iter: 0; batch classifier loss: 0.132124; batch adversarial loss: 0.517467\n",
      "epoch 58; iter: 0; batch classifier loss: 0.099149; batch adversarial loss: 0.393534\n",
      "epoch 59; iter: 0; batch classifier loss: 0.115313; batch adversarial loss: 0.505602\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122157; batch adversarial loss: 0.542649\n",
      "epoch 61; iter: 0; batch classifier loss: 0.148216; batch adversarial loss: 0.417647\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093823; batch adversarial loss: 0.466468\n",
      "epoch 63; iter: 0; batch classifier loss: 0.109421; batch adversarial loss: 0.437367\n",
      "epoch 64; iter: 0; batch classifier loss: 0.096124; batch adversarial loss: 0.509739\n",
      "epoch 65; iter: 0; batch classifier loss: 0.121490; batch adversarial loss: 0.532936\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092969; batch adversarial loss: 0.511119\n",
      "epoch 67; iter: 0; batch classifier loss: 0.135057; batch adversarial loss: 0.428314\n",
      "epoch 68; iter: 0; batch classifier loss: 0.119703; batch adversarial loss: 0.415122\n",
      "epoch 69; iter: 0; batch classifier loss: 0.090513; batch adversarial loss: 0.470258\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079621; batch adversarial loss: 0.374545\n",
      "epoch 71; iter: 0; batch classifier loss: 0.051822; batch adversarial loss: 0.509858\n",
      "epoch 72; iter: 0; batch classifier loss: 0.075242; batch adversarial loss: 0.372034\n",
      "epoch 73; iter: 0; batch classifier loss: 0.129554; batch adversarial loss: 0.419971\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076536; batch adversarial loss: 0.398325\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071463; batch adversarial loss: 0.444404\n",
      "epoch 76; iter: 0; batch classifier loss: 0.109226; batch adversarial loss: 0.396232\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087108; batch adversarial loss: 0.476727\n",
      "epoch 78; iter: 0; batch classifier loss: 0.130165; batch adversarial loss: 0.431252\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063657; batch adversarial loss: 0.392314\n",
      "epoch 80; iter: 0; batch classifier loss: 0.092366; batch adversarial loss: 0.510709\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050382; batch adversarial loss: 0.514484\n",
      "epoch 82; iter: 0; batch classifier loss: 0.032649; batch adversarial loss: 0.485258\n",
      "epoch 83; iter: 0; batch classifier loss: 0.055120; batch adversarial loss: 0.382259\n",
      "epoch 84; iter: 0; batch classifier loss: 0.103793; batch adversarial loss: 0.511119\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051039; batch adversarial loss: 0.388300\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084469; batch adversarial loss: 0.498376\n",
      "epoch 87; iter: 0; batch classifier loss: 0.113939; batch adversarial loss: 0.394282\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059761; batch adversarial loss: 0.411236\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057614; batch adversarial loss: 0.339158\n",
      "epoch 90; iter: 0; batch classifier loss: 0.107825; batch adversarial loss: 0.438066\n",
      "epoch 91; iter: 0; batch classifier loss: 0.087128; batch adversarial loss: 0.516291\n",
      "epoch 92; iter: 0; batch classifier loss: 0.094452; batch adversarial loss: 0.428827\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056962; batch adversarial loss: 0.482282\n",
      "epoch 94; iter: 0; batch classifier loss: 0.067469; batch adversarial loss: 0.548233\n",
      "epoch 95; iter: 0; batch classifier loss: 0.083549; batch adversarial loss: 0.432498\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082046; batch adversarial loss: 0.348662\n",
      "epoch 97; iter: 0; batch classifier loss: 0.061689; batch adversarial loss: 0.476607\n",
      "epoch 98; iter: 0; batch classifier loss: 0.041643; batch adversarial loss: 0.457368\n",
      "epoch 99; iter: 0; batch classifier loss: 0.079529; batch adversarial loss: 0.457740\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046291; batch adversarial loss: 0.441898\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070581; batch adversarial loss: 0.436781\n",
      "epoch 102; iter: 0; batch classifier loss: 0.115633; batch adversarial loss: 0.577472\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043342; batch adversarial loss: 0.476358\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059066; batch adversarial loss: 0.419643\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053425; batch adversarial loss: 0.416154\n",
      "epoch 106; iter: 0; batch classifier loss: 0.106497; batch adversarial loss: 0.405629\n",
      "epoch 107; iter: 0; batch classifier loss: 0.109661; batch adversarial loss: 0.426568\n",
      "epoch 108; iter: 0; batch classifier loss: 0.063997; batch adversarial loss: 0.382549\n",
      "epoch 109; iter: 0; batch classifier loss: 0.055837; batch adversarial loss: 0.438857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.015959; batch adversarial loss: 0.438361\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062363; batch adversarial loss: 0.425914\n",
      "epoch 112; iter: 0; batch classifier loss: 0.076371; batch adversarial loss: 0.606108\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045759; batch adversarial loss: 0.426164\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032538; batch adversarial loss: 0.383526\n",
      "epoch 115; iter: 0; batch classifier loss: 0.061472; batch adversarial loss: 0.528131\n",
      "epoch 116; iter: 0; batch classifier loss: 0.072216; batch adversarial loss: 0.446573\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050980; batch adversarial loss: 0.320290\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033591; batch adversarial loss: 0.479776\n",
      "epoch 119; iter: 0; batch classifier loss: 0.061879; batch adversarial loss: 0.453662\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053838; batch adversarial loss: 0.386288\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029346; batch adversarial loss: 0.473705\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046924; batch adversarial loss: 0.468746\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039537; batch adversarial loss: 0.431133\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046462; batch adversarial loss: 0.453748\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044622; batch adversarial loss: 0.455075\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038912; batch adversarial loss: 0.367611\n",
      "epoch 127; iter: 0; batch classifier loss: 0.066487; batch adversarial loss: 0.440057\n",
      "epoch 128; iter: 0; batch classifier loss: 0.095958; batch adversarial loss: 0.451317\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028332; batch adversarial loss: 0.394848\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032974; batch adversarial loss: 0.430394\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021542; batch adversarial loss: 0.347706\n",
      "epoch 132; iter: 0; batch classifier loss: 0.055937; batch adversarial loss: 0.363330\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040647; batch adversarial loss: 0.532198\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040565; batch adversarial loss: 0.405007\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024325; batch adversarial loss: 0.419733\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024193; batch adversarial loss: 0.438722\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027764; batch adversarial loss: 0.547386\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035958; batch adversarial loss: 0.421794\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045448; batch adversarial loss: 0.389292\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019842; batch adversarial loss: 0.377741\n",
      "epoch 141; iter: 0; batch classifier loss: 0.072272; batch adversarial loss: 0.512940\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048682; batch adversarial loss: 0.444316\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041432; batch adversarial loss: 0.372503\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029160; batch adversarial loss: 0.412817\n",
      "epoch 145; iter: 0; batch classifier loss: 0.047391; batch adversarial loss: 0.427115\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018308; batch adversarial loss: 0.440766\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010539; batch adversarial loss: 0.492106\n",
      "epoch 148; iter: 0; batch classifier loss: 0.047463; batch adversarial loss: 0.361010\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022523; batch adversarial loss: 0.352541\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034571; batch adversarial loss: 0.356466\n",
      "epoch 151; iter: 0; batch classifier loss: 0.053263; batch adversarial loss: 0.526209\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019390; batch adversarial loss: 0.430942\n",
      "epoch 153; iter: 0; batch classifier loss: 0.049550; batch adversarial loss: 0.554793\n",
      "epoch 154; iter: 0; batch classifier loss: 0.045309; batch adversarial loss: 0.383219\n",
      "epoch 155; iter: 0; batch classifier loss: 0.045294; batch adversarial loss: 0.465203\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024609; batch adversarial loss: 0.473623\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041061; batch adversarial loss: 0.485429\n",
      "epoch 158; iter: 0; batch classifier loss: 0.031178; batch adversarial loss: 0.449453\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024618; batch adversarial loss: 0.436281\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033431; batch adversarial loss: 0.462728\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040255; batch adversarial loss: 0.459502\n",
      "epoch 162; iter: 0; batch classifier loss: 0.059581; batch adversarial loss: 0.427918\n",
      "epoch 163; iter: 0; batch classifier loss: 0.063197; batch adversarial loss: 0.463982\n",
      "epoch 164; iter: 0; batch classifier loss: 0.044689; batch adversarial loss: 0.445973\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038795; batch adversarial loss: 0.456796\n",
      "epoch 166; iter: 0; batch classifier loss: 0.068717; batch adversarial loss: 0.356829\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019554; batch adversarial loss: 0.406555\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011612; batch adversarial loss: 0.396199\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030588; batch adversarial loss: 0.425875\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022256; batch adversarial loss: 0.489293\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016691; batch adversarial loss: 0.405892\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005914; batch adversarial loss: 0.483632\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037101; batch adversarial loss: 0.448214\n",
      "epoch 174; iter: 0; batch classifier loss: 0.052769; batch adversarial loss: 0.394247\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014516; batch adversarial loss: 0.420518\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014595; batch adversarial loss: 0.446416\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012258; batch adversarial loss: 0.468167\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032494; batch adversarial loss: 0.404266\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030006; batch adversarial loss: 0.458477\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027694; batch adversarial loss: 0.493239\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019357; batch adversarial loss: 0.416734\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021796; batch adversarial loss: 0.415779\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016936; batch adversarial loss: 0.423713\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024395; batch adversarial loss: 0.392735\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017290; batch adversarial loss: 0.438791\n",
      "epoch 186; iter: 0; batch classifier loss: 0.044925; batch adversarial loss: 0.380045\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031290; batch adversarial loss: 0.368986\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018093; batch adversarial loss: 0.386814\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023684; batch adversarial loss: 0.394586\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031760; batch adversarial loss: 0.472493\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006938; batch adversarial loss: 0.499791\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033662; batch adversarial loss: 0.498091\n",
      "epoch 193; iter: 0; batch classifier loss: 0.041610; batch adversarial loss: 0.453111\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019033; batch adversarial loss: 0.432626\n",
      "epoch 195; iter: 0; batch classifier loss: 0.040193; batch adversarial loss: 0.413317\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031163; batch adversarial loss: 0.441413\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006319; batch adversarial loss: 0.402253\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014720; batch adversarial loss: 0.509314\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022270; batch adversarial loss: 0.455074\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705864; batch adversarial loss: 0.493060\n",
      "epoch 1; iter: 0; batch classifier loss: 0.532157; batch adversarial loss: 0.565972\n",
      "epoch 2; iter: 0; batch classifier loss: 0.400552; batch adversarial loss: 0.570325\n",
      "epoch 3; iter: 0; batch classifier loss: 0.282107; batch adversarial loss: 0.530950\n",
      "epoch 4; iter: 0; batch classifier loss: 0.357411; batch adversarial loss: 0.624233\n",
      "epoch 5; iter: 0; batch classifier loss: 0.325429; batch adversarial loss: 0.618812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.350959; batch adversarial loss: 0.547090\n",
      "epoch 7; iter: 0; batch classifier loss: 0.298936; batch adversarial loss: 0.615984\n",
      "epoch 8; iter: 0; batch classifier loss: 0.308830; batch adversarial loss: 0.528561\n",
      "epoch 9; iter: 0; batch classifier loss: 0.260488; batch adversarial loss: 0.591482\n",
      "epoch 10; iter: 0; batch classifier loss: 0.334917; batch adversarial loss: 0.478319\n",
      "epoch 11; iter: 0; batch classifier loss: 0.376762; batch adversarial loss: 0.539380\n",
      "epoch 12; iter: 0; batch classifier loss: 0.396482; batch adversarial loss: 0.566648\n",
      "epoch 13; iter: 0; batch classifier loss: 0.398396; batch adversarial loss: 0.509096\n",
      "epoch 14; iter: 0; batch classifier loss: 0.315257; batch adversarial loss: 0.485490\n",
      "epoch 15; iter: 0; batch classifier loss: 0.294927; batch adversarial loss: 0.474775\n",
      "epoch 16; iter: 0; batch classifier loss: 0.211622; batch adversarial loss: 0.428551\n",
      "epoch 17; iter: 0; batch classifier loss: 0.225327; batch adversarial loss: 0.494379\n",
      "epoch 18; iter: 0; batch classifier loss: 0.241798; batch adversarial loss: 0.432458\n",
      "epoch 19; iter: 0; batch classifier loss: 0.125534; batch adversarial loss: 0.470233\n",
      "epoch 20; iter: 0; batch classifier loss: 0.181125; batch adversarial loss: 0.551199\n",
      "epoch 21; iter: 0; batch classifier loss: 0.162840; batch adversarial loss: 0.368837\n",
      "epoch 22; iter: 0; batch classifier loss: 0.197283; batch adversarial loss: 0.419488\n",
      "epoch 23; iter: 0; batch classifier loss: 0.188602; batch adversarial loss: 0.450307\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195464; batch adversarial loss: 0.385508\n",
      "epoch 25; iter: 0; batch classifier loss: 0.158588; batch adversarial loss: 0.428211\n",
      "epoch 26; iter: 0; batch classifier loss: 0.206065; batch adversarial loss: 0.357782\n",
      "epoch 27; iter: 0; batch classifier loss: 0.128728; batch adversarial loss: 0.529816\n",
      "epoch 28; iter: 0; batch classifier loss: 0.131591; batch adversarial loss: 0.453683\n",
      "epoch 29; iter: 0; batch classifier loss: 0.157356; batch adversarial loss: 0.526060\n",
      "epoch 30; iter: 0; batch classifier loss: 0.173779; batch adversarial loss: 0.422016\n",
      "epoch 31; iter: 0; batch classifier loss: 0.175408; batch adversarial loss: 0.477604\n",
      "epoch 32; iter: 0; batch classifier loss: 0.138137; batch adversarial loss: 0.470018\n",
      "epoch 33; iter: 0; batch classifier loss: 0.125400; batch adversarial loss: 0.459178\n",
      "epoch 34; iter: 0; batch classifier loss: 0.136474; batch adversarial loss: 0.474448\n",
      "epoch 35; iter: 0; batch classifier loss: 0.112856; batch adversarial loss: 0.482222\n",
      "epoch 36; iter: 0; batch classifier loss: 0.135457; batch adversarial loss: 0.441264\n",
      "epoch 37; iter: 0; batch classifier loss: 0.102275; batch adversarial loss: 0.495401\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117251; batch adversarial loss: 0.485041\n",
      "epoch 39; iter: 0; batch classifier loss: 0.154507; batch adversarial loss: 0.425054\n",
      "epoch 40; iter: 0; batch classifier loss: 0.100498; batch adversarial loss: 0.490134\n",
      "epoch 41; iter: 0; batch classifier loss: 0.107336; batch adversarial loss: 0.425773\n",
      "epoch 42; iter: 0; batch classifier loss: 0.104222; batch adversarial loss: 0.483724\n",
      "epoch 43; iter: 0; batch classifier loss: 0.135949; batch adversarial loss: 0.441372\n",
      "epoch 44; iter: 0; batch classifier loss: 0.107403; batch adversarial loss: 0.428902\n",
      "epoch 45; iter: 0; batch classifier loss: 0.134545; batch adversarial loss: 0.514667\n",
      "epoch 46; iter: 0; batch classifier loss: 0.105160; batch adversarial loss: 0.427155\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112662; batch adversarial loss: 0.444189\n",
      "epoch 48; iter: 0; batch classifier loss: 0.075394; batch adversarial loss: 0.442023\n",
      "epoch 49; iter: 0; batch classifier loss: 0.135345; batch adversarial loss: 0.411946\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074180; batch adversarial loss: 0.435003\n",
      "epoch 51; iter: 0; batch classifier loss: 0.125886; batch adversarial loss: 0.550337\n",
      "epoch 52; iter: 0; batch classifier loss: 0.090969; batch adversarial loss: 0.464802\n",
      "epoch 53; iter: 0; batch classifier loss: 0.132741; batch adversarial loss: 0.395529\n",
      "epoch 54; iter: 0; batch classifier loss: 0.131503; batch adversarial loss: 0.375612\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084433; batch adversarial loss: 0.435159\n",
      "epoch 56; iter: 0; batch classifier loss: 0.094144; batch adversarial loss: 0.446534\n",
      "epoch 57; iter: 0; batch classifier loss: 0.150539; batch adversarial loss: 0.490858\n",
      "epoch 58; iter: 0; batch classifier loss: 0.088839; batch adversarial loss: 0.449507\n",
      "epoch 59; iter: 0; batch classifier loss: 0.150417; batch adversarial loss: 0.445027\n",
      "epoch 60; iter: 0; batch classifier loss: 0.111406; batch adversarial loss: 0.496832\n",
      "epoch 61; iter: 0; batch classifier loss: 0.091521; batch adversarial loss: 0.473926\n",
      "epoch 62; iter: 0; batch classifier loss: 0.124585; batch adversarial loss: 0.415375\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097721; batch adversarial loss: 0.410158\n",
      "epoch 64; iter: 0; batch classifier loss: 0.127305; batch adversarial loss: 0.389296\n",
      "epoch 65; iter: 0; batch classifier loss: 0.173583; batch adversarial loss: 0.439629\n",
      "epoch 66; iter: 0; batch classifier loss: 0.142643; batch adversarial loss: 0.448263\n",
      "epoch 67; iter: 0; batch classifier loss: 0.075865; batch adversarial loss: 0.464428\n",
      "epoch 68; iter: 0; batch classifier loss: 0.118293; batch adversarial loss: 0.317528\n",
      "epoch 69; iter: 0; batch classifier loss: 0.113482; batch adversarial loss: 0.450120\n",
      "epoch 70; iter: 0; batch classifier loss: 0.101243; batch adversarial loss: 0.516652\n",
      "epoch 71; iter: 0; batch classifier loss: 0.148308; batch adversarial loss: 0.504026\n",
      "epoch 72; iter: 0; batch classifier loss: 0.126137; batch adversarial loss: 0.480509\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085814; batch adversarial loss: 0.427543\n",
      "epoch 74; iter: 0; batch classifier loss: 0.135125; batch adversarial loss: 0.352087\n",
      "epoch 75; iter: 0; batch classifier loss: 0.149843; batch adversarial loss: 0.418265\n",
      "epoch 76; iter: 0; batch classifier loss: 0.139562; batch adversarial loss: 0.482446\n",
      "epoch 77; iter: 0; batch classifier loss: 0.112689; batch adversarial loss: 0.501697\n",
      "epoch 78; iter: 0; batch classifier loss: 0.134241; batch adversarial loss: 0.418379\n",
      "epoch 79; iter: 0; batch classifier loss: 0.108501; batch adversarial loss: 0.416796\n",
      "epoch 80; iter: 0; batch classifier loss: 0.112777; batch adversarial loss: 0.416363\n",
      "epoch 81; iter: 0; batch classifier loss: 0.108293; batch adversarial loss: 0.397975\n",
      "epoch 82; iter: 0; batch classifier loss: 0.092939; batch adversarial loss: 0.500524\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078038; batch adversarial loss: 0.524036\n",
      "epoch 84; iter: 0; batch classifier loss: 0.125087; batch adversarial loss: 0.382265\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076986; batch adversarial loss: 0.541476\n",
      "epoch 86; iter: 0; batch classifier loss: 0.098084; batch adversarial loss: 0.585119\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054892; batch adversarial loss: 0.384789\n",
      "epoch 88; iter: 0; batch classifier loss: 0.110579; batch adversarial loss: 0.483557\n",
      "epoch 89; iter: 0; batch classifier loss: 0.147613; batch adversarial loss: 0.422430\n",
      "epoch 90; iter: 0; batch classifier loss: 0.085857; batch adversarial loss: 0.459571\n",
      "epoch 91; iter: 0; batch classifier loss: 0.102099; batch adversarial loss: 0.485148\n",
      "epoch 92; iter: 0; batch classifier loss: 0.088018; batch adversarial loss: 0.430922\n",
      "epoch 93; iter: 0; batch classifier loss: 0.088657; batch adversarial loss: 0.417114\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042215; batch adversarial loss: 0.441655\n",
      "epoch 95; iter: 0; batch classifier loss: 0.098768; batch adversarial loss: 0.528221\n",
      "epoch 96; iter: 0; batch classifier loss: 0.084231; batch adversarial loss: 0.448418\n",
      "epoch 97; iter: 0; batch classifier loss: 0.088820; batch adversarial loss: 0.376389\n",
      "epoch 98; iter: 0; batch classifier loss: 0.060994; batch adversarial loss: 0.493923\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078429; batch adversarial loss: 0.475531\n",
      "epoch 100; iter: 0; batch classifier loss: 0.108610; batch adversarial loss: 0.414125\n",
      "epoch 101; iter: 0; batch classifier loss: 0.102549; batch adversarial loss: 0.415115\n",
      "epoch 102; iter: 0; batch classifier loss: 0.102904; batch adversarial loss: 0.472622\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050983; batch adversarial loss: 0.450438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.108249; batch adversarial loss: 0.405552\n",
      "epoch 105; iter: 0; batch classifier loss: 0.073763; batch adversarial loss: 0.499417\n",
      "epoch 106; iter: 0; batch classifier loss: 0.069185; batch adversarial loss: 0.450077\n",
      "epoch 107; iter: 0; batch classifier loss: 0.097119; batch adversarial loss: 0.509041\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039251; batch adversarial loss: 0.560148\n",
      "epoch 109; iter: 0; batch classifier loss: 0.095075; batch adversarial loss: 0.421946\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044263; batch adversarial loss: 0.395552\n",
      "epoch 111; iter: 0; batch classifier loss: 0.070054; batch adversarial loss: 0.421822\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053295; batch adversarial loss: 0.432387\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056476; batch adversarial loss: 0.481813\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057284; batch adversarial loss: 0.424793\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045499; batch adversarial loss: 0.534064\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027023; batch adversarial loss: 0.463930\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035057; batch adversarial loss: 0.338262\n",
      "epoch 118; iter: 0; batch classifier loss: 0.053718; batch adversarial loss: 0.502549\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048744; batch adversarial loss: 0.385580\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062613; batch adversarial loss: 0.451710\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034570; batch adversarial loss: 0.459209\n",
      "epoch 122; iter: 0; batch classifier loss: 0.053723; batch adversarial loss: 0.545778\n",
      "epoch 123; iter: 0; batch classifier loss: 0.070943; batch adversarial loss: 0.476922\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033164; batch adversarial loss: 0.505849\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051292; batch adversarial loss: 0.448401\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026381; batch adversarial loss: 0.501066\n",
      "epoch 127; iter: 0; batch classifier loss: 0.056405; batch adversarial loss: 0.449308\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032324; batch adversarial loss: 0.531248\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042878; batch adversarial loss: 0.366458\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048065; batch adversarial loss: 0.524146\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052271; batch adversarial loss: 0.502827\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040701; batch adversarial loss: 0.415539\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031855; batch adversarial loss: 0.554756\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038011; batch adversarial loss: 0.387426\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041034; batch adversarial loss: 0.376734\n",
      "epoch 136; iter: 0; batch classifier loss: 0.079486; batch adversarial loss: 0.547145\n",
      "epoch 137; iter: 0; batch classifier loss: 0.079938; batch adversarial loss: 0.438335\n",
      "epoch 138; iter: 0; batch classifier loss: 0.055847; batch adversarial loss: 0.488507\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046306; batch adversarial loss: 0.406957\n",
      "epoch 140; iter: 0; batch classifier loss: 0.012127; batch adversarial loss: 0.441813\n",
      "epoch 141; iter: 0; batch classifier loss: 0.007464; batch adversarial loss: 0.485299\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044030; batch adversarial loss: 0.435640\n",
      "epoch 143; iter: 0; batch classifier loss: 0.044458; batch adversarial loss: 0.457747\n",
      "epoch 144; iter: 0; batch classifier loss: 0.061558; batch adversarial loss: 0.406039\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027950; batch adversarial loss: 0.450259\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048105; batch adversarial loss: 0.470810\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017868; batch adversarial loss: 0.523805\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025759; batch adversarial loss: 0.378195\n",
      "epoch 149; iter: 0; batch classifier loss: 0.049721; batch adversarial loss: 0.404495\n",
      "epoch 150; iter: 0; batch classifier loss: 0.059068; batch adversarial loss: 0.593261\n",
      "epoch 151; iter: 0; batch classifier loss: 0.010720; batch adversarial loss: 0.606466\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032981; batch adversarial loss: 0.465556\n",
      "epoch 153; iter: 0; batch classifier loss: 0.033447; batch adversarial loss: 0.525542\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029106; batch adversarial loss: 0.475516\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030644; batch adversarial loss: 0.450430\n",
      "epoch 156; iter: 0; batch classifier loss: 0.046734; batch adversarial loss: 0.386428\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018331; batch adversarial loss: 0.489594\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016291; batch adversarial loss: 0.418380\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035353; batch adversarial loss: 0.427696\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032905; batch adversarial loss: 0.522812\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028140; batch adversarial loss: 0.460590\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034864; batch adversarial loss: 0.421248\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028672; batch adversarial loss: 0.459301\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021279; batch adversarial loss: 0.452107\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013983; batch adversarial loss: 0.467752\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018366; batch adversarial loss: 0.415191\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036861; batch adversarial loss: 0.457587\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013790; batch adversarial loss: 0.382558\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017366; batch adversarial loss: 0.503522\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014735; batch adversarial loss: 0.460192\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023929; batch adversarial loss: 0.501320\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015916; batch adversarial loss: 0.401358\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031133; batch adversarial loss: 0.409753\n",
      "epoch 174; iter: 0; batch classifier loss: 0.048084; batch adversarial loss: 0.566491\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020191; batch adversarial loss: 0.490486\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015430; batch adversarial loss: 0.446491\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021912; batch adversarial loss: 0.436438\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017047; batch adversarial loss: 0.510300\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034131; batch adversarial loss: 0.407835\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040520; batch adversarial loss: 0.451134\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006576; batch adversarial loss: 0.476734\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017970; batch adversarial loss: 0.362939\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036002; batch adversarial loss: 0.402822\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037296; batch adversarial loss: 0.473108\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028300; batch adversarial loss: 0.444911\n",
      "epoch 186; iter: 0; batch classifier loss: 0.048221; batch adversarial loss: 0.438923\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011018; batch adversarial loss: 0.387699\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040494; batch adversarial loss: 0.382281\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019825; batch adversarial loss: 0.394028\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009874; batch adversarial loss: 0.352594\n",
      "epoch 191; iter: 0; batch classifier loss: 0.036000; batch adversarial loss: 0.434966\n",
      "epoch 192; iter: 0; batch classifier loss: 0.052520; batch adversarial loss: 0.488268\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015861; batch adversarial loss: 0.393864\n",
      "epoch 194; iter: 0; batch classifier loss: 0.042880; batch adversarial loss: 0.542218\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004077; batch adversarial loss: 0.378753\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037334; batch adversarial loss: 0.392728\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007602; batch adversarial loss: 0.490637\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011482; batch adversarial loss: 0.401702\n",
      "epoch 199; iter: 0; batch classifier loss: 0.058926; batch adversarial loss: 0.458801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.689786; batch adversarial loss: 0.579024\n",
      "epoch 1; iter: 0; batch classifier loss: 0.432469; batch adversarial loss: 0.610413\n",
      "epoch 2; iter: 0; batch classifier loss: 0.334748; batch adversarial loss: 0.602710\n",
      "epoch 3; iter: 0; batch classifier loss: 0.378060; batch adversarial loss: 0.587593\n",
      "epoch 4; iter: 0; batch classifier loss: 0.286868; batch adversarial loss: 0.523222\n",
      "epoch 5; iter: 0; batch classifier loss: 0.292814; batch adversarial loss: 0.597063\n",
      "epoch 6; iter: 0; batch classifier loss: 0.386665; batch adversarial loss: 0.580391\n",
      "epoch 7; iter: 0; batch classifier loss: 0.326913; batch adversarial loss: 0.578457\n",
      "epoch 8; iter: 0; batch classifier loss: 0.394772; batch adversarial loss: 0.558485\n",
      "epoch 9; iter: 0; batch classifier loss: 0.304752; batch adversarial loss: 0.578424\n",
      "epoch 10; iter: 0; batch classifier loss: 0.316596; batch adversarial loss: 0.588925\n",
      "epoch 11; iter: 0; batch classifier loss: 0.344737; batch adversarial loss: 0.581029\n",
      "epoch 12; iter: 0; batch classifier loss: 0.399308; batch adversarial loss: 0.525710\n",
      "epoch 13; iter: 0; batch classifier loss: 0.579909; batch adversarial loss: 0.556006\n",
      "epoch 14; iter: 0; batch classifier loss: 0.562266; batch adversarial loss: 0.569197\n",
      "epoch 15; iter: 0; batch classifier loss: 0.400152; batch adversarial loss: 0.505067\n",
      "epoch 16; iter: 0; batch classifier loss: 0.344353; batch adversarial loss: 0.548646\n",
      "epoch 17; iter: 0; batch classifier loss: 0.223496; batch adversarial loss: 0.494673\n",
      "epoch 18; iter: 0; batch classifier loss: 0.169373; batch adversarial loss: 0.520391\n",
      "epoch 19; iter: 0; batch classifier loss: 0.181682; batch adversarial loss: 0.544406\n",
      "epoch 20; iter: 0; batch classifier loss: 0.168713; batch adversarial loss: 0.459468\n",
      "epoch 21; iter: 0; batch classifier loss: 0.170674; batch adversarial loss: 0.490553\n",
      "epoch 22; iter: 0; batch classifier loss: 0.172348; batch adversarial loss: 0.425158\n",
      "epoch 23; iter: 0; batch classifier loss: 0.130080; batch adversarial loss: 0.427800\n",
      "epoch 24; iter: 0; batch classifier loss: 0.160454; batch adversarial loss: 0.444393\n",
      "epoch 25; iter: 0; batch classifier loss: 0.244092; batch adversarial loss: 0.423456\n",
      "epoch 26; iter: 0; batch classifier loss: 0.140403; batch adversarial loss: 0.573003\n",
      "epoch 27; iter: 0; batch classifier loss: 0.188587; batch adversarial loss: 0.425773\n",
      "epoch 28; iter: 0; batch classifier loss: 0.192120; batch adversarial loss: 0.464276\n",
      "epoch 29; iter: 0; batch classifier loss: 0.113482; batch adversarial loss: 0.467774\n",
      "epoch 30; iter: 0; batch classifier loss: 0.146161; batch adversarial loss: 0.479487\n",
      "epoch 31; iter: 0; batch classifier loss: 0.100417; batch adversarial loss: 0.430743\n",
      "epoch 32; iter: 0; batch classifier loss: 0.105511; batch adversarial loss: 0.509230\n",
      "epoch 33; iter: 0; batch classifier loss: 0.149198; batch adversarial loss: 0.411063\n",
      "epoch 34; iter: 0; batch classifier loss: 0.129285; batch adversarial loss: 0.429872\n",
      "epoch 35; iter: 0; batch classifier loss: 0.128431; batch adversarial loss: 0.437959\n",
      "epoch 36; iter: 0; batch classifier loss: 0.115182; batch adversarial loss: 0.497537\n",
      "epoch 37; iter: 0; batch classifier loss: 0.099169; batch adversarial loss: 0.471113\n",
      "epoch 38; iter: 0; batch classifier loss: 0.104644; batch adversarial loss: 0.443680\n",
      "epoch 39; iter: 0; batch classifier loss: 0.116841; batch adversarial loss: 0.456082\n",
      "epoch 40; iter: 0; batch classifier loss: 0.179160; batch adversarial loss: 0.401017\n",
      "epoch 41; iter: 0; batch classifier loss: 0.134081; batch adversarial loss: 0.423818\n",
      "epoch 42; iter: 0; batch classifier loss: 0.102904; batch adversarial loss: 0.416754\n",
      "epoch 43; iter: 0; batch classifier loss: 0.119262; batch adversarial loss: 0.427392\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105273; batch adversarial loss: 0.440203\n",
      "epoch 45; iter: 0; batch classifier loss: 0.061104; batch adversarial loss: 0.569306\n",
      "epoch 46; iter: 0; batch classifier loss: 0.068988; batch adversarial loss: 0.545104\n",
      "epoch 47; iter: 0; batch classifier loss: 0.063270; batch adversarial loss: 0.364296\n",
      "epoch 48; iter: 0; batch classifier loss: 0.145162; batch adversarial loss: 0.455586\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074590; batch adversarial loss: 0.450955\n",
      "epoch 50; iter: 0; batch classifier loss: 0.070411; batch adversarial loss: 0.483040\n",
      "epoch 51; iter: 0; batch classifier loss: 0.125077; batch adversarial loss: 0.443841\n",
      "epoch 52; iter: 0; batch classifier loss: 0.080478; batch adversarial loss: 0.452123\n",
      "epoch 53; iter: 0; batch classifier loss: 0.082839; batch adversarial loss: 0.376652\n",
      "epoch 54; iter: 0; batch classifier loss: 0.051918; batch adversarial loss: 0.519605\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098966; batch adversarial loss: 0.454116\n",
      "epoch 56; iter: 0; batch classifier loss: 0.090218; batch adversarial loss: 0.430009\n",
      "epoch 57; iter: 0; batch classifier loss: 0.092783; batch adversarial loss: 0.391707\n",
      "epoch 58; iter: 0; batch classifier loss: 0.094127; batch adversarial loss: 0.400797\n",
      "epoch 59; iter: 0; batch classifier loss: 0.101090; batch adversarial loss: 0.494849\n",
      "epoch 60; iter: 0; batch classifier loss: 0.088294; batch adversarial loss: 0.422200\n",
      "epoch 61; iter: 0; batch classifier loss: 0.139288; batch adversarial loss: 0.533289\n",
      "epoch 62; iter: 0; batch classifier loss: 0.087580; batch adversarial loss: 0.406291\n",
      "epoch 63; iter: 0; batch classifier loss: 0.142517; batch adversarial loss: 0.363178\n",
      "epoch 64; iter: 0; batch classifier loss: 0.059197; batch adversarial loss: 0.477544\n",
      "epoch 65; iter: 0; batch classifier loss: 0.078522; batch adversarial loss: 0.452210\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091260; batch adversarial loss: 0.473865\n",
      "epoch 67; iter: 0; batch classifier loss: 0.067197; batch adversarial loss: 0.490139\n",
      "epoch 68; iter: 0; batch classifier loss: 0.051367; batch adversarial loss: 0.461583\n",
      "epoch 69; iter: 0; batch classifier loss: 0.137188; batch adversarial loss: 0.378743\n",
      "epoch 70; iter: 0; batch classifier loss: 0.076125; batch adversarial loss: 0.492018\n",
      "epoch 71; iter: 0; batch classifier loss: 0.051921; batch adversarial loss: 0.387184\n",
      "epoch 72; iter: 0; batch classifier loss: 0.084001; batch adversarial loss: 0.487685\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079605; batch adversarial loss: 0.433815\n",
      "epoch 74; iter: 0; batch classifier loss: 0.056617; batch adversarial loss: 0.577920\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059888; batch adversarial loss: 0.537364\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082640; batch adversarial loss: 0.475146\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064758; batch adversarial loss: 0.439686\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082573; batch adversarial loss: 0.475111\n",
      "epoch 79; iter: 0; batch classifier loss: 0.119629; batch adversarial loss: 0.386482\n",
      "epoch 80; iter: 0; batch classifier loss: 0.104029; batch adversarial loss: 0.460575\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055151; batch adversarial loss: 0.448617\n",
      "epoch 82; iter: 0; batch classifier loss: 0.104919; batch adversarial loss: 0.367983\n",
      "epoch 83; iter: 0; batch classifier loss: 0.087339; batch adversarial loss: 0.432736\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056454; batch adversarial loss: 0.523721\n",
      "epoch 85; iter: 0; batch classifier loss: 0.124717; batch adversarial loss: 0.405089\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073837; batch adversarial loss: 0.548563\n",
      "epoch 87; iter: 0; batch classifier loss: 0.087327; batch adversarial loss: 0.465635\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054913; batch adversarial loss: 0.442659\n",
      "epoch 89; iter: 0; batch classifier loss: 0.079237; batch adversarial loss: 0.335857\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048988; batch adversarial loss: 0.487665\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063485; batch adversarial loss: 0.467749\n",
      "epoch 92; iter: 0; batch classifier loss: 0.043596; batch adversarial loss: 0.452225\n",
      "epoch 93; iter: 0; batch classifier loss: 0.102172; batch adversarial loss: 0.477768\n",
      "epoch 94; iter: 0; batch classifier loss: 0.068585; batch adversarial loss: 0.534324\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079519; batch adversarial loss: 0.448104\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070209; batch adversarial loss: 0.377075\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039205; batch adversarial loss: 0.504337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.040206; batch adversarial loss: 0.409319\n",
      "epoch 99; iter: 0; batch classifier loss: 0.100085; batch adversarial loss: 0.434884\n",
      "epoch 100; iter: 0; batch classifier loss: 0.031526; batch adversarial loss: 0.484723\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056549; batch adversarial loss: 0.416963\n",
      "epoch 102; iter: 0; batch classifier loss: 0.064242; batch adversarial loss: 0.470689\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042273; batch adversarial loss: 0.464868\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056657; batch adversarial loss: 0.455997\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044371; batch adversarial loss: 0.494624\n",
      "epoch 106; iter: 0; batch classifier loss: 0.061027; batch adversarial loss: 0.378808\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027618; batch adversarial loss: 0.446522\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064771; batch adversarial loss: 0.425578\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053842; batch adversarial loss: 0.415071\n",
      "epoch 110; iter: 0; batch classifier loss: 0.056891; batch adversarial loss: 0.474991\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037718; batch adversarial loss: 0.365995\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026410; batch adversarial loss: 0.435076\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055293; batch adversarial loss: 0.499427\n",
      "epoch 114; iter: 0; batch classifier loss: 0.066373; batch adversarial loss: 0.461762\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054595; batch adversarial loss: 0.595731\n",
      "epoch 116; iter: 0; batch classifier loss: 0.059136; batch adversarial loss: 0.470506\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042867; batch adversarial loss: 0.491843\n",
      "epoch 118; iter: 0; batch classifier loss: 0.027690; batch adversarial loss: 0.551553\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059786; batch adversarial loss: 0.461919\n",
      "epoch 120; iter: 0; batch classifier loss: 0.064991; batch adversarial loss: 0.466603\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028941; batch adversarial loss: 0.487119\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033658; batch adversarial loss: 0.574861\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024889; batch adversarial loss: 0.487986\n",
      "epoch 124; iter: 0; batch classifier loss: 0.016156; batch adversarial loss: 0.545838\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052904; batch adversarial loss: 0.423461\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023096; batch adversarial loss: 0.384872\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027509; batch adversarial loss: 0.444667\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030391; batch adversarial loss: 0.488384\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020655; batch adversarial loss: 0.495732\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044094; batch adversarial loss: 0.494562\n",
      "epoch 131; iter: 0; batch classifier loss: 0.058744; batch adversarial loss: 0.475896\n",
      "epoch 132; iter: 0; batch classifier loss: 0.071745; batch adversarial loss: 0.536450\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022893; batch adversarial loss: 0.566527\n",
      "epoch 134; iter: 0; batch classifier loss: 0.060820; batch adversarial loss: 0.426085\n",
      "epoch 135; iter: 0; batch classifier loss: 0.052615; batch adversarial loss: 0.504494\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018298; batch adversarial loss: 0.506716\n",
      "epoch 137; iter: 0; batch classifier loss: 0.075104; batch adversarial loss: 0.464292\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040765; batch adversarial loss: 0.463489\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019111; batch adversarial loss: 0.434575\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024944; batch adversarial loss: 0.351351\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049476; batch adversarial loss: 0.458865\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014695; batch adversarial loss: 0.452823\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014106; batch adversarial loss: 0.421631\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027007; batch adversarial loss: 0.460871\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026115; batch adversarial loss: 0.533256\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029689; batch adversarial loss: 0.397804\n",
      "epoch 147; iter: 0; batch classifier loss: 0.056289; batch adversarial loss: 0.380614\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035180; batch adversarial loss: 0.417121\n",
      "epoch 149; iter: 0; batch classifier loss: 0.060545; batch adversarial loss: 0.516285\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043636; batch adversarial loss: 0.475710\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025171; batch adversarial loss: 0.434652\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018686; batch adversarial loss: 0.436424\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040048; batch adversarial loss: 0.404669\n",
      "epoch 154; iter: 0; batch classifier loss: 0.009478; batch adversarial loss: 0.401159\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033142; batch adversarial loss: 0.397734\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031343; batch adversarial loss: 0.439763\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038833; batch adversarial loss: 0.522497\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019390; batch adversarial loss: 0.415473\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013100; batch adversarial loss: 0.546613\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024946; batch adversarial loss: 0.428590\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040637; batch adversarial loss: 0.405730\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015248; batch adversarial loss: 0.498833\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014727; batch adversarial loss: 0.399719\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027756; batch adversarial loss: 0.460634\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020342; batch adversarial loss: 0.404969\n",
      "epoch 166; iter: 0; batch classifier loss: 0.059405; batch adversarial loss: 0.405362\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008735; batch adversarial loss: 0.374625\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032604; batch adversarial loss: 0.475187\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031310; batch adversarial loss: 0.462549\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034283; batch adversarial loss: 0.499291\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010813; batch adversarial loss: 0.373416\n",
      "epoch 172; iter: 0; batch classifier loss: 0.041647; batch adversarial loss: 0.495191\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017729; batch adversarial loss: 0.400222\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011271; batch adversarial loss: 0.457131\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037100; batch adversarial loss: 0.435134\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029189; batch adversarial loss: 0.510121\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018149; batch adversarial loss: 0.441981\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016122; batch adversarial loss: 0.426925\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022665; batch adversarial loss: 0.461954\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024046; batch adversarial loss: 0.456120\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037035; batch adversarial loss: 0.531048\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009833; batch adversarial loss: 0.473352\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025091; batch adversarial loss: 0.542932\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028041; batch adversarial loss: 0.401875\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011481; batch adversarial loss: 0.483083\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017562; batch adversarial loss: 0.468902\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027897; batch adversarial loss: 0.417072\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011045; batch adversarial loss: 0.429607\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025771; batch adversarial loss: 0.405143\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024106; batch adversarial loss: 0.462014\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015946; batch adversarial loss: 0.352676\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012973; batch adversarial loss: 0.529348\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011008; batch adversarial loss: 0.356080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.016446; batch adversarial loss: 0.420765\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013946; batch adversarial loss: 0.491265\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017453; batch adversarial loss: 0.418750\n",
      "epoch 197; iter: 0; batch classifier loss: 0.036020; batch adversarial loss: 0.453412\n",
      "epoch 198; iter: 0; batch classifier loss: 0.042488; batch adversarial loss: 0.441439\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009178; batch adversarial loss: 0.502791\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691499; batch adversarial loss: 0.702718\n",
      "epoch 1; iter: 0; batch classifier loss: 0.534147; batch adversarial loss: 0.668477\n",
      "epoch 2; iter: 0; batch classifier loss: 0.514322; batch adversarial loss: 0.633328\n",
      "epoch 3; iter: 0; batch classifier loss: 0.415773; batch adversarial loss: 0.608716\n",
      "epoch 4; iter: 0; batch classifier loss: 0.422045; batch adversarial loss: 0.604055\n",
      "epoch 5; iter: 0; batch classifier loss: 0.466959; batch adversarial loss: 0.587248\n",
      "epoch 6; iter: 0; batch classifier loss: 0.473693; batch adversarial loss: 0.565779\n",
      "epoch 7; iter: 0; batch classifier loss: 0.518550; batch adversarial loss: 0.568190\n",
      "epoch 8; iter: 0; batch classifier loss: 0.467932; batch adversarial loss: 0.549405\n",
      "epoch 9; iter: 0; batch classifier loss: 0.462226; batch adversarial loss: 0.520720\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374846; batch adversarial loss: 0.541687\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505215; batch adversarial loss: 0.501891\n",
      "epoch 12; iter: 0; batch classifier loss: 0.376553; batch adversarial loss: 0.492342\n",
      "epoch 13; iter: 0; batch classifier loss: 0.321663; batch adversarial loss: 0.496941\n",
      "epoch 14; iter: 0; batch classifier loss: 0.317917; batch adversarial loss: 0.478321\n",
      "epoch 15; iter: 0; batch classifier loss: 0.357001; batch adversarial loss: 0.506842\n",
      "epoch 16; iter: 0; batch classifier loss: 0.280239; batch adversarial loss: 0.507550\n",
      "epoch 17; iter: 0; batch classifier loss: 0.216169; batch adversarial loss: 0.490871\n",
      "epoch 18; iter: 0; batch classifier loss: 0.267916; batch adversarial loss: 0.436159\n",
      "epoch 19; iter: 0; batch classifier loss: 0.302825; batch adversarial loss: 0.504532\n",
      "epoch 20; iter: 0; batch classifier loss: 0.326720; batch adversarial loss: 0.480035\n",
      "epoch 21; iter: 0; batch classifier loss: 0.211448; batch adversarial loss: 0.632397\n",
      "epoch 22; iter: 0; batch classifier loss: 0.236742; batch adversarial loss: 0.519145\n",
      "epoch 23; iter: 0; batch classifier loss: 0.261640; batch adversarial loss: 0.508355\n",
      "epoch 24; iter: 0; batch classifier loss: 0.248586; batch adversarial loss: 0.479943\n",
      "epoch 25; iter: 0; batch classifier loss: 0.209894; batch adversarial loss: 0.506779\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182819; batch adversarial loss: 0.537564\n",
      "epoch 27; iter: 0; batch classifier loss: 0.202006; batch adversarial loss: 0.453038\n",
      "epoch 28; iter: 0; batch classifier loss: 0.246932; batch adversarial loss: 0.426185\n",
      "epoch 29; iter: 0; batch classifier loss: 0.211810; batch adversarial loss: 0.423032\n",
      "epoch 30; iter: 0; batch classifier loss: 0.209005; batch adversarial loss: 0.499909\n",
      "epoch 31; iter: 0; batch classifier loss: 0.220100; batch adversarial loss: 0.521485\n",
      "epoch 32; iter: 0; batch classifier loss: 0.177978; batch adversarial loss: 0.492198\n",
      "epoch 33; iter: 0; batch classifier loss: 0.222714; batch adversarial loss: 0.461867\n",
      "epoch 34; iter: 0; batch classifier loss: 0.156967; batch adversarial loss: 0.398236\n",
      "epoch 35; iter: 0; batch classifier loss: 0.127450; batch adversarial loss: 0.456145\n",
      "epoch 36; iter: 0; batch classifier loss: 0.165200; batch adversarial loss: 0.523714\n",
      "epoch 37; iter: 0; batch classifier loss: 0.173841; batch adversarial loss: 0.483872\n",
      "epoch 38; iter: 0; batch classifier loss: 0.161905; batch adversarial loss: 0.363183\n",
      "epoch 39; iter: 0; batch classifier loss: 0.196468; batch adversarial loss: 0.423950\n",
      "epoch 40; iter: 0; batch classifier loss: 0.159424; batch adversarial loss: 0.524239\n",
      "epoch 41; iter: 0; batch classifier loss: 0.211417; batch adversarial loss: 0.359854\n",
      "epoch 42; iter: 0; batch classifier loss: 0.161365; batch adversarial loss: 0.466408\n",
      "epoch 43; iter: 0; batch classifier loss: 0.124115; batch adversarial loss: 0.398623\n",
      "epoch 44; iter: 0; batch classifier loss: 0.099687; batch adversarial loss: 0.504960\n",
      "epoch 45; iter: 0; batch classifier loss: 0.138868; batch adversarial loss: 0.409831\n",
      "epoch 46; iter: 0; batch classifier loss: 0.100185; batch adversarial loss: 0.540621\n",
      "epoch 47; iter: 0; batch classifier loss: 0.089283; batch adversarial loss: 0.435796\n",
      "epoch 48; iter: 0; batch classifier loss: 0.121410; batch adversarial loss: 0.535915\n",
      "epoch 49; iter: 0; batch classifier loss: 0.091285; batch adversarial loss: 0.522835\n",
      "epoch 50; iter: 0; batch classifier loss: 0.118689; batch adversarial loss: 0.505401\n",
      "epoch 51; iter: 0; batch classifier loss: 0.093701; batch adversarial loss: 0.438585\n",
      "epoch 52; iter: 0; batch classifier loss: 0.116119; batch adversarial loss: 0.435842\n",
      "epoch 53; iter: 0; batch classifier loss: 0.145291; batch adversarial loss: 0.486926\n",
      "epoch 54; iter: 0; batch classifier loss: 0.094863; batch adversarial loss: 0.356483\n",
      "epoch 55; iter: 0; batch classifier loss: 0.069568; batch adversarial loss: 0.477515\n",
      "epoch 56; iter: 0; batch classifier loss: 0.056577; batch adversarial loss: 0.488924\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086019; batch adversarial loss: 0.427116\n",
      "epoch 58; iter: 0; batch classifier loss: 0.071545; batch adversarial loss: 0.502980\n",
      "epoch 59; iter: 0; batch classifier loss: 0.093456; batch adversarial loss: 0.455336\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095717; batch adversarial loss: 0.469319\n",
      "epoch 61; iter: 0; batch classifier loss: 0.063138; batch adversarial loss: 0.428222\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094750; batch adversarial loss: 0.385758\n",
      "epoch 63; iter: 0; batch classifier loss: 0.064024; batch adversarial loss: 0.433724\n",
      "epoch 64; iter: 0; batch classifier loss: 0.086166; batch adversarial loss: 0.469857\n",
      "epoch 65; iter: 0; batch classifier loss: 0.078222; batch adversarial loss: 0.492825\n",
      "epoch 66; iter: 0; batch classifier loss: 0.042919; batch adversarial loss: 0.456753\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110068; batch adversarial loss: 0.406637\n",
      "epoch 68; iter: 0; batch classifier loss: 0.084074; batch adversarial loss: 0.471012\n",
      "epoch 69; iter: 0; batch classifier loss: 0.067816; batch adversarial loss: 0.381126\n",
      "epoch 70; iter: 0; batch classifier loss: 0.028068; batch adversarial loss: 0.499542\n",
      "epoch 71; iter: 0; batch classifier loss: 0.054672; batch adversarial loss: 0.484246\n",
      "epoch 72; iter: 0; batch classifier loss: 0.105930; batch adversarial loss: 0.432210\n",
      "epoch 73; iter: 0; batch classifier loss: 0.087266; batch adversarial loss: 0.543984\n",
      "epoch 74; iter: 0; batch classifier loss: 0.071554; batch adversarial loss: 0.417164\n",
      "epoch 75; iter: 0; batch classifier loss: 0.056140; batch adversarial loss: 0.477712\n",
      "epoch 76; iter: 0; batch classifier loss: 0.085434; batch adversarial loss: 0.537764\n",
      "epoch 77; iter: 0; batch classifier loss: 0.059067; batch adversarial loss: 0.412494\n",
      "epoch 78; iter: 0; batch classifier loss: 0.045016; batch adversarial loss: 0.556590\n",
      "epoch 79; iter: 0; batch classifier loss: 0.047517; batch adversarial loss: 0.410952\n",
      "epoch 80; iter: 0; batch classifier loss: 0.047975; batch adversarial loss: 0.433686\n",
      "epoch 81; iter: 0; batch classifier loss: 0.045742; batch adversarial loss: 0.507496\n",
      "epoch 82; iter: 0; batch classifier loss: 0.057925; batch adversarial loss: 0.452539\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070387; batch adversarial loss: 0.376055\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056283; batch adversarial loss: 0.478112\n",
      "epoch 85; iter: 0; batch classifier loss: 0.031057; batch adversarial loss: 0.527722\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054115; batch adversarial loss: 0.411952\n",
      "epoch 87; iter: 0; batch classifier loss: 0.034131; batch adversarial loss: 0.412818\n",
      "epoch 88; iter: 0; batch classifier loss: 0.024428; batch adversarial loss: 0.493388\n",
      "epoch 89; iter: 0; batch classifier loss: 0.035234; batch adversarial loss: 0.485497\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068370; batch adversarial loss: 0.459300\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062956; batch adversarial loss: 0.362488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.029100; batch adversarial loss: 0.454656\n",
      "epoch 93; iter: 0; batch classifier loss: 0.037012; batch adversarial loss: 0.349621\n",
      "epoch 94; iter: 0; batch classifier loss: 0.028850; batch adversarial loss: 0.408539\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058526; batch adversarial loss: 0.489106\n",
      "epoch 96; iter: 0; batch classifier loss: 0.019879; batch adversarial loss: 0.470549\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050110; batch adversarial loss: 0.476694\n",
      "epoch 98; iter: 0; batch classifier loss: 0.038942; batch adversarial loss: 0.424679\n",
      "epoch 99; iter: 0; batch classifier loss: 0.027797; batch adversarial loss: 0.418739\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045873; batch adversarial loss: 0.381169\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040022; batch adversarial loss: 0.350361\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049374; batch adversarial loss: 0.426542\n",
      "epoch 103; iter: 0; batch classifier loss: 0.019231; batch adversarial loss: 0.393411\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043878; batch adversarial loss: 0.546336\n",
      "epoch 105; iter: 0; batch classifier loss: 0.028295; batch adversarial loss: 0.504735\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039970; batch adversarial loss: 0.391081\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028740; batch adversarial loss: 0.475139\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064603; batch adversarial loss: 0.515854\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042763; batch adversarial loss: 0.420188\n",
      "epoch 110; iter: 0; batch classifier loss: 0.018510; batch adversarial loss: 0.420057\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032377; batch adversarial loss: 0.433684\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025554; batch adversarial loss: 0.483515\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028395; batch adversarial loss: 0.505654\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026486; batch adversarial loss: 0.408654\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029304; batch adversarial loss: 0.391340\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039160; batch adversarial loss: 0.391971\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038963; batch adversarial loss: 0.444980\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037434; batch adversarial loss: 0.459637\n",
      "epoch 119; iter: 0; batch classifier loss: 0.013951; batch adversarial loss: 0.464962\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027427; batch adversarial loss: 0.610087\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037885; batch adversarial loss: 0.540222\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017641; batch adversarial loss: 0.453803\n",
      "epoch 123; iter: 0; batch classifier loss: 0.016854; batch adversarial loss: 0.449545\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032459; batch adversarial loss: 0.360127\n",
      "epoch 125; iter: 0; batch classifier loss: 0.013881; batch adversarial loss: 0.413742\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017205; batch adversarial loss: 0.380982\n",
      "epoch 127; iter: 0; batch classifier loss: 0.014605; batch adversarial loss: 0.478147\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033519; batch adversarial loss: 0.487140\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023556; batch adversarial loss: 0.363753\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025215; batch adversarial loss: 0.470988\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022944; batch adversarial loss: 0.431452\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019684; batch adversarial loss: 0.418733\n",
      "epoch 133; iter: 0; batch classifier loss: 0.002487; batch adversarial loss: 0.527945\n",
      "epoch 134; iter: 0; batch classifier loss: 0.008814; batch adversarial loss: 0.574551\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035863; batch adversarial loss: 0.464610\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017513; batch adversarial loss: 0.468149\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025875; batch adversarial loss: 0.454837\n",
      "epoch 138; iter: 0; batch classifier loss: 0.002581; batch adversarial loss: 0.496551\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039542; batch adversarial loss: 0.479356\n",
      "epoch 140; iter: 0; batch classifier loss: 0.014447; batch adversarial loss: 0.496206\n",
      "epoch 141; iter: 0; batch classifier loss: 0.012777; batch adversarial loss: 0.503806\n",
      "epoch 142; iter: 0; batch classifier loss: 0.052161; batch adversarial loss: 0.475946\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029201; batch adversarial loss: 0.386694\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016631; batch adversarial loss: 0.481852\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029776; batch adversarial loss: 0.463834\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030946; batch adversarial loss: 0.508046\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028349; batch adversarial loss: 0.373945\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018124; batch adversarial loss: 0.401682\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021174; batch adversarial loss: 0.542334\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011055; batch adversarial loss: 0.438608\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012806; batch adversarial loss: 0.461828\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016836; batch adversarial loss: 0.427765\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014879; batch adversarial loss: 0.499317\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022548; batch adversarial loss: 0.489425\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021828; batch adversarial loss: 0.468633\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033331; batch adversarial loss: 0.488083\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031480; batch adversarial loss: 0.446613\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011309; batch adversarial loss: 0.419284\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024532; batch adversarial loss: 0.359818\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008274; batch adversarial loss: 0.437748\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025226; batch adversarial loss: 0.451558\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024118; batch adversarial loss: 0.413383\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021462; batch adversarial loss: 0.486932\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021524; batch adversarial loss: 0.505591\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018307; batch adversarial loss: 0.474202\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037746; batch adversarial loss: 0.416790\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016075; batch adversarial loss: 0.442024\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017758; batch adversarial loss: 0.512567\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014344; batch adversarial loss: 0.493132\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024815; batch adversarial loss: 0.518266\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013147; batch adversarial loss: 0.417028\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009935; batch adversarial loss: 0.545432\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017474; batch adversarial loss: 0.440883\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010360; batch adversarial loss: 0.460556\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015355; batch adversarial loss: 0.494104\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025635; batch adversarial loss: 0.388938\n",
      "epoch 177; iter: 0; batch classifier loss: 0.007211; batch adversarial loss: 0.456050\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027861; batch adversarial loss: 0.459612\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021561; batch adversarial loss: 0.363675\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016214; batch adversarial loss: 0.466516\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016369; batch adversarial loss: 0.486045\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024261; batch adversarial loss: 0.511998\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024090; batch adversarial loss: 0.498635\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011067; batch adversarial loss: 0.442748\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008515; batch adversarial loss: 0.390375\n",
      "epoch 186; iter: 0; batch classifier loss: 0.036874; batch adversarial loss: 0.358422\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014183; batch adversarial loss: 0.388627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.022343; batch adversarial loss: 0.387657\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014946; batch adversarial loss: 0.493515\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018705; batch adversarial loss: 0.427637\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025489; batch adversarial loss: 0.493373\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018424; batch adversarial loss: 0.338123\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013266; batch adversarial loss: 0.439788\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008808; batch adversarial loss: 0.488645\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029251; batch adversarial loss: 0.425206\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011903; batch adversarial loss: 0.490517\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025637; batch adversarial loss: 0.356700\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015626; batch adversarial loss: 0.517108\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028453; batch adversarial loss: 0.431404\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694255; batch adversarial loss: 0.681486\n",
      "epoch 1; iter: 0; batch classifier loss: 0.513089; batch adversarial loss: 0.609329\n",
      "epoch 2; iter: 0; batch classifier loss: 0.471138; batch adversarial loss: 0.623104\n",
      "epoch 3; iter: 0; batch classifier loss: 0.341498; batch adversarial loss: 0.627606\n",
      "epoch 4; iter: 0; batch classifier loss: 0.468782; batch adversarial loss: 0.600287\n",
      "epoch 5; iter: 0; batch classifier loss: 0.318869; batch adversarial loss: 0.542457\n",
      "epoch 6; iter: 0; batch classifier loss: 0.324086; batch adversarial loss: 0.637492\n",
      "epoch 7; iter: 0; batch classifier loss: 0.320431; batch adversarial loss: 0.592732\n",
      "epoch 8; iter: 0; batch classifier loss: 0.395442; batch adversarial loss: 0.525035\n",
      "epoch 9; iter: 0; batch classifier loss: 0.340311; batch adversarial loss: 0.574822\n",
      "epoch 10; iter: 0; batch classifier loss: 0.350217; batch adversarial loss: 0.540703\n",
      "epoch 11; iter: 0; batch classifier loss: 0.340160; batch adversarial loss: 0.500485\n",
      "epoch 12; iter: 0; batch classifier loss: 0.288987; batch adversarial loss: 0.502299\n",
      "epoch 13; iter: 0; batch classifier loss: 0.264013; batch adversarial loss: 0.603521\n",
      "epoch 14; iter: 0; batch classifier loss: 0.271750; batch adversarial loss: 0.489829\n",
      "epoch 15; iter: 0; batch classifier loss: 0.283442; batch adversarial loss: 0.499720\n",
      "epoch 16; iter: 0; batch classifier loss: 0.231307; batch adversarial loss: 0.472871\n",
      "epoch 17; iter: 0; batch classifier loss: 0.248713; batch adversarial loss: 0.475828\n",
      "epoch 18; iter: 0; batch classifier loss: 0.219506; batch adversarial loss: 0.504404\n",
      "epoch 19; iter: 0; batch classifier loss: 0.235813; batch adversarial loss: 0.489402\n",
      "epoch 20; iter: 0; batch classifier loss: 0.156475; batch adversarial loss: 0.437348\n",
      "epoch 21; iter: 0; batch classifier loss: 0.174861; batch adversarial loss: 0.466953\n",
      "epoch 22; iter: 0; batch classifier loss: 0.156629; batch adversarial loss: 0.474932\n",
      "epoch 23; iter: 0; batch classifier loss: 0.212052; batch adversarial loss: 0.453850\n",
      "epoch 24; iter: 0; batch classifier loss: 0.183619; batch adversarial loss: 0.430008\n",
      "epoch 25; iter: 0; batch classifier loss: 0.160573; batch adversarial loss: 0.587737\n",
      "epoch 26; iter: 0; batch classifier loss: 0.179027; batch adversarial loss: 0.441292\n",
      "epoch 27; iter: 0; batch classifier loss: 0.178525; batch adversarial loss: 0.391421\n",
      "epoch 28; iter: 0; batch classifier loss: 0.181772; batch adversarial loss: 0.546176\n",
      "epoch 29; iter: 0; batch classifier loss: 0.119444; batch adversarial loss: 0.464788\n",
      "epoch 30; iter: 0; batch classifier loss: 0.162892; batch adversarial loss: 0.420861\n",
      "epoch 31; iter: 0; batch classifier loss: 0.163525; batch adversarial loss: 0.400283\n",
      "epoch 32; iter: 0; batch classifier loss: 0.081428; batch adversarial loss: 0.421300\n",
      "epoch 33; iter: 0; batch classifier loss: 0.189078; batch adversarial loss: 0.445769\n",
      "epoch 34; iter: 0; batch classifier loss: 0.179399; batch adversarial loss: 0.507184\n",
      "epoch 35; iter: 0; batch classifier loss: 0.121000; batch adversarial loss: 0.439528\n",
      "epoch 36; iter: 0; batch classifier loss: 0.197055; batch adversarial loss: 0.512002\n",
      "epoch 37; iter: 0; batch classifier loss: 0.185792; batch adversarial loss: 0.470221\n",
      "epoch 38; iter: 0; batch classifier loss: 0.186266; batch adversarial loss: 0.528078\n",
      "epoch 39; iter: 0; batch classifier loss: 0.145504; batch adversarial loss: 0.461791\n",
      "epoch 40; iter: 0; batch classifier loss: 0.122176; batch adversarial loss: 0.482376\n",
      "epoch 41; iter: 0; batch classifier loss: 0.141453; batch adversarial loss: 0.432371\n",
      "epoch 42; iter: 0; batch classifier loss: 0.148013; batch adversarial loss: 0.458691\n",
      "epoch 43; iter: 0; batch classifier loss: 0.191127; batch adversarial loss: 0.469450\n",
      "epoch 44; iter: 0; batch classifier loss: 0.160182; batch adversarial loss: 0.454875\n",
      "epoch 45; iter: 0; batch classifier loss: 0.208339; batch adversarial loss: 0.446728\n",
      "epoch 46; iter: 0; batch classifier loss: 0.174320; batch adversarial loss: 0.461040\n",
      "epoch 47; iter: 0; batch classifier loss: 0.174732; batch adversarial loss: 0.462997\n",
      "epoch 48; iter: 0; batch classifier loss: 0.122137; batch adversarial loss: 0.470055\n",
      "epoch 49; iter: 0; batch classifier loss: 0.120826; batch adversarial loss: 0.434973\n",
      "epoch 50; iter: 0; batch classifier loss: 0.143720; batch adversarial loss: 0.411467\n",
      "epoch 51; iter: 0; batch classifier loss: 0.133631; batch adversarial loss: 0.414149\n",
      "epoch 52; iter: 0; batch classifier loss: 0.151493; batch adversarial loss: 0.492677\n",
      "epoch 53; iter: 0; batch classifier loss: 0.151296; batch adversarial loss: 0.467875\n",
      "epoch 54; iter: 0; batch classifier loss: 0.146846; batch adversarial loss: 0.496054\n",
      "epoch 55; iter: 0; batch classifier loss: 0.151252; batch adversarial loss: 0.434005\n",
      "epoch 56; iter: 0; batch classifier loss: 0.180574; batch adversarial loss: 0.419998\n",
      "epoch 57; iter: 0; batch classifier loss: 0.132216; batch adversarial loss: 0.446629\n",
      "epoch 58; iter: 0; batch classifier loss: 0.175616; batch adversarial loss: 0.459593\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105510; batch adversarial loss: 0.536817\n",
      "epoch 60; iter: 0; batch classifier loss: 0.148322; batch adversarial loss: 0.414485\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113976; batch adversarial loss: 0.513557\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090565; batch adversarial loss: 0.551413\n",
      "epoch 63; iter: 0; batch classifier loss: 0.131811; batch adversarial loss: 0.393502\n",
      "epoch 64; iter: 0; batch classifier loss: 0.136538; batch adversarial loss: 0.509921\n",
      "epoch 65; iter: 0; batch classifier loss: 0.104219; batch adversarial loss: 0.451607\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084767; batch adversarial loss: 0.432835\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080711; batch adversarial loss: 0.450152\n",
      "epoch 68; iter: 0; batch classifier loss: 0.149231; batch adversarial loss: 0.477492\n",
      "epoch 69; iter: 0; batch classifier loss: 0.109480; batch adversarial loss: 0.410529\n",
      "epoch 70; iter: 0; batch classifier loss: 0.142852; batch adversarial loss: 0.491659\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083515; batch adversarial loss: 0.441297\n",
      "epoch 72; iter: 0; batch classifier loss: 0.081420; batch adversarial loss: 0.403966\n",
      "epoch 73; iter: 0; batch classifier loss: 0.134977; batch adversarial loss: 0.440352\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082590; batch adversarial loss: 0.501032\n",
      "epoch 75; iter: 0; batch classifier loss: 0.139812; batch adversarial loss: 0.395768\n",
      "epoch 76; iter: 0; batch classifier loss: 0.120561; batch adversarial loss: 0.437585\n",
      "epoch 77; iter: 0; batch classifier loss: 0.075586; batch adversarial loss: 0.422304\n",
      "epoch 78; iter: 0; batch classifier loss: 0.130856; batch adversarial loss: 0.459333\n",
      "epoch 79; iter: 0; batch classifier loss: 0.111753; batch adversarial loss: 0.517477\n",
      "epoch 80; iter: 0; batch classifier loss: 0.107217; batch adversarial loss: 0.500475\n",
      "epoch 81; iter: 0; batch classifier loss: 0.053932; batch adversarial loss: 0.475148\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091103; batch adversarial loss: 0.497265\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071035; batch adversarial loss: 0.389968\n",
      "epoch 84; iter: 0; batch classifier loss: 0.076131; batch adversarial loss: 0.410948\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055203; batch adversarial loss: 0.379386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.067607; batch adversarial loss: 0.449295\n",
      "epoch 87; iter: 0; batch classifier loss: 0.032668; batch adversarial loss: 0.561674\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064112; batch adversarial loss: 0.403308\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081457; batch adversarial loss: 0.453119\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059423; batch adversarial loss: 0.556423\n",
      "epoch 91; iter: 0; batch classifier loss: 0.072327; batch adversarial loss: 0.410556\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066239; batch adversarial loss: 0.457682\n",
      "epoch 93; iter: 0; batch classifier loss: 0.085645; batch adversarial loss: 0.491521\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049906; batch adversarial loss: 0.441099\n",
      "epoch 95; iter: 0; batch classifier loss: 0.099387; batch adversarial loss: 0.440965\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044937; batch adversarial loss: 0.489602\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049487; batch adversarial loss: 0.432438\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051201; batch adversarial loss: 0.500053\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042427; batch adversarial loss: 0.415692\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055530; batch adversarial loss: 0.509093\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044891; batch adversarial loss: 0.442783\n",
      "epoch 102; iter: 0; batch classifier loss: 0.030812; batch adversarial loss: 0.437375\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032227; batch adversarial loss: 0.410766\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065871; batch adversarial loss: 0.460987\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043278; batch adversarial loss: 0.444827\n",
      "epoch 106; iter: 0; batch classifier loss: 0.066886; batch adversarial loss: 0.452828\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044004; batch adversarial loss: 0.507298\n",
      "epoch 108; iter: 0; batch classifier loss: 0.035443; batch adversarial loss: 0.589910\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059544; batch adversarial loss: 0.393039\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051007; batch adversarial loss: 0.446194\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033952; batch adversarial loss: 0.569130\n",
      "epoch 112; iter: 0; batch classifier loss: 0.032849; batch adversarial loss: 0.486728\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053674; batch adversarial loss: 0.495053\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028179; batch adversarial loss: 0.403729\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027848; batch adversarial loss: 0.522846\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028287; batch adversarial loss: 0.449443\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032396; batch adversarial loss: 0.508635\n",
      "epoch 118; iter: 0; batch classifier loss: 0.022108; batch adversarial loss: 0.419210\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032774; batch adversarial loss: 0.463060\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033601; batch adversarial loss: 0.477854\n",
      "epoch 121; iter: 0; batch classifier loss: 0.077054; batch adversarial loss: 0.457027\n",
      "epoch 122; iter: 0; batch classifier loss: 0.020080; batch adversarial loss: 0.462402\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036869; batch adversarial loss: 0.510916\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037820; batch adversarial loss: 0.381716\n",
      "epoch 125; iter: 0; batch classifier loss: 0.024719; batch adversarial loss: 0.550554\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027228; batch adversarial loss: 0.402275\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043936; batch adversarial loss: 0.490082\n",
      "epoch 128; iter: 0; batch classifier loss: 0.062661; batch adversarial loss: 0.495585\n",
      "epoch 129; iter: 0; batch classifier loss: 0.065356; batch adversarial loss: 0.520738\n",
      "epoch 130; iter: 0; batch classifier loss: 0.071153; batch adversarial loss: 0.459175\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017167; batch adversarial loss: 0.556060\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024638; batch adversarial loss: 0.487562\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015372; batch adversarial loss: 0.429405\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052723; batch adversarial loss: 0.417807\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025527; batch adversarial loss: 0.449410\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024843; batch adversarial loss: 0.463459\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048944; batch adversarial loss: 0.425050\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029714; batch adversarial loss: 0.506827\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013998; batch adversarial loss: 0.537709\n",
      "epoch 140; iter: 0; batch classifier loss: 0.039071; batch adversarial loss: 0.422221\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028529; batch adversarial loss: 0.389443\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035110; batch adversarial loss: 0.355616\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040083; batch adversarial loss: 0.497874\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052982; batch adversarial loss: 0.363665\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032405; batch adversarial loss: 0.482895\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042972; batch adversarial loss: 0.479219\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038175; batch adversarial loss: 0.497063\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018503; batch adversarial loss: 0.460253\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016997; batch adversarial loss: 0.487336\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016898; batch adversarial loss: 0.426921\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035192; batch adversarial loss: 0.484488\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018176; batch adversarial loss: 0.449142\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028782; batch adversarial loss: 0.417715\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029315; batch adversarial loss: 0.441588\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016588; batch adversarial loss: 0.363246\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018592; batch adversarial loss: 0.501686\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014295; batch adversarial loss: 0.468346\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023284; batch adversarial loss: 0.444863\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014508; batch adversarial loss: 0.439358\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028787; batch adversarial loss: 0.471974\n",
      "epoch 161; iter: 0; batch classifier loss: 0.061564; batch adversarial loss: 0.412578\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023036; batch adversarial loss: 0.406735\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026464; batch adversarial loss: 0.362134\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019912; batch adversarial loss: 0.493972\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013584; batch adversarial loss: 0.446312\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015926; batch adversarial loss: 0.524124\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016964; batch adversarial loss: 0.421075\n",
      "epoch 168; iter: 0; batch classifier loss: 0.041687; batch adversarial loss: 0.580014\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017788; batch adversarial loss: 0.427459\n",
      "epoch 170; iter: 0; batch classifier loss: 0.046296; batch adversarial loss: 0.465840\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027055; batch adversarial loss: 0.398834\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036044; batch adversarial loss: 0.413885\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012651; batch adversarial loss: 0.440836\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039269; batch adversarial loss: 0.522959\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024500; batch adversarial loss: 0.462542\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020870; batch adversarial loss: 0.408120\n",
      "epoch 177; iter: 0; batch classifier loss: 0.056190; batch adversarial loss: 0.390874\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022452; batch adversarial loss: 0.483688\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030260; batch adversarial loss: 0.436258\n",
      "epoch 180; iter: 0; batch classifier loss: 0.048399; batch adversarial loss: 0.448033\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006766; batch adversarial loss: 0.388405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.011127; batch adversarial loss: 0.432405\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027523; batch adversarial loss: 0.423741\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028945; batch adversarial loss: 0.478396\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032854; batch adversarial loss: 0.375754\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012965; batch adversarial loss: 0.362461\n",
      "epoch 187; iter: 0; batch classifier loss: 0.052831; batch adversarial loss: 0.425312\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021802; batch adversarial loss: 0.540851\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023190; batch adversarial loss: 0.482957\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020283; batch adversarial loss: 0.497401\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019813; batch adversarial loss: 0.486167\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016456; batch adversarial loss: 0.505121\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026637; batch adversarial loss: 0.404690\n",
      "epoch 194; iter: 0; batch classifier loss: 0.048345; batch adversarial loss: 0.459823\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009280; batch adversarial loss: 0.417704\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010853; batch adversarial loss: 0.515537\n",
      "epoch 197; iter: 0; batch classifier loss: 0.040544; batch adversarial loss: 0.467973\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023898; batch adversarial loss: 0.456834\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014209; batch adversarial loss: 0.448959\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697082; batch adversarial loss: 0.594839\n",
      "epoch 1; iter: 0; batch classifier loss: 0.474001; batch adversarial loss: 0.606245\n",
      "epoch 2; iter: 0; batch classifier loss: 0.404063; batch adversarial loss: 0.584730\n",
      "epoch 3; iter: 0; batch classifier loss: 0.266211; batch adversarial loss: 0.560225\n",
      "epoch 4; iter: 0; batch classifier loss: 0.288409; batch adversarial loss: 0.533208\n",
      "epoch 5; iter: 0; batch classifier loss: 0.313365; batch adversarial loss: 0.637502\n",
      "epoch 6; iter: 0; batch classifier loss: 0.257449; batch adversarial loss: 0.520622\n",
      "epoch 7; iter: 0; batch classifier loss: 0.435282; batch adversarial loss: 0.558135\n",
      "epoch 8; iter: 0; batch classifier loss: 0.306478; batch adversarial loss: 0.464265\n",
      "epoch 9; iter: 0; batch classifier loss: 0.180842; batch adversarial loss: 0.564298\n",
      "epoch 10; iter: 0; batch classifier loss: 0.284857; batch adversarial loss: 0.553919\n",
      "epoch 11; iter: 0; batch classifier loss: 0.298417; batch adversarial loss: 0.579471\n",
      "epoch 12; iter: 0; batch classifier loss: 0.267084; batch adversarial loss: 0.567264\n",
      "epoch 13; iter: 0; batch classifier loss: 0.220475; batch adversarial loss: 0.471408\n",
      "epoch 14; iter: 0; batch classifier loss: 0.314636; batch adversarial loss: 0.550470\n",
      "epoch 15; iter: 0; batch classifier loss: 0.422773; batch adversarial loss: 0.568721\n",
      "epoch 16; iter: 0; batch classifier loss: 0.436284; batch adversarial loss: 0.523511\n",
      "epoch 17; iter: 0; batch classifier loss: 0.379201; batch adversarial loss: 0.473579\n",
      "epoch 18; iter: 0; batch classifier loss: 0.473381; batch adversarial loss: 0.482370\n",
      "epoch 19; iter: 0; batch classifier loss: 0.379909; batch adversarial loss: 0.446123\n",
      "epoch 20; iter: 0; batch classifier loss: 0.257870; batch adversarial loss: 0.552054\n",
      "epoch 21; iter: 0; batch classifier loss: 0.126573; batch adversarial loss: 0.519154\n",
      "epoch 22; iter: 0; batch classifier loss: 0.193914; batch adversarial loss: 0.425200\n",
      "epoch 23; iter: 0; batch classifier loss: 0.184975; batch adversarial loss: 0.496799\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199496; batch adversarial loss: 0.405507\n",
      "epoch 25; iter: 0; batch classifier loss: 0.199693; batch adversarial loss: 0.427200\n",
      "epoch 26; iter: 0; batch classifier loss: 0.150071; batch adversarial loss: 0.411158\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171205; batch adversarial loss: 0.471740\n",
      "epoch 28; iter: 0; batch classifier loss: 0.140461; batch adversarial loss: 0.422077\n",
      "epoch 29; iter: 0; batch classifier loss: 0.235801; batch adversarial loss: 0.476465\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144960; batch adversarial loss: 0.535997\n",
      "epoch 31; iter: 0; batch classifier loss: 0.163585; batch adversarial loss: 0.458869\n",
      "epoch 32; iter: 0; batch classifier loss: 0.136876; batch adversarial loss: 0.438489\n",
      "epoch 33; iter: 0; batch classifier loss: 0.134387; batch adversarial loss: 0.449211\n",
      "epoch 34; iter: 0; batch classifier loss: 0.095466; batch adversarial loss: 0.427573\n",
      "epoch 35; iter: 0; batch classifier loss: 0.116378; batch adversarial loss: 0.490707\n",
      "epoch 36; iter: 0; batch classifier loss: 0.120712; batch adversarial loss: 0.479888\n",
      "epoch 37; iter: 0; batch classifier loss: 0.100193; batch adversarial loss: 0.500166\n",
      "epoch 38; iter: 0; batch classifier loss: 0.125528; batch adversarial loss: 0.473759\n",
      "epoch 39; iter: 0; batch classifier loss: 0.129077; batch adversarial loss: 0.434328\n",
      "epoch 40; iter: 0; batch classifier loss: 0.151089; batch adversarial loss: 0.469643\n",
      "epoch 41; iter: 0; batch classifier loss: 0.145207; batch adversarial loss: 0.463413\n",
      "epoch 42; iter: 0; batch classifier loss: 0.093615; batch adversarial loss: 0.503756\n",
      "epoch 43; iter: 0; batch classifier loss: 0.120929; batch adversarial loss: 0.476584\n",
      "epoch 44; iter: 0; batch classifier loss: 0.111118; batch adversarial loss: 0.463034\n",
      "epoch 45; iter: 0; batch classifier loss: 0.107169; batch adversarial loss: 0.421081\n",
      "epoch 46; iter: 0; batch classifier loss: 0.171327; batch adversarial loss: 0.423899\n",
      "epoch 47; iter: 0; batch classifier loss: 0.126688; batch adversarial loss: 0.425677\n",
      "epoch 48; iter: 0; batch classifier loss: 0.092579; batch adversarial loss: 0.548691\n",
      "epoch 49; iter: 0; batch classifier loss: 0.077418; batch adversarial loss: 0.492559\n",
      "epoch 50; iter: 0; batch classifier loss: 0.084710; batch adversarial loss: 0.554132\n",
      "epoch 51; iter: 0; batch classifier loss: 0.130471; batch adversarial loss: 0.464587\n",
      "epoch 52; iter: 0; batch classifier loss: 0.158253; batch adversarial loss: 0.472274\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095673; batch adversarial loss: 0.477969\n",
      "epoch 54; iter: 0; batch classifier loss: 0.120029; batch adversarial loss: 0.480817\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117867; batch adversarial loss: 0.412662\n",
      "epoch 56; iter: 0; batch classifier loss: 0.122385; batch adversarial loss: 0.445839\n",
      "epoch 57; iter: 0; batch classifier loss: 0.097757; batch adversarial loss: 0.411009\n",
      "epoch 58; iter: 0; batch classifier loss: 0.107199; batch adversarial loss: 0.505784\n",
      "epoch 59; iter: 0; batch classifier loss: 0.085013; batch adversarial loss: 0.526092\n",
      "epoch 60; iter: 0; batch classifier loss: 0.119944; batch adversarial loss: 0.441319\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103907; batch adversarial loss: 0.543427\n",
      "epoch 62; iter: 0; batch classifier loss: 0.120081; batch adversarial loss: 0.508070\n",
      "epoch 63; iter: 0; batch classifier loss: 0.114532; batch adversarial loss: 0.460033\n",
      "epoch 64; iter: 0; batch classifier loss: 0.101799; batch adversarial loss: 0.463776\n",
      "epoch 65; iter: 0; batch classifier loss: 0.140166; batch adversarial loss: 0.482878\n",
      "epoch 66; iter: 0; batch classifier loss: 0.136410; batch adversarial loss: 0.440922\n",
      "epoch 67; iter: 0; batch classifier loss: 0.143732; batch adversarial loss: 0.427662\n",
      "epoch 68; iter: 0; batch classifier loss: 0.093094; batch adversarial loss: 0.495079\n",
      "epoch 69; iter: 0; batch classifier loss: 0.160614; batch adversarial loss: 0.464201\n",
      "epoch 70; iter: 0; batch classifier loss: 0.091978; batch adversarial loss: 0.532559\n",
      "epoch 71; iter: 0; batch classifier loss: 0.176495; batch adversarial loss: 0.373606\n",
      "epoch 72; iter: 0; batch classifier loss: 0.108989; batch adversarial loss: 0.442012\n",
      "epoch 73; iter: 0; batch classifier loss: 0.112274; batch adversarial loss: 0.444441\n",
      "epoch 74; iter: 0; batch classifier loss: 0.098921; batch adversarial loss: 0.446154\n",
      "epoch 75; iter: 0; batch classifier loss: 0.144444; batch adversarial loss: 0.542071\n",
      "epoch 76; iter: 0; batch classifier loss: 0.140810; batch adversarial loss: 0.390743\n",
      "epoch 77; iter: 0; batch classifier loss: 0.155538; batch adversarial loss: 0.428691\n",
      "epoch 78; iter: 0; batch classifier loss: 0.175696; batch adversarial loss: 0.458560\n",
      "epoch 79; iter: 0; batch classifier loss: 0.149499; batch adversarial loss: 0.433146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.111774; batch adversarial loss: 0.384296\n",
      "epoch 81; iter: 0; batch classifier loss: 0.105492; batch adversarial loss: 0.461423\n",
      "epoch 82; iter: 0; batch classifier loss: 0.098953; batch adversarial loss: 0.578322\n",
      "epoch 83; iter: 0; batch classifier loss: 0.121962; batch adversarial loss: 0.405418\n",
      "epoch 84; iter: 0; batch classifier loss: 0.122443; batch adversarial loss: 0.428741\n",
      "epoch 85; iter: 0; batch classifier loss: 0.102547; batch adversarial loss: 0.469326\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089748; batch adversarial loss: 0.562722\n",
      "epoch 87; iter: 0; batch classifier loss: 0.114642; batch adversarial loss: 0.523778\n",
      "epoch 88; iter: 0; batch classifier loss: 0.179982; batch adversarial loss: 0.409847\n",
      "epoch 89; iter: 0; batch classifier loss: 0.130513; batch adversarial loss: 0.469972\n",
      "epoch 90; iter: 0; batch classifier loss: 0.161626; batch adversarial loss: 0.420668\n",
      "epoch 91; iter: 0; batch classifier loss: 0.116510; batch adversarial loss: 0.532089\n",
      "epoch 92; iter: 0; batch classifier loss: 0.141832; batch adversarial loss: 0.397988\n",
      "epoch 93; iter: 0; batch classifier loss: 0.154239; batch adversarial loss: 0.348778\n",
      "epoch 94; iter: 0; batch classifier loss: 0.145808; batch adversarial loss: 0.371728\n",
      "epoch 95; iter: 0; batch classifier loss: 0.156375; batch adversarial loss: 0.522267\n",
      "epoch 96; iter: 0; batch classifier loss: 0.112674; batch adversarial loss: 0.558435\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071823; batch adversarial loss: 0.532690\n",
      "epoch 98; iter: 0; batch classifier loss: 0.120062; batch adversarial loss: 0.406289\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071139; batch adversarial loss: 0.498780\n",
      "epoch 100; iter: 0; batch classifier loss: 0.131030; batch adversarial loss: 0.378972\n",
      "epoch 101; iter: 0; batch classifier loss: 0.121200; batch adversarial loss: 0.441366\n",
      "epoch 102; iter: 0; batch classifier loss: 0.118411; batch adversarial loss: 0.488167\n",
      "epoch 103; iter: 0; batch classifier loss: 0.088219; batch adversarial loss: 0.404745\n",
      "epoch 104; iter: 0; batch classifier loss: 0.076426; batch adversarial loss: 0.455411\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084357; batch adversarial loss: 0.418274\n",
      "epoch 106; iter: 0; batch classifier loss: 0.095455; batch adversarial loss: 0.404689\n",
      "epoch 107; iter: 0; batch classifier loss: 0.122758; batch adversarial loss: 0.515052\n",
      "epoch 108; iter: 0; batch classifier loss: 0.102973; batch adversarial loss: 0.446355\n",
      "epoch 109; iter: 0; batch classifier loss: 0.077006; batch adversarial loss: 0.334844\n",
      "epoch 110; iter: 0; batch classifier loss: 0.078601; batch adversarial loss: 0.479486\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054303; batch adversarial loss: 0.528077\n",
      "epoch 112; iter: 0; batch classifier loss: 0.092378; batch adversarial loss: 0.448182\n",
      "epoch 113; iter: 0; batch classifier loss: 0.061055; batch adversarial loss: 0.477847\n",
      "epoch 114; iter: 0; batch classifier loss: 0.084339; batch adversarial loss: 0.474950\n",
      "epoch 115; iter: 0; batch classifier loss: 0.026823; batch adversarial loss: 0.488342\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060617; batch adversarial loss: 0.397790\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048613; batch adversarial loss: 0.530344\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060027; batch adversarial loss: 0.496453\n",
      "epoch 119; iter: 0; batch classifier loss: 0.075933; batch adversarial loss: 0.446388\n",
      "epoch 120; iter: 0; batch classifier loss: 0.072768; batch adversarial loss: 0.492844\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026800; batch adversarial loss: 0.421769\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035781; batch adversarial loss: 0.592974\n",
      "epoch 123; iter: 0; batch classifier loss: 0.067659; batch adversarial loss: 0.488046\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059295; batch adversarial loss: 0.424686\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032236; batch adversarial loss: 0.446405\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044028; batch adversarial loss: 0.422509\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037544; batch adversarial loss: 0.431640\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038552; batch adversarial loss: 0.459764\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038411; batch adversarial loss: 0.444271\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061134; batch adversarial loss: 0.486624\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037529; batch adversarial loss: 0.436770\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048490; batch adversarial loss: 0.470580\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037097; batch adversarial loss: 0.457691\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023517; batch adversarial loss: 0.459750\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044632; batch adversarial loss: 0.412551\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036991; batch adversarial loss: 0.439692\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037094; batch adversarial loss: 0.429505\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036731; batch adversarial loss: 0.440947\n",
      "epoch 139; iter: 0; batch classifier loss: 0.047801; batch adversarial loss: 0.484006\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053579; batch adversarial loss: 0.533631\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035605; batch adversarial loss: 0.544426\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018863; batch adversarial loss: 0.385823\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025944; batch adversarial loss: 0.562530\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019270; batch adversarial loss: 0.501635\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030764; batch adversarial loss: 0.409460\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029728; batch adversarial loss: 0.442678\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036312; batch adversarial loss: 0.496323\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028950; batch adversarial loss: 0.459517\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017001; batch adversarial loss: 0.365305\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052455; batch adversarial loss: 0.437109\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024492; batch adversarial loss: 0.427221\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024690; batch adversarial loss: 0.555618\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028533; batch adversarial loss: 0.407192\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027556; batch adversarial loss: 0.462310\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042683; batch adversarial loss: 0.477793\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040149; batch adversarial loss: 0.412994\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019206; batch adversarial loss: 0.411804\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017022; batch adversarial loss: 0.426847\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029544; batch adversarial loss: 0.477602\n",
      "epoch 160; iter: 0; batch classifier loss: 0.052150; batch adversarial loss: 0.460930\n",
      "epoch 161; iter: 0; batch classifier loss: 0.062586; batch adversarial loss: 0.490990\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009243; batch adversarial loss: 0.382640\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019216; batch adversarial loss: 0.480202\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032054; batch adversarial loss: 0.445543\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023373; batch adversarial loss: 0.507730\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024128; batch adversarial loss: 0.391121\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018814; batch adversarial loss: 0.452458\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022013; batch adversarial loss: 0.559725\n",
      "epoch 169; iter: 0; batch classifier loss: 0.041374; batch adversarial loss: 0.466011\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025238; batch adversarial loss: 0.434038\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038506; batch adversarial loss: 0.475838\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019702; batch adversarial loss: 0.465246\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007508; batch adversarial loss: 0.442929\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026289; batch adversarial loss: 0.516223\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021482; batch adversarial loss: 0.387825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.017935; batch adversarial loss: 0.512810\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015738; batch adversarial loss: 0.490636\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017968; batch adversarial loss: 0.427590\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030124; batch adversarial loss: 0.560106\n",
      "epoch 180; iter: 0; batch classifier loss: 0.042510; batch adversarial loss: 0.403286\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017151; batch adversarial loss: 0.556665\n",
      "epoch 182; iter: 0; batch classifier loss: 0.041216; batch adversarial loss: 0.507527\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016031; batch adversarial loss: 0.412908\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025805; batch adversarial loss: 0.530551\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012410; batch adversarial loss: 0.436275\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015983; batch adversarial loss: 0.433493\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030076; batch adversarial loss: 0.561447\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017047; batch adversarial loss: 0.397286\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015099; batch adversarial loss: 0.375597\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017203; batch adversarial loss: 0.433673\n",
      "epoch 191; iter: 0; batch classifier loss: 0.045905; batch adversarial loss: 0.453197\n",
      "epoch 192; iter: 0; batch classifier loss: 0.034059; batch adversarial loss: 0.464160\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008558; batch adversarial loss: 0.471327\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014777; batch adversarial loss: 0.539579\n",
      "epoch 195; iter: 0; batch classifier loss: 0.039624; batch adversarial loss: 0.389886\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006840; batch adversarial loss: 0.417654\n",
      "epoch 197; iter: 0; batch classifier loss: 0.041049; batch adversarial loss: 0.450546\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004231; batch adversarial loss: 0.436411\n",
      "epoch 199; iter: 0; batch classifier loss: 0.042498; batch adversarial loss: 0.450060\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704579; batch adversarial loss: 0.465615\n",
      "epoch 1; iter: 0; batch classifier loss: 0.431369; batch adversarial loss: 0.509840\n",
      "epoch 2; iter: 0; batch classifier loss: 0.345983; batch adversarial loss: 0.584862\n",
      "epoch 3; iter: 0; batch classifier loss: 0.342214; batch adversarial loss: 0.592717\n",
      "epoch 4; iter: 0; batch classifier loss: 0.361452; batch adversarial loss: 0.606996\n",
      "epoch 5; iter: 0; batch classifier loss: 0.335159; batch adversarial loss: 0.566881\n",
      "epoch 6; iter: 0; batch classifier loss: 0.313894; batch adversarial loss: 0.566589\n",
      "epoch 7; iter: 0; batch classifier loss: 0.273886; batch adversarial loss: 0.582283\n",
      "epoch 8; iter: 0; batch classifier loss: 0.300026; batch adversarial loss: 0.519786\n",
      "epoch 9; iter: 0; batch classifier loss: 0.341217; batch adversarial loss: 0.515634\n",
      "epoch 10; iter: 0; batch classifier loss: 0.267780; batch adversarial loss: 0.602084\n",
      "epoch 11; iter: 0; batch classifier loss: 0.280050; batch adversarial loss: 0.510386\n",
      "epoch 12; iter: 0; batch classifier loss: 0.394568; batch adversarial loss: 0.506305\n",
      "epoch 13; iter: 0; batch classifier loss: 0.412617; batch adversarial loss: 0.552108\n",
      "epoch 14; iter: 0; batch classifier loss: 0.597792; batch adversarial loss: 0.542853\n",
      "epoch 15; iter: 0; batch classifier loss: 0.550902; batch adversarial loss: 0.543429\n",
      "epoch 16; iter: 0; batch classifier loss: 0.371975; batch adversarial loss: 0.461506\n",
      "epoch 17; iter: 0; batch classifier loss: 0.255617; batch adversarial loss: 0.475443\n",
      "epoch 18; iter: 0; batch classifier loss: 0.233807; batch adversarial loss: 0.538086\n",
      "epoch 19; iter: 0; batch classifier loss: 0.199204; batch adversarial loss: 0.504292\n",
      "epoch 20; iter: 0; batch classifier loss: 0.187049; batch adversarial loss: 0.461440\n",
      "epoch 21; iter: 0; batch classifier loss: 0.168913; batch adversarial loss: 0.440875\n",
      "epoch 22; iter: 0; batch classifier loss: 0.238063; batch adversarial loss: 0.438160\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168660; batch adversarial loss: 0.473701\n",
      "epoch 24; iter: 0; batch classifier loss: 0.136006; batch adversarial loss: 0.440388\n",
      "epoch 25; iter: 0; batch classifier loss: 0.156134; batch adversarial loss: 0.561130\n",
      "epoch 26; iter: 0; batch classifier loss: 0.174785; batch adversarial loss: 0.451370\n",
      "epoch 27; iter: 0; batch classifier loss: 0.146624; batch adversarial loss: 0.380188\n",
      "epoch 28; iter: 0; batch classifier loss: 0.133435; batch adversarial loss: 0.440499\n",
      "epoch 29; iter: 0; batch classifier loss: 0.112147; batch adversarial loss: 0.473914\n",
      "epoch 30; iter: 0; batch classifier loss: 0.135456; batch adversarial loss: 0.435460\n",
      "epoch 31; iter: 0; batch classifier loss: 0.144448; batch adversarial loss: 0.439655\n",
      "epoch 32; iter: 0; batch classifier loss: 0.138639; batch adversarial loss: 0.467315\n",
      "epoch 33; iter: 0; batch classifier loss: 0.135462; batch adversarial loss: 0.455816\n",
      "epoch 34; iter: 0; batch classifier loss: 0.088493; batch adversarial loss: 0.511728\n",
      "epoch 35; iter: 0; batch classifier loss: 0.134706; batch adversarial loss: 0.503789\n",
      "epoch 36; iter: 0; batch classifier loss: 0.125558; batch adversarial loss: 0.410111\n",
      "epoch 37; iter: 0; batch classifier loss: 0.107442; batch adversarial loss: 0.408495\n",
      "epoch 38; iter: 0; batch classifier loss: 0.133661; batch adversarial loss: 0.452487\n",
      "epoch 39; iter: 0; batch classifier loss: 0.160785; batch adversarial loss: 0.369225\n",
      "epoch 40; iter: 0; batch classifier loss: 0.070080; batch adversarial loss: 0.552733\n",
      "epoch 41; iter: 0; batch classifier loss: 0.087770; batch adversarial loss: 0.477742\n",
      "epoch 42; iter: 0; batch classifier loss: 0.077151; batch adversarial loss: 0.624902\n",
      "epoch 43; iter: 0; batch classifier loss: 0.093200; batch adversarial loss: 0.484435\n",
      "epoch 44; iter: 0; batch classifier loss: 0.130281; batch adversarial loss: 0.498057\n",
      "epoch 45; iter: 0; batch classifier loss: 0.101312; batch adversarial loss: 0.504516\n",
      "epoch 46; iter: 0; batch classifier loss: 0.120150; batch adversarial loss: 0.431844\n",
      "epoch 47; iter: 0; batch classifier loss: 0.109560; batch adversarial loss: 0.529950\n",
      "epoch 48; iter: 0; batch classifier loss: 0.085361; batch adversarial loss: 0.353563\n",
      "epoch 49; iter: 0; batch classifier loss: 0.133027; batch adversarial loss: 0.448821\n",
      "epoch 50; iter: 0; batch classifier loss: 0.100723; batch adversarial loss: 0.534826\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098256; batch adversarial loss: 0.336473\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089039; batch adversarial loss: 0.308625\n",
      "epoch 53; iter: 0; batch classifier loss: 0.107939; batch adversarial loss: 0.465071\n",
      "epoch 54; iter: 0; batch classifier loss: 0.088079; batch adversarial loss: 0.488485\n",
      "epoch 55; iter: 0; batch classifier loss: 0.073388; batch adversarial loss: 0.361074\n",
      "epoch 56; iter: 0; batch classifier loss: 0.109531; batch adversarial loss: 0.381473\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082994; batch adversarial loss: 0.413322\n",
      "epoch 58; iter: 0; batch classifier loss: 0.105775; batch adversarial loss: 0.523440\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090543; batch adversarial loss: 0.545048\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076790; batch adversarial loss: 0.479528\n",
      "epoch 61; iter: 0; batch classifier loss: 0.068185; batch adversarial loss: 0.415556\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081006; batch adversarial loss: 0.382799\n",
      "epoch 63; iter: 0; batch classifier loss: 0.114613; batch adversarial loss: 0.450874\n",
      "epoch 64; iter: 0; batch classifier loss: 0.116821; batch adversarial loss: 0.576379\n",
      "epoch 65; iter: 0; batch classifier loss: 0.090178; batch adversarial loss: 0.530437\n",
      "epoch 66; iter: 0; batch classifier loss: 0.119327; batch adversarial loss: 0.302023\n",
      "epoch 67; iter: 0; batch classifier loss: 0.106397; batch adversarial loss: 0.330278\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081977; batch adversarial loss: 0.495063\n",
      "epoch 69; iter: 0; batch classifier loss: 0.084105; batch adversarial loss: 0.498821\n",
      "epoch 70; iter: 0; batch classifier loss: 0.099758; batch adversarial loss: 0.431244\n",
      "epoch 71; iter: 0; batch classifier loss: 0.101590; batch adversarial loss: 0.388714\n",
      "epoch 72; iter: 0; batch classifier loss: 0.102223; batch adversarial loss: 0.385942\n",
      "epoch 73; iter: 0; batch classifier loss: 0.096217; batch adversarial loss: 0.533717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.083506; batch adversarial loss: 0.453782\n",
      "epoch 75; iter: 0; batch classifier loss: 0.045248; batch adversarial loss: 0.404904\n",
      "epoch 76; iter: 0; batch classifier loss: 0.117580; batch adversarial loss: 0.470327\n",
      "epoch 77; iter: 0; batch classifier loss: 0.066774; batch adversarial loss: 0.466382\n",
      "epoch 78; iter: 0; batch classifier loss: 0.083554; batch adversarial loss: 0.396838\n",
      "epoch 79; iter: 0; batch classifier loss: 0.111833; batch adversarial loss: 0.523354\n",
      "epoch 80; iter: 0; batch classifier loss: 0.062400; batch adversarial loss: 0.482552\n",
      "epoch 81; iter: 0; batch classifier loss: 0.045664; batch adversarial loss: 0.443700\n",
      "epoch 82; iter: 0; batch classifier loss: 0.098816; batch adversarial loss: 0.498930\n",
      "epoch 83; iter: 0; batch classifier loss: 0.142119; batch adversarial loss: 0.456307\n",
      "epoch 84; iter: 0; batch classifier loss: 0.094953; batch adversarial loss: 0.471969\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064902; batch adversarial loss: 0.438606\n",
      "epoch 86; iter: 0; batch classifier loss: 0.085006; batch adversarial loss: 0.438261\n",
      "epoch 87; iter: 0; batch classifier loss: 0.070846; batch adversarial loss: 0.512663\n",
      "epoch 88; iter: 0; batch classifier loss: 0.083260; batch adversarial loss: 0.428051\n",
      "epoch 89; iter: 0; batch classifier loss: 0.093362; batch adversarial loss: 0.410740\n",
      "epoch 90; iter: 0; batch classifier loss: 0.086790; batch adversarial loss: 0.580779\n",
      "epoch 91; iter: 0; batch classifier loss: 0.054312; batch adversarial loss: 0.495799\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055094; batch adversarial loss: 0.460777\n",
      "epoch 93; iter: 0; batch classifier loss: 0.084043; batch adversarial loss: 0.415455\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077881; batch adversarial loss: 0.423163\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053804; batch adversarial loss: 0.524853\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058317; batch adversarial loss: 0.407235\n",
      "epoch 97; iter: 0; batch classifier loss: 0.067496; batch adversarial loss: 0.492537\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056995; batch adversarial loss: 0.522260\n",
      "epoch 99; iter: 0; batch classifier loss: 0.066545; batch adversarial loss: 0.375141\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060602; batch adversarial loss: 0.422672\n",
      "epoch 101; iter: 0; batch classifier loss: 0.045681; batch adversarial loss: 0.421496\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044246; batch adversarial loss: 0.428973\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061068; batch adversarial loss: 0.525714\n",
      "epoch 104; iter: 0; batch classifier loss: 0.064858; batch adversarial loss: 0.400199\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058722; batch adversarial loss: 0.501786\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043951; batch adversarial loss: 0.392318\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066712; batch adversarial loss: 0.416997\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045572; batch adversarial loss: 0.434869\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066051; batch adversarial loss: 0.453367\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045725; batch adversarial loss: 0.428539\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047484; batch adversarial loss: 0.413206\n",
      "epoch 112; iter: 0; batch classifier loss: 0.066577; batch adversarial loss: 0.501806\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055672; batch adversarial loss: 0.419855\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056697; batch adversarial loss: 0.477303\n",
      "epoch 115; iter: 0; batch classifier loss: 0.064518; batch adversarial loss: 0.396737\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060616; batch adversarial loss: 0.404123\n",
      "epoch 117; iter: 0; batch classifier loss: 0.019911; batch adversarial loss: 0.560436\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028468; batch adversarial loss: 0.501903\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025441; batch adversarial loss: 0.553798\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048919; batch adversarial loss: 0.365755\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024048; batch adversarial loss: 0.450130\n",
      "epoch 122; iter: 0; batch classifier loss: 0.072444; batch adversarial loss: 0.556706\n",
      "epoch 123; iter: 0; batch classifier loss: 0.054159; batch adversarial loss: 0.476126\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039338; batch adversarial loss: 0.532898\n",
      "epoch 125; iter: 0; batch classifier loss: 0.089287; batch adversarial loss: 0.466446\n",
      "epoch 126; iter: 0; batch classifier loss: 0.015463; batch adversarial loss: 0.535383\n",
      "epoch 127; iter: 0; batch classifier loss: 0.058885; batch adversarial loss: 0.534722\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024761; batch adversarial loss: 0.499083\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034215; batch adversarial loss: 0.473200\n",
      "epoch 130; iter: 0; batch classifier loss: 0.013591; batch adversarial loss: 0.415829\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040962; batch adversarial loss: 0.448899\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015051; batch adversarial loss: 0.467143\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045819; batch adversarial loss: 0.382891\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023873; batch adversarial loss: 0.450722\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035622; batch adversarial loss: 0.519860\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021769; batch adversarial loss: 0.549600\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048995; batch adversarial loss: 0.373222\n",
      "epoch 138; iter: 0; batch classifier loss: 0.063623; batch adversarial loss: 0.473347\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036164; batch adversarial loss: 0.420382\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019905; batch adversarial loss: 0.442022\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025397; batch adversarial loss: 0.477130\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026624; batch adversarial loss: 0.567413\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046711; batch adversarial loss: 0.366319\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027610; batch adversarial loss: 0.409133\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024308; batch adversarial loss: 0.502864\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038252; batch adversarial loss: 0.566286\n",
      "epoch 147; iter: 0; batch classifier loss: 0.045030; batch adversarial loss: 0.411570\n",
      "epoch 148; iter: 0; batch classifier loss: 0.006109; batch adversarial loss: 0.411862\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018698; batch adversarial loss: 0.450433\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011252; batch adversarial loss: 0.428669\n",
      "epoch 151; iter: 0; batch classifier loss: 0.053246; batch adversarial loss: 0.463379\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025571; batch adversarial loss: 0.443068\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029559; batch adversarial loss: 0.497482\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044549; batch adversarial loss: 0.564811\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023830; batch adversarial loss: 0.494174\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028552; batch adversarial loss: 0.412340\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010207; batch adversarial loss: 0.400562\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012460; batch adversarial loss: 0.478361\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027341; batch adversarial loss: 0.490676\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014985; batch adversarial loss: 0.545539\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028382; batch adversarial loss: 0.526901\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016143; batch adversarial loss: 0.568146\n",
      "epoch 163; iter: 0; batch classifier loss: 0.041995; batch adversarial loss: 0.496017\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023173; batch adversarial loss: 0.454955\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019851; batch adversarial loss: 0.414425\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018494; batch adversarial loss: 0.564423\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011465; batch adversarial loss: 0.563779\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026099; batch adversarial loss: 0.538800\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034660; batch adversarial loss: 0.404231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.033775; batch adversarial loss: 0.432484\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033572; batch adversarial loss: 0.485047\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015183; batch adversarial loss: 0.486744\n",
      "epoch 173; iter: 0; batch classifier loss: 0.042106; batch adversarial loss: 0.473133\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016958; batch adversarial loss: 0.464700\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039657; batch adversarial loss: 0.416215\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025817; batch adversarial loss: 0.448392\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011101; batch adversarial loss: 0.437989\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024549; batch adversarial loss: 0.437507\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024068; batch adversarial loss: 0.446889\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008642; batch adversarial loss: 0.496315\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014696; batch adversarial loss: 0.458671\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006731; batch adversarial loss: 0.417562\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006919; batch adversarial loss: 0.418517\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016743; batch adversarial loss: 0.404503\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011460; batch adversarial loss: 0.379835\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035706; batch adversarial loss: 0.476732\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013826; batch adversarial loss: 0.403979\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023738; batch adversarial loss: 0.427676\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031463; batch adversarial loss: 0.440853\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018339; batch adversarial loss: 0.466777\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018634; batch adversarial loss: 0.518884\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015115; batch adversarial loss: 0.430634\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035763; batch adversarial loss: 0.428752\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013768; batch adversarial loss: 0.442685\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030965; batch adversarial loss: 0.407499\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017382; batch adversarial loss: 0.441433\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014089; batch adversarial loss: 0.420835\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037317; batch adversarial loss: 0.505588\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024154; batch adversarial loss: 0.512383\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696278; batch adversarial loss: 0.875984\n",
      "epoch 1; iter: 0; batch classifier loss: 0.420294; batch adversarial loss: 0.837955\n",
      "epoch 2; iter: 0; batch classifier loss: 0.364493; batch adversarial loss: 0.818052\n",
      "epoch 3; iter: 0; batch classifier loss: 0.355878; batch adversarial loss: 0.726926\n",
      "epoch 4; iter: 0; batch classifier loss: 0.333152; batch adversarial loss: 0.697145\n",
      "epoch 5; iter: 0; batch classifier loss: 0.261768; batch adversarial loss: 0.652135\n",
      "epoch 6; iter: 0; batch classifier loss: 0.361631; batch adversarial loss: 0.637826\n",
      "epoch 7; iter: 0; batch classifier loss: 0.325923; batch adversarial loss: 0.619257\n",
      "epoch 8; iter: 0; batch classifier loss: 0.325157; batch adversarial loss: 0.588391\n",
      "epoch 9; iter: 0; batch classifier loss: 0.287633; batch adversarial loss: 0.533347\n",
      "epoch 10; iter: 0; batch classifier loss: 0.328941; batch adversarial loss: 0.541238\n",
      "epoch 11; iter: 0; batch classifier loss: 0.285036; batch adversarial loss: 0.483846\n",
      "epoch 12; iter: 0; batch classifier loss: 0.284683; batch adversarial loss: 0.491724\n",
      "epoch 13; iter: 0; batch classifier loss: 0.242797; batch adversarial loss: 0.504708\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236026; batch adversarial loss: 0.459947\n",
      "epoch 15; iter: 0; batch classifier loss: 0.280392; batch adversarial loss: 0.485231\n",
      "epoch 16; iter: 0; batch classifier loss: 0.210880; batch adversarial loss: 0.437862\n",
      "epoch 17; iter: 0; batch classifier loss: 0.219100; batch adversarial loss: 0.473362\n",
      "epoch 18; iter: 0; batch classifier loss: 0.196453; batch adversarial loss: 0.484926\n",
      "epoch 19; iter: 0; batch classifier loss: 0.199224; batch adversarial loss: 0.423593\n",
      "epoch 20; iter: 0; batch classifier loss: 0.169897; batch adversarial loss: 0.462012\n",
      "epoch 21; iter: 0; batch classifier loss: 0.257003; batch adversarial loss: 0.373122\n",
      "epoch 22; iter: 0; batch classifier loss: 0.218488; batch adversarial loss: 0.469464\n",
      "epoch 23; iter: 0; batch classifier loss: 0.250061; batch adversarial loss: 0.436336\n",
      "epoch 24; iter: 0; batch classifier loss: 0.223683; batch adversarial loss: 0.358459\n",
      "epoch 25; iter: 0; batch classifier loss: 0.271852; batch adversarial loss: 0.412801\n",
      "epoch 26; iter: 0; batch classifier loss: 0.236962; batch adversarial loss: 0.360209\n",
      "epoch 27; iter: 0; batch classifier loss: 0.224941; batch adversarial loss: 0.397963\n",
      "epoch 28; iter: 0; batch classifier loss: 0.155254; batch adversarial loss: 0.383102\n",
      "epoch 29; iter: 0; batch classifier loss: 0.181985; batch adversarial loss: 0.418776\n",
      "epoch 30; iter: 0; batch classifier loss: 0.158702; batch adversarial loss: 0.381035\n",
      "epoch 31; iter: 0; batch classifier loss: 0.173304; batch adversarial loss: 0.438487\n",
      "epoch 32; iter: 0; batch classifier loss: 0.115659; batch adversarial loss: 0.436431\n",
      "epoch 33; iter: 0; batch classifier loss: 0.190075; batch adversarial loss: 0.425710\n",
      "epoch 34; iter: 0; batch classifier loss: 0.155706; batch adversarial loss: 0.454073\n",
      "epoch 35; iter: 0; batch classifier loss: 0.139868; batch adversarial loss: 0.385214\n",
      "epoch 36; iter: 0; batch classifier loss: 0.117695; batch adversarial loss: 0.436354\n",
      "epoch 37; iter: 0; batch classifier loss: 0.160099; batch adversarial loss: 0.408825\n",
      "epoch 38; iter: 0; batch classifier loss: 0.121350; batch adversarial loss: 0.385473\n",
      "epoch 39; iter: 0; batch classifier loss: 0.175566; batch adversarial loss: 0.351617\n",
      "epoch 40; iter: 0; batch classifier loss: 0.141302; batch adversarial loss: 0.373553\n",
      "epoch 41; iter: 0; batch classifier loss: 0.119055; batch adversarial loss: 0.450012\n",
      "epoch 42; iter: 0; batch classifier loss: 0.136266; batch adversarial loss: 0.334410\n",
      "epoch 43; iter: 0; batch classifier loss: 0.108039; batch adversarial loss: 0.367840\n",
      "epoch 44; iter: 0; batch classifier loss: 0.137227; batch adversarial loss: 0.365414\n",
      "epoch 45; iter: 0; batch classifier loss: 0.157510; batch adversarial loss: 0.468236\n",
      "epoch 46; iter: 0; batch classifier loss: 0.135631; batch adversarial loss: 0.406706\n",
      "epoch 47; iter: 0; batch classifier loss: 0.093674; batch adversarial loss: 0.404646\n",
      "epoch 48; iter: 0; batch classifier loss: 0.145007; batch adversarial loss: 0.504662\n",
      "epoch 49; iter: 0; batch classifier loss: 0.112337; batch adversarial loss: 0.349428\n",
      "epoch 50; iter: 0; batch classifier loss: 0.117491; batch adversarial loss: 0.389972\n",
      "epoch 51; iter: 0; batch classifier loss: 0.139182; batch adversarial loss: 0.400363\n",
      "epoch 52; iter: 0; batch classifier loss: 0.106877; batch adversarial loss: 0.421058\n",
      "epoch 53; iter: 0; batch classifier loss: 0.123195; batch adversarial loss: 0.351593\n",
      "epoch 54; iter: 0; batch classifier loss: 0.090875; batch adversarial loss: 0.405996\n",
      "epoch 55; iter: 0; batch classifier loss: 0.103353; batch adversarial loss: 0.400753\n",
      "epoch 56; iter: 0; batch classifier loss: 0.079293; batch adversarial loss: 0.414619\n",
      "epoch 57; iter: 0; batch classifier loss: 0.085858; batch adversarial loss: 0.400134\n",
      "epoch 58; iter: 0; batch classifier loss: 0.087718; batch adversarial loss: 0.433932\n",
      "epoch 59; iter: 0; batch classifier loss: 0.142394; batch adversarial loss: 0.498698\n",
      "epoch 60; iter: 0; batch classifier loss: 0.125234; batch adversarial loss: 0.435886\n",
      "epoch 61; iter: 0; batch classifier loss: 0.075852; batch adversarial loss: 0.472807\n",
      "epoch 62; iter: 0; batch classifier loss: 0.106162; batch adversarial loss: 0.448914\n",
      "epoch 63; iter: 0; batch classifier loss: 0.131380; batch adversarial loss: 0.398467\n",
      "epoch 64; iter: 0; batch classifier loss: 0.103536; batch adversarial loss: 0.412098\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088202; batch adversarial loss: 0.406827\n",
      "epoch 66; iter: 0; batch classifier loss: 0.074020; batch adversarial loss: 0.376618\n",
      "epoch 67; iter: 0; batch classifier loss: 0.060228; batch adversarial loss: 0.423502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.074162; batch adversarial loss: 0.392937\n",
      "epoch 69; iter: 0; batch classifier loss: 0.089493; batch adversarial loss: 0.499130\n",
      "epoch 70; iter: 0; batch classifier loss: 0.115430; batch adversarial loss: 0.388128\n",
      "epoch 71; iter: 0; batch classifier loss: 0.055706; batch adversarial loss: 0.441978\n",
      "epoch 72; iter: 0; batch classifier loss: 0.070279; batch adversarial loss: 0.475158\n",
      "epoch 73; iter: 0; batch classifier loss: 0.078942; batch adversarial loss: 0.428136\n",
      "epoch 74; iter: 0; batch classifier loss: 0.051214; batch adversarial loss: 0.385793\n",
      "epoch 75; iter: 0; batch classifier loss: 0.058237; batch adversarial loss: 0.344098\n",
      "epoch 76; iter: 0; batch classifier loss: 0.093175; batch adversarial loss: 0.485649\n",
      "epoch 77; iter: 0; batch classifier loss: 0.071371; batch adversarial loss: 0.392034\n",
      "epoch 78; iter: 0; batch classifier loss: 0.119037; batch adversarial loss: 0.394032\n",
      "epoch 79; iter: 0; batch classifier loss: 0.043282; batch adversarial loss: 0.368629\n",
      "epoch 80; iter: 0; batch classifier loss: 0.073659; batch adversarial loss: 0.452510\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067876; batch adversarial loss: 0.436897\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075545; batch adversarial loss: 0.547520\n",
      "epoch 83; iter: 0; batch classifier loss: 0.047434; batch adversarial loss: 0.399694\n",
      "epoch 84; iter: 0; batch classifier loss: 0.074321; batch adversarial loss: 0.457288\n",
      "epoch 85; iter: 0; batch classifier loss: 0.066821; batch adversarial loss: 0.522206\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083755; batch adversarial loss: 0.401595\n",
      "epoch 87; iter: 0; batch classifier loss: 0.089313; batch adversarial loss: 0.384471\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057679; batch adversarial loss: 0.436821\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098106; batch adversarial loss: 0.376729\n",
      "epoch 90; iter: 0; batch classifier loss: 0.089092; batch adversarial loss: 0.408526\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073108; batch adversarial loss: 0.377411\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082868; batch adversarial loss: 0.464130\n",
      "epoch 93; iter: 0; batch classifier loss: 0.038797; batch adversarial loss: 0.367893\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066576; batch adversarial loss: 0.356313\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047067; batch adversarial loss: 0.418671\n",
      "epoch 96; iter: 0; batch classifier loss: 0.081021; batch adversarial loss: 0.397021\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064352; batch adversarial loss: 0.443223\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055105; batch adversarial loss: 0.403106\n",
      "epoch 99; iter: 0; batch classifier loss: 0.110173; batch adversarial loss: 0.491323\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051188; batch adversarial loss: 0.494713\n",
      "epoch 101; iter: 0; batch classifier loss: 0.059062; batch adversarial loss: 0.404314\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054899; batch adversarial loss: 0.517343\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042997; batch adversarial loss: 0.441399\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044161; batch adversarial loss: 0.444185\n",
      "epoch 105; iter: 0; batch classifier loss: 0.036321; batch adversarial loss: 0.478267\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049659; batch adversarial loss: 0.429626\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024242; batch adversarial loss: 0.432910\n",
      "epoch 108; iter: 0; batch classifier loss: 0.029565; batch adversarial loss: 0.507468\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053700; batch adversarial loss: 0.405970\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037055; batch adversarial loss: 0.480105\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036480; batch adversarial loss: 0.414743\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052666; batch adversarial loss: 0.437616\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044958; batch adversarial loss: 0.508485\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035375; batch adversarial loss: 0.377041\n",
      "epoch 115; iter: 0; batch classifier loss: 0.021237; batch adversarial loss: 0.442034\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041446; batch adversarial loss: 0.387730\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053980; batch adversarial loss: 0.382650\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028284; batch adversarial loss: 0.414914\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050898; batch adversarial loss: 0.454247\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040605; batch adversarial loss: 0.476320\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021522; batch adversarial loss: 0.508655\n",
      "epoch 122; iter: 0; batch classifier loss: 0.020262; batch adversarial loss: 0.488171\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034530; batch adversarial loss: 0.425689\n",
      "epoch 124; iter: 0; batch classifier loss: 0.028056; batch adversarial loss: 0.438174\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030044; batch adversarial loss: 0.489115\n",
      "epoch 126; iter: 0; batch classifier loss: 0.020097; batch adversarial loss: 0.399855\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031055; batch adversarial loss: 0.424567\n",
      "epoch 128; iter: 0; batch classifier loss: 0.055854; batch adversarial loss: 0.458301\n",
      "epoch 129; iter: 0; batch classifier loss: 0.077935; batch adversarial loss: 0.466080\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033326; batch adversarial loss: 0.373228\n",
      "epoch 131; iter: 0; batch classifier loss: 0.059702; batch adversarial loss: 0.614749\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050682; batch adversarial loss: 0.524636\n",
      "epoch 133; iter: 0; batch classifier loss: 0.079511; batch adversarial loss: 0.571098\n",
      "epoch 134; iter: 0; batch classifier loss: 0.060770; batch adversarial loss: 0.539640\n",
      "epoch 135; iter: 0; batch classifier loss: 0.053827; batch adversarial loss: 0.484971\n",
      "epoch 136; iter: 0; batch classifier loss: 0.060930; batch adversarial loss: 0.574863\n",
      "epoch 137; iter: 0; batch classifier loss: 0.159458; batch adversarial loss: 0.744292\n",
      "epoch 138; iter: 0; batch classifier loss: 0.130456; batch adversarial loss: 0.629622\n",
      "epoch 139; iter: 0; batch classifier loss: 0.153779; batch adversarial loss: 0.657242\n",
      "epoch 140; iter: 0; batch classifier loss: 0.080997; batch adversarial loss: 0.549948\n",
      "epoch 141; iter: 0; batch classifier loss: 0.224953; batch adversarial loss: 0.805062\n",
      "epoch 142; iter: 0; batch classifier loss: 0.106391; batch adversarial loss: 0.524363\n",
      "epoch 143; iter: 0; batch classifier loss: 0.260219; batch adversarial loss: 0.861604\n",
      "epoch 144; iter: 0; batch classifier loss: 0.220233; batch adversarial loss: 0.718782\n",
      "epoch 145; iter: 0; batch classifier loss: 0.084400; batch adversarial loss: 0.504634\n",
      "epoch 146; iter: 0; batch classifier loss: 0.132088; batch adversarial loss: 0.522522\n",
      "epoch 147; iter: 0; batch classifier loss: 0.114834; batch adversarial loss: 0.649531\n",
      "epoch 148; iter: 0; batch classifier loss: 0.103701; batch adversarial loss: 0.495091\n",
      "epoch 149; iter: 0; batch classifier loss: 0.137950; batch adversarial loss: 0.641542\n",
      "epoch 150; iter: 0; batch classifier loss: 0.267577; batch adversarial loss: 0.854095\n",
      "epoch 151; iter: 0; batch classifier loss: 0.200792; batch adversarial loss: 0.682931\n",
      "epoch 152; iter: 0; batch classifier loss: 0.175241; batch adversarial loss: 0.649284\n",
      "epoch 153; iter: 0; batch classifier loss: 0.155863; batch adversarial loss: 0.603698\n",
      "epoch 154; iter: 0; batch classifier loss: 0.187333; batch adversarial loss: 0.573267\n",
      "epoch 155; iter: 0; batch classifier loss: 0.142764; batch adversarial loss: 0.560173\n",
      "epoch 156; iter: 0; batch classifier loss: 0.199499; batch adversarial loss: 0.658612\n",
      "epoch 157; iter: 0; batch classifier loss: 0.162218; batch adversarial loss: 0.569719\n",
      "epoch 158; iter: 0; batch classifier loss: 0.136420; batch adversarial loss: 0.543064\n",
      "epoch 159; iter: 0; batch classifier loss: 0.224164; batch adversarial loss: 0.613684\n",
      "epoch 160; iter: 0; batch classifier loss: 0.178780; batch adversarial loss: 0.509479\n",
      "epoch 161; iter: 0; batch classifier loss: 0.198050; batch adversarial loss: 0.663353\n",
      "epoch 162; iter: 0; batch classifier loss: 0.201163; batch adversarial loss: 0.562795\n",
      "epoch 163; iter: 0; batch classifier loss: 0.139532; batch adversarial loss: 0.388347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.125385; batch adversarial loss: 0.541278\n",
      "epoch 165; iter: 0; batch classifier loss: 0.184552; batch adversarial loss: 0.494851\n",
      "epoch 166; iter: 0; batch classifier loss: 0.130640; batch adversarial loss: 0.376516\n",
      "epoch 167; iter: 0; batch classifier loss: 0.154367; batch adversarial loss: 0.551807\n",
      "epoch 168; iter: 0; batch classifier loss: 0.191164; batch adversarial loss: 0.607732\n",
      "epoch 169; iter: 0; batch classifier loss: 0.163239; batch adversarial loss: 0.565901\n",
      "epoch 170; iter: 0; batch classifier loss: 0.147613; batch adversarial loss: 0.556369\n",
      "epoch 171; iter: 0; batch classifier loss: 0.095938; batch adversarial loss: 0.412550\n",
      "epoch 172; iter: 0; batch classifier loss: 0.128620; batch adversarial loss: 0.536475\n",
      "epoch 173; iter: 0; batch classifier loss: 0.084494; batch adversarial loss: 0.452401\n",
      "epoch 174; iter: 0; batch classifier loss: 0.158764; batch adversarial loss: 0.493220\n",
      "epoch 175; iter: 0; batch classifier loss: 0.069943; batch adversarial loss: 0.446258\n",
      "epoch 176; iter: 0; batch classifier loss: 0.128912; batch adversarial loss: 0.471469\n",
      "epoch 177; iter: 0; batch classifier loss: 0.120603; batch adversarial loss: 0.517540\n",
      "epoch 178; iter: 0; batch classifier loss: 0.129986; batch adversarial loss: 0.451541\n",
      "epoch 179; iter: 0; batch classifier loss: 0.128345; batch adversarial loss: 0.482498\n",
      "epoch 180; iter: 0; batch classifier loss: 0.139617; batch adversarial loss: 0.504165\n",
      "epoch 181; iter: 0; batch classifier loss: 0.040275; batch adversarial loss: 0.383203\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033657; batch adversarial loss: 0.468277\n",
      "epoch 183; iter: 0; batch classifier loss: 0.041588; batch adversarial loss: 0.408075\n",
      "epoch 184; iter: 0; batch classifier loss: 0.047956; batch adversarial loss: 0.500228\n",
      "epoch 185; iter: 0; batch classifier loss: 0.041097; batch adversarial loss: 0.524400\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041019; batch adversarial loss: 0.343730\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036425; batch adversarial loss: 0.424649\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022066; batch adversarial loss: 0.515412\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036792; batch adversarial loss: 0.324541\n",
      "epoch 190; iter: 0; batch classifier loss: 0.044447; batch adversarial loss: 0.439157\n",
      "epoch 191; iter: 0; batch classifier loss: 0.040562; batch adversarial loss: 0.437890\n",
      "epoch 192; iter: 0; batch classifier loss: 0.053931; batch adversarial loss: 0.457133\n",
      "epoch 193; iter: 0; batch classifier loss: 0.034378; batch adversarial loss: 0.447587\n",
      "epoch 194; iter: 0; batch classifier loss: 0.077896; batch adversarial loss: 0.390941\n",
      "epoch 195; iter: 0; batch classifier loss: 0.068975; batch adversarial loss: 0.415504\n",
      "epoch 196; iter: 0; batch classifier loss: 0.134389; batch adversarial loss: 0.435259\n",
      "epoch 197; iter: 0; batch classifier loss: 0.064779; batch adversarial loss: 0.455423\n",
      "epoch 198; iter: 0; batch classifier loss: 0.072884; batch adversarial loss: 0.428012\n",
      "epoch 199; iter: 0; batch classifier loss: 0.062548; batch adversarial loss: 0.499212\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691175; batch adversarial loss: 0.511643\n",
      "epoch 1; iter: 0; batch classifier loss: 0.457859; batch adversarial loss: 0.567964\n",
      "epoch 2; iter: 0; batch classifier loss: 0.425717; batch adversarial loss: 0.625557\n",
      "epoch 3; iter: 0; batch classifier loss: 0.405453; batch adversarial loss: 0.578306\n",
      "epoch 4; iter: 0; batch classifier loss: 0.299158; batch adversarial loss: 0.678019\n",
      "epoch 5; iter: 0; batch classifier loss: 0.326869; batch adversarial loss: 0.531317\n",
      "epoch 6; iter: 0; batch classifier loss: 0.349475; batch adversarial loss: 0.552270\n",
      "epoch 7; iter: 0; batch classifier loss: 0.486508; batch adversarial loss: 0.594747\n",
      "epoch 8; iter: 0; batch classifier loss: 0.414229; batch adversarial loss: 0.574102\n",
      "epoch 9; iter: 0; batch classifier loss: 0.348244; batch adversarial loss: 0.513530\n",
      "epoch 10; iter: 0; batch classifier loss: 0.379348; batch adversarial loss: 0.558737\n",
      "epoch 11; iter: 0; batch classifier loss: 0.474434; batch adversarial loss: 0.521918\n",
      "epoch 12; iter: 0; batch classifier loss: 0.437909; batch adversarial loss: 0.511246\n",
      "epoch 13; iter: 0; batch classifier loss: 0.503043; batch adversarial loss: 0.525199\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389808; batch adversarial loss: 0.501998\n",
      "epoch 15; iter: 0; batch classifier loss: 0.274407; batch adversarial loss: 0.474931\n",
      "epoch 16; iter: 0; batch classifier loss: 0.197239; batch adversarial loss: 0.482774\n",
      "epoch 17; iter: 0; batch classifier loss: 0.185142; batch adversarial loss: 0.528785\n",
      "epoch 18; iter: 0; batch classifier loss: 0.240077; batch adversarial loss: 0.472132\n",
      "epoch 19; iter: 0; batch classifier loss: 0.201829; batch adversarial loss: 0.506473\n",
      "epoch 20; iter: 0; batch classifier loss: 0.202826; batch adversarial loss: 0.379614\n",
      "epoch 21; iter: 0; batch classifier loss: 0.152529; batch adversarial loss: 0.384596\n",
      "epoch 22; iter: 0; batch classifier loss: 0.146919; batch adversarial loss: 0.417240\n",
      "epoch 23; iter: 0; batch classifier loss: 0.121259; batch adversarial loss: 0.520525\n",
      "epoch 24; iter: 0; batch classifier loss: 0.102879; batch adversarial loss: 0.474077\n",
      "epoch 25; iter: 0; batch classifier loss: 0.151951; batch adversarial loss: 0.450781\n",
      "epoch 26; iter: 0; batch classifier loss: 0.119274; batch adversarial loss: 0.515153\n",
      "epoch 27; iter: 0; batch classifier loss: 0.142178; batch adversarial loss: 0.484423\n",
      "epoch 28; iter: 0; batch classifier loss: 0.116999; batch adversarial loss: 0.492076\n",
      "epoch 29; iter: 0; batch classifier loss: 0.086504; batch adversarial loss: 0.452647\n",
      "epoch 30; iter: 0; batch classifier loss: 0.086125; batch adversarial loss: 0.362207\n",
      "epoch 31; iter: 0; batch classifier loss: 0.122655; batch adversarial loss: 0.407768\n",
      "epoch 32; iter: 0; batch classifier loss: 0.133635; batch adversarial loss: 0.481298\n",
      "epoch 33; iter: 0; batch classifier loss: 0.087446; batch adversarial loss: 0.521151\n",
      "epoch 34; iter: 0; batch classifier loss: 0.145893; batch adversarial loss: 0.562730\n",
      "epoch 35; iter: 0; batch classifier loss: 0.071934; batch adversarial loss: 0.446181\n",
      "epoch 36; iter: 0; batch classifier loss: 0.144500; batch adversarial loss: 0.418391\n",
      "epoch 37; iter: 0; batch classifier loss: 0.089748; batch adversarial loss: 0.520140\n",
      "epoch 38; iter: 0; batch classifier loss: 0.070134; batch adversarial loss: 0.410376\n",
      "epoch 39; iter: 0; batch classifier loss: 0.103361; batch adversarial loss: 0.507756\n",
      "epoch 40; iter: 0; batch classifier loss: 0.121723; batch adversarial loss: 0.478511\n",
      "epoch 41; iter: 0; batch classifier loss: 0.089963; batch adversarial loss: 0.388355\n",
      "epoch 42; iter: 0; batch classifier loss: 0.075560; batch adversarial loss: 0.314303\n",
      "epoch 43; iter: 0; batch classifier loss: 0.138891; batch adversarial loss: 0.484847\n",
      "epoch 44; iter: 0; batch classifier loss: 0.072866; batch adversarial loss: 0.413245\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117539; batch adversarial loss: 0.430313\n",
      "epoch 46; iter: 0; batch classifier loss: 0.121562; batch adversarial loss: 0.331714\n",
      "epoch 47; iter: 0; batch classifier loss: 0.070014; batch adversarial loss: 0.476330\n",
      "epoch 48; iter: 0; batch classifier loss: 0.091596; batch adversarial loss: 0.563050\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119172; batch adversarial loss: 0.524368\n",
      "epoch 50; iter: 0; batch classifier loss: 0.081886; batch adversarial loss: 0.499450\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098389; batch adversarial loss: 0.427263\n",
      "epoch 52; iter: 0; batch classifier loss: 0.045331; batch adversarial loss: 0.496824\n",
      "epoch 53; iter: 0; batch classifier loss: 0.097733; batch adversarial loss: 0.437600\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096274; batch adversarial loss: 0.519057\n",
      "epoch 55; iter: 0; batch classifier loss: 0.071789; batch adversarial loss: 0.461851\n",
      "epoch 56; iter: 0; batch classifier loss: 0.072541; batch adversarial loss: 0.467710\n",
      "epoch 57; iter: 0; batch classifier loss: 0.069228; batch adversarial loss: 0.453094\n",
      "epoch 58; iter: 0; batch classifier loss: 0.086007; batch adversarial loss: 0.557529\n",
      "epoch 59; iter: 0; batch classifier loss: 0.073488; batch adversarial loss: 0.443320\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081447; batch adversarial loss: 0.521201\n",
      "epoch 61; iter: 0; batch classifier loss: 0.077093; batch adversarial loss: 0.447907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.084524; batch adversarial loss: 0.350479\n",
      "epoch 63; iter: 0; batch classifier loss: 0.086017; batch adversarial loss: 0.501013\n",
      "epoch 64; iter: 0; batch classifier loss: 0.149092; batch adversarial loss: 0.516118\n",
      "epoch 65; iter: 0; batch classifier loss: 0.068658; batch adversarial loss: 0.537399\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078953; batch adversarial loss: 0.578658\n",
      "epoch 67; iter: 0; batch classifier loss: 0.064966; batch adversarial loss: 0.466005\n",
      "epoch 68; iter: 0; batch classifier loss: 0.127977; batch adversarial loss: 0.409182\n",
      "epoch 69; iter: 0; batch classifier loss: 0.132538; batch adversarial loss: 0.476616\n",
      "epoch 70; iter: 0; batch classifier loss: 0.126340; batch adversarial loss: 0.399600\n",
      "epoch 71; iter: 0; batch classifier loss: 0.091690; batch adversarial loss: 0.470068\n",
      "epoch 72; iter: 0; batch classifier loss: 0.068111; batch adversarial loss: 0.526893\n",
      "epoch 73; iter: 0; batch classifier loss: 0.082160; batch adversarial loss: 0.441902\n",
      "epoch 74; iter: 0; batch classifier loss: 0.092092; batch adversarial loss: 0.326882\n",
      "epoch 75; iter: 0; batch classifier loss: 0.064170; batch adversarial loss: 0.522940\n",
      "epoch 76; iter: 0; batch classifier loss: 0.105181; batch adversarial loss: 0.501405\n",
      "epoch 77; iter: 0; batch classifier loss: 0.077700; batch adversarial loss: 0.449157\n",
      "epoch 78; iter: 0; batch classifier loss: 0.070936; batch adversarial loss: 0.451653\n",
      "epoch 79; iter: 0; batch classifier loss: 0.054066; batch adversarial loss: 0.483569\n",
      "epoch 80; iter: 0; batch classifier loss: 0.099947; batch adversarial loss: 0.467146\n",
      "epoch 81; iter: 0; batch classifier loss: 0.156037; batch adversarial loss: 0.535458\n",
      "epoch 82; iter: 0; batch classifier loss: 0.051321; batch adversarial loss: 0.406922\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065948; batch adversarial loss: 0.450683\n",
      "epoch 84; iter: 0; batch classifier loss: 0.072682; batch adversarial loss: 0.495885\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073017; batch adversarial loss: 0.412723\n",
      "epoch 86; iter: 0; batch classifier loss: 0.121363; batch adversarial loss: 0.496795\n",
      "epoch 87; iter: 0; batch classifier loss: 0.064938; batch adversarial loss: 0.419207\n",
      "epoch 88; iter: 0; batch classifier loss: 0.052782; batch adversarial loss: 0.536204\n",
      "epoch 89; iter: 0; batch classifier loss: 0.091588; batch adversarial loss: 0.461446\n",
      "epoch 90; iter: 0; batch classifier loss: 0.081249; batch adversarial loss: 0.478297\n",
      "epoch 91; iter: 0; batch classifier loss: 0.095774; batch adversarial loss: 0.392600\n",
      "epoch 92; iter: 0; batch classifier loss: 0.036537; batch adversarial loss: 0.459224\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051193; batch adversarial loss: 0.416656\n",
      "epoch 94; iter: 0; batch classifier loss: 0.059185; batch adversarial loss: 0.413884\n",
      "epoch 95; iter: 0; batch classifier loss: 0.088175; batch adversarial loss: 0.459909\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062754; batch adversarial loss: 0.457450\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081155; batch adversarial loss: 0.411793\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045293; batch adversarial loss: 0.506313\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073328; batch adversarial loss: 0.515318\n",
      "epoch 100; iter: 0; batch classifier loss: 0.070353; batch adversarial loss: 0.473907\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071698; batch adversarial loss: 0.431737\n",
      "epoch 102; iter: 0; batch classifier loss: 0.098536; batch adversarial loss: 0.428885\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049335; batch adversarial loss: 0.555039\n",
      "epoch 104; iter: 0; batch classifier loss: 0.102355; batch adversarial loss: 0.501114\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042226; batch adversarial loss: 0.482273\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052013; batch adversarial loss: 0.452496\n",
      "epoch 107; iter: 0; batch classifier loss: 0.074987; batch adversarial loss: 0.422196\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056141; batch adversarial loss: 0.530129\n",
      "epoch 109; iter: 0; batch classifier loss: 0.068933; batch adversarial loss: 0.558827\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036717; batch adversarial loss: 0.499301\n",
      "epoch 111; iter: 0; batch classifier loss: 0.093791; batch adversarial loss: 0.497793\n",
      "epoch 112; iter: 0; batch classifier loss: 0.070306; batch adversarial loss: 0.426258\n",
      "epoch 113; iter: 0; batch classifier loss: 0.050408; batch adversarial loss: 0.430887\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054990; batch adversarial loss: 0.436155\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044826; batch adversarial loss: 0.501903\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053597; batch adversarial loss: 0.450265\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034050; batch adversarial loss: 0.445423\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028811; batch adversarial loss: 0.425053\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029166; batch adversarial loss: 0.455413\n",
      "epoch 120; iter: 0; batch classifier loss: 0.082948; batch adversarial loss: 0.501944\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054012; batch adversarial loss: 0.503689\n",
      "epoch 122; iter: 0; batch classifier loss: 0.020562; batch adversarial loss: 0.467037\n",
      "epoch 123; iter: 0; batch classifier loss: 0.059727; batch adversarial loss: 0.540950\n",
      "epoch 124; iter: 0; batch classifier loss: 0.063747; batch adversarial loss: 0.412446\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056495; batch adversarial loss: 0.487086\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031535; batch adversarial loss: 0.482559\n",
      "epoch 127; iter: 0; batch classifier loss: 0.064384; batch adversarial loss: 0.305372\n",
      "epoch 128; iter: 0; batch classifier loss: 0.072551; batch adversarial loss: 0.461615\n",
      "epoch 129; iter: 0; batch classifier loss: 0.082440; batch adversarial loss: 0.516143\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044910; batch adversarial loss: 0.410940\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049065; batch adversarial loss: 0.456666\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029812; batch adversarial loss: 0.447887\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044313; batch adversarial loss: 0.475729\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052619; batch adversarial loss: 0.544959\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032391; batch adversarial loss: 0.517696\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026548; batch adversarial loss: 0.525693\n",
      "epoch 137; iter: 0; batch classifier loss: 0.012948; batch adversarial loss: 0.445457\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029061; batch adversarial loss: 0.489771\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040089; batch adversarial loss: 0.465253\n",
      "epoch 140; iter: 0; batch classifier loss: 0.069973; batch adversarial loss: 0.473159\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049117; batch adversarial loss: 0.423771\n",
      "epoch 142; iter: 0; batch classifier loss: 0.055815; batch adversarial loss: 0.453163\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036413; batch adversarial loss: 0.421504\n",
      "epoch 144; iter: 0; batch classifier loss: 0.047707; batch adversarial loss: 0.510587\n",
      "epoch 145; iter: 0; batch classifier loss: 0.049703; batch adversarial loss: 0.495752\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027324; batch adversarial loss: 0.563725\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027140; batch adversarial loss: 0.457481\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022656; batch adversarial loss: 0.472302\n",
      "epoch 149; iter: 0; batch classifier loss: 0.051759; batch adversarial loss: 0.458167\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040538; batch adversarial loss: 0.432165\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044891; batch adversarial loss: 0.591487\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028640; batch adversarial loss: 0.534617\n",
      "epoch 153; iter: 0; batch classifier loss: 0.033292; batch adversarial loss: 0.455303\n",
      "epoch 154; iter: 0; batch classifier loss: 0.051514; batch adversarial loss: 0.439911\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026782; batch adversarial loss: 0.537871\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024045; batch adversarial loss: 0.482627\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030325; batch adversarial loss: 0.483820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.020438; batch adversarial loss: 0.441672\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020275; batch adversarial loss: 0.467200\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041402; batch adversarial loss: 0.449499\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033222; batch adversarial loss: 0.514625\n",
      "epoch 162; iter: 0; batch classifier loss: 0.047451; batch adversarial loss: 0.492005\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035391; batch adversarial loss: 0.424097\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012457; batch adversarial loss: 0.465524\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017662; batch adversarial loss: 0.432143\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033968; batch adversarial loss: 0.492045\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022776; batch adversarial loss: 0.504541\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008340; batch adversarial loss: 0.453916\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021619; batch adversarial loss: 0.414365\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018186; batch adversarial loss: 0.402276\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021418; batch adversarial loss: 0.516061\n",
      "epoch 172; iter: 0; batch classifier loss: 0.048485; batch adversarial loss: 0.449534\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036393; batch adversarial loss: 0.453029\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039617; batch adversarial loss: 0.488958\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016824; batch adversarial loss: 0.413402\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024333; batch adversarial loss: 0.441919\n",
      "epoch 177; iter: 0; batch classifier loss: 0.043665; batch adversarial loss: 0.410724\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024341; batch adversarial loss: 0.518003\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011411; batch adversarial loss: 0.562860\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010309; batch adversarial loss: 0.512172\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030569; batch adversarial loss: 0.466854\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016560; batch adversarial loss: 0.453310\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027832; batch adversarial loss: 0.517203\n",
      "epoch 184; iter: 0; batch classifier loss: 0.046025; batch adversarial loss: 0.407849\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033664; batch adversarial loss: 0.445368\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013899; batch adversarial loss: 0.387447\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015350; batch adversarial loss: 0.494462\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027673; batch adversarial loss: 0.368043\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033178; batch adversarial loss: 0.438238\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021577; batch adversarial loss: 0.406911\n",
      "epoch 191; iter: 0; batch classifier loss: 0.048309; batch adversarial loss: 0.444632\n",
      "epoch 192; iter: 0; batch classifier loss: 0.034841; batch adversarial loss: 0.441363\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005320; batch adversarial loss: 0.426383\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020398; batch adversarial loss: 0.528476\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004756; batch adversarial loss: 0.481802\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026772; batch adversarial loss: 0.510988\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007875; batch adversarial loss: 0.440746\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008166; batch adversarial loss: 0.407433\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010250; batch adversarial loss: 0.483154\n",
      "epoch 0; iter: 0; batch classifier loss: 0.737117; batch adversarial loss: 0.678022\n",
      "epoch 1; iter: 0; batch classifier loss: 0.371686; batch adversarial loss: 0.648024\n",
      "epoch 2; iter: 0; batch classifier loss: 0.417130; batch adversarial loss: 0.626205\n",
      "epoch 3; iter: 0; batch classifier loss: 0.312344; batch adversarial loss: 0.578257\n",
      "epoch 4; iter: 0; batch classifier loss: 0.275623; batch adversarial loss: 0.568167\n",
      "epoch 5; iter: 0; batch classifier loss: 0.347509; batch adversarial loss: 0.573181\n",
      "epoch 6; iter: 0; batch classifier loss: 0.348424; batch adversarial loss: 0.548247\n",
      "epoch 7; iter: 0; batch classifier loss: 0.288931; batch adversarial loss: 0.568015\n",
      "epoch 8; iter: 0; batch classifier loss: 0.278499; batch adversarial loss: 0.508222\n",
      "epoch 9; iter: 0; batch classifier loss: 0.277920; batch adversarial loss: 0.497692\n",
      "epoch 10; iter: 0; batch classifier loss: 0.240188; batch adversarial loss: 0.530692\n",
      "epoch 11; iter: 0; batch classifier loss: 0.273427; batch adversarial loss: 0.531268\n",
      "epoch 12; iter: 0; batch classifier loss: 0.213791; batch adversarial loss: 0.504560\n",
      "epoch 13; iter: 0; batch classifier loss: 0.228781; batch adversarial loss: 0.552073\n",
      "epoch 14; iter: 0; batch classifier loss: 0.163725; batch adversarial loss: 0.461639\n",
      "epoch 15; iter: 0; batch classifier loss: 0.267043; batch adversarial loss: 0.464565\n",
      "epoch 16; iter: 0; batch classifier loss: 0.205960; batch adversarial loss: 0.423095\n",
      "epoch 17; iter: 0; batch classifier loss: 0.310152; batch adversarial loss: 0.510378\n",
      "epoch 18; iter: 0; batch classifier loss: 0.374046; batch adversarial loss: 0.490640\n",
      "epoch 19; iter: 0; batch classifier loss: 0.352551; batch adversarial loss: 0.458874\n",
      "epoch 20; iter: 0; batch classifier loss: 0.487501; batch adversarial loss: 0.450870\n",
      "epoch 21; iter: 0; batch classifier loss: 0.405053; batch adversarial loss: 0.422952\n",
      "epoch 22; iter: 0; batch classifier loss: 0.209238; batch adversarial loss: 0.454022\n",
      "epoch 23; iter: 0; batch classifier loss: 0.203130; batch adversarial loss: 0.401558\n",
      "epoch 24; iter: 0; batch classifier loss: 0.142557; batch adversarial loss: 0.519940\n",
      "epoch 25; iter: 0; batch classifier loss: 0.156721; batch adversarial loss: 0.397360\n",
      "epoch 26; iter: 0; batch classifier loss: 0.149991; batch adversarial loss: 0.437352\n",
      "epoch 27; iter: 0; batch classifier loss: 0.165361; batch adversarial loss: 0.392372\n",
      "epoch 28; iter: 0; batch classifier loss: 0.127693; batch adversarial loss: 0.417333\n",
      "epoch 29; iter: 0; batch classifier loss: 0.146613; batch adversarial loss: 0.417524\n",
      "epoch 30; iter: 0; batch classifier loss: 0.130394; batch adversarial loss: 0.456729\n",
      "epoch 31; iter: 0; batch classifier loss: 0.203501; batch adversarial loss: 0.364217\n",
      "epoch 32; iter: 0; batch classifier loss: 0.127878; batch adversarial loss: 0.516201\n",
      "epoch 33; iter: 0; batch classifier loss: 0.105252; batch adversarial loss: 0.500364\n",
      "epoch 34; iter: 0; batch classifier loss: 0.103912; batch adversarial loss: 0.355655\n",
      "epoch 35; iter: 0; batch classifier loss: 0.157729; batch adversarial loss: 0.505881\n",
      "epoch 36; iter: 0; batch classifier loss: 0.107990; batch adversarial loss: 0.489617\n",
      "epoch 37; iter: 0; batch classifier loss: 0.067075; batch adversarial loss: 0.504371\n",
      "epoch 38; iter: 0; batch classifier loss: 0.114751; batch adversarial loss: 0.536531\n",
      "epoch 39; iter: 0; batch classifier loss: 0.163774; batch adversarial loss: 0.406696\n",
      "epoch 40; iter: 0; batch classifier loss: 0.111022; batch adversarial loss: 0.429322\n",
      "epoch 41; iter: 0; batch classifier loss: 0.071008; batch adversarial loss: 0.430778\n",
      "epoch 42; iter: 0; batch classifier loss: 0.144112; batch adversarial loss: 0.483387\n",
      "epoch 43; iter: 0; batch classifier loss: 0.084237; batch adversarial loss: 0.457649\n",
      "epoch 44; iter: 0; batch classifier loss: 0.104689; batch adversarial loss: 0.375934\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089368; batch adversarial loss: 0.381232\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112281; batch adversarial loss: 0.473322\n",
      "epoch 47; iter: 0; batch classifier loss: 0.056403; batch adversarial loss: 0.505665\n",
      "epoch 48; iter: 0; batch classifier loss: 0.116724; batch adversarial loss: 0.434103\n",
      "epoch 49; iter: 0; batch classifier loss: 0.095944; batch adversarial loss: 0.449044\n",
      "epoch 50; iter: 0; batch classifier loss: 0.088208; batch adversarial loss: 0.477780\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121956; batch adversarial loss: 0.511015\n",
      "epoch 52; iter: 0; batch classifier loss: 0.078207; batch adversarial loss: 0.458413\n",
      "epoch 53; iter: 0; batch classifier loss: 0.091068; batch adversarial loss: 0.500553\n",
      "epoch 54; iter: 0; batch classifier loss: 0.059924; batch adversarial loss: 0.470824\n",
      "epoch 55; iter: 0; batch classifier loss: 0.056243; batch adversarial loss: 0.472910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.115774; batch adversarial loss: 0.411024\n",
      "epoch 57; iter: 0; batch classifier loss: 0.065883; batch adversarial loss: 0.510017\n",
      "epoch 58; iter: 0; batch classifier loss: 0.045730; batch adversarial loss: 0.533125\n",
      "epoch 59; iter: 0; batch classifier loss: 0.073869; batch adversarial loss: 0.444425\n",
      "epoch 60; iter: 0; batch classifier loss: 0.051953; batch adversarial loss: 0.496515\n",
      "epoch 61; iter: 0; batch classifier loss: 0.083178; batch adversarial loss: 0.522837\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090319; batch adversarial loss: 0.410145\n",
      "epoch 63; iter: 0; batch classifier loss: 0.075617; batch adversarial loss: 0.436795\n",
      "epoch 64; iter: 0; batch classifier loss: 0.060187; batch adversarial loss: 0.473017\n",
      "epoch 65; iter: 0; batch classifier loss: 0.058230; batch adversarial loss: 0.421737\n",
      "epoch 66; iter: 0; batch classifier loss: 0.057516; batch adversarial loss: 0.527526\n",
      "epoch 67; iter: 0; batch classifier loss: 0.072708; batch adversarial loss: 0.502477\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061596; batch adversarial loss: 0.463197\n",
      "epoch 69; iter: 0; batch classifier loss: 0.045807; batch adversarial loss: 0.473003\n",
      "epoch 70; iter: 0; batch classifier loss: 0.092594; batch adversarial loss: 0.452141\n",
      "epoch 71; iter: 0; batch classifier loss: 0.075549; batch adversarial loss: 0.566587\n",
      "epoch 72; iter: 0; batch classifier loss: 0.038521; batch adversarial loss: 0.474109\n",
      "epoch 73; iter: 0; batch classifier loss: 0.097142; batch adversarial loss: 0.396455\n",
      "epoch 74; iter: 0; batch classifier loss: 0.068757; batch adversarial loss: 0.542704\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069131; batch adversarial loss: 0.399907\n",
      "epoch 76; iter: 0; batch classifier loss: 0.066308; batch adversarial loss: 0.427169\n",
      "epoch 77; iter: 0; batch classifier loss: 0.097122; batch adversarial loss: 0.497545\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061006; batch adversarial loss: 0.510882\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074795; batch adversarial loss: 0.478354\n",
      "epoch 80; iter: 0; batch classifier loss: 0.071018; batch adversarial loss: 0.396159\n",
      "epoch 81; iter: 0; batch classifier loss: 0.054259; batch adversarial loss: 0.440255\n",
      "epoch 82; iter: 0; batch classifier loss: 0.087387; batch adversarial loss: 0.475902\n",
      "epoch 83; iter: 0; batch classifier loss: 0.049114; batch adversarial loss: 0.557204\n",
      "epoch 84; iter: 0; batch classifier loss: 0.035512; batch adversarial loss: 0.356355\n",
      "epoch 85; iter: 0; batch classifier loss: 0.047830; batch adversarial loss: 0.451006\n",
      "epoch 86; iter: 0; batch classifier loss: 0.096706; batch adversarial loss: 0.449297\n",
      "epoch 87; iter: 0; batch classifier loss: 0.087142; batch adversarial loss: 0.491143\n",
      "epoch 88; iter: 0; batch classifier loss: 0.096737; batch adversarial loss: 0.417194\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074663; batch adversarial loss: 0.454546\n",
      "epoch 90; iter: 0; batch classifier loss: 0.044489; batch adversarial loss: 0.453301\n",
      "epoch 91; iter: 0; batch classifier loss: 0.033855; batch adversarial loss: 0.526468\n",
      "epoch 92; iter: 0; batch classifier loss: 0.043641; batch adversarial loss: 0.444133\n",
      "epoch 93; iter: 0; batch classifier loss: 0.057178; batch adversarial loss: 0.404828\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047302; batch adversarial loss: 0.438933\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073583; batch adversarial loss: 0.443894\n",
      "epoch 96; iter: 0; batch classifier loss: 0.040736; batch adversarial loss: 0.498764\n",
      "epoch 97; iter: 0; batch classifier loss: 0.027992; batch adversarial loss: 0.502894\n",
      "epoch 98; iter: 0; batch classifier loss: 0.115423; batch adversarial loss: 0.434554\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052289; batch adversarial loss: 0.422559\n",
      "epoch 100; iter: 0; batch classifier loss: 0.070552; batch adversarial loss: 0.455345\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044929; batch adversarial loss: 0.549417\n",
      "epoch 102; iter: 0; batch classifier loss: 0.077150; batch adversarial loss: 0.356801\n",
      "epoch 103; iter: 0; batch classifier loss: 0.029661; batch adversarial loss: 0.436296\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060877; batch adversarial loss: 0.459643\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048731; batch adversarial loss: 0.503746\n",
      "epoch 106; iter: 0; batch classifier loss: 0.038337; batch adversarial loss: 0.560192\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049224; batch adversarial loss: 0.420583\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056807; batch adversarial loss: 0.511855\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050613; batch adversarial loss: 0.427002\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069354; batch adversarial loss: 0.381150\n",
      "epoch 111; iter: 0; batch classifier loss: 0.109765; batch adversarial loss: 0.439222\n",
      "epoch 112; iter: 0; batch classifier loss: 0.058129; batch adversarial loss: 0.382345\n",
      "epoch 113; iter: 0; batch classifier loss: 0.075294; batch adversarial loss: 0.456912\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033558; batch adversarial loss: 0.548796\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040804; batch adversarial loss: 0.432815\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052584; batch adversarial loss: 0.430778\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030759; batch adversarial loss: 0.534702\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026228; batch adversarial loss: 0.406939\n",
      "epoch 119; iter: 0; batch classifier loss: 0.061238; batch adversarial loss: 0.477032\n",
      "epoch 120; iter: 0; batch classifier loss: 0.052839; batch adversarial loss: 0.501439\n",
      "epoch 121; iter: 0; batch classifier loss: 0.017977; batch adversarial loss: 0.362474\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067091; batch adversarial loss: 0.468528\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050686; batch adversarial loss: 0.495414\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039227; batch adversarial loss: 0.445784\n",
      "epoch 125; iter: 0; batch classifier loss: 0.021078; batch adversarial loss: 0.442734\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038598; batch adversarial loss: 0.450538\n",
      "epoch 127; iter: 0; batch classifier loss: 0.066114; batch adversarial loss: 0.377002\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036776; batch adversarial loss: 0.437734\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056002; batch adversarial loss: 0.420343\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048744; batch adversarial loss: 0.424064\n",
      "epoch 131; iter: 0; batch classifier loss: 0.062426; batch adversarial loss: 0.420971\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028440; batch adversarial loss: 0.430980\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042993; batch adversarial loss: 0.443376\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038962; batch adversarial loss: 0.471279\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038811; batch adversarial loss: 0.507120\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038662; batch adversarial loss: 0.476216\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035178; batch adversarial loss: 0.354518\n",
      "epoch 138; iter: 0; batch classifier loss: 0.047219; batch adversarial loss: 0.405019\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040763; batch adversarial loss: 0.474881\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050591; batch adversarial loss: 0.454526\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046984; batch adversarial loss: 0.405761\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026423; batch adversarial loss: 0.524468\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023495; batch adversarial loss: 0.442990\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027058; batch adversarial loss: 0.469601\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040555; batch adversarial loss: 0.411185\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016310; batch adversarial loss: 0.464182\n",
      "epoch 147; iter: 0; batch classifier loss: 0.076594; batch adversarial loss: 0.449130\n",
      "epoch 148; iter: 0; batch classifier loss: 0.062982; batch adversarial loss: 0.383138\n",
      "epoch 149; iter: 0; batch classifier loss: 0.051714; batch adversarial loss: 0.470085\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024050; batch adversarial loss: 0.485699\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038908; batch adversarial loss: 0.467803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.009625; batch adversarial loss: 0.434169\n",
      "epoch 153; iter: 0; batch classifier loss: 0.053294; batch adversarial loss: 0.459229\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022705; batch adversarial loss: 0.458758\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019939; batch adversarial loss: 0.466473\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024186; batch adversarial loss: 0.382747\n",
      "epoch 157; iter: 0; batch classifier loss: 0.049005; batch adversarial loss: 0.445503\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032197; batch adversarial loss: 0.489616\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030211; batch adversarial loss: 0.450643\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046621; batch adversarial loss: 0.362715\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033025; batch adversarial loss: 0.468278\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024666; batch adversarial loss: 0.443758\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038043; batch adversarial loss: 0.426413\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011903; batch adversarial loss: 0.428857\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021464; batch adversarial loss: 0.494708\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015879; batch adversarial loss: 0.345109\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031649; batch adversarial loss: 0.474466\n",
      "epoch 168; iter: 0; batch classifier loss: 0.004311; batch adversarial loss: 0.380639\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020532; batch adversarial loss: 0.451666\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009459; batch adversarial loss: 0.424889\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030846; batch adversarial loss: 0.445895\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028804; batch adversarial loss: 0.462178\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021316; batch adversarial loss: 0.418549\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019996; batch adversarial loss: 0.349530\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037122; batch adversarial loss: 0.440328\n",
      "epoch 176; iter: 0; batch classifier loss: 0.004805; batch adversarial loss: 0.519383\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012786; batch adversarial loss: 0.460314\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016702; batch adversarial loss: 0.474374\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019687; batch adversarial loss: 0.496828\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021089; batch adversarial loss: 0.522668\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018451; batch adversarial loss: 0.440620\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034423; batch adversarial loss: 0.464646\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015340; batch adversarial loss: 0.489467\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011645; batch adversarial loss: 0.425552\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010439; batch adversarial loss: 0.410730\n",
      "epoch 186; iter: 0; batch classifier loss: 0.034104; batch adversarial loss: 0.399375\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010712; batch adversarial loss: 0.429533\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015485; batch adversarial loss: 0.415882\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010137; batch adversarial loss: 0.504637\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016536; batch adversarial loss: 0.464186\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022458; batch adversarial loss: 0.491401\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015503; batch adversarial loss: 0.462947\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016043; batch adversarial loss: 0.464773\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009870; batch adversarial loss: 0.507483\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011811; batch adversarial loss: 0.412624\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010342; batch adversarial loss: 0.409330\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024396; batch adversarial loss: 0.513725\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015737; batch adversarial loss: 0.462477\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021576; batch adversarial loss: 0.416677\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669818; batch adversarial loss: 0.868039\n",
      "epoch 1; iter: 0; batch classifier loss: 0.475682; batch adversarial loss: 0.862493\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571102; batch adversarial loss: 0.831275\n",
      "epoch 3; iter: 0; batch classifier loss: 0.702348; batch adversarial loss: 0.789622\n",
      "epoch 4; iter: 0; batch classifier loss: 0.875891; batch adversarial loss: 0.725058\n",
      "epoch 5; iter: 0; batch classifier loss: 0.813603; batch adversarial loss: 0.677699\n",
      "epoch 6; iter: 0; batch classifier loss: 0.668276; batch adversarial loss: 0.617085\n",
      "epoch 7; iter: 0; batch classifier loss: 0.406195; batch adversarial loss: 0.557598\n",
      "epoch 8; iter: 0; batch classifier loss: 0.419916; batch adversarial loss: 0.536644\n",
      "epoch 9; iter: 0; batch classifier loss: 0.329644; batch adversarial loss: 0.497122\n",
      "epoch 10; iter: 0; batch classifier loss: 0.308280; batch adversarial loss: 0.527873\n",
      "epoch 11; iter: 0; batch classifier loss: 0.283528; batch adversarial loss: 0.544283\n",
      "epoch 12; iter: 0; batch classifier loss: 0.231172; batch adversarial loss: 0.492558\n",
      "epoch 13; iter: 0; batch classifier loss: 0.203553; batch adversarial loss: 0.512394\n",
      "epoch 14; iter: 0; batch classifier loss: 0.174045; batch adversarial loss: 0.462151\n",
      "epoch 15; iter: 0; batch classifier loss: 0.253771; batch adversarial loss: 0.523432\n",
      "epoch 16; iter: 0; batch classifier loss: 0.199454; batch adversarial loss: 0.439477\n",
      "epoch 17; iter: 0; batch classifier loss: 0.153039; batch adversarial loss: 0.448176\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197831; batch adversarial loss: 0.500658\n",
      "epoch 19; iter: 0; batch classifier loss: 0.157189; batch adversarial loss: 0.442385\n",
      "epoch 20; iter: 0; batch classifier loss: 0.181315; batch adversarial loss: 0.495918\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149968; batch adversarial loss: 0.470202\n",
      "epoch 22; iter: 0; batch classifier loss: 0.160942; batch adversarial loss: 0.431226\n",
      "epoch 23; iter: 0; batch classifier loss: 0.133971; batch adversarial loss: 0.536626\n",
      "epoch 24; iter: 0; batch classifier loss: 0.096909; batch adversarial loss: 0.518629\n",
      "epoch 25; iter: 0; batch classifier loss: 0.091748; batch adversarial loss: 0.449556\n",
      "epoch 26; iter: 0; batch classifier loss: 0.108050; batch adversarial loss: 0.447964\n",
      "epoch 27; iter: 0; batch classifier loss: 0.163379; batch adversarial loss: 0.521076\n",
      "epoch 28; iter: 0; batch classifier loss: 0.129741; batch adversarial loss: 0.436025\n",
      "epoch 29; iter: 0; batch classifier loss: 0.095165; batch adversarial loss: 0.488627\n",
      "epoch 30; iter: 0; batch classifier loss: 0.183386; batch adversarial loss: 0.449462\n",
      "epoch 31; iter: 0; batch classifier loss: 0.083296; batch adversarial loss: 0.527486\n",
      "epoch 32; iter: 0; batch classifier loss: 0.122886; batch adversarial loss: 0.428002\n",
      "epoch 33; iter: 0; batch classifier loss: 0.103706; batch adversarial loss: 0.427924\n",
      "epoch 34; iter: 0; batch classifier loss: 0.135079; batch adversarial loss: 0.413611\n",
      "epoch 35; iter: 0; batch classifier loss: 0.106987; batch adversarial loss: 0.439512\n",
      "epoch 36; iter: 0; batch classifier loss: 0.097676; batch adversarial loss: 0.452593\n",
      "epoch 37; iter: 0; batch classifier loss: 0.120105; batch adversarial loss: 0.520604\n",
      "epoch 38; iter: 0; batch classifier loss: 0.088064; batch adversarial loss: 0.390445\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132578; batch adversarial loss: 0.498143\n",
      "epoch 40; iter: 0; batch classifier loss: 0.150043; batch adversarial loss: 0.566311\n",
      "epoch 41; iter: 0; batch classifier loss: 0.087753; batch adversarial loss: 0.462736\n",
      "epoch 42; iter: 0; batch classifier loss: 0.130962; batch adversarial loss: 0.411002\n",
      "epoch 43; iter: 0; batch classifier loss: 0.081318; batch adversarial loss: 0.518882\n",
      "epoch 44; iter: 0; batch classifier loss: 0.062062; batch adversarial loss: 0.398897\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124844; batch adversarial loss: 0.367921\n",
      "epoch 46; iter: 0; batch classifier loss: 0.082305; batch adversarial loss: 0.393526\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106801; batch adversarial loss: 0.502605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.132345; batch adversarial loss: 0.438617\n",
      "epoch 49; iter: 0; batch classifier loss: 0.070802; batch adversarial loss: 0.457907\n",
      "epoch 50; iter: 0; batch classifier loss: 0.059041; batch adversarial loss: 0.549853\n",
      "epoch 51; iter: 0; batch classifier loss: 0.097739; batch adversarial loss: 0.480225\n",
      "epoch 52; iter: 0; batch classifier loss: 0.083096; batch adversarial loss: 0.415881\n",
      "epoch 53; iter: 0; batch classifier loss: 0.110179; batch adversarial loss: 0.461721\n",
      "epoch 54; iter: 0; batch classifier loss: 0.033401; batch adversarial loss: 0.424458\n",
      "epoch 55; iter: 0; batch classifier loss: 0.058210; batch adversarial loss: 0.466609\n",
      "epoch 56; iter: 0; batch classifier loss: 0.078017; batch adversarial loss: 0.424663\n",
      "epoch 57; iter: 0; batch classifier loss: 0.059435; batch adversarial loss: 0.492267\n",
      "epoch 58; iter: 0; batch classifier loss: 0.151766; batch adversarial loss: 0.369928\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081110; batch adversarial loss: 0.445180\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072747; batch adversarial loss: 0.415724\n",
      "epoch 61; iter: 0; batch classifier loss: 0.107712; batch adversarial loss: 0.483309\n",
      "epoch 62; iter: 0; batch classifier loss: 0.063786; batch adversarial loss: 0.502371\n",
      "epoch 63; iter: 0; batch classifier loss: 0.072946; batch adversarial loss: 0.461632\n",
      "epoch 64; iter: 0; batch classifier loss: 0.050104; batch adversarial loss: 0.371620\n",
      "epoch 65; iter: 0; batch classifier loss: 0.055947; batch adversarial loss: 0.482039\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075413; batch adversarial loss: 0.424901\n",
      "epoch 67; iter: 0; batch classifier loss: 0.056010; batch adversarial loss: 0.449319\n",
      "epoch 68; iter: 0; batch classifier loss: 0.033877; batch adversarial loss: 0.446159\n",
      "epoch 69; iter: 0; batch classifier loss: 0.048215; batch adversarial loss: 0.415731\n",
      "epoch 70; iter: 0; batch classifier loss: 0.093106; batch adversarial loss: 0.421397\n",
      "epoch 71; iter: 0; batch classifier loss: 0.039127; batch adversarial loss: 0.473999\n",
      "epoch 72; iter: 0; batch classifier loss: 0.059017; batch adversarial loss: 0.464958\n",
      "epoch 73; iter: 0; batch classifier loss: 0.028805; batch adversarial loss: 0.469136\n",
      "epoch 74; iter: 0; batch classifier loss: 0.044461; batch adversarial loss: 0.409644\n",
      "epoch 75; iter: 0; batch classifier loss: 0.034531; batch adversarial loss: 0.537661\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070028; batch adversarial loss: 0.510050\n",
      "epoch 77; iter: 0; batch classifier loss: 0.036108; batch adversarial loss: 0.384751\n",
      "epoch 78; iter: 0; batch classifier loss: 0.065520; batch adversarial loss: 0.348934\n",
      "epoch 79; iter: 0; batch classifier loss: 0.041898; batch adversarial loss: 0.360718\n",
      "epoch 80; iter: 0; batch classifier loss: 0.108521; batch adversarial loss: 0.455119\n",
      "epoch 81; iter: 0; batch classifier loss: 0.037169; batch adversarial loss: 0.468121\n",
      "epoch 82; iter: 0; batch classifier loss: 0.082535; batch adversarial loss: 0.362616\n",
      "epoch 83; iter: 0; batch classifier loss: 0.029613; batch adversarial loss: 0.410136\n",
      "epoch 84; iter: 0; batch classifier loss: 0.086106; batch adversarial loss: 0.504695\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055846; batch adversarial loss: 0.330122\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046224; batch adversarial loss: 0.464925\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066348; batch adversarial loss: 0.419844\n",
      "epoch 88; iter: 0; batch classifier loss: 0.024865; batch adversarial loss: 0.524942\n",
      "epoch 89; iter: 0; batch classifier loss: 0.039815; batch adversarial loss: 0.425564\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039586; batch adversarial loss: 0.477286\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057579; batch adversarial loss: 0.586528\n",
      "epoch 92; iter: 0; batch classifier loss: 0.035860; batch adversarial loss: 0.626501\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050388; batch adversarial loss: 0.434161\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043771; batch adversarial loss: 0.457571\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081919; batch adversarial loss: 0.405064\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063308; batch adversarial loss: 0.489482\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048840; batch adversarial loss: 0.381857\n",
      "epoch 98; iter: 0; batch classifier loss: 0.020377; batch adversarial loss: 0.432048\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046974; batch adversarial loss: 0.396735\n",
      "epoch 100; iter: 0; batch classifier loss: 0.035831; batch adversarial loss: 0.498375\n",
      "epoch 101; iter: 0; batch classifier loss: 0.032540; batch adversarial loss: 0.423208\n",
      "epoch 102; iter: 0; batch classifier loss: 0.020144; batch adversarial loss: 0.565585\n",
      "epoch 103; iter: 0; batch classifier loss: 0.077048; batch adversarial loss: 0.472902\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045053; batch adversarial loss: 0.389645\n",
      "epoch 105; iter: 0; batch classifier loss: 0.016538; batch adversarial loss: 0.416844\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051726; batch adversarial loss: 0.564574\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035522; batch adversarial loss: 0.453037\n",
      "epoch 108; iter: 0; batch classifier loss: 0.032374; batch adversarial loss: 0.379981\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044400; batch adversarial loss: 0.446072\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025688; batch adversarial loss: 0.377788\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033556; batch adversarial loss: 0.439901\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036965; batch adversarial loss: 0.461646\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028019; batch adversarial loss: 0.397374\n",
      "epoch 114; iter: 0; batch classifier loss: 0.021608; batch adversarial loss: 0.439835\n",
      "epoch 115; iter: 0; batch classifier loss: 0.023630; batch adversarial loss: 0.440855\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024596; batch adversarial loss: 0.483447\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045498; batch adversarial loss: 0.446643\n",
      "epoch 118; iter: 0; batch classifier loss: 0.064522; batch adversarial loss: 0.477886\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046758; batch adversarial loss: 0.445131\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028116; batch adversarial loss: 0.440170\n",
      "epoch 121; iter: 0; batch classifier loss: 0.013368; batch adversarial loss: 0.419692\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043519; batch adversarial loss: 0.383588\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032792; batch adversarial loss: 0.369774\n",
      "epoch 124; iter: 0; batch classifier loss: 0.016172; batch adversarial loss: 0.392712\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026214; batch adversarial loss: 0.391072\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047561; batch adversarial loss: 0.353894\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029873; batch adversarial loss: 0.423734\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021067; batch adversarial loss: 0.446661\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019746; batch adversarial loss: 0.551795\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034112; batch adversarial loss: 0.457500\n",
      "epoch 131; iter: 0; batch classifier loss: 0.062005; batch adversarial loss: 0.418350\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027168; batch adversarial loss: 0.427308\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035718; batch adversarial loss: 0.484218\n",
      "epoch 134; iter: 0; batch classifier loss: 0.009935; batch adversarial loss: 0.459581\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018309; batch adversarial loss: 0.377272\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025167; batch adversarial loss: 0.411436\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031978; batch adversarial loss: 0.522783\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030486; batch adversarial loss: 0.383078\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031325; batch adversarial loss: 0.435652\n",
      "epoch 140; iter: 0; batch classifier loss: 0.042636; batch adversarial loss: 0.509764\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027291; batch adversarial loss: 0.336879\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031565; batch adversarial loss: 0.373376\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033088; batch adversarial loss: 0.444835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.013582; batch adversarial loss: 0.446105\n",
      "epoch 145; iter: 0; batch classifier loss: 0.009779; batch adversarial loss: 0.424773\n",
      "epoch 146; iter: 0; batch classifier loss: 0.046852; batch adversarial loss: 0.510819\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013403; batch adversarial loss: 0.373182\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028902; batch adversarial loss: 0.402949\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030667; batch adversarial loss: 0.475655\n",
      "epoch 150; iter: 0; batch classifier loss: 0.010286; batch adversarial loss: 0.533748\n",
      "epoch 151; iter: 0; batch classifier loss: 0.009778; batch adversarial loss: 0.418830\n",
      "epoch 152; iter: 0; batch classifier loss: 0.068622; batch adversarial loss: 0.390460\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030591; batch adversarial loss: 0.499533\n",
      "epoch 154; iter: 0; batch classifier loss: 0.009595; batch adversarial loss: 0.439424\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052071; batch adversarial loss: 0.457458\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025304; batch adversarial loss: 0.454135\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036592; batch adversarial loss: 0.390124\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020135; batch adversarial loss: 0.425391\n",
      "epoch 159; iter: 0; batch classifier loss: 0.052193; batch adversarial loss: 0.378999\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018567; batch adversarial loss: 0.530788\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016651; batch adversarial loss: 0.506560\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017736; batch adversarial loss: 0.562328\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021401; batch adversarial loss: 0.337747\n",
      "epoch 164; iter: 0; batch classifier loss: 0.053403; batch adversarial loss: 0.435168\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026163; batch adversarial loss: 0.449889\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014091; batch adversarial loss: 0.456055\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023776; batch adversarial loss: 0.390916\n",
      "epoch 168; iter: 0; batch classifier loss: 0.042825; batch adversarial loss: 0.440020\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025909; batch adversarial loss: 0.475538\n",
      "epoch 170; iter: 0; batch classifier loss: 0.036424; batch adversarial loss: 0.352097\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030098; batch adversarial loss: 0.428965\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028364; batch adversarial loss: 0.421716\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016641; batch adversarial loss: 0.393849\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020204; batch adversarial loss: 0.428748\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021638; batch adversarial loss: 0.466363\n",
      "epoch 176; iter: 0; batch classifier loss: 0.005566; batch adversarial loss: 0.505447\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034090; batch adversarial loss: 0.393017\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030854; batch adversarial loss: 0.441165\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010573; batch adversarial loss: 0.466972\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024117; batch adversarial loss: 0.482956\n",
      "epoch 181; iter: 0; batch classifier loss: 0.042001; batch adversarial loss: 0.442734\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027028; batch adversarial loss: 0.457205\n",
      "epoch 183; iter: 0; batch classifier loss: 0.047032; batch adversarial loss: 0.459339\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014149; batch adversarial loss: 0.541458\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013330; batch adversarial loss: 0.508846\n",
      "epoch 186; iter: 0; batch classifier loss: 0.062425; batch adversarial loss: 0.494675\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025149; batch adversarial loss: 0.367404\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040756; batch adversarial loss: 0.465367\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022290; batch adversarial loss: 0.445288\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013019; batch adversarial loss: 0.504201\n",
      "epoch 191; iter: 0; batch classifier loss: 0.046080; batch adversarial loss: 0.485141\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022133; batch adversarial loss: 0.440711\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017360; batch adversarial loss: 0.441534\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021860; batch adversarial loss: 0.407122\n",
      "epoch 195; iter: 0; batch classifier loss: 0.033036; batch adversarial loss: 0.461949\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014985; batch adversarial loss: 0.483503\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013778; batch adversarial loss: 0.434942\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019338; batch adversarial loss: 0.518937\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031817; batch adversarial loss: 0.442039\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700522; batch adversarial loss: 0.913334\n",
      "epoch 1; iter: 0; batch classifier loss: 0.515670; batch adversarial loss: 0.883801\n",
      "epoch 2; iter: 0; batch classifier loss: 0.515110; batch adversarial loss: 0.854477\n",
      "epoch 3; iter: 0; batch classifier loss: 0.700074; batch adversarial loss: 0.817741\n",
      "epoch 4; iter: 0; batch classifier loss: 0.842037; batch adversarial loss: 0.742578\n",
      "epoch 5; iter: 0; batch classifier loss: 0.768752; batch adversarial loss: 0.678668\n",
      "epoch 6; iter: 0; batch classifier loss: 0.706514; batch adversarial loss: 0.609873\n",
      "epoch 7; iter: 0; batch classifier loss: 0.400859; batch adversarial loss: 0.570961\n",
      "epoch 8; iter: 0; batch classifier loss: 0.474446; batch adversarial loss: 0.556487\n",
      "epoch 9; iter: 0; batch classifier loss: 0.383282; batch adversarial loss: 0.539637\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358556; batch adversarial loss: 0.531221\n",
      "epoch 11; iter: 0; batch classifier loss: 0.362448; batch adversarial loss: 0.506282\n",
      "epoch 12; iter: 0; batch classifier loss: 0.258731; batch adversarial loss: 0.479493\n",
      "epoch 13; iter: 0; batch classifier loss: 0.275074; batch adversarial loss: 0.445307\n",
      "epoch 14; iter: 0; batch classifier loss: 0.233756; batch adversarial loss: 0.482787\n",
      "epoch 15; iter: 0; batch classifier loss: 0.286362; batch adversarial loss: 0.508422\n",
      "epoch 16; iter: 0; batch classifier loss: 0.177032; batch adversarial loss: 0.470355\n",
      "epoch 17; iter: 0; batch classifier loss: 0.184045; batch adversarial loss: 0.507701\n",
      "epoch 18; iter: 0; batch classifier loss: 0.157390; batch adversarial loss: 0.459388\n",
      "epoch 19; iter: 0; batch classifier loss: 0.170366; batch adversarial loss: 0.467069\n",
      "epoch 20; iter: 0; batch classifier loss: 0.197263; batch adversarial loss: 0.412221\n",
      "epoch 21; iter: 0; batch classifier loss: 0.161779; batch adversarial loss: 0.484929\n",
      "epoch 22; iter: 0; batch classifier loss: 0.141395; batch adversarial loss: 0.422447\n",
      "epoch 23; iter: 0; batch classifier loss: 0.138356; batch adversarial loss: 0.423257\n",
      "epoch 24; iter: 0; batch classifier loss: 0.107806; batch adversarial loss: 0.445669\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172498; batch adversarial loss: 0.465333\n",
      "epoch 26; iter: 0; batch classifier loss: 0.127123; batch adversarial loss: 0.463238\n",
      "epoch 27; iter: 0; batch classifier loss: 0.094463; batch adversarial loss: 0.470188\n",
      "epoch 28; iter: 0; batch classifier loss: 0.102873; batch adversarial loss: 0.473992\n",
      "epoch 29; iter: 0; batch classifier loss: 0.125793; batch adversarial loss: 0.424896\n",
      "epoch 30; iter: 0; batch classifier loss: 0.113156; batch adversarial loss: 0.447483\n",
      "epoch 31; iter: 0; batch classifier loss: 0.075580; batch adversarial loss: 0.550207\n",
      "epoch 32; iter: 0; batch classifier loss: 0.125275; batch adversarial loss: 0.487757\n",
      "epoch 33; iter: 0; batch classifier loss: 0.080156; batch adversarial loss: 0.410110\n",
      "epoch 34; iter: 0; batch classifier loss: 0.101546; batch adversarial loss: 0.408957\n",
      "epoch 35; iter: 0; batch classifier loss: 0.109759; batch adversarial loss: 0.402503\n",
      "epoch 36; iter: 0; batch classifier loss: 0.087277; batch adversarial loss: 0.415780\n",
      "epoch 37; iter: 0; batch classifier loss: 0.093392; batch adversarial loss: 0.468131\n",
      "epoch 38; iter: 0; batch classifier loss: 0.121890; batch adversarial loss: 0.465201\n",
      "epoch 39; iter: 0; batch classifier loss: 0.096147; batch adversarial loss: 0.425545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.074409; batch adversarial loss: 0.458194\n",
      "epoch 41; iter: 0; batch classifier loss: 0.108680; batch adversarial loss: 0.426579\n",
      "epoch 42; iter: 0; batch classifier loss: 0.123438; batch adversarial loss: 0.459565\n",
      "epoch 43; iter: 0; batch classifier loss: 0.165336; batch adversarial loss: 0.512705\n",
      "epoch 44; iter: 0; batch classifier loss: 0.090925; batch adversarial loss: 0.489377\n",
      "epoch 45; iter: 0; batch classifier loss: 0.052125; batch adversarial loss: 0.474716\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102410; batch adversarial loss: 0.360609\n",
      "epoch 47; iter: 0; batch classifier loss: 0.086715; batch adversarial loss: 0.383074\n",
      "epoch 48; iter: 0; batch classifier loss: 0.106146; batch adversarial loss: 0.406657\n",
      "epoch 49; iter: 0; batch classifier loss: 0.083342; batch adversarial loss: 0.446033\n",
      "epoch 50; iter: 0; batch classifier loss: 0.070092; batch adversarial loss: 0.480837\n",
      "epoch 51; iter: 0; batch classifier loss: 0.094439; batch adversarial loss: 0.432522\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096444; batch adversarial loss: 0.441443\n",
      "epoch 53; iter: 0; batch classifier loss: 0.082821; batch adversarial loss: 0.407269\n",
      "epoch 54; iter: 0; batch classifier loss: 0.092757; batch adversarial loss: 0.463909\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079996; batch adversarial loss: 0.356496\n",
      "epoch 56; iter: 0; batch classifier loss: 0.071304; batch adversarial loss: 0.507797\n",
      "epoch 57; iter: 0; batch classifier loss: 0.051373; batch adversarial loss: 0.430875\n",
      "epoch 58; iter: 0; batch classifier loss: 0.070539; batch adversarial loss: 0.451496\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102218; batch adversarial loss: 0.469461\n",
      "epoch 60; iter: 0; batch classifier loss: 0.082658; batch adversarial loss: 0.429727\n",
      "epoch 61; iter: 0; batch classifier loss: 0.060335; batch adversarial loss: 0.442819\n",
      "epoch 62; iter: 0; batch classifier loss: 0.070436; batch adversarial loss: 0.447733\n",
      "epoch 63; iter: 0; batch classifier loss: 0.072297; batch adversarial loss: 0.518441\n",
      "epoch 64; iter: 0; batch classifier loss: 0.049834; batch adversarial loss: 0.382945\n",
      "epoch 65; iter: 0; batch classifier loss: 0.076978; batch adversarial loss: 0.365122\n",
      "epoch 66; iter: 0; batch classifier loss: 0.032500; batch adversarial loss: 0.471110\n",
      "epoch 67; iter: 0; batch classifier loss: 0.065232; batch adversarial loss: 0.404145\n",
      "epoch 68; iter: 0; batch classifier loss: 0.043000; batch adversarial loss: 0.462543\n",
      "epoch 69; iter: 0; batch classifier loss: 0.057321; batch adversarial loss: 0.421245\n",
      "epoch 70; iter: 0; batch classifier loss: 0.044158; batch adversarial loss: 0.385709\n",
      "epoch 71; iter: 0; batch classifier loss: 0.066633; batch adversarial loss: 0.492524\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087889; batch adversarial loss: 0.458371\n",
      "epoch 73; iter: 0; batch classifier loss: 0.040907; batch adversarial loss: 0.473835\n",
      "epoch 74; iter: 0; batch classifier loss: 0.044189; batch adversarial loss: 0.334821\n",
      "epoch 75; iter: 0; batch classifier loss: 0.041378; batch adversarial loss: 0.438342\n",
      "epoch 76; iter: 0; batch classifier loss: 0.048156; batch adversarial loss: 0.413759\n",
      "epoch 77; iter: 0; batch classifier loss: 0.075577; batch adversarial loss: 0.396450\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074246; batch adversarial loss: 0.428843\n",
      "epoch 79; iter: 0; batch classifier loss: 0.027429; batch adversarial loss: 0.419453\n",
      "epoch 80; iter: 0; batch classifier loss: 0.081615; batch adversarial loss: 0.432801\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067742; batch adversarial loss: 0.514784\n",
      "epoch 82; iter: 0; batch classifier loss: 0.047325; batch adversarial loss: 0.471554\n",
      "epoch 83; iter: 0; batch classifier loss: 0.084451; batch adversarial loss: 0.426687\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052851; batch adversarial loss: 0.411942\n",
      "epoch 85; iter: 0; batch classifier loss: 0.039257; batch adversarial loss: 0.365703\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061486; batch adversarial loss: 0.488392\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057204; batch adversarial loss: 0.483359\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057503; batch adversarial loss: 0.461291\n",
      "epoch 89; iter: 0; batch classifier loss: 0.111861; batch adversarial loss: 0.510695\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075907; batch adversarial loss: 0.448188\n",
      "epoch 91; iter: 0; batch classifier loss: 0.018913; batch adversarial loss: 0.363993\n",
      "epoch 92; iter: 0; batch classifier loss: 0.081606; batch adversarial loss: 0.454131\n",
      "epoch 93; iter: 0; batch classifier loss: 0.049970; batch adversarial loss: 0.486744\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062941; batch adversarial loss: 0.383434\n",
      "epoch 95; iter: 0; batch classifier loss: 0.061788; batch adversarial loss: 0.401696\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065587; batch adversarial loss: 0.435206\n",
      "epoch 97; iter: 0; batch classifier loss: 0.078314; batch adversarial loss: 0.436188\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072991; batch adversarial loss: 0.533169\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044890; batch adversarial loss: 0.453799\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043114; batch adversarial loss: 0.531299\n",
      "epoch 101; iter: 0; batch classifier loss: 0.020254; batch adversarial loss: 0.450093\n",
      "epoch 102; iter: 0; batch classifier loss: 0.088823; batch adversarial loss: 0.475720\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055941; batch adversarial loss: 0.430340\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037056; batch adversarial loss: 0.435332\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055675; batch adversarial loss: 0.503379\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047726; batch adversarial loss: 0.379916\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034593; batch adversarial loss: 0.383970\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049084; batch adversarial loss: 0.411492\n",
      "epoch 109; iter: 0; batch classifier loss: 0.031131; batch adversarial loss: 0.375422\n",
      "epoch 110; iter: 0; batch classifier loss: 0.093045; batch adversarial loss: 0.429484\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033272; batch adversarial loss: 0.350441\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043508; batch adversarial loss: 0.418441\n",
      "epoch 113; iter: 0; batch classifier loss: 0.091609; batch adversarial loss: 0.478559\n",
      "epoch 114; iter: 0; batch classifier loss: 0.070423; batch adversarial loss: 0.452617\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065174; batch adversarial loss: 0.456019\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039991; batch adversarial loss: 0.464034\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039958; batch adversarial loss: 0.440483\n",
      "epoch 118; iter: 0; batch classifier loss: 0.061110; batch adversarial loss: 0.391573\n",
      "epoch 119; iter: 0; batch classifier loss: 0.072077; batch adversarial loss: 0.492233\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054652; batch adversarial loss: 0.492465\n",
      "epoch 121; iter: 0; batch classifier loss: 0.068472; batch adversarial loss: 0.383603\n",
      "epoch 122; iter: 0; batch classifier loss: 0.077010; batch adversarial loss: 0.425943\n",
      "epoch 123; iter: 0; batch classifier loss: 0.066148; batch adversarial loss: 0.541000\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048433; batch adversarial loss: 0.482705\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036955; batch adversarial loss: 0.413873\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028097; batch adversarial loss: 0.428456\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043190; batch adversarial loss: 0.456328\n",
      "epoch 128; iter: 0; batch classifier loss: 0.020479; batch adversarial loss: 0.428004\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043173; batch adversarial loss: 0.531814\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039483; batch adversarial loss: 0.406002\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044984; batch adversarial loss: 0.443023\n",
      "epoch 132; iter: 0; batch classifier loss: 0.052284; batch adversarial loss: 0.541716\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038832; batch adversarial loss: 0.417911\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040355; batch adversarial loss: 0.347389\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046952; batch adversarial loss: 0.478972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.046063; batch adversarial loss: 0.447143\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054441; batch adversarial loss: 0.453343\n",
      "epoch 138; iter: 0; batch classifier loss: 0.061454; batch adversarial loss: 0.435184\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018276; batch adversarial loss: 0.400480\n",
      "epoch 140; iter: 0; batch classifier loss: 0.070403; batch adversarial loss: 0.459102\n",
      "epoch 141; iter: 0; batch classifier loss: 0.051373; batch adversarial loss: 0.462820\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042112; batch adversarial loss: 0.363783\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034570; batch adversarial loss: 0.506998\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032712; batch adversarial loss: 0.378025\n",
      "epoch 145; iter: 0; batch classifier loss: 0.072107; batch adversarial loss: 0.448930\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032197; batch adversarial loss: 0.500647\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037471; batch adversarial loss: 0.508542\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038269; batch adversarial loss: 0.450434\n",
      "epoch 149; iter: 0; batch classifier loss: 0.058479; batch adversarial loss: 0.563631\n",
      "epoch 150; iter: 0; batch classifier loss: 0.069216; batch adversarial loss: 0.364531\n",
      "epoch 151; iter: 0; batch classifier loss: 0.055777; batch adversarial loss: 0.395965\n",
      "epoch 152; iter: 0; batch classifier loss: 0.043552; batch adversarial loss: 0.491881\n",
      "epoch 153; iter: 0; batch classifier loss: 0.099859; batch adversarial loss: 0.490268\n",
      "epoch 154; iter: 0; batch classifier loss: 0.054585; batch adversarial loss: 0.487565\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027863; batch adversarial loss: 0.396720\n",
      "epoch 156; iter: 0; batch classifier loss: 0.054587; batch adversarial loss: 0.403264\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021984; batch adversarial loss: 0.344538\n",
      "epoch 158; iter: 0; batch classifier loss: 0.050417; batch adversarial loss: 0.441319\n",
      "epoch 159; iter: 0; batch classifier loss: 0.070129; batch adversarial loss: 0.468013\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034690; batch adversarial loss: 0.494742\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024842; batch adversarial loss: 0.463432\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036162; batch adversarial loss: 0.456006\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030143; batch adversarial loss: 0.439099\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016973; batch adversarial loss: 0.413927\n",
      "epoch 165; iter: 0; batch classifier loss: 0.061458; batch adversarial loss: 0.364091\n",
      "epoch 166; iter: 0; batch classifier loss: 0.052777; batch adversarial loss: 0.440562\n",
      "epoch 167; iter: 0; batch classifier loss: 0.046287; batch adversarial loss: 0.470633\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026526; batch adversarial loss: 0.414977\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026487; batch adversarial loss: 0.485910\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037804; batch adversarial loss: 0.393122\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033569; batch adversarial loss: 0.383660\n",
      "epoch 172; iter: 0; batch classifier loss: 0.057325; batch adversarial loss: 0.376135\n",
      "epoch 173; iter: 0; batch classifier loss: 0.050918; batch adversarial loss: 0.461203\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039533; batch adversarial loss: 0.377355\n",
      "epoch 175; iter: 0; batch classifier loss: 0.049327; batch adversarial loss: 0.414590\n",
      "epoch 176; iter: 0; batch classifier loss: 0.046501; batch adversarial loss: 0.433038\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042089; batch adversarial loss: 0.466273\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028565; batch adversarial loss: 0.426839\n",
      "epoch 179; iter: 0; batch classifier loss: 0.060675; batch adversarial loss: 0.461358\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032687; batch adversarial loss: 0.391450\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016655; batch adversarial loss: 0.359205\n",
      "epoch 182; iter: 0; batch classifier loss: 0.045546; batch adversarial loss: 0.446622\n",
      "epoch 183; iter: 0; batch classifier loss: 0.049805; batch adversarial loss: 0.409114\n",
      "epoch 184; iter: 0; batch classifier loss: 0.049791; batch adversarial loss: 0.556418\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036758; batch adversarial loss: 0.441446\n",
      "epoch 186; iter: 0; batch classifier loss: 0.046064; batch adversarial loss: 0.345040\n",
      "epoch 187; iter: 0; batch classifier loss: 0.045643; batch adversarial loss: 0.530098\n",
      "epoch 188; iter: 0; batch classifier loss: 0.056541; batch adversarial loss: 0.434777\n",
      "epoch 189; iter: 0; batch classifier loss: 0.043322; batch adversarial loss: 0.346968\n",
      "epoch 190; iter: 0; batch classifier loss: 0.044020; batch adversarial loss: 0.511440\n",
      "epoch 191; iter: 0; batch classifier loss: 0.043902; batch adversarial loss: 0.397386\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018842; batch adversarial loss: 0.413060\n",
      "epoch 193; iter: 0; batch classifier loss: 0.051294; batch adversarial loss: 0.434039\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033548; batch adversarial loss: 0.447428\n",
      "epoch 195; iter: 0; batch classifier loss: 0.055677; batch adversarial loss: 0.344002\n",
      "epoch 196; iter: 0; batch classifier loss: 0.047833; batch adversarial loss: 0.423792\n",
      "epoch 197; iter: 0; batch classifier loss: 0.050169; batch adversarial loss: 0.441498\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038384; batch adversarial loss: 0.523799\n",
      "epoch 199; iter: 0; batch classifier loss: 0.070733; batch adversarial loss: 0.467452\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673646; batch adversarial loss: 0.720230\n",
      "epoch 1; iter: 0; batch classifier loss: 0.533991; batch adversarial loss: 0.667701\n",
      "epoch 2; iter: 0; batch classifier loss: 0.345455; batch adversarial loss: 0.627573\n",
      "epoch 3; iter: 0; batch classifier loss: 0.434779; batch adversarial loss: 0.623687\n",
      "epoch 4; iter: 0; batch classifier loss: 0.395990; batch adversarial loss: 0.573463\n",
      "epoch 5; iter: 0; batch classifier loss: 0.371805; batch adversarial loss: 0.599772\n",
      "epoch 6; iter: 0; batch classifier loss: 0.402436; batch adversarial loss: 0.579391\n",
      "epoch 7; iter: 0; batch classifier loss: 0.391353; batch adversarial loss: 0.551486\n",
      "epoch 8; iter: 0; batch classifier loss: 0.375876; batch adversarial loss: 0.515893\n",
      "epoch 9; iter: 0; batch classifier loss: 0.337579; batch adversarial loss: 0.488401\n",
      "epoch 10; iter: 0; batch classifier loss: 0.282207; batch adversarial loss: 0.549277\n",
      "epoch 11; iter: 0; batch classifier loss: 0.288292; batch adversarial loss: 0.539216\n",
      "epoch 12; iter: 0; batch classifier loss: 0.292431; batch adversarial loss: 0.585371\n",
      "epoch 13; iter: 0; batch classifier loss: 0.278500; batch adversarial loss: 0.512068\n",
      "epoch 14; iter: 0; batch classifier loss: 0.339857; batch adversarial loss: 0.461765\n",
      "epoch 15; iter: 0; batch classifier loss: 0.220453; batch adversarial loss: 0.490768\n",
      "epoch 16; iter: 0; batch classifier loss: 0.244418; batch adversarial loss: 0.571380\n",
      "epoch 17; iter: 0; batch classifier loss: 0.301696; batch adversarial loss: 0.471459\n",
      "epoch 18; iter: 0; batch classifier loss: 0.248929; batch adversarial loss: 0.519745\n",
      "epoch 19; iter: 0; batch classifier loss: 0.276368; batch adversarial loss: 0.519230\n",
      "epoch 20; iter: 0; batch classifier loss: 0.227682; batch adversarial loss: 0.443938\n",
      "epoch 21; iter: 0; batch classifier loss: 0.340992; batch adversarial loss: 0.444031\n",
      "epoch 22; iter: 0; batch classifier loss: 0.339045; batch adversarial loss: 0.463675\n",
      "epoch 23; iter: 0; batch classifier loss: 0.227576; batch adversarial loss: 0.513933\n",
      "epoch 24; iter: 0; batch classifier loss: 0.274425; batch adversarial loss: 0.432438\n",
      "epoch 25; iter: 0; batch classifier loss: 0.205310; batch adversarial loss: 0.471168\n",
      "epoch 26; iter: 0; batch classifier loss: 0.177026; batch adversarial loss: 0.464919\n",
      "epoch 27; iter: 0; batch classifier loss: 0.259211; batch adversarial loss: 0.446324\n",
      "epoch 28; iter: 0; batch classifier loss: 0.262051; batch adversarial loss: 0.441725\n",
      "epoch 29; iter: 0; batch classifier loss: 0.243002; batch adversarial loss: 0.421654\n",
      "epoch 30; iter: 0; batch classifier loss: 0.198599; batch adversarial loss: 0.484368\n",
      "epoch 31; iter: 0; batch classifier loss: 0.168384; batch adversarial loss: 0.418579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.210235; batch adversarial loss: 0.472257\n",
      "epoch 33; iter: 0; batch classifier loss: 0.262416; batch adversarial loss: 0.441676\n",
      "epoch 34; iter: 0; batch classifier loss: 0.209946; batch adversarial loss: 0.521262\n",
      "epoch 35; iter: 0; batch classifier loss: 0.251598; batch adversarial loss: 0.474623\n",
      "epoch 36; iter: 0; batch classifier loss: 0.182571; batch adversarial loss: 0.467920\n",
      "epoch 37; iter: 0; batch classifier loss: 0.229900; batch adversarial loss: 0.463520\n",
      "epoch 38; iter: 0; batch classifier loss: 0.232475; batch adversarial loss: 0.413691\n",
      "epoch 39; iter: 0; batch classifier loss: 0.143838; batch adversarial loss: 0.569507\n",
      "epoch 40; iter: 0; batch classifier loss: 0.206636; batch adversarial loss: 0.479614\n",
      "epoch 41; iter: 0; batch classifier loss: 0.205772; batch adversarial loss: 0.484689\n",
      "epoch 42; iter: 0; batch classifier loss: 0.231712; batch adversarial loss: 0.438792\n",
      "epoch 43; iter: 0; batch classifier loss: 0.209938; batch adversarial loss: 0.438771\n",
      "epoch 44; iter: 0; batch classifier loss: 0.196551; batch adversarial loss: 0.460812\n",
      "epoch 45; iter: 0; batch classifier loss: 0.222957; batch adversarial loss: 0.467768\n",
      "epoch 46; iter: 0; batch classifier loss: 0.200572; batch adversarial loss: 0.406472\n",
      "epoch 47; iter: 0; batch classifier loss: 0.216287; batch adversarial loss: 0.556876\n",
      "epoch 48; iter: 0; batch classifier loss: 0.227851; batch adversarial loss: 0.408043\n",
      "epoch 49; iter: 0; batch classifier loss: 0.247801; batch adversarial loss: 0.375950\n",
      "epoch 50; iter: 0; batch classifier loss: 0.207744; batch adversarial loss: 0.365907\n",
      "epoch 51; iter: 0; batch classifier loss: 0.172355; batch adversarial loss: 0.460495\n",
      "epoch 52; iter: 0; batch classifier loss: 0.224229; batch adversarial loss: 0.460504\n",
      "epoch 53; iter: 0; batch classifier loss: 0.189702; batch adversarial loss: 0.412202\n",
      "epoch 54; iter: 0; batch classifier loss: 0.204766; batch adversarial loss: 0.413001\n",
      "epoch 55; iter: 0; batch classifier loss: 0.209793; batch adversarial loss: 0.399492\n",
      "epoch 56; iter: 0; batch classifier loss: 0.211761; batch adversarial loss: 0.458244\n",
      "epoch 57; iter: 0; batch classifier loss: 0.200615; batch adversarial loss: 0.435177\n",
      "epoch 58; iter: 0; batch classifier loss: 0.221307; batch adversarial loss: 0.435797\n",
      "epoch 59; iter: 0; batch classifier loss: 0.263315; batch adversarial loss: 0.447433\n",
      "epoch 60; iter: 0; batch classifier loss: 0.192882; batch adversarial loss: 0.580112\n",
      "epoch 61; iter: 0; batch classifier loss: 0.233975; batch adversarial loss: 0.507074\n",
      "epoch 62; iter: 0; batch classifier loss: 0.098061; batch adversarial loss: 0.519755\n",
      "epoch 63; iter: 0; batch classifier loss: 0.087709; batch adversarial loss: 0.453582\n",
      "epoch 64; iter: 0; batch classifier loss: 0.057743; batch adversarial loss: 0.458341\n",
      "epoch 65; iter: 0; batch classifier loss: 0.069776; batch adversarial loss: 0.440344\n",
      "epoch 66; iter: 0; batch classifier loss: 0.079646; batch adversarial loss: 0.473703\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073925; batch adversarial loss: 0.421683\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071206; batch adversarial loss: 0.415861\n",
      "epoch 69; iter: 0; batch classifier loss: 0.044404; batch adversarial loss: 0.444281\n",
      "epoch 70; iter: 0; batch classifier loss: 0.097997; batch adversarial loss: 0.533123\n",
      "epoch 71; iter: 0; batch classifier loss: 0.051887; batch adversarial loss: 0.462759\n",
      "epoch 72; iter: 0; batch classifier loss: 0.091750; batch adversarial loss: 0.452761\n",
      "epoch 73; iter: 0; batch classifier loss: 0.078375; batch adversarial loss: 0.323141\n",
      "epoch 74; iter: 0; batch classifier loss: 0.084329; batch adversarial loss: 0.372581\n",
      "epoch 75; iter: 0; batch classifier loss: 0.085608; batch adversarial loss: 0.466422\n",
      "epoch 76; iter: 0; batch classifier loss: 0.089185; batch adversarial loss: 0.499820\n",
      "epoch 77; iter: 0; batch classifier loss: 0.079644; batch adversarial loss: 0.482906\n",
      "epoch 78; iter: 0; batch classifier loss: 0.111996; batch adversarial loss: 0.411062\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063230; batch adversarial loss: 0.420285\n",
      "epoch 80; iter: 0; batch classifier loss: 0.065191; batch adversarial loss: 0.454242\n",
      "epoch 81; iter: 0; batch classifier loss: 0.077101; batch adversarial loss: 0.412654\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073103; batch adversarial loss: 0.506469\n",
      "epoch 83; iter: 0; batch classifier loss: 0.092319; batch adversarial loss: 0.508537\n",
      "epoch 84; iter: 0; batch classifier loss: 0.099884; batch adversarial loss: 0.371166\n",
      "epoch 85; iter: 0; batch classifier loss: 0.115937; batch adversarial loss: 0.485136\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063436; batch adversarial loss: 0.493264\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049975; batch adversarial loss: 0.490252\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064908; batch adversarial loss: 0.525051\n",
      "epoch 89; iter: 0; batch classifier loss: 0.111686; batch adversarial loss: 0.350396\n",
      "epoch 90; iter: 0; batch classifier loss: 0.090487; batch adversarial loss: 0.499489\n",
      "epoch 91; iter: 0; batch classifier loss: 0.065804; batch adversarial loss: 0.441911\n",
      "epoch 92; iter: 0; batch classifier loss: 0.033736; batch adversarial loss: 0.382159\n",
      "epoch 93; iter: 0; batch classifier loss: 0.082925; batch adversarial loss: 0.521465\n",
      "epoch 94; iter: 0; batch classifier loss: 0.065818; batch adversarial loss: 0.478997\n",
      "epoch 95; iter: 0; batch classifier loss: 0.067194; batch adversarial loss: 0.419297\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070100; batch adversarial loss: 0.361233\n",
      "epoch 97; iter: 0; batch classifier loss: 0.061514; batch adversarial loss: 0.498738\n",
      "epoch 98; iter: 0; batch classifier loss: 0.090522; batch adversarial loss: 0.436306\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037849; batch adversarial loss: 0.464044\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034299; batch adversarial loss: 0.368447\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054537; batch adversarial loss: 0.509397\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057891; batch adversarial loss: 0.432946\n",
      "epoch 103; iter: 0; batch classifier loss: 0.078233; batch adversarial loss: 0.390092\n",
      "epoch 104; iter: 0; batch classifier loss: 0.078719; batch adversarial loss: 0.562035\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064130; batch adversarial loss: 0.418202\n",
      "epoch 106; iter: 0; batch classifier loss: 0.065521; batch adversarial loss: 0.417090\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069943; batch adversarial loss: 0.538210\n",
      "epoch 108; iter: 0; batch classifier loss: 0.050093; batch adversarial loss: 0.500698\n",
      "epoch 109; iter: 0; batch classifier loss: 0.063294; batch adversarial loss: 0.398493\n",
      "epoch 110; iter: 0; batch classifier loss: 0.070512; batch adversarial loss: 0.453851\n",
      "epoch 111; iter: 0; batch classifier loss: 0.096088; batch adversarial loss: 0.521613\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034835; batch adversarial loss: 0.333700\n",
      "epoch 113; iter: 0; batch classifier loss: 0.086274; batch adversarial loss: 0.375876\n",
      "epoch 114; iter: 0; batch classifier loss: 0.111744; batch adversarial loss: 0.434368\n",
      "epoch 115; iter: 0; batch classifier loss: 0.083461; batch adversarial loss: 0.536391\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044514; batch adversarial loss: 0.391781\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050314; batch adversarial loss: 0.474957\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043161; batch adversarial loss: 0.446607\n",
      "epoch 119; iter: 0; batch classifier loss: 0.052946; batch adversarial loss: 0.336613\n",
      "epoch 120; iter: 0; batch classifier loss: 0.096130; batch adversarial loss: 0.455248\n",
      "epoch 121; iter: 0; batch classifier loss: 0.079773; batch adversarial loss: 0.364448\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036484; batch adversarial loss: 0.354920\n",
      "epoch 123; iter: 0; batch classifier loss: 0.086008; batch adversarial loss: 0.433464\n",
      "epoch 124; iter: 0; batch classifier loss: 0.116467; batch adversarial loss: 0.483388\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054959; batch adversarial loss: 0.446682\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055259; batch adversarial loss: 0.360967\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042639; batch adversarial loss: 0.493110\n",
      "epoch 128; iter: 0; batch classifier loss: 0.098688; batch adversarial loss: 0.502242\n",
      "epoch 129; iter: 0; batch classifier loss: 0.085204; batch adversarial loss: 0.420836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.076041; batch adversarial loss: 0.573464\n",
      "epoch 131; iter: 0; batch classifier loss: 0.090472; batch adversarial loss: 0.397045\n",
      "epoch 132; iter: 0; batch classifier loss: 0.075307; batch adversarial loss: 0.351650\n",
      "epoch 133; iter: 0; batch classifier loss: 0.051991; batch adversarial loss: 0.486573\n",
      "epoch 134; iter: 0; batch classifier loss: 0.079517; batch adversarial loss: 0.400378\n",
      "epoch 135; iter: 0; batch classifier loss: 0.081454; batch adversarial loss: 0.404635\n",
      "epoch 136; iter: 0; batch classifier loss: 0.060961; batch adversarial loss: 0.356036\n",
      "epoch 137; iter: 0; batch classifier loss: 0.062393; batch adversarial loss: 0.437036\n",
      "epoch 138; iter: 0; batch classifier loss: 0.061500; batch adversarial loss: 0.384332\n",
      "epoch 139; iter: 0; batch classifier loss: 0.051056; batch adversarial loss: 0.387458\n",
      "epoch 140; iter: 0; batch classifier loss: 0.056931; batch adversarial loss: 0.467635\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035484; batch adversarial loss: 0.345693\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045689; batch adversarial loss: 0.417594\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037399; batch adversarial loss: 0.450262\n",
      "epoch 144; iter: 0; batch classifier loss: 0.064306; batch adversarial loss: 0.423077\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040922; batch adversarial loss: 0.427502\n",
      "epoch 146; iter: 0; batch classifier loss: 0.062355; batch adversarial loss: 0.425671\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040122; batch adversarial loss: 0.460198\n",
      "epoch 148; iter: 0; batch classifier loss: 0.061879; batch adversarial loss: 0.386719\n",
      "epoch 149; iter: 0; batch classifier loss: 0.070792; batch adversarial loss: 0.376812\n",
      "epoch 150; iter: 0; batch classifier loss: 0.063257; batch adversarial loss: 0.438948\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028356; batch adversarial loss: 0.490845\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033321; batch adversarial loss: 0.531743\n",
      "epoch 153; iter: 0; batch classifier loss: 0.051512; batch adversarial loss: 0.459378\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036857; batch adversarial loss: 0.368166\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041202; batch adversarial loss: 0.350013\n",
      "epoch 156; iter: 0; batch classifier loss: 0.048663; batch adversarial loss: 0.488129\n",
      "epoch 157; iter: 0; batch classifier loss: 0.050844; batch adversarial loss: 0.455928\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048925; batch adversarial loss: 0.449425\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034633; batch adversarial loss: 0.390803\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024589; batch adversarial loss: 0.464439\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039908; batch adversarial loss: 0.358958\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016641; batch adversarial loss: 0.447735\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029406; batch adversarial loss: 0.435430\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027740; batch adversarial loss: 0.426248\n",
      "epoch 165; iter: 0; batch classifier loss: 0.062177; batch adversarial loss: 0.401228\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045753; batch adversarial loss: 0.466330\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029884; batch adversarial loss: 0.441323\n",
      "epoch 168; iter: 0; batch classifier loss: 0.047030; batch adversarial loss: 0.445601\n",
      "epoch 169; iter: 0; batch classifier loss: 0.059477; batch adversarial loss: 0.380390\n",
      "epoch 170; iter: 0; batch classifier loss: 0.042114; batch adversarial loss: 0.478507\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026089; batch adversarial loss: 0.424086\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017657; batch adversarial loss: 0.524619\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016560; batch adversarial loss: 0.465394\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021065; batch adversarial loss: 0.483259\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040766; batch adversarial loss: 0.337271\n",
      "epoch 176; iter: 0; batch classifier loss: 0.042310; batch adversarial loss: 0.610863\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046686; batch adversarial loss: 0.426641\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014393; batch adversarial loss: 0.512752\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044674; batch adversarial loss: 0.356889\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017597; batch adversarial loss: 0.431625\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020065; batch adversarial loss: 0.496489\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024765; batch adversarial loss: 0.452768\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042047; batch adversarial loss: 0.422924\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029661; batch adversarial loss: 0.408352\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012423; batch adversarial loss: 0.374070\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040046; batch adversarial loss: 0.429638\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033348; batch adversarial loss: 0.358037\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012312; batch adversarial loss: 0.380597\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022258; batch adversarial loss: 0.461695\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034955; batch adversarial loss: 0.396361\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019264; batch adversarial loss: 0.529809\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032362; batch adversarial loss: 0.398903\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026497; batch adversarial loss: 0.432870\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023391; batch adversarial loss: 0.389867\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022095; batch adversarial loss: 0.532496\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033183; batch adversarial loss: 0.551137\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017003; batch adversarial loss: 0.466638\n",
      "epoch 198; iter: 0; batch classifier loss: 0.034421; batch adversarial loss: 0.377365\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010871; batch adversarial loss: 0.532862\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714227; batch adversarial loss: 1.017333\n",
      "epoch 1; iter: 0; batch classifier loss: 0.676353; batch adversarial loss: 1.179259\n",
      "epoch 2; iter: 0; batch classifier loss: 0.934703; batch adversarial loss: 1.239522\n",
      "epoch 3; iter: 0; batch classifier loss: 1.044400; batch adversarial loss: 1.147679\n",
      "epoch 4; iter: 0; batch classifier loss: 1.105230; batch adversarial loss: 1.035591\n",
      "epoch 5; iter: 0; batch classifier loss: 1.131145; batch adversarial loss: 0.949200\n",
      "epoch 6; iter: 0; batch classifier loss: 1.303456; batch adversarial loss: 0.882284\n",
      "epoch 7; iter: 0; batch classifier loss: 1.092947; batch adversarial loss: 0.784281\n",
      "epoch 8; iter: 0; batch classifier loss: 1.121237; batch adversarial loss: 0.720798\n",
      "epoch 9; iter: 0; batch classifier loss: 1.134440; batch adversarial loss: 0.673444\n",
      "epoch 10; iter: 0; batch classifier loss: 1.040901; batch adversarial loss: 0.634256\n",
      "epoch 11; iter: 0; batch classifier loss: 0.796720; batch adversarial loss: 0.562927\n",
      "epoch 12; iter: 0; batch classifier loss: 0.586307; batch adversarial loss: 0.543492\n",
      "epoch 13; iter: 0; batch classifier loss: 0.423839; batch adversarial loss: 0.523949\n",
      "epoch 14; iter: 0; batch classifier loss: 0.313415; batch adversarial loss: 0.503475\n",
      "epoch 15; iter: 0; batch classifier loss: 0.319294; batch adversarial loss: 0.516975\n",
      "epoch 16; iter: 0; batch classifier loss: 0.303779; batch adversarial loss: 0.511671\n",
      "epoch 17; iter: 0; batch classifier loss: 0.250072; batch adversarial loss: 0.475710\n",
      "epoch 18; iter: 0; batch classifier loss: 0.239795; batch adversarial loss: 0.487656\n",
      "epoch 19; iter: 0; batch classifier loss: 0.280137; batch adversarial loss: 0.469687\n",
      "epoch 20; iter: 0; batch classifier loss: 0.287112; batch adversarial loss: 0.475559\n",
      "epoch 21; iter: 0; batch classifier loss: 0.265390; batch adversarial loss: 0.460482\n",
      "epoch 22; iter: 0; batch classifier loss: 0.187664; batch adversarial loss: 0.452556\n",
      "epoch 23; iter: 0; batch classifier loss: 0.247652; batch adversarial loss: 0.491758\n",
      "epoch 24; iter: 0; batch classifier loss: 0.217125; batch adversarial loss: 0.455590\n",
      "epoch 25; iter: 0; batch classifier loss: 0.154971; batch adversarial loss: 0.501852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.198652; batch adversarial loss: 0.429841\n",
      "epoch 27; iter: 0; batch classifier loss: 0.193206; batch adversarial loss: 0.481807\n",
      "epoch 28; iter: 0; batch classifier loss: 0.256430; batch adversarial loss: 0.440033\n",
      "epoch 29; iter: 0; batch classifier loss: 0.265421; batch adversarial loss: 0.497652\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151344; batch adversarial loss: 0.484257\n",
      "epoch 31; iter: 0; batch classifier loss: 0.172720; batch adversarial loss: 0.516760\n",
      "epoch 32; iter: 0; batch classifier loss: 0.247582; batch adversarial loss: 0.514418\n",
      "epoch 33; iter: 0; batch classifier loss: 0.150410; batch adversarial loss: 0.489607\n",
      "epoch 34; iter: 0; batch classifier loss: 0.198337; batch adversarial loss: 0.431558\n",
      "epoch 35; iter: 0; batch classifier loss: 0.208965; batch adversarial loss: 0.587047\n",
      "epoch 36; iter: 0; batch classifier loss: 0.193635; batch adversarial loss: 0.471640\n",
      "epoch 37; iter: 0; batch classifier loss: 0.241857; batch adversarial loss: 0.499704\n",
      "epoch 38; iter: 0; batch classifier loss: 0.197068; batch adversarial loss: 0.449420\n",
      "epoch 39; iter: 0; batch classifier loss: 0.185552; batch adversarial loss: 0.429680\n",
      "epoch 40; iter: 0; batch classifier loss: 0.202011; batch adversarial loss: 0.440615\n",
      "epoch 41; iter: 0; batch classifier loss: 0.202125; batch adversarial loss: 0.431290\n",
      "epoch 42; iter: 0; batch classifier loss: 0.222302; batch adversarial loss: 0.542969\n",
      "epoch 43; iter: 0; batch classifier loss: 0.221734; batch adversarial loss: 0.460976\n",
      "epoch 44; iter: 0; batch classifier loss: 0.161726; batch adversarial loss: 0.455609\n",
      "epoch 45; iter: 0; batch classifier loss: 0.128713; batch adversarial loss: 0.478932\n",
      "epoch 46; iter: 0; batch classifier loss: 0.149614; batch adversarial loss: 0.454498\n",
      "epoch 47; iter: 0; batch classifier loss: 0.221568; batch adversarial loss: 0.400998\n",
      "epoch 48; iter: 0; batch classifier loss: 0.170072; batch adversarial loss: 0.462685\n",
      "epoch 49; iter: 0; batch classifier loss: 0.189168; batch adversarial loss: 0.395463\n",
      "epoch 50; iter: 0; batch classifier loss: 0.150142; batch adversarial loss: 0.639510\n",
      "epoch 51; iter: 0; batch classifier loss: 0.192229; batch adversarial loss: 0.500283\n",
      "epoch 52; iter: 0; batch classifier loss: 0.157256; batch adversarial loss: 0.556154\n",
      "epoch 53; iter: 0; batch classifier loss: 0.152491; batch adversarial loss: 0.465423\n",
      "epoch 54; iter: 0; batch classifier loss: 0.195340; batch adversarial loss: 0.452884\n",
      "epoch 55; iter: 0; batch classifier loss: 0.224720; batch adversarial loss: 0.438993\n",
      "epoch 56; iter: 0; batch classifier loss: 0.253949; batch adversarial loss: 0.507516\n",
      "epoch 57; iter: 0; batch classifier loss: 0.203657; batch adversarial loss: 0.461151\n",
      "epoch 58; iter: 0; batch classifier loss: 0.163420; batch adversarial loss: 0.391335\n",
      "epoch 59; iter: 0; batch classifier loss: 0.268805; batch adversarial loss: 0.420195\n",
      "epoch 60; iter: 0; batch classifier loss: 0.246729; batch adversarial loss: 0.530377\n",
      "epoch 61; iter: 0; batch classifier loss: 0.159852; batch adversarial loss: 0.462747\n",
      "epoch 62; iter: 0; batch classifier loss: 0.208743; batch adversarial loss: 0.394028\n",
      "epoch 63; iter: 0; batch classifier loss: 0.183103; batch adversarial loss: 0.401380\n",
      "epoch 64; iter: 0; batch classifier loss: 0.231910; batch adversarial loss: 0.463307\n",
      "epoch 65; iter: 0; batch classifier loss: 0.205417; batch adversarial loss: 0.514484\n",
      "epoch 66; iter: 0; batch classifier loss: 0.184737; batch adversarial loss: 0.494448\n",
      "epoch 67; iter: 0; batch classifier loss: 0.245844; batch adversarial loss: 0.494011\n",
      "epoch 68; iter: 0; batch classifier loss: 0.190430; batch adversarial loss: 0.445054\n",
      "epoch 69; iter: 0; batch classifier loss: 0.171344; batch adversarial loss: 0.454838\n",
      "epoch 70; iter: 0; batch classifier loss: 0.204694; batch adversarial loss: 0.471405\n",
      "epoch 71; iter: 0; batch classifier loss: 0.166687; batch adversarial loss: 0.506411\n",
      "epoch 72; iter: 0; batch classifier loss: 0.182808; batch adversarial loss: 0.456373\n",
      "epoch 73; iter: 0; batch classifier loss: 0.185161; batch adversarial loss: 0.467755\n",
      "epoch 74; iter: 0; batch classifier loss: 0.209734; batch adversarial loss: 0.387591\n",
      "epoch 75; iter: 0; batch classifier loss: 0.206979; batch adversarial loss: 0.525113\n",
      "epoch 76; iter: 0; batch classifier loss: 0.156718; batch adversarial loss: 0.484957\n",
      "epoch 77; iter: 0; batch classifier loss: 0.165854; batch adversarial loss: 0.435468\n",
      "epoch 78; iter: 0; batch classifier loss: 0.236804; batch adversarial loss: 0.480840\n",
      "epoch 79; iter: 0; batch classifier loss: 0.222696; batch adversarial loss: 0.409783\n",
      "epoch 80; iter: 0; batch classifier loss: 0.174240; batch adversarial loss: 0.424659\n",
      "epoch 81; iter: 0; batch classifier loss: 0.285687; batch adversarial loss: 0.422585\n",
      "epoch 82; iter: 0; batch classifier loss: 0.148307; batch adversarial loss: 0.497907\n",
      "epoch 83; iter: 0; batch classifier loss: 0.265687; batch adversarial loss: 0.475829\n",
      "epoch 84; iter: 0; batch classifier loss: 0.188543; batch adversarial loss: 0.456322\n",
      "epoch 85; iter: 0; batch classifier loss: 0.243856; batch adversarial loss: 0.505662\n",
      "epoch 86; iter: 0; batch classifier loss: 0.161071; batch adversarial loss: 0.494102\n",
      "epoch 87; iter: 0; batch classifier loss: 0.201995; batch adversarial loss: 0.605740\n",
      "epoch 88; iter: 0; batch classifier loss: 0.202686; batch adversarial loss: 0.421727\n",
      "epoch 89; iter: 0; batch classifier loss: 0.261387; batch adversarial loss: 0.370956\n",
      "epoch 90; iter: 0; batch classifier loss: 0.188495; batch adversarial loss: 0.507513\n",
      "epoch 91; iter: 0; batch classifier loss: 0.257124; batch adversarial loss: 0.471669\n",
      "epoch 92; iter: 0; batch classifier loss: 0.165394; batch adversarial loss: 0.483243\n",
      "epoch 93; iter: 0; batch classifier loss: 0.208861; batch adversarial loss: 0.532734\n",
      "epoch 94; iter: 0; batch classifier loss: 0.175422; batch adversarial loss: 0.496509\n",
      "epoch 95; iter: 0; batch classifier loss: 0.195253; batch adversarial loss: 0.496035\n",
      "epoch 96; iter: 0; batch classifier loss: 0.248467; batch adversarial loss: 0.434347\n",
      "epoch 97; iter: 0; batch classifier loss: 0.214231; batch adversarial loss: 0.458261\n",
      "epoch 98; iter: 0; batch classifier loss: 0.264075; batch adversarial loss: 0.384962\n",
      "epoch 99; iter: 0; batch classifier loss: 0.154310; batch adversarial loss: 0.445671\n",
      "epoch 100; iter: 0; batch classifier loss: 0.208659; batch adversarial loss: 0.436220\n",
      "epoch 101; iter: 0; batch classifier loss: 0.224322; batch adversarial loss: 0.508097\n",
      "epoch 102; iter: 0; batch classifier loss: 0.205736; batch adversarial loss: 0.421874\n",
      "epoch 103; iter: 0; batch classifier loss: 0.245265; batch adversarial loss: 0.483126\n",
      "epoch 104; iter: 0; batch classifier loss: 0.191787; batch adversarial loss: 0.458923\n",
      "epoch 105; iter: 0; batch classifier loss: 0.249535; batch adversarial loss: 0.471019\n",
      "epoch 106; iter: 0; batch classifier loss: 0.165830; batch adversarial loss: 0.545600\n",
      "epoch 107; iter: 0; batch classifier loss: 0.237687; batch adversarial loss: 0.446531\n",
      "epoch 108; iter: 0; batch classifier loss: 0.161565; batch adversarial loss: 0.557458\n",
      "epoch 109; iter: 0; batch classifier loss: 0.076264; batch adversarial loss: 0.508735\n",
      "epoch 110; iter: 0; batch classifier loss: 0.062763; batch adversarial loss: 0.442822\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059588; batch adversarial loss: 0.476848\n",
      "epoch 112; iter: 0; batch classifier loss: 0.130813; batch adversarial loss: 0.454138\n",
      "epoch 113; iter: 0; batch classifier loss: 0.137378; batch adversarial loss: 0.428417\n",
      "epoch 114; iter: 0; batch classifier loss: 0.158942; batch adversarial loss: 0.436785\n",
      "epoch 115; iter: 0; batch classifier loss: 0.191024; batch adversarial loss: 0.546683\n",
      "epoch 116; iter: 0; batch classifier loss: 0.248923; batch adversarial loss: 0.387706\n",
      "epoch 117; iter: 0; batch classifier loss: 0.200418; batch adversarial loss: 0.460465\n",
      "epoch 118; iter: 0; batch classifier loss: 0.207504; batch adversarial loss: 0.410541\n",
      "epoch 119; iter: 0; batch classifier loss: 0.206645; batch adversarial loss: 0.495362\n",
      "epoch 120; iter: 0; batch classifier loss: 0.217493; batch adversarial loss: 0.446735\n",
      "epoch 121; iter: 0; batch classifier loss: 0.212329; batch adversarial loss: 0.520025\n",
      "epoch 122; iter: 0; batch classifier loss: 0.183179; batch adversarial loss: 0.520164\n",
      "epoch 123; iter: 0; batch classifier loss: 0.194647; batch adversarial loss: 0.446266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.202171; batch adversarial loss: 0.447214\n",
      "epoch 125; iter: 0; batch classifier loss: 0.178327; batch adversarial loss: 0.447130\n",
      "epoch 126; iter: 0; batch classifier loss: 0.157936; batch adversarial loss: 0.544984\n",
      "epoch 127; iter: 0; batch classifier loss: 0.177121; batch adversarial loss: 0.370142\n",
      "epoch 128; iter: 0; batch classifier loss: 0.195350; batch adversarial loss: 0.508973\n",
      "epoch 129; iter: 0; batch classifier loss: 0.154450; batch adversarial loss: 0.459027\n",
      "epoch 130; iter: 0; batch classifier loss: 0.196576; batch adversarial loss: 0.497158\n",
      "epoch 131; iter: 0; batch classifier loss: 0.274250; batch adversarial loss: 0.436136\n",
      "epoch 132; iter: 0; batch classifier loss: 0.251295; batch adversarial loss: 0.508310\n",
      "epoch 133; iter: 0; batch classifier loss: 0.201015; batch adversarial loss: 0.384419\n",
      "epoch 134; iter: 0; batch classifier loss: 0.188516; batch adversarial loss: 0.360843\n",
      "epoch 135; iter: 0; batch classifier loss: 0.221668; batch adversarial loss: 0.558483\n",
      "epoch 136; iter: 0; batch classifier loss: 0.159361; batch adversarial loss: 0.434273\n",
      "epoch 137; iter: 0; batch classifier loss: 0.228627; batch adversarial loss: 0.421997\n",
      "epoch 138; iter: 0; batch classifier loss: 0.092781; batch adversarial loss: 0.470770\n",
      "epoch 139; iter: 0; batch classifier loss: 0.182941; batch adversarial loss: 0.382728\n",
      "epoch 140; iter: 0; batch classifier loss: 0.245972; batch adversarial loss: 0.359934\n",
      "epoch 141; iter: 0; batch classifier loss: 0.189348; batch adversarial loss: 0.521366\n",
      "epoch 142; iter: 0; batch classifier loss: 0.132105; batch adversarial loss: 0.482704\n",
      "epoch 143; iter: 0; batch classifier loss: 0.195381; batch adversarial loss: 0.484659\n",
      "epoch 144; iter: 0; batch classifier loss: 0.184271; batch adversarial loss: 0.545146\n",
      "epoch 145; iter: 0; batch classifier loss: 0.221743; batch adversarial loss: 0.470584\n",
      "epoch 146; iter: 0; batch classifier loss: 0.212269; batch adversarial loss: 0.446645\n",
      "epoch 147; iter: 0; batch classifier loss: 0.206761; batch adversarial loss: 0.471219\n",
      "epoch 148; iter: 0; batch classifier loss: 0.145106; batch adversarial loss: 0.433808\n",
      "epoch 149; iter: 0; batch classifier loss: 0.103781; batch adversarial loss: 0.581892\n",
      "epoch 150; iter: 0; batch classifier loss: 0.147939; batch adversarial loss: 0.345888\n",
      "epoch 151; iter: 0; batch classifier loss: 0.144563; batch adversarial loss: 0.445731\n",
      "epoch 152; iter: 0; batch classifier loss: 0.190975; batch adversarial loss: 0.322726\n",
      "epoch 153; iter: 0; batch classifier loss: 0.222743; batch adversarial loss: 0.394441\n",
      "epoch 154; iter: 0; batch classifier loss: 0.194990; batch adversarial loss: 0.396299\n",
      "epoch 155; iter: 0; batch classifier loss: 0.169281; batch adversarial loss: 0.522397\n",
      "epoch 156; iter: 0; batch classifier loss: 0.208579; batch adversarial loss: 0.360447\n",
      "epoch 157; iter: 0; batch classifier loss: 0.173063; batch adversarial loss: 0.483687\n",
      "epoch 158; iter: 0; batch classifier loss: 0.227419; batch adversarial loss: 0.483783\n",
      "epoch 159; iter: 0; batch classifier loss: 0.214287; batch adversarial loss: 0.496163\n",
      "epoch 160; iter: 0; batch classifier loss: 0.102402; batch adversarial loss: 0.495533\n",
      "epoch 161; iter: 0; batch classifier loss: 0.128575; batch adversarial loss: 0.371148\n",
      "epoch 162; iter: 0; batch classifier loss: 0.179425; batch adversarial loss: 0.545380\n",
      "epoch 163; iter: 0; batch classifier loss: 0.191918; batch adversarial loss: 0.572391\n",
      "epoch 164; iter: 0; batch classifier loss: 0.194388; batch adversarial loss: 0.484737\n",
      "epoch 165; iter: 0; batch classifier loss: 0.219014; batch adversarial loss: 0.483441\n",
      "epoch 166; iter: 0; batch classifier loss: 0.201231; batch adversarial loss: 0.484021\n",
      "epoch 167; iter: 0; batch classifier loss: 0.189515; batch adversarial loss: 0.458765\n",
      "epoch 168; iter: 0; batch classifier loss: 0.231797; batch adversarial loss: 0.546269\n",
      "epoch 169; iter: 0; batch classifier loss: 0.168258; batch adversarial loss: 0.533343\n",
      "epoch 170; iter: 0; batch classifier loss: 0.136716; batch adversarial loss: 0.594915\n",
      "epoch 171; iter: 0; batch classifier loss: 0.176463; batch adversarial loss: 0.495848\n",
      "epoch 172; iter: 0; batch classifier loss: 0.257147; batch adversarial loss: 0.434276\n",
      "epoch 173; iter: 0; batch classifier loss: 0.172411; batch adversarial loss: 0.471153\n",
      "epoch 174; iter: 0; batch classifier loss: 0.109144; batch adversarial loss: 0.445724\n",
      "epoch 175; iter: 0; batch classifier loss: 0.096841; batch adversarial loss: 0.470356\n",
      "epoch 176; iter: 0; batch classifier loss: 0.140783; batch adversarial loss: 0.530536\n",
      "epoch 177; iter: 0; batch classifier loss: 0.133974; batch adversarial loss: 0.468750\n",
      "epoch 178; iter: 0; batch classifier loss: 0.122422; batch adversarial loss: 0.396957\n",
      "epoch 179; iter: 0; batch classifier loss: 0.132524; batch adversarial loss: 0.470972\n",
      "epoch 180; iter: 0; batch classifier loss: 0.094996; batch adversarial loss: 0.485540\n",
      "epoch 181; iter: 0; batch classifier loss: 0.110773; batch adversarial loss: 0.438089\n",
      "epoch 182; iter: 0; batch classifier loss: 0.069083; batch adversarial loss: 0.458175\n",
      "epoch 183; iter: 0; batch classifier loss: 0.069460; batch adversarial loss: 0.415972\n",
      "epoch 184; iter: 0; batch classifier loss: 0.054719; batch adversarial loss: 0.630235\n",
      "epoch 185; iter: 0; batch classifier loss: 0.050073; batch adversarial loss: 0.391243\n",
      "epoch 186; iter: 0; batch classifier loss: 0.044833; batch adversarial loss: 0.417814\n",
      "epoch 187; iter: 0; batch classifier loss: 0.063525; batch adversarial loss: 0.472745\n",
      "epoch 188; iter: 0; batch classifier loss: 0.042823; batch adversarial loss: 0.501424\n",
      "epoch 189; iter: 0; batch classifier loss: 0.053884; batch adversarial loss: 0.508205\n",
      "epoch 190; iter: 0; batch classifier loss: 0.048018; batch adversarial loss: 0.511564\n",
      "epoch 191; iter: 0; batch classifier loss: 0.063415; batch adversarial loss: 0.407267\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021506; batch adversarial loss: 0.415545\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037588; batch adversarial loss: 0.497207\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019763; batch adversarial loss: 0.505901\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036795; batch adversarial loss: 0.399015\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029121; batch adversarial loss: 0.411366\n",
      "epoch 197; iter: 0; batch classifier loss: 0.042025; batch adversarial loss: 0.476256\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024625; batch adversarial loss: 0.426260\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032554; batch adversarial loss: 0.444831\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684377; batch adversarial loss: 0.859872\n",
      "epoch 1; iter: 0; batch classifier loss: 0.534665; batch adversarial loss: 0.805770\n",
      "epoch 2; iter: 0; batch classifier loss: 0.683065; batch adversarial loss: 0.785568\n",
      "epoch 3; iter: 0; batch classifier loss: 0.767778; batch adversarial loss: 0.745890\n",
      "epoch 4; iter: 0; batch classifier loss: 0.735581; batch adversarial loss: 0.659446\n",
      "epoch 5; iter: 0; batch classifier loss: 0.543624; batch adversarial loss: 0.603085\n",
      "epoch 6; iter: 0; batch classifier loss: 0.430414; batch adversarial loss: 0.576057\n",
      "epoch 7; iter: 0; batch classifier loss: 0.383390; batch adversarial loss: 0.546172\n",
      "epoch 8; iter: 0; batch classifier loss: 0.313895; batch adversarial loss: 0.551681\n",
      "epoch 9; iter: 0; batch classifier loss: 0.341435; batch adversarial loss: 0.510105\n",
      "epoch 10; iter: 0; batch classifier loss: 0.368684; batch adversarial loss: 0.531954\n",
      "epoch 11; iter: 0; batch classifier loss: 0.320804; batch adversarial loss: 0.532696\n",
      "epoch 12; iter: 0; batch classifier loss: 0.266358; batch adversarial loss: 0.481027\n",
      "epoch 13; iter: 0; batch classifier loss: 0.320783; batch adversarial loss: 0.436200\n",
      "epoch 14; iter: 0; batch classifier loss: 0.260713; batch adversarial loss: 0.508991\n",
      "epoch 15; iter: 0; batch classifier loss: 0.320552; batch adversarial loss: 0.494577\n",
      "epoch 16; iter: 0; batch classifier loss: 0.280276; batch adversarial loss: 0.485378\n",
      "epoch 17; iter: 0; batch classifier loss: 0.328351; batch adversarial loss: 0.501691\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243374; batch adversarial loss: 0.564906\n",
      "epoch 19; iter: 0; batch classifier loss: 0.277479; batch adversarial loss: 0.445965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.242240; batch adversarial loss: 0.502075\n",
      "epoch 21; iter: 0; batch classifier loss: 0.246135; batch adversarial loss: 0.448727\n",
      "epoch 22; iter: 0; batch classifier loss: 0.217124; batch adversarial loss: 0.427808\n",
      "epoch 23; iter: 0; batch classifier loss: 0.196584; batch adversarial loss: 0.475165\n",
      "epoch 24; iter: 0; batch classifier loss: 0.186499; batch adversarial loss: 0.501279\n",
      "epoch 25; iter: 0; batch classifier loss: 0.210347; batch adversarial loss: 0.591087\n",
      "epoch 26; iter: 0; batch classifier loss: 0.162833; batch adversarial loss: 0.478921\n",
      "epoch 27; iter: 0; batch classifier loss: 0.218179; batch adversarial loss: 0.505336\n",
      "epoch 28; iter: 0; batch classifier loss: 0.219929; batch adversarial loss: 0.453917\n",
      "epoch 29; iter: 0; batch classifier loss: 0.166076; batch adversarial loss: 0.439441\n",
      "epoch 30; iter: 0; batch classifier loss: 0.199838; batch adversarial loss: 0.426798\n",
      "epoch 31; iter: 0; batch classifier loss: 0.154515; batch adversarial loss: 0.448109\n",
      "epoch 32; iter: 0; batch classifier loss: 0.169392; batch adversarial loss: 0.464511\n",
      "epoch 33; iter: 0; batch classifier loss: 0.152623; batch adversarial loss: 0.476786\n",
      "epoch 34; iter: 0; batch classifier loss: 0.133717; batch adversarial loss: 0.375198\n",
      "epoch 35; iter: 0; batch classifier loss: 0.115362; batch adversarial loss: 0.461822\n",
      "epoch 36; iter: 0; batch classifier loss: 0.195657; batch adversarial loss: 0.428629\n",
      "epoch 37; iter: 0; batch classifier loss: 0.160457; batch adversarial loss: 0.442172\n",
      "epoch 38; iter: 0; batch classifier loss: 0.189677; batch adversarial loss: 0.406111\n",
      "epoch 39; iter: 0; batch classifier loss: 0.105662; batch adversarial loss: 0.450008\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116302; batch adversarial loss: 0.441193\n",
      "epoch 41; iter: 0; batch classifier loss: 0.111489; batch adversarial loss: 0.407731\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146696; batch adversarial loss: 0.405384\n",
      "epoch 43; iter: 0; batch classifier loss: 0.119957; batch adversarial loss: 0.497881\n",
      "epoch 44; iter: 0; batch classifier loss: 0.083553; batch adversarial loss: 0.474757\n",
      "epoch 45; iter: 0; batch classifier loss: 0.146448; batch adversarial loss: 0.473038\n",
      "epoch 46; iter: 0; batch classifier loss: 0.107190; batch adversarial loss: 0.466079\n",
      "epoch 47; iter: 0; batch classifier loss: 0.125453; batch adversarial loss: 0.387236\n",
      "epoch 48; iter: 0; batch classifier loss: 0.114107; batch adversarial loss: 0.503873\n",
      "epoch 49; iter: 0; batch classifier loss: 0.081350; batch adversarial loss: 0.446094\n",
      "epoch 50; iter: 0; batch classifier loss: 0.089759; batch adversarial loss: 0.486376\n",
      "epoch 51; iter: 0; batch classifier loss: 0.055301; batch adversarial loss: 0.496348\n",
      "epoch 52; iter: 0; batch classifier loss: 0.081582; batch adversarial loss: 0.585078\n",
      "epoch 53; iter: 0; batch classifier loss: 0.064747; batch adversarial loss: 0.459797\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116745; batch adversarial loss: 0.476469\n",
      "epoch 55; iter: 0; batch classifier loss: 0.138920; batch adversarial loss: 0.488579\n",
      "epoch 56; iter: 0; batch classifier loss: 0.086430; batch adversarial loss: 0.431707\n",
      "epoch 57; iter: 0; batch classifier loss: 0.056237; batch adversarial loss: 0.435191\n",
      "epoch 58; iter: 0; batch classifier loss: 0.058409; batch adversarial loss: 0.454609\n",
      "epoch 59; iter: 0; batch classifier loss: 0.091947; batch adversarial loss: 0.447988\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079469; batch adversarial loss: 0.467250\n",
      "epoch 61; iter: 0; batch classifier loss: 0.059868; batch adversarial loss: 0.429203\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104081; batch adversarial loss: 0.555346\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085887; batch adversarial loss: 0.440021\n",
      "epoch 64; iter: 0; batch classifier loss: 0.042673; batch adversarial loss: 0.455635\n",
      "epoch 65; iter: 0; batch classifier loss: 0.067076; batch adversarial loss: 0.390121\n",
      "epoch 66; iter: 0; batch classifier loss: 0.067622; batch adversarial loss: 0.387818\n",
      "epoch 67; iter: 0; batch classifier loss: 0.038106; batch adversarial loss: 0.438939\n",
      "epoch 68; iter: 0; batch classifier loss: 0.139914; batch adversarial loss: 0.338212\n",
      "epoch 69; iter: 0; batch classifier loss: 0.040975; batch adversarial loss: 0.438030\n",
      "epoch 70; iter: 0; batch classifier loss: 0.040850; batch adversarial loss: 0.511720\n",
      "epoch 71; iter: 0; batch classifier loss: 0.095866; batch adversarial loss: 0.494828\n",
      "epoch 72; iter: 0; batch classifier loss: 0.045559; batch adversarial loss: 0.434162\n",
      "epoch 73; iter: 0; batch classifier loss: 0.063883; batch adversarial loss: 0.436430\n",
      "epoch 74; iter: 0; batch classifier loss: 0.078585; batch adversarial loss: 0.424040\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073767; batch adversarial loss: 0.399276\n",
      "epoch 76; iter: 0; batch classifier loss: 0.051024; batch adversarial loss: 0.356259\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050236; batch adversarial loss: 0.441497\n",
      "epoch 78; iter: 0; batch classifier loss: 0.065644; batch adversarial loss: 0.471647\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053998; batch adversarial loss: 0.396814\n",
      "epoch 80; iter: 0; batch classifier loss: 0.046294; batch adversarial loss: 0.464017\n",
      "epoch 81; iter: 0; batch classifier loss: 0.049376; batch adversarial loss: 0.503105\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052944; batch adversarial loss: 0.432485\n",
      "epoch 83; iter: 0; batch classifier loss: 0.036283; batch adversarial loss: 0.493363\n",
      "epoch 84; iter: 0; batch classifier loss: 0.037553; batch adversarial loss: 0.425280\n",
      "epoch 85; iter: 0; batch classifier loss: 0.025756; batch adversarial loss: 0.390682\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040382; batch adversarial loss: 0.426060\n",
      "epoch 87; iter: 0; batch classifier loss: 0.016643; batch adversarial loss: 0.444086\n",
      "epoch 88; iter: 0; batch classifier loss: 0.035411; batch adversarial loss: 0.489720\n",
      "epoch 89; iter: 0; batch classifier loss: 0.046644; batch adversarial loss: 0.533283\n",
      "epoch 90; iter: 0; batch classifier loss: 0.038567; batch adversarial loss: 0.422708\n",
      "epoch 91; iter: 0; batch classifier loss: 0.061057; batch adversarial loss: 0.436580\n",
      "epoch 92; iter: 0; batch classifier loss: 0.049666; batch adversarial loss: 0.522877\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044465; batch adversarial loss: 0.389999\n",
      "epoch 94; iter: 0; batch classifier loss: 0.068159; batch adversarial loss: 0.461075\n",
      "epoch 95; iter: 0; batch classifier loss: 0.059128; batch adversarial loss: 0.341933\n",
      "epoch 96; iter: 0; batch classifier loss: 0.010195; batch adversarial loss: 0.550826\n",
      "epoch 97; iter: 0; batch classifier loss: 0.034964; batch adversarial loss: 0.460895\n",
      "epoch 98; iter: 0; batch classifier loss: 0.022766; batch adversarial loss: 0.409584\n",
      "epoch 99; iter: 0; batch classifier loss: 0.022893; batch adversarial loss: 0.474145\n",
      "epoch 100; iter: 0; batch classifier loss: 0.024961; batch adversarial loss: 0.541271\n",
      "epoch 101; iter: 0; batch classifier loss: 0.028555; batch adversarial loss: 0.612215\n",
      "epoch 102; iter: 0; batch classifier loss: 0.035294; batch adversarial loss: 0.560575\n",
      "epoch 103; iter: 0; batch classifier loss: 0.034118; batch adversarial loss: 0.534401\n",
      "epoch 104; iter: 0; batch classifier loss: 0.020339; batch adversarial loss: 0.450019\n",
      "epoch 105; iter: 0; batch classifier loss: 0.021543; batch adversarial loss: 0.447720\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039725; batch adversarial loss: 0.461416\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038571; batch adversarial loss: 0.445743\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040538; batch adversarial loss: 0.508357\n",
      "epoch 109; iter: 0; batch classifier loss: 0.011050; batch adversarial loss: 0.451474\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036613; batch adversarial loss: 0.527129\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029252; batch adversarial loss: 0.399951\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044189; batch adversarial loss: 0.381447\n",
      "epoch 113; iter: 0; batch classifier loss: 0.010502; batch adversarial loss: 0.391174\n",
      "epoch 114; iter: 0; batch classifier loss: 0.009177; batch adversarial loss: 0.399322\n",
      "epoch 115; iter: 0; batch classifier loss: 0.009559; batch adversarial loss: 0.510500\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042724; batch adversarial loss: 0.356147\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060171; batch adversarial loss: 0.429324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.013000; batch adversarial loss: 0.446616\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036969; batch adversarial loss: 0.393965\n",
      "epoch 120; iter: 0; batch classifier loss: 0.017808; batch adversarial loss: 0.481668\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026866; batch adversarial loss: 0.411358\n",
      "epoch 122; iter: 0; batch classifier loss: 0.008499; batch adversarial loss: 0.443365\n",
      "epoch 123; iter: 0; batch classifier loss: 0.012915; batch adversarial loss: 0.469633\n",
      "epoch 124; iter: 0; batch classifier loss: 0.010154; batch adversarial loss: 0.424004\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017411; batch adversarial loss: 0.410671\n",
      "epoch 126; iter: 0; batch classifier loss: 0.014762; batch adversarial loss: 0.462441\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022354; batch adversarial loss: 0.417805\n",
      "epoch 128; iter: 0; batch classifier loss: 0.051518; batch adversarial loss: 0.342128\n",
      "epoch 129; iter: 0; batch classifier loss: 0.014258; batch adversarial loss: 0.499552\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035729; batch adversarial loss: 0.413602\n",
      "epoch 131; iter: 0; batch classifier loss: 0.068262; batch adversarial loss: 0.453435\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021843; batch adversarial loss: 0.462996\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045093; batch adversarial loss: 0.509462\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015677; batch adversarial loss: 0.449809\n",
      "epoch 135; iter: 0; batch classifier loss: 0.006359; batch adversarial loss: 0.564705\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019037; batch adversarial loss: 0.399432\n",
      "epoch 137; iter: 0; batch classifier loss: 0.010995; batch adversarial loss: 0.392480\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017920; batch adversarial loss: 0.455154\n",
      "epoch 139; iter: 0; batch classifier loss: 0.008669; batch adversarial loss: 0.469107\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030307; batch adversarial loss: 0.412574\n",
      "epoch 141; iter: 0; batch classifier loss: 0.008091; batch adversarial loss: 0.453644\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014143; batch adversarial loss: 0.425997\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039185; batch adversarial loss: 0.468494\n",
      "epoch 144; iter: 0; batch classifier loss: 0.008446; batch adversarial loss: 0.408166\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030158; batch adversarial loss: 0.423854\n",
      "epoch 146; iter: 0; batch classifier loss: 0.014544; batch adversarial loss: 0.408964\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015425; batch adversarial loss: 0.460593\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032298; batch adversarial loss: 0.437031\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024875; batch adversarial loss: 0.488641\n",
      "epoch 150; iter: 0; batch classifier loss: 0.010697; batch adversarial loss: 0.428722\n",
      "epoch 151; iter: 0; batch classifier loss: 0.010589; batch adversarial loss: 0.401373\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027570; batch adversarial loss: 0.436893\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023678; batch adversarial loss: 0.421233\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012221; batch adversarial loss: 0.424923\n",
      "epoch 155; iter: 0; batch classifier loss: 0.008475; batch adversarial loss: 0.419627\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013260; batch adversarial loss: 0.450307\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035796; batch adversarial loss: 0.427350\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022795; batch adversarial loss: 0.479098\n",
      "epoch 159; iter: 0; batch classifier loss: 0.006465; batch adversarial loss: 0.425586\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016298; batch adversarial loss: 0.342687\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010536; batch adversarial loss: 0.396857\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010455; batch adversarial loss: 0.483241\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036653; batch adversarial loss: 0.348399\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015102; batch adversarial loss: 0.474428\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033577; batch adversarial loss: 0.445903\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033749; batch adversarial loss: 0.469527\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011985; batch adversarial loss: 0.396470\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015363; batch adversarial loss: 0.447755\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024082; batch adversarial loss: 0.459325\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008515; batch adversarial loss: 0.429445\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028604; batch adversarial loss: 0.468685\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005296; batch adversarial loss: 0.432885\n",
      "epoch 173; iter: 0; batch classifier loss: 0.003245; batch adversarial loss: 0.353261\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013767; batch adversarial loss: 0.503345\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019412; batch adversarial loss: 0.490769\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008472; batch adversarial loss: 0.397504\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038545; batch adversarial loss: 0.455069\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020957; batch adversarial loss: 0.421688\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007081; batch adversarial loss: 0.416137\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007370; batch adversarial loss: 0.495165\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019983; batch adversarial loss: 0.426246\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012024; batch adversarial loss: 0.468195\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016056; batch adversarial loss: 0.410717\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003690; batch adversarial loss: 0.473720\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007632; batch adversarial loss: 0.447102\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024969; batch adversarial loss: 0.426352\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008490; batch adversarial loss: 0.397235\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014628; batch adversarial loss: 0.387933\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036467; batch adversarial loss: 0.524946\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015932; batch adversarial loss: 0.366231\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013812; batch adversarial loss: 0.483426\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021678; batch adversarial loss: 0.443251\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009115; batch adversarial loss: 0.373428\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007855; batch adversarial loss: 0.495674\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005091; batch adversarial loss: 0.425717\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009943; batch adversarial loss: 0.384566\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010205; batch adversarial loss: 0.382991\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037107; batch adversarial loss: 0.385678\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012668; batch adversarial loss: 0.437095\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696929; batch adversarial loss: 0.639467\n",
      "epoch 1; iter: 0; batch classifier loss: 0.468646; batch adversarial loss: 0.636216\n",
      "epoch 2; iter: 0; batch classifier loss: 0.392209; batch adversarial loss: 0.628003\n",
      "epoch 3; iter: 0; batch classifier loss: 0.400234; batch adversarial loss: 0.608343\n",
      "epoch 4; iter: 0; batch classifier loss: 0.358460; batch adversarial loss: 0.570936\n",
      "epoch 5; iter: 0; batch classifier loss: 0.378554; batch adversarial loss: 0.572946\n",
      "epoch 6; iter: 0; batch classifier loss: 0.412762; batch adversarial loss: 0.581205\n",
      "epoch 7; iter: 0; batch classifier loss: 0.319264; batch adversarial loss: 0.520912\n",
      "epoch 8; iter: 0; batch classifier loss: 0.362124; batch adversarial loss: 0.558821\n",
      "epoch 9; iter: 0; batch classifier loss: 0.339602; batch adversarial loss: 0.522200\n",
      "epoch 10; iter: 0; batch classifier loss: 0.228783; batch adversarial loss: 0.509675\n",
      "epoch 11; iter: 0; batch classifier loss: 0.308171; batch adversarial loss: 0.518967\n",
      "epoch 12; iter: 0; batch classifier loss: 0.353317; batch adversarial loss: 0.508570\n",
      "epoch 13; iter: 0; batch classifier loss: 0.302833; batch adversarial loss: 0.491946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.239432; batch adversarial loss: 0.491344\n",
      "epoch 15; iter: 0; batch classifier loss: 0.229996; batch adversarial loss: 0.538691\n",
      "epoch 16; iter: 0; batch classifier loss: 0.211403; batch adversarial loss: 0.523632\n",
      "epoch 17; iter: 0; batch classifier loss: 0.207408; batch adversarial loss: 0.459793\n",
      "epoch 18; iter: 0; batch classifier loss: 0.182228; batch adversarial loss: 0.423082\n",
      "epoch 19; iter: 0; batch classifier loss: 0.243136; batch adversarial loss: 0.466911\n",
      "epoch 20; iter: 0; batch classifier loss: 0.192373; batch adversarial loss: 0.465725\n",
      "epoch 21; iter: 0; batch classifier loss: 0.235773; batch adversarial loss: 0.503159\n",
      "epoch 22; iter: 0; batch classifier loss: 0.179476; batch adversarial loss: 0.505479\n",
      "epoch 23; iter: 0; batch classifier loss: 0.165178; batch adversarial loss: 0.527587\n",
      "epoch 24; iter: 0; batch classifier loss: 0.174603; batch adversarial loss: 0.418826\n",
      "epoch 25; iter: 0; batch classifier loss: 0.207633; batch adversarial loss: 0.469196\n",
      "epoch 26; iter: 0; batch classifier loss: 0.154993; batch adversarial loss: 0.484438\n",
      "epoch 27; iter: 0; batch classifier loss: 0.184543; batch adversarial loss: 0.487900\n",
      "epoch 28; iter: 0; batch classifier loss: 0.198209; batch adversarial loss: 0.499972\n",
      "epoch 29; iter: 0; batch classifier loss: 0.184180; batch adversarial loss: 0.526895\n",
      "epoch 30; iter: 0; batch classifier loss: 0.183841; batch adversarial loss: 0.440571\n",
      "epoch 31; iter: 0; batch classifier loss: 0.135446; batch adversarial loss: 0.530397\n",
      "epoch 32; iter: 0; batch classifier loss: 0.159524; batch adversarial loss: 0.428475\n",
      "epoch 33; iter: 0; batch classifier loss: 0.114729; batch adversarial loss: 0.506253\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142126; batch adversarial loss: 0.460086\n",
      "epoch 35; iter: 0; batch classifier loss: 0.169830; batch adversarial loss: 0.486388\n",
      "epoch 36; iter: 0; batch classifier loss: 0.112775; batch adversarial loss: 0.481636\n",
      "epoch 37; iter: 0; batch classifier loss: 0.135348; batch adversarial loss: 0.428907\n",
      "epoch 38; iter: 0; batch classifier loss: 0.174505; batch adversarial loss: 0.466424\n",
      "epoch 39; iter: 0; batch classifier loss: 0.157952; batch adversarial loss: 0.477693\n",
      "epoch 40; iter: 0; batch classifier loss: 0.150518; batch adversarial loss: 0.497941\n",
      "epoch 41; iter: 0; batch classifier loss: 0.164644; batch adversarial loss: 0.453728\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131526; batch adversarial loss: 0.410045\n",
      "epoch 43; iter: 0; batch classifier loss: 0.148204; batch adversarial loss: 0.527479\n",
      "epoch 44; iter: 0; batch classifier loss: 0.114098; batch adversarial loss: 0.444500\n",
      "epoch 45; iter: 0; batch classifier loss: 0.167005; batch adversarial loss: 0.494256\n",
      "epoch 46; iter: 0; batch classifier loss: 0.108799; batch adversarial loss: 0.402652\n",
      "epoch 47; iter: 0; batch classifier loss: 0.127059; batch adversarial loss: 0.436729\n",
      "epoch 48; iter: 0; batch classifier loss: 0.130474; batch adversarial loss: 0.513612\n",
      "epoch 49; iter: 0; batch classifier loss: 0.079786; batch adversarial loss: 0.477641\n",
      "epoch 50; iter: 0; batch classifier loss: 0.146486; batch adversarial loss: 0.427734\n",
      "epoch 51; iter: 0; batch classifier loss: 0.182867; batch adversarial loss: 0.458667\n",
      "epoch 52; iter: 0; batch classifier loss: 0.123191; batch adversarial loss: 0.465030\n",
      "epoch 53; iter: 0; batch classifier loss: 0.092039; batch adversarial loss: 0.434009\n",
      "epoch 54; iter: 0; batch classifier loss: 0.091626; batch adversarial loss: 0.452290\n",
      "epoch 55; iter: 0; batch classifier loss: 0.120060; batch adversarial loss: 0.469867\n",
      "epoch 56; iter: 0; batch classifier loss: 0.143339; batch adversarial loss: 0.469532\n",
      "epoch 57; iter: 0; batch classifier loss: 0.101766; batch adversarial loss: 0.430837\n",
      "epoch 58; iter: 0; batch classifier loss: 0.114052; batch adversarial loss: 0.408857\n",
      "epoch 59; iter: 0; batch classifier loss: 0.100672; batch adversarial loss: 0.392999\n",
      "epoch 60; iter: 0; batch classifier loss: 0.203193; batch adversarial loss: 0.464434\n",
      "epoch 61; iter: 0; batch classifier loss: 0.119259; batch adversarial loss: 0.422471\n",
      "epoch 62; iter: 0; batch classifier loss: 0.106415; batch adversarial loss: 0.462315\n",
      "epoch 63; iter: 0; batch classifier loss: 0.133917; batch adversarial loss: 0.461874\n",
      "epoch 64; iter: 0; batch classifier loss: 0.097680; batch adversarial loss: 0.543644\n",
      "epoch 65; iter: 0; batch classifier loss: 0.095739; batch adversarial loss: 0.542190\n",
      "epoch 66; iter: 0; batch classifier loss: 0.129046; batch adversarial loss: 0.475444\n",
      "epoch 67; iter: 0; batch classifier loss: 0.105426; batch adversarial loss: 0.546579\n",
      "epoch 68; iter: 0; batch classifier loss: 0.089719; batch adversarial loss: 0.538971\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072696; batch adversarial loss: 0.544469\n",
      "epoch 70; iter: 0; batch classifier loss: 0.121444; batch adversarial loss: 0.367521\n",
      "epoch 71; iter: 0; batch classifier loss: 0.090114; batch adversarial loss: 0.463843\n",
      "epoch 72; iter: 0; batch classifier loss: 0.120865; batch adversarial loss: 0.506425\n",
      "epoch 73; iter: 0; batch classifier loss: 0.125552; batch adversarial loss: 0.458875\n",
      "epoch 74; iter: 0; batch classifier loss: 0.103240; batch adversarial loss: 0.523070\n",
      "epoch 75; iter: 0; batch classifier loss: 0.138522; batch adversarial loss: 0.434509\n",
      "epoch 76; iter: 0; batch classifier loss: 0.125086; batch adversarial loss: 0.436963\n",
      "epoch 77; iter: 0; batch classifier loss: 0.090772; batch adversarial loss: 0.454649\n",
      "epoch 78; iter: 0; batch classifier loss: 0.095335; batch adversarial loss: 0.424136\n",
      "epoch 79; iter: 0; batch classifier loss: 0.120160; batch adversarial loss: 0.488763\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078600; batch adversarial loss: 0.504782\n",
      "epoch 81; iter: 0; batch classifier loss: 0.053333; batch adversarial loss: 0.521470\n",
      "epoch 82; iter: 0; batch classifier loss: 0.072266; batch adversarial loss: 0.504461\n",
      "epoch 83; iter: 0; batch classifier loss: 0.089183; batch adversarial loss: 0.544599\n",
      "epoch 84; iter: 0; batch classifier loss: 0.107709; batch adversarial loss: 0.410063\n",
      "epoch 85; iter: 0; batch classifier loss: 0.130770; batch adversarial loss: 0.562953\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081613; batch adversarial loss: 0.430230\n",
      "epoch 87; iter: 0; batch classifier loss: 0.103175; batch adversarial loss: 0.486168\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069979; batch adversarial loss: 0.482935\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098571; batch adversarial loss: 0.431271\n",
      "epoch 90; iter: 0; batch classifier loss: 0.079015; batch adversarial loss: 0.436638\n",
      "epoch 91; iter: 0; batch classifier loss: 0.047295; batch adversarial loss: 0.421580\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055360; batch adversarial loss: 0.534612\n",
      "epoch 93; iter: 0; batch classifier loss: 0.045253; batch adversarial loss: 0.507318\n",
      "epoch 94; iter: 0; batch classifier loss: 0.084580; batch adversarial loss: 0.559398\n",
      "epoch 95; iter: 0; batch classifier loss: 0.069166; batch adversarial loss: 0.517840\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059483; batch adversarial loss: 0.439334\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075214; batch adversarial loss: 0.458974\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061938; batch adversarial loss: 0.589325\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063920; batch adversarial loss: 0.426074\n",
      "epoch 100; iter: 0; batch classifier loss: 0.058797; batch adversarial loss: 0.358460\n",
      "epoch 101; iter: 0; batch classifier loss: 0.074502; batch adversarial loss: 0.426020\n",
      "epoch 102; iter: 0; batch classifier loss: 0.030400; batch adversarial loss: 0.432954\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038154; batch adversarial loss: 0.441315\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036784; batch adversarial loss: 0.456383\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048250; batch adversarial loss: 0.480800\n",
      "epoch 106; iter: 0; batch classifier loss: 0.070232; batch adversarial loss: 0.475438\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066877; batch adversarial loss: 0.588189\n",
      "epoch 108; iter: 0; batch classifier loss: 0.014774; batch adversarial loss: 0.449446\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044081; batch adversarial loss: 0.487112\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040020; batch adversarial loss: 0.467857\n",
      "epoch 111; iter: 0; batch classifier loss: 0.075442; batch adversarial loss: 0.478536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.048209; batch adversarial loss: 0.475019\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033632; batch adversarial loss: 0.456283\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037305; batch adversarial loss: 0.460719\n",
      "epoch 115; iter: 0; batch classifier loss: 0.058317; batch adversarial loss: 0.364530\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042298; batch adversarial loss: 0.461117\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032007; batch adversarial loss: 0.460549\n",
      "epoch 118; iter: 0; batch classifier loss: 0.013840; batch adversarial loss: 0.522714\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025737; batch adversarial loss: 0.482172\n",
      "epoch 120; iter: 0; batch classifier loss: 0.072585; batch adversarial loss: 0.464686\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018763; batch adversarial loss: 0.481667\n",
      "epoch 122; iter: 0; batch classifier loss: 0.023359; batch adversarial loss: 0.410128\n",
      "epoch 123; iter: 0; batch classifier loss: 0.016568; batch adversarial loss: 0.507654\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033554; batch adversarial loss: 0.441206\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052453; batch adversarial loss: 0.431715\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023329; batch adversarial loss: 0.531783\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021167; batch adversarial loss: 0.635273\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023968; batch adversarial loss: 0.425494\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059585; batch adversarial loss: 0.505471\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028041; batch adversarial loss: 0.472128\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047902; batch adversarial loss: 0.409281\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022120; batch adversarial loss: 0.470426\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022929; batch adversarial loss: 0.416508\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028951; batch adversarial loss: 0.404140\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028043; batch adversarial loss: 0.397747\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044439; batch adversarial loss: 0.498577\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031111; batch adversarial loss: 0.514223\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032462; batch adversarial loss: 0.532326\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018696; batch adversarial loss: 0.456254\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013344; batch adversarial loss: 0.565998\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044796; batch adversarial loss: 0.465523\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050877; batch adversarial loss: 0.495001\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041289; batch adversarial loss: 0.440217\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036561; batch adversarial loss: 0.542687\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024484; batch adversarial loss: 0.381152\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018388; batch adversarial loss: 0.467805\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027719; batch adversarial loss: 0.486542\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038666; batch adversarial loss: 0.403672\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014132; batch adversarial loss: 0.458590\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034318; batch adversarial loss: 0.465546\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008686; batch adversarial loss: 0.372232\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035892; batch adversarial loss: 0.488567\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024647; batch adversarial loss: 0.453677\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018324; batch adversarial loss: 0.482476\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009725; batch adversarial loss: 0.489527\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030372; batch adversarial loss: 0.431343\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019035; batch adversarial loss: 0.394682\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012340; batch adversarial loss: 0.442959\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013502; batch adversarial loss: 0.480338\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009882; batch adversarial loss: 0.359781\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042960; batch adversarial loss: 0.466747\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021719; batch adversarial loss: 0.317623\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027924; batch adversarial loss: 0.517500\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028961; batch adversarial loss: 0.434831\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013730; batch adversarial loss: 0.477765\n",
      "epoch 166; iter: 0; batch classifier loss: 0.009793; batch adversarial loss: 0.553874\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022546; batch adversarial loss: 0.565665\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027682; batch adversarial loss: 0.444713\n",
      "epoch 169; iter: 0; batch classifier loss: 0.004986; batch adversarial loss: 0.440312\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018410; batch adversarial loss: 0.474982\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036809; batch adversarial loss: 0.423112\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016839; batch adversarial loss: 0.486443\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027061; batch adversarial loss: 0.511661\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014038; batch adversarial loss: 0.471901\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017110; batch adversarial loss: 0.375786\n",
      "epoch 176; iter: 0; batch classifier loss: 0.039210; batch adversarial loss: 0.490726\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028805; batch adversarial loss: 0.579425\n",
      "epoch 178; iter: 0; batch classifier loss: 0.004377; batch adversarial loss: 0.520957\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008118; batch adversarial loss: 0.555178\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021342; batch adversarial loss: 0.391127\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026046; batch adversarial loss: 0.524991\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033553; batch adversarial loss: 0.418593\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015087; batch adversarial loss: 0.467170\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015644; batch adversarial loss: 0.517917\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008102; batch adversarial loss: 0.418398\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012003; batch adversarial loss: 0.429133\n",
      "epoch 187; iter: 0; batch classifier loss: 0.037355; batch adversarial loss: 0.441559\n",
      "epoch 188; iter: 0; batch classifier loss: 0.045211; batch adversarial loss: 0.507950\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021113; batch adversarial loss: 0.410803\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017937; batch adversarial loss: 0.531039\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030026; batch adversarial loss: 0.493977\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030408; batch adversarial loss: 0.572415\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014898; batch adversarial loss: 0.460718\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028025; batch adversarial loss: 0.365494\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006681; batch adversarial loss: 0.449400\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007334; batch adversarial loss: 0.394111\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021669; batch adversarial loss: 0.385754\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029305; batch adversarial loss: 0.417488\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009987; batch adversarial loss: 0.435487\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705003; batch adversarial loss: 0.996285\n",
      "epoch 1; iter: 0; batch classifier loss: 0.557014; batch adversarial loss: 0.929364\n",
      "epoch 2; iter: 0; batch classifier loss: 0.729819; batch adversarial loss: 0.954863\n",
      "epoch 3; iter: 0; batch classifier loss: 0.897375; batch adversarial loss: 0.883622\n",
      "epoch 4; iter: 0; batch classifier loss: 0.996412; batch adversarial loss: 0.797527\n",
      "epoch 5; iter: 0; batch classifier loss: 0.769648; batch adversarial loss: 0.740307\n",
      "epoch 6; iter: 0; batch classifier loss: 0.974362; batch adversarial loss: 0.678066\n",
      "epoch 7; iter: 0; batch classifier loss: 0.863935; batch adversarial loss: 0.585892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.614837; batch adversarial loss: 0.608987\n",
      "epoch 9; iter: 0; batch classifier loss: 0.463778; batch adversarial loss: 0.580205\n",
      "epoch 10; iter: 0; batch classifier loss: 0.482095; batch adversarial loss: 0.517828\n",
      "epoch 11; iter: 0; batch classifier loss: 0.424908; batch adversarial loss: 0.500574\n",
      "epoch 12; iter: 0; batch classifier loss: 0.325315; batch adversarial loss: 0.519170\n",
      "epoch 13; iter: 0; batch classifier loss: 0.263971; batch adversarial loss: 0.529801\n",
      "epoch 14; iter: 0; batch classifier loss: 0.345818; batch adversarial loss: 0.494582\n",
      "epoch 15; iter: 0; batch classifier loss: 0.213453; batch adversarial loss: 0.514075\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222283; batch adversarial loss: 0.486503\n",
      "epoch 17; iter: 0; batch classifier loss: 0.180343; batch adversarial loss: 0.498546\n",
      "epoch 18; iter: 0; batch classifier loss: 0.134034; batch adversarial loss: 0.520339\n",
      "epoch 19; iter: 0; batch classifier loss: 0.198530; batch adversarial loss: 0.479492\n",
      "epoch 20; iter: 0; batch classifier loss: 0.197353; batch adversarial loss: 0.566641\n",
      "epoch 21; iter: 0; batch classifier loss: 0.148794; batch adversarial loss: 0.407922\n",
      "epoch 22; iter: 0; batch classifier loss: 0.143864; batch adversarial loss: 0.448034\n",
      "epoch 23; iter: 0; batch classifier loss: 0.178447; batch adversarial loss: 0.532829\n",
      "epoch 24; iter: 0; batch classifier loss: 0.092247; batch adversarial loss: 0.465181\n",
      "epoch 25; iter: 0; batch classifier loss: 0.143902; batch adversarial loss: 0.453702\n",
      "epoch 26; iter: 0; batch classifier loss: 0.085900; batch adversarial loss: 0.469150\n",
      "epoch 27; iter: 0; batch classifier loss: 0.112210; batch adversarial loss: 0.565655\n",
      "epoch 28; iter: 0; batch classifier loss: 0.100557; batch adversarial loss: 0.410298\n",
      "epoch 29; iter: 0; batch classifier loss: 0.139256; batch adversarial loss: 0.439980\n",
      "epoch 30; iter: 0; batch classifier loss: 0.108600; batch adversarial loss: 0.457384\n",
      "epoch 31; iter: 0; batch classifier loss: 0.151560; batch adversarial loss: 0.439842\n",
      "epoch 32; iter: 0; batch classifier loss: 0.085587; batch adversarial loss: 0.487436\n",
      "epoch 33; iter: 0; batch classifier loss: 0.126298; batch adversarial loss: 0.540411\n",
      "epoch 34; iter: 0; batch classifier loss: 0.073549; batch adversarial loss: 0.491756\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122732; batch adversarial loss: 0.444611\n",
      "epoch 36; iter: 0; batch classifier loss: 0.074927; batch adversarial loss: 0.497376\n",
      "epoch 37; iter: 0; batch classifier loss: 0.059319; batch adversarial loss: 0.445765\n",
      "epoch 38; iter: 0; batch classifier loss: 0.142350; batch adversarial loss: 0.461370\n",
      "epoch 39; iter: 0; batch classifier loss: 0.052144; batch adversarial loss: 0.443392\n",
      "epoch 40; iter: 0; batch classifier loss: 0.067899; batch adversarial loss: 0.382249\n",
      "epoch 41; iter: 0; batch classifier loss: 0.078701; batch adversarial loss: 0.522898\n",
      "epoch 42; iter: 0; batch classifier loss: 0.070539; batch adversarial loss: 0.442638\n",
      "epoch 43; iter: 0; batch classifier loss: 0.120854; batch adversarial loss: 0.465099\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118128; batch adversarial loss: 0.418654\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091937; batch adversarial loss: 0.405897\n",
      "epoch 46; iter: 0; batch classifier loss: 0.113927; batch adversarial loss: 0.428284\n",
      "epoch 47; iter: 0; batch classifier loss: 0.102653; batch adversarial loss: 0.463847\n",
      "epoch 48; iter: 0; batch classifier loss: 0.055384; batch adversarial loss: 0.448416\n",
      "epoch 49; iter: 0; batch classifier loss: 0.066343; batch adversarial loss: 0.442698\n",
      "epoch 50; iter: 0; batch classifier loss: 0.090799; batch adversarial loss: 0.450435\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081789; batch adversarial loss: 0.461253\n",
      "epoch 52; iter: 0; batch classifier loss: 0.081413; batch adversarial loss: 0.462042\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094726; batch adversarial loss: 0.429536\n",
      "epoch 54; iter: 0; batch classifier loss: 0.057101; batch adversarial loss: 0.560008\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077178; batch adversarial loss: 0.505109\n",
      "epoch 56; iter: 0; batch classifier loss: 0.045663; batch adversarial loss: 0.475694\n",
      "epoch 57; iter: 0; batch classifier loss: 0.076541; batch adversarial loss: 0.454742\n",
      "epoch 58; iter: 0; batch classifier loss: 0.059355; batch adversarial loss: 0.444404\n",
      "epoch 59; iter: 0; batch classifier loss: 0.068374; batch adversarial loss: 0.480518\n",
      "epoch 60; iter: 0; batch classifier loss: 0.047102; batch adversarial loss: 0.476274\n",
      "epoch 61; iter: 0; batch classifier loss: 0.032736; batch adversarial loss: 0.377467\n",
      "epoch 62; iter: 0; batch classifier loss: 0.039746; batch adversarial loss: 0.417822\n",
      "epoch 63; iter: 0; batch classifier loss: 0.046687; batch adversarial loss: 0.464342\n",
      "epoch 64; iter: 0; batch classifier loss: 0.033089; batch adversarial loss: 0.509529\n",
      "epoch 65; iter: 0; batch classifier loss: 0.068653; batch adversarial loss: 0.509505\n",
      "epoch 66; iter: 0; batch classifier loss: 0.048448; batch adversarial loss: 0.482596\n",
      "epoch 67; iter: 0; batch classifier loss: 0.048421; batch adversarial loss: 0.470117\n",
      "epoch 68; iter: 0; batch classifier loss: 0.108052; batch adversarial loss: 0.407591\n",
      "epoch 69; iter: 0; batch classifier loss: 0.042620; batch adversarial loss: 0.401948\n",
      "epoch 70; iter: 0; batch classifier loss: 0.057082; batch adversarial loss: 0.494177\n",
      "epoch 71; iter: 0; batch classifier loss: 0.036754; batch adversarial loss: 0.431354\n",
      "epoch 72; iter: 0; batch classifier loss: 0.025464; batch adversarial loss: 0.453791\n",
      "epoch 73; iter: 0; batch classifier loss: 0.040283; batch adversarial loss: 0.416610\n",
      "epoch 74; iter: 0; batch classifier loss: 0.038073; batch adversarial loss: 0.353832\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069497; batch adversarial loss: 0.510731\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055181; batch adversarial loss: 0.450228\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055878; batch adversarial loss: 0.541515\n",
      "epoch 78; iter: 0; batch classifier loss: 0.056917; batch adversarial loss: 0.449810\n",
      "epoch 79; iter: 0; batch classifier loss: 0.043656; batch adversarial loss: 0.441020\n",
      "epoch 80; iter: 0; batch classifier loss: 0.032454; batch adversarial loss: 0.476737\n",
      "epoch 81; iter: 0; batch classifier loss: 0.042092; batch adversarial loss: 0.470863\n",
      "epoch 82; iter: 0; batch classifier loss: 0.023448; batch adversarial loss: 0.399916\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064881; batch adversarial loss: 0.441955\n",
      "epoch 84; iter: 0; batch classifier loss: 0.111927; batch adversarial loss: 0.441255\n",
      "epoch 85; iter: 0; batch classifier loss: 0.028678; batch adversarial loss: 0.459930\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070864; batch adversarial loss: 0.468113\n",
      "epoch 87; iter: 0; batch classifier loss: 0.027019; batch adversarial loss: 0.577758\n",
      "epoch 88; iter: 0; batch classifier loss: 0.019018; batch adversarial loss: 0.511760\n",
      "epoch 89; iter: 0; batch classifier loss: 0.037036; batch adversarial loss: 0.441268\n",
      "epoch 90; iter: 0; batch classifier loss: 0.032370; batch adversarial loss: 0.426727\n",
      "epoch 91; iter: 0; batch classifier loss: 0.031650; batch adversarial loss: 0.523091\n",
      "epoch 92; iter: 0; batch classifier loss: 0.037312; batch adversarial loss: 0.520204\n",
      "epoch 93; iter: 0; batch classifier loss: 0.042777; batch adversarial loss: 0.398025\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044501; batch adversarial loss: 0.468804\n",
      "epoch 95; iter: 0; batch classifier loss: 0.022642; batch adversarial loss: 0.387683\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037368; batch adversarial loss: 0.465972\n",
      "epoch 97; iter: 0; batch classifier loss: 0.013461; batch adversarial loss: 0.388379\n",
      "epoch 98; iter: 0; batch classifier loss: 0.077021; batch adversarial loss: 0.496679\n",
      "epoch 99; iter: 0; batch classifier loss: 0.036540; batch adversarial loss: 0.448509\n",
      "epoch 100; iter: 0; batch classifier loss: 0.040814; batch adversarial loss: 0.409107\n",
      "epoch 101; iter: 0; batch classifier loss: 0.031340; batch adversarial loss: 0.456846\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056086; batch adversarial loss: 0.470713\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047298; batch adversarial loss: 0.444241\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062178; batch adversarial loss: 0.537908\n",
      "epoch 105; iter: 0; batch classifier loss: 0.023788; batch adversarial loss: 0.515555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.057326; batch adversarial loss: 0.428701\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036558; batch adversarial loss: 0.447944\n",
      "epoch 108; iter: 0; batch classifier loss: 0.018976; batch adversarial loss: 0.458507\n",
      "epoch 109; iter: 0; batch classifier loss: 0.022925; batch adversarial loss: 0.491384\n",
      "epoch 110; iter: 0; batch classifier loss: 0.016435; batch adversarial loss: 0.480064\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059795; batch adversarial loss: 0.507340\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041929; batch adversarial loss: 0.453985\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054509; batch adversarial loss: 0.492379\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032280; batch adversarial loss: 0.501791\n",
      "epoch 115; iter: 0; batch classifier loss: 0.023068; batch adversarial loss: 0.402661\n",
      "epoch 116; iter: 0; batch classifier loss: 0.074585; batch adversarial loss: 0.422285\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049468; batch adversarial loss: 0.465604\n",
      "epoch 118; iter: 0; batch classifier loss: 0.099562; batch adversarial loss: 0.460668\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025403; batch adversarial loss: 0.464896\n",
      "epoch 120; iter: 0; batch classifier loss: 0.012417; batch adversarial loss: 0.628121\n",
      "epoch 121; iter: 0; batch classifier loss: 0.063480; batch adversarial loss: 0.465566\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050487; batch adversarial loss: 0.486488\n",
      "epoch 123; iter: 0; batch classifier loss: 0.013416; batch adversarial loss: 0.479321\n",
      "epoch 124; iter: 0; batch classifier loss: 0.056856; batch adversarial loss: 0.459326\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029094; batch adversarial loss: 0.469042\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030595; batch adversarial loss: 0.443616\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040246; batch adversarial loss: 0.409139\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026180; batch adversarial loss: 0.437037\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029467; batch adversarial loss: 0.458917\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016375; batch adversarial loss: 0.494387\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038257; batch adversarial loss: 0.488052\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027466; batch adversarial loss: 0.383499\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023882; batch adversarial loss: 0.512104\n",
      "epoch 134; iter: 0; batch classifier loss: 0.011642; batch adversarial loss: 0.440132\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020389; batch adversarial loss: 0.511292\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026509; batch adversarial loss: 0.458533\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030956; batch adversarial loss: 0.410437\n",
      "epoch 138; iter: 0; batch classifier loss: 0.012156; batch adversarial loss: 0.428439\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032654; batch adversarial loss: 0.426088\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018158; batch adversarial loss: 0.460129\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025596; batch adversarial loss: 0.496486\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028221; batch adversarial loss: 0.405350\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025805; batch adversarial loss: 0.528073\n",
      "epoch 144; iter: 0; batch classifier loss: 0.054355; batch adversarial loss: 0.525426\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024954; batch adversarial loss: 0.452843\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035219; batch adversarial loss: 0.601254\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041953; batch adversarial loss: 0.378284\n",
      "epoch 148; iter: 0; batch classifier loss: 0.010666; batch adversarial loss: 0.451167\n",
      "epoch 149; iter: 0; batch classifier loss: 0.010108; batch adversarial loss: 0.463279\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016570; batch adversarial loss: 0.489700\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033485; batch adversarial loss: 0.484470\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036174; batch adversarial loss: 0.412468\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031419; batch adversarial loss: 0.427790\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015534; batch adversarial loss: 0.461989\n",
      "epoch 155; iter: 0; batch classifier loss: 0.051624; batch adversarial loss: 0.399002\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020362; batch adversarial loss: 0.352769\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031907; batch adversarial loss: 0.447111\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026235; batch adversarial loss: 0.489568\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033492; batch adversarial loss: 0.514383\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025717; batch adversarial loss: 0.544114\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028841; batch adversarial loss: 0.418606\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014856; batch adversarial loss: 0.559023\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034146; batch adversarial loss: 0.500744\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038073; batch adversarial loss: 0.420425\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016990; batch adversarial loss: 0.398416\n",
      "epoch 166; iter: 0; batch classifier loss: 0.048383; batch adversarial loss: 0.431108\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039997; batch adversarial loss: 0.481317\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033860; batch adversarial loss: 0.457916\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010177; batch adversarial loss: 0.456841\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020352; batch adversarial loss: 0.579506\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018883; batch adversarial loss: 0.491615\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012661; batch adversarial loss: 0.461660\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015456; batch adversarial loss: 0.389229\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009214; batch adversarial loss: 0.403787\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021822; batch adversarial loss: 0.455234\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024347; batch adversarial loss: 0.465492\n",
      "epoch 177; iter: 0; batch classifier loss: 0.043291; batch adversarial loss: 0.446447\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017926; batch adversarial loss: 0.443595\n",
      "epoch 179; iter: 0; batch classifier loss: 0.003468; batch adversarial loss: 0.378429\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012001; batch adversarial loss: 0.436451\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011129; batch adversarial loss: 0.439510\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010193; batch adversarial loss: 0.438996\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018313; batch adversarial loss: 0.480425\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022908; batch adversarial loss: 0.447190\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013078; batch adversarial loss: 0.465512\n",
      "epoch 186; iter: 0; batch classifier loss: 0.054203; batch adversarial loss: 0.445506\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017308; batch adversarial loss: 0.516930\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008116; batch adversarial loss: 0.456250\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011019; batch adversarial loss: 0.493520\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005482; batch adversarial loss: 0.405875\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028180; batch adversarial loss: 0.481379\n",
      "epoch 192; iter: 0; batch classifier loss: 0.044520; batch adversarial loss: 0.434357\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017514; batch adversarial loss: 0.556439\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004028; batch adversarial loss: 0.509725\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028090; batch adversarial loss: 0.402967\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015980; batch adversarial loss: 0.396371\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006331; batch adversarial loss: 0.512487\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003015; batch adversarial loss: 0.510178\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011506; batch adversarial loss: 0.443926\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705492; batch adversarial loss: 0.576549\n",
      "epoch 1; iter: 0; batch classifier loss: 0.498250; batch adversarial loss: 0.589741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.348721; batch adversarial loss: 0.565529\n",
      "epoch 3; iter: 0; batch classifier loss: 0.353520; batch adversarial loss: 0.584258\n",
      "epoch 4; iter: 0; batch classifier loss: 0.348527; batch adversarial loss: 0.547469\n",
      "epoch 5; iter: 0; batch classifier loss: 0.274270; batch adversarial loss: 0.484043\n",
      "epoch 6; iter: 0; batch classifier loss: 0.333741; batch adversarial loss: 0.511936\n",
      "epoch 7; iter: 0; batch classifier loss: 0.280244; batch adversarial loss: 0.532699\n",
      "epoch 8; iter: 0; batch classifier loss: 0.290742; batch adversarial loss: 0.594374\n",
      "epoch 9; iter: 0; batch classifier loss: 0.236715; batch adversarial loss: 0.545837\n",
      "epoch 10; iter: 0; batch classifier loss: 0.306585; batch adversarial loss: 0.570759\n",
      "epoch 11; iter: 0; batch classifier loss: 0.275748; batch adversarial loss: 0.512028\n",
      "epoch 12; iter: 0; batch classifier loss: 0.235354; batch adversarial loss: 0.556042\n",
      "epoch 13; iter: 0; batch classifier loss: 0.290208; batch adversarial loss: 0.487347\n",
      "epoch 14; iter: 0; batch classifier loss: 0.203846; batch adversarial loss: 0.471397\n",
      "epoch 15; iter: 0; batch classifier loss: 0.265069; batch adversarial loss: 0.583790\n",
      "epoch 16; iter: 0; batch classifier loss: 0.182764; batch adversarial loss: 0.479419\n",
      "epoch 17; iter: 0; batch classifier loss: 0.245724; batch adversarial loss: 0.580414\n",
      "epoch 18; iter: 0; batch classifier loss: 0.318472; batch adversarial loss: 0.471830\n",
      "epoch 19; iter: 0; batch classifier loss: 0.250757; batch adversarial loss: 0.553262\n",
      "epoch 20; iter: 0; batch classifier loss: 0.288472; batch adversarial loss: 0.399628\n",
      "epoch 21; iter: 0; batch classifier loss: 0.288678; batch adversarial loss: 0.429106\n",
      "epoch 22; iter: 0; batch classifier loss: 0.295621; batch adversarial loss: 0.481412\n",
      "epoch 23; iter: 0; batch classifier loss: 0.460568; batch adversarial loss: 0.467405\n",
      "epoch 24; iter: 0; batch classifier loss: 0.278363; batch adversarial loss: 0.463159\n",
      "epoch 25; iter: 0; batch classifier loss: 0.162170; batch adversarial loss: 0.406350\n",
      "epoch 26; iter: 0; batch classifier loss: 0.154018; batch adversarial loss: 0.476262\n",
      "epoch 27; iter: 0; batch classifier loss: 0.126675; batch adversarial loss: 0.560358\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185327; batch adversarial loss: 0.422285\n",
      "epoch 29; iter: 0; batch classifier loss: 0.142135; batch adversarial loss: 0.485894\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153111; batch adversarial loss: 0.393142\n",
      "epoch 31; iter: 0; batch classifier loss: 0.071898; batch adversarial loss: 0.474198\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154881; batch adversarial loss: 0.415184\n",
      "epoch 33; iter: 0; batch classifier loss: 0.126351; batch adversarial loss: 0.525713\n",
      "epoch 34; iter: 0; batch classifier loss: 0.126283; batch adversarial loss: 0.397497\n",
      "epoch 35; iter: 0; batch classifier loss: 0.124446; batch adversarial loss: 0.409927\n",
      "epoch 36; iter: 0; batch classifier loss: 0.154611; batch adversarial loss: 0.479688\n",
      "epoch 37; iter: 0; batch classifier loss: 0.147288; batch adversarial loss: 0.450003\n",
      "epoch 38; iter: 0; batch classifier loss: 0.083575; batch adversarial loss: 0.494569\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126047; batch adversarial loss: 0.478735\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099827; batch adversarial loss: 0.485997\n",
      "epoch 41; iter: 0; batch classifier loss: 0.088685; batch adversarial loss: 0.473288\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088756; batch adversarial loss: 0.469143\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150959; batch adversarial loss: 0.414189\n",
      "epoch 44; iter: 0; batch classifier loss: 0.087272; batch adversarial loss: 0.508820\n",
      "epoch 45; iter: 0; batch classifier loss: 0.121962; batch adversarial loss: 0.389957\n",
      "epoch 46; iter: 0; batch classifier loss: 0.068358; batch adversarial loss: 0.429484\n",
      "epoch 47; iter: 0; batch classifier loss: 0.092091; batch adversarial loss: 0.394468\n",
      "epoch 48; iter: 0; batch classifier loss: 0.157244; batch adversarial loss: 0.443620\n",
      "epoch 49; iter: 0; batch classifier loss: 0.134599; batch adversarial loss: 0.484010\n",
      "epoch 50; iter: 0; batch classifier loss: 0.103832; batch adversarial loss: 0.505938\n",
      "epoch 51; iter: 0; batch classifier loss: 0.090641; batch adversarial loss: 0.487904\n",
      "epoch 52; iter: 0; batch classifier loss: 0.090330; batch adversarial loss: 0.508255\n",
      "epoch 53; iter: 0; batch classifier loss: 0.108847; batch adversarial loss: 0.455739\n",
      "epoch 54; iter: 0; batch classifier loss: 0.102016; batch adversarial loss: 0.446880\n",
      "epoch 55; iter: 0; batch classifier loss: 0.081992; batch adversarial loss: 0.414735\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103789; batch adversarial loss: 0.428651\n",
      "epoch 57; iter: 0; batch classifier loss: 0.098971; batch adversarial loss: 0.420057\n",
      "epoch 58; iter: 0; batch classifier loss: 0.073654; batch adversarial loss: 0.424395\n",
      "epoch 59; iter: 0; batch classifier loss: 0.097292; batch adversarial loss: 0.461552\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076822; batch adversarial loss: 0.381647\n",
      "epoch 61; iter: 0; batch classifier loss: 0.094815; batch adversarial loss: 0.528228\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104275; batch adversarial loss: 0.356953\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093682; batch adversarial loss: 0.479318\n",
      "epoch 64; iter: 0; batch classifier loss: 0.159090; batch adversarial loss: 0.501818\n",
      "epoch 65; iter: 0; batch classifier loss: 0.080212; batch adversarial loss: 0.426458\n",
      "epoch 66; iter: 0; batch classifier loss: 0.133382; batch adversarial loss: 0.442999\n",
      "epoch 67; iter: 0; batch classifier loss: 0.088116; batch adversarial loss: 0.463397\n",
      "epoch 68; iter: 0; batch classifier loss: 0.050988; batch adversarial loss: 0.437745\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094388; batch adversarial loss: 0.466236\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078918; batch adversarial loss: 0.506058\n",
      "epoch 71; iter: 0; batch classifier loss: 0.100103; batch adversarial loss: 0.428269\n",
      "epoch 72; iter: 0; batch classifier loss: 0.107008; batch adversarial loss: 0.496836\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067018; batch adversarial loss: 0.421050\n",
      "epoch 74; iter: 0; batch classifier loss: 0.107003; batch adversarial loss: 0.525508\n",
      "epoch 75; iter: 0; batch classifier loss: 0.110488; batch adversarial loss: 0.418280\n",
      "epoch 76; iter: 0; batch classifier loss: 0.089810; batch adversarial loss: 0.394403\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102964; batch adversarial loss: 0.453314\n",
      "epoch 78; iter: 0; batch classifier loss: 0.121597; batch adversarial loss: 0.537411\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075686; batch adversarial loss: 0.504371\n",
      "epoch 80; iter: 0; batch classifier loss: 0.097356; batch adversarial loss: 0.469642\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084122; batch adversarial loss: 0.488637\n",
      "epoch 82; iter: 0; batch classifier loss: 0.104475; batch adversarial loss: 0.356135\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085554; batch adversarial loss: 0.380675\n",
      "epoch 84; iter: 0; batch classifier loss: 0.134966; batch adversarial loss: 0.425102\n",
      "epoch 85; iter: 0; batch classifier loss: 0.146246; batch adversarial loss: 0.466645\n",
      "epoch 86; iter: 0; batch classifier loss: 0.092733; batch adversarial loss: 0.513110\n",
      "epoch 87; iter: 0; batch classifier loss: 0.133973; batch adversarial loss: 0.409062\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051596; batch adversarial loss: 0.533980\n",
      "epoch 89; iter: 0; batch classifier loss: 0.076266; batch adversarial loss: 0.550259\n",
      "epoch 90; iter: 0; batch classifier loss: 0.120867; batch adversarial loss: 0.455406\n",
      "epoch 91; iter: 0; batch classifier loss: 0.118503; batch adversarial loss: 0.464498\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058802; batch adversarial loss: 0.509478\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061516; batch adversarial loss: 0.433805\n",
      "epoch 94; iter: 0; batch classifier loss: 0.054330; batch adversarial loss: 0.444195\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081567; batch adversarial loss: 0.518450\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058616; batch adversarial loss: 0.514383\n",
      "epoch 97; iter: 0; batch classifier loss: 0.103818; batch adversarial loss: 0.360836\n",
      "epoch 98; iter: 0; batch classifier loss: 0.078594; batch adversarial loss: 0.467661\n",
      "epoch 99; iter: 0; batch classifier loss: 0.090616; batch adversarial loss: 0.488149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.109006; batch adversarial loss: 0.488874\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083925; batch adversarial loss: 0.459213\n",
      "epoch 102; iter: 0; batch classifier loss: 0.107706; batch adversarial loss: 0.393799\n",
      "epoch 103; iter: 0; batch classifier loss: 0.096995; batch adversarial loss: 0.415531\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063556; batch adversarial loss: 0.461680\n",
      "epoch 105; iter: 0; batch classifier loss: 0.170338; batch adversarial loss: 0.510544\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059308; batch adversarial loss: 0.478224\n",
      "epoch 107; iter: 0; batch classifier loss: 0.110911; batch adversarial loss: 0.370930\n",
      "epoch 108; iter: 0; batch classifier loss: 0.078699; batch adversarial loss: 0.528557\n",
      "epoch 109; iter: 0; batch classifier loss: 0.071839; batch adversarial loss: 0.484671\n",
      "epoch 110; iter: 0; batch classifier loss: 0.074648; batch adversarial loss: 0.483209\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069051; batch adversarial loss: 0.479179\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042145; batch adversarial loss: 0.463274\n",
      "epoch 113; iter: 0; batch classifier loss: 0.070678; batch adversarial loss: 0.466443\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060554; batch adversarial loss: 0.484961\n",
      "epoch 115; iter: 0; batch classifier loss: 0.096520; batch adversarial loss: 0.535198\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052864; batch adversarial loss: 0.518975\n",
      "epoch 117; iter: 0; batch classifier loss: 0.066272; batch adversarial loss: 0.453113\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041615; batch adversarial loss: 0.447619\n",
      "epoch 119; iter: 0; batch classifier loss: 0.071641; batch adversarial loss: 0.446846\n",
      "epoch 120; iter: 0; batch classifier loss: 0.058607; batch adversarial loss: 0.498111\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039072; batch adversarial loss: 0.488553\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034971; batch adversarial loss: 0.433788\n",
      "epoch 123; iter: 0; batch classifier loss: 0.111585; batch adversarial loss: 0.438607\n",
      "epoch 124; iter: 0; batch classifier loss: 0.098577; batch adversarial loss: 0.547936\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046534; batch adversarial loss: 0.489696\n",
      "epoch 126; iter: 0; batch classifier loss: 0.068553; batch adversarial loss: 0.425911\n",
      "epoch 127; iter: 0; batch classifier loss: 0.055008; batch adversarial loss: 0.420279\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028443; batch adversarial loss: 0.503431\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040279; batch adversarial loss: 0.422790\n",
      "epoch 130; iter: 0; batch classifier loss: 0.052755; batch adversarial loss: 0.488632\n",
      "epoch 131; iter: 0; batch classifier loss: 0.053379; batch adversarial loss: 0.319147\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034163; batch adversarial loss: 0.415107\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029634; batch adversarial loss: 0.504128\n",
      "epoch 134; iter: 0; batch classifier loss: 0.077599; batch adversarial loss: 0.531758\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049457; batch adversarial loss: 0.563486\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036148; batch adversarial loss: 0.393233\n",
      "epoch 137; iter: 0; batch classifier loss: 0.055716; batch adversarial loss: 0.431803\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026744; batch adversarial loss: 0.420025\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043472; batch adversarial loss: 0.488238\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029259; batch adversarial loss: 0.417961\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031106; batch adversarial loss: 0.402347\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017716; batch adversarial loss: 0.406915\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023105; batch adversarial loss: 0.439236\n",
      "epoch 144; iter: 0; batch classifier loss: 0.046025; batch adversarial loss: 0.493551\n",
      "epoch 145; iter: 0; batch classifier loss: 0.064706; batch adversarial loss: 0.487671\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025142; batch adversarial loss: 0.445691\n",
      "epoch 147; iter: 0; batch classifier loss: 0.047563; batch adversarial loss: 0.407095\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022380; batch adversarial loss: 0.433895\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031271; batch adversarial loss: 0.424254\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024738; batch adversarial loss: 0.547263\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029561; batch adversarial loss: 0.384603\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027586; batch adversarial loss: 0.414533\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025931; batch adversarial loss: 0.499278\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032461; batch adversarial loss: 0.439213\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035335; batch adversarial loss: 0.442531\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040319; batch adversarial loss: 0.398935\n",
      "epoch 157; iter: 0; batch classifier loss: 0.055537; batch adversarial loss: 0.438757\n",
      "epoch 158; iter: 0; batch classifier loss: 0.057788; batch adversarial loss: 0.447559\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026186; batch adversarial loss: 0.438662\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031005; batch adversarial loss: 0.544188\n",
      "epoch 161; iter: 0; batch classifier loss: 0.060842; batch adversarial loss: 0.418202\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041351; batch adversarial loss: 0.548186\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022816; batch adversarial loss: 0.502515\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021385; batch adversarial loss: 0.432884\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026613; batch adversarial loss: 0.498047\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034073; batch adversarial loss: 0.415134\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034682; batch adversarial loss: 0.516752\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037103; batch adversarial loss: 0.488260\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020530; batch adversarial loss: 0.395921\n",
      "epoch 170; iter: 0; batch classifier loss: 0.065648; batch adversarial loss: 0.403452\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016955; batch adversarial loss: 0.389016\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028491; batch adversarial loss: 0.575537\n",
      "epoch 173; iter: 0; batch classifier loss: 0.041799; batch adversarial loss: 0.449817\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030720; batch adversarial loss: 0.402281\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020458; batch adversarial loss: 0.482270\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018413; batch adversarial loss: 0.428207\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025548; batch adversarial loss: 0.476356\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032985; batch adversarial loss: 0.464897\n",
      "epoch 179; iter: 0; batch classifier loss: 0.054258; batch adversarial loss: 0.490382\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019152; batch adversarial loss: 0.432000\n",
      "epoch 181; iter: 0; batch classifier loss: 0.045710; batch adversarial loss: 0.426094\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012419; batch adversarial loss: 0.388048\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015517; batch adversarial loss: 0.477861\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019682; batch adversarial loss: 0.505294\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012004; batch adversarial loss: 0.457423\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031106; batch adversarial loss: 0.423744\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026103; batch adversarial loss: 0.373723\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019184; batch adversarial loss: 0.449701\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017179; batch adversarial loss: 0.432661\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024620; batch adversarial loss: 0.537881\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025242; batch adversarial loss: 0.452962\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009021; batch adversarial loss: 0.427542\n",
      "epoch 193; iter: 0; batch classifier loss: 0.044964; batch adversarial loss: 0.491680\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011168; batch adversarial loss: 0.452887\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008376; batch adversarial loss: 0.530091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.015470; batch adversarial loss: 0.392663\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020620; batch adversarial loss: 0.537124\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016349; batch adversarial loss: 0.421672\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031781; batch adversarial loss: 0.389656\n",
      "epoch 0; iter: 0; batch classifier loss: 0.662162; batch adversarial loss: 0.581224\n",
      "epoch 1; iter: 0; batch classifier loss: 0.432043; batch adversarial loss: 0.614071\n",
      "epoch 2; iter: 0; batch classifier loss: 0.384162; batch adversarial loss: 0.586254\n",
      "epoch 3; iter: 0; batch classifier loss: 0.314501; batch adversarial loss: 0.561865\n",
      "epoch 4; iter: 0; batch classifier loss: 0.385382; batch adversarial loss: 0.569188\n",
      "epoch 5; iter: 0; batch classifier loss: 0.309277; batch adversarial loss: 0.475792\n",
      "epoch 6; iter: 0; batch classifier loss: 0.293164; batch adversarial loss: 0.542748\n",
      "epoch 7; iter: 0; batch classifier loss: 0.312961; batch adversarial loss: 0.504306\n",
      "epoch 8; iter: 0; batch classifier loss: 0.288176; batch adversarial loss: 0.489342\n",
      "epoch 9; iter: 0; batch classifier loss: 0.296058; batch adversarial loss: 0.597411\n",
      "epoch 10; iter: 0; batch classifier loss: 0.202004; batch adversarial loss: 0.565030\n",
      "epoch 11; iter: 0; batch classifier loss: 0.265630; batch adversarial loss: 0.498854\n",
      "epoch 12; iter: 0; batch classifier loss: 0.320626; batch adversarial loss: 0.566993\n",
      "epoch 13; iter: 0; batch classifier loss: 0.220896; batch adversarial loss: 0.449379\n",
      "epoch 14; iter: 0; batch classifier loss: 0.288545; batch adversarial loss: 0.531538\n",
      "epoch 15; iter: 0; batch classifier loss: 0.266611; batch adversarial loss: 0.491656\n",
      "epoch 16; iter: 0; batch classifier loss: 0.337764; batch adversarial loss: 0.483637\n",
      "epoch 17; iter: 0; batch classifier loss: 0.531674; batch adversarial loss: 0.554844\n",
      "epoch 18; iter: 0; batch classifier loss: 0.565673; batch adversarial loss: 0.470966\n",
      "epoch 19; iter: 0; batch classifier loss: 0.291895; batch adversarial loss: 0.434738\n",
      "epoch 20; iter: 0; batch classifier loss: 0.252553; batch adversarial loss: 0.496199\n",
      "epoch 21; iter: 0; batch classifier loss: 0.214022; batch adversarial loss: 0.463100\n",
      "epoch 22; iter: 0; batch classifier loss: 0.208330; batch adversarial loss: 0.449049\n",
      "epoch 23; iter: 0; batch classifier loss: 0.197359; batch adversarial loss: 0.489962\n",
      "epoch 24; iter: 0; batch classifier loss: 0.212303; batch adversarial loss: 0.445363\n",
      "epoch 25; iter: 0; batch classifier loss: 0.151454; batch adversarial loss: 0.540623\n",
      "epoch 26; iter: 0; batch classifier loss: 0.159041; batch adversarial loss: 0.391252\n",
      "epoch 27; iter: 0; batch classifier loss: 0.140603; batch adversarial loss: 0.407412\n",
      "epoch 28; iter: 0; batch classifier loss: 0.129043; batch adversarial loss: 0.507681\n",
      "epoch 29; iter: 0; batch classifier loss: 0.102180; batch adversarial loss: 0.490418\n",
      "epoch 30; iter: 0; batch classifier loss: 0.154250; batch adversarial loss: 0.412217\n",
      "epoch 31; iter: 0; batch classifier loss: 0.151087; batch adversarial loss: 0.555332\n",
      "epoch 32; iter: 0; batch classifier loss: 0.145007; batch adversarial loss: 0.467934\n",
      "epoch 33; iter: 0; batch classifier loss: 0.103090; batch adversarial loss: 0.520888\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122260; batch adversarial loss: 0.472951\n",
      "epoch 35; iter: 0; batch classifier loss: 0.118165; batch adversarial loss: 0.475967\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102817; batch adversarial loss: 0.497767\n",
      "epoch 37; iter: 0; batch classifier loss: 0.098323; batch adversarial loss: 0.526641\n",
      "epoch 38; iter: 0; batch classifier loss: 0.077587; batch adversarial loss: 0.625386\n",
      "epoch 39; iter: 0; batch classifier loss: 0.128660; batch adversarial loss: 0.352437\n",
      "epoch 40; iter: 0; batch classifier loss: 0.081585; batch adversarial loss: 0.519927\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106662; batch adversarial loss: 0.374587\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110364; batch adversarial loss: 0.412406\n",
      "epoch 43; iter: 0; batch classifier loss: 0.096778; batch adversarial loss: 0.447126\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112021; batch adversarial loss: 0.528184\n",
      "epoch 45; iter: 0; batch classifier loss: 0.134042; batch adversarial loss: 0.488307\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112022; batch adversarial loss: 0.472964\n",
      "epoch 47; iter: 0; batch classifier loss: 0.118985; batch adversarial loss: 0.500216\n",
      "epoch 48; iter: 0; batch classifier loss: 0.177652; batch adversarial loss: 0.485170\n",
      "epoch 49; iter: 0; batch classifier loss: 0.124026; batch adversarial loss: 0.442025\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108447; batch adversarial loss: 0.362027\n",
      "epoch 51; iter: 0; batch classifier loss: 0.195061; batch adversarial loss: 0.524758\n",
      "epoch 52; iter: 0; batch classifier loss: 0.120981; batch adversarial loss: 0.375373\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096813; batch adversarial loss: 0.505210\n",
      "epoch 54; iter: 0; batch classifier loss: 0.113491; batch adversarial loss: 0.566666\n",
      "epoch 55; iter: 0; batch classifier loss: 0.133663; batch adversarial loss: 0.530240\n",
      "epoch 56; iter: 0; batch classifier loss: 0.109367; batch adversarial loss: 0.468882\n",
      "epoch 57; iter: 0; batch classifier loss: 0.130907; batch adversarial loss: 0.445590\n",
      "epoch 58; iter: 0; batch classifier loss: 0.123648; batch adversarial loss: 0.419186\n",
      "epoch 59; iter: 0; batch classifier loss: 0.136609; batch adversarial loss: 0.470452\n",
      "epoch 60; iter: 0; batch classifier loss: 0.129828; batch adversarial loss: 0.445697\n",
      "epoch 61; iter: 0; batch classifier loss: 0.124375; batch adversarial loss: 0.534799\n",
      "epoch 62; iter: 0; batch classifier loss: 0.119814; batch adversarial loss: 0.534543\n",
      "epoch 63; iter: 0; batch classifier loss: 0.117126; batch adversarial loss: 0.498103\n",
      "epoch 64; iter: 0; batch classifier loss: 0.121068; batch adversarial loss: 0.418072\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088590; batch adversarial loss: 0.496891\n",
      "epoch 66; iter: 0; batch classifier loss: 0.107584; batch adversarial loss: 0.419067\n",
      "epoch 67; iter: 0; batch classifier loss: 0.093513; batch adversarial loss: 0.506994\n",
      "epoch 68; iter: 0; batch classifier loss: 0.106322; batch adversarial loss: 0.466010\n",
      "epoch 69; iter: 0; batch classifier loss: 0.156426; batch adversarial loss: 0.518467\n",
      "epoch 70; iter: 0; batch classifier loss: 0.106388; batch adversarial loss: 0.381555\n",
      "epoch 71; iter: 0; batch classifier loss: 0.053132; batch adversarial loss: 0.402961\n",
      "epoch 72; iter: 0; batch classifier loss: 0.089667; batch adversarial loss: 0.463969\n",
      "epoch 73; iter: 0; batch classifier loss: 0.160613; batch adversarial loss: 0.408718\n",
      "epoch 74; iter: 0; batch classifier loss: 0.086750; batch adversarial loss: 0.419990\n",
      "epoch 75; iter: 0; batch classifier loss: 0.090114; batch adversarial loss: 0.493863\n",
      "epoch 76; iter: 0; batch classifier loss: 0.139609; batch adversarial loss: 0.429273\n",
      "epoch 77; iter: 0; batch classifier loss: 0.091947; batch adversarial loss: 0.494200\n",
      "epoch 78; iter: 0; batch classifier loss: 0.116368; batch adversarial loss: 0.416724\n",
      "epoch 79; iter: 0; batch classifier loss: 0.122356; batch adversarial loss: 0.473171\n",
      "epoch 80; iter: 0; batch classifier loss: 0.119177; batch adversarial loss: 0.470937\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064339; batch adversarial loss: 0.426784\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075859; batch adversarial loss: 0.454018\n",
      "epoch 83; iter: 0; batch classifier loss: 0.106226; batch adversarial loss: 0.482915\n",
      "epoch 84; iter: 0; batch classifier loss: 0.165071; batch adversarial loss: 0.485274\n",
      "epoch 85; iter: 0; batch classifier loss: 0.118316; batch adversarial loss: 0.430739\n",
      "epoch 86; iter: 0; batch classifier loss: 0.108691; batch adversarial loss: 0.462905\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082936; batch adversarial loss: 0.522460\n",
      "epoch 88; iter: 0; batch classifier loss: 0.066214; batch adversarial loss: 0.455932\n",
      "epoch 89; iter: 0; batch classifier loss: 0.097697; batch adversarial loss: 0.481437\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057688; batch adversarial loss: 0.534969\n",
      "epoch 91; iter: 0; batch classifier loss: 0.107496; batch adversarial loss: 0.481550\n",
      "epoch 92; iter: 0; batch classifier loss: 0.097991; batch adversarial loss: 0.500195\n",
      "epoch 93; iter: 0; batch classifier loss: 0.111130; batch adversarial loss: 0.482740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.108106; batch adversarial loss: 0.498048\n",
      "epoch 95; iter: 0; batch classifier loss: 0.117651; batch adversarial loss: 0.444950\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037554; batch adversarial loss: 0.469468\n",
      "epoch 97; iter: 0; batch classifier loss: 0.090782; batch adversarial loss: 0.465654\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051561; batch adversarial loss: 0.444838\n",
      "epoch 99; iter: 0; batch classifier loss: 0.090741; batch adversarial loss: 0.437974\n",
      "epoch 100; iter: 0; batch classifier loss: 0.083222; batch adversarial loss: 0.452398\n",
      "epoch 101; iter: 0; batch classifier loss: 0.115810; batch adversarial loss: 0.369716\n",
      "epoch 102; iter: 0; batch classifier loss: 0.096355; batch adversarial loss: 0.462474\n",
      "epoch 103; iter: 0; batch classifier loss: 0.090088; batch adversarial loss: 0.405007\n",
      "epoch 104; iter: 0; batch classifier loss: 0.035827; batch adversarial loss: 0.482329\n",
      "epoch 105; iter: 0; batch classifier loss: 0.075173; batch adversarial loss: 0.467463\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040687; batch adversarial loss: 0.452183\n",
      "epoch 107; iter: 0; batch classifier loss: 0.105962; batch adversarial loss: 0.429415\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046034; batch adversarial loss: 0.480938\n",
      "epoch 109; iter: 0; batch classifier loss: 0.078482; batch adversarial loss: 0.484300\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048808; batch adversarial loss: 0.421934\n",
      "epoch 111; iter: 0; batch classifier loss: 0.075268; batch adversarial loss: 0.500041\n",
      "epoch 112; iter: 0; batch classifier loss: 0.067786; batch adversarial loss: 0.426293\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069894; batch adversarial loss: 0.437596\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054286; batch adversarial loss: 0.406215\n",
      "epoch 115; iter: 0; batch classifier loss: 0.077110; batch adversarial loss: 0.442225\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035769; batch adversarial loss: 0.456285\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031223; batch adversarial loss: 0.514723\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029496; batch adversarial loss: 0.388537\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059564; batch adversarial loss: 0.457027\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039389; batch adversarial loss: 0.488164\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048091; batch adversarial loss: 0.599653\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062459; batch adversarial loss: 0.429705\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053075; batch adversarial loss: 0.510463\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052958; batch adversarial loss: 0.431814\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037843; batch adversarial loss: 0.446979\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046128; batch adversarial loss: 0.488037\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044112; batch adversarial loss: 0.437792\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033355; batch adversarial loss: 0.444385\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034658; batch adversarial loss: 0.498637\n",
      "epoch 130; iter: 0; batch classifier loss: 0.015200; batch adversarial loss: 0.434484\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019500; batch adversarial loss: 0.448470\n",
      "epoch 132; iter: 0; batch classifier loss: 0.056452; batch adversarial loss: 0.452702\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024891; batch adversarial loss: 0.483075\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028754; batch adversarial loss: 0.386597\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030850; batch adversarial loss: 0.412330\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039616; batch adversarial loss: 0.483295\n",
      "epoch 137; iter: 0; batch classifier loss: 0.078938; batch adversarial loss: 0.419751\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022419; batch adversarial loss: 0.485341\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032072; batch adversarial loss: 0.452203\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041202; batch adversarial loss: 0.476380\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020210; batch adversarial loss: 0.488006\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036840; batch adversarial loss: 0.428161\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029642; batch adversarial loss: 0.487628\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020333; batch adversarial loss: 0.422313\n",
      "epoch 145; iter: 0; batch classifier loss: 0.068847; batch adversarial loss: 0.546957\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032900; batch adversarial loss: 0.366293\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019409; batch adversarial loss: 0.484737\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024654; batch adversarial loss: 0.455678\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035182; batch adversarial loss: 0.486812\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032009; batch adversarial loss: 0.471886\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020427; batch adversarial loss: 0.376981\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032778; batch adversarial loss: 0.443809\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027777; batch adversarial loss: 0.485754\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046256; batch adversarial loss: 0.438760\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038134; batch adversarial loss: 0.455098\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018549; batch adversarial loss: 0.441983\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032421; batch adversarial loss: 0.429704\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012569; batch adversarial loss: 0.480919\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020915; batch adversarial loss: 0.496867\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015029; batch adversarial loss: 0.454506\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029758; batch adversarial loss: 0.534032\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011015; batch adversarial loss: 0.483450\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029442; batch adversarial loss: 0.482647\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024264; batch adversarial loss: 0.454653\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041523; batch adversarial loss: 0.422288\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035401; batch adversarial loss: 0.587573\n",
      "epoch 167; iter: 0; batch classifier loss: 0.045209; batch adversarial loss: 0.478614\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016431; batch adversarial loss: 0.496268\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030137; batch adversarial loss: 0.492812\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013656; batch adversarial loss: 0.449817\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033245; batch adversarial loss: 0.485852\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032814; batch adversarial loss: 0.473553\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006715; batch adversarial loss: 0.469825\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023907; batch adversarial loss: 0.456355\n",
      "epoch 175; iter: 0; batch classifier loss: 0.052766; batch adversarial loss: 0.411698\n",
      "epoch 176; iter: 0; batch classifier loss: 0.036656; batch adversarial loss: 0.398515\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018297; batch adversarial loss: 0.442332\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038249; batch adversarial loss: 0.439006\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024502; batch adversarial loss: 0.381353\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024788; batch adversarial loss: 0.419480\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011071; batch adversarial loss: 0.423037\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015063; batch adversarial loss: 0.479314\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008570; batch adversarial loss: 0.409976\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016083; batch adversarial loss: 0.435651\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016069; batch adversarial loss: 0.498722\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006365; batch adversarial loss: 0.451951\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026039; batch adversarial loss: 0.528279\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021448; batch adversarial loss: 0.432536\n",
      "epoch 189; iter: 0; batch classifier loss: 0.040122; batch adversarial loss: 0.499511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.029266; batch adversarial loss: 0.498270\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014518; batch adversarial loss: 0.326357\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007100; batch adversarial loss: 0.548058\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018094; batch adversarial loss: 0.459453\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008062; batch adversarial loss: 0.530478\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016145; batch adversarial loss: 0.474935\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028118; batch adversarial loss: 0.421554\n",
      "epoch 197; iter: 0; batch classifier loss: 0.070912; batch adversarial loss: 0.478466\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020559; batch adversarial loss: 0.463314\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008975; batch adversarial loss: 0.386687\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716403; batch adversarial loss: 0.752886\n",
      "epoch 1; iter: 0; batch classifier loss: 0.485483; batch adversarial loss: 0.698871\n",
      "epoch 2; iter: 0; batch classifier loss: 0.444147; batch adversarial loss: 0.688951\n",
      "epoch 3; iter: 0; batch classifier loss: 0.383757; batch adversarial loss: 0.667142\n",
      "epoch 4; iter: 0; batch classifier loss: 0.339873; batch adversarial loss: 0.628744\n",
      "epoch 5; iter: 0; batch classifier loss: 0.292270; batch adversarial loss: 0.598846\n",
      "epoch 6; iter: 0; batch classifier loss: 0.238900; batch adversarial loss: 0.610974\n",
      "epoch 7; iter: 0; batch classifier loss: 0.291826; batch adversarial loss: 0.522300\n",
      "epoch 8; iter: 0; batch classifier loss: 0.280212; batch adversarial loss: 0.498115\n",
      "epoch 9; iter: 0; batch classifier loss: 0.297503; batch adversarial loss: 0.477452\n",
      "epoch 10; iter: 0; batch classifier loss: 0.217600; batch adversarial loss: 0.500636\n",
      "epoch 11; iter: 0; batch classifier loss: 0.222105; batch adversarial loss: 0.488149\n",
      "epoch 12; iter: 0; batch classifier loss: 0.260098; batch adversarial loss: 0.519589\n",
      "epoch 13; iter: 0; batch classifier loss: 0.204374; batch adversarial loss: 0.450838\n",
      "epoch 14; iter: 0; batch classifier loss: 0.186318; batch adversarial loss: 0.482528\n",
      "epoch 15; iter: 0; batch classifier loss: 0.112470; batch adversarial loss: 0.484963\n",
      "epoch 16; iter: 0; batch classifier loss: 0.187317; batch adversarial loss: 0.428250\n",
      "epoch 17; iter: 0; batch classifier loss: 0.159032; batch adversarial loss: 0.462489\n",
      "epoch 18; iter: 0; batch classifier loss: 0.157044; batch adversarial loss: 0.425602\n",
      "epoch 19; iter: 0; batch classifier loss: 0.231946; batch adversarial loss: 0.400001\n",
      "epoch 20; iter: 0; batch classifier loss: 0.210859; batch adversarial loss: 0.447329\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149873; batch adversarial loss: 0.438198\n",
      "epoch 22; iter: 0; batch classifier loss: 0.165158; batch adversarial loss: 0.433703\n",
      "epoch 23; iter: 0; batch classifier loss: 0.141379; batch adversarial loss: 0.399743\n",
      "epoch 24; iter: 0; batch classifier loss: 0.126091; batch adversarial loss: 0.417108\n",
      "epoch 25; iter: 0; batch classifier loss: 0.180354; batch adversarial loss: 0.423216\n",
      "epoch 26; iter: 0; batch classifier loss: 0.116191; batch adversarial loss: 0.465304\n",
      "epoch 27; iter: 0; batch classifier loss: 0.179969; batch adversarial loss: 0.460829\n",
      "epoch 28; iter: 0; batch classifier loss: 0.139199; batch adversarial loss: 0.416626\n",
      "epoch 29; iter: 0; batch classifier loss: 0.223295; batch adversarial loss: 0.454380\n",
      "epoch 30; iter: 0; batch classifier loss: 0.125536; batch adversarial loss: 0.341932\n",
      "epoch 31; iter: 0; batch classifier loss: 0.167424; batch adversarial loss: 0.389583\n",
      "epoch 32; iter: 0; batch classifier loss: 0.125490; batch adversarial loss: 0.463949\n",
      "epoch 33; iter: 0; batch classifier loss: 0.106750; batch adversarial loss: 0.403212\n",
      "epoch 34; iter: 0; batch classifier loss: 0.118108; batch adversarial loss: 0.393327\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148812; batch adversarial loss: 0.426157\n",
      "epoch 36; iter: 0; batch classifier loss: 0.197990; batch adversarial loss: 0.383833\n",
      "epoch 37; iter: 0; batch classifier loss: 0.116433; batch adversarial loss: 0.451096\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107769; batch adversarial loss: 0.422880\n",
      "epoch 39; iter: 0; batch classifier loss: 0.116424; batch adversarial loss: 0.533913\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099283; batch adversarial loss: 0.540303\n",
      "epoch 41; iter: 0; batch classifier loss: 0.076540; batch adversarial loss: 0.414078\n",
      "epoch 42; iter: 0; batch classifier loss: 0.136116; batch adversarial loss: 0.508580\n",
      "epoch 43; iter: 0; batch classifier loss: 0.106929; batch adversarial loss: 0.417218\n",
      "epoch 44; iter: 0; batch classifier loss: 0.126009; batch adversarial loss: 0.460486\n",
      "epoch 45; iter: 0; batch classifier loss: 0.118664; batch adversarial loss: 0.503294\n",
      "epoch 46; iter: 0; batch classifier loss: 0.118638; batch adversarial loss: 0.421009\n",
      "epoch 47; iter: 0; batch classifier loss: 0.094598; batch adversarial loss: 0.413612\n",
      "epoch 48; iter: 0; batch classifier loss: 0.112224; batch adversarial loss: 0.460432\n",
      "epoch 49; iter: 0; batch classifier loss: 0.110880; batch adversarial loss: 0.435135\n",
      "epoch 50; iter: 0; batch classifier loss: 0.092021; batch adversarial loss: 0.402660\n",
      "epoch 51; iter: 0; batch classifier loss: 0.107219; batch adversarial loss: 0.425636\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100492; batch adversarial loss: 0.411589\n",
      "epoch 53; iter: 0; batch classifier loss: 0.085685; batch adversarial loss: 0.430010\n",
      "epoch 54; iter: 0; batch classifier loss: 0.090523; batch adversarial loss: 0.425106\n",
      "epoch 55; iter: 0; batch classifier loss: 0.068470; batch adversarial loss: 0.410905\n",
      "epoch 56; iter: 0; batch classifier loss: 0.079144; batch adversarial loss: 0.508471\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112332; batch adversarial loss: 0.396478\n",
      "epoch 58; iter: 0; batch classifier loss: 0.074501; batch adversarial loss: 0.518413\n",
      "epoch 59; iter: 0; batch classifier loss: 0.108265; batch adversarial loss: 0.458483\n",
      "epoch 60; iter: 0; batch classifier loss: 0.110419; batch adversarial loss: 0.406479\n",
      "epoch 61; iter: 0; batch classifier loss: 0.120136; batch adversarial loss: 0.423036\n",
      "epoch 62; iter: 0; batch classifier loss: 0.121094; batch adversarial loss: 0.357636\n",
      "epoch 63; iter: 0; batch classifier loss: 0.078265; batch adversarial loss: 0.446855\n",
      "epoch 64; iter: 0; batch classifier loss: 0.060098; batch adversarial loss: 0.399309\n",
      "epoch 65; iter: 0; batch classifier loss: 0.081793; batch adversarial loss: 0.439608\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075769; batch adversarial loss: 0.368211\n",
      "epoch 67; iter: 0; batch classifier loss: 0.084494; batch adversarial loss: 0.429400\n",
      "epoch 68; iter: 0; batch classifier loss: 0.088663; batch adversarial loss: 0.429300\n",
      "epoch 69; iter: 0; batch classifier loss: 0.059739; batch adversarial loss: 0.355493\n",
      "epoch 70; iter: 0; batch classifier loss: 0.063618; batch adversarial loss: 0.408813\n",
      "epoch 71; iter: 0; batch classifier loss: 0.069045; batch adversarial loss: 0.430989\n",
      "epoch 72; iter: 0; batch classifier loss: 0.094944; batch adversarial loss: 0.501826\n",
      "epoch 73; iter: 0; batch classifier loss: 0.057735; batch adversarial loss: 0.426439\n",
      "epoch 74; iter: 0; batch classifier loss: 0.046593; batch adversarial loss: 0.389629\n",
      "epoch 75; iter: 0; batch classifier loss: 0.060535; batch adversarial loss: 0.473322\n",
      "epoch 76; iter: 0; batch classifier loss: 0.056915; batch adversarial loss: 0.461989\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050289; batch adversarial loss: 0.445967\n",
      "epoch 78; iter: 0; batch classifier loss: 0.103364; batch adversarial loss: 0.475677\n",
      "epoch 79; iter: 0; batch classifier loss: 0.058888; batch adversarial loss: 0.471171\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078552; batch adversarial loss: 0.495610\n",
      "epoch 81; iter: 0; batch classifier loss: 0.033384; batch adversarial loss: 0.469208\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059993; batch adversarial loss: 0.442644\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056389; batch adversarial loss: 0.493356\n",
      "epoch 84; iter: 0; batch classifier loss: 0.029391; batch adversarial loss: 0.401305\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046421; batch adversarial loss: 0.484424\n",
      "epoch 86; iter: 0; batch classifier loss: 0.022463; batch adversarial loss: 0.430775\n",
      "epoch 87; iter: 0; batch classifier loss: 0.044031; batch adversarial loss: 0.410807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.024509; batch adversarial loss: 0.432680\n",
      "epoch 89; iter: 0; batch classifier loss: 0.044909; batch adversarial loss: 0.452364\n",
      "epoch 90; iter: 0; batch classifier loss: 0.047459; batch adversarial loss: 0.466549\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060586; batch adversarial loss: 0.515678\n",
      "epoch 92; iter: 0; batch classifier loss: 0.042249; batch adversarial loss: 0.426887\n",
      "epoch 93; iter: 0; batch classifier loss: 0.031258; batch adversarial loss: 0.339264\n",
      "epoch 94; iter: 0; batch classifier loss: 0.034331; batch adversarial loss: 0.522011\n",
      "epoch 95; iter: 0; batch classifier loss: 0.030094; batch adversarial loss: 0.433481\n",
      "epoch 96; iter: 0; batch classifier loss: 0.025755; batch adversarial loss: 0.449941\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052095; batch adversarial loss: 0.532037\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059277; batch adversarial loss: 0.462588\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038391; batch adversarial loss: 0.437080\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047298; batch adversarial loss: 0.394452\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054488; batch adversarial loss: 0.481190\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037790; batch adversarial loss: 0.475143\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035049; batch adversarial loss: 0.416023\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034444; batch adversarial loss: 0.537549\n",
      "epoch 105; iter: 0; batch classifier loss: 0.015538; batch adversarial loss: 0.460616\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055412; batch adversarial loss: 0.528935\n",
      "epoch 107; iter: 0; batch classifier loss: 0.132261; batch adversarial loss: 0.603577\n",
      "epoch 108; iter: 0; batch classifier loss: 0.098460; batch adversarial loss: 0.601772\n",
      "epoch 109; iter: 0; batch classifier loss: 0.089314; batch adversarial loss: 0.517414\n",
      "epoch 110; iter: 0; batch classifier loss: 0.062959; batch adversarial loss: 0.492889\n",
      "epoch 111; iter: 0; batch classifier loss: 0.131093; batch adversarial loss: 0.602860\n",
      "epoch 112; iter: 0; batch classifier loss: 0.099476; batch adversarial loss: 0.584659\n",
      "epoch 113; iter: 0; batch classifier loss: 0.096535; batch adversarial loss: 0.622241\n",
      "epoch 114; iter: 0; batch classifier loss: 0.150291; batch adversarial loss: 0.629330\n",
      "epoch 115; iter: 0; batch classifier loss: 0.237001; batch adversarial loss: 0.727208\n",
      "epoch 116; iter: 0; batch classifier loss: 0.150522; batch adversarial loss: 0.642505\n",
      "epoch 117; iter: 0; batch classifier loss: 0.155816; batch adversarial loss: 0.560278\n",
      "epoch 118; iter: 0; batch classifier loss: 0.115080; batch adversarial loss: 0.605322\n",
      "epoch 119; iter: 0; batch classifier loss: 0.194609; batch adversarial loss: 0.604705\n",
      "epoch 120; iter: 0; batch classifier loss: 0.113622; batch adversarial loss: 0.498598\n",
      "epoch 121; iter: 0; batch classifier loss: 0.134707; batch adversarial loss: 0.617562\n",
      "epoch 122; iter: 0; batch classifier loss: 0.197807; batch adversarial loss: 0.793622\n",
      "epoch 123; iter: 0; batch classifier loss: 0.165425; batch adversarial loss: 0.486289\n",
      "epoch 124; iter: 0; batch classifier loss: 0.105209; batch adversarial loss: 0.517265\n",
      "epoch 125; iter: 0; batch classifier loss: 0.137925; batch adversarial loss: 0.480279\n",
      "epoch 126; iter: 0; batch classifier loss: 0.144452; batch adversarial loss: 0.516205\n",
      "epoch 127; iter: 0; batch classifier loss: 0.147091; batch adversarial loss: 0.519234\n",
      "epoch 128; iter: 0; batch classifier loss: 0.170721; batch adversarial loss: 0.597885\n",
      "epoch 129; iter: 0; batch classifier loss: 0.102185; batch adversarial loss: 0.469408\n",
      "epoch 130; iter: 0; batch classifier loss: 0.052361; batch adversarial loss: 0.428263\n",
      "epoch 131; iter: 0; batch classifier loss: 0.133251; batch adversarial loss: 0.541987\n",
      "epoch 132; iter: 0; batch classifier loss: 0.144730; batch adversarial loss: 0.481550\n",
      "epoch 133; iter: 0; batch classifier loss: 0.097964; batch adversarial loss: 0.474462\n",
      "epoch 134; iter: 0; batch classifier loss: 0.094139; batch adversarial loss: 0.487130\n",
      "epoch 135; iter: 0; batch classifier loss: 0.152431; batch adversarial loss: 0.604784\n",
      "epoch 136; iter: 0; batch classifier loss: 0.110475; batch adversarial loss: 0.483150\n",
      "epoch 137; iter: 0; batch classifier loss: 0.118805; batch adversarial loss: 0.476320\n",
      "epoch 138; iter: 0; batch classifier loss: 0.122491; batch adversarial loss: 0.526858\n",
      "epoch 139; iter: 0; batch classifier loss: 0.168505; batch adversarial loss: 0.613943\n",
      "epoch 140; iter: 0; batch classifier loss: 0.121053; batch adversarial loss: 0.479264\n",
      "epoch 141; iter: 0; batch classifier loss: 0.096195; batch adversarial loss: 0.510289\n",
      "epoch 142; iter: 0; batch classifier loss: 0.137596; batch adversarial loss: 0.496223\n",
      "epoch 143; iter: 0; batch classifier loss: 0.127086; batch adversarial loss: 0.459385\n",
      "epoch 144; iter: 0; batch classifier loss: 0.088477; batch adversarial loss: 0.453158\n",
      "epoch 145; iter: 0; batch classifier loss: 0.076797; batch adversarial loss: 0.449648\n",
      "epoch 146; iter: 0; batch classifier loss: 0.058869; batch adversarial loss: 0.401704\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022362; batch adversarial loss: 0.447170\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038410; batch adversarial loss: 0.456830\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036421; batch adversarial loss: 0.468148\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019994; batch adversarial loss: 0.574027\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029549; batch adversarial loss: 0.491882\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033081; batch adversarial loss: 0.494158\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040630; batch adversarial loss: 0.480143\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022348; batch adversarial loss: 0.658528\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012103; batch adversarial loss: 0.440584\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035138; batch adversarial loss: 0.402820\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020714; batch adversarial loss: 0.445409\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027800; batch adversarial loss: 0.514101\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021210; batch adversarial loss: 0.449918\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025069; batch adversarial loss: 0.431180\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026451; batch adversarial loss: 0.421740\n",
      "epoch 162; iter: 0; batch classifier loss: 0.050494; batch adversarial loss: 0.391442\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028875; batch adversarial loss: 0.425880\n",
      "epoch 164; iter: 0; batch classifier loss: 0.074645; batch adversarial loss: 0.528351\n",
      "epoch 165; iter: 0; batch classifier loss: 0.042268; batch adversarial loss: 0.431947\n",
      "epoch 166; iter: 0; batch classifier loss: 0.059533; batch adversarial loss: 0.474639\n",
      "epoch 167; iter: 0; batch classifier loss: 0.037202; batch adversarial loss: 0.619157\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020856; batch adversarial loss: 0.485100\n",
      "epoch 169; iter: 0; batch classifier loss: 0.055422; batch adversarial loss: 0.506848\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019659; batch adversarial loss: 0.485301\n",
      "epoch 171; iter: 0; batch classifier loss: 0.055269; batch adversarial loss: 0.420570\n",
      "epoch 172; iter: 0; batch classifier loss: 0.045542; batch adversarial loss: 0.487832\n",
      "epoch 173; iter: 0; batch classifier loss: 0.043473; batch adversarial loss: 0.420037\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018353; batch adversarial loss: 0.348337\n",
      "epoch 175; iter: 0; batch classifier loss: 0.045470; batch adversarial loss: 0.356618\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032350; batch adversarial loss: 0.501225\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038836; batch adversarial loss: 0.439951\n",
      "epoch 178; iter: 0; batch classifier loss: 0.050198; batch adversarial loss: 0.437387\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039180; batch adversarial loss: 0.505209\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029548; batch adversarial loss: 0.465895\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020074; batch adversarial loss: 0.430370\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021969; batch adversarial loss: 0.366356\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030992; batch adversarial loss: 0.565116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.060779; batch adversarial loss: 0.486577\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035597; batch adversarial loss: 0.476113\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021714; batch adversarial loss: 0.340446\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034549; batch adversarial loss: 0.459850\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033744; batch adversarial loss: 0.430521\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025782; batch adversarial loss: 0.552892\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032228; batch adversarial loss: 0.549629\n",
      "epoch 191; iter: 0; batch classifier loss: 0.054321; batch adversarial loss: 0.464527\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012483; batch adversarial loss: 0.560152\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019500; batch adversarial loss: 0.404872\n",
      "epoch 194; iter: 0; batch classifier loss: 0.058308; batch adversarial loss: 0.520333\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034107; batch adversarial loss: 0.554869\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020080; batch adversarial loss: 0.425476\n",
      "epoch 197; iter: 0; batch classifier loss: 0.057317; batch adversarial loss: 0.471482\n",
      "epoch 198; iter: 0; batch classifier loss: 0.050845; batch adversarial loss: 0.463653\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026023; batch adversarial loss: 0.460959\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691764; batch adversarial loss: 0.757133\n",
      "epoch 1; iter: 0; batch classifier loss: 0.485426; batch adversarial loss: 0.692551\n",
      "epoch 2; iter: 0; batch classifier loss: 0.450227; batch adversarial loss: 0.640722\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374081; batch adversarial loss: 0.600252\n",
      "epoch 4; iter: 0; batch classifier loss: 0.325865; batch adversarial loss: 0.591336\n",
      "epoch 5; iter: 0; batch classifier loss: 0.285106; batch adversarial loss: 0.600984\n",
      "epoch 6; iter: 0; batch classifier loss: 0.287285; batch adversarial loss: 0.574626\n",
      "epoch 7; iter: 0; batch classifier loss: 0.308617; batch adversarial loss: 0.545554\n",
      "epoch 8; iter: 0; batch classifier loss: 0.370327; batch adversarial loss: 0.537788\n",
      "epoch 9; iter: 0; batch classifier loss: 0.450970; batch adversarial loss: 0.554176\n",
      "epoch 10; iter: 0; batch classifier loss: 0.364019; batch adversarial loss: 0.532676\n",
      "epoch 11; iter: 0; batch classifier loss: 0.366836; batch adversarial loss: 0.529690\n",
      "epoch 12; iter: 0; batch classifier loss: 0.339287; batch adversarial loss: 0.504091\n",
      "epoch 13; iter: 0; batch classifier loss: 0.299556; batch adversarial loss: 0.582411\n",
      "epoch 14; iter: 0; batch classifier loss: 0.280959; batch adversarial loss: 0.553738\n",
      "epoch 15; iter: 0; batch classifier loss: 0.356759; batch adversarial loss: 0.502948\n",
      "epoch 16; iter: 0; batch classifier loss: 0.310059; batch adversarial loss: 0.482897\n",
      "epoch 17; iter: 0; batch classifier loss: 0.293109; batch adversarial loss: 0.435770\n",
      "epoch 18; iter: 0; batch classifier loss: 0.234420; batch adversarial loss: 0.594205\n",
      "epoch 19; iter: 0; batch classifier loss: 0.229759; batch adversarial loss: 0.507292\n",
      "epoch 20; iter: 0; batch classifier loss: 0.224671; batch adversarial loss: 0.482678\n",
      "epoch 21; iter: 0; batch classifier loss: 0.320391; batch adversarial loss: 0.515768\n",
      "epoch 22; iter: 0; batch classifier loss: 0.249607; batch adversarial loss: 0.465190\n",
      "epoch 23; iter: 0; batch classifier loss: 0.255666; batch adversarial loss: 0.471017\n",
      "epoch 24; iter: 0; batch classifier loss: 0.213244; batch adversarial loss: 0.538519\n",
      "epoch 25; iter: 0; batch classifier loss: 0.157245; batch adversarial loss: 0.551576\n",
      "epoch 26; iter: 0; batch classifier loss: 0.236578; batch adversarial loss: 0.420845\n",
      "epoch 27; iter: 0; batch classifier loss: 0.138984; batch adversarial loss: 0.473911\n",
      "epoch 28; iter: 0; batch classifier loss: 0.183845; batch adversarial loss: 0.461422\n",
      "epoch 29; iter: 0; batch classifier loss: 0.201410; batch adversarial loss: 0.516093\n",
      "epoch 30; iter: 0; batch classifier loss: 0.226403; batch adversarial loss: 0.447652\n",
      "epoch 31; iter: 0; batch classifier loss: 0.195403; batch adversarial loss: 0.422979\n",
      "epoch 32; iter: 0; batch classifier loss: 0.138010; batch adversarial loss: 0.492250\n",
      "epoch 33; iter: 0; batch classifier loss: 0.144282; batch adversarial loss: 0.451548\n",
      "epoch 34; iter: 0; batch classifier loss: 0.198802; batch adversarial loss: 0.454666\n",
      "epoch 35; iter: 0; batch classifier loss: 0.161051; batch adversarial loss: 0.436183\n",
      "epoch 36; iter: 0; batch classifier loss: 0.211633; batch adversarial loss: 0.388199\n",
      "epoch 37; iter: 0; batch classifier loss: 0.155113; batch adversarial loss: 0.526147\n",
      "epoch 38; iter: 0; batch classifier loss: 0.167360; batch adversarial loss: 0.417020\n",
      "epoch 39; iter: 0; batch classifier loss: 0.142074; batch adversarial loss: 0.519165\n",
      "epoch 40; iter: 0; batch classifier loss: 0.150088; batch adversarial loss: 0.514220\n",
      "epoch 41; iter: 0; batch classifier loss: 0.160392; batch adversarial loss: 0.457431\n",
      "epoch 42; iter: 0; batch classifier loss: 0.168439; batch adversarial loss: 0.443654\n",
      "epoch 43; iter: 0; batch classifier loss: 0.098411; batch adversarial loss: 0.488038\n",
      "epoch 44; iter: 0; batch classifier loss: 0.122257; batch adversarial loss: 0.488782\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086677; batch adversarial loss: 0.497235\n",
      "epoch 46; iter: 0; batch classifier loss: 0.184266; batch adversarial loss: 0.413323\n",
      "epoch 47; iter: 0; batch classifier loss: 0.117015; batch adversarial loss: 0.425789\n",
      "epoch 48; iter: 0; batch classifier loss: 0.150215; batch adversarial loss: 0.489593\n",
      "epoch 49; iter: 0; batch classifier loss: 0.143980; batch adversarial loss: 0.482340\n",
      "epoch 50; iter: 0; batch classifier loss: 0.119091; batch adversarial loss: 0.431937\n",
      "epoch 51; iter: 0; batch classifier loss: 0.094855; batch adversarial loss: 0.409365\n",
      "epoch 52; iter: 0; batch classifier loss: 0.109759; batch adversarial loss: 0.419334\n",
      "epoch 53; iter: 0; batch classifier loss: 0.113104; batch adversarial loss: 0.409838\n",
      "epoch 54; iter: 0; batch classifier loss: 0.076553; batch adversarial loss: 0.444721\n",
      "epoch 55; iter: 0; batch classifier loss: 0.111779; batch adversarial loss: 0.363194\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103166; batch adversarial loss: 0.592181\n",
      "epoch 57; iter: 0; batch classifier loss: 0.084452; batch adversarial loss: 0.545977\n",
      "epoch 58; iter: 0; batch classifier loss: 0.093674; batch adversarial loss: 0.503322\n",
      "epoch 59; iter: 0; batch classifier loss: 0.106680; batch adversarial loss: 0.465300\n",
      "epoch 60; iter: 0; batch classifier loss: 0.062389; batch adversarial loss: 0.563816\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113891; batch adversarial loss: 0.525740\n",
      "epoch 62; iter: 0; batch classifier loss: 0.142805; batch adversarial loss: 0.389616\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088867; batch adversarial loss: 0.395664\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106309; batch adversarial loss: 0.429290\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082784; batch adversarial loss: 0.420534\n",
      "epoch 66; iter: 0; batch classifier loss: 0.157967; batch adversarial loss: 0.568694\n",
      "epoch 67; iter: 0; batch classifier loss: 0.076821; batch adversarial loss: 0.457724\n",
      "epoch 68; iter: 0; batch classifier loss: 0.074140; batch adversarial loss: 0.467508\n",
      "epoch 69; iter: 0; batch classifier loss: 0.080372; batch adversarial loss: 0.501700\n",
      "epoch 70; iter: 0; batch classifier loss: 0.107567; batch adversarial loss: 0.386083\n",
      "epoch 71; iter: 0; batch classifier loss: 0.095502; batch adversarial loss: 0.482401\n",
      "epoch 72; iter: 0; batch classifier loss: 0.043255; batch adversarial loss: 0.513002\n",
      "epoch 73; iter: 0; batch classifier loss: 0.082035; batch adversarial loss: 0.533913\n",
      "epoch 74; iter: 0; batch classifier loss: 0.052911; batch adversarial loss: 0.415333\n",
      "epoch 75; iter: 0; batch classifier loss: 0.054418; batch adversarial loss: 0.457239\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081234; batch adversarial loss: 0.495173\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056277; batch adversarial loss: 0.497717\n",
      "epoch 78; iter: 0; batch classifier loss: 0.124582; batch adversarial loss: 0.398159\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061853; batch adversarial loss: 0.457508\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054343; batch adversarial loss: 0.508039\n",
      "epoch 81; iter: 0; batch classifier loss: 0.060007; batch adversarial loss: 0.488720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.060067; batch adversarial loss: 0.538397\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061193; batch adversarial loss: 0.482454\n",
      "epoch 84; iter: 0; batch classifier loss: 0.057926; batch adversarial loss: 0.457370\n",
      "epoch 85; iter: 0; batch classifier loss: 0.040835; batch adversarial loss: 0.461170\n",
      "epoch 86; iter: 0; batch classifier loss: 0.091521; batch adversarial loss: 0.488404\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053767; batch adversarial loss: 0.524546\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062756; batch adversarial loss: 0.415312\n",
      "epoch 89; iter: 0; batch classifier loss: 0.045370; batch adversarial loss: 0.434820\n",
      "epoch 90; iter: 0; batch classifier loss: 0.082273; batch adversarial loss: 0.541205\n",
      "epoch 91; iter: 0; batch classifier loss: 0.076120; batch adversarial loss: 0.463608\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062246; batch adversarial loss: 0.361912\n",
      "epoch 93; iter: 0; batch classifier loss: 0.059771; batch adversarial loss: 0.489269\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047686; batch adversarial loss: 0.453631\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048250; batch adversarial loss: 0.460726\n",
      "epoch 96; iter: 0; batch classifier loss: 0.085413; batch adversarial loss: 0.440603\n",
      "epoch 97; iter: 0; batch classifier loss: 0.032534; batch adversarial loss: 0.465224\n",
      "epoch 98; iter: 0; batch classifier loss: 0.064085; batch adversarial loss: 0.483635\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055899; batch adversarial loss: 0.565459\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043029; batch adversarial loss: 0.549756\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040759; batch adversarial loss: 0.462302\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055623; batch adversarial loss: 0.512680\n",
      "epoch 103; iter: 0; batch classifier loss: 0.074712; batch adversarial loss: 0.356925\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038266; batch adversarial loss: 0.552140\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053599; batch adversarial loss: 0.501595\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049126; batch adversarial loss: 0.501123\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028528; batch adversarial loss: 0.536899\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049539; batch adversarial loss: 0.463886\n",
      "epoch 109; iter: 0; batch classifier loss: 0.079241; batch adversarial loss: 0.470336\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046136; batch adversarial loss: 0.497743\n",
      "epoch 111; iter: 0; batch classifier loss: 0.013239; batch adversarial loss: 0.536129\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056204; batch adversarial loss: 0.504530\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051012; batch adversarial loss: 0.439164\n",
      "epoch 114; iter: 0; batch classifier loss: 0.013641; batch adversarial loss: 0.392521\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041196; batch adversarial loss: 0.504950\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060846; batch adversarial loss: 0.443491\n",
      "epoch 117; iter: 0; batch classifier loss: 0.062516; batch adversarial loss: 0.469287\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044227; batch adversarial loss: 0.389391\n",
      "epoch 119; iter: 0; batch classifier loss: 0.027210; batch adversarial loss: 0.403935\n",
      "epoch 120; iter: 0; batch classifier loss: 0.020189; batch adversarial loss: 0.446731\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045780; batch adversarial loss: 0.464085\n",
      "epoch 122; iter: 0; batch classifier loss: 0.047090; batch adversarial loss: 0.445609\n",
      "epoch 123; iter: 0; batch classifier loss: 0.060614; batch adversarial loss: 0.460339\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052652; batch adversarial loss: 0.549814\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031190; batch adversarial loss: 0.447175\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032674; batch adversarial loss: 0.410658\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044303; batch adversarial loss: 0.367161\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024676; batch adversarial loss: 0.597352\n",
      "epoch 129; iter: 0; batch classifier loss: 0.044600; batch adversarial loss: 0.435320\n",
      "epoch 130; iter: 0; batch classifier loss: 0.055816; batch adversarial loss: 0.449429\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037583; batch adversarial loss: 0.311848\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015006; batch adversarial loss: 0.423051\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044487; batch adversarial loss: 0.369180\n",
      "epoch 134; iter: 0; batch classifier loss: 0.022291; batch adversarial loss: 0.399493\n",
      "epoch 135; iter: 0; batch classifier loss: 0.052553; batch adversarial loss: 0.413259\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042780; batch adversarial loss: 0.418057\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031510; batch adversarial loss: 0.609967\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027782; batch adversarial loss: 0.487505\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022827; batch adversarial loss: 0.508363\n",
      "epoch 140; iter: 0; batch classifier loss: 0.011929; batch adversarial loss: 0.495176\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048632; batch adversarial loss: 0.440357\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026531; batch adversarial loss: 0.524796\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021330; batch adversarial loss: 0.503197\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018345; batch adversarial loss: 0.510092\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034536; batch adversarial loss: 0.493870\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030282; batch adversarial loss: 0.524077\n",
      "epoch 147; iter: 0; batch classifier loss: 0.047703; batch adversarial loss: 0.446880\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018657; batch adversarial loss: 0.538419\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025634; batch adversarial loss: 0.466928\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014090; batch adversarial loss: 0.514099\n",
      "epoch 151; iter: 0; batch classifier loss: 0.051669; batch adversarial loss: 0.469802\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019473; batch adversarial loss: 0.485260\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011820; batch adversarial loss: 0.431953\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036665; batch adversarial loss: 0.421814\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014333; batch adversarial loss: 0.448382\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011159; batch adversarial loss: 0.533884\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036748; batch adversarial loss: 0.477902\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019937; batch adversarial loss: 0.415572\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017963; batch adversarial loss: 0.432214\n",
      "epoch 160; iter: 0; batch classifier loss: 0.038129; batch adversarial loss: 0.387115\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022661; batch adversarial loss: 0.497293\n",
      "epoch 162; iter: 0; batch classifier loss: 0.050035; batch adversarial loss: 0.469657\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038732; batch adversarial loss: 0.343020\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014338; batch adversarial loss: 0.418482\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013919; batch adversarial loss: 0.459205\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021213; batch adversarial loss: 0.420132\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015614; batch adversarial loss: 0.428939\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007396; batch adversarial loss: 0.494990\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021905; batch adversarial loss: 0.424457\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033177; batch adversarial loss: 0.340039\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012689; batch adversarial loss: 0.346330\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021553; batch adversarial loss: 0.382129\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013824; batch adversarial loss: 0.449040\n",
      "epoch 174; iter: 0; batch classifier loss: 0.044366; batch adversarial loss: 0.498291\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010901; batch adversarial loss: 0.467846\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013217; batch adversarial loss: 0.419330\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022180; batch adversarial loss: 0.481562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.015112; batch adversarial loss: 0.385071\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014561; batch adversarial loss: 0.490499\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026112; batch adversarial loss: 0.401506\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021758; batch adversarial loss: 0.496235\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011278; batch adversarial loss: 0.427924\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011698; batch adversarial loss: 0.461299\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006588; batch adversarial loss: 0.483669\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007004; batch adversarial loss: 0.513744\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014450; batch adversarial loss: 0.433009\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008902; batch adversarial loss: 0.437216\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012708; batch adversarial loss: 0.472834\n",
      "epoch 189; iter: 0; batch classifier loss: 0.040341; batch adversarial loss: 0.486219\n",
      "epoch 190; iter: 0; batch classifier loss: 0.044591; batch adversarial loss: 0.448223\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021050; batch adversarial loss: 0.418346\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009386; batch adversarial loss: 0.368728\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008216; batch adversarial loss: 0.406628\n",
      "epoch 194; iter: 0; batch classifier loss: 0.074585; batch adversarial loss: 0.396342\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019083; batch adversarial loss: 0.449337\n",
      "epoch 196; iter: 0; batch classifier loss: 0.035500; batch adversarial loss: 0.526071\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010556; batch adversarial loss: 0.492695\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014153; batch adversarial loss: 0.465257\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016401; batch adversarial loss: 0.408655\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683396; batch adversarial loss: 0.675724\n",
      "epoch 1; iter: 0; batch classifier loss: 0.462023; batch adversarial loss: 0.654064\n",
      "epoch 2; iter: 0; batch classifier loss: 0.328106; batch adversarial loss: 0.629499\n",
      "epoch 3; iter: 0; batch classifier loss: 0.329821; batch adversarial loss: 0.569082\n",
      "epoch 4; iter: 0; batch classifier loss: 0.290696; batch adversarial loss: 0.554397\n",
      "epoch 5; iter: 0; batch classifier loss: 0.260571; batch adversarial loss: 0.540059\n",
      "epoch 6; iter: 0; batch classifier loss: 0.252001; batch adversarial loss: 0.516944\n",
      "epoch 7; iter: 0; batch classifier loss: 0.289951; batch adversarial loss: 0.545500\n",
      "epoch 8; iter: 0; batch classifier loss: 0.264729; batch adversarial loss: 0.460060\n",
      "epoch 9; iter: 0; batch classifier loss: 0.191819; batch adversarial loss: 0.510329\n",
      "epoch 10; iter: 0; batch classifier loss: 0.313249; batch adversarial loss: 0.432562\n",
      "epoch 11; iter: 0; batch classifier loss: 0.253401; batch adversarial loss: 0.453107\n",
      "epoch 12; iter: 0; batch classifier loss: 0.264955; batch adversarial loss: 0.502975\n",
      "epoch 13; iter: 0; batch classifier loss: 0.181487; batch adversarial loss: 0.534039\n",
      "epoch 14; iter: 0; batch classifier loss: 0.171694; batch adversarial loss: 0.463523\n",
      "epoch 15; iter: 0; batch classifier loss: 0.202378; batch adversarial loss: 0.474323\n",
      "epoch 16; iter: 0; batch classifier loss: 0.103232; batch adversarial loss: 0.496098\n",
      "epoch 17; iter: 0; batch classifier loss: 0.193509; batch adversarial loss: 0.461048\n",
      "epoch 18; iter: 0; batch classifier loss: 0.141808; batch adversarial loss: 0.474983\n",
      "epoch 19; iter: 0; batch classifier loss: 0.156576; batch adversarial loss: 0.474321\n",
      "epoch 20; iter: 0; batch classifier loss: 0.154147; batch adversarial loss: 0.550381\n",
      "epoch 21; iter: 0; batch classifier loss: 0.191030; batch adversarial loss: 0.542023\n",
      "epoch 22; iter: 0; batch classifier loss: 0.180558; batch adversarial loss: 0.532757\n",
      "epoch 23; iter: 0; batch classifier loss: 0.189319; batch adversarial loss: 0.473258\n",
      "epoch 24; iter: 0; batch classifier loss: 0.240142; batch adversarial loss: 0.537140\n",
      "epoch 25; iter: 0; batch classifier loss: 0.138735; batch adversarial loss: 0.393467\n",
      "epoch 26; iter: 0; batch classifier loss: 0.130857; batch adversarial loss: 0.566795\n",
      "epoch 27; iter: 0; batch classifier loss: 0.179184; batch adversarial loss: 0.475125\n",
      "epoch 28; iter: 0; batch classifier loss: 0.197929; batch adversarial loss: 0.494664\n",
      "epoch 29; iter: 0; batch classifier loss: 0.250283; batch adversarial loss: 0.511160\n",
      "epoch 30; iter: 0; batch classifier loss: 0.291220; batch adversarial loss: 0.538006\n",
      "epoch 31; iter: 0; batch classifier loss: 0.167812; batch adversarial loss: 0.446558\n",
      "epoch 32; iter: 0; batch classifier loss: 0.315544; batch adversarial loss: 0.547541\n",
      "epoch 33; iter: 0; batch classifier loss: 0.204365; batch adversarial loss: 0.500677\n",
      "epoch 34; iter: 0; batch classifier loss: 0.266206; batch adversarial loss: 0.519171\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142683; batch adversarial loss: 0.531937\n",
      "epoch 36; iter: 0; batch classifier loss: 0.117767; batch adversarial loss: 0.404866\n",
      "epoch 37; iter: 0; batch classifier loss: 0.095846; batch adversarial loss: 0.434503\n",
      "epoch 38; iter: 0; batch classifier loss: 0.080392; batch adversarial loss: 0.389824\n",
      "epoch 39; iter: 0; batch classifier loss: 0.110811; batch adversarial loss: 0.375058\n",
      "epoch 40; iter: 0; batch classifier loss: 0.075692; batch adversarial loss: 0.473479\n",
      "epoch 41; iter: 0; batch classifier loss: 0.112158; batch adversarial loss: 0.466913\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103920; batch adversarial loss: 0.540776\n",
      "epoch 43; iter: 0; batch classifier loss: 0.093150; batch adversarial loss: 0.439577\n",
      "epoch 44; iter: 0; batch classifier loss: 0.116870; batch adversarial loss: 0.442965\n",
      "epoch 45; iter: 0; batch classifier loss: 0.088631; batch adversarial loss: 0.510669\n",
      "epoch 46; iter: 0; batch classifier loss: 0.105612; batch adversarial loss: 0.437905\n",
      "epoch 47; iter: 0; batch classifier loss: 0.066586; batch adversarial loss: 0.403473\n",
      "epoch 48; iter: 0; batch classifier loss: 0.093464; batch adversarial loss: 0.471311\n",
      "epoch 49; iter: 0; batch classifier loss: 0.111014; batch adversarial loss: 0.468487\n",
      "epoch 50; iter: 0; batch classifier loss: 0.065112; batch adversarial loss: 0.413422\n",
      "epoch 51; iter: 0; batch classifier loss: 0.118804; batch adversarial loss: 0.360753\n",
      "epoch 52; iter: 0; batch classifier loss: 0.110296; batch adversarial loss: 0.500140\n",
      "epoch 53; iter: 0; batch classifier loss: 0.079438; batch adversarial loss: 0.391891\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074726; batch adversarial loss: 0.517926\n",
      "epoch 55; iter: 0; batch classifier loss: 0.090969; batch adversarial loss: 0.398435\n",
      "epoch 56; iter: 0; batch classifier loss: 0.063138; batch adversarial loss: 0.456269\n",
      "epoch 57; iter: 0; batch classifier loss: 0.099373; batch adversarial loss: 0.462413\n",
      "epoch 58; iter: 0; batch classifier loss: 0.078778; batch adversarial loss: 0.410533\n",
      "epoch 59; iter: 0; batch classifier loss: 0.064730; batch adversarial loss: 0.511214\n",
      "epoch 60; iter: 0; batch classifier loss: 0.063924; batch adversarial loss: 0.475446\n",
      "epoch 61; iter: 0; batch classifier loss: 0.094047; batch adversarial loss: 0.397039\n",
      "epoch 62; iter: 0; batch classifier loss: 0.072867; batch adversarial loss: 0.461373\n",
      "epoch 63; iter: 0; batch classifier loss: 0.081143; batch adversarial loss: 0.524237\n",
      "epoch 64; iter: 0; batch classifier loss: 0.058328; batch adversarial loss: 0.424847\n",
      "epoch 65; iter: 0; batch classifier loss: 0.098339; batch adversarial loss: 0.506116\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066745; batch adversarial loss: 0.427534\n",
      "epoch 67; iter: 0; batch classifier loss: 0.089179; batch adversarial loss: 0.366273\n",
      "epoch 68; iter: 0; batch classifier loss: 0.088119; batch adversarial loss: 0.543914\n",
      "epoch 69; iter: 0; batch classifier loss: 0.067432; batch adversarial loss: 0.489825\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067874; batch adversarial loss: 0.502364\n",
      "epoch 71; iter: 0; batch classifier loss: 0.069627; batch adversarial loss: 0.397720\n",
      "epoch 72; iter: 0; batch classifier loss: 0.103716; batch adversarial loss: 0.438841\n",
      "epoch 73; iter: 0; batch classifier loss: 0.086611; batch adversarial loss: 0.446880\n",
      "epoch 74; iter: 0; batch classifier loss: 0.050532; batch adversarial loss: 0.478434\n",
      "epoch 75; iter: 0; batch classifier loss: 0.119981; batch adversarial loss: 0.402167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.071381; batch adversarial loss: 0.455945\n",
      "epoch 77; iter: 0; batch classifier loss: 0.080820; batch adversarial loss: 0.452071\n",
      "epoch 78; iter: 0; batch classifier loss: 0.056248; batch adversarial loss: 0.567793\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067980; batch adversarial loss: 0.427875\n",
      "epoch 80; iter: 0; batch classifier loss: 0.096752; batch adversarial loss: 0.464519\n",
      "epoch 81; iter: 0; batch classifier loss: 0.109557; batch adversarial loss: 0.471777\n",
      "epoch 82; iter: 0; batch classifier loss: 0.113318; batch adversarial loss: 0.446222\n",
      "epoch 83; iter: 0; batch classifier loss: 0.041294; batch adversarial loss: 0.428344\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048957; batch adversarial loss: 0.434087\n",
      "epoch 85; iter: 0; batch classifier loss: 0.043334; batch adversarial loss: 0.494006\n",
      "epoch 86; iter: 0; batch classifier loss: 0.034638; batch adversarial loss: 0.437048\n",
      "epoch 87; iter: 0; batch classifier loss: 0.043312; batch adversarial loss: 0.416107\n",
      "epoch 88; iter: 0; batch classifier loss: 0.045176; batch adversarial loss: 0.414870\n",
      "epoch 89; iter: 0; batch classifier loss: 0.082216; batch adversarial loss: 0.497243\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063556; batch adversarial loss: 0.470953\n",
      "epoch 91; iter: 0; batch classifier loss: 0.096754; batch adversarial loss: 0.436223\n",
      "epoch 92; iter: 0; batch classifier loss: 0.046738; batch adversarial loss: 0.555225\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055772; batch adversarial loss: 0.457307\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079743; batch adversarial loss: 0.524500\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056746; batch adversarial loss: 0.576083\n",
      "epoch 96; iter: 0; batch classifier loss: 0.077868; batch adversarial loss: 0.474894\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055713; batch adversarial loss: 0.437290\n",
      "epoch 98; iter: 0; batch classifier loss: 0.071978; batch adversarial loss: 0.419613\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041515; batch adversarial loss: 0.498754\n",
      "epoch 100; iter: 0; batch classifier loss: 0.071316; batch adversarial loss: 0.448569\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070153; batch adversarial loss: 0.504156\n",
      "epoch 102; iter: 0; batch classifier loss: 0.080343; batch adversarial loss: 0.445053\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050086; batch adversarial loss: 0.459246\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044214; batch adversarial loss: 0.453827\n",
      "epoch 105; iter: 0; batch classifier loss: 0.063053; batch adversarial loss: 0.436324\n",
      "epoch 106; iter: 0; batch classifier loss: 0.020530; batch adversarial loss: 0.474385\n",
      "epoch 107; iter: 0; batch classifier loss: 0.060852; batch adversarial loss: 0.476293\n",
      "epoch 108; iter: 0; batch classifier loss: 0.071162; batch adversarial loss: 0.495700\n",
      "epoch 109; iter: 0; batch classifier loss: 0.035976; batch adversarial loss: 0.470376\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060470; batch adversarial loss: 0.461585\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030354; batch adversarial loss: 0.503287\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038791; batch adversarial loss: 0.469264\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058657; batch adversarial loss: 0.459520\n",
      "epoch 114; iter: 0; batch classifier loss: 0.023572; batch adversarial loss: 0.476531\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053357; batch adversarial loss: 0.470948\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050061; batch adversarial loss: 0.543057\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048891; batch adversarial loss: 0.499278\n",
      "epoch 118; iter: 0; batch classifier loss: 0.088781; batch adversarial loss: 0.482326\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053687; batch adversarial loss: 0.516097\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031171; batch adversarial loss: 0.444703\n",
      "epoch 121; iter: 0; batch classifier loss: 0.061073; batch adversarial loss: 0.532256\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049532; batch adversarial loss: 0.378233\n",
      "epoch 123; iter: 0; batch classifier loss: 0.070770; batch adversarial loss: 0.449588\n",
      "epoch 124; iter: 0; batch classifier loss: 0.056743; batch adversarial loss: 0.459047\n",
      "epoch 125; iter: 0; batch classifier loss: 0.059556; batch adversarial loss: 0.477532\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031322; batch adversarial loss: 0.506536\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022091; batch adversarial loss: 0.475945\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049987; batch adversarial loss: 0.429155\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026845; batch adversarial loss: 0.427033\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046444; batch adversarial loss: 0.432761\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050087; batch adversarial loss: 0.479878\n",
      "epoch 132; iter: 0; batch classifier loss: 0.074973; batch adversarial loss: 0.485143\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037527; batch adversarial loss: 0.498267\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030538; batch adversarial loss: 0.465573\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050739; batch adversarial loss: 0.439995\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025873; batch adversarial loss: 0.485430\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034546; batch adversarial loss: 0.455637\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019013; batch adversarial loss: 0.415653\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020659; batch adversarial loss: 0.458832\n",
      "epoch 140; iter: 0; batch classifier loss: 0.005027; batch adversarial loss: 0.453216\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032764; batch adversarial loss: 0.407335\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023889; batch adversarial loss: 0.471368\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020924; batch adversarial loss: 0.484269\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032034; batch adversarial loss: 0.526087\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029053; batch adversarial loss: 0.400046\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044497; batch adversarial loss: 0.492419\n",
      "epoch 147; iter: 0; batch classifier loss: 0.063857; batch adversarial loss: 0.452131\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020694; batch adversarial loss: 0.517491\n",
      "epoch 149; iter: 0; batch classifier loss: 0.046569; batch adversarial loss: 0.474191\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037746; batch adversarial loss: 0.490664\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023484; batch adversarial loss: 0.490982\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045163; batch adversarial loss: 0.335378\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028595; batch adversarial loss: 0.513613\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037412; batch adversarial loss: 0.484095\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021694; batch adversarial loss: 0.403227\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020144; batch adversarial loss: 0.437964\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025738; batch adversarial loss: 0.524768\n",
      "epoch 158; iter: 0; batch classifier loss: 0.064558; batch adversarial loss: 0.532271\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017312; batch adversarial loss: 0.419447\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029489; batch adversarial loss: 0.445202\n",
      "epoch 161; iter: 0; batch classifier loss: 0.051749; batch adversarial loss: 0.481509\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038753; batch adversarial loss: 0.431158\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028655; batch adversarial loss: 0.432603\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032186; batch adversarial loss: 0.427984\n",
      "epoch 165; iter: 0; batch classifier loss: 0.045810; batch adversarial loss: 0.476028\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017629; batch adversarial loss: 0.453416\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015750; batch adversarial loss: 0.480383\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022624; batch adversarial loss: 0.451454\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014852; batch adversarial loss: 0.474430\n",
      "epoch 170; iter: 0; batch classifier loss: 0.036612; batch adversarial loss: 0.386725\n",
      "epoch 171; iter: 0; batch classifier loss: 0.055608; batch adversarial loss: 0.462985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.029446; batch adversarial loss: 0.495934\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010358; batch adversarial loss: 0.487579\n",
      "epoch 174; iter: 0; batch classifier loss: 0.043321; batch adversarial loss: 0.442005\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013451; batch adversarial loss: 0.458930\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018981; batch adversarial loss: 0.505936\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014461; batch adversarial loss: 0.435955\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012354; batch adversarial loss: 0.373182\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021829; batch adversarial loss: 0.474940\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013263; batch adversarial loss: 0.457947\n",
      "epoch 181; iter: 0; batch classifier loss: 0.057773; batch adversarial loss: 0.397590\n",
      "epoch 182; iter: 0; batch classifier loss: 0.005880; batch adversarial loss: 0.474780\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023861; batch adversarial loss: 0.492950\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031778; batch adversarial loss: 0.447389\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024466; batch adversarial loss: 0.496428\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025534; batch adversarial loss: 0.530375\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029762; batch adversarial loss: 0.509135\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016248; batch adversarial loss: 0.507234\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021362; batch adversarial loss: 0.529622\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018729; batch adversarial loss: 0.488127\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020260; batch adversarial loss: 0.479538\n",
      "epoch 192; iter: 0; batch classifier loss: 0.053001; batch adversarial loss: 0.508286\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010437; batch adversarial loss: 0.457630\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036990; batch adversarial loss: 0.462838\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020869; batch adversarial loss: 0.490116\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014749; batch adversarial loss: 0.404256\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011475; batch adversarial loss: 0.509645\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032603; batch adversarial loss: 0.502161\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015281; batch adversarial loss: 0.438125\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711838; batch adversarial loss: 0.538431\n",
      "epoch 1; iter: 0; batch classifier loss: 0.459114; batch adversarial loss: 0.576351\n",
      "epoch 2; iter: 0; batch classifier loss: 0.397384; batch adversarial loss: 0.649048\n",
      "epoch 3; iter: 0; batch classifier loss: 0.369453; batch adversarial loss: 0.561254\n",
      "epoch 4; iter: 0; batch classifier loss: 0.429304; batch adversarial loss: 0.565488\n",
      "epoch 5; iter: 0; batch classifier loss: 0.365836; batch adversarial loss: 0.529189\n",
      "epoch 6; iter: 0; batch classifier loss: 0.403804; batch adversarial loss: 0.576430\n",
      "epoch 7; iter: 0; batch classifier loss: 0.376043; batch adversarial loss: 0.604092\n",
      "epoch 8; iter: 0; batch classifier loss: 0.488801; batch adversarial loss: 0.525911\n",
      "epoch 9; iter: 0; batch classifier loss: 0.474439; batch adversarial loss: 0.639142\n",
      "epoch 10; iter: 0; batch classifier loss: 0.524065; batch adversarial loss: 0.574834\n",
      "epoch 11; iter: 0; batch classifier loss: 0.583778; batch adversarial loss: 0.583572\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491534; batch adversarial loss: 0.539348\n",
      "epoch 13; iter: 0; batch classifier loss: 0.473367; batch adversarial loss: 0.546798\n",
      "epoch 14; iter: 0; batch classifier loss: 0.382964; batch adversarial loss: 0.461556\n",
      "epoch 15; iter: 0; batch classifier loss: 0.261496; batch adversarial loss: 0.457665\n",
      "epoch 16; iter: 0; batch classifier loss: 0.209105; batch adversarial loss: 0.416782\n",
      "epoch 17; iter: 0; batch classifier loss: 0.258736; batch adversarial loss: 0.422373\n",
      "epoch 18; iter: 0; batch classifier loss: 0.231344; batch adversarial loss: 0.426413\n",
      "epoch 19; iter: 0; batch classifier loss: 0.258388; batch adversarial loss: 0.466595\n",
      "epoch 20; iter: 0; batch classifier loss: 0.177027; batch adversarial loss: 0.469943\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186756; batch adversarial loss: 0.519441\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189142; batch adversarial loss: 0.451029\n",
      "epoch 23; iter: 0; batch classifier loss: 0.140295; batch adversarial loss: 0.526911\n",
      "epoch 24; iter: 0; batch classifier loss: 0.163236; batch adversarial loss: 0.387432\n",
      "epoch 25; iter: 0; batch classifier loss: 0.226698; batch adversarial loss: 0.462035\n",
      "epoch 26; iter: 0; batch classifier loss: 0.157503; batch adversarial loss: 0.451633\n",
      "epoch 27; iter: 0; batch classifier loss: 0.199035; batch adversarial loss: 0.371790\n",
      "epoch 28; iter: 0; batch classifier loss: 0.145601; batch adversarial loss: 0.472776\n",
      "epoch 29; iter: 0; batch classifier loss: 0.133898; batch adversarial loss: 0.545713\n",
      "epoch 30; iter: 0; batch classifier loss: 0.135218; batch adversarial loss: 0.402314\n",
      "epoch 31; iter: 0; batch classifier loss: 0.134701; batch adversarial loss: 0.400453\n",
      "epoch 32; iter: 0; batch classifier loss: 0.142396; batch adversarial loss: 0.433749\n",
      "epoch 33; iter: 0; batch classifier loss: 0.128038; batch adversarial loss: 0.508296\n",
      "epoch 34; iter: 0; batch classifier loss: 0.163745; batch adversarial loss: 0.353175\n",
      "epoch 35; iter: 0; batch classifier loss: 0.114003; batch adversarial loss: 0.506935\n",
      "epoch 36; iter: 0; batch classifier loss: 0.126457; batch adversarial loss: 0.429246\n",
      "epoch 37; iter: 0; batch classifier loss: 0.078824; batch adversarial loss: 0.423002\n",
      "epoch 38; iter: 0; batch classifier loss: 0.120561; batch adversarial loss: 0.413437\n",
      "epoch 39; iter: 0; batch classifier loss: 0.150465; batch adversarial loss: 0.374969\n",
      "epoch 40; iter: 0; batch classifier loss: 0.131454; batch adversarial loss: 0.427175\n",
      "epoch 41; iter: 0; batch classifier loss: 0.092272; batch adversarial loss: 0.548493\n",
      "epoch 42; iter: 0; batch classifier loss: 0.180027; batch adversarial loss: 0.456804\n",
      "epoch 43; iter: 0; batch classifier loss: 0.091159; batch adversarial loss: 0.457541\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101420; batch adversarial loss: 0.394774\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097320; batch adversarial loss: 0.370672\n",
      "epoch 46; iter: 0; batch classifier loss: 0.110952; batch adversarial loss: 0.474335\n",
      "epoch 47; iter: 0; batch classifier loss: 0.148052; batch adversarial loss: 0.423325\n",
      "epoch 48; iter: 0; batch classifier loss: 0.145450; batch adversarial loss: 0.468469\n",
      "epoch 49; iter: 0; batch classifier loss: 0.118793; batch adversarial loss: 0.491504\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096791; batch adversarial loss: 0.517726\n",
      "epoch 51; iter: 0; batch classifier loss: 0.132572; batch adversarial loss: 0.545032\n",
      "epoch 52; iter: 0; batch classifier loss: 0.163965; batch adversarial loss: 0.411100\n",
      "epoch 53; iter: 0; batch classifier loss: 0.125740; batch adversarial loss: 0.452449\n",
      "epoch 54; iter: 0; batch classifier loss: 0.129904; batch adversarial loss: 0.550280\n",
      "epoch 55; iter: 0; batch classifier loss: 0.147277; batch adversarial loss: 0.399960\n",
      "epoch 56; iter: 0; batch classifier loss: 0.169121; batch adversarial loss: 0.383470\n",
      "epoch 57; iter: 0; batch classifier loss: 0.123933; batch adversarial loss: 0.547916\n",
      "epoch 58; iter: 0; batch classifier loss: 0.138760; batch adversarial loss: 0.513576\n",
      "epoch 59; iter: 0; batch classifier loss: 0.159260; batch adversarial loss: 0.483780\n",
      "epoch 60; iter: 0; batch classifier loss: 0.129988; batch adversarial loss: 0.527311\n",
      "epoch 61; iter: 0; batch classifier loss: 0.124988; batch adversarial loss: 0.492543\n",
      "epoch 62; iter: 0; batch classifier loss: 0.139085; batch adversarial loss: 0.414096\n",
      "epoch 63; iter: 0; batch classifier loss: 0.120505; batch adversarial loss: 0.508927\n",
      "epoch 64; iter: 0; batch classifier loss: 0.170946; batch adversarial loss: 0.427894\n",
      "epoch 65; iter: 0; batch classifier loss: 0.196797; batch adversarial loss: 0.433250\n",
      "epoch 66; iter: 0; batch classifier loss: 0.163323; batch adversarial loss: 0.396777\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107961; batch adversarial loss: 0.405104\n",
      "epoch 68; iter: 0; batch classifier loss: 0.120789; batch adversarial loss: 0.485291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.132459; batch adversarial loss: 0.383159\n",
      "epoch 70; iter: 0; batch classifier loss: 0.130146; batch adversarial loss: 0.549763\n",
      "epoch 71; iter: 0; batch classifier loss: 0.124471; batch adversarial loss: 0.470787\n",
      "epoch 72; iter: 0; batch classifier loss: 0.143722; batch adversarial loss: 0.425876\n",
      "epoch 73; iter: 0; batch classifier loss: 0.176914; batch adversarial loss: 0.432969\n",
      "epoch 74; iter: 0; batch classifier loss: 0.144741; batch adversarial loss: 0.444769\n",
      "epoch 75; iter: 0; batch classifier loss: 0.153055; batch adversarial loss: 0.513755\n",
      "epoch 76; iter: 0; batch classifier loss: 0.214657; batch adversarial loss: 0.446490\n",
      "epoch 77; iter: 0; batch classifier loss: 0.251573; batch adversarial loss: 0.510458\n",
      "epoch 78; iter: 0; batch classifier loss: 0.204438; batch adversarial loss: 0.478966\n",
      "epoch 79; iter: 0; batch classifier loss: 0.131294; batch adversarial loss: 0.432694\n",
      "epoch 80; iter: 0; batch classifier loss: 0.153795; batch adversarial loss: 0.361306\n",
      "epoch 81; iter: 0; batch classifier loss: 0.176678; batch adversarial loss: 0.385730\n",
      "epoch 82; iter: 0; batch classifier loss: 0.201171; batch adversarial loss: 0.482408\n",
      "epoch 83; iter: 0; batch classifier loss: 0.202019; batch adversarial loss: 0.460446\n",
      "epoch 84; iter: 0; batch classifier loss: 0.153688; batch adversarial loss: 0.481437\n",
      "epoch 85; iter: 0; batch classifier loss: 0.140498; batch adversarial loss: 0.456872\n",
      "epoch 86; iter: 0; batch classifier loss: 0.097883; batch adversarial loss: 0.421933\n",
      "epoch 87; iter: 0; batch classifier loss: 0.166027; batch adversarial loss: 0.472449\n",
      "epoch 88; iter: 0; batch classifier loss: 0.114782; batch adversarial loss: 0.468488\n",
      "epoch 89; iter: 0; batch classifier loss: 0.157964; batch adversarial loss: 0.519453\n",
      "epoch 90; iter: 0; batch classifier loss: 0.171677; batch adversarial loss: 0.419534\n",
      "epoch 91; iter: 0; batch classifier loss: 0.204107; batch adversarial loss: 0.364092\n",
      "epoch 92; iter: 0; batch classifier loss: 0.189706; batch adversarial loss: 0.458120\n",
      "epoch 93; iter: 0; batch classifier loss: 0.233195; batch adversarial loss: 0.456410\n",
      "epoch 94; iter: 0; batch classifier loss: 0.114716; batch adversarial loss: 0.507986\n",
      "epoch 95; iter: 0; batch classifier loss: 0.130839; batch adversarial loss: 0.364055\n",
      "epoch 96; iter: 0; batch classifier loss: 0.117332; batch adversarial loss: 0.494018\n",
      "epoch 97; iter: 0; batch classifier loss: 0.099071; batch adversarial loss: 0.508357\n",
      "epoch 98; iter: 0; batch classifier loss: 0.222504; batch adversarial loss: 0.431217\n",
      "epoch 99; iter: 0; batch classifier loss: 0.208505; batch adversarial loss: 0.483210\n",
      "epoch 100; iter: 0; batch classifier loss: 0.154013; batch adversarial loss: 0.484559\n",
      "epoch 101; iter: 0; batch classifier loss: 0.161306; batch adversarial loss: 0.411320\n",
      "epoch 102; iter: 0; batch classifier loss: 0.170951; batch adversarial loss: 0.542391\n",
      "epoch 103; iter: 0; batch classifier loss: 0.141851; batch adversarial loss: 0.471346\n",
      "epoch 104; iter: 0; batch classifier loss: 0.131119; batch adversarial loss: 0.349727\n",
      "epoch 105; iter: 0; batch classifier loss: 0.178671; batch adversarial loss: 0.423163\n",
      "epoch 106; iter: 0; batch classifier loss: 0.125044; batch adversarial loss: 0.568436\n",
      "epoch 107; iter: 0; batch classifier loss: 0.139950; batch adversarial loss: 0.498310\n",
      "epoch 108; iter: 0; batch classifier loss: 0.125889; batch adversarial loss: 0.422394\n",
      "epoch 109; iter: 0; batch classifier loss: 0.167996; batch adversarial loss: 0.384145\n",
      "epoch 110; iter: 0; batch classifier loss: 0.152715; batch adversarial loss: 0.460905\n",
      "epoch 111; iter: 0; batch classifier loss: 0.131609; batch adversarial loss: 0.482497\n",
      "epoch 112; iter: 0; batch classifier loss: 0.120848; batch adversarial loss: 0.422668\n",
      "epoch 113; iter: 0; batch classifier loss: 0.133030; batch adversarial loss: 0.411343\n",
      "epoch 114; iter: 0; batch classifier loss: 0.160033; batch adversarial loss: 0.410733\n",
      "epoch 115; iter: 0; batch classifier loss: 0.166452; batch adversarial loss: 0.530769\n",
      "epoch 116; iter: 0; batch classifier loss: 0.197324; batch adversarial loss: 0.484211\n",
      "epoch 117; iter: 0; batch classifier loss: 0.160497; batch adversarial loss: 0.482206\n",
      "epoch 118; iter: 0; batch classifier loss: 0.129458; batch adversarial loss: 0.517403\n",
      "epoch 119; iter: 0; batch classifier loss: 0.163079; batch adversarial loss: 0.459313\n",
      "epoch 120; iter: 0; batch classifier loss: 0.101792; batch adversarial loss: 0.494710\n",
      "epoch 121; iter: 0; batch classifier loss: 0.147767; batch adversarial loss: 0.605184\n",
      "epoch 122; iter: 0; batch classifier loss: 0.117896; batch adversarial loss: 0.411196\n",
      "epoch 123; iter: 0; batch classifier loss: 0.135037; batch adversarial loss: 0.420927\n",
      "epoch 124; iter: 0; batch classifier loss: 0.179251; batch adversarial loss: 0.432212\n",
      "epoch 125; iter: 0; batch classifier loss: 0.136840; batch adversarial loss: 0.444112\n",
      "epoch 126; iter: 0; batch classifier loss: 0.143375; batch adversarial loss: 0.459744\n",
      "epoch 127; iter: 0; batch classifier loss: 0.085613; batch adversarial loss: 0.449894\n",
      "epoch 128; iter: 0; batch classifier loss: 0.202090; batch adversarial loss: 0.471098\n",
      "epoch 129; iter: 0; batch classifier loss: 0.149187; batch adversarial loss: 0.420658\n",
      "epoch 130; iter: 0; batch classifier loss: 0.166218; batch adversarial loss: 0.530236\n",
      "epoch 131; iter: 0; batch classifier loss: 0.138356; batch adversarial loss: 0.517096\n",
      "epoch 132; iter: 0; batch classifier loss: 0.105232; batch adversarial loss: 0.485298\n",
      "epoch 133; iter: 0; batch classifier loss: 0.145767; batch adversarial loss: 0.422241\n",
      "epoch 134; iter: 0; batch classifier loss: 0.116318; batch adversarial loss: 0.483655\n",
      "epoch 135; iter: 0; batch classifier loss: 0.165050; batch adversarial loss: 0.384198\n",
      "epoch 136; iter: 0; batch classifier loss: 0.123867; batch adversarial loss: 0.512777\n",
      "epoch 137; iter: 0; batch classifier loss: 0.103628; batch adversarial loss: 0.396191\n",
      "epoch 138; iter: 0; batch classifier loss: 0.112311; batch adversarial loss: 0.442416\n",
      "epoch 139; iter: 0; batch classifier loss: 0.066893; batch adversarial loss: 0.392137\n",
      "epoch 140; iter: 0; batch classifier loss: 0.069033; batch adversarial loss: 0.442380\n",
      "epoch 141; iter: 0; batch classifier loss: 0.086568; batch adversarial loss: 0.471987\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042473; batch adversarial loss: 0.487994\n",
      "epoch 143; iter: 0; batch classifier loss: 0.076585; batch adversarial loss: 0.471166\n",
      "epoch 144; iter: 0; batch classifier loss: 0.059773; batch adversarial loss: 0.460100\n",
      "epoch 145; iter: 0; batch classifier loss: 0.056469; batch adversarial loss: 0.416643\n",
      "epoch 146; iter: 0; batch classifier loss: 0.047651; batch adversarial loss: 0.414230\n",
      "epoch 147; iter: 0; batch classifier loss: 0.099874; batch adversarial loss: 0.429866\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054885; batch adversarial loss: 0.397697\n",
      "epoch 149; iter: 0; batch classifier loss: 0.051840; batch adversarial loss: 0.460773\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028795; batch adversarial loss: 0.408409\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039435; batch adversarial loss: 0.397723\n",
      "epoch 152; iter: 0; batch classifier loss: 0.097280; batch adversarial loss: 0.476079\n",
      "epoch 153; iter: 0; batch classifier loss: 0.033697; batch adversarial loss: 0.447440\n",
      "epoch 154; iter: 0; batch classifier loss: 0.061106; batch adversarial loss: 0.443676\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023111; batch adversarial loss: 0.416921\n",
      "epoch 156; iter: 0; batch classifier loss: 0.052165; batch adversarial loss: 0.422477\n",
      "epoch 157; iter: 0; batch classifier loss: 0.068438; batch adversarial loss: 0.541574\n",
      "epoch 158; iter: 0; batch classifier loss: 0.039743; batch adversarial loss: 0.431422\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018879; batch adversarial loss: 0.426797\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010187; batch adversarial loss: 0.463765\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033272; batch adversarial loss: 0.455672\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036872; batch adversarial loss: 0.516915\n",
      "epoch 163; iter: 0; batch classifier loss: 0.044524; batch adversarial loss: 0.434635\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036030; batch adversarial loss: 0.465638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.032863; batch adversarial loss: 0.476565\n",
      "epoch 166; iter: 0; batch classifier loss: 0.041668; batch adversarial loss: 0.494799\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022585; batch adversarial loss: 0.400219\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018782; batch adversarial loss: 0.436066\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020681; batch adversarial loss: 0.481113\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023595; batch adversarial loss: 0.488154\n",
      "epoch 171; iter: 0; batch classifier loss: 0.035384; batch adversarial loss: 0.473070\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012568; batch adversarial loss: 0.453150\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025142; batch adversarial loss: 0.398739\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025679; batch adversarial loss: 0.483815\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041998; batch adversarial loss: 0.391883\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027404; batch adversarial loss: 0.426297\n",
      "epoch 177; iter: 0; batch classifier loss: 0.045354; batch adversarial loss: 0.465831\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022731; batch adversarial loss: 0.567610\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024245; batch adversarial loss: 0.378328\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049743; batch adversarial loss: 0.421342\n",
      "epoch 181; iter: 0; batch classifier loss: 0.040344; batch adversarial loss: 0.482715\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012520; batch adversarial loss: 0.572763\n",
      "epoch 183; iter: 0; batch classifier loss: 0.035244; batch adversarial loss: 0.476450\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032333; batch adversarial loss: 0.422117\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028761; batch adversarial loss: 0.500455\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029324; batch adversarial loss: 0.424643\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017754; batch adversarial loss: 0.451738\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031343; batch adversarial loss: 0.468977\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017210; batch adversarial loss: 0.517102\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018177; batch adversarial loss: 0.453482\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030684; batch adversarial loss: 0.459363\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017767; batch adversarial loss: 0.484053\n",
      "epoch 193; iter: 0; batch classifier loss: 0.044797; batch adversarial loss: 0.521257\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027157; batch adversarial loss: 0.429366\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016577; batch adversarial loss: 0.479169\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027135; batch adversarial loss: 0.438305\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026628; batch adversarial loss: 0.514927\n",
      "epoch 198; iter: 0; batch classifier loss: 0.036668; batch adversarial loss: 0.393513\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007351; batch adversarial loss: 0.507466\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672947; batch adversarial loss: 0.631092\n",
      "epoch 1; iter: 0; batch classifier loss: 0.457986; batch adversarial loss: 0.624828\n",
      "epoch 2; iter: 0; batch classifier loss: 0.483915; batch adversarial loss: 0.598239\n",
      "epoch 3; iter: 0; batch classifier loss: 0.411045; batch adversarial loss: 0.623217\n",
      "epoch 4; iter: 0; batch classifier loss: 0.316422; batch adversarial loss: 0.610702\n",
      "epoch 5; iter: 0; batch classifier loss: 0.332959; batch adversarial loss: 0.541889\n",
      "epoch 6; iter: 0; batch classifier loss: 0.330000; batch adversarial loss: 0.589507\n",
      "epoch 7; iter: 0; batch classifier loss: 0.401956; batch adversarial loss: 0.532855\n",
      "epoch 8; iter: 0; batch classifier loss: 0.295347; batch adversarial loss: 0.598341\n",
      "epoch 9; iter: 0; batch classifier loss: 0.295942; batch adversarial loss: 0.513631\n",
      "epoch 10; iter: 0; batch classifier loss: 0.267743; batch adversarial loss: 0.490910\n",
      "epoch 11; iter: 0; batch classifier loss: 0.190709; batch adversarial loss: 0.511846\n",
      "epoch 12; iter: 0; batch classifier loss: 0.244178; batch adversarial loss: 0.551639\n",
      "epoch 13; iter: 0; batch classifier loss: 0.278817; batch adversarial loss: 0.504815\n",
      "epoch 14; iter: 0; batch classifier loss: 0.180888; batch adversarial loss: 0.564458\n",
      "epoch 15; iter: 0; batch classifier loss: 0.273974; batch adversarial loss: 0.501778\n",
      "epoch 16; iter: 0; batch classifier loss: 0.207168; batch adversarial loss: 0.537268\n",
      "epoch 17; iter: 0; batch classifier loss: 0.142680; batch adversarial loss: 0.460247\n",
      "epoch 18; iter: 0; batch classifier loss: 0.204045; batch adversarial loss: 0.476585\n",
      "epoch 19; iter: 0; batch classifier loss: 0.155036; batch adversarial loss: 0.511213\n",
      "epoch 20; iter: 0; batch classifier loss: 0.218292; batch adversarial loss: 0.467236\n",
      "epoch 21; iter: 0; batch classifier loss: 0.179793; batch adversarial loss: 0.469232\n",
      "epoch 22; iter: 0; batch classifier loss: 0.191412; batch adversarial loss: 0.433998\n",
      "epoch 23; iter: 0; batch classifier loss: 0.183821; batch adversarial loss: 0.530972\n",
      "epoch 24; iter: 0; batch classifier loss: 0.170442; batch adversarial loss: 0.453265\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174717; batch adversarial loss: 0.466489\n",
      "epoch 26; iter: 0; batch classifier loss: 0.161666; batch adversarial loss: 0.504133\n",
      "epoch 27; iter: 0; batch classifier loss: 0.134538; batch adversarial loss: 0.432960\n",
      "epoch 28; iter: 0; batch classifier loss: 0.191209; batch adversarial loss: 0.467083\n",
      "epoch 29; iter: 0; batch classifier loss: 0.140259; batch adversarial loss: 0.512398\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144817; batch adversarial loss: 0.486335\n",
      "epoch 31; iter: 0; batch classifier loss: 0.095794; batch adversarial loss: 0.461793\n",
      "epoch 32; iter: 0; batch classifier loss: 0.166548; batch adversarial loss: 0.481727\n",
      "epoch 33; iter: 0; batch classifier loss: 0.156010; batch adversarial loss: 0.498708\n",
      "epoch 34; iter: 0; batch classifier loss: 0.123672; batch adversarial loss: 0.435830\n",
      "epoch 35; iter: 0; batch classifier loss: 0.121640; batch adversarial loss: 0.487850\n",
      "epoch 36; iter: 0; batch classifier loss: 0.082532; batch adversarial loss: 0.552284\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132172; batch adversarial loss: 0.459779\n",
      "epoch 38; iter: 0; batch classifier loss: 0.144353; batch adversarial loss: 0.581546\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131949; batch adversarial loss: 0.464141\n",
      "epoch 40; iter: 0; batch classifier loss: 0.113941; batch adversarial loss: 0.519224\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106803; batch adversarial loss: 0.373933\n",
      "epoch 42; iter: 0; batch classifier loss: 0.157055; batch adversarial loss: 0.414624\n",
      "epoch 43; iter: 0; batch classifier loss: 0.098721; batch adversarial loss: 0.572436\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098576; batch adversarial loss: 0.511093\n",
      "epoch 45; iter: 0; batch classifier loss: 0.118727; batch adversarial loss: 0.591532\n",
      "epoch 46; iter: 0; batch classifier loss: 0.154272; batch adversarial loss: 0.437804\n",
      "epoch 47; iter: 0; batch classifier loss: 0.123227; batch adversarial loss: 0.499202\n",
      "epoch 48; iter: 0; batch classifier loss: 0.142154; batch adversarial loss: 0.406640\n",
      "epoch 49; iter: 0; batch classifier loss: 0.158900; batch adversarial loss: 0.519101\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094233; batch adversarial loss: 0.436398\n",
      "epoch 51; iter: 0; batch classifier loss: 0.144363; batch adversarial loss: 0.483222\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111079; batch adversarial loss: 0.411816\n",
      "epoch 53; iter: 0; batch classifier loss: 0.163775; batch adversarial loss: 0.432074\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103982; batch adversarial loss: 0.497270\n",
      "epoch 55; iter: 0; batch classifier loss: 0.068327; batch adversarial loss: 0.487273\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099700; batch adversarial loss: 0.523598\n",
      "epoch 57; iter: 0; batch classifier loss: 0.106850; batch adversarial loss: 0.442188\n",
      "epoch 58; iter: 0; batch classifier loss: 0.109013; batch adversarial loss: 0.412254\n",
      "epoch 59; iter: 0; batch classifier loss: 0.122405; batch adversarial loss: 0.460067\n",
      "epoch 60; iter: 0; batch classifier loss: 0.130446; batch adversarial loss: 0.449347\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113922; batch adversarial loss: 0.541479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.060010; batch adversarial loss: 0.515324\n",
      "epoch 63; iter: 0; batch classifier loss: 0.083931; batch adversarial loss: 0.457610\n",
      "epoch 64; iter: 0; batch classifier loss: 0.099552; batch adversarial loss: 0.567065\n",
      "epoch 65; iter: 0; batch classifier loss: 0.099508; batch adversarial loss: 0.495837\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088516; batch adversarial loss: 0.362701\n",
      "epoch 67; iter: 0; batch classifier loss: 0.135610; batch adversarial loss: 0.392894\n",
      "epoch 68; iter: 0; batch classifier loss: 0.097117; batch adversarial loss: 0.436104\n",
      "epoch 69; iter: 0; batch classifier loss: 0.195998; batch adversarial loss: 0.562174\n",
      "epoch 70; iter: 0; batch classifier loss: 0.110411; batch adversarial loss: 0.533681\n",
      "epoch 71; iter: 0; batch classifier loss: 0.113993; batch adversarial loss: 0.419614\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097263; batch adversarial loss: 0.595597\n",
      "epoch 73; iter: 0; batch classifier loss: 0.096252; batch adversarial loss: 0.486181\n",
      "epoch 74; iter: 0; batch classifier loss: 0.110185; batch adversarial loss: 0.458103\n",
      "epoch 75; iter: 0; batch classifier loss: 0.081524; batch adversarial loss: 0.414113\n",
      "epoch 76; iter: 0; batch classifier loss: 0.124313; batch adversarial loss: 0.429945\n",
      "epoch 77; iter: 0; batch classifier loss: 0.103155; batch adversarial loss: 0.362650\n",
      "epoch 78; iter: 0; batch classifier loss: 0.089046; batch adversarial loss: 0.420994\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071441; batch adversarial loss: 0.661565\n",
      "epoch 80; iter: 0; batch classifier loss: 0.087466; batch adversarial loss: 0.412414\n",
      "epoch 81; iter: 0; batch classifier loss: 0.100009; batch adversarial loss: 0.369816\n",
      "epoch 82; iter: 0; batch classifier loss: 0.064577; batch adversarial loss: 0.524416\n",
      "epoch 83; iter: 0; batch classifier loss: 0.114517; batch adversarial loss: 0.398791\n",
      "epoch 84; iter: 0; batch classifier loss: 0.100379; batch adversarial loss: 0.476575\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055656; batch adversarial loss: 0.435737\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081962; batch adversarial loss: 0.459007\n",
      "epoch 87; iter: 0; batch classifier loss: 0.083225; batch adversarial loss: 0.496283\n",
      "epoch 88; iter: 0; batch classifier loss: 0.043416; batch adversarial loss: 0.385620\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081978; batch adversarial loss: 0.470538\n",
      "epoch 90; iter: 0; batch classifier loss: 0.107662; batch adversarial loss: 0.428646\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045907; batch adversarial loss: 0.546633\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071881; batch adversarial loss: 0.414647\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064310; batch adversarial loss: 0.567175\n",
      "epoch 94; iter: 0; batch classifier loss: 0.032933; batch adversarial loss: 0.441307\n",
      "epoch 95; iter: 0; batch classifier loss: 0.072962; batch adversarial loss: 0.483419\n",
      "epoch 96; iter: 0; batch classifier loss: 0.077119; batch adversarial loss: 0.470814\n",
      "epoch 97; iter: 0; batch classifier loss: 0.027877; batch adversarial loss: 0.472696\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052750; batch adversarial loss: 0.485495\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061617; batch adversarial loss: 0.465050\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038496; batch adversarial loss: 0.489916\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068450; batch adversarial loss: 0.446510\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043981; batch adversarial loss: 0.378932\n",
      "epoch 103; iter: 0; batch classifier loss: 0.067553; batch adversarial loss: 0.587473\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027547; batch adversarial loss: 0.484080\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049050; batch adversarial loss: 0.504562\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039769; batch adversarial loss: 0.427715\n",
      "epoch 107; iter: 0; batch classifier loss: 0.042597; batch adversarial loss: 0.441184\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039672; batch adversarial loss: 0.539164\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032591; batch adversarial loss: 0.498232\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050329; batch adversarial loss: 0.450620\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050560; batch adversarial loss: 0.510447\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036365; batch adversarial loss: 0.472061\n",
      "epoch 113; iter: 0; batch classifier loss: 0.036445; batch adversarial loss: 0.446877\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029641; batch adversarial loss: 0.425498\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059041; batch adversarial loss: 0.444291\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055309; batch adversarial loss: 0.431653\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039125; batch adversarial loss: 0.515426\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052367; batch adversarial loss: 0.492232\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050054; batch adversarial loss: 0.481534\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050032; batch adversarial loss: 0.363789\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040624; batch adversarial loss: 0.514325\n",
      "epoch 122; iter: 0; batch classifier loss: 0.087003; batch adversarial loss: 0.425856\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038725; batch adversarial loss: 0.517200\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024157; batch adversarial loss: 0.490517\n",
      "epoch 125; iter: 0; batch classifier loss: 0.011569; batch adversarial loss: 0.561057\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032687; batch adversarial loss: 0.356828\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032974; batch adversarial loss: 0.412764\n",
      "epoch 128; iter: 0; batch classifier loss: 0.048772; batch adversarial loss: 0.459324\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035045; batch adversarial loss: 0.485793\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026226; batch adversarial loss: 0.405252\n",
      "epoch 131; iter: 0; batch classifier loss: 0.109880; batch adversarial loss: 0.549800\n",
      "epoch 132; iter: 0; batch classifier loss: 0.072744; batch adversarial loss: 0.405300\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024127; batch adversarial loss: 0.445821\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040388; batch adversarial loss: 0.414960\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033508; batch adversarial loss: 0.476599\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035936; batch adversarial loss: 0.545335\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027840; batch adversarial loss: 0.391780\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028033; batch adversarial loss: 0.406907\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028945; batch adversarial loss: 0.390252\n",
      "epoch 140; iter: 0; batch classifier loss: 0.054593; batch adversarial loss: 0.378010\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031841; batch adversarial loss: 0.506331\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030830; batch adversarial loss: 0.438469\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030385; batch adversarial loss: 0.486381\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033517; batch adversarial loss: 0.485064\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016472; batch adversarial loss: 0.474848\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023580; batch adversarial loss: 0.426762\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019772; batch adversarial loss: 0.572168\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045687; batch adversarial loss: 0.465522\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028285; batch adversarial loss: 0.430936\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023453; batch adversarial loss: 0.458220\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043789; batch adversarial loss: 0.417694\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019871; batch adversarial loss: 0.454553\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038689; batch adversarial loss: 0.480932\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032724; batch adversarial loss: 0.472081\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017321; batch adversarial loss: 0.431970\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031594; batch adversarial loss: 0.424494\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014003; batch adversarial loss: 0.412534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.021640; batch adversarial loss: 0.433858\n",
      "epoch 159; iter: 0; batch classifier loss: 0.056969; batch adversarial loss: 0.493541\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013567; batch adversarial loss: 0.523864\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029048; batch adversarial loss: 0.554592\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034781; batch adversarial loss: 0.483124\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040407; batch adversarial loss: 0.405430\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014609; batch adversarial loss: 0.460495\n",
      "epoch 165; iter: 0; batch classifier loss: 0.039409; batch adversarial loss: 0.448050\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015415; batch adversarial loss: 0.436500\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011596; batch adversarial loss: 0.481597\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018306; batch adversarial loss: 0.542226\n",
      "epoch 169; iter: 0; batch classifier loss: 0.039477; batch adversarial loss: 0.504300\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018441; batch adversarial loss: 0.452813\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018037; batch adversarial loss: 0.583629\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015815; batch adversarial loss: 0.491432\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026949; batch adversarial loss: 0.504463\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012123; batch adversarial loss: 0.489664\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035013; batch adversarial loss: 0.472891\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009139; batch adversarial loss: 0.428376\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028444; batch adversarial loss: 0.526866\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013945; batch adversarial loss: 0.342873\n",
      "epoch 179; iter: 0; batch classifier loss: 0.046441; batch adversarial loss: 0.437488\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031630; batch adversarial loss: 0.463788\n",
      "epoch 181; iter: 0; batch classifier loss: 0.050061; batch adversarial loss: 0.379526\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018452; batch adversarial loss: 0.450047\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008028; batch adversarial loss: 0.480459\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038793; batch adversarial loss: 0.497012\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042801; batch adversarial loss: 0.438818\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007095; batch adversarial loss: 0.480393\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009878; batch adversarial loss: 0.470405\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012854; batch adversarial loss: 0.495950\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004463; batch adversarial loss: 0.521454\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007850; batch adversarial loss: 0.536602\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018013; batch adversarial loss: 0.588268\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026708; batch adversarial loss: 0.509826\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019703; batch adversarial loss: 0.405429\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028037; batch adversarial loss: 0.464938\n",
      "epoch 195; iter: 0; batch classifier loss: 0.007804; batch adversarial loss: 0.462516\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004162; batch adversarial loss: 0.505838\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015206; batch adversarial loss: 0.524972\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005634; batch adversarial loss: 0.439683\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012924; batch adversarial loss: 0.452385\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694615; batch adversarial loss: 0.705927\n",
      "epoch 1; iter: 0; batch classifier loss: 0.493159; batch adversarial loss: 0.700476\n",
      "epoch 2; iter: 0; batch classifier loss: 0.399200; batch adversarial loss: 0.678712\n",
      "epoch 3; iter: 0; batch classifier loss: 0.375870; batch adversarial loss: 0.629954\n",
      "epoch 4; iter: 0; batch classifier loss: 0.306634; batch adversarial loss: 0.616840\n",
      "epoch 5; iter: 0; batch classifier loss: 0.315552; batch adversarial loss: 0.558887\n",
      "epoch 6; iter: 0; batch classifier loss: 0.359779; batch adversarial loss: 0.532748\n",
      "epoch 7; iter: 0; batch classifier loss: 0.262789; batch adversarial loss: 0.539152\n",
      "epoch 8; iter: 0; batch classifier loss: 0.282615; batch adversarial loss: 0.483605\n",
      "epoch 9; iter: 0; batch classifier loss: 0.311549; batch adversarial loss: 0.440776\n",
      "epoch 10; iter: 0; batch classifier loss: 0.228610; batch adversarial loss: 0.490675\n",
      "epoch 11; iter: 0; batch classifier loss: 0.159356; batch adversarial loss: 0.492392\n",
      "epoch 12; iter: 0; batch classifier loss: 0.248331; batch adversarial loss: 0.426331\n",
      "epoch 13; iter: 0; batch classifier loss: 0.177079; batch adversarial loss: 0.436662\n",
      "epoch 14; iter: 0; batch classifier loss: 0.182312; batch adversarial loss: 0.458804\n",
      "epoch 15; iter: 0; batch classifier loss: 0.183840; batch adversarial loss: 0.444172\n",
      "epoch 16; iter: 0; batch classifier loss: 0.121051; batch adversarial loss: 0.425779\n",
      "epoch 17; iter: 0; batch classifier loss: 0.161774; batch adversarial loss: 0.471467\n",
      "epoch 18; iter: 0; batch classifier loss: 0.220632; batch adversarial loss: 0.557355\n",
      "epoch 19; iter: 0; batch classifier loss: 0.135459; batch adversarial loss: 0.513442\n",
      "epoch 20; iter: 0; batch classifier loss: 0.101411; batch adversarial loss: 0.459856\n",
      "epoch 21; iter: 0; batch classifier loss: 0.098015; batch adversarial loss: 0.430080\n",
      "epoch 22; iter: 0; batch classifier loss: 0.105959; batch adversarial loss: 0.539004\n",
      "epoch 23; iter: 0; batch classifier loss: 0.147316; batch adversarial loss: 0.448756\n",
      "epoch 24; iter: 0; batch classifier loss: 0.122988; batch adversarial loss: 0.474593\n",
      "epoch 25; iter: 0; batch classifier loss: 0.093314; batch adversarial loss: 0.473122\n",
      "epoch 26; iter: 0; batch classifier loss: 0.130550; batch adversarial loss: 0.443296\n",
      "epoch 27; iter: 0; batch classifier loss: 0.120611; batch adversarial loss: 0.420778\n",
      "epoch 28; iter: 0; batch classifier loss: 0.080966; batch adversarial loss: 0.389016\n",
      "epoch 29; iter: 0; batch classifier loss: 0.145096; batch adversarial loss: 0.481660\n",
      "epoch 30; iter: 0; batch classifier loss: 0.111774; batch adversarial loss: 0.424544\n",
      "epoch 31; iter: 0; batch classifier loss: 0.087650; batch adversarial loss: 0.410210\n",
      "epoch 32; iter: 0; batch classifier loss: 0.102446; batch adversarial loss: 0.402524\n",
      "epoch 33; iter: 0; batch classifier loss: 0.115878; batch adversarial loss: 0.421162\n",
      "epoch 34; iter: 0; batch classifier loss: 0.119371; batch adversarial loss: 0.390979\n",
      "epoch 35; iter: 0; batch classifier loss: 0.149156; batch adversarial loss: 0.491095\n",
      "epoch 36; iter: 0; batch classifier loss: 0.095973; batch adversarial loss: 0.413625\n",
      "epoch 37; iter: 0; batch classifier loss: 0.109089; batch adversarial loss: 0.394932\n",
      "epoch 38; iter: 0; batch classifier loss: 0.071598; batch adversarial loss: 0.481330\n",
      "epoch 39; iter: 0; batch classifier loss: 0.127272; batch adversarial loss: 0.415109\n",
      "epoch 40; iter: 0; batch classifier loss: 0.145486; batch adversarial loss: 0.394873\n",
      "epoch 41; iter: 0; batch classifier loss: 0.103930; batch adversarial loss: 0.365075\n",
      "epoch 42; iter: 0; batch classifier loss: 0.121527; batch adversarial loss: 0.423264\n",
      "epoch 43; iter: 0; batch classifier loss: 0.086533; batch adversarial loss: 0.365606\n",
      "epoch 44; iter: 0; batch classifier loss: 0.140464; batch adversarial loss: 0.434036\n",
      "epoch 45; iter: 0; batch classifier loss: 0.076312; batch adversarial loss: 0.439110\n",
      "epoch 46; iter: 0; batch classifier loss: 0.062342; batch adversarial loss: 0.426094\n",
      "epoch 47; iter: 0; batch classifier loss: 0.077276; batch adversarial loss: 0.358162\n",
      "epoch 48; iter: 0; batch classifier loss: 0.128550; batch adversarial loss: 0.391730\n",
      "epoch 49; iter: 0; batch classifier loss: 0.078149; batch adversarial loss: 0.448440\n",
      "epoch 50; iter: 0; batch classifier loss: 0.066468; batch adversarial loss: 0.434335\n",
      "epoch 51; iter: 0; batch classifier loss: 0.079048; batch adversarial loss: 0.413152\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100394; batch adversarial loss: 0.430424\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094775; batch adversarial loss: 0.386773\n",
      "epoch 54; iter: 0; batch classifier loss: 0.085959; batch adversarial loss: 0.386852\n",
      "epoch 55; iter: 0; batch classifier loss: 0.058022; batch adversarial loss: 0.356847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.112955; batch adversarial loss: 0.419020\n",
      "epoch 57; iter: 0; batch classifier loss: 0.071467; batch adversarial loss: 0.420018\n",
      "epoch 58; iter: 0; batch classifier loss: 0.092403; batch adversarial loss: 0.446156\n",
      "epoch 59; iter: 0; batch classifier loss: 0.071873; batch adversarial loss: 0.419357\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081332; batch adversarial loss: 0.479732\n",
      "epoch 61; iter: 0; batch classifier loss: 0.079322; batch adversarial loss: 0.517589\n",
      "epoch 62; iter: 0; batch classifier loss: 0.051126; batch adversarial loss: 0.433600\n",
      "epoch 63; iter: 0; batch classifier loss: 0.080089; batch adversarial loss: 0.428821\n",
      "epoch 64; iter: 0; batch classifier loss: 0.065677; batch adversarial loss: 0.460908\n",
      "epoch 65; iter: 0; batch classifier loss: 0.073441; batch adversarial loss: 0.380009\n",
      "epoch 66; iter: 0; batch classifier loss: 0.065312; batch adversarial loss: 0.508765\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069012; batch adversarial loss: 0.386632\n",
      "epoch 68; iter: 0; batch classifier loss: 0.036132; batch adversarial loss: 0.412080\n",
      "epoch 69; iter: 0; batch classifier loss: 0.043275; batch adversarial loss: 0.419038\n",
      "epoch 70; iter: 0; batch classifier loss: 0.041500; batch adversarial loss: 0.355617\n",
      "epoch 71; iter: 0; batch classifier loss: 0.081999; batch adversarial loss: 0.483162\n",
      "epoch 72; iter: 0; batch classifier loss: 0.052355; batch adversarial loss: 0.469848\n",
      "epoch 73; iter: 0; batch classifier loss: 0.059362; batch adversarial loss: 0.412706\n",
      "epoch 74; iter: 0; batch classifier loss: 0.064622; batch adversarial loss: 0.445835\n",
      "epoch 75; iter: 0; batch classifier loss: 0.056772; batch adversarial loss: 0.418452\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064957; batch adversarial loss: 0.394578\n",
      "epoch 77; iter: 0; batch classifier loss: 0.041618; batch adversarial loss: 0.376575\n",
      "epoch 78; iter: 0; batch classifier loss: 0.077697; batch adversarial loss: 0.401836\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070279; batch adversarial loss: 0.429815\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060305; batch adversarial loss: 0.364785\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067656; batch adversarial loss: 0.447541\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053012; batch adversarial loss: 0.469522\n",
      "epoch 83; iter: 0; batch classifier loss: 0.034306; batch adversarial loss: 0.442720\n",
      "epoch 84; iter: 0; batch classifier loss: 0.073267; batch adversarial loss: 0.449229\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075104; batch adversarial loss: 0.456193\n",
      "epoch 86; iter: 0; batch classifier loss: 0.038958; batch adversarial loss: 0.419352\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055339; batch adversarial loss: 0.378688\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076683; batch adversarial loss: 0.441314\n",
      "epoch 89; iter: 0; batch classifier loss: 0.094717; batch adversarial loss: 0.489103\n",
      "epoch 90; iter: 0; batch classifier loss: 0.085313; batch adversarial loss: 0.333390\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067259; batch adversarial loss: 0.330206\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057768; batch adversarial loss: 0.498238\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050054; batch adversarial loss: 0.438038\n",
      "epoch 94; iter: 0; batch classifier loss: 0.064930; batch adversarial loss: 0.536754\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060871; batch adversarial loss: 0.412622\n",
      "epoch 96; iter: 0; batch classifier loss: 0.033825; batch adversarial loss: 0.418998\n",
      "epoch 97; iter: 0; batch classifier loss: 0.019195; batch adversarial loss: 0.423408\n",
      "epoch 98; iter: 0; batch classifier loss: 0.069602; batch adversarial loss: 0.453316\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057497; batch adversarial loss: 0.398899\n",
      "epoch 100; iter: 0; batch classifier loss: 0.016624; batch adversarial loss: 0.390641\n",
      "epoch 101; iter: 0; batch classifier loss: 0.034091; batch adversarial loss: 0.513718\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047820; batch adversarial loss: 0.397458\n",
      "epoch 103; iter: 0; batch classifier loss: 0.027506; batch adversarial loss: 0.478259\n",
      "epoch 104; iter: 0; batch classifier loss: 0.049097; batch adversarial loss: 0.389369\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029152; batch adversarial loss: 0.455724\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030524; batch adversarial loss: 0.359754\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024225; batch adversarial loss: 0.558837\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040879; batch adversarial loss: 0.493464\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050433; batch adversarial loss: 0.468320\n",
      "epoch 110; iter: 0; batch classifier loss: 0.020138; batch adversarial loss: 0.487017\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029313; batch adversarial loss: 0.569254\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037338; batch adversarial loss: 0.418238\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033768; batch adversarial loss: 0.414060\n",
      "epoch 114; iter: 0; batch classifier loss: 0.012404; batch adversarial loss: 0.468358\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027117; batch adversarial loss: 0.548186\n",
      "epoch 116; iter: 0; batch classifier loss: 0.017408; batch adversarial loss: 0.457491\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032714; batch adversarial loss: 0.477065\n",
      "epoch 118; iter: 0; batch classifier loss: 0.019275; batch adversarial loss: 0.497826\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026728; batch adversarial loss: 0.472618\n",
      "epoch 120; iter: 0; batch classifier loss: 0.026952; batch adversarial loss: 0.487509\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041182; batch adversarial loss: 0.513645\n",
      "epoch 122; iter: 0; batch classifier loss: 0.054172; batch adversarial loss: 0.488589\n",
      "epoch 123; iter: 0; batch classifier loss: 0.012845; batch adversarial loss: 0.495429\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067985; batch adversarial loss: 0.470900\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018345; batch adversarial loss: 0.439413\n",
      "epoch 126; iter: 0; batch classifier loss: 0.065519; batch adversarial loss: 0.545596\n",
      "epoch 127; iter: 0; batch classifier loss: 0.077065; batch adversarial loss: 0.698117\n",
      "epoch 128; iter: 0; batch classifier loss: 0.072258; batch adversarial loss: 0.589461\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056979; batch adversarial loss: 0.524411\n",
      "epoch 130; iter: 0; batch classifier loss: 0.099550; batch adversarial loss: 0.561644\n",
      "epoch 131; iter: 0; batch classifier loss: 0.101359; batch adversarial loss: 0.591635\n",
      "epoch 132; iter: 0; batch classifier loss: 0.061487; batch adversarial loss: 0.460944\n",
      "epoch 133; iter: 0; batch classifier loss: 0.133696; batch adversarial loss: 0.588427\n",
      "epoch 134; iter: 0; batch classifier loss: 0.130759; batch adversarial loss: 0.650671\n",
      "epoch 135; iter: 0; batch classifier loss: 0.178411; batch adversarial loss: 0.828015\n",
      "epoch 136; iter: 0; batch classifier loss: 0.123970; batch adversarial loss: 0.662447\n",
      "epoch 137; iter: 0; batch classifier loss: 0.133428; batch adversarial loss: 0.615388\n",
      "epoch 138; iter: 0; batch classifier loss: 0.115816; batch adversarial loss: 0.696429\n",
      "epoch 139; iter: 0; batch classifier loss: 0.119921; batch adversarial loss: 0.529719\n",
      "epoch 140; iter: 0; batch classifier loss: 0.111768; batch adversarial loss: 0.578526\n",
      "epoch 141; iter: 0; batch classifier loss: 0.013039; batch adversarial loss: 0.358329\n",
      "epoch 142; iter: 0; batch classifier loss: 0.163308; batch adversarial loss: 0.658081\n",
      "epoch 143; iter: 0; batch classifier loss: 0.134911; batch adversarial loss: 0.652308\n",
      "epoch 144; iter: 0; batch classifier loss: 0.168563; batch adversarial loss: 0.656518\n",
      "epoch 145; iter: 0; batch classifier loss: 0.116206; batch adversarial loss: 0.541343\n",
      "epoch 146; iter: 0; batch classifier loss: 0.156759; batch adversarial loss: 0.632960\n",
      "epoch 147; iter: 0; batch classifier loss: 0.191178; batch adversarial loss: 0.642464\n",
      "epoch 148; iter: 0; batch classifier loss: 0.128365; batch adversarial loss: 0.579804\n",
      "epoch 149; iter: 0; batch classifier loss: 0.198396; batch adversarial loss: 0.620355\n",
      "epoch 150; iter: 0; batch classifier loss: 0.116256; batch adversarial loss: 0.551792\n",
      "epoch 151; iter: 0; batch classifier loss: 0.131339; batch adversarial loss: 0.615218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.134731; batch adversarial loss: 0.548273\n",
      "epoch 153; iter: 0; batch classifier loss: 0.190438; batch adversarial loss: 0.605332\n",
      "epoch 154; iter: 0; batch classifier loss: 0.109195; batch adversarial loss: 0.537434\n",
      "epoch 155; iter: 0; batch classifier loss: 0.137169; batch adversarial loss: 0.534647\n",
      "epoch 156; iter: 0; batch classifier loss: 0.145545; batch adversarial loss: 0.533888\n",
      "epoch 157; iter: 0; batch classifier loss: 0.110939; batch adversarial loss: 0.420597\n",
      "epoch 158; iter: 0; batch classifier loss: 0.150997; batch adversarial loss: 0.561509\n",
      "epoch 159; iter: 0; batch classifier loss: 0.147203; batch adversarial loss: 0.549073\n",
      "epoch 160; iter: 0; batch classifier loss: 0.068251; batch adversarial loss: 0.410023\n",
      "epoch 161; iter: 0; batch classifier loss: 0.150682; batch adversarial loss: 0.513026\n",
      "epoch 162; iter: 0; batch classifier loss: 0.144008; batch adversarial loss: 0.512606\n",
      "epoch 163; iter: 0; batch classifier loss: 0.083849; batch adversarial loss: 0.381860\n",
      "epoch 164; iter: 0; batch classifier loss: 0.104885; batch adversarial loss: 0.505756\n",
      "epoch 165; iter: 0; batch classifier loss: 0.097814; batch adversarial loss: 0.506107\n",
      "epoch 166; iter: 0; batch classifier loss: 0.099883; batch adversarial loss: 0.432106\n",
      "epoch 167; iter: 0; batch classifier loss: 0.091752; batch adversarial loss: 0.427679\n",
      "epoch 168; iter: 0; batch classifier loss: 0.181500; batch adversarial loss: 0.499889\n",
      "epoch 169; iter: 0; batch classifier loss: 0.068310; batch adversarial loss: 0.447284\n",
      "epoch 170; iter: 0; batch classifier loss: 0.084003; batch adversarial loss: 0.517898\n",
      "epoch 171; iter: 0; batch classifier loss: 0.067788; batch adversarial loss: 0.442591\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030260; batch adversarial loss: 0.507696\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036839; batch adversarial loss: 0.490364\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019136; batch adversarial loss: 0.418756\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016678; batch adversarial loss: 0.512345\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026238; batch adversarial loss: 0.350724\n",
      "epoch 177; iter: 0; batch classifier loss: 0.044586; batch adversarial loss: 0.487644\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031534; batch adversarial loss: 0.383209\n",
      "epoch 179; iter: 0; batch classifier loss: 0.050362; batch adversarial loss: 0.430171\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025801; batch adversarial loss: 0.371491\n",
      "epoch 181; iter: 0; batch classifier loss: 0.043798; batch adversarial loss: 0.503989\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017774; batch adversarial loss: 0.516426\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036626; batch adversarial loss: 0.404363\n",
      "epoch 184; iter: 0; batch classifier loss: 0.066503; batch adversarial loss: 0.505215\n",
      "epoch 185; iter: 0; batch classifier loss: 0.047522; batch adversarial loss: 0.469803\n",
      "epoch 186; iter: 0; batch classifier loss: 0.057025; batch adversarial loss: 0.473756\n",
      "epoch 187; iter: 0; batch classifier loss: 0.059079; batch adversarial loss: 0.490314\n",
      "epoch 188; iter: 0; batch classifier loss: 0.071638; batch adversarial loss: 0.457225\n",
      "epoch 189; iter: 0; batch classifier loss: 0.047494; batch adversarial loss: 0.426679\n",
      "epoch 190; iter: 0; batch classifier loss: 0.040915; batch adversarial loss: 0.513652\n",
      "epoch 191; iter: 0; batch classifier loss: 0.075092; batch adversarial loss: 0.438233\n",
      "epoch 192; iter: 0; batch classifier loss: 0.078482; batch adversarial loss: 0.396841\n",
      "epoch 193; iter: 0; batch classifier loss: 0.062062; batch adversarial loss: 0.513129\n",
      "epoch 194; iter: 0; batch classifier loss: 0.074563; batch adversarial loss: 0.525758\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036958; batch adversarial loss: 0.554575\n",
      "epoch 196; iter: 0; batch classifier loss: 0.098009; batch adversarial loss: 0.388564\n",
      "epoch 197; iter: 0; batch classifier loss: 0.053416; batch adversarial loss: 0.384775\n",
      "epoch 198; iter: 0; batch classifier loss: 0.067462; batch adversarial loss: 0.425118\n",
      "epoch 199; iter: 0; batch classifier loss: 0.096743; batch adversarial loss: 0.446564\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684645; batch adversarial loss: 0.786382\n",
      "epoch 1; iter: 0; batch classifier loss: 0.538290; batch adversarial loss: 0.761706\n",
      "epoch 2; iter: 0; batch classifier loss: 0.754656; batch adversarial loss: 0.814577\n",
      "epoch 3; iter: 0; batch classifier loss: 0.771011; batch adversarial loss: 0.793698\n",
      "epoch 4; iter: 0; batch classifier loss: 0.676424; batch adversarial loss: 0.653841\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549459; batch adversarial loss: 0.621701\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331023; batch adversarial loss: 0.560025\n",
      "epoch 7; iter: 0; batch classifier loss: 0.353255; batch adversarial loss: 0.519294\n",
      "epoch 8; iter: 0; batch classifier loss: 0.277743; batch adversarial loss: 0.514124\n",
      "epoch 9; iter: 0; batch classifier loss: 0.252159; batch adversarial loss: 0.539392\n",
      "epoch 10; iter: 0; batch classifier loss: 0.263405; batch adversarial loss: 0.471602\n",
      "epoch 11; iter: 0; batch classifier loss: 0.250490; batch adversarial loss: 0.518427\n",
      "epoch 12; iter: 0; batch classifier loss: 0.272487; batch adversarial loss: 0.481480\n",
      "epoch 13; iter: 0; batch classifier loss: 0.250109; batch adversarial loss: 0.518177\n",
      "epoch 14; iter: 0; batch classifier loss: 0.190286; batch adversarial loss: 0.470909\n",
      "epoch 15; iter: 0; batch classifier loss: 0.200218; batch adversarial loss: 0.449101\n",
      "epoch 16; iter: 0; batch classifier loss: 0.240085; batch adversarial loss: 0.477697\n",
      "epoch 17; iter: 0; batch classifier loss: 0.246452; batch adversarial loss: 0.441403\n",
      "epoch 18; iter: 0; batch classifier loss: 0.210787; batch adversarial loss: 0.473953\n",
      "epoch 19; iter: 0; batch classifier loss: 0.178841; batch adversarial loss: 0.376924\n",
      "epoch 20; iter: 0; batch classifier loss: 0.172833; batch adversarial loss: 0.475352\n",
      "epoch 21; iter: 0; batch classifier loss: 0.209490; batch adversarial loss: 0.489077\n",
      "epoch 22; iter: 0; batch classifier loss: 0.144250; batch adversarial loss: 0.572463\n",
      "epoch 23; iter: 0; batch classifier loss: 0.174311; batch adversarial loss: 0.522176\n",
      "epoch 24; iter: 0; batch classifier loss: 0.125685; batch adversarial loss: 0.427098\n",
      "epoch 25; iter: 0; batch classifier loss: 0.098452; batch adversarial loss: 0.580738\n",
      "epoch 26; iter: 0; batch classifier loss: 0.225353; batch adversarial loss: 0.441875\n",
      "epoch 27; iter: 0; batch classifier loss: 0.241531; batch adversarial loss: 0.484804\n",
      "epoch 28; iter: 0; batch classifier loss: 0.123356; batch adversarial loss: 0.495393\n",
      "epoch 29; iter: 0; batch classifier loss: 0.160002; batch adversarial loss: 0.461927\n",
      "epoch 30; iter: 0; batch classifier loss: 0.123835; batch adversarial loss: 0.513300\n",
      "epoch 31; iter: 0; batch classifier loss: 0.155330; batch adversarial loss: 0.556956\n",
      "epoch 32; iter: 0; batch classifier loss: 0.108521; batch adversarial loss: 0.459539\n",
      "epoch 33; iter: 0; batch classifier loss: 0.129670; batch adversarial loss: 0.461170\n",
      "epoch 34; iter: 0; batch classifier loss: 0.123417; batch adversarial loss: 0.483542\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129009; batch adversarial loss: 0.481107\n",
      "epoch 36; iter: 0; batch classifier loss: 0.119929; batch adversarial loss: 0.450787\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111306; batch adversarial loss: 0.416658\n",
      "epoch 38; iter: 0; batch classifier loss: 0.190952; batch adversarial loss: 0.535031\n",
      "epoch 39; iter: 0; batch classifier loss: 0.092101; batch adversarial loss: 0.566596\n",
      "epoch 40; iter: 0; batch classifier loss: 0.084991; batch adversarial loss: 0.444692\n",
      "epoch 41; iter: 0; batch classifier loss: 0.105967; batch adversarial loss: 0.415038\n",
      "epoch 42; iter: 0; batch classifier loss: 0.074914; batch adversarial loss: 0.462379\n",
      "epoch 43; iter: 0; batch classifier loss: 0.134557; batch adversarial loss: 0.503068\n",
      "epoch 44; iter: 0; batch classifier loss: 0.130456; batch adversarial loss: 0.412316\n",
      "epoch 45; iter: 0; batch classifier loss: 0.093244; batch adversarial loss: 0.435264\n",
      "epoch 46; iter: 0; batch classifier loss: 0.090328; batch adversarial loss: 0.543917\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113999; batch adversarial loss: 0.507811\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104049; batch adversarial loss: 0.415944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49; iter: 0; batch classifier loss: 0.105810; batch adversarial loss: 0.527827\n",
      "epoch 50; iter: 0; batch classifier loss: 0.092436; batch adversarial loss: 0.431513\n",
      "epoch 51; iter: 0; batch classifier loss: 0.076688; batch adversarial loss: 0.460626\n",
      "epoch 52; iter: 0; batch classifier loss: 0.065012; batch adversarial loss: 0.506346\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122673; batch adversarial loss: 0.447367\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103949; batch adversarial loss: 0.378815\n",
      "epoch 55; iter: 0; batch classifier loss: 0.128468; batch adversarial loss: 0.479935\n",
      "epoch 56; iter: 0; batch classifier loss: 0.083384; batch adversarial loss: 0.453659\n",
      "epoch 57; iter: 0; batch classifier loss: 0.118072; batch adversarial loss: 0.476822\n",
      "epoch 58; iter: 0; batch classifier loss: 0.109500; batch adversarial loss: 0.384017\n",
      "epoch 59; iter: 0; batch classifier loss: 0.063513; batch adversarial loss: 0.497842\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065878; batch adversarial loss: 0.511892\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093052; batch adversarial loss: 0.613319\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089231; batch adversarial loss: 0.456645\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103139; batch adversarial loss: 0.470653\n",
      "epoch 64; iter: 0; batch classifier loss: 0.108245; batch adversarial loss: 0.455243\n",
      "epoch 65; iter: 0; batch classifier loss: 0.055740; batch adversarial loss: 0.473333\n",
      "epoch 66; iter: 0; batch classifier loss: 0.080317; batch adversarial loss: 0.478015\n",
      "epoch 67; iter: 0; batch classifier loss: 0.120418; batch adversarial loss: 0.375530\n",
      "epoch 68; iter: 0; batch classifier loss: 0.073214; batch adversarial loss: 0.540525\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081632; batch adversarial loss: 0.407300\n",
      "epoch 70; iter: 0; batch classifier loss: 0.099208; batch adversarial loss: 0.480574\n",
      "epoch 71; iter: 0; batch classifier loss: 0.074032; batch adversarial loss: 0.537747\n",
      "epoch 72; iter: 0; batch classifier loss: 0.109052; batch adversarial loss: 0.431191\n",
      "epoch 73; iter: 0; batch classifier loss: 0.110754; batch adversarial loss: 0.483600\n",
      "epoch 74; iter: 0; batch classifier loss: 0.061210; batch adversarial loss: 0.483687\n",
      "epoch 75; iter: 0; batch classifier loss: 0.065339; batch adversarial loss: 0.516546\n",
      "epoch 76; iter: 0; batch classifier loss: 0.101143; batch adversarial loss: 0.419359\n",
      "epoch 77; iter: 0; batch classifier loss: 0.088774; batch adversarial loss: 0.462128\n",
      "epoch 78; iter: 0; batch classifier loss: 0.040696; batch adversarial loss: 0.459799\n",
      "epoch 79; iter: 0; batch classifier loss: 0.112278; batch adversarial loss: 0.400257\n",
      "epoch 80; iter: 0; batch classifier loss: 0.064743; batch adversarial loss: 0.462211\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067339; batch adversarial loss: 0.415735\n",
      "epoch 82; iter: 0; batch classifier loss: 0.087374; batch adversarial loss: 0.433208\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074007; batch adversarial loss: 0.469885\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075558; batch adversarial loss: 0.478555\n",
      "epoch 85; iter: 0; batch classifier loss: 0.120417; batch adversarial loss: 0.436750\n",
      "epoch 86; iter: 0; batch classifier loss: 0.036879; batch adversarial loss: 0.388990\n",
      "epoch 87; iter: 0; batch classifier loss: 0.030498; batch adversarial loss: 0.475856\n",
      "epoch 88; iter: 0; batch classifier loss: 0.053957; batch adversarial loss: 0.459236\n",
      "epoch 89; iter: 0; batch classifier loss: 0.071969; batch adversarial loss: 0.421746\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062545; batch adversarial loss: 0.521177\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056271; batch adversarial loss: 0.487464\n",
      "epoch 92; iter: 0; batch classifier loss: 0.093207; batch adversarial loss: 0.399508\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077719; batch adversarial loss: 0.519107\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043858; batch adversarial loss: 0.468919\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057599; batch adversarial loss: 0.402712\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062662; batch adversarial loss: 0.422003\n",
      "epoch 97; iter: 0; batch classifier loss: 0.070740; batch adversarial loss: 0.438540\n",
      "epoch 98; iter: 0; batch classifier loss: 0.071293; batch adversarial loss: 0.375015\n",
      "epoch 99; iter: 0; batch classifier loss: 0.032757; batch adversarial loss: 0.408773\n",
      "epoch 100; iter: 0; batch classifier loss: 0.029642; batch adversarial loss: 0.523374\n",
      "epoch 101; iter: 0; batch classifier loss: 0.064552; batch adversarial loss: 0.402380\n",
      "epoch 102; iter: 0; batch classifier loss: 0.075799; batch adversarial loss: 0.458871\n",
      "epoch 103; iter: 0; batch classifier loss: 0.078488; batch adversarial loss: 0.424269\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034036; batch adversarial loss: 0.451393\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064298; batch adversarial loss: 0.438343\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055871; batch adversarial loss: 0.444694\n",
      "epoch 107; iter: 0; batch classifier loss: 0.029527; batch adversarial loss: 0.472787\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040601; batch adversarial loss: 0.453209\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037012; batch adversarial loss: 0.345774\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058727; batch adversarial loss: 0.439102\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066874; batch adversarial loss: 0.412785\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044874; batch adversarial loss: 0.427901\n",
      "epoch 113; iter: 0; batch classifier loss: 0.019652; batch adversarial loss: 0.491813\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041340; batch adversarial loss: 0.384864\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031324; batch adversarial loss: 0.479647\n",
      "epoch 116; iter: 0; batch classifier loss: 0.023922; batch adversarial loss: 0.441870\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027719; batch adversarial loss: 0.398158\n",
      "epoch 118; iter: 0; batch classifier loss: 0.078273; batch adversarial loss: 0.406547\n",
      "epoch 119; iter: 0; batch classifier loss: 0.084388; batch adversarial loss: 0.517931\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049662; batch adversarial loss: 0.465158\n",
      "epoch 121; iter: 0; batch classifier loss: 0.074150; batch adversarial loss: 0.494762\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034853; batch adversarial loss: 0.460889\n",
      "epoch 123; iter: 0; batch classifier loss: 0.022371; batch adversarial loss: 0.477255\n",
      "epoch 124; iter: 0; batch classifier loss: 0.015917; batch adversarial loss: 0.416556\n",
      "epoch 125; iter: 0; batch classifier loss: 0.015815; batch adversarial loss: 0.547377\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038285; batch adversarial loss: 0.409581\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019188; batch adversarial loss: 0.501522\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021801; batch adversarial loss: 0.408477\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059730; batch adversarial loss: 0.438344\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040482; batch adversarial loss: 0.489120\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021288; batch adversarial loss: 0.513736\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031527; batch adversarial loss: 0.429445\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052784; batch adversarial loss: 0.510567\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040700; batch adversarial loss: 0.455799\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020112; batch adversarial loss: 0.475071\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018192; batch adversarial loss: 0.541353\n",
      "epoch 137; iter: 0; batch classifier loss: 0.057192; batch adversarial loss: 0.426738\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036402; batch adversarial loss: 0.359595\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022110; batch adversarial loss: 0.364644\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030940; batch adversarial loss: 0.371514\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021551; batch adversarial loss: 0.528905\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032128; batch adversarial loss: 0.451751\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026377; batch adversarial loss: 0.416348\n",
      "epoch 144; iter: 0; batch classifier loss: 0.086954; batch adversarial loss: 0.426894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 145; iter: 0; batch classifier loss: 0.045108; batch adversarial loss: 0.490162\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017481; batch adversarial loss: 0.497931\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014578; batch adversarial loss: 0.432384\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039498; batch adversarial loss: 0.401633\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019256; batch adversarial loss: 0.493031\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025159; batch adversarial loss: 0.486177\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022385; batch adversarial loss: 0.427974\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037730; batch adversarial loss: 0.370502\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027315; batch adversarial loss: 0.437343\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014148; batch adversarial loss: 0.430311\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014868; batch adversarial loss: 0.467016\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021466; batch adversarial loss: 0.441983\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036708; batch adversarial loss: 0.417917\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013853; batch adversarial loss: 0.438317\n",
      "epoch 159; iter: 0; batch classifier loss: 0.009034; batch adversarial loss: 0.441041\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010995; batch adversarial loss: 0.563191\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026865; batch adversarial loss: 0.546854\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026957; batch adversarial loss: 0.457722\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013221; batch adversarial loss: 0.505297\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031533; batch adversarial loss: 0.504021\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038722; batch adversarial loss: 0.481152\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011227; batch adversarial loss: 0.409169\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021994; batch adversarial loss: 0.513406\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029264; batch adversarial loss: 0.443752\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016368; batch adversarial loss: 0.452717\n",
      "epoch 170; iter: 0; batch classifier loss: 0.041363; batch adversarial loss: 0.565071\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011602; batch adversarial loss: 0.461041\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007782; batch adversarial loss: 0.408361\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026510; batch adversarial loss: 0.426536\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010665; batch adversarial loss: 0.432009\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031018; batch adversarial loss: 0.424065\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008719; batch adversarial loss: 0.506398\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024345; batch adversarial loss: 0.316600\n",
      "epoch 178; iter: 0; batch classifier loss: 0.004439; batch adversarial loss: 0.456364\n",
      "epoch 179; iter: 0; batch classifier loss: 0.042406; batch adversarial loss: 0.400115\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024026; batch adversarial loss: 0.481560\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028858; batch adversarial loss: 0.458011\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016158; batch adversarial loss: 0.389378\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024358; batch adversarial loss: 0.495599\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013958; batch adversarial loss: 0.456344\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027347; batch adversarial loss: 0.520145\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007677; batch adversarial loss: 0.507149\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026387; batch adversarial loss: 0.506780\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023073; batch adversarial loss: 0.519675\n",
      "epoch 189; iter: 0; batch classifier loss: 0.048186; batch adversarial loss: 0.551134\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009632; batch adversarial loss: 0.439275\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014103; batch adversarial loss: 0.375535\n",
      "epoch 192; iter: 0; batch classifier loss: 0.044055; batch adversarial loss: 0.424213\n",
      "epoch 193; iter: 0; batch classifier loss: 0.049330; batch adversarial loss: 0.470675\n",
      "epoch 194; iter: 0; batch classifier loss: 0.029493; batch adversarial loss: 0.492457\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017952; batch adversarial loss: 0.400501\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024270; batch adversarial loss: 0.417066\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025927; batch adversarial loss: 0.425463\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011325; batch adversarial loss: 0.387190\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023587; batch adversarial loss: 0.456352\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671056; batch adversarial loss: 0.432076\n",
      "epoch 1; iter: 0; batch classifier loss: 0.419786; batch adversarial loss: 0.539474\n",
      "epoch 2; iter: 0; batch classifier loss: 0.324832; batch adversarial loss: 0.576465\n",
      "epoch 3; iter: 0; batch classifier loss: 0.366160; batch adversarial loss: 0.599060\n",
      "epoch 4; iter: 0; batch classifier loss: 0.368132; batch adversarial loss: 0.600476\n",
      "epoch 5; iter: 0; batch classifier loss: 0.417974; batch adversarial loss: 0.565664\n",
      "epoch 6; iter: 0; batch classifier loss: 0.387872; batch adversarial loss: 0.681958\n",
      "epoch 7; iter: 0; batch classifier loss: 0.342677; batch adversarial loss: 0.627079\n",
      "epoch 8; iter: 0; batch classifier loss: 0.308605; batch adversarial loss: 0.639287\n",
      "epoch 9; iter: 0; batch classifier loss: 0.388731; batch adversarial loss: 0.508854\n",
      "epoch 10; iter: 0; batch classifier loss: 0.418861; batch adversarial loss: 0.511814\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501649; batch adversarial loss: 0.601999\n",
      "epoch 12; iter: 0; batch classifier loss: 0.664051; batch adversarial loss: 0.501018\n",
      "epoch 13; iter: 0; batch classifier loss: 0.508590; batch adversarial loss: 0.504035\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512468; batch adversarial loss: 0.472080\n",
      "epoch 15; iter: 0; batch classifier loss: 0.424837; batch adversarial loss: 0.430321\n",
      "epoch 16; iter: 0; batch classifier loss: 0.324874; batch adversarial loss: 0.493496\n",
      "epoch 17; iter: 0; batch classifier loss: 0.317621; batch adversarial loss: 0.486473\n",
      "epoch 18; iter: 0; batch classifier loss: 0.326489; batch adversarial loss: 0.501449\n",
      "epoch 19; iter: 0; batch classifier loss: 0.271583; batch adversarial loss: 0.516222\n",
      "epoch 20; iter: 0; batch classifier loss: 0.203445; batch adversarial loss: 0.388877\n",
      "epoch 21; iter: 0; batch classifier loss: 0.200116; batch adversarial loss: 0.454908\n",
      "epoch 22; iter: 0; batch classifier loss: 0.138984; batch adversarial loss: 0.450116\n",
      "epoch 23; iter: 0; batch classifier loss: 0.232377; batch adversarial loss: 0.460425\n",
      "epoch 24; iter: 0; batch classifier loss: 0.185404; batch adversarial loss: 0.468992\n",
      "epoch 25; iter: 0; batch classifier loss: 0.210503; batch adversarial loss: 0.405114\n",
      "epoch 26; iter: 0; batch classifier loss: 0.159780; batch adversarial loss: 0.435881\n",
      "epoch 27; iter: 0; batch classifier loss: 0.192725; batch adversarial loss: 0.438855\n",
      "epoch 28; iter: 0; batch classifier loss: 0.159539; batch adversarial loss: 0.551501\n",
      "epoch 29; iter: 0; batch classifier loss: 0.173724; batch adversarial loss: 0.455797\n",
      "epoch 30; iter: 0; batch classifier loss: 0.122928; batch adversarial loss: 0.437575\n",
      "epoch 31; iter: 0; batch classifier loss: 0.182970; batch adversarial loss: 0.419376\n",
      "epoch 32; iter: 0; batch classifier loss: 0.172612; batch adversarial loss: 0.469533\n",
      "epoch 33; iter: 0; batch classifier loss: 0.202386; batch adversarial loss: 0.412515\n",
      "epoch 34; iter: 0; batch classifier loss: 0.128080; batch adversarial loss: 0.473419\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160094; batch adversarial loss: 0.535375\n",
      "epoch 36; iter: 0; batch classifier loss: 0.200837; batch adversarial loss: 0.417526\n",
      "epoch 37; iter: 0; batch classifier loss: 0.178231; batch adversarial loss: 0.366679\n",
      "epoch 38; iter: 0; batch classifier loss: 0.128073; batch adversarial loss: 0.505480\n",
      "epoch 39; iter: 0; batch classifier loss: 0.197297; batch adversarial loss: 0.351564\n",
      "epoch 40; iter: 0; batch classifier loss: 0.221707; batch adversarial loss: 0.482874\n",
      "epoch 41; iter: 0; batch classifier loss: 0.216623; batch adversarial loss: 0.437527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.118529; batch adversarial loss: 0.518751\n",
      "epoch 43; iter: 0; batch classifier loss: 0.219537; batch adversarial loss: 0.456638\n",
      "epoch 44; iter: 0; batch classifier loss: 0.171487; batch adversarial loss: 0.474160\n",
      "epoch 45; iter: 0; batch classifier loss: 0.174195; batch adversarial loss: 0.493823\n",
      "epoch 46; iter: 0; batch classifier loss: 0.258828; batch adversarial loss: 0.359221\n",
      "epoch 47; iter: 0; batch classifier loss: 0.137904; batch adversarial loss: 0.550909\n",
      "epoch 48; iter: 0; batch classifier loss: 0.203368; batch adversarial loss: 0.467117\n",
      "epoch 49; iter: 0; batch classifier loss: 0.197357; batch adversarial loss: 0.544736\n",
      "epoch 50; iter: 0; batch classifier loss: 0.208979; batch adversarial loss: 0.472898\n",
      "epoch 51; iter: 0; batch classifier loss: 0.174995; batch adversarial loss: 0.448748\n",
      "epoch 52; iter: 0; batch classifier loss: 0.189631; batch adversarial loss: 0.412455\n",
      "epoch 53; iter: 0; batch classifier loss: 0.231072; batch adversarial loss: 0.432982\n",
      "epoch 54; iter: 0; batch classifier loss: 0.213642; batch adversarial loss: 0.481915\n",
      "epoch 55; iter: 0; batch classifier loss: 0.221162; batch adversarial loss: 0.424041\n",
      "epoch 56; iter: 0; batch classifier loss: 0.232635; batch adversarial loss: 0.520295\n",
      "epoch 57; iter: 0; batch classifier loss: 0.178841; batch adversarial loss: 0.480760\n",
      "epoch 58; iter: 0; batch classifier loss: 0.260729; batch adversarial loss: 0.445976\n",
      "epoch 59; iter: 0; batch classifier loss: 0.224145; batch adversarial loss: 0.413392\n",
      "epoch 60; iter: 0; batch classifier loss: 0.222061; batch adversarial loss: 0.532475\n",
      "epoch 61; iter: 0; batch classifier loss: 0.240261; batch adversarial loss: 0.470023\n",
      "epoch 62; iter: 0; batch classifier loss: 0.211085; batch adversarial loss: 0.528741\n",
      "epoch 63; iter: 0; batch classifier loss: 0.245730; batch adversarial loss: 0.521256\n",
      "epoch 64; iter: 0; batch classifier loss: 0.232257; batch adversarial loss: 0.495540\n",
      "epoch 65; iter: 0; batch classifier loss: 0.223342; batch adversarial loss: 0.542572\n",
      "epoch 66; iter: 0; batch classifier loss: 0.240225; batch adversarial loss: 0.446866\n",
      "epoch 67; iter: 0; batch classifier loss: 0.244766; batch adversarial loss: 0.459813\n",
      "epoch 68; iter: 0; batch classifier loss: 0.302172; batch adversarial loss: 0.434953\n",
      "epoch 69; iter: 0; batch classifier loss: 0.195170; batch adversarial loss: 0.386490\n",
      "epoch 70; iter: 0; batch classifier loss: 0.095759; batch adversarial loss: 0.445951\n",
      "epoch 71; iter: 0; batch classifier loss: 0.114199; batch adversarial loss: 0.459399\n",
      "epoch 72; iter: 0; batch classifier loss: 0.232679; batch adversarial loss: 0.381673\n",
      "epoch 73; iter: 0; batch classifier loss: 0.292670; batch adversarial loss: 0.460526\n",
      "epoch 74; iter: 0; batch classifier loss: 0.197139; batch adversarial loss: 0.508601\n",
      "epoch 75; iter: 0; batch classifier loss: 0.209189; batch adversarial loss: 0.447245\n",
      "epoch 76; iter: 0; batch classifier loss: 0.248242; batch adversarial loss: 0.459239\n",
      "epoch 77; iter: 0; batch classifier loss: 0.189167; batch adversarial loss: 0.495761\n",
      "epoch 78; iter: 0; batch classifier loss: 0.212960; batch adversarial loss: 0.533117\n",
      "epoch 79; iter: 0; batch classifier loss: 0.223178; batch adversarial loss: 0.459538\n",
      "epoch 80; iter: 0; batch classifier loss: 0.247441; batch adversarial loss: 0.446782\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075229; batch adversarial loss: 0.408739\n",
      "epoch 82; iter: 0; batch classifier loss: 0.079554; batch adversarial loss: 0.566710\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085208; batch adversarial loss: 0.415240\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085895; batch adversarial loss: 0.424492\n",
      "epoch 85; iter: 0; batch classifier loss: 0.116345; batch adversarial loss: 0.390740\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073400; batch adversarial loss: 0.438691\n",
      "epoch 87; iter: 0; batch classifier loss: 0.183325; batch adversarial loss: 0.441302\n",
      "epoch 88; iter: 0; batch classifier loss: 0.247159; batch adversarial loss: 0.517516\n",
      "epoch 89; iter: 0; batch classifier loss: 0.189248; batch adversarial loss: 0.417020\n",
      "epoch 90; iter: 0; batch classifier loss: 0.145452; batch adversarial loss: 0.423955\n",
      "epoch 91; iter: 0; batch classifier loss: 0.250719; batch adversarial loss: 0.445047\n",
      "epoch 92; iter: 0; batch classifier loss: 0.225093; batch adversarial loss: 0.410291\n",
      "epoch 93; iter: 0; batch classifier loss: 0.220966; batch adversarial loss: 0.409586\n",
      "epoch 94; iter: 0; batch classifier loss: 0.214303; batch adversarial loss: 0.436853\n",
      "epoch 95; iter: 0; batch classifier loss: 0.334061; batch adversarial loss: 0.399262\n",
      "epoch 96; iter: 0; batch classifier loss: 0.290620; batch adversarial loss: 0.372246\n",
      "epoch 97; iter: 0; batch classifier loss: 0.222375; batch adversarial loss: 0.444660\n",
      "epoch 98; iter: 0; batch classifier loss: 0.172342; batch adversarial loss: 0.544940\n",
      "epoch 99; iter: 0; batch classifier loss: 0.284580; batch adversarial loss: 0.421282\n",
      "epoch 100; iter: 0; batch classifier loss: 0.217770; batch adversarial loss: 0.385467\n",
      "epoch 101; iter: 0; batch classifier loss: 0.192030; batch adversarial loss: 0.471865\n",
      "epoch 102; iter: 0; batch classifier loss: 0.195689; batch adversarial loss: 0.446267\n",
      "epoch 103; iter: 0; batch classifier loss: 0.205824; batch adversarial loss: 0.470084\n",
      "epoch 104; iter: 0; batch classifier loss: 0.213728; batch adversarial loss: 0.493785\n",
      "epoch 105; iter: 0; batch classifier loss: 0.250189; batch adversarial loss: 0.397253\n",
      "epoch 106; iter: 0; batch classifier loss: 0.192306; batch adversarial loss: 0.518170\n",
      "epoch 107; iter: 0; batch classifier loss: 0.317251; batch adversarial loss: 0.433613\n",
      "epoch 108; iter: 0; batch classifier loss: 0.178941; batch adversarial loss: 0.495675\n",
      "epoch 109; iter: 0; batch classifier loss: 0.191898; batch adversarial loss: 0.410251\n",
      "epoch 110; iter: 0; batch classifier loss: 0.267804; batch adversarial loss: 0.580448\n",
      "epoch 111; iter: 0; batch classifier loss: 0.199971; batch adversarial loss: 0.421920\n",
      "epoch 112; iter: 0; batch classifier loss: 0.249207; batch adversarial loss: 0.482653\n",
      "epoch 113; iter: 0; batch classifier loss: 0.163677; batch adversarial loss: 0.485215\n",
      "epoch 114; iter: 0; batch classifier loss: 0.225500; batch adversarial loss: 0.506978\n",
      "epoch 115; iter: 0; batch classifier loss: 0.219115; batch adversarial loss: 0.519860\n",
      "epoch 116; iter: 0; batch classifier loss: 0.162517; batch adversarial loss: 0.447078\n",
      "epoch 117; iter: 0; batch classifier loss: 0.151279; batch adversarial loss: 0.446170\n",
      "epoch 118; iter: 0; batch classifier loss: 0.149387; batch adversarial loss: 0.433479\n",
      "epoch 119; iter: 0; batch classifier loss: 0.157744; batch adversarial loss: 0.469858\n",
      "epoch 120; iter: 0; batch classifier loss: 0.140720; batch adversarial loss: 0.433685\n",
      "epoch 121; iter: 0; batch classifier loss: 0.185953; batch adversarial loss: 0.563240\n",
      "epoch 122; iter: 0; batch classifier loss: 0.186818; batch adversarial loss: 0.447327\n",
      "epoch 123; iter: 0; batch classifier loss: 0.172653; batch adversarial loss: 0.478989\n",
      "epoch 124; iter: 0; batch classifier loss: 0.187346; batch adversarial loss: 0.509695\n",
      "epoch 125; iter: 0; batch classifier loss: 0.190468; batch adversarial loss: 0.408882\n",
      "epoch 126; iter: 0; batch classifier loss: 0.199123; batch adversarial loss: 0.351069\n",
      "epoch 127; iter: 0; batch classifier loss: 0.165417; batch adversarial loss: 0.421155\n",
      "epoch 128; iter: 0; batch classifier loss: 0.185652; batch adversarial loss: 0.434119\n",
      "epoch 129; iter: 0; batch classifier loss: 0.116100; batch adversarial loss: 0.493970\n",
      "epoch 130; iter: 0; batch classifier loss: 0.172153; batch adversarial loss: 0.415185\n",
      "epoch 131; iter: 0; batch classifier loss: 0.161854; batch adversarial loss: 0.480963\n",
      "epoch 132; iter: 0; batch classifier loss: 0.172737; batch adversarial loss: 0.413752\n",
      "epoch 133; iter: 0; batch classifier loss: 0.101556; batch adversarial loss: 0.374808\n",
      "epoch 134; iter: 0; batch classifier loss: 0.093245; batch adversarial loss: 0.441338\n",
      "epoch 135; iter: 0; batch classifier loss: 0.065771; batch adversarial loss: 0.501782\n",
      "epoch 136; iter: 0; batch classifier loss: 0.121681; batch adversarial loss: 0.366113\n",
      "epoch 137; iter: 0; batch classifier loss: 0.056374; batch adversarial loss: 0.442633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.070245; batch adversarial loss: 0.465846\n",
      "epoch 139; iter: 0; batch classifier loss: 0.072025; batch adversarial loss: 0.465926\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046393; batch adversarial loss: 0.415357\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045240; batch adversarial loss: 0.441846\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045189; batch adversarial loss: 0.572358\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043758; batch adversarial loss: 0.494434\n",
      "epoch 144; iter: 0; batch classifier loss: 0.055612; batch adversarial loss: 0.487638\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025665; batch adversarial loss: 0.502378\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035303; batch adversarial loss: 0.422838\n",
      "epoch 147; iter: 0; batch classifier loss: 0.048385; batch adversarial loss: 0.397055\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030849; batch adversarial loss: 0.495647\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036755; batch adversarial loss: 0.408781\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039817; batch adversarial loss: 0.512696\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016799; batch adversarial loss: 0.489366\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044838; batch adversarial loss: 0.440846\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017445; batch adversarial loss: 0.403336\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046171; batch adversarial loss: 0.431947\n",
      "epoch 155; iter: 0; batch classifier loss: 0.057629; batch adversarial loss: 0.421402\n",
      "epoch 156; iter: 0; batch classifier loss: 0.077763; batch adversarial loss: 0.355347\n",
      "epoch 157; iter: 0; batch classifier loss: 0.051060; batch adversarial loss: 0.460103\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048644; batch adversarial loss: 0.473416\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029885; batch adversarial loss: 0.384600\n",
      "epoch 160; iter: 0; batch classifier loss: 0.051234; batch adversarial loss: 0.351020\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016321; batch adversarial loss: 0.482473\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043574; batch adversarial loss: 0.430223\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017198; batch adversarial loss: 0.406872\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021464; batch adversarial loss: 0.447909\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016338; batch adversarial loss: 0.494721\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022354; batch adversarial loss: 0.414747\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033792; batch adversarial loss: 0.389486\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019215; batch adversarial loss: 0.457247\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024700; batch adversarial loss: 0.510456\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015035; batch adversarial loss: 0.424627\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024975; batch adversarial loss: 0.414952\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031536; batch adversarial loss: 0.484496\n",
      "epoch 173; iter: 0; batch classifier loss: 0.050340; batch adversarial loss: 0.495197\n",
      "epoch 174; iter: 0; batch classifier loss: 0.048314; batch adversarial loss: 0.436064\n",
      "epoch 175; iter: 0; batch classifier loss: 0.065862; batch adversarial loss: 0.482293\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014994; batch adversarial loss: 0.454234\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033475; batch adversarial loss: 0.362109\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033335; batch adversarial loss: 0.457143\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031776; batch adversarial loss: 0.499773\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015866; batch adversarial loss: 0.443921\n",
      "epoch 181; iter: 0; batch classifier loss: 0.031898; batch adversarial loss: 0.401482\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014639; batch adversarial loss: 0.419791\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021893; batch adversarial loss: 0.483238\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035879; batch adversarial loss: 0.452101\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014144; batch adversarial loss: 0.419204\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033604; batch adversarial loss: 0.384351\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036512; batch adversarial loss: 0.460173\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020375; batch adversarial loss: 0.409124\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009108; batch adversarial loss: 0.562929\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019833; batch adversarial loss: 0.349793\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023261; batch adversarial loss: 0.382294\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012351; batch adversarial loss: 0.494212\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006551; batch adversarial loss: 0.463738\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016783; batch adversarial loss: 0.436462\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018861; batch adversarial loss: 0.437515\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005267; batch adversarial loss: 0.407933\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019056; batch adversarial loss: 0.444541\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025785; batch adversarial loss: 0.464493\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009296; batch adversarial loss: 0.513378\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731766; batch adversarial loss: 0.598883\n",
      "epoch 1; iter: 0; batch classifier loss: 0.419917; batch adversarial loss: 0.596669\n",
      "epoch 2; iter: 0; batch classifier loss: 0.375784; batch adversarial loss: 0.588780\n",
      "epoch 3; iter: 0; batch classifier loss: 0.326182; batch adversarial loss: 0.572163\n",
      "epoch 4; iter: 0; batch classifier loss: 0.337882; batch adversarial loss: 0.559018\n",
      "epoch 5; iter: 0; batch classifier loss: 0.239363; batch adversarial loss: 0.555497\n",
      "epoch 6; iter: 0; batch classifier loss: 0.308457; batch adversarial loss: 0.499995\n",
      "epoch 7; iter: 0; batch classifier loss: 0.283098; batch adversarial loss: 0.511514\n",
      "epoch 8; iter: 0; batch classifier loss: 0.236049; batch adversarial loss: 0.488734\n",
      "epoch 9; iter: 0; batch classifier loss: 0.251301; batch adversarial loss: 0.529358\n",
      "epoch 10; iter: 0; batch classifier loss: 0.229987; batch adversarial loss: 0.508025\n",
      "epoch 11; iter: 0; batch classifier loss: 0.266169; batch adversarial loss: 0.501953\n",
      "epoch 12; iter: 0; batch classifier loss: 0.171764; batch adversarial loss: 0.481771\n",
      "epoch 13; iter: 0; batch classifier loss: 0.244234; batch adversarial loss: 0.506160\n",
      "epoch 14; iter: 0; batch classifier loss: 0.316858; batch adversarial loss: 0.563745\n",
      "epoch 15; iter: 0; batch classifier loss: 0.206669; batch adversarial loss: 0.480765\n",
      "epoch 16; iter: 0; batch classifier loss: 0.223167; batch adversarial loss: 0.476310\n",
      "epoch 17; iter: 0; batch classifier loss: 0.242062; batch adversarial loss: 0.451195\n",
      "epoch 18; iter: 0; batch classifier loss: 0.262377; batch adversarial loss: 0.567775\n",
      "epoch 19; iter: 0; batch classifier loss: 0.202916; batch adversarial loss: 0.489708\n",
      "epoch 20; iter: 0; batch classifier loss: 0.313535; batch adversarial loss: 0.560478\n",
      "epoch 21; iter: 0; batch classifier loss: 0.300521; batch adversarial loss: 0.512931\n",
      "epoch 22; iter: 0; batch classifier loss: 0.223189; batch adversarial loss: 0.446376\n",
      "epoch 23; iter: 0; batch classifier loss: 0.398931; batch adversarial loss: 0.465139\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482365; batch adversarial loss: 0.498700\n",
      "epoch 25; iter: 0; batch classifier loss: 0.346387; batch adversarial loss: 0.539635\n",
      "epoch 26; iter: 0; batch classifier loss: 0.253272; batch adversarial loss: 0.432047\n",
      "epoch 27; iter: 0; batch classifier loss: 0.161333; batch adversarial loss: 0.419065\n",
      "epoch 28; iter: 0; batch classifier loss: 0.164458; batch adversarial loss: 0.431368\n",
      "epoch 29; iter: 0; batch classifier loss: 0.138298; batch adversarial loss: 0.475231\n",
      "epoch 30; iter: 0; batch classifier loss: 0.146373; batch adversarial loss: 0.423762\n",
      "epoch 31; iter: 0; batch classifier loss: 0.121894; batch adversarial loss: 0.510949\n",
      "epoch 32; iter: 0; batch classifier loss: 0.112183; batch adversarial loss: 0.453219\n",
      "epoch 33; iter: 0; batch classifier loss: 0.134469; batch adversarial loss: 0.444649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.096687; batch adversarial loss: 0.516517\n",
      "epoch 35; iter: 0; batch classifier loss: 0.089981; batch adversarial loss: 0.511669\n",
      "epoch 36; iter: 0; batch classifier loss: 0.163302; batch adversarial loss: 0.433565\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111236; batch adversarial loss: 0.420399\n",
      "epoch 38; iter: 0; batch classifier loss: 0.095154; batch adversarial loss: 0.414650\n",
      "epoch 39; iter: 0; batch classifier loss: 0.084551; batch adversarial loss: 0.569764\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095451; batch adversarial loss: 0.525207\n",
      "epoch 41; iter: 0; batch classifier loss: 0.145060; batch adversarial loss: 0.443836\n",
      "epoch 42; iter: 0; batch classifier loss: 0.081243; batch adversarial loss: 0.542425\n",
      "epoch 43; iter: 0; batch classifier loss: 0.112382; batch adversarial loss: 0.426038\n",
      "epoch 44; iter: 0; batch classifier loss: 0.094905; batch adversarial loss: 0.399893\n",
      "epoch 45; iter: 0; batch classifier loss: 0.074837; batch adversarial loss: 0.489197\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126845; batch adversarial loss: 0.308447\n",
      "epoch 47; iter: 0; batch classifier loss: 0.091035; batch adversarial loss: 0.395846\n",
      "epoch 48; iter: 0; batch classifier loss: 0.135148; batch adversarial loss: 0.433653\n",
      "epoch 49; iter: 0; batch classifier loss: 0.063060; batch adversarial loss: 0.519673\n",
      "epoch 50; iter: 0; batch classifier loss: 0.115980; batch adversarial loss: 0.507276\n",
      "epoch 51; iter: 0; batch classifier loss: 0.100217; batch adversarial loss: 0.438988\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112583; batch adversarial loss: 0.450379\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076081; batch adversarial loss: 0.363412\n",
      "epoch 54; iter: 0; batch classifier loss: 0.078912; batch adversarial loss: 0.440084\n",
      "epoch 55; iter: 0; batch classifier loss: 0.088087; batch adversarial loss: 0.421727\n",
      "epoch 56; iter: 0; batch classifier loss: 0.109164; batch adversarial loss: 0.408462\n",
      "epoch 57; iter: 0; batch classifier loss: 0.099048; batch adversarial loss: 0.394096\n",
      "epoch 58; iter: 0; batch classifier loss: 0.069618; batch adversarial loss: 0.425360\n",
      "epoch 59; iter: 0; batch classifier loss: 0.107197; batch adversarial loss: 0.388040\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105717; batch adversarial loss: 0.530671\n",
      "epoch 61; iter: 0; batch classifier loss: 0.079284; batch adversarial loss: 0.416042\n",
      "epoch 62; iter: 0; batch classifier loss: 0.088143; batch adversarial loss: 0.515417\n",
      "epoch 63; iter: 0; batch classifier loss: 0.039723; batch adversarial loss: 0.457713\n",
      "epoch 64; iter: 0; batch classifier loss: 0.079347; batch adversarial loss: 0.435539\n",
      "epoch 65; iter: 0; batch classifier loss: 0.114278; batch adversarial loss: 0.351581\n",
      "epoch 66; iter: 0; batch classifier loss: 0.058296; batch adversarial loss: 0.565096\n",
      "epoch 67; iter: 0; batch classifier loss: 0.121814; batch adversarial loss: 0.374216\n",
      "epoch 68; iter: 0; batch classifier loss: 0.072675; batch adversarial loss: 0.432230\n",
      "epoch 69; iter: 0; batch classifier loss: 0.117316; batch adversarial loss: 0.491825\n",
      "epoch 70; iter: 0; batch classifier loss: 0.095169; batch adversarial loss: 0.501008\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063345; batch adversarial loss: 0.468435\n",
      "epoch 72; iter: 0; batch classifier loss: 0.126619; batch adversarial loss: 0.417795\n",
      "epoch 73; iter: 0; batch classifier loss: 0.110423; batch adversarial loss: 0.454741\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079028; batch adversarial loss: 0.465972\n",
      "epoch 75; iter: 0; batch classifier loss: 0.048907; batch adversarial loss: 0.439699\n",
      "epoch 76; iter: 0; batch classifier loss: 0.107886; batch adversarial loss: 0.383304\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056825; batch adversarial loss: 0.506418\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074202; batch adversarial loss: 0.414084\n",
      "epoch 79; iter: 0; batch classifier loss: 0.036367; batch adversarial loss: 0.520460\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068869; batch adversarial loss: 0.430258\n",
      "epoch 81; iter: 0; batch classifier loss: 0.090929; batch adversarial loss: 0.505288\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052666; batch adversarial loss: 0.460582\n",
      "epoch 83; iter: 0; batch classifier loss: 0.099941; batch adversarial loss: 0.430040\n",
      "epoch 84; iter: 0; batch classifier loss: 0.053396; batch adversarial loss: 0.490912\n",
      "epoch 85; iter: 0; batch classifier loss: 0.050719; batch adversarial loss: 0.542102\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068665; batch adversarial loss: 0.422549\n",
      "epoch 87; iter: 0; batch classifier loss: 0.033444; batch adversarial loss: 0.509945\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049299; batch adversarial loss: 0.432818\n",
      "epoch 89; iter: 0; batch classifier loss: 0.061324; batch adversarial loss: 0.419149\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064090; batch adversarial loss: 0.398984\n",
      "epoch 91; iter: 0; batch classifier loss: 0.069377; batch adversarial loss: 0.526163\n",
      "epoch 92; iter: 0; batch classifier loss: 0.034472; batch adversarial loss: 0.449991\n",
      "epoch 93; iter: 0; batch classifier loss: 0.082938; batch adversarial loss: 0.470578\n",
      "epoch 94; iter: 0; batch classifier loss: 0.081959; batch adversarial loss: 0.518705\n",
      "epoch 95; iter: 0; batch classifier loss: 0.098667; batch adversarial loss: 0.476858\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049873; batch adversarial loss: 0.438084\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052820; batch adversarial loss: 0.472130\n",
      "epoch 98; iter: 0; batch classifier loss: 0.025822; batch adversarial loss: 0.372189\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062635; batch adversarial loss: 0.501002\n",
      "epoch 100; iter: 0; batch classifier loss: 0.070456; batch adversarial loss: 0.518236\n",
      "epoch 101; iter: 0; batch classifier loss: 0.031551; batch adversarial loss: 0.470764\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042874; batch adversarial loss: 0.418410\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076064; batch adversarial loss: 0.423807\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069383; batch adversarial loss: 0.500984\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046426; batch adversarial loss: 0.467241\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044113; batch adversarial loss: 0.540208\n",
      "epoch 107; iter: 0; batch classifier loss: 0.078253; batch adversarial loss: 0.467660\n",
      "epoch 108; iter: 0; batch classifier loss: 0.070124; batch adversarial loss: 0.420336\n",
      "epoch 109; iter: 0; batch classifier loss: 0.113272; batch adversarial loss: 0.424348\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031668; batch adversarial loss: 0.474468\n",
      "epoch 111; iter: 0; batch classifier loss: 0.095997; batch adversarial loss: 0.397079\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043407; batch adversarial loss: 0.481360\n",
      "epoch 113; iter: 0; batch classifier loss: 0.068326; batch adversarial loss: 0.500692\n",
      "epoch 114; iter: 0; batch classifier loss: 0.025476; batch adversarial loss: 0.462419\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046222; batch adversarial loss: 0.497050\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026098; batch adversarial loss: 0.495793\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052397; batch adversarial loss: 0.422187\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060858; batch adversarial loss: 0.545287\n",
      "epoch 119; iter: 0; batch classifier loss: 0.085514; batch adversarial loss: 0.442796\n",
      "epoch 120; iter: 0; batch classifier loss: 0.024709; batch adversarial loss: 0.489329\n",
      "epoch 121; iter: 0; batch classifier loss: 0.095026; batch adversarial loss: 0.375552\n",
      "epoch 122; iter: 0; batch classifier loss: 0.069786; batch adversarial loss: 0.403632\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029733; batch adversarial loss: 0.356791\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044085; batch adversarial loss: 0.483917\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051004; batch adversarial loss: 0.435890\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032318; batch adversarial loss: 0.501185\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042844; batch adversarial loss: 0.516532\n",
      "epoch 128; iter: 0; batch classifier loss: 0.048607; batch adversarial loss: 0.425642\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027753; batch adversarial loss: 0.513922\n",
      "epoch 130; iter: 0; batch classifier loss: 0.062094; batch adversarial loss: 0.465018\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034308; batch adversarial loss: 0.440379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.020342; batch adversarial loss: 0.473246\n",
      "epoch 133; iter: 0; batch classifier loss: 0.069678; batch adversarial loss: 0.388072\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053599; batch adversarial loss: 0.512205\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031732; batch adversarial loss: 0.474572\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026682; batch adversarial loss: 0.471932\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041887; batch adversarial loss: 0.372246\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040516; batch adversarial loss: 0.442218\n",
      "epoch 139; iter: 0; batch classifier loss: 0.012224; batch adversarial loss: 0.507296\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026021; batch adversarial loss: 0.422199\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029530; batch adversarial loss: 0.467538\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040510; batch adversarial loss: 0.442773\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036411; batch adversarial loss: 0.400104\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032640; batch adversarial loss: 0.420705\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018228; batch adversarial loss: 0.501138\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031190; batch adversarial loss: 0.369114\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037283; batch adversarial loss: 0.398207\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033184; batch adversarial loss: 0.533106\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021820; batch adversarial loss: 0.525367\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037056; batch adversarial loss: 0.441227\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039889; batch adversarial loss: 0.368865\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022201; batch adversarial loss: 0.441237\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024461; batch adversarial loss: 0.461922\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044145; batch adversarial loss: 0.467716\n",
      "epoch 155; iter: 0; batch classifier loss: 0.054196; batch adversarial loss: 0.447176\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021234; batch adversarial loss: 0.444800\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033012; batch adversarial loss: 0.474715\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018400; batch adversarial loss: 0.625566\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017411; batch adversarial loss: 0.460729\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029993; batch adversarial loss: 0.375166\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007607; batch adversarial loss: 0.523293\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012998; batch adversarial loss: 0.465316\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039229; batch adversarial loss: 0.495560\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020048; batch adversarial loss: 0.425103\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019229; batch adversarial loss: 0.467177\n",
      "epoch 166; iter: 0; batch classifier loss: 0.039854; batch adversarial loss: 0.446095\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029962; batch adversarial loss: 0.457628\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017426; batch adversarial loss: 0.490011\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034747; batch adversarial loss: 0.505189\n",
      "epoch 170; iter: 0; batch classifier loss: 0.050956; batch adversarial loss: 0.505165\n",
      "epoch 171; iter: 0; batch classifier loss: 0.063518; batch adversarial loss: 0.368337\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033815; batch adversarial loss: 0.450222\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020629; batch adversarial loss: 0.564470\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035917; batch adversarial loss: 0.484253\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016904; batch adversarial loss: 0.375555\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030010; batch adversarial loss: 0.446080\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020992; batch adversarial loss: 0.399550\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017642; batch adversarial loss: 0.380258\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027082; batch adversarial loss: 0.482107\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032313; batch adversarial loss: 0.371322\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026902; batch adversarial loss: 0.453433\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018524; batch adversarial loss: 0.478374\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014170; batch adversarial loss: 0.428323\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019712; batch adversarial loss: 0.432817\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018351; batch adversarial loss: 0.391410\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030418; batch adversarial loss: 0.359086\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009653; batch adversarial loss: 0.498946\n",
      "epoch 188; iter: 0; batch classifier loss: 0.004504; batch adversarial loss: 0.452903\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022825; batch adversarial loss: 0.452710\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016259; batch adversarial loss: 0.507163\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010428; batch adversarial loss: 0.474696\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021920; batch adversarial loss: 0.468616\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005573; batch adversarial loss: 0.446253\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024315; batch adversarial loss: 0.471315\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027410; batch adversarial loss: 0.347079\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013163; batch adversarial loss: 0.450275\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020189; batch adversarial loss: 0.462114\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016886; batch adversarial loss: 0.519396\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014510; batch adversarial loss: 0.442991\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717907; batch adversarial loss: 0.553909\n",
      "epoch 1; iter: 0; batch classifier loss: 0.369656; batch adversarial loss: 0.606024\n",
      "epoch 2; iter: 0; batch classifier loss: 0.353001; batch adversarial loss: 0.592892\n",
      "epoch 3; iter: 0; batch classifier loss: 0.345904; batch adversarial loss: 0.575580\n",
      "epoch 4; iter: 0; batch classifier loss: 0.369573; batch adversarial loss: 0.541047\n",
      "epoch 5; iter: 0; batch classifier loss: 0.428484; batch adversarial loss: 0.585991\n",
      "epoch 6; iter: 0; batch classifier loss: 0.229493; batch adversarial loss: 0.601456\n",
      "epoch 7; iter: 0; batch classifier loss: 0.243830; batch adversarial loss: 0.507420\n",
      "epoch 8; iter: 0; batch classifier loss: 0.278466; batch adversarial loss: 0.536281\n",
      "epoch 9; iter: 0; batch classifier loss: 0.327856; batch adversarial loss: 0.615122\n",
      "epoch 10; iter: 0; batch classifier loss: 0.242190; batch adversarial loss: 0.549982\n",
      "epoch 11; iter: 0; batch classifier loss: 0.214475; batch adversarial loss: 0.575479\n",
      "epoch 12; iter: 0; batch classifier loss: 0.239527; batch adversarial loss: 0.482541\n",
      "epoch 13; iter: 0; batch classifier loss: 0.306667; batch adversarial loss: 0.584518\n",
      "epoch 14; iter: 0; batch classifier loss: 0.268869; batch adversarial loss: 0.487352\n",
      "epoch 15; iter: 0; batch classifier loss: 0.232884; batch adversarial loss: 0.470854\n",
      "epoch 16; iter: 0; batch classifier loss: 0.316062; batch adversarial loss: 0.522442\n",
      "epoch 17; iter: 0; batch classifier loss: 0.401247; batch adversarial loss: 0.581518\n",
      "epoch 18; iter: 0; batch classifier loss: 0.409559; batch adversarial loss: 0.547855\n",
      "epoch 19; iter: 0; batch classifier loss: 0.451994; batch adversarial loss: 0.468556\n",
      "epoch 20; iter: 0; batch classifier loss: 0.378241; batch adversarial loss: 0.570296\n",
      "epoch 21; iter: 0; batch classifier loss: 0.232812; batch adversarial loss: 0.443071\n",
      "epoch 22; iter: 0; batch classifier loss: 0.183564; batch adversarial loss: 0.436980\n",
      "epoch 23; iter: 0; batch classifier loss: 0.137406; batch adversarial loss: 0.485945\n",
      "epoch 24; iter: 0; batch classifier loss: 0.165315; batch adversarial loss: 0.510099\n",
      "epoch 25; iter: 0; batch classifier loss: 0.110229; batch adversarial loss: 0.511032\n",
      "epoch 26; iter: 0; batch classifier loss: 0.119429; batch adversarial loss: 0.540628\n",
      "epoch 27; iter: 0; batch classifier loss: 0.173714; batch adversarial loss: 0.525638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.174091; batch adversarial loss: 0.410663\n",
      "epoch 29; iter: 0; batch classifier loss: 0.136560; batch adversarial loss: 0.523209\n",
      "epoch 30; iter: 0; batch classifier loss: 0.084962; batch adversarial loss: 0.617386\n",
      "epoch 31; iter: 0; batch classifier loss: 0.110086; batch adversarial loss: 0.460609\n",
      "epoch 32; iter: 0; batch classifier loss: 0.147380; batch adversarial loss: 0.357403\n",
      "epoch 33; iter: 0; batch classifier loss: 0.140003; batch adversarial loss: 0.448648\n",
      "epoch 34; iter: 0; batch classifier loss: 0.098671; batch adversarial loss: 0.435693\n",
      "epoch 35; iter: 0; batch classifier loss: 0.100693; batch adversarial loss: 0.450561\n",
      "epoch 36; iter: 0; batch classifier loss: 0.088035; batch adversarial loss: 0.540948\n",
      "epoch 37; iter: 0; batch classifier loss: 0.144110; batch adversarial loss: 0.494568\n",
      "epoch 38; iter: 0; batch classifier loss: 0.132129; batch adversarial loss: 0.539747\n",
      "epoch 39; iter: 0; batch classifier loss: 0.136189; batch adversarial loss: 0.430640\n",
      "epoch 40; iter: 0; batch classifier loss: 0.096953; batch adversarial loss: 0.510858\n",
      "epoch 41; iter: 0; batch classifier loss: 0.101568; batch adversarial loss: 0.452516\n",
      "epoch 42; iter: 0; batch classifier loss: 0.127330; batch adversarial loss: 0.478798\n",
      "epoch 43; iter: 0; batch classifier loss: 0.074311; batch adversarial loss: 0.476757\n",
      "epoch 44; iter: 0; batch classifier loss: 0.148123; batch adversarial loss: 0.457487\n",
      "epoch 45; iter: 0; batch classifier loss: 0.079362; batch adversarial loss: 0.457691\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127440; batch adversarial loss: 0.457554\n",
      "epoch 47; iter: 0; batch classifier loss: 0.132022; batch adversarial loss: 0.412426\n",
      "epoch 48; iter: 0; batch classifier loss: 0.112003; batch adversarial loss: 0.427066\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094103; batch adversarial loss: 0.455425\n",
      "epoch 50; iter: 0; batch classifier loss: 0.118202; batch adversarial loss: 0.451657\n",
      "epoch 51; iter: 0; batch classifier loss: 0.129803; batch adversarial loss: 0.500018\n",
      "epoch 52; iter: 0; batch classifier loss: 0.131609; batch adversarial loss: 0.582887\n",
      "epoch 53; iter: 0; batch classifier loss: 0.134038; batch adversarial loss: 0.501147\n",
      "epoch 54; iter: 0; batch classifier loss: 0.071036; batch adversarial loss: 0.487648\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125935; batch adversarial loss: 0.396652\n",
      "epoch 56; iter: 0; batch classifier loss: 0.083342; batch adversarial loss: 0.535440\n",
      "epoch 57; iter: 0; batch classifier loss: 0.090366; batch adversarial loss: 0.438675\n",
      "epoch 58; iter: 0; batch classifier loss: 0.126687; batch adversarial loss: 0.434611\n",
      "epoch 59; iter: 0; batch classifier loss: 0.095422; batch adversarial loss: 0.402094\n",
      "epoch 60; iter: 0; batch classifier loss: 0.080016; batch adversarial loss: 0.458215\n",
      "epoch 61; iter: 0; batch classifier loss: 0.086863; batch adversarial loss: 0.327792\n",
      "epoch 62; iter: 0; batch classifier loss: 0.107687; batch adversarial loss: 0.431239\n",
      "epoch 63; iter: 0; batch classifier loss: 0.133000; batch adversarial loss: 0.394746\n",
      "epoch 64; iter: 0; batch classifier loss: 0.133236; batch adversarial loss: 0.523602\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088139; batch adversarial loss: 0.492130\n",
      "epoch 66; iter: 0; batch classifier loss: 0.119965; batch adversarial loss: 0.436669\n",
      "epoch 67; iter: 0; batch classifier loss: 0.112228; batch adversarial loss: 0.470680\n",
      "epoch 68; iter: 0; batch classifier loss: 0.125447; batch adversarial loss: 0.432801\n",
      "epoch 69; iter: 0; batch classifier loss: 0.129955; batch adversarial loss: 0.446899\n",
      "epoch 70; iter: 0; batch classifier loss: 0.082792; batch adversarial loss: 0.470096\n",
      "epoch 71; iter: 0; batch classifier loss: 0.107416; batch adversarial loss: 0.464926\n",
      "epoch 72; iter: 0; batch classifier loss: 0.118133; batch adversarial loss: 0.522589\n",
      "epoch 73; iter: 0; batch classifier loss: 0.109854; batch adversarial loss: 0.531344\n",
      "epoch 74; iter: 0; batch classifier loss: 0.138656; batch adversarial loss: 0.462628\n",
      "epoch 75; iter: 0; batch classifier loss: 0.110965; batch adversarial loss: 0.479144\n",
      "epoch 76; iter: 0; batch classifier loss: 0.102983; batch adversarial loss: 0.594357\n",
      "epoch 77; iter: 0; batch classifier loss: 0.127001; batch adversarial loss: 0.490828\n",
      "epoch 78; iter: 0; batch classifier loss: 0.101501; batch adversarial loss: 0.467172\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065803; batch adversarial loss: 0.436429\n",
      "epoch 80; iter: 0; batch classifier loss: 0.132142; batch adversarial loss: 0.552567\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084320; batch adversarial loss: 0.369377\n",
      "epoch 82; iter: 0; batch classifier loss: 0.122085; batch adversarial loss: 0.448333\n",
      "epoch 83; iter: 0; batch classifier loss: 0.090568; batch adversarial loss: 0.441610\n",
      "epoch 84; iter: 0; batch classifier loss: 0.107253; batch adversarial loss: 0.485578\n",
      "epoch 85; iter: 0; batch classifier loss: 0.079270; batch adversarial loss: 0.452912\n",
      "epoch 86; iter: 0; batch classifier loss: 0.108509; batch adversarial loss: 0.495201\n",
      "epoch 87; iter: 0; batch classifier loss: 0.108038; batch adversarial loss: 0.516464\n",
      "epoch 88; iter: 0; batch classifier loss: 0.109597; batch adversarial loss: 0.506001\n",
      "epoch 89; iter: 0; batch classifier loss: 0.116007; batch adversarial loss: 0.477614\n",
      "epoch 90; iter: 0; batch classifier loss: 0.103728; batch adversarial loss: 0.457041\n",
      "epoch 91; iter: 0; batch classifier loss: 0.085591; batch adversarial loss: 0.442100\n",
      "epoch 92; iter: 0; batch classifier loss: 0.121053; batch adversarial loss: 0.504215\n",
      "epoch 93; iter: 0; batch classifier loss: 0.127230; batch adversarial loss: 0.431470\n",
      "epoch 94; iter: 0; batch classifier loss: 0.086498; batch adversarial loss: 0.436837\n",
      "epoch 95; iter: 0; batch classifier loss: 0.156557; batch adversarial loss: 0.471840\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035988; batch adversarial loss: 0.389710\n",
      "epoch 97; iter: 0; batch classifier loss: 0.095984; batch adversarial loss: 0.543582\n",
      "epoch 98; iter: 0; batch classifier loss: 0.075691; batch adversarial loss: 0.446951\n",
      "epoch 99; iter: 0; batch classifier loss: 0.091469; batch adversarial loss: 0.455232\n",
      "epoch 100; iter: 0; batch classifier loss: 0.088897; batch adversarial loss: 0.551989\n",
      "epoch 101; iter: 0; batch classifier loss: 0.102380; batch adversarial loss: 0.402667\n",
      "epoch 102; iter: 0; batch classifier loss: 0.132963; batch adversarial loss: 0.625494\n",
      "epoch 103; iter: 0; batch classifier loss: 0.105739; batch adversarial loss: 0.587492\n",
      "epoch 104; iter: 0; batch classifier loss: 0.064664; batch adversarial loss: 0.387860\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059238; batch adversarial loss: 0.424251\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058763; batch adversarial loss: 0.504197\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058994; batch adversarial loss: 0.485102\n",
      "epoch 108; iter: 0; batch classifier loss: 0.098466; batch adversarial loss: 0.453273\n",
      "epoch 109; iter: 0; batch classifier loss: 0.081070; batch adversarial loss: 0.461509\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060963; batch adversarial loss: 0.422172\n",
      "epoch 111; iter: 0; batch classifier loss: 0.085656; batch adversarial loss: 0.391220\n",
      "epoch 112; iter: 0; batch classifier loss: 0.106902; batch adversarial loss: 0.452494\n",
      "epoch 113; iter: 0; batch classifier loss: 0.065713; batch adversarial loss: 0.482353\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051706; batch adversarial loss: 0.484546\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059654; batch adversarial loss: 0.456998\n",
      "epoch 116; iter: 0; batch classifier loss: 0.081234; batch adversarial loss: 0.402000\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045089; batch adversarial loss: 0.525563\n",
      "epoch 118; iter: 0; batch classifier loss: 0.118877; batch adversarial loss: 0.469519\n",
      "epoch 119; iter: 0; batch classifier loss: 0.071525; batch adversarial loss: 0.505587\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050558; batch adversarial loss: 0.545886\n",
      "epoch 121; iter: 0; batch classifier loss: 0.086101; batch adversarial loss: 0.576925\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067064; batch adversarial loss: 0.570712\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048533; batch adversarial loss: 0.443439\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043184; batch adversarial loss: 0.492072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.050676; batch adversarial loss: 0.394305\n",
      "epoch 126; iter: 0; batch classifier loss: 0.073320; batch adversarial loss: 0.520218\n",
      "epoch 127; iter: 0; batch classifier loss: 0.089919; batch adversarial loss: 0.383689\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022542; batch adversarial loss: 0.408847\n",
      "epoch 129; iter: 0; batch classifier loss: 0.067530; batch adversarial loss: 0.422168\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059502; batch adversarial loss: 0.523944\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032338; batch adversarial loss: 0.443837\n",
      "epoch 132; iter: 0; batch classifier loss: 0.090128; batch adversarial loss: 0.494019\n",
      "epoch 133; iter: 0; batch classifier loss: 0.056155; batch adversarial loss: 0.486317\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045983; batch adversarial loss: 0.392627\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037783; batch adversarial loss: 0.450078\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027532; batch adversarial loss: 0.470121\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034405; batch adversarial loss: 0.615678\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041175; batch adversarial loss: 0.532868\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029890; batch adversarial loss: 0.459113\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034679; batch adversarial loss: 0.498056\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027248; batch adversarial loss: 0.399342\n",
      "epoch 142; iter: 0; batch classifier loss: 0.046137; batch adversarial loss: 0.482313\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031184; batch adversarial loss: 0.489548\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034424; batch adversarial loss: 0.485379\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032197; batch adversarial loss: 0.462175\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010129; batch adversarial loss: 0.536416\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018312; batch adversarial loss: 0.475734\n",
      "epoch 148; iter: 0; batch classifier loss: 0.056613; batch adversarial loss: 0.477272\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021570; batch adversarial loss: 0.483486\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033969; batch adversarial loss: 0.471151\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032776; batch adversarial loss: 0.449230\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041760; batch adversarial loss: 0.444806\n",
      "epoch 153; iter: 0; batch classifier loss: 0.045556; batch adversarial loss: 0.411598\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020535; batch adversarial loss: 0.563622\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042925; batch adversarial loss: 0.474856\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019509; batch adversarial loss: 0.514358\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034440; batch adversarial loss: 0.445023\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022485; batch adversarial loss: 0.557323\n",
      "epoch 159; iter: 0; batch classifier loss: 0.074166; batch adversarial loss: 0.564541\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046807; batch adversarial loss: 0.512328\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035235; batch adversarial loss: 0.442391\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014584; batch adversarial loss: 0.518487\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035894; batch adversarial loss: 0.557413\n",
      "epoch 164; iter: 0; batch classifier loss: 0.046301; batch adversarial loss: 0.355617\n",
      "epoch 165; iter: 0; batch classifier loss: 0.043191; batch adversarial loss: 0.413400\n",
      "epoch 166; iter: 0; batch classifier loss: 0.049560; batch adversarial loss: 0.472745\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011045; batch adversarial loss: 0.403098\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024419; batch adversarial loss: 0.602579\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032357; batch adversarial loss: 0.387353\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037970; batch adversarial loss: 0.391732\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022148; batch adversarial loss: 0.421647\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014928; batch adversarial loss: 0.457578\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033201; batch adversarial loss: 0.464783\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018555; batch adversarial loss: 0.452705\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041862; batch adversarial loss: 0.447990\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029196; batch adversarial loss: 0.361825\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027024; batch adversarial loss: 0.489242\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026962; batch adversarial loss: 0.539750\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023004; batch adversarial loss: 0.453100\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032440; batch adversarial loss: 0.457336\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018471; batch adversarial loss: 0.488260\n",
      "epoch 182; iter: 0; batch classifier loss: 0.040259; batch adversarial loss: 0.538565\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016342; batch adversarial loss: 0.394657\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018877; batch adversarial loss: 0.481207\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036116; batch adversarial loss: 0.462632\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009679; batch adversarial loss: 0.662573\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013112; batch adversarial loss: 0.442853\n",
      "epoch 188; iter: 0; batch classifier loss: 0.067415; batch adversarial loss: 0.476997\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019029; batch adversarial loss: 0.476097\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026712; batch adversarial loss: 0.373669\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017214; batch adversarial loss: 0.458198\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028125; batch adversarial loss: 0.417796\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015996; batch adversarial loss: 0.546643\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005948; batch adversarial loss: 0.386702\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023831; batch adversarial loss: 0.485571\n",
      "epoch 196; iter: 0; batch classifier loss: 0.048979; batch adversarial loss: 0.495839\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017767; batch adversarial loss: 0.465126\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012607; batch adversarial loss: 0.439588\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018047; batch adversarial loss: 0.416203\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700740; batch adversarial loss: 0.808526\n",
      "epoch 1; iter: 0; batch classifier loss: 0.539347; batch adversarial loss: 0.744515\n",
      "epoch 2; iter: 0; batch classifier loss: 0.742689; batch adversarial loss: 0.752653\n",
      "epoch 3; iter: 0; batch classifier loss: 0.659369; batch adversarial loss: 0.669143\n",
      "epoch 4; iter: 0; batch classifier loss: 0.537262; batch adversarial loss: 0.611572\n",
      "epoch 5; iter: 0; batch classifier loss: 0.416264; batch adversarial loss: 0.586102\n",
      "epoch 6; iter: 0; batch classifier loss: 0.306062; batch adversarial loss: 0.543851\n",
      "epoch 7; iter: 0; batch classifier loss: 0.343750; batch adversarial loss: 0.527467\n",
      "epoch 8; iter: 0; batch classifier loss: 0.336498; batch adversarial loss: 0.508285\n",
      "epoch 9; iter: 0; batch classifier loss: 0.289674; batch adversarial loss: 0.568470\n",
      "epoch 10; iter: 0; batch classifier loss: 0.310870; batch adversarial loss: 0.499667\n",
      "epoch 11; iter: 0; batch classifier loss: 0.247509; batch adversarial loss: 0.506685\n",
      "epoch 12; iter: 0; batch classifier loss: 0.331944; batch adversarial loss: 0.506745\n",
      "epoch 13; iter: 0; batch classifier loss: 0.249925; batch adversarial loss: 0.490297\n",
      "epoch 14; iter: 0; batch classifier loss: 0.255279; batch adversarial loss: 0.490338\n",
      "epoch 15; iter: 0; batch classifier loss: 0.233430; batch adversarial loss: 0.531881\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222854; batch adversarial loss: 0.459660\n",
      "epoch 17; iter: 0; batch classifier loss: 0.228725; batch adversarial loss: 0.444018\n",
      "epoch 18; iter: 0; batch classifier loss: 0.233123; batch adversarial loss: 0.458270\n",
      "epoch 19; iter: 0; batch classifier loss: 0.226058; batch adversarial loss: 0.505499\n",
      "epoch 20; iter: 0; batch classifier loss: 0.168203; batch adversarial loss: 0.518097\n",
      "epoch 21; iter: 0; batch classifier loss: 0.172691; batch adversarial loss: 0.515728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.226970; batch adversarial loss: 0.468142\n",
      "epoch 23; iter: 0; batch classifier loss: 0.158214; batch adversarial loss: 0.481778\n",
      "epoch 24; iter: 0; batch classifier loss: 0.203874; batch adversarial loss: 0.373681\n",
      "epoch 25; iter: 0; batch classifier loss: 0.201170; batch adversarial loss: 0.456941\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193037; batch adversarial loss: 0.452018\n",
      "epoch 27; iter: 0; batch classifier loss: 0.243749; batch adversarial loss: 0.469202\n",
      "epoch 28; iter: 0; batch classifier loss: 0.205098; batch adversarial loss: 0.521523\n",
      "epoch 29; iter: 0; batch classifier loss: 0.125348; batch adversarial loss: 0.503948\n",
      "epoch 30; iter: 0; batch classifier loss: 0.236126; batch adversarial loss: 0.482740\n",
      "epoch 31; iter: 0; batch classifier loss: 0.232638; batch adversarial loss: 0.426948\n",
      "epoch 32; iter: 0; batch classifier loss: 0.175619; batch adversarial loss: 0.372977\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143314; batch adversarial loss: 0.357565\n",
      "epoch 34; iter: 0; batch classifier loss: 0.102302; batch adversarial loss: 0.538288\n",
      "epoch 35; iter: 0; batch classifier loss: 0.100287; batch adversarial loss: 0.434722\n",
      "epoch 36; iter: 0; batch classifier loss: 0.199144; batch adversarial loss: 0.420129\n",
      "epoch 37; iter: 0; batch classifier loss: 0.174641; batch adversarial loss: 0.380990\n",
      "epoch 38; iter: 0; batch classifier loss: 0.166904; batch adversarial loss: 0.438682\n",
      "epoch 39; iter: 0; batch classifier loss: 0.147149; batch adversarial loss: 0.512878\n",
      "epoch 40; iter: 0; batch classifier loss: 0.150554; batch adversarial loss: 0.428955\n",
      "epoch 41; iter: 0; batch classifier loss: 0.180301; batch adversarial loss: 0.418996\n",
      "epoch 42; iter: 0; batch classifier loss: 0.125401; batch adversarial loss: 0.387435\n",
      "epoch 43; iter: 0; batch classifier loss: 0.160198; batch adversarial loss: 0.530511\n",
      "epoch 44; iter: 0; batch classifier loss: 0.165285; batch adversarial loss: 0.410325\n",
      "epoch 45; iter: 0; batch classifier loss: 0.180151; batch adversarial loss: 0.436426\n",
      "epoch 46; iter: 0; batch classifier loss: 0.255511; batch adversarial loss: 0.503448\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112967; batch adversarial loss: 0.524943\n",
      "epoch 48; iter: 0; batch classifier loss: 0.181621; batch adversarial loss: 0.348466\n",
      "epoch 49; iter: 0; batch classifier loss: 0.161857; batch adversarial loss: 0.469496\n",
      "epoch 50; iter: 0; batch classifier loss: 0.144082; batch adversarial loss: 0.497860\n",
      "epoch 51; iter: 0; batch classifier loss: 0.142731; batch adversarial loss: 0.429283\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161707; batch adversarial loss: 0.486133\n",
      "epoch 53; iter: 0; batch classifier loss: 0.176612; batch adversarial loss: 0.471363\n",
      "epoch 54; iter: 0; batch classifier loss: 0.141749; batch adversarial loss: 0.463954\n",
      "epoch 55; iter: 0; batch classifier loss: 0.163614; batch adversarial loss: 0.521410\n",
      "epoch 56; iter: 0; batch classifier loss: 0.177238; batch adversarial loss: 0.433823\n",
      "epoch 57; iter: 0; batch classifier loss: 0.158496; batch adversarial loss: 0.484952\n",
      "epoch 58; iter: 0; batch classifier loss: 0.166454; batch adversarial loss: 0.458561\n",
      "epoch 59; iter: 0; batch classifier loss: 0.143351; batch adversarial loss: 0.443389\n",
      "epoch 60; iter: 0; batch classifier loss: 0.187729; batch adversarial loss: 0.531357\n",
      "epoch 61; iter: 0; batch classifier loss: 0.135310; batch adversarial loss: 0.404590\n",
      "epoch 62; iter: 0; batch classifier loss: 0.118202; batch adversarial loss: 0.500627\n",
      "epoch 63; iter: 0; batch classifier loss: 0.165552; batch adversarial loss: 0.483887\n",
      "epoch 64; iter: 0; batch classifier loss: 0.140000; batch adversarial loss: 0.433861\n",
      "epoch 65; iter: 0; batch classifier loss: 0.150982; batch adversarial loss: 0.477302\n",
      "epoch 66; iter: 0; batch classifier loss: 0.152422; batch adversarial loss: 0.466624\n",
      "epoch 67; iter: 0; batch classifier loss: 0.174546; batch adversarial loss: 0.399484\n",
      "epoch 68; iter: 0; batch classifier loss: 0.153736; batch adversarial loss: 0.429111\n",
      "epoch 69; iter: 0; batch classifier loss: 0.160471; batch adversarial loss: 0.486048\n",
      "epoch 70; iter: 0; batch classifier loss: 0.153646; batch adversarial loss: 0.463029\n",
      "epoch 71; iter: 0; batch classifier loss: 0.178182; batch adversarial loss: 0.476571\n",
      "epoch 72; iter: 0; batch classifier loss: 0.159233; batch adversarial loss: 0.448559\n",
      "epoch 73; iter: 0; batch classifier loss: 0.199148; batch adversarial loss: 0.384285\n",
      "epoch 74; iter: 0; batch classifier loss: 0.168910; batch adversarial loss: 0.439148\n",
      "epoch 75; iter: 0; batch classifier loss: 0.158242; batch adversarial loss: 0.486560\n",
      "epoch 76; iter: 0; batch classifier loss: 0.147120; batch adversarial loss: 0.428386\n",
      "epoch 77; iter: 0; batch classifier loss: 0.165895; batch adversarial loss: 0.459716\n",
      "epoch 78; iter: 0; batch classifier loss: 0.174080; batch adversarial loss: 0.469390\n",
      "epoch 79; iter: 0; batch classifier loss: 0.171992; batch adversarial loss: 0.417136\n",
      "epoch 80; iter: 0; batch classifier loss: 0.194446; batch adversarial loss: 0.471657\n",
      "epoch 81; iter: 0; batch classifier loss: 0.136162; batch adversarial loss: 0.504505\n",
      "epoch 82; iter: 0; batch classifier loss: 0.166883; batch adversarial loss: 0.399764\n",
      "epoch 83; iter: 0; batch classifier loss: 0.180643; batch adversarial loss: 0.444603\n",
      "epoch 84; iter: 0; batch classifier loss: 0.161918; batch adversarial loss: 0.489582\n",
      "epoch 85; iter: 0; batch classifier loss: 0.136813; batch adversarial loss: 0.388286\n",
      "epoch 86; iter: 0; batch classifier loss: 0.244516; batch adversarial loss: 0.437594\n",
      "epoch 87; iter: 0; batch classifier loss: 0.214970; batch adversarial loss: 0.460940\n",
      "epoch 88; iter: 0; batch classifier loss: 0.150133; batch adversarial loss: 0.480568\n",
      "epoch 89; iter: 0; batch classifier loss: 0.139141; batch adversarial loss: 0.487901\n",
      "epoch 90; iter: 0; batch classifier loss: 0.160873; batch adversarial loss: 0.437420\n",
      "epoch 91; iter: 0; batch classifier loss: 0.274669; batch adversarial loss: 0.430597\n",
      "epoch 92; iter: 0; batch classifier loss: 0.187302; batch adversarial loss: 0.418016\n",
      "epoch 93; iter: 0; batch classifier loss: 0.162778; batch adversarial loss: 0.438254\n",
      "epoch 94; iter: 0; batch classifier loss: 0.191836; batch adversarial loss: 0.473473\n",
      "epoch 95; iter: 0; batch classifier loss: 0.238178; batch adversarial loss: 0.447115\n",
      "epoch 96; iter: 0; batch classifier loss: 0.176045; batch adversarial loss: 0.422527\n",
      "epoch 97; iter: 0; batch classifier loss: 0.148204; batch adversarial loss: 0.397875\n",
      "epoch 98; iter: 0; batch classifier loss: 0.184324; batch adversarial loss: 0.531848\n",
      "epoch 99; iter: 0; batch classifier loss: 0.143292; batch adversarial loss: 0.432309\n",
      "epoch 100; iter: 0; batch classifier loss: 0.147534; batch adversarial loss: 0.553880\n",
      "epoch 101; iter: 0; batch classifier loss: 0.212451; batch adversarial loss: 0.409432\n",
      "epoch 102; iter: 0; batch classifier loss: 0.161066; batch adversarial loss: 0.510261\n",
      "epoch 103; iter: 0; batch classifier loss: 0.196697; batch adversarial loss: 0.492247\n",
      "epoch 104; iter: 0; batch classifier loss: 0.269834; batch adversarial loss: 0.489037\n",
      "epoch 105; iter: 0; batch classifier loss: 0.261804; batch adversarial loss: 0.357840\n",
      "epoch 106; iter: 0; batch classifier loss: 0.211421; batch adversarial loss: 0.491671\n",
      "epoch 107; iter: 0; batch classifier loss: 0.238635; batch adversarial loss: 0.461273\n",
      "epoch 108; iter: 0; batch classifier loss: 0.230063; batch adversarial loss: 0.398079\n",
      "epoch 109; iter: 0; batch classifier loss: 0.243547; batch adversarial loss: 0.350302\n",
      "epoch 110; iter: 0; batch classifier loss: 0.262893; batch adversarial loss: 0.446271\n",
      "epoch 111; iter: 0; batch classifier loss: 0.212564; batch adversarial loss: 0.483896\n",
      "epoch 112; iter: 0; batch classifier loss: 0.259224; batch adversarial loss: 0.446488\n",
      "epoch 113; iter: 0; batch classifier loss: 0.303942; batch adversarial loss: 0.447363\n",
      "epoch 114; iter: 0; batch classifier loss: 0.218799; batch adversarial loss: 0.459178\n",
      "epoch 115; iter: 0; batch classifier loss: 0.109729; batch adversarial loss: 0.568533\n",
      "epoch 116; iter: 0; batch classifier loss: 0.228722; batch adversarial loss: 0.421050\n",
      "epoch 117; iter: 0; batch classifier loss: 0.139620; batch adversarial loss: 0.448626\n",
      "epoch 118; iter: 0; batch classifier loss: 0.291957; batch adversarial loss: 0.446213\n",
      "epoch 119; iter: 0; batch classifier loss: 0.110672; batch adversarial loss: 0.446514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.084242; batch adversarial loss: 0.457333\n",
      "epoch 121; iter: 0; batch classifier loss: 0.077618; batch adversarial loss: 0.436125\n",
      "epoch 122; iter: 0; batch classifier loss: 0.110161; batch adversarial loss: 0.482558\n",
      "epoch 123; iter: 0; batch classifier loss: 0.126589; batch adversarial loss: 0.420099\n",
      "epoch 124; iter: 0; batch classifier loss: 0.176321; batch adversarial loss: 0.534923\n",
      "epoch 125; iter: 0; batch classifier loss: 0.237541; batch adversarial loss: 0.454969\n",
      "epoch 126; iter: 0; batch classifier loss: 0.132316; batch adversarial loss: 0.482049\n",
      "epoch 127; iter: 0; batch classifier loss: 0.142626; batch adversarial loss: 0.381729\n",
      "epoch 128; iter: 0; batch classifier loss: 0.203589; batch adversarial loss: 0.420249\n",
      "epoch 129; iter: 0; batch classifier loss: 0.201434; batch adversarial loss: 0.426730\n",
      "epoch 130; iter: 0; batch classifier loss: 0.219077; batch adversarial loss: 0.402039\n",
      "epoch 131; iter: 0; batch classifier loss: 0.151674; batch adversarial loss: 0.475654\n",
      "epoch 132; iter: 0; batch classifier loss: 0.183090; batch adversarial loss: 0.431022\n",
      "epoch 133; iter: 0; batch classifier loss: 0.139582; batch adversarial loss: 0.380799\n",
      "epoch 134; iter: 0; batch classifier loss: 0.110270; batch adversarial loss: 0.484950\n",
      "epoch 135; iter: 0; batch classifier loss: 0.170853; batch adversarial loss: 0.519550\n",
      "epoch 136; iter: 0; batch classifier loss: 0.104436; batch adversarial loss: 0.517760\n",
      "epoch 137; iter: 0; batch classifier loss: 0.070659; batch adversarial loss: 0.427760\n",
      "epoch 138; iter: 0; batch classifier loss: 0.065827; batch adversarial loss: 0.460941\n",
      "epoch 139; iter: 0; batch classifier loss: 0.077568; batch adversarial loss: 0.533316\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053363; batch adversarial loss: 0.434855\n",
      "epoch 141; iter: 0; batch classifier loss: 0.062054; batch adversarial loss: 0.443030\n",
      "epoch 142; iter: 0; batch classifier loss: 0.098675; batch adversarial loss: 0.501616\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039586; batch adversarial loss: 0.399756\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034155; batch adversarial loss: 0.373807\n",
      "epoch 145; iter: 0; batch classifier loss: 0.054033; batch adversarial loss: 0.363493\n",
      "epoch 146; iter: 0; batch classifier loss: 0.065999; batch adversarial loss: 0.504154\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029918; batch adversarial loss: 0.408520\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045009; batch adversarial loss: 0.441669\n",
      "epoch 149; iter: 0; batch classifier loss: 0.046503; batch adversarial loss: 0.421561\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040414; batch adversarial loss: 0.432925\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031481; batch adversarial loss: 0.381839\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042737; batch adversarial loss: 0.409353\n",
      "epoch 153; iter: 0; batch classifier loss: 0.043726; batch adversarial loss: 0.355074\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036484; batch adversarial loss: 0.437714\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049398; batch adversarial loss: 0.367941\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022208; batch adversarial loss: 0.471527\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040546; batch adversarial loss: 0.556874\n",
      "epoch 158; iter: 0; batch classifier loss: 0.052837; batch adversarial loss: 0.469305\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033378; batch adversarial loss: 0.391777\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044109; batch adversarial loss: 0.413045\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037571; batch adversarial loss: 0.415836\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022397; batch adversarial loss: 0.410933\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035933; batch adversarial loss: 0.399655\n",
      "epoch 164; iter: 0; batch classifier loss: 0.062714; batch adversarial loss: 0.448856\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031212; batch adversarial loss: 0.419515\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017747; batch adversarial loss: 0.471767\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026789; batch adversarial loss: 0.560583\n",
      "epoch 168; iter: 0; batch classifier loss: 0.043577; batch adversarial loss: 0.508289\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030365; batch adversarial loss: 0.433470\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026590; batch adversarial loss: 0.504776\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016326; batch adversarial loss: 0.504114\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028394; batch adversarial loss: 0.486513\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019551; batch adversarial loss: 0.413631\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017827; batch adversarial loss: 0.383252\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030948; batch adversarial loss: 0.419461\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016171; batch adversarial loss: 0.469462\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017671; batch adversarial loss: 0.477748\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026966; batch adversarial loss: 0.442214\n",
      "epoch 179; iter: 0; batch classifier loss: 0.004325; batch adversarial loss: 0.457925\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022795; batch adversarial loss: 0.503510\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006964; batch adversarial loss: 0.462109\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024024; batch adversarial loss: 0.324792\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025089; batch adversarial loss: 0.418380\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018492; batch adversarial loss: 0.492504\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022612; batch adversarial loss: 0.458856\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008740; batch adversarial loss: 0.364837\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014972; batch adversarial loss: 0.477136\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018985; batch adversarial loss: 0.454614\n",
      "epoch 189; iter: 0; batch classifier loss: 0.040088; batch adversarial loss: 0.441879\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023850; batch adversarial loss: 0.457503\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010758; batch adversarial loss: 0.380803\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013853; batch adversarial loss: 0.367289\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011493; batch adversarial loss: 0.388842\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014703; batch adversarial loss: 0.407784\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012513; batch adversarial loss: 0.434078\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005221; batch adversarial loss: 0.459791\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007018; batch adversarial loss: 0.491146\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006856; batch adversarial loss: 0.453437\n",
      "epoch 199; iter: 0; batch classifier loss: 0.003933; batch adversarial loss: 0.442324\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700171; batch adversarial loss: 0.709681\n",
      "epoch 1; iter: 0; batch classifier loss: 0.448058; batch adversarial loss: 0.677891\n",
      "epoch 2; iter: 0; batch classifier loss: 0.407174; batch adversarial loss: 0.666496\n",
      "epoch 3; iter: 0; batch classifier loss: 0.409616; batch adversarial loss: 0.644490\n",
      "epoch 4; iter: 0; batch classifier loss: 0.398358; batch adversarial loss: 0.585822\n",
      "epoch 5; iter: 0; batch classifier loss: 0.287626; batch adversarial loss: 0.563762\n",
      "epoch 6; iter: 0; batch classifier loss: 0.230640; batch adversarial loss: 0.538614\n",
      "epoch 7; iter: 0; batch classifier loss: 0.328095; batch adversarial loss: 0.533613\n",
      "epoch 8; iter: 0; batch classifier loss: 0.267240; batch adversarial loss: 0.534636\n",
      "epoch 9; iter: 0; batch classifier loss: 0.270659; batch adversarial loss: 0.537373\n",
      "epoch 10; iter: 0; batch classifier loss: 0.188545; batch adversarial loss: 0.465063\n",
      "epoch 11; iter: 0; batch classifier loss: 0.207348; batch adversarial loss: 0.468157\n",
      "epoch 12; iter: 0; batch classifier loss: 0.188112; batch adversarial loss: 0.493369\n",
      "epoch 13; iter: 0; batch classifier loss: 0.294535; batch adversarial loss: 0.482029\n",
      "epoch 14; iter: 0; batch classifier loss: 0.231174; batch adversarial loss: 0.484380\n",
      "epoch 15; iter: 0; batch classifier loss: 0.180108; batch adversarial loss: 0.489031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.237905; batch adversarial loss: 0.428900\n",
      "epoch 17; iter: 0; batch classifier loss: 0.211780; batch adversarial loss: 0.453838\n",
      "epoch 18; iter: 0; batch classifier loss: 0.129512; batch adversarial loss: 0.461157\n",
      "epoch 19; iter: 0; batch classifier loss: 0.135004; batch adversarial loss: 0.502798\n",
      "epoch 20; iter: 0; batch classifier loss: 0.160550; batch adversarial loss: 0.498037\n",
      "epoch 21; iter: 0; batch classifier loss: 0.124606; batch adversarial loss: 0.430066\n",
      "epoch 22; iter: 0; batch classifier loss: 0.166771; batch adversarial loss: 0.466421\n",
      "epoch 23; iter: 0; batch classifier loss: 0.143645; batch adversarial loss: 0.499216\n",
      "epoch 24; iter: 0; batch classifier loss: 0.147292; batch adversarial loss: 0.514941\n",
      "epoch 25; iter: 0; batch classifier loss: 0.103877; batch adversarial loss: 0.536545\n",
      "epoch 26; iter: 0; batch classifier loss: 0.154865; batch adversarial loss: 0.562700\n",
      "epoch 27; iter: 0; batch classifier loss: 0.135958; batch adversarial loss: 0.440006\n",
      "epoch 28; iter: 0; batch classifier loss: 0.162160; batch adversarial loss: 0.450682\n",
      "epoch 29; iter: 0; batch classifier loss: 0.195360; batch adversarial loss: 0.519246\n",
      "epoch 30; iter: 0; batch classifier loss: 0.239808; batch adversarial loss: 0.540259\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178238; batch adversarial loss: 0.505143\n",
      "epoch 32; iter: 0; batch classifier loss: 0.213614; batch adversarial loss: 0.559754\n",
      "epoch 33; iter: 0; batch classifier loss: 0.168657; batch adversarial loss: 0.474408\n",
      "epoch 34; iter: 0; batch classifier loss: 0.150616; batch adversarial loss: 0.459686\n",
      "epoch 35; iter: 0; batch classifier loss: 0.224053; batch adversarial loss: 0.503330\n",
      "epoch 36; iter: 0; batch classifier loss: 0.238547; batch adversarial loss: 0.571380\n",
      "epoch 37; iter: 0; batch classifier loss: 0.230800; batch adversarial loss: 0.611965\n",
      "epoch 38; iter: 0; batch classifier loss: 0.203147; batch adversarial loss: 0.447767\n",
      "epoch 39; iter: 0; batch classifier loss: 0.129379; batch adversarial loss: 0.390201\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095795; batch adversarial loss: 0.480872\n",
      "epoch 41; iter: 0; batch classifier loss: 0.076369; batch adversarial loss: 0.512434\n",
      "epoch 42; iter: 0; batch classifier loss: 0.052321; batch adversarial loss: 0.540782\n",
      "epoch 43; iter: 0; batch classifier loss: 0.069175; batch adversarial loss: 0.460219\n",
      "epoch 44; iter: 0; batch classifier loss: 0.104938; batch adversarial loss: 0.482709\n",
      "epoch 45; iter: 0; batch classifier loss: 0.093332; batch adversarial loss: 0.360077\n",
      "epoch 46; iter: 0; batch classifier loss: 0.054012; batch adversarial loss: 0.461421\n",
      "epoch 47; iter: 0; batch classifier loss: 0.047096; batch adversarial loss: 0.508364\n",
      "epoch 48; iter: 0; batch classifier loss: 0.095253; batch adversarial loss: 0.470061\n",
      "epoch 49; iter: 0; batch classifier loss: 0.046285; batch adversarial loss: 0.487809\n",
      "epoch 50; iter: 0; batch classifier loss: 0.053632; batch adversarial loss: 0.519055\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083480; batch adversarial loss: 0.446478\n",
      "epoch 52; iter: 0; batch classifier loss: 0.104119; batch adversarial loss: 0.464925\n",
      "epoch 53; iter: 0; batch classifier loss: 0.107865; batch adversarial loss: 0.468572\n",
      "epoch 54; iter: 0; batch classifier loss: 0.117261; batch adversarial loss: 0.467657\n",
      "epoch 55; iter: 0; batch classifier loss: 0.054948; batch adversarial loss: 0.483223\n",
      "epoch 56; iter: 0; batch classifier loss: 0.111900; batch adversarial loss: 0.484843\n",
      "epoch 57; iter: 0; batch classifier loss: 0.069231; batch adversarial loss: 0.534541\n",
      "epoch 58; iter: 0; batch classifier loss: 0.084122; batch adversarial loss: 0.466475\n",
      "epoch 59; iter: 0; batch classifier loss: 0.077525; batch adversarial loss: 0.438064\n",
      "epoch 60; iter: 0; batch classifier loss: 0.070472; batch adversarial loss: 0.513249\n",
      "epoch 61; iter: 0; batch classifier loss: 0.089289; batch adversarial loss: 0.449853\n",
      "epoch 62; iter: 0; batch classifier loss: 0.067727; batch adversarial loss: 0.449702\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085503; batch adversarial loss: 0.448018\n",
      "epoch 64; iter: 0; batch classifier loss: 0.113979; batch adversarial loss: 0.378021\n",
      "epoch 65; iter: 0; batch classifier loss: 0.037331; batch adversarial loss: 0.477026\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066938; batch adversarial loss: 0.477099\n",
      "epoch 67; iter: 0; batch classifier loss: 0.116074; batch adversarial loss: 0.437987\n",
      "epoch 68; iter: 0; batch classifier loss: 0.099829; batch adversarial loss: 0.511688\n",
      "epoch 69; iter: 0; batch classifier loss: 0.040520; batch adversarial loss: 0.511431\n",
      "epoch 70; iter: 0; batch classifier loss: 0.063888; batch adversarial loss: 0.429882\n",
      "epoch 71; iter: 0; batch classifier loss: 0.056497; batch adversarial loss: 0.558835\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082833; batch adversarial loss: 0.384261\n",
      "epoch 73; iter: 0; batch classifier loss: 0.108700; batch adversarial loss: 0.453426\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076899; batch adversarial loss: 0.469582\n",
      "epoch 75; iter: 0; batch classifier loss: 0.098091; batch adversarial loss: 0.409221\n",
      "epoch 76; iter: 0; batch classifier loss: 0.103993; batch adversarial loss: 0.400341\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050406; batch adversarial loss: 0.404688\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082607; batch adversarial loss: 0.462480\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053059; batch adversarial loss: 0.563797\n",
      "epoch 80; iter: 0; batch classifier loss: 0.065633; batch adversarial loss: 0.527059\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057895; batch adversarial loss: 0.484807\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074436; batch adversarial loss: 0.495003\n",
      "epoch 83; iter: 0; batch classifier loss: 0.077037; batch adversarial loss: 0.506731\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065054; batch adversarial loss: 0.492248\n",
      "epoch 85; iter: 0; batch classifier loss: 0.104418; batch adversarial loss: 0.408449\n",
      "epoch 86; iter: 0; batch classifier loss: 0.155195; batch adversarial loss: 0.529671\n",
      "epoch 87; iter: 0; batch classifier loss: 0.114903; batch adversarial loss: 0.466421\n",
      "epoch 88; iter: 0; batch classifier loss: 0.099823; batch adversarial loss: 0.459829\n",
      "epoch 89; iter: 0; batch classifier loss: 0.100770; batch adversarial loss: 0.400850\n",
      "epoch 90; iter: 0; batch classifier loss: 0.098718; batch adversarial loss: 0.384725\n",
      "epoch 91; iter: 0; batch classifier loss: 0.112629; batch adversarial loss: 0.437722\n",
      "epoch 92; iter: 0; batch classifier loss: 0.091752; batch adversarial loss: 0.462479\n",
      "epoch 93; iter: 0; batch classifier loss: 0.085180; batch adversarial loss: 0.411902\n",
      "epoch 94; iter: 0; batch classifier loss: 0.138913; batch adversarial loss: 0.447169\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080706; batch adversarial loss: 0.421828\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063841; batch adversarial loss: 0.419799\n",
      "epoch 97; iter: 0; batch classifier loss: 0.082937; batch adversarial loss: 0.509902\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059562; batch adversarial loss: 0.501094\n",
      "epoch 99; iter: 0; batch classifier loss: 0.118565; batch adversarial loss: 0.440688\n",
      "epoch 100; iter: 0; batch classifier loss: 0.090152; batch adversarial loss: 0.410234\n",
      "epoch 101; iter: 0; batch classifier loss: 0.091323; batch adversarial loss: 0.454699\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054902; batch adversarial loss: 0.426407\n",
      "epoch 103; iter: 0; batch classifier loss: 0.097791; batch adversarial loss: 0.478140\n",
      "epoch 104; iter: 0; batch classifier loss: 0.098757; batch adversarial loss: 0.503153\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052879; batch adversarial loss: 0.511407\n",
      "epoch 106; iter: 0; batch classifier loss: 0.060469; batch adversarial loss: 0.464586\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034595; batch adversarial loss: 0.306353\n",
      "epoch 108; iter: 0; batch classifier loss: 0.035665; batch adversarial loss: 0.459377\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066392; batch adversarial loss: 0.406102\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023654; batch adversarial loss: 0.477207\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048697; batch adversarial loss: 0.406283\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063850; batch adversarial loss: 0.545062\n",
      "epoch 113; iter: 0; batch classifier loss: 0.068456; batch adversarial loss: 0.523234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.060964; batch adversarial loss: 0.494090\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065934; batch adversarial loss: 0.498812\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045182; batch adversarial loss: 0.471602\n",
      "epoch 117; iter: 0; batch classifier loss: 0.054620; batch adversarial loss: 0.460199\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035255; batch adversarial loss: 0.442463\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044417; batch adversarial loss: 0.470256\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047603; batch adversarial loss: 0.485016\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042636; batch adversarial loss: 0.515177\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045336; batch adversarial loss: 0.549939\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036647; batch adversarial loss: 0.453415\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054176; batch adversarial loss: 0.476400\n",
      "epoch 125; iter: 0; batch classifier loss: 0.076783; batch adversarial loss: 0.434927\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037511; batch adversarial loss: 0.430871\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046605; batch adversarial loss: 0.404318\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039586; batch adversarial loss: 0.559198\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019834; batch adversarial loss: 0.443897\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040665; batch adversarial loss: 0.503441\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034296; batch adversarial loss: 0.530942\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036243; batch adversarial loss: 0.438147\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026920; batch adversarial loss: 0.365182\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048554; batch adversarial loss: 0.551195\n",
      "epoch 135; iter: 0; batch classifier loss: 0.079316; batch adversarial loss: 0.403206\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034516; batch adversarial loss: 0.442221\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043748; batch adversarial loss: 0.434430\n",
      "epoch 138; iter: 0; batch classifier loss: 0.054942; batch adversarial loss: 0.425405\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050431; batch adversarial loss: 0.372043\n",
      "epoch 140; iter: 0; batch classifier loss: 0.082207; batch adversarial loss: 0.471505\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036849; batch adversarial loss: 0.448002\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033567; batch adversarial loss: 0.592300\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028485; batch adversarial loss: 0.445002\n",
      "epoch 144; iter: 0; batch classifier loss: 0.046057; batch adversarial loss: 0.463338\n",
      "epoch 145; iter: 0; batch classifier loss: 0.056256; batch adversarial loss: 0.480014\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052212; batch adversarial loss: 0.502888\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022487; batch adversarial loss: 0.430690\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040654; batch adversarial loss: 0.443486\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035666; batch adversarial loss: 0.438040\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033645; batch adversarial loss: 0.468107\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016221; batch adversarial loss: 0.470082\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024421; batch adversarial loss: 0.358637\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024628; batch adversarial loss: 0.415712\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028741; batch adversarial loss: 0.538029\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052514; batch adversarial loss: 0.456445\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026851; batch adversarial loss: 0.402082\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035325; batch adversarial loss: 0.443067\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022902; batch adversarial loss: 0.477798\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021575; batch adversarial loss: 0.467563\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012831; batch adversarial loss: 0.524003\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020805; batch adversarial loss: 0.529798\n",
      "epoch 162; iter: 0; batch classifier loss: 0.044878; batch adversarial loss: 0.430458\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042021; batch adversarial loss: 0.408550\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032286; batch adversarial loss: 0.485499\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012525; batch adversarial loss: 0.496097\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024893; batch adversarial loss: 0.462728\n",
      "epoch 167; iter: 0; batch classifier loss: 0.076091; batch adversarial loss: 0.476580\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014184; batch adversarial loss: 0.498688\n",
      "epoch 169; iter: 0; batch classifier loss: 0.048676; batch adversarial loss: 0.403960\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017764; batch adversarial loss: 0.458136\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030519; batch adversarial loss: 0.585934\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014701; batch adversarial loss: 0.428094\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023095; batch adversarial loss: 0.500512\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037187; batch adversarial loss: 0.541789\n",
      "epoch 175; iter: 0; batch classifier loss: 0.049630; batch adversarial loss: 0.524188\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021777; batch adversarial loss: 0.406071\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036461; batch adversarial loss: 0.550442\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014740; batch adversarial loss: 0.533728\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018596; batch adversarial loss: 0.485461\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039759; batch adversarial loss: 0.473404\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007666; batch adversarial loss: 0.458839\n",
      "epoch 182; iter: 0; batch classifier loss: 0.054116; batch adversarial loss: 0.524950\n",
      "epoch 183; iter: 0; batch classifier loss: 0.039231; batch adversarial loss: 0.485735\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027377; batch adversarial loss: 0.420114\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017391; batch adversarial loss: 0.481656\n",
      "epoch 186; iter: 0; batch classifier loss: 0.039215; batch adversarial loss: 0.456999\n",
      "epoch 187; iter: 0; batch classifier loss: 0.037200; batch adversarial loss: 0.508826\n",
      "epoch 188; iter: 0; batch classifier loss: 0.004374; batch adversarial loss: 0.499215\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020010; batch adversarial loss: 0.505046\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016917; batch adversarial loss: 0.382722\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024625; batch adversarial loss: 0.464388\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018014; batch adversarial loss: 0.486397\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013978; batch adversarial loss: 0.379341\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021108; batch adversarial loss: 0.375827\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017811; batch adversarial loss: 0.502249\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014806; batch adversarial loss: 0.465329\n",
      "epoch 197; iter: 0; batch classifier loss: 0.035790; batch adversarial loss: 0.499648\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009823; batch adversarial loss: 0.530097\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018757; batch adversarial loss: 0.458762\n",
      "epoch 0; iter: 0; batch classifier loss: 0.759674; batch adversarial loss: 0.522664\n",
      "epoch 1; iter: 0; batch classifier loss: 0.486664; batch adversarial loss: 0.569864\n",
      "epoch 2; iter: 0; batch classifier loss: 0.489002; batch adversarial loss: 0.578596\n",
      "epoch 3; iter: 0; batch classifier loss: 0.314153; batch adversarial loss: 0.565308\n",
      "epoch 4; iter: 0; batch classifier loss: 0.460966; batch adversarial loss: 0.533788\n",
      "epoch 5; iter: 0; batch classifier loss: 0.353394; batch adversarial loss: 0.577639\n",
      "epoch 6; iter: 0; batch classifier loss: 0.404453; batch adversarial loss: 0.527983\n",
      "epoch 7; iter: 0; batch classifier loss: 0.314491; batch adversarial loss: 0.561019\n",
      "epoch 8; iter: 0; batch classifier loss: 0.370407; batch adversarial loss: 0.636836\n",
      "epoch 9; iter: 0; batch classifier loss: 0.473730; batch adversarial loss: 0.530183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.402195; batch adversarial loss: 0.623165\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521403; batch adversarial loss: 0.566230\n",
      "epoch 12; iter: 0; batch classifier loss: 0.517817; batch adversarial loss: 0.539937\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540736; batch adversarial loss: 0.590349\n",
      "epoch 14; iter: 0; batch classifier loss: 0.426505; batch adversarial loss: 0.560488\n",
      "epoch 15; iter: 0; batch classifier loss: 0.341246; batch adversarial loss: 0.562162\n",
      "epoch 16; iter: 0; batch classifier loss: 0.380438; batch adversarial loss: 0.471527\n",
      "epoch 17; iter: 0; batch classifier loss: 0.233249; batch adversarial loss: 0.522483\n",
      "epoch 18; iter: 0; batch classifier loss: 0.254708; batch adversarial loss: 0.445397\n",
      "epoch 19; iter: 0; batch classifier loss: 0.287082; batch adversarial loss: 0.447171\n",
      "epoch 20; iter: 0; batch classifier loss: 0.203563; batch adversarial loss: 0.516194\n",
      "epoch 21; iter: 0; batch classifier loss: 0.175730; batch adversarial loss: 0.390020\n",
      "epoch 22; iter: 0; batch classifier loss: 0.262646; batch adversarial loss: 0.445515\n",
      "epoch 23; iter: 0; batch classifier loss: 0.182584; batch adversarial loss: 0.368336\n",
      "epoch 24; iter: 0; batch classifier loss: 0.170894; batch adversarial loss: 0.503063\n",
      "epoch 25; iter: 0; batch classifier loss: 0.227319; batch adversarial loss: 0.363776\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181470; batch adversarial loss: 0.409843\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162550; batch adversarial loss: 0.427420\n",
      "epoch 28; iter: 0; batch classifier loss: 0.118304; batch adversarial loss: 0.456527\n",
      "epoch 29; iter: 0; batch classifier loss: 0.123616; batch adversarial loss: 0.364080\n",
      "epoch 30; iter: 0; batch classifier loss: 0.123378; batch adversarial loss: 0.551073\n",
      "epoch 31; iter: 0; batch classifier loss: 0.128569; batch adversarial loss: 0.346281\n",
      "epoch 32; iter: 0; batch classifier loss: 0.122821; batch adversarial loss: 0.502255\n",
      "epoch 33; iter: 0; batch classifier loss: 0.139978; batch adversarial loss: 0.446789\n",
      "epoch 34; iter: 0; batch classifier loss: 0.156044; batch adversarial loss: 0.435051\n",
      "epoch 35; iter: 0; batch classifier loss: 0.099399; batch adversarial loss: 0.539795\n",
      "epoch 36; iter: 0; batch classifier loss: 0.083521; batch adversarial loss: 0.455678\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110330; batch adversarial loss: 0.468272\n",
      "epoch 38; iter: 0; batch classifier loss: 0.093467; batch adversarial loss: 0.430385\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126270; batch adversarial loss: 0.434310\n",
      "epoch 40; iter: 0; batch classifier loss: 0.135384; batch adversarial loss: 0.473299\n",
      "epoch 41; iter: 0; batch classifier loss: 0.109154; batch adversarial loss: 0.411223\n",
      "epoch 42; iter: 0; batch classifier loss: 0.099619; batch adversarial loss: 0.427016\n",
      "epoch 43; iter: 0; batch classifier loss: 0.075103; batch adversarial loss: 0.409165\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123352; batch adversarial loss: 0.489357\n",
      "epoch 45; iter: 0; batch classifier loss: 0.151558; batch adversarial loss: 0.449610\n",
      "epoch 46; iter: 0; batch classifier loss: 0.097094; batch adversarial loss: 0.397500\n",
      "epoch 47; iter: 0; batch classifier loss: 0.115646; batch adversarial loss: 0.486379\n",
      "epoch 48; iter: 0; batch classifier loss: 0.144230; batch adversarial loss: 0.447058\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107626; batch adversarial loss: 0.440830\n",
      "epoch 50; iter: 0; batch classifier loss: 0.104750; batch adversarial loss: 0.423771\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098027; batch adversarial loss: 0.465532\n",
      "epoch 52; iter: 0; batch classifier loss: 0.123022; batch adversarial loss: 0.481863\n",
      "epoch 53; iter: 0; batch classifier loss: 0.077911; batch adversarial loss: 0.411017\n",
      "epoch 54; iter: 0; batch classifier loss: 0.139963; batch adversarial loss: 0.388721\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091612; batch adversarial loss: 0.471177\n",
      "epoch 56; iter: 0; batch classifier loss: 0.159975; batch adversarial loss: 0.395935\n",
      "epoch 57; iter: 0; batch classifier loss: 0.210631; batch adversarial loss: 0.564787\n",
      "epoch 58; iter: 0; batch classifier loss: 0.130635; batch adversarial loss: 0.482248\n",
      "epoch 59; iter: 0; batch classifier loss: 0.119551; batch adversarial loss: 0.430010\n",
      "epoch 60; iter: 0; batch classifier loss: 0.114150; batch adversarial loss: 0.476869\n",
      "epoch 61; iter: 0; batch classifier loss: 0.167875; batch adversarial loss: 0.451598\n",
      "epoch 62; iter: 0; batch classifier loss: 0.123308; batch adversarial loss: 0.346834\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095857; batch adversarial loss: 0.414820\n",
      "epoch 64; iter: 0; batch classifier loss: 0.128344; batch adversarial loss: 0.401389\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088867; batch adversarial loss: 0.467718\n",
      "epoch 66; iter: 0; batch classifier loss: 0.098332; batch adversarial loss: 0.414615\n",
      "epoch 67; iter: 0; batch classifier loss: 0.168650; batch adversarial loss: 0.430459\n",
      "epoch 68; iter: 0; batch classifier loss: 0.205763; batch adversarial loss: 0.376186\n",
      "epoch 69; iter: 0; batch classifier loss: 0.125769; batch adversarial loss: 0.431075\n",
      "epoch 70; iter: 0; batch classifier loss: 0.114247; batch adversarial loss: 0.547075\n",
      "epoch 71; iter: 0; batch classifier loss: 0.117831; batch adversarial loss: 0.465300\n",
      "epoch 72; iter: 0; batch classifier loss: 0.147442; batch adversarial loss: 0.402122\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084883; batch adversarial loss: 0.540488\n",
      "epoch 74; iter: 0; batch classifier loss: 0.139714; batch adversarial loss: 0.381259\n",
      "epoch 75; iter: 0; batch classifier loss: 0.141469; batch adversarial loss: 0.527910\n",
      "epoch 76; iter: 0; batch classifier loss: 0.223356; batch adversarial loss: 0.395707\n",
      "epoch 77; iter: 0; batch classifier loss: 0.121756; batch adversarial loss: 0.382195\n",
      "epoch 78; iter: 0; batch classifier loss: 0.124704; batch adversarial loss: 0.448387\n",
      "epoch 79; iter: 0; batch classifier loss: 0.201319; batch adversarial loss: 0.555050\n",
      "epoch 80; iter: 0; batch classifier loss: 0.158888; batch adversarial loss: 0.446020\n",
      "epoch 81; iter: 0; batch classifier loss: 0.109781; batch adversarial loss: 0.491400\n",
      "epoch 82; iter: 0; batch classifier loss: 0.161817; batch adversarial loss: 0.394480\n",
      "epoch 83; iter: 0; batch classifier loss: 0.113762; batch adversarial loss: 0.427990\n",
      "epoch 84; iter: 0; batch classifier loss: 0.114903; batch adversarial loss: 0.492176\n",
      "epoch 85; iter: 0; batch classifier loss: 0.139458; batch adversarial loss: 0.391958\n",
      "epoch 86; iter: 0; batch classifier loss: 0.134746; batch adversarial loss: 0.451290\n",
      "epoch 87; iter: 0; batch classifier loss: 0.165768; batch adversarial loss: 0.438833\n",
      "epoch 88; iter: 0; batch classifier loss: 0.081912; batch adversarial loss: 0.421400\n",
      "epoch 89; iter: 0; batch classifier loss: 0.155725; batch adversarial loss: 0.469201\n",
      "epoch 90; iter: 0; batch classifier loss: 0.190505; batch adversarial loss: 0.384472\n",
      "epoch 91; iter: 0; batch classifier loss: 0.168027; batch adversarial loss: 0.533229\n",
      "epoch 92; iter: 0; batch classifier loss: 0.162888; batch adversarial loss: 0.528166\n",
      "epoch 93; iter: 0; batch classifier loss: 0.147885; batch adversarial loss: 0.399047\n",
      "epoch 94; iter: 0; batch classifier loss: 0.153693; batch adversarial loss: 0.405705\n",
      "epoch 95; iter: 0; batch classifier loss: 0.166209; batch adversarial loss: 0.495726\n",
      "epoch 96; iter: 0; batch classifier loss: 0.121221; batch adversarial loss: 0.476591\n",
      "epoch 97; iter: 0; batch classifier loss: 0.109563; batch adversarial loss: 0.455708\n",
      "epoch 98; iter: 0; batch classifier loss: 0.152669; batch adversarial loss: 0.464141\n",
      "epoch 99; iter: 0; batch classifier loss: 0.132395; batch adversarial loss: 0.442825\n",
      "epoch 100; iter: 0; batch classifier loss: 0.086546; batch adversarial loss: 0.464660\n",
      "epoch 101; iter: 0; batch classifier loss: 0.154194; batch adversarial loss: 0.453305\n",
      "epoch 102; iter: 0; batch classifier loss: 0.102164; batch adversarial loss: 0.387814\n",
      "epoch 103; iter: 0; batch classifier loss: 0.126254; batch adversarial loss: 0.493033\n",
      "epoch 104; iter: 0; batch classifier loss: 0.133005; batch adversarial loss: 0.430840\n",
      "epoch 105; iter: 0; batch classifier loss: 0.112230; batch adversarial loss: 0.464490\n",
      "epoch 106; iter: 0; batch classifier loss: 0.126432; batch adversarial loss: 0.503070\n",
      "epoch 107; iter: 0; batch classifier loss: 0.132059; batch adversarial loss: 0.452053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.144788; batch adversarial loss: 0.399568\n",
      "epoch 109; iter: 0; batch classifier loss: 0.151519; batch adversarial loss: 0.464513\n",
      "epoch 110; iter: 0; batch classifier loss: 0.124544; batch adversarial loss: 0.490887\n",
      "epoch 111; iter: 0; batch classifier loss: 0.143163; batch adversarial loss: 0.454697\n",
      "epoch 112; iter: 0; batch classifier loss: 0.148031; batch adversarial loss: 0.486867\n",
      "epoch 113; iter: 0; batch classifier loss: 0.066271; batch adversarial loss: 0.461834\n",
      "epoch 114; iter: 0; batch classifier loss: 0.132953; batch adversarial loss: 0.447843\n",
      "epoch 115; iter: 0; batch classifier loss: 0.190881; batch adversarial loss: 0.328940\n",
      "epoch 116; iter: 0; batch classifier loss: 0.179566; batch adversarial loss: 0.487940\n",
      "epoch 117; iter: 0; batch classifier loss: 0.124636; batch adversarial loss: 0.398889\n",
      "epoch 118; iter: 0; batch classifier loss: 0.170687; batch adversarial loss: 0.551841\n",
      "epoch 119; iter: 0; batch classifier loss: 0.108914; batch adversarial loss: 0.463619\n",
      "epoch 120; iter: 0; batch classifier loss: 0.143833; batch adversarial loss: 0.435869\n",
      "epoch 121; iter: 0; batch classifier loss: 0.115951; batch adversarial loss: 0.481581\n",
      "epoch 122; iter: 0; batch classifier loss: 0.149098; batch adversarial loss: 0.366268\n",
      "epoch 123; iter: 0; batch classifier loss: 0.146601; batch adversarial loss: 0.446330\n",
      "epoch 124; iter: 0; batch classifier loss: 0.189019; batch adversarial loss: 0.515945\n",
      "epoch 125; iter: 0; batch classifier loss: 0.154760; batch adversarial loss: 0.439258\n",
      "epoch 126; iter: 0; batch classifier loss: 0.148817; batch adversarial loss: 0.436131\n",
      "epoch 127; iter: 0; batch classifier loss: 0.198216; batch adversarial loss: 0.456800\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058557; batch adversarial loss: 0.441922\n",
      "epoch 129; iter: 0; batch classifier loss: 0.171113; batch adversarial loss: 0.474224\n",
      "epoch 130; iter: 0; batch classifier loss: 0.150895; batch adversarial loss: 0.394152\n",
      "epoch 131; iter: 0; batch classifier loss: 0.137567; batch adversarial loss: 0.516034\n",
      "epoch 132; iter: 0; batch classifier loss: 0.132537; batch adversarial loss: 0.499252\n",
      "epoch 133; iter: 0; batch classifier loss: 0.215811; batch adversarial loss: 0.379647\n",
      "epoch 134; iter: 0; batch classifier loss: 0.272725; batch adversarial loss: 0.499882\n",
      "epoch 135; iter: 0; batch classifier loss: 0.218855; batch adversarial loss: 0.526470\n",
      "epoch 136; iter: 0; batch classifier loss: 0.220002; batch adversarial loss: 0.456825\n",
      "epoch 137; iter: 0; batch classifier loss: 0.187777; batch adversarial loss: 0.427282\n",
      "epoch 138; iter: 0; batch classifier loss: 0.258205; batch adversarial loss: 0.429676\n",
      "epoch 139; iter: 0; batch classifier loss: 0.260237; batch adversarial loss: 0.508408\n",
      "epoch 140; iter: 0; batch classifier loss: 0.220782; batch adversarial loss: 0.457893\n",
      "epoch 141; iter: 0; batch classifier loss: 0.200574; batch adversarial loss: 0.382560\n",
      "epoch 142; iter: 0; batch classifier loss: 0.239857; batch adversarial loss: 0.384349\n",
      "epoch 143; iter: 0; batch classifier loss: 0.282908; batch adversarial loss: 0.394263\n",
      "epoch 144; iter: 0; batch classifier loss: 0.327087; batch adversarial loss: 0.435253\n",
      "epoch 145; iter: 0; batch classifier loss: 0.217410; batch adversarial loss: 0.447917\n",
      "epoch 146; iter: 0; batch classifier loss: 0.247204; batch adversarial loss: 0.446715\n",
      "epoch 147; iter: 0; batch classifier loss: 0.277904; batch adversarial loss: 0.498016\n",
      "epoch 148; iter: 0; batch classifier loss: 0.301354; batch adversarial loss: 0.436415\n",
      "epoch 149; iter: 0; batch classifier loss: 0.309478; batch adversarial loss: 0.473305\n",
      "epoch 150; iter: 0; batch classifier loss: 0.315071; batch adversarial loss: 0.435661\n",
      "epoch 151; iter: 0; batch classifier loss: 0.270753; batch adversarial loss: 0.506558\n",
      "epoch 152; iter: 0; batch classifier loss: 0.205729; batch adversarial loss: 0.459146\n",
      "epoch 153; iter: 0; batch classifier loss: 0.244816; batch adversarial loss: 0.496034\n",
      "epoch 154; iter: 0; batch classifier loss: 0.234707; batch adversarial loss: 0.532858\n",
      "epoch 155; iter: 0; batch classifier loss: 0.244475; batch adversarial loss: 0.397821\n",
      "epoch 156; iter: 0; batch classifier loss: 0.148251; batch adversarial loss: 0.459984\n",
      "epoch 157; iter: 0; batch classifier loss: 0.094273; batch adversarial loss: 0.496469\n",
      "epoch 158; iter: 0; batch classifier loss: 0.178445; batch adversarial loss: 0.432290\n",
      "epoch 159; iter: 0; batch classifier loss: 0.238511; batch adversarial loss: 0.345885\n",
      "epoch 160; iter: 0; batch classifier loss: 0.216387; batch adversarial loss: 0.361245\n",
      "epoch 161; iter: 0; batch classifier loss: 0.188940; batch adversarial loss: 0.482652\n",
      "epoch 162; iter: 0; batch classifier loss: 0.192562; batch adversarial loss: 0.495458\n",
      "epoch 163; iter: 0; batch classifier loss: 0.193555; batch adversarial loss: 0.459174\n",
      "epoch 164; iter: 0; batch classifier loss: 0.257048; batch adversarial loss: 0.483692\n",
      "epoch 165; iter: 0; batch classifier loss: 0.261341; batch adversarial loss: 0.347104\n",
      "epoch 166; iter: 0; batch classifier loss: 0.251298; batch adversarial loss: 0.446341\n",
      "epoch 167; iter: 0; batch classifier loss: 0.198870; batch adversarial loss: 0.558144\n",
      "epoch 168; iter: 0; batch classifier loss: 0.227602; batch adversarial loss: 0.483344\n",
      "epoch 169; iter: 0; batch classifier loss: 0.128799; batch adversarial loss: 0.458741\n",
      "epoch 170; iter: 0; batch classifier loss: 0.090519; batch adversarial loss: 0.483644\n",
      "epoch 171; iter: 0; batch classifier loss: 0.192111; batch adversarial loss: 0.520339\n",
      "epoch 172; iter: 0; batch classifier loss: 0.194585; batch adversarial loss: 0.546878\n",
      "epoch 173; iter: 0; batch classifier loss: 0.212285; batch adversarial loss: 0.521912\n",
      "epoch 174; iter: 0; batch classifier loss: 0.231005; batch adversarial loss: 0.482335\n",
      "epoch 175; iter: 0; batch classifier loss: 0.207114; batch adversarial loss: 0.470856\n",
      "epoch 176; iter: 0; batch classifier loss: 0.170274; batch adversarial loss: 0.347032\n",
      "epoch 177; iter: 0; batch classifier loss: 0.237403; batch adversarial loss: 0.421336\n",
      "epoch 178; iter: 0; batch classifier loss: 0.285188; batch adversarial loss: 0.483807\n",
      "epoch 179; iter: 0; batch classifier loss: 0.179650; batch adversarial loss: 0.471884\n",
      "epoch 180; iter: 0; batch classifier loss: 0.212277; batch adversarial loss: 0.384855\n",
      "epoch 181; iter: 0; batch classifier loss: 0.209189; batch adversarial loss: 0.532913\n",
      "epoch 182; iter: 0; batch classifier loss: 0.256425; batch adversarial loss: 0.507735\n",
      "epoch 183; iter: 0; batch classifier loss: 0.203012; batch adversarial loss: 0.409036\n",
      "epoch 184; iter: 0; batch classifier loss: 0.121610; batch adversarial loss: 0.534340\n",
      "epoch 185; iter: 0; batch classifier loss: 0.259303; batch adversarial loss: 0.434367\n",
      "epoch 186; iter: 0; batch classifier loss: 0.242322; batch adversarial loss: 0.520735\n",
      "epoch 187; iter: 0; batch classifier loss: 0.237056; batch adversarial loss: 0.408974\n",
      "epoch 188; iter: 0; batch classifier loss: 0.203869; batch adversarial loss: 0.533024\n",
      "epoch 189; iter: 0; batch classifier loss: 0.222327; batch adversarial loss: 0.420639\n",
      "epoch 190; iter: 0; batch classifier loss: 0.133428; batch adversarial loss: 0.496556\n",
      "epoch 191; iter: 0; batch classifier loss: 0.236195; batch adversarial loss: 0.497585\n",
      "epoch 192; iter: 0; batch classifier loss: 0.219886; batch adversarial loss: 0.484249\n",
      "epoch 193; iter: 0; batch classifier loss: 0.222744; batch adversarial loss: 0.458683\n",
      "epoch 194; iter: 0; batch classifier loss: 0.150896; batch adversarial loss: 0.409945\n",
      "epoch 195; iter: 0; batch classifier loss: 0.164904; batch adversarial loss: 0.432730\n",
      "epoch 196; iter: 0; batch classifier loss: 0.133577; batch adversarial loss: 0.458970\n",
      "epoch 197; iter: 0; batch classifier loss: 0.150370; batch adversarial loss: 0.507473\n",
      "epoch 198; iter: 0; batch classifier loss: 0.131652; batch adversarial loss: 0.429870\n",
      "epoch 199; iter: 0; batch classifier loss: 0.111440; batch adversarial loss: 0.430860\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713252; batch adversarial loss: 0.542171\n",
      "epoch 1; iter: 0; batch classifier loss: 0.447551; batch adversarial loss: 0.597010\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396571; batch adversarial loss: 0.625794\n",
      "epoch 3; iter: 0; batch classifier loss: 0.359342; batch adversarial loss: 0.609895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.391898; batch adversarial loss: 0.564893\n",
      "epoch 5; iter: 0; batch classifier loss: 0.323617; batch adversarial loss: 0.569587\n",
      "epoch 6; iter: 0; batch classifier loss: 0.448971; batch adversarial loss: 0.582485\n",
      "epoch 7; iter: 0; batch classifier loss: 0.371313; batch adversarial loss: 0.556077\n",
      "epoch 8; iter: 0; batch classifier loss: 0.337738; batch adversarial loss: 0.566021\n",
      "epoch 9; iter: 0; batch classifier loss: 0.429640; batch adversarial loss: 0.591885\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472875; batch adversarial loss: 0.614334\n",
      "epoch 11; iter: 0; batch classifier loss: 0.559215; batch adversarial loss: 0.523514\n",
      "epoch 12; iter: 0; batch classifier loss: 0.639702; batch adversarial loss: 0.584156\n",
      "epoch 13; iter: 0; batch classifier loss: 0.439747; batch adversarial loss: 0.529667\n",
      "epoch 14; iter: 0; batch classifier loss: 0.282607; batch adversarial loss: 0.575418\n",
      "epoch 15; iter: 0; batch classifier loss: 0.254542; batch adversarial loss: 0.507894\n",
      "epoch 16; iter: 0; batch classifier loss: 0.262151; batch adversarial loss: 0.498366\n",
      "epoch 17; iter: 0; batch classifier loss: 0.260826; batch adversarial loss: 0.522722\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246472; batch adversarial loss: 0.452243\n",
      "epoch 19; iter: 0; batch classifier loss: 0.205380; batch adversarial loss: 0.450807\n",
      "epoch 20; iter: 0; batch classifier loss: 0.218364; batch adversarial loss: 0.465007\n",
      "epoch 21; iter: 0; batch classifier loss: 0.168953; batch adversarial loss: 0.461252\n",
      "epoch 22; iter: 0; batch classifier loss: 0.219667; batch adversarial loss: 0.467231\n",
      "epoch 23; iter: 0; batch classifier loss: 0.174730; batch adversarial loss: 0.492663\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199757; batch adversarial loss: 0.467816\n",
      "epoch 25; iter: 0; batch classifier loss: 0.199110; batch adversarial loss: 0.456582\n",
      "epoch 26; iter: 0; batch classifier loss: 0.189894; batch adversarial loss: 0.507152\n",
      "epoch 27; iter: 0; batch classifier loss: 0.138684; batch adversarial loss: 0.375897\n",
      "epoch 28; iter: 0; batch classifier loss: 0.142900; batch adversarial loss: 0.466398\n",
      "epoch 29; iter: 0; batch classifier loss: 0.129469; batch adversarial loss: 0.383328\n",
      "epoch 30; iter: 0; batch classifier loss: 0.152909; batch adversarial loss: 0.595939\n",
      "epoch 31; iter: 0; batch classifier loss: 0.099998; batch adversarial loss: 0.505621\n",
      "epoch 32; iter: 0; batch classifier loss: 0.152299; batch adversarial loss: 0.435297\n",
      "epoch 33; iter: 0; batch classifier loss: 0.111426; batch adversarial loss: 0.483848\n",
      "epoch 34; iter: 0; batch classifier loss: 0.121516; batch adversarial loss: 0.445275\n",
      "epoch 35; iter: 0; batch classifier loss: 0.133528; batch adversarial loss: 0.495676\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109385; batch adversarial loss: 0.367860\n",
      "epoch 37; iter: 0; batch classifier loss: 0.098459; batch adversarial loss: 0.476947\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126351; batch adversarial loss: 0.479504\n",
      "epoch 39; iter: 0; batch classifier loss: 0.099823; batch adversarial loss: 0.422997\n",
      "epoch 40; iter: 0; batch classifier loss: 0.123549; batch adversarial loss: 0.439914\n",
      "epoch 41; iter: 0; batch classifier loss: 0.087309; batch adversarial loss: 0.537640\n",
      "epoch 42; iter: 0; batch classifier loss: 0.095189; batch adversarial loss: 0.571862\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150865; batch adversarial loss: 0.503945\n",
      "epoch 44; iter: 0; batch classifier loss: 0.087946; batch adversarial loss: 0.514933\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091371; batch adversarial loss: 0.462179\n",
      "epoch 46; iter: 0; batch classifier loss: 0.106506; batch adversarial loss: 0.549433\n",
      "epoch 47; iter: 0; batch classifier loss: 0.087116; batch adversarial loss: 0.455122\n",
      "epoch 48; iter: 0; batch classifier loss: 0.086386; batch adversarial loss: 0.442864\n",
      "epoch 49; iter: 0; batch classifier loss: 0.081597; batch adversarial loss: 0.447846\n",
      "epoch 50; iter: 0; batch classifier loss: 0.126736; batch adversarial loss: 0.500962\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109685; batch adversarial loss: 0.455386\n",
      "epoch 52; iter: 0; batch classifier loss: 0.079964; batch adversarial loss: 0.448876\n",
      "epoch 53; iter: 0; batch classifier loss: 0.167417; batch adversarial loss: 0.376776\n",
      "epoch 54; iter: 0; batch classifier loss: 0.060783; batch adversarial loss: 0.424458\n",
      "epoch 55; iter: 0; batch classifier loss: 0.116015; batch adversarial loss: 0.471146\n",
      "epoch 56; iter: 0; batch classifier loss: 0.095187; batch adversarial loss: 0.355273\n",
      "epoch 57; iter: 0; batch classifier loss: 0.092683; batch adversarial loss: 0.444926\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097709; batch adversarial loss: 0.419100\n",
      "epoch 59; iter: 0; batch classifier loss: 0.089274; batch adversarial loss: 0.543569\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086039; batch adversarial loss: 0.429042\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093928; batch adversarial loss: 0.397139\n",
      "epoch 62; iter: 0; batch classifier loss: 0.046893; batch adversarial loss: 0.403685\n",
      "epoch 63; iter: 0; batch classifier loss: 0.079549; batch adversarial loss: 0.470314\n",
      "epoch 64; iter: 0; batch classifier loss: 0.110504; batch adversarial loss: 0.462267\n",
      "epoch 65; iter: 0; batch classifier loss: 0.080583; batch adversarial loss: 0.458008\n",
      "epoch 66; iter: 0; batch classifier loss: 0.076973; batch adversarial loss: 0.454394\n",
      "epoch 67; iter: 0; batch classifier loss: 0.145690; batch adversarial loss: 0.493560\n",
      "epoch 68; iter: 0; batch classifier loss: 0.065805; batch adversarial loss: 0.412676\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095482; batch adversarial loss: 0.501807\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066863; batch adversarial loss: 0.478613\n",
      "epoch 71; iter: 0; batch classifier loss: 0.077250; batch adversarial loss: 0.371586\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080333; batch adversarial loss: 0.371694\n",
      "epoch 73; iter: 0; batch classifier loss: 0.081770; batch adversarial loss: 0.456641\n",
      "epoch 74; iter: 0; batch classifier loss: 0.052894; batch adversarial loss: 0.558435\n",
      "epoch 75; iter: 0; batch classifier loss: 0.052967; batch adversarial loss: 0.488726\n",
      "epoch 76; iter: 0; batch classifier loss: 0.095650; batch adversarial loss: 0.477082\n",
      "epoch 77; iter: 0; batch classifier loss: 0.108079; batch adversarial loss: 0.412642\n",
      "epoch 78; iter: 0; batch classifier loss: 0.092894; batch adversarial loss: 0.485064\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057864; batch adversarial loss: 0.399118\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076303; batch adversarial loss: 0.425442\n",
      "epoch 81; iter: 0; batch classifier loss: 0.049546; batch adversarial loss: 0.400936\n",
      "epoch 82; iter: 0; batch classifier loss: 0.076715; batch adversarial loss: 0.504411\n",
      "epoch 83; iter: 0; batch classifier loss: 0.021292; batch adversarial loss: 0.508069\n",
      "epoch 84; iter: 0; batch classifier loss: 0.047112; batch adversarial loss: 0.336653\n",
      "epoch 85; iter: 0; batch classifier loss: 0.028207; batch adversarial loss: 0.534317\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046756; batch adversarial loss: 0.509083\n",
      "epoch 87; iter: 0; batch classifier loss: 0.083309; batch adversarial loss: 0.452381\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058113; batch adversarial loss: 0.490082\n",
      "epoch 89; iter: 0; batch classifier loss: 0.108214; batch adversarial loss: 0.467123\n",
      "epoch 90; iter: 0; batch classifier loss: 0.045583; batch adversarial loss: 0.483928\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083244; batch adversarial loss: 0.477497\n",
      "epoch 92; iter: 0; batch classifier loss: 0.035199; batch adversarial loss: 0.488641\n",
      "epoch 93; iter: 0; batch classifier loss: 0.066481; batch adversarial loss: 0.460420\n",
      "epoch 94; iter: 0; batch classifier loss: 0.084322; batch adversarial loss: 0.449741\n",
      "epoch 95; iter: 0; batch classifier loss: 0.078975; batch adversarial loss: 0.478420\n",
      "epoch 96; iter: 0; batch classifier loss: 0.080217; batch adversarial loss: 0.499163\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044594; batch adversarial loss: 0.546901\n",
      "epoch 98; iter: 0; batch classifier loss: 0.070828; batch adversarial loss: 0.450116\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057648; batch adversarial loss: 0.477653\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057120; batch adversarial loss: 0.537849\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040086; batch adversarial loss: 0.488131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.056876; batch adversarial loss: 0.433700\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035444; batch adversarial loss: 0.507713\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057298; batch adversarial loss: 0.566178\n",
      "epoch 105; iter: 0; batch classifier loss: 0.019122; batch adversarial loss: 0.560749\n",
      "epoch 106; iter: 0; batch classifier loss: 0.060439; batch adversarial loss: 0.410393\n",
      "epoch 107; iter: 0; batch classifier loss: 0.064777; batch adversarial loss: 0.471458\n",
      "epoch 108; iter: 0; batch classifier loss: 0.027866; batch adversarial loss: 0.474485\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067952; batch adversarial loss: 0.466963\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052635; batch adversarial loss: 0.481454\n",
      "epoch 111; iter: 0; batch classifier loss: 0.019300; batch adversarial loss: 0.487679\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039728; batch adversarial loss: 0.384154\n",
      "epoch 113; iter: 0; batch classifier loss: 0.022830; batch adversarial loss: 0.531082\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027616; batch adversarial loss: 0.471804\n",
      "epoch 115; iter: 0; batch classifier loss: 0.047197; batch adversarial loss: 0.495668\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032658; batch adversarial loss: 0.398449\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033867; batch adversarial loss: 0.487388\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048556; batch adversarial loss: 0.409226\n",
      "epoch 119; iter: 0; batch classifier loss: 0.018139; batch adversarial loss: 0.466880\n",
      "epoch 120; iter: 0; batch classifier loss: 0.066337; batch adversarial loss: 0.501274\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043343; batch adversarial loss: 0.504939\n",
      "epoch 122; iter: 0; batch classifier loss: 0.016923; batch adversarial loss: 0.445579\n",
      "epoch 123; iter: 0; batch classifier loss: 0.016420; batch adversarial loss: 0.511733\n",
      "epoch 124; iter: 0; batch classifier loss: 0.049870; batch adversarial loss: 0.399502\n",
      "epoch 125; iter: 0; batch classifier loss: 0.024910; batch adversarial loss: 0.530705\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025260; batch adversarial loss: 0.550152\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048436; batch adversarial loss: 0.460955\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063286; batch adversarial loss: 0.491370\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051019; batch adversarial loss: 0.396561\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028338; batch adversarial loss: 0.537158\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026557; batch adversarial loss: 0.407943\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024583; batch adversarial loss: 0.500349\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032913; batch adversarial loss: 0.541491\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051822; batch adversarial loss: 0.512552\n",
      "epoch 135; iter: 0; batch classifier loss: 0.076727; batch adversarial loss: 0.475996\n",
      "epoch 136; iter: 0; batch classifier loss: 0.047772; batch adversarial loss: 0.490118\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023999; batch adversarial loss: 0.516234\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040178; batch adversarial loss: 0.468830\n",
      "epoch 139; iter: 0; batch classifier loss: 0.027243; batch adversarial loss: 0.485842\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050272; batch adversarial loss: 0.435704\n",
      "epoch 141; iter: 0; batch classifier loss: 0.014231; batch adversarial loss: 0.458690\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043523; batch adversarial loss: 0.502743\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039973; batch adversarial loss: 0.523823\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032315; batch adversarial loss: 0.500065\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022506; batch adversarial loss: 0.543813\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052073; batch adversarial loss: 0.405399\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021822; batch adversarial loss: 0.464993\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019816; batch adversarial loss: 0.429343\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012039; batch adversarial loss: 0.546437\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037894; batch adversarial loss: 0.441520\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029781; batch adversarial loss: 0.486066\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011619; batch adversarial loss: 0.549213\n",
      "epoch 153; iter: 0; batch classifier loss: 0.007813; batch adversarial loss: 0.494626\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020325; batch adversarial loss: 0.430215\n",
      "epoch 155; iter: 0; batch classifier loss: 0.064448; batch adversarial loss: 0.460838\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014957; batch adversarial loss: 0.467809\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025118; batch adversarial loss: 0.504985\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028456; batch adversarial loss: 0.451888\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032667; batch adversarial loss: 0.456946\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008192; batch adversarial loss: 0.485336\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039205; batch adversarial loss: 0.483772\n",
      "epoch 162; iter: 0; batch classifier loss: 0.058786; batch adversarial loss: 0.463545\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014320; batch adversarial loss: 0.518530\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009663; batch adversarial loss: 0.492621\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021830; batch adversarial loss: 0.413612\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007179; batch adversarial loss: 0.520690\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013403; batch adversarial loss: 0.483462\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028748; batch adversarial loss: 0.435044\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034155; batch adversarial loss: 0.469787\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020466; batch adversarial loss: 0.438507\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013851; batch adversarial loss: 0.474639\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023486; batch adversarial loss: 0.405298\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014525; batch adversarial loss: 0.380375\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020553; batch adversarial loss: 0.382310\n",
      "epoch 175; iter: 0; batch classifier loss: 0.005308; batch adversarial loss: 0.488624\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037106; batch adversarial loss: 0.426320\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017648; batch adversarial loss: 0.415775\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009486; batch adversarial loss: 0.499900\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040111; batch adversarial loss: 0.519461\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019466; batch adversarial loss: 0.480511\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013576; batch adversarial loss: 0.497917\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020602; batch adversarial loss: 0.415570\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006102; batch adversarial loss: 0.463745\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006730; batch adversarial loss: 0.554645\n",
      "epoch 185; iter: 0; batch classifier loss: 0.034828; batch adversarial loss: 0.470291\n",
      "epoch 186; iter: 0; batch classifier loss: 0.050474; batch adversarial loss: 0.429614\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008501; batch adversarial loss: 0.553667\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014998; batch adversarial loss: 0.400635\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036187; batch adversarial loss: 0.490066\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007325; batch adversarial loss: 0.501355\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024702; batch adversarial loss: 0.478191\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027305; batch adversarial loss: 0.506733\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012858; batch adversarial loss: 0.450494\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035506; batch adversarial loss: 0.484512\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014076; batch adversarial loss: 0.470584\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023599; batch adversarial loss: 0.483680\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031716; batch adversarial loss: 0.515951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.017762; batch adversarial loss: 0.402426\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018214; batch adversarial loss: 0.522631\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698204; batch adversarial loss: 0.759854\n",
      "epoch 1; iter: 0; batch classifier loss: 0.397167; batch adversarial loss: 0.732097\n",
      "epoch 2; iter: 0; batch classifier loss: 0.440337; batch adversarial loss: 0.702811\n",
      "epoch 3; iter: 0; batch classifier loss: 0.311981; batch adversarial loss: 0.666830\n",
      "epoch 4; iter: 0; batch classifier loss: 0.321216; batch adversarial loss: 0.638454\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343743; batch adversarial loss: 0.598494\n",
      "epoch 6; iter: 0; batch classifier loss: 0.322527; batch adversarial loss: 0.560208\n",
      "epoch 7; iter: 0; batch classifier loss: 0.290379; batch adversarial loss: 0.538938\n",
      "epoch 8; iter: 0; batch classifier loss: 0.253947; batch adversarial loss: 0.529332\n",
      "epoch 9; iter: 0; batch classifier loss: 0.320736; batch adversarial loss: 0.506296\n",
      "epoch 10; iter: 0; batch classifier loss: 0.289977; batch adversarial loss: 0.493969\n",
      "epoch 11; iter: 0; batch classifier loss: 0.255293; batch adversarial loss: 0.464238\n",
      "epoch 12; iter: 0; batch classifier loss: 0.221702; batch adversarial loss: 0.470940\n",
      "epoch 13; iter: 0; batch classifier loss: 0.191799; batch adversarial loss: 0.451799\n",
      "epoch 14; iter: 0; batch classifier loss: 0.198118; batch adversarial loss: 0.473312\n",
      "epoch 15; iter: 0; batch classifier loss: 0.211007; batch adversarial loss: 0.436239\n",
      "epoch 16; iter: 0; batch classifier loss: 0.269572; batch adversarial loss: 0.392222\n",
      "epoch 17; iter: 0; batch classifier loss: 0.165301; batch adversarial loss: 0.402961\n",
      "epoch 18; iter: 0; batch classifier loss: 0.231645; batch adversarial loss: 0.461596\n",
      "epoch 19; iter: 0; batch classifier loss: 0.177540; batch adversarial loss: 0.373572\n",
      "epoch 20; iter: 0; batch classifier loss: 0.234999; batch adversarial loss: 0.399227\n",
      "epoch 21; iter: 0; batch classifier loss: 0.197505; batch adversarial loss: 0.413457\n",
      "epoch 22; iter: 0; batch classifier loss: 0.188538; batch adversarial loss: 0.437291\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171337; batch adversarial loss: 0.416896\n",
      "epoch 24; iter: 0; batch classifier loss: 0.143387; batch adversarial loss: 0.425368\n",
      "epoch 25; iter: 0; batch classifier loss: 0.165265; batch adversarial loss: 0.404696\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165121; batch adversarial loss: 0.347773\n",
      "epoch 27; iter: 0; batch classifier loss: 0.185588; batch adversarial loss: 0.430983\n",
      "epoch 28; iter: 0; batch classifier loss: 0.150343; batch adversarial loss: 0.397848\n",
      "epoch 29; iter: 0; batch classifier loss: 0.132725; batch adversarial loss: 0.477265\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144840; batch adversarial loss: 0.377823\n",
      "epoch 31; iter: 0; batch classifier loss: 0.110887; batch adversarial loss: 0.440391\n",
      "epoch 32; iter: 0; batch classifier loss: 0.130421; batch adversarial loss: 0.345216\n",
      "epoch 33; iter: 0; batch classifier loss: 0.170167; batch adversarial loss: 0.378898\n",
      "epoch 34; iter: 0; batch classifier loss: 0.118736; batch adversarial loss: 0.354618\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142314; batch adversarial loss: 0.457619\n",
      "epoch 36; iter: 0; batch classifier loss: 0.071996; batch adversarial loss: 0.467476\n",
      "epoch 37; iter: 0; batch classifier loss: 0.107278; batch adversarial loss: 0.404095\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107777; batch adversarial loss: 0.398090\n",
      "epoch 39; iter: 0; batch classifier loss: 0.089554; batch adversarial loss: 0.418781\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099622; batch adversarial loss: 0.356743\n",
      "epoch 41; iter: 0; batch classifier loss: 0.124891; batch adversarial loss: 0.402261\n",
      "epoch 42; iter: 0; batch classifier loss: 0.100399; batch adversarial loss: 0.363835\n",
      "epoch 43; iter: 0; batch classifier loss: 0.088362; batch adversarial loss: 0.483953\n",
      "epoch 44; iter: 0; batch classifier loss: 0.081659; batch adversarial loss: 0.391070\n",
      "epoch 45; iter: 0; batch classifier loss: 0.118354; batch adversarial loss: 0.471984\n",
      "epoch 46; iter: 0; batch classifier loss: 0.113929; batch adversarial loss: 0.446462\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095477; batch adversarial loss: 0.392440\n",
      "epoch 48; iter: 0; batch classifier loss: 0.087973; batch adversarial loss: 0.413422\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098132; batch adversarial loss: 0.410706\n",
      "epoch 50; iter: 0; batch classifier loss: 0.095440; batch adversarial loss: 0.433241\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083744; batch adversarial loss: 0.380243\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096376; batch adversarial loss: 0.394225\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098431; batch adversarial loss: 0.365639\n",
      "epoch 54; iter: 0; batch classifier loss: 0.084918; batch adversarial loss: 0.466768\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119887; batch adversarial loss: 0.401178\n",
      "epoch 56; iter: 0; batch classifier loss: 0.071896; batch adversarial loss: 0.366519\n",
      "epoch 57; iter: 0; batch classifier loss: 0.066907; batch adversarial loss: 0.357959\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072309; batch adversarial loss: 0.361393\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081720; batch adversarial loss: 0.419801\n",
      "epoch 60; iter: 0; batch classifier loss: 0.089407; batch adversarial loss: 0.482657\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093148; batch adversarial loss: 0.360073\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093167; batch adversarial loss: 0.389193\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089786; batch adversarial loss: 0.461481\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076165; batch adversarial loss: 0.340663\n",
      "epoch 65; iter: 0; batch classifier loss: 0.058865; batch adversarial loss: 0.450859\n",
      "epoch 66; iter: 0; batch classifier loss: 0.048986; batch adversarial loss: 0.412657\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059681; batch adversarial loss: 0.445012\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071177; batch adversarial loss: 0.400460\n",
      "epoch 69; iter: 0; batch classifier loss: 0.068193; batch adversarial loss: 0.446583\n",
      "epoch 70; iter: 0; batch classifier loss: 0.048928; batch adversarial loss: 0.375638\n",
      "epoch 71; iter: 0; batch classifier loss: 0.091110; batch adversarial loss: 0.509365\n",
      "epoch 72; iter: 0; batch classifier loss: 0.056073; batch adversarial loss: 0.439494\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069392; batch adversarial loss: 0.408884\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081685; batch adversarial loss: 0.483298\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076005; batch adversarial loss: 0.433224\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075182; batch adversarial loss: 0.473350\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063894; batch adversarial loss: 0.502074\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066217; batch adversarial loss: 0.326512\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053206; batch adversarial loss: 0.368369\n",
      "epoch 80; iter: 0; batch classifier loss: 0.052321; batch adversarial loss: 0.506750\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067675; batch adversarial loss: 0.448090\n",
      "epoch 82; iter: 0; batch classifier loss: 0.068623; batch adversarial loss: 0.460936\n",
      "epoch 83; iter: 0; batch classifier loss: 0.067966; batch adversarial loss: 0.417127\n",
      "epoch 84; iter: 0; batch classifier loss: 0.049866; batch adversarial loss: 0.356023\n",
      "epoch 85; iter: 0; batch classifier loss: 0.037377; batch adversarial loss: 0.417831\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054989; batch adversarial loss: 0.408815\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067155; batch adversarial loss: 0.512862\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050604; batch adversarial loss: 0.392310\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065220; batch adversarial loss: 0.422079\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053826; batch adversarial loss: 0.498898\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073909; batch adversarial loss: 0.465967\n",
      "epoch 92; iter: 0; batch classifier loss: 0.039244; batch adversarial loss: 0.437295\n",
      "epoch 93; iter: 0; batch classifier loss: 0.031577; batch adversarial loss: 0.409630\n",
      "epoch 94; iter: 0; batch classifier loss: 0.089972; batch adversarial loss: 0.429105\n",
      "epoch 95; iter: 0; batch classifier loss: 0.040403; batch adversarial loss: 0.435393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.063573; batch adversarial loss: 0.518451\n",
      "epoch 97; iter: 0; batch classifier loss: 0.098831; batch adversarial loss: 0.422642\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035123; batch adversarial loss: 0.500653\n",
      "epoch 99; iter: 0; batch classifier loss: 0.031864; batch adversarial loss: 0.523380\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037274; batch adversarial loss: 0.474150\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042044; batch adversarial loss: 0.403485\n",
      "epoch 102; iter: 0; batch classifier loss: 0.026141; batch adversarial loss: 0.533882\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035249; batch adversarial loss: 0.442214\n",
      "epoch 104; iter: 0; batch classifier loss: 0.032094; batch adversarial loss: 0.401927\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048740; batch adversarial loss: 0.467993\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044614; batch adversarial loss: 0.353639\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053278; batch adversarial loss: 0.378220\n",
      "epoch 108; iter: 0; batch classifier loss: 0.031042; batch adversarial loss: 0.445890\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040542; batch adversarial loss: 0.418570\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051201; batch adversarial loss: 0.449386\n",
      "epoch 111; iter: 0; batch classifier loss: 0.021815; batch adversarial loss: 0.399593\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044596; batch adversarial loss: 0.518038\n",
      "epoch 113; iter: 0; batch classifier loss: 0.023871; batch adversarial loss: 0.464900\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027198; batch adversarial loss: 0.473749\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037385; batch adversarial loss: 0.456138\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026959; batch adversarial loss: 0.429977\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033090; batch adversarial loss: 0.462343\n",
      "epoch 118; iter: 0; batch classifier loss: 0.019509; batch adversarial loss: 0.448041\n",
      "epoch 119; iter: 0; batch classifier loss: 0.028462; batch adversarial loss: 0.419692\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032891; batch adversarial loss: 0.409562\n",
      "epoch 121; iter: 0; batch classifier loss: 0.023894; batch adversarial loss: 0.529705\n",
      "epoch 122; iter: 0; batch classifier loss: 0.023205; batch adversarial loss: 0.468881\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057870; batch adversarial loss: 0.383667\n",
      "epoch 124; iter: 0; batch classifier loss: 0.009457; batch adversarial loss: 0.455786\n",
      "epoch 125; iter: 0; batch classifier loss: 0.012502; batch adversarial loss: 0.432559\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024440; batch adversarial loss: 0.473045\n",
      "epoch 127; iter: 0; batch classifier loss: 0.011931; batch adversarial loss: 0.384151\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042531; batch adversarial loss: 0.465099\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028416; batch adversarial loss: 0.414104\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022344; batch adversarial loss: 0.370489\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048577; batch adversarial loss: 0.503053\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034423; batch adversarial loss: 0.432034\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041141; batch adversarial loss: 0.423034\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050254; batch adversarial loss: 0.392362\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034112; batch adversarial loss: 0.458545\n",
      "epoch 136; iter: 0; batch classifier loss: 0.106059; batch adversarial loss: 0.571577\n",
      "epoch 137; iter: 0; batch classifier loss: 0.169418; batch adversarial loss: 0.686433\n",
      "epoch 138; iter: 0; batch classifier loss: 0.092612; batch adversarial loss: 0.614416\n",
      "epoch 139; iter: 0; batch classifier loss: 0.116819; batch adversarial loss: 0.720228\n",
      "epoch 140; iter: 0; batch classifier loss: 0.097437; batch adversarial loss: 0.628313\n",
      "epoch 141; iter: 0; batch classifier loss: 0.137249; batch adversarial loss: 0.524953\n",
      "epoch 142; iter: 0; batch classifier loss: 0.111951; batch adversarial loss: 0.623121\n",
      "epoch 143; iter: 0; batch classifier loss: 0.054763; batch adversarial loss: 0.452763\n",
      "epoch 144; iter: 0; batch classifier loss: 0.167214; batch adversarial loss: 0.674705\n",
      "epoch 145; iter: 0; batch classifier loss: 0.115869; batch adversarial loss: 0.622111\n",
      "epoch 146; iter: 0; batch classifier loss: 0.099993; batch adversarial loss: 0.608863\n",
      "epoch 147; iter: 0; batch classifier loss: 0.169770; batch adversarial loss: 0.714270\n",
      "epoch 148; iter: 0; batch classifier loss: 0.122674; batch adversarial loss: 0.593236\n",
      "epoch 149; iter: 0; batch classifier loss: 0.102654; batch adversarial loss: 0.501375\n",
      "epoch 150; iter: 0; batch classifier loss: 0.163457; batch adversarial loss: 0.592593\n",
      "epoch 151; iter: 0; batch classifier loss: 0.090277; batch adversarial loss: 0.513897\n",
      "epoch 152; iter: 0; batch classifier loss: 0.078934; batch adversarial loss: 0.506459\n",
      "epoch 153; iter: 0; batch classifier loss: 0.148622; batch adversarial loss: 0.680545\n",
      "epoch 154; iter: 0; batch classifier loss: 0.103050; batch adversarial loss: 0.630494\n",
      "epoch 155; iter: 0; batch classifier loss: 0.080233; batch adversarial loss: 0.443411\n",
      "epoch 156; iter: 0; batch classifier loss: 0.067485; batch adversarial loss: 0.485452\n",
      "epoch 157; iter: 0; batch classifier loss: 0.139731; batch adversarial loss: 0.653638\n",
      "epoch 158; iter: 0; batch classifier loss: 0.088526; batch adversarial loss: 0.441496\n",
      "epoch 159; iter: 0; batch classifier loss: 0.145116; batch adversarial loss: 0.522473\n",
      "epoch 160; iter: 0; batch classifier loss: 0.134859; batch adversarial loss: 0.457413\n",
      "epoch 161; iter: 0; batch classifier loss: 0.158145; batch adversarial loss: 0.625831\n",
      "epoch 162; iter: 0; batch classifier loss: 0.130668; batch adversarial loss: 0.516260\n",
      "epoch 163; iter: 0; batch classifier loss: 0.146237; batch adversarial loss: 0.541588\n",
      "epoch 164; iter: 0; batch classifier loss: 0.111157; batch adversarial loss: 0.570068\n",
      "epoch 165; iter: 0; batch classifier loss: 0.174167; batch adversarial loss: 0.521084\n",
      "epoch 166; iter: 0; batch classifier loss: 0.127435; batch adversarial loss: 0.515876\n",
      "epoch 167; iter: 0; batch classifier loss: 0.161053; batch adversarial loss: 0.538936\n",
      "epoch 168; iter: 0; batch classifier loss: 0.103616; batch adversarial loss: 0.593880\n",
      "epoch 169; iter: 0; batch classifier loss: 0.111967; batch adversarial loss: 0.551048\n",
      "epoch 170; iter: 0; batch classifier loss: 0.072896; batch adversarial loss: 0.407365\n",
      "epoch 171; iter: 0; batch classifier loss: 0.102251; batch adversarial loss: 0.523048\n",
      "epoch 172; iter: 0; batch classifier loss: 0.109827; batch adversarial loss: 0.521582\n",
      "epoch 173; iter: 0; batch classifier loss: 0.081186; batch adversarial loss: 0.494304\n",
      "epoch 174; iter: 0; batch classifier loss: 0.109264; batch adversarial loss: 0.551819\n",
      "epoch 175; iter: 0; batch classifier loss: 0.096747; batch adversarial loss: 0.472574\n",
      "epoch 176; iter: 0; batch classifier loss: 0.135862; batch adversarial loss: 0.620718\n",
      "epoch 177; iter: 0; batch classifier loss: 0.083170; batch adversarial loss: 0.426371\n",
      "epoch 178; iter: 0; batch classifier loss: 0.076611; batch adversarial loss: 0.436191\n",
      "epoch 179; iter: 0; batch classifier loss: 0.125605; batch adversarial loss: 0.439983\n",
      "epoch 180; iter: 0; batch classifier loss: 0.101196; batch adversarial loss: 0.443896\n",
      "epoch 181; iter: 0; batch classifier loss: 0.098966; batch adversarial loss: 0.405612\n",
      "epoch 182; iter: 0; batch classifier loss: 0.115748; batch adversarial loss: 0.515880\n",
      "epoch 183; iter: 0; batch classifier loss: 0.067038; batch adversarial loss: 0.398814\n",
      "epoch 184; iter: 0; batch classifier loss: 0.114040; batch adversarial loss: 0.472532\n",
      "epoch 185; iter: 0; batch classifier loss: 0.121544; batch adversarial loss: 0.398983\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025906; batch adversarial loss: 0.517076\n",
      "epoch 187; iter: 0; batch classifier loss: 0.058542; batch adversarial loss: 0.528923\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022678; batch adversarial loss: 0.490660\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020148; batch adversarial loss: 0.519299\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026111; batch adversarial loss: 0.492316\n",
      "epoch 191; iter: 0; batch classifier loss: 0.042770; batch adversarial loss: 0.447641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.020670; batch adversarial loss: 0.427871\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021069; batch adversarial loss: 0.524745\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027577; batch adversarial loss: 0.420872\n",
      "epoch 195; iter: 0; batch classifier loss: 0.049660; batch adversarial loss: 0.473429\n",
      "epoch 196; iter: 0; batch classifier loss: 0.040217; batch adversarial loss: 0.473034\n",
      "epoch 197; iter: 0; batch classifier loss: 0.078266; batch adversarial loss: 0.446163\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030210; batch adversarial loss: 0.511545\n",
      "epoch 199; iter: 0; batch classifier loss: 0.058185; batch adversarial loss: 0.451928\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698945; batch adversarial loss: 0.771976\n",
      "epoch 1; iter: 0; batch classifier loss: 0.482507; batch adversarial loss: 0.737586\n",
      "epoch 2; iter: 0; batch classifier loss: 0.451886; batch adversarial loss: 0.681686\n",
      "epoch 3; iter: 0; batch classifier loss: 0.423738; batch adversarial loss: 0.639031\n",
      "epoch 4; iter: 0; batch classifier loss: 0.362243; batch adversarial loss: 0.585835\n",
      "epoch 5; iter: 0; batch classifier loss: 0.354979; batch adversarial loss: 0.591667\n",
      "epoch 6; iter: 0; batch classifier loss: 0.370989; batch adversarial loss: 0.582875\n",
      "epoch 7; iter: 0; batch classifier loss: 0.327303; batch adversarial loss: 0.577341\n",
      "epoch 8; iter: 0; batch classifier loss: 0.321775; batch adversarial loss: 0.526712\n",
      "epoch 9; iter: 0; batch classifier loss: 0.332398; batch adversarial loss: 0.554851\n",
      "epoch 10; iter: 0; batch classifier loss: 0.301577; batch adversarial loss: 0.508824\n",
      "epoch 11; iter: 0; batch classifier loss: 0.276210; batch adversarial loss: 0.498096\n",
      "epoch 12; iter: 0; batch classifier loss: 0.299583; batch adversarial loss: 0.470893\n",
      "epoch 13; iter: 0; batch classifier loss: 0.310226; batch adversarial loss: 0.514025\n",
      "epoch 14; iter: 0; batch classifier loss: 0.359659; batch adversarial loss: 0.469393\n",
      "epoch 15; iter: 0; batch classifier loss: 0.356610; batch adversarial loss: 0.460982\n",
      "epoch 16; iter: 0; batch classifier loss: 0.298291; batch adversarial loss: 0.462988\n",
      "epoch 17; iter: 0; batch classifier loss: 0.252275; batch adversarial loss: 0.510813\n",
      "epoch 18; iter: 0; batch classifier loss: 0.281382; batch adversarial loss: 0.510144\n",
      "epoch 19; iter: 0; batch classifier loss: 0.298795; batch adversarial loss: 0.542253\n",
      "epoch 20; iter: 0; batch classifier loss: 0.322176; batch adversarial loss: 0.508804\n",
      "epoch 21; iter: 0; batch classifier loss: 0.244463; batch adversarial loss: 0.470644\n",
      "epoch 22; iter: 0; batch classifier loss: 0.190464; batch adversarial loss: 0.540257\n",
      "epoch 23; iter: 0; batch classifier loss: 0.270905; batch adversarial loss: 0.452589\n",
      "epoch 24; iter: 0; batch classifier loss: 0.206764; batch adversarial loss: 0.474660\n",
      "epoch 25; iter: 0; batch classifier loss: 0.169549; batch adversarial loss: 0.490273\n",
      "epoch 26; iter: 0; batch classifier loss: 0.205187; batch adversarial loss: 0.524565\n",
      "epoch 27; iter: 0; batch classifier loss: 0.203874; batch adversarial loss: 0.461621\n",
      "epoch 28; iter: 0; batch classifier loss: 0.228969; batch adversarial loss: 0.486603\n",
      "epoch 29; iter: 0; batch classifier loss: 0.152541; batch adversarial loss: 0.410995\n",
      "epoch 30; iter: 0; batch classifier loss: 0.129399; batch adversarial loss: 0.503393\n",
      "epoch 31; iter: 0; batch classifier loss: 0.121146; batch adversarial loss: 0.529046\n",
      "epoch 32; iter: 0; batch classifier loss: 0.122724; batch adversarial loss: 0.491450\n",
      "epoch 33; iter: 0; batch classifier loss: 0.176960; batch adversarial loss: 0.479073\n",
      "epoch 34; iter: 0; batch classifier loss: 0.143041; batch adversarial loss: 0.487106\n",
      "epoch 35; iter: 0; batch classifier loss: 0.082009; batch adversarial loss: 0.470763\n",
      "epoch 36; iter: 0; batch classifier loss: 0.137637; batch adversarial loss: 0.474465\n",
      "epoch 37; iter: 0; batch classifier loss: 0.093287; batch adversarial loss: 0.417930\n",
      "epoch 38; iter: 0; batch classifier loss: 0.080923; batch adversarial loss: 0.515066\n",
      "epoch 39; iter: 0; batch classifier loss: 0.137080; batch adversarial loss: 0.522690\n",
      "epoch 40; iter: 0; batch classifier loss: 0.106544; batch adversarial loss: 0.308985\n",
      "epoch 41; iter: 0; batch classifier loss: 0.109316; batch adversarial loss: 0.412294\n",
      "epoch 42; iter: 0; batch classifier loss: 0.114298; batch adversarial loss: 0.413714\n",
      "epoch 43; iter: 0; batch classifier loss: 0.072892; batch adversarial loss: 0.483835\n",
      "epoch 44; iter: 0; batch classifier loss: 0.074379; batch adversarial loss: 0.477999\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097164; batch adversarial loss: 0.519223\n",
      "epoch 46; iter: 0; batch classifier loss: 0.069199; batch adversarial loss: 0.406797\n",
      "epoch 47; iter: 0; batch classifier loss: 0.070038; batch adversarial loss: 0.524796\n",
      "epoch 48; iter: 0; batch classifier loss: 0.145877; batch adversarial loss: 0.515916\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080016; batch adversarial loss: 0.494891\n",
      "epoch 50; iter: 0; batch classifier loss: 0.076777; batch adversarial loss: 0.479189\n",
      "epoch 51; iter: 0; batch classifier loss: 0.077848; batch adversarial loss: 0.445369\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096223; batch adversarial loss: 0.454673\n",
      "epoch 53; iter: 0; batch classifier loss: 0.062484; batch adversarial loss: 0.601083\n",
      "epoch 54; iter: 0; batch classifier loss: 0.076907; batch adversarial loss: 0.491346\n",
      "epoch 55; iter: 0; batch classifier loss: 0.121451; batch adversarial loss: 0.465053\n",
      "epoch 56; iter: 0; batch classifier loss: 0.064919; batch adversarial loss: 0.471569\n",
      "epoch 57; iter: 0; batch classifier loss: 0.049296; batch adversarial loss: 0.364826\n",
      "epoch 58; iter: 0; batch classifier loss: 0.066712; batch adversarial loss: 0.441954\n",
      "epoch 59; iter: 0; batch classifier loss: 0.095024; batch adversarial loss: 0.399672\n",
      "epoch 60; iter: 0; batch classifier loss: 0.083135; batch adversarial loss: 0.463111\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078057; batch adversarial loss: 0.480762\n",
      "epoch 62; iter: 0; batch classifier loss: 0.120914; batch adversarial loss: 0.452037\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099995; batch adversarial loss: 0.471223\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084662; batch adversarial loss: 0.506163\n",
      "epoch 65; iter: 0; batch classifier loss: 0.056420; batch adversarial loss: 0.513756\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075751; batch adversarial loss: 0.539629\n",
      "epoch 67; iter: 0; batch classifier loss: 0.031723; batch adversarial loss: 0.509199\n",
      "epoch 68; iter: 0; batch classifier loss: 0.064558; batch adversarial loss: 0.447685\n",
      "epoch 69; iter: 0; batch classifier loss: 0.053750; batch adversarial loss: 0.415686\n",
      "epoch 70; iter: 0; batch classifier loss: 0.052089; batch adversarial loss: 0.480445\n",
      "epoch 71; iter: 0; batch classifier loss: 0.047620; batch adversarial loss: 0.459112\n",
      "epoch 72; iter: 0; batch classifier loss: 0.067625; batch adversarial loss: 0.478337\n",
      "epoch 73; iter: 0; batch classifier loss: 0.094465; batch adversarial loss: 0.439187\n",
      "epoch 74; iter: 0; batch classifier loss: 0.112282; batch adversarial loss: 0.419025\n",
      "epoch 75; iter: 0; batch classifier loss: 0.027361; batch adversarial loss: 0.467062\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065675; batch adversarial loss: 0.411017\n",
      "epoch 77; iter: 0; batch classifier loss: 0.042099; batch adversarial loss: 0.389945\n",
      "epoch 78; iter: 0; batch classifier loss: 0.056284; batch adversarial loss: 0.422208\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057179; batch adversarial loss: 0.485500\n",
      "epoch 80; iter: 0; batch classifier loss: 0.038953; batch adversarial loss: 0.477246\n",
      "epoch 81; iter: 0; batch classifier loss: 0.044679; batch adversarial loss: 0.411823\n",
      "epoch 82; iter: 0; batch classifier loss: 0.054518; batch adversarial loss: 0.409770\n",
      "epoch 83; iter: 0; batch classifier loss: 0.039485; batch adversarial loss: 0.448277\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051394; batch adversarial loss: 0.394613\n",
      "epoch 85; iter: 0; batch classifier loss: 0.024175; batch adversarial loss: 0.405158\n",
      "epoch 86; iter: 0; batch classifier loss: 0.077842; batch adversarial loss: 0.479211\n",
      "epoch 87; iter: 0; batch classifier loss: 0.063788; batch adversarial loss: 0.408514\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042102; batch adversarial loss: 0.420429\n",
      "epoch 89; iter: 0; batch classifier loss: 0.086302; batch adversarial loss: 0.499495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.026229; batch adversarial loss: 0.505646\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048134; batch adversarial loss: 0.489837\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057629; batch adversarial loss: 0.448956\n",
      "epoch 93; iter: 0; batch classifier loss: 0.023490; batch adversarial loss: 0.500766\n",
      "epoch 94; iter: 0; batch classifier loss: 0.085555; batch adversarial loss: 0.498425\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038334; batch adversarial loss: 0.425281\n",
      "epoch 96; iter: 0; batch classifier loss: 0.032181; batch adversarial loss: 0.520428\n",
      "epoch 97; iter: 0; batch classifier loss: 0.016697; batch adversarial loss: 0.461905\n",
      "epoch 98; iter: 0; batch classifier loss: 0.043778; batch adversarial loss: 0.527689\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073844; batch adversarial loss: 0.476020\n",
      "epoch 100; iter: 0; batch classifier loss: 0.029670; batch adversarial loss: 0.377426\n",
      "epoch 101; iter: 0; batch classifier loss: 0.031708; batch adversarial loss: 0.473418\n",
      "epoch 102; iter: 0; batch classifier loss: 0.045891; batch adversarial loss: 0.370089\n",
      "epoch 103; iter: 0; batch classifier loss: 0.073580; batch adversarial loss: 0.470810\n",
      "epoch 104; iter: 0; batch classifier loss: 0.028124; batch adversarial loss: 0.511778\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037744; batch adversarial loss: 0.503790\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055712; batch adversarial loss: 0.397460\n",
      "epoch 107; iter: 0; batch classifier loss: 0.018760; batch adversarial loss: 0.486563\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037242; batch adversarial loss: 0.344886\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057508; batch adversarial loss: 0.466668\n",
      "epoch 110; iter: 0; batch classifier loss: 0.072835; batch adversarial loss: 0.454112\n",
      "epoch 111; iter: 0; batch classifier loss: 0.022987; batch adversarial loss: 0.499480\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044826; batch adversarial loss: 0.350125\n",
      "epoch 113; iter: 0; batch classifier loss: 0.050599; batch adversarial loss: 0.451713\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052717; batch adversarial loss: 0.393921\n",
      "epoch 115; iter: 0; batch classifier loss: 0.021245; batch adversarial loss: 0.444805\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024641; batch adversarial loss: 0.559886\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028993; batch adversarial loss: 0.430315\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037096; batch adversarial loss: 0.548090\n",
      "epoch 119; iter: 0; batch classifier loss: 0.007572; batch adversarial loss: 0.514118\n",
      "epoch 120; iter: 0; batch classifier loss: 0.018883; batch adversarial loss: 0.417863\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036756; batch adversarial loss: 0.455197\n",
      "epoch 122; iter: 0; batch classifier loss: 0.012955; batch adversarial loss: 0.441985\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024386; batch adversarial loss: 0.482537\n",
      "epoch 124; iter: 0; batch classifier loss: 0.065722; batch adversarial loss: 0.436156\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051094; batch adversarial loss: 0.459727\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037732; batch adversarial loss: 0.442483\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034090; batch adversarial loss: 0.403516\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030675; batch adversarial loss: 0.499612\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023495; batch adversarial loss: 0.418895\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047573; batch adversarial loss: 0.374406\n",
      "epoch 131; iter: 0; batch classifier loss: 0.014191; batch adversarial loss: 0.492264\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015326; batch adversarial loss: 0.456316\n",
      "epoch 133; iter: 0; batch classifier loss: 0.059986; batch adversarial loss: 0.371208\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037249; batch adversarial loss: 0.487728\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030338; batch adversarial loss: 0.458660\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044361; batch adversarial loss: 0.476633\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018926; batch adversarial loss: 0.431418\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024216; batch adversarial loss: 0.499712\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046234; batch adversarial loss: 0.463933\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026020; batch adversarial loss: 0.378734\n",
      "epoch 141; iter: 0; batch classifier loss: 0.011789; batch adversarial loss: 0.489832\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028093; batch adversarial loss: 0.502329\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019118; batch adversarial loss: 0.429722\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028892; batch adversarial loss: 0.485303\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020267; batch adversarial loss: 0.482234\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034209; batch adversarial loss: 0.388854\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018860; batch adversarial loss: 0.483177\n",
      "epoch 148; iter: 0; batch classifier loss: 0.009243; batch adversarial loss: 0.534306\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018300; batch adversarial loss: 0.602374\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015536; batch adversarial loss: 0.397519\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040973; batch adversarial loss: 0.500334\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032168; batch adversarial loss: 0.486314\n",
      "epoch 153; iter: 0; batch classifier loss: 0.057173; batch adversarial loss: 0.554044\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024751; batch adversarial loss: 0.474442\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030266; batch adversarial loss: 0.362575\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014827; batch adversarial loss: 0.399663\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027337; batch adversarial loss: 0.413044\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022757; batch adversarial loss: 0.449780\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022141; batch adversarial loss: 0.399732\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014852; batch adversarial loss: 0.441226\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019612; batch adversarial loss: 0.540464\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030034; batch adversarial loss: 0.492063\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018529; batch adversarial loss: 0.460428\n",
      "epoch 164; iter: 0; batch classifier loss: 0.045593; batch adversarial loss: 0.458454\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030570; batch adversarial loss: 0.524374\n",
      "epoch 166; iter: 0; batch classifier loss: 0.009559; batch adversarial loss: 0.491024\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008079; batch adversarial loss: 0.453849\n",
      "epoch 168; iter: 0; batch classifier loss: 0.044113; batch adversarial loss: 0.546098\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015688; batch adversarial loss: 0.450466\n",
      "epoch 170; iter: 0; batch classifier loss: 0.045658; batch adversarial loss: 0.514579\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012206; batch adversarial loss: 0.555651\n",
      "epoch 172; iter: 0; batch classifier loss: 0.060276; batch adversarial loss: 0.445103\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011699; batch adversarial loss: 0.411522\n",
      "epoch 174; iter: 0; batch classifier loss: 0.043248; batch adversarial loss: 0.446756\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015834; batch adversarial loss: 0.377912\n",
      "epoch 176; iter: 0; batch classifier loss: 0.006786; batch adversarial loss: 0.441742\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006395; batch adversarial loss: 0.482222\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010885; batch adversarial loss: 0.460754\n",
      "epoch 179; iter: 0; batch classifier loss: 0.005650; batch adversarial loss: 0.452066\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032818; batch adversarial loss: 0.392183\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022912; batch adversarial loss: 0.508213\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009255; batch adversarial loss: 0.525446\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017528; batch adversarial loss: 0.489834\n",
      "epoch 184; iter: 0; batch classifier loss: 0.080005; batch adversarial loss: 0.399174\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011890; batch adversarial loss: 0.464926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.024711; batch adversarial loss: 0.398365\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032285; batch adversarial loss: 0.438833\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016943; batch adversarial loss: 0.400270\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020614; batch adversarial loss: 0.498717\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005856; batch adversarial loss: 0.438407\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013432; batch adversarial loss: 0.472474\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009764; batch adversarial loss: 0.503736\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008881; batch adversarial loss: 0.444772\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014069; batch adversarial loss: 0.497695\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022584; batch adversarial loss: 0.510501\n",
      "epoch 196; iter: 0; batch classifier loss: 0.056207; batch adversarial loss: 0.434275\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032871; batch adversarial loss: 0.497703\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029560; batch adversarial loss: 0.475049\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017309; batch adversarial loss: 0.453809\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683562; batch adversarial loss: 0.815839\n",
      "epoch 1; iter: 0; batch classifier loss: 0.329265; batch adversarial loss: 0.814120\n",
      "epoch 2; iter: 0; batch classifier loss: 0.420258; batch adversarial loss: 0.743964\n",
      "epoch 3; iter: 0; batch classifier loss: 0.292058; batch adversarial loss: 0.712954\n",
      "epoch 4; iter: 0; batch classifier loss: 0.320744; batch adversarial loss: 0.665530\n",
      "epoch 5; iter: 0; batch classifier loss: 0.327964; batch adversarial loss: 0.635069\n",
      "epoch 6; iter: 0; batch classifier loss: 0.242025; batch adversarial loss: 0.592521\n",
      "epoch 7; iter: 0; batch classifier loss: 0.230787; batch adversarial loss: 0.575309\n",
      "epoch 8; iter: 0; batch classifier loss: 0.345665; batch adversarial loss: 0.570816\n",
      "epoch 9; iter: 0; batch classifier loss: 0.348337; batch adversarial loss: 0.558520\n",
      "epoch 10; iter: 0; batch classifier loss: 0.305209; batch adversarial loss: 0.511091\n",
      "epoch 11; iter: 0; batch classifier loss: 0.311155; batch adversarial loss: 0.496589\n",
      "epoch 12; iter: 0; batch classifier loss: 0.296307; batch adversarial loss: 0.527134\n",
      "epoch 13; iter: 0; batch classifier loss: 0.203044; batch adversarial loss: 0.486867\n",
      "epoch 14; iter: 0; batch classifier loss: 0.249364; batch adversarial loss: 0.448187\n",
      "epoch 15; iter: 0; batch classifier loss: 0.301377; batch adversarial loss: 0.445262\n",
      "epoch 16; iter: 0; batch classifier loss: 0.241409; batch adversarial loss: 0.513512\n",
      "epoch 17; iter: 0; batch classifier loss: 0.215310; batch adversarial loss: 0.404045\n",
      "epoch 18; iter: 0; batch classifier loss: 0.210081; batch adversarial loss: 0.506189\n",
      "epoch 19; iter: 0; batch classifier loss: 0.227656; batch adversarial loss: 0.435404\n",
      "epoch 20; iter: 0; batch classifier loss: 0.188863; batch adversarial loss: 0.438781\n",
      "epoch 21; iter: 0; batch classifier loss: 0.205831; batch adversarial loss: 0.440085\n",
      "epoch 22; iter: 0; batch classifier loss: 0.142072; batch adversarial loss: 0.432392\n",
      "epoch 23; iter: 0; batch classifier loss: 0.275239; batch adversarial loss: 0.383750\n",
      "epoch 24; iter: 0; batch classifier loss: 0.173522; batch adversarial loss: 0.380440\n",
      "epoch 25; iter: 0; batch classifier loss: 0.213291; batch adversarial loss: 0.424166\n",
      "epoch 26; iter: 0; batch classifier loss: 0.152310; batch adversarial loss: 0.506841\n",
      "epoch 27; iter: 0; batch classifier loss: 0.199996; batch adversarial loss: 0.488558\n",
      "epoch 28; iter: 0; batch classifier loss: 0.176876; batch adversarial loss: 0.402686\n",
      "epoch 29; iter: 0; batch classifier loss: 0.162061; batch adversarial loss: 0.351382\n",
      "epoch 30; iter: 0; batch classifier loss: 0.195064; batch adversarial loss: 0.398708\n",
      "epoch 31; iter: 0; batch classifier loss: 0.164323; batch adversarial loss: 0.462546\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154712; batch adversarial loss: 0.413989\n",
      "epoch 33; iter: 0; batch classifier loss: 0.117745; batch adversarial loss: 0.347928\n",
      "epoch 34; iter: 0; batch classifier loss: 0.136964; batch adversarial loss: 0.441920\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130101; batch adversarial loss: 0.382920\n",
      "epoch 36; iter: 0; batch classifier loss: 0.175588; batch adversarial loss: 0.459658\n",
      "epoch 37; iter: 0; batch classifier loss: 0.133415; batch adversarial loss: 0.431788\n",
      "epoch 38; iter: 0; batch classifier loss: 0.214987; batch adversarial loss: 0.411400\n",
      "epoch 39; iter: 0; batch classifier loss: 0.168198; batch adversarial loss: 0.408896\n",
      "epoch 40; iter: 0; batch classifier loss: 0.144209; batch adversarial loss: 0.506189\n",
      "epoch 41; iter: 0; batch classifier loss: 0.131959; batch adversarial loss: 0.374048\n",
      "epoch 42; iter: 0; batch classifier loss: 0.137348; batch adversarial loss: 0.543777\n",
      "epoch 43; iter: 0; batch classifier loss: 0.140374; batch adversarial loss: 0.392727\n",
      "epoch 44; iter: 0; batch classifier loss: 0.165652; batch adversarial loss: 0.461734\n",
      "epoch 45; iter: 0; batch classifier loss: 0.120152; batch adversarial loss: 0.342006\n",
      "epoch 46; iter: 0; batch classifier loss: 0.119202; batch adversarial loss: 0.353845\n",
      "epoch 47; iter: 0; batch classifier loss: 0.082781; batch adversarial loss: 0.350826\n",
      "epoch 48; iter: 0; batch classifier loss: 0.092546; batch adversarial loss: 0.419677\n",
      "epoch 49; iter: 0; batch classifier loss: 0.104940; batch adversarial loss: 0.473223\n",
      "epoch 50; iter: 0; batch classifier loss: 0.062347; batch adversarial loss: 0.358810\n",
      "epoch 51; iter: 0; batch classifier loss: 0.102324; batch adversarial loss: 0.319107\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089697; batch adversarial loss: 0.341808\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088824; batch adversarial loss: 0.389166\n",
      "epoch 54; iter: 0; batch classifier loss: 0.100144; batch adversarial loss: 0.516508\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089311; batch adversarial loss: 0.418610\n",
      "epoch 56; iter: 0; batch classifier loss: 0.120735; batch adversarial loss: 0.432640\n",
      "epoch 57; iter: 0; batch classifier loss: 0.144804; batch adversarial loss: 0.447519\n",
      "epoch 58; iter: 0; batch classifier loss: 0.093623; batch adversarial loss: 0.416285\n",
      "epoch 59; iter: 0; batch classifier loss: 0.074776; batch adversarial loss: 0.432768\n",
      "epoch 60; iter: 0; batch classifier loss: 0.130744; batch adversarial loss: 0.450341\n",
      "epoch 61; iter: 0; batch classifier loss: 0.081676; batch adversarial loss: 0.381174\n",
      "epoch 62; iter: 0; batch classifier loss: 0.057517; batch adversarial loss: 0.415064\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070008; batch adversarial loss: 0.413627\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080436; batch adversarial loss: 0.401082\n",
      "epoch 65; iter: 0; batch classifier loss: 0.113408; batch adversarial loss: 0.418936\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066297; batch adversarial loss: 0.496570\n",
      "epoch 67; iter: 0; batch classifier loss: 0.054745; batch adversarial loss: 0.414812\n",
      "epoch 68; iter: 0; batch classifier loss: 0.125487; batch adversarial loss: 0.404505\n",
      "epoch 69; iter: 0; batch classifier loss: 0.130338; batch adversarial loss: 0.400915\n",
      "epoch 70; iter: 0; batch classifier loss: 0.076370; batch adversarial loss: 0.483007\n",
      "epoch 71; iter: 0; batch classifier loss: 0.084437; batch adversarial loss: 0.392082\n",
      "epoch 72; iter: 0; batch classifier loss: 0.092945; batch adversarial loss: 0.464957\n",
      "epoch 73; iter: 0; batch classifier loss: 0.058491; batch adversarial loss: 0.459891\n",
      "epoch 74; iter: 0; batch classifier loss: 0.074599; batch adversarial loss: 0.426801\n",
      "epoch 75; iter: 0; batch classifier loss: 0.080318; batch adversarial loss: 0.503857\n",
      "epoch 76; iter: 0; batch classifier loss: 0.050311; batch adversarial loss: 0.398014\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062769; batch adversarial loss: 0.389977\n",
      "epoch 78; iter: 0; batch classifier loss: 0.120347; batch adversarial loss: 0.465654\n",
      "epoch 79; iter: 0; batch classifier loss: 0.100693; batch adversarial loss: 0.422235\n",
      "epoch 80; iter: 0; batch classifier loss: 0.052835; batch adversarial loss: 0.442208\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067187; batch adversarial loss: 0.463125\n",
      "epoch 82; iter: 0; batch classifier loss: 0.056731; batch adversarial loss: 0.423442\n",
      "epoch 83; iter: 0; batch classifier loss: 0.050128; batch adversarial loss: 0.416380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.067347; batch adversarial loss: 0.438388\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068454; batch adversarial loss: 0.438453\n",
      "epoch 86; iter: 0; batch classifier loss: 0.066279; batch adversarial loss: 0.465554\n",
      "epoch 87; iter: 0; batch classifier loss: 0.077323; batch adversarial loss: 0.431916\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075967; batch adversarial loss: 0.394470\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051533; batch adversarial loss: 0.576812\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050755; batch adversarial loss: 0.434963\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067880; batch adversarial loss: 0.463422\n",
      "epoch 92; iter: 0; batch classifier loss: 0.087007; batch adversarial loss: 0.359269\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050807; batch adversarial loss: 0.450939\n",
      "epoch 94; iter: 0; batch classifier loss: 0.081433; batch adversarial loss: 0.472326\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054389; batch adversarial loss: 0.413177\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058647; batch adversarial loss: 0.386604\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066135; batch adversarial loss: 0.431197\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048395; batch adversarial loss: 0.371612\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061637; batch adversarial loss: 0.426872\n",
      "epoch 100; iter: 0; batch classifier loss: 0.092891; batch adversarial loss: 0.385322\n",
      "epoch 101; iter: 0; batch classifier loss: 0.060038; batch adversarial loss: 0.295502\n",
      "epoch 102; iter: 0; batch classifier loss: 0.096149; batch adversarial loss: 0.381934\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076272; batch adversarial loss: 0.401134\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050287; batch adversarial loss: 0.363356\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044147; batch adversarial loss: 0.339037\n",
      "epoch 106; iter: 0; batch classifier loss: 0.066902; batch adversarial loss: 0.389781\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051569; batch adversarial loss: 0.409023\n",
      "epoch 108; iter: 0; batch classifier loss: 0.062755; batch adversarial loss: 0.418328\n",
      "epoch 109; iter: 0; batch classifier loss: 0.055194; batch adversarial loss: 0.451627\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052718; batch adversarial loss: 0.443560\n",
      "epoch 111; iter: 0; batch classifier loss: 0.068320; batch adversarial loss: 0.518339\n",
      "epoch 112; iter: 0; batch classifier loss: 0.087218; batch adversarial loss: 0.427604\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051790; batch adversarial loss: 0.416305\n",
      "epoch 114; iter: 0; batch classifier loss: 0.079318; batch adversarial loss: 0.416298\n",
      "epoch 115; iter: 0; batch classifier loss: 0.101515; batch adversarial loss: 0.439433\n",
      "epoch 116; iter: 0; batch classifier loss: 0.088657; batch adversarial loss: 0.461031\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052452; batch adversarial loss: 0.390907\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069404; batch adversarial loss: 0.396641\n",
      "epoch 119; iter: 0; batch classifier loss: 0.101202; batch adversarial loss: 0.377895\n",
      "epoch 120; iter: 0; batch classifier loss: 0.063705; batch adversarial loss: 0.347608\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047688; batch adversarial loss: 0.547967\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052535; batch adversarial loss: 0.396781\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042888; batch adversarial loss: 0.439765\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042635; batch adversarial loss: 0.364339\n",
      "epoch 125; iter: 0; batch classifier loss: 0.104169; batch adversarial loss: 0.371593\n",
      "epoch 126; iter: 0; batch classifier loss: 0.062731; batch adversarial loss: 0.417901\n",
      "epoch 127; iter: 0; batch classifier loss: 0.083328; batch adversarial loss: 0.402531\n",
      "epoch 128; iter: 0; batch classifier loss: 0.051678; batch adversarial loss: 0.355742\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037124; batch adversarial loss: 0.425938\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059100; batch adversarial loss: 0.491880\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040356; batch adversarial loss: 0.358224\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045515; batch adversarial loss: 0.530887\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040151; batch adversarial loss: 0.418156\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062458; batch adversarial loss: 0.423486\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040506; batch adversarial loss: 0.416864\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021487; batch adversarial loss: 0.415315\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039215; batch adversarial loss: 0.479225\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039295; batch adversarial loss: 0.451986\n",
      "epoch 139; iter: 0; batch classifier loss: 0.055430; batch adversarial loss: 0.496266\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047348; batch adversarial loss: 0.457768\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053244; batch adversarial loss: 0.430411\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040059; batch adversarial loss: 0.371914\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023834; batch adversarial loss: 0.371966\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037808; batch adversarial loss: 0.412678\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035676; batch adversarial loss: 0.472272\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020123; batch adversarial loss: 0.530379\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029785; batch adversarial loss: 0.370082\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020548; batch adversarial loss: 0.371010\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034907; batch adversarial loss: 0.506817\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039180; batch adversarial loss: 0.381616\n",
      "epoch 151; iter: 0; batch classifier loss: 0.079810; batch adversarial loss: 0.480724\n",
      "epoch 152; iter: 0; batch classifier loss: 0.049742; batch adversarial loss: 0.521462\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027145; batch adversarial loss: 0.449902\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022085; batch adversarial loss: 0.438041\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024650; batch adversarial loss: 0.389489\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030587; batch adversarial loss: 0.380566\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046926; batch adversarial loss: 0.407197\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019668; batch adversarial loss: 0.510056\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028119; batch adversarial loss: 0.460890\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027927; batch adversarial loss: 0.490565\n",
      "epoch 161; iter: 0; batch classifier loss: 0.041390; batch adversarial loss: 0.567700\n",
      "epoch 162; iter: 0; batch classifier loss: 0.035834; batch adversarial loss: 0.455597\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027363; batch adversarial loss: 0.441001\n",
      "epoch 164; iter: 0; batch classifier loss: 0.039168; batch adversarial loss: 0.467025\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015808; batch adversarial loss: 0.394321\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030349; batch adversarial loss: 0.462596\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024052; batch adversarial loss: 0.548847\n",
      "epoch 168; iter: 0; batch classifier loss: 0.062518; batch adversarial loss: 0.379448\n",
      "epoch 169; iter: 0; batch classifier loss: 0.078552; batch adversarial loss: 0.477934\n",
      "epoch 170; iter: 0; batch classifier loss: 0.069791; batch adversarial loss: 0.565192\n",
      "epoch 171; iter: 0; batch classifier loss: 0.059041; batch adversarial loss: 0.687733\n",
      "epoch 172; iter: 0; batch classifier loss: 0.077444; batch adversarial loss: 0.646927\n",
      "epoch 173; iter: 0; batch classifier loss: 0.107678; batch adversarial loss: 0.658277\n",
      "epoch 174; iter: 0; batch classifier loss: 0.071153; batch adversarial loss: 0.516901\n",
      "epoch 175; iter: 0; batch classifier loss: 0.072405; batch adversarial loss: 0.556362\n",
      "epoch 176; iter: 0; batch classifier loss: 0.038227; batch adversarial loss: 0.469431\n",
      "epoch 177; iter: 0; batch classifier loss: 0.056393; batch adversarial loss: 0.576828\n",
      "epoch 178; iter: 0; batch classifier loss: 0.111321; batch adversarial loss: 0.544288\n",
      "epoch 179; iter: 0; batch classifier loss: 0.106102; batch adversarial loss: 0.591626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.180839; batch adversarial loss: 0.541328\n",
      "epoch 181; iter: 0; batch classifier loss: 0.086496; batch adversarial loss: 0.585168\n",
      "epoch 182; iter: 0; batch classifier loss: 0.090426; batch adversarial loss: 0.606662\n",
      "epoch 183; iter: 0; batch classifier loss: 0.150869; batch adversarial loss: 0.699859\n",
      "epoch 184; iter: 0; batch classifier loss: 0.167000; batch adversarial loss: 0.800096\n",
      "epoch 185; iter: 0; batch classifier loss: 0.137882; batch adversarial loss: 0.667381\n",
      "epoch 186; iter: 0; batch classifier loss: 0.193712; batch adversarial loss: 0.823524\n",
      "epoch 187; iter: 0; batch classifier loss: 0.263000; batch adversarial loss: 0.891206\n",
      "epoch 188; iter: 0; batch classifier loss: 0.106004; batch adversarial loss: 0.576015\n",
      "epoch 189; iter: 0; batch classifier loss: 0.155313; batch adversarial loss: 0.728708\n",
      "epoch 190; iter: 0; batch classifier loss: 0.230251; batch adversarial loss: 0.798040\n",
      "epoch 191; iter: 0; batch classifier loss: 0.232727; batch adversarial loss: 0.702822\n",
      "epoch 192; iter: 0; batch classifier loss: 0.112726; batch adversarial loss: 0.538469\n",
      "epoch 193; iter: 0; batch classifier loss: 0.074990; batch adversarial loss: 0.493711\n",
      "epoch 194; iter: 0; batch classifier loss: 0.183607; batch adversarial loss: 0.653244\n",
      "epoch 195; iter: 0; batch classifier loss: 0.162456; batch adversarial loss: 0.578832\n",
      "epoch 196; iter: 0; batch classifier loss: 0.136210; batch adversarial loss: 0.558608\n",
      "epoch 197; iter: 0; batch classifier loss: 0.180813; batch adversarial loss: 0.628670\n",
      "epoch 198; iter: 0; batch classifier loss: 0.284962; batch adversarial loss: 0.747089\n",
      "epoch 199; iter: 0; batch classifier loss: 0.154553; batch adversarial loss: 0.592111\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705215; batch adversarial loss: 0.881344\n",
      "epoch 1; iter: 0; batch classifier loss: 0.513913; batch adversarial loss: 0.866184\n",
      "epoch 2; iter: 0; batch classifier loss: 0.573718; batch adversarial loss: 0.820781\n",
      "epoch 3; iter: 0; batch classifier loss: 0.772815; batch adversarial loss: 0.772049\n",
      "epoch 4; iter: 0; batch classifier loss: 0.790750; batch adversarial loss: 0.705162\n",
      "epoch 5; iter: 0; batch classifier loss: 0.777359; batch adversarial loss: 0.635761\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513691; batch adversarial loss: 0.585778\n",
      "epoch 7; iter: 0; batch classifier loss: 0.377435; batch adversarial loss: 0.577026\n",
      "epoch 8; iter: 0; batch classifier loss: 0.342413; batch adversarial loss: 0.572759\n",
      "epoch 9; iter: 0; batch classifier loss: 0.314065; batch adversarial loss: 0.552926\n",
      "epoch 10; iter: 0; batch classifier loss: 0.343961; batch adversarial loss: 0.531430\n",
      "epoch 11; iter: 0; batch classifier loss: 0.297117; batch adversarial loss: 0.557256\n",
      "epoch 12; iter: 0; batch classifier loss: 0.327163; batch adversarial loss: 0.508857\n",
      "epoch 13; iter: 0; batch classifier loss: 0.347742; batch adversarial loss: 0.547552\n",
      "epoch 14; iter: 0; batch classifier loss: 0.397747; batch adversarial loss: 0.488687\n",
      "epoch 15; iter: 0; batch classifier loss: 0.282714; batch adversarial loss: 0.486118\n",
      "epoch 16; iter: 0; batch classifier loss: 0.352199; batch adversarial loss: 0.447258\n",
      "epoch 17; iter: 0; batch classifier loss: 0.386083; batch adversarial loss: 0.476433\n",
      "epoch 18; iter: 0; batch classifier loss: 0.407506; batch adversarial loss: 0.473104\n",
      "epoch 19; iter: 0; batch classifier loss: 0.273338; batch adversarial loss: 0.555111\n",
      "epoch 20; iter: 0; batch classifier loss: 0.309531; batch adversarial loss: 0.462418\n",
      "epoch 21; iter: 0; batch classifier loss: 0.344057; batch adversarial loss: 0.471799\n",
      "epoch 22; iter: 0; batch classifier loss: 0.321054; batch adversarial loss: 0.488363\n",
      "epoch 23; iter: 0; batch classifier loss: 0.273488; batch adversarial loss: 0.487918\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280074; batch adversarial loss: 0.536630\n",
      "epoch 25; iter: 0; batch classifier loss: 0.231139; batch adversarial loss: 0.430156\n",
      "epoch 26; iter: 0; batch classifier loss: 0.249141; batch adversarial loss: 0.479263\n",
      "epoch 27; iter: 0; batch classifier loss: 0.242366; batch adversarial loss: 0.485914\n",
      "epoch 28; iter: 0; batch classifier loss: 0.222016; batch adversarial loss: 0.516373\n",
      "epoch 29; iter: 0; batch classifier loss: 0.249618; batch adversarial loss: 0.488957\n",
      "epoch 30; iter: 0; batch classifier loss: 0.237135; batch adversarial loss: 0.523223\n",
      "epoch 31; iter: 0; batch classifier loss: 0.185400; batch adversarial loss: 0.491581\n",
      "epoch 32; iter: 0; batch classifier loss: 0.221259; batch adversarial loss: 0.534523\n",
      "epoch 33; iter: 0; batch classifier loss: 0.172445; batch adversarial loss: 0.405768\n",
      "epoch 34; iter: 0; batch classifier loss: 0.193941; batch adversarial loss: 0.587987\n",
      "epoch 35; iter: 0; batch classifier loss: 0.180193; batch adversarial loss: 0.471542\n",
      "epoch 36; iter: 0; batch classifier loss: 0.230585; batch adversarial loss: 0.420004\n",
      "epoch 37; iter: 0; batch classifier loss: 0.179691; batch adversarial loss: 0.406546\n",
      "epoch 38; iter: 0; batch classifier loss: 0.202716; batch adversarial loss: 0.434414\n",
      "epoch 39; iter: 0; batch classifier loss: 0.164520; batch adversarial loss: 0.508289\n",
      "epoch 40; iter: 0; batch classifier loss: 0.230299; batch adversarial loss: 0.527998\n",
      "epoch 41; iter: 0; batch classifier loss: 0.175702; batch adversarial loss: 0.428002\n",
      "epoch 42; iter: 0; batch classifier loss: 0.166918; batch adversarial loss: 0.398931\n",
      "epoch 43; iter: 0; batch classifier loss: 0.152689; batch adversarial loss: 0.514618\n",
      "epoch 44; iter: 0; batch classifier loss: 0.126752; batch adversarial loss: 0.523109\n",
      "epoch 45; iter: 0; batch classifier loss: 0.135350; batch adversarial loss: 0.519157\n",
      "epoch 46; iter: 0; batch classifier loss: 0.111834; batch adversarial loss: 0.480475\n",
      "epoch 47; iter: 0; batch classifier loss: 0.184632; batch adversarial loss: 0.465820\n",
      "epoch 48; iter: 0; batch classifier loss: 0.203334; batch adversarial loss: 0.507885\n",
      "epoch 49; iter: 0; batch classifier loss: 0.198687; batch adversarial loss: 0.431565\n",
      "epoch 50; iter: 0; batch classifier loss: 0.129635; batch adversarial loss: 0.375286\n",
      "epoch 51; iter: 0; batch classifier loss: 0.113403; batch adversarial loss: 0.429327\n",
      "epoch 52; iter: 0; batch classifier loss: 0.142492; batch adversarial loss: 0.407684\n",
      "epoch 53; iter: 0; batch classifier loss: 0.109394; batch adversarial loss: 0.429242\n",
      "epoch 54; iter: 0; batch classifier loss: 0.130491; batch adversarial loss: 0.478181\n",
      "epoch 55; iter: 0; batch classifier loss: 0.159626; batch adversarial loss: 0.427517\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103486; batch adversarial loss: 0.446140\n",
      "epoch 57; iter: 0; batch classifier loss: 0.120665; batch adversarial loss: 0.500890\n",
      "epoch 58; iter: 0; batch classifier loss: 0.149177; batch adversarial loss: 0.502095\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102483; batch adversarial loss: 0.492045\n",
      "epoch 60; iter: 0; batch classifier loss: 0.127193; batch adversarial loss: 0.406795\n",
      "epoch 61; iter: 0; batch classifier loss: 0.124082; batch adversarial loss: 0.510942\n",
      "epoch 62; iter: 0; batch classifier loss: 0.132800; batch adversarial loss: 0.428195\n",
      "epoch 63; iter: 0; batch classifier loss: 0.062014; batch adversarial loss: 0.510586\n",
      "epoch 64; iter: 0; batch classifier loss: 0.087955; batch adversarial loss: 0.497400\n",
      "epoch 65; iter: 0; batch classifier loss: 0.108176; batch adversarial loss: 0.468209\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089212; batch adversarial loss: 0.392606\n",
      "epoch 67; iter: 0; batch classifier loss: 0.064585; batch adversarial loss: 0.495587\n",
      "epoch 68; iter: 0; batch classifier loss: 0.064404; batch adversarial loss: 0.552283\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076007; batch adversarial loss: 0.421060\n",
      "epoch 70; iter: 0; batch classifier loss: 0.058458; batch adversarial loss: 0.489892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.069495; batch adversarial loss: 0.512685\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062884; batch adversarial loss: 0.560810\n",
      "epoch 73; iter: 0; batch classifier loss: 0.074861; batch adversarial loss: 0.481709\n",
      "epoch 74; iter: 0; batch classifier loss: 0.043771; batch adversarial loss: 0.592205\n",
      "epoch 75; iter: 0; batch classifier loss: 0.066848; batch adversarial loss: 0.505813\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082407; batch adversarial loss: 0.553769\n",
      "epoch 77; iter: 0; batch classifier loss: 0.066650; batch adversarial loss: 0.482493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.078801; batch adversarial loss: 0.395589\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057581; batch adversarial loss: 0.441206\n",
      "epoch 80; iter: 0; batch classifier loss: 0.046417; batch adversarial loss: 0.477462\n",
      "epoch 81; iter: 0; batch classifier loss: 0.030219; batch adversarial loss: 0.454829\n",
      "epoch 82; iter: 0; batch classifier loss: 0.038627; batch adversarial loss: 0.534982\n",
      "epoch 83; iter: 0; batch classifier loss: 0.034621; batch adversarial loss: 0.437339\n",
      "epoch 84; iter: 0; batch classifier loss: 0.033945; batch adversarial loss: 0.602178\n",
      "epoch 85; iter: 0; batch classifier loss: 0.042556; batch adversarial loss: 0.407296\n",
      "epoch 86; iter: 0; batch classifier loss: 0.038327; batch adversarial loss: 0.500128\n",
      "epoch 87; iter: 0; batch classifier loss: 0.084821; batch adversarial loss: 0.501396\n",
      "epoch 88; iter: 0; batch classifier loss: 0.031318; batch adversarial loss: 0.370943\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056554; batch adversarial loss: 0.592944\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039413; batch adversarial loss: 0.563211\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048926; batch adversarial loss: 0.420235\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064057; batch adversarial loss: 0.596641\n",
      "epoch 93; iter: 0; batch classifier loss: 0.040767; batch adversarial loss: 0.420519\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033009; batch adversarial loss: 0.555694\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042917; batch adversarial loss: 0.401023\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049876; batch adversarial loss: 0.393546\n",
      "epoch 97; iter: 0; batch classifier loss: 0.038911; batch adversarial loss: 0.455670\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048834; batch adversarial loss: 0.417186\n",
      "epoch 99; iter: 0; batch classifier loss: 0.006576; batch adversarial loss: 0.470833\n",
      "epoch 100; iter: 0; batch classifier loss: 0.026301; batch adversarial loss: 0.436990\n",
      "epoch 101; iter: 0; batch classifier loss: 0.027846; batch adversarial loss: 0.498417\n",
      "epoch 102; iter: 0; batch classifier loss: 0.034203; batch adversarial loss: 0.434671\n",
      "epoch 103; iter: 0; batch classifier loss: 0.021106; batch adversarial loss: 0.379011\n",
      "epoch 104; iter: 0; batch classifier loss: 0.021142; batch adversarial loss: 0.471484\n",
      "epoch 105; iter: 0; batch classifier loss: 0.026103; batch adversarial loss: 0.522369\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030313; batch adversarial loss: 0.430102\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036222; batch adversarial loss: 0.509130\n",
      "epoch 108; iter: 0; batch classifier loss: 0.020789; batch adversarial loss: 0.477565\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048756; batch adversarial loss: 0.571331\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026105; batch adversarial loss: 0.464652\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029205; batch adversarial loss: 0.469994\n",
      "epoch 112; iter: 0; batch classifier loss: 0.019762; batch adversarial loss: 0.477050\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042816; batch adversarial loss: 0.383828\n",
      "epoch 114; iter: 0; batch classifier loss: 0.012096; batch adversarial loss: 0.508118\n",
      "epoch 115; iter: 0; batch classifier loss: 0.018229; batch adversarial loss: 0.536457\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021972; batch adversarial loss: 0.552776\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033839; batch adversarial loss: 0.438797\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030520; batch adversarial loss: 0.487868\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056734; batch adversarial loss: 0.557174\n",
      "epoch 120; iter: 0; batch classifier loss: 0.010877; batch adversarial loss: 0.370978\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029136; batch adversarial loss: 0.597284\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049550; batch adversarial loss: 0.441070\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039934; batch adversarial loss: 0.449990\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023356; batch adversarial loss: 0.420728\n",
      "epoch 125; iter: 0; batch classifier loss: 0.015799; batch adversarial loss: 0.433838\n",
      "epoch 126; iter: 0; batch classifier loss: 0.003245; batch adversarial loss: 0.346805\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024465; batch adversarial loss: 0.440037\n",
      "epoch 128; iter: 0; batch classifier loss: 0.015382; batch adversarial loss: 0.466743\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016514; batch adversarial loss: 0.446406\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030145; batch adversarial loss: 0.521301\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022192; batch adversarial loss: 0.443562\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016278; batch adversarial loss: 0.443088\n",
      "epoch 133; iter: 0; batch classifier loss: 0.016714; batch adversarial loss: 0.456671\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028442; batch adversarial loss: 0.422321\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026181; batch adversarial loss: 0.425185\n",
      "epoch 136; iter: 0; batch classifier loss: 0.014130; batch adversarial loss: 0.457354\n",
      "epoch 137; iter: 0; batch classifier loss: 0.016242; batch adversarial loss: 0.464810\n",
      "epoch 138; iter: 0; batch classifier loss: 0.015484; batch adversarial loss: 0.435043\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023945; batch adversarial loss: 0.507899\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024585; batch adversarial loss: 0.516232\n",
      "epoch 141; iter: 0; batch classifier loss: 0.060789; batch adversarial loss: 0.482009\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040515; batch adversarial loss: 0.535118\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019278; batch adversarial loss: 0.563196\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013106; batch adversarial loss: 0.428289\n",
      "epoch 145; iter: 0; batch classifier loss: 0.055631; batch adversarial loss: 0.426499\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025501; batch adversarial loss: 0.448621\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011482; batch adversarial loss: 0.503205\n",
      "epoch 148; iter: 0; batch classifier loss: 0.007355; batch adversarial loss: 0.399075\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039993; batch adversarial loss: 0.526794\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026683; batch adversarial loss: 0.447252\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015423; batch adversarial loss: 0.422229\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008277; batch adversarial loss: 0.477489\n",
      "epoch 153; iter: 0; batch classifier loss: 0.005942; batch adversarial loss: 0.502913\n",
      "epoch 154; iter: 0; batch classifier loss: 0.055456; batch adversarial loss: 0.409859\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023313; batch adversarial loss: 0.465654\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013824; batch adversarial loss: 0.451215\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031934; batch adversarial loss: 0.406852\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009715; batch adversarial loss: 0.570582\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027680; batch adversarial loss: 0.452363\n",
      "epoch 160; iter: 0; batch classifier loss: 0.006641; batch adversarial loss: 0.506642\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033293; batch adversarial loss: 0.504517\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013929; batch adversarial loss: 0.411543\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016520; batch adversarial loss: 0.509710\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032569; batch adversarial loss: 0.568423\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014891; batch adversarial loss: 0.406623\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021949; batch adversarial loss: 0.437846\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012294; batch adversarial loss: 0.431491\n",
      "epoch 168; iter: 0; batch classifier loss: 0.004853; batch adversarial loss: 0.362863\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007968; batch adversarial loss: 0.443209\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016072; batch adversarial loss: 0.412001\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009696; batch adversarial loss: 0.493138\n",
      "epoch 172; iter: 0; batch classifier loss: 0.053998; batch adversarial loss: 0.382498\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014327; batch adversarial loss: 0.441653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.008470; batch adversarial loss: 0.505058\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017421; batch adversarial loss: 0.482735\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024601; batch adversarial loss: 0.372805\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019831; batch adversarial loss: 0.427935\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018489; batch adversarial loss: 0.467291\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024025; batch adversarial loss: 0.573612\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013166; batch adversarial loss: 0.492703\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012630; batch adversarial loss: 0.500215\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009678; batch adversarial loss: 0.487691\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005342; batch adversarial loss: 0.437418\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027605; batch adversarial loss: 0.428913\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025024; batch adversarial loss: 0.455151\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035689; batch adversarial loss: 0.383777\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010785; batch adversarial loss: 0.390755\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005615; batch adversarial loss: 0.476828\n",
      "epoch 189; iter: 0; batch classifier loss: 0.005061; batch adversarial loss: 0.403705\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007355; batch adversarial loss: 0.495726\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006154; batch adversarial loss: 0.506660\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018405; batch adversarial loss: 0.455961\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006419; batch adversarial loss: 0.510339\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032851; batch adversarial loss: 0.466043\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005017; batch adversarial loss: 0.362333\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006215; batch adversarial loss: 0.463140\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004413; batch adversarial loss: 0.521702\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012208; batch adversarial loss: 0.568966\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014393; batch adversarial loss: 0.497894\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692659; batch adversarial loss: 0.539535\n",
      "epoch 1; iter: 0; batch classifier loss: 0.536103; batch adversarial loss: 0.611498\n",
      "epoch 2; iter: 0; batch classifier loss: 0.355193; batch adversarial loss: 0.577776\n",
      "epoch 3; iter: 0; batch classifier loss: 0.386749; batch adversarial loss: 0.625763\n",
      "epoch 4; iter: 0; batch classifier loss: 0.287340; batch adversarial loss: 0.605870\n",
      "epoch 5; iter: 0; batch classifier loss: 0.281500; batch adversarial loss: 0.554039\n",
      "epoch 6; iter: 0; batch classifier loss: 0.322801; batch adversarial loss: 0.527560\n",
      "epoch 7; iter: 0; batch classifier loss: 0.306343; batch adversarial loss: 0.495390\n",
      "epoch 8; iter: 0; batch classifier loss: 0.366553; batch adversarial loss: 0.541269\n",
      "epoch 9; iter: 0; batch classifier loss: 0.385259; batch adversarial loss: 0.630873\n",
      "epoch 10; iter: 0; batch classifier loss: 0.289377; batch adversarial loss: 0.590429\n",
      "epoch 11; iter: 0; batch classifier loss: 0.351857; batch adversarial loss: 0.550387\n",
      "epoch 12; iter: 0; batch classifier loss: 0.338643; batch adversarial loss: 0.538698\n",
      "epoch 13; iter: 0; batch classifier loss: 0.439002; batch adversarial loss: 0.498775\n",
      "epoch 14; iter: 0; batch classifier loss: 0.579276; batch adversarial loss: 0.573969\n",
      "epoch 15; iter: 0; batch classifier loss: 0.678042; batch adversarial loss: 0.514185\n",
      "epoch 16; iter: 0; batch classifier loss: 0.462216; batch adversarial loss: 0.530555\n",
      "epoch 17; iter: 0; batch classifier loss: 0.312186; batch adversarial loss: 0.504272\n",
      "epoch 18; iter: 0; batch classifier loss: 0.268297; batch adversarial loss: 0.478225\n",
      "epoch 19; iter: 0; batch classifier loss: 0.185805; batch adversarial loss: 0.449495\n",
      "epoch 20; iter: 0; batch classifier loss: 0.257537; batch adversarial loss: 0.433031\n",
      "epoch 21; iter: 0; batch classifier loss: 0.213252; batch adversarial loss: 0.455271\n",
      "epoch 22; iter: 0; batch classifier loss: 0.233856; batch adversarial loss: 0.489691\n",
      "epoch 23; iter: 0; batch classifier loss: 0.176402; batch adversarial loss: 0.388497\n",
      "epoch 24; iter: 0; batch classifier loss: 0.225003; batch adversarial loss: 0.444302\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179579; batch adversarial loss: 0.500619\n",
      "epoch 26; iter: 0; batch classifier loss: 0.111375; batch adversarial loss: 0.578977\n",
      "epoch 27; iter: 0; batch classifier loss: 0.139425; batch adversarial loss: 0.549578\n",
      "epoch 28; iter: 0; batch classifier loss: 0.186699; batch adversarial loss: 0.474154\n",
      "epoch 29; iter: 0; batch classifier loss: 0.187108; batch adversarial loss: 0.438095\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153978; batch adversarial loss: 0.485336\n",
      "epoch 31; iter: 0; batch classifier loss: 0.138454; batch adversarial loss: 0.519126\n",
      "epoch 32; iter: 0; batch classifier loss: 0.173185; batch adversarial loss: 0.450365\n",
      "epoch 33; iter: 0; batch classifier loss: 0.167904; batch adversarial loss: 0.448484\n",
      "epoch 34; iter: 0; batch classifier loss: 0.113793; batch adversarial loss: 0.472903\n",
      "epoch 35; iter: 0; batch classifier loss: 0.147530; batch adversarial loss: 0.463970\n",
      "epoch 36; iter: 0; batch classifier loss: 0.171393; batch adversarial loss: 0.500701\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153959; batch adversarial loss: 0.395177\n",
      "epoch 38; iter: 0; batch classifier loss: 0.151670; batch adversarial loss: 0.536856\n",
      "epoch 39; iter: 0; batch classifier loss: 0.226712; batch adversarial loss: 0.461383\n",
      "epoch 40; iter: 0; batch classifier loss: 0.143364; batch adversarial loss: 0.486115\n",
      "epoch 41; iter: 0; batch classifier loss: 0.107953; batch adversarial loss: 0.412575\n",
      "epoch 42; iter: 0; batch classifier loss: 0.172575; batch adversarial loss: 0.407516\n",
      "epoch 43; iter: 0; batch classifier loss: 0.184195; batch adversarial loss: 0.449961\n",
      "epoch 44; iter: 0; batch classifier loss: 0.126592; batch adversarial loss: 0.484475\n",
      "epoch 45; iter: 0; batch classifier loss: 0.138176; batch adversarial loss: 0.521823\n",
      "epoch 46; iter: 0; batch classifier loss: 0.154671; batch adversarial loss: 0.354412\n",
      "epoch 47; iter: 0; batch classifier loss: 0.161688; batch adversarial loss: 0.528369\n",
      "epoch 48; iter: 0; batch classifier loss: 0.143148; batch adversarial loss: 0.520629\n",
      "epoch 49; iter: 0; batch classifier loss: 0.130055; batch adversarial loss: 0.460316\n",
      "epoch 50; iter: 0; batch classifier loss: 0.163644; batch adversarial loss: 0.487671\n",
      "epoch 51; iter: 0; batch classifier loss: 0.174822; batch adversarial loss: 0.464415\n",
      "epoch 52; iter: 0; batch classifier loss: 0.207547; batch adversarial loss: 0.373779\n",
      "epoch 53; iter: 0; batch classifier loss: 0.147986; batch adversarial loss: 0.501050\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112419; batch adversarial loss: 0.507456\n",
      "epoch 55; iter: 0; batch classifier loss: 0.157925; batch adversarial loss: 0.414463\n",
      "epoch 56; iter: 0; batch classifier loss: 0.150416; batch adversarial loss: 0.526140\n",
      "epoch 57; iter: 0; batch classifier loss: 0.176972; batch adversarial loss: 0.524358\n",
      "epoch 58; iter: 0; batch classifier loss: 0.164839; batch adversarial loss: 0.448985\n",
      "epoch 59; iter: 0; batch classifier loss: 0.139074; batch adversarial loss: 0.419484\n",
      "epoch 60; iter: 0; batch classifier loss: 0.155891; batch adversarial loss: 0.425470\n",
      "epoch 61; iter: 0; batch classifier loss: 0.166801; batch adversarial loss: 0.497144\n",
      "epoch 62; iter: 0; batch classifier loss: 0.121021; batch adversarial loss: 0.425958\n",
      "epoch 63; iter: 0; batch classifier loss: 0.229265; batch adversarial loss: 0.374038\n",
      "epoch 64; iter: 0; batch classifier loss: 0.172092; batch adversarial loss: 0.445799\n",
      "epoch 65; iter: 0; batch classifier loss: 0.192479; batch adversarial loss: 0.447853\n",
      "epoch 66; iter: 0; batch classifier loss: 0.132767; batch adversarial loss: 0.553094\n",
      "epoch 67; iter: 0; batch classifier loss: 0.131171; batch adversarial loss: 0.558300\n",
      "epoch 68; iter: 0; batch classifier loss: 0.175127; batch adversarial loss: 0.337775\n",
      "epoch 69; iter: 0; batch classifier loss: 0.170079; batch adversarial loss: 0.494469\n",
      "epoch 70; iter: 0; batch classifier loss: 0.208004; batch adversarial loss: 0.479556\n",
      "epoch 71; iter: 0; batch classifier loss: 0.168713; batch adversarial loss: 0.446000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.247014; batch adversarial loss: 0.527530\n",
      "epoch 73; iter: 0; batch classifier loss: 0.201889; batch adversarial loss: 0.422704\n",
      "epoch 74; iter: 0; batch classifier loss: 0.205689; batch adversarial loss: 0.423951\n",
      "epoch 75; iter: 0; batch classifier loss: 0.198988; batch adversarial loss: 0.473300\n",
      "epoch 76; iter: 0; batch classifier loss: 0.177214; batch adversarial loss: 0.410091\n",
      "epoch 77; iter: 0; batch classifier loss: 0.188879; batch adversarial loss: 0.435302\n",
      "epoch 78; iter: 0; batch classifier loss: 0.172489; batch adversarial loss: 0.591203\n",
      "epoch 79; iter: 0; batch classifier loss: 0.132812; batch adversarial loss: 0.447775\n",
      "epoch 80; iter: 0; batch classifier loss: 0.173012; batch adversarial loss: 0.446370\n",
      "epoch 81; iter: 0; batch classifier loss: 0.209919; batch adversarial loss: 0.364991\n",
      "epoch 82; iter: 0; batch classifier loss: 0.181131; batch adversarial loss: 0.459697\n",
      "epoch 83; iter: 0; batch classifier loss: 0.200087; batch adversarial loss: 0.446717\n",
      "epoch 84; iter: 0; batch classifier loss: 0.231534; batch adversarial loss: 0.435298\n",
      "epoch 85; iter: 0; batch classifier loss: 0.193219; batch adversarial loss: 0.423444\n",
      "epoch 86; iter: 0; batch classifier loss: 0.124964; batch adversarial loss: 0.423623\n",
      "epoch 87; iter: 0; batch classifier loss: 0.135979; batch adversarial loss: 0.435434\n",
      "epoch 88; iter: 0; batch classifier loss: 0.167618; batch adversarial loss: 0.446507\n",
      "epoch 89; iter: 0; batch classifier loss: 0.207500; batch adversarial loss: 0.506785\n",
      "epoch 90; iter: 0; batch classifier loss: 0.208914; batch adversarial loss: 0.506688\n",
      "epoch 91; iter: 0; batch classifier loss: 0.214593; batch adversarial loss: 0.470190\n",
      "epoch 92; iter: 0; batch classifier loss: 0.182194; batch adversarial loss: 0.482471\n",
      "epoch 93; iter: 0; batch classifier loss: 0.160752; batch adversarial loss: 0.506966\n",
      "epoch 94; iter: 0; batch classifier loss: 0.143465; batch adversarial loss: 0.471595\n",
      "epoch 95; iter: 0; batch classifier loss: 0.193834; batch adversarial loss: 0.554837\n",
      "epoch 96; iter: 0; batch classifier loss: 0.147926; batch adversarial loss: 0.554934\n",
      "epoch 97; iter: 0; batch classifier loss: 0.179980; batch adversarial loss: 0.495265\n",
      "epoch 98; iter: 0; batch classifier loss: 0.204341; batch adversarial loss: 0.470360\n",
      "epoch 99; iter: 0; batch classifier loss: 0.141689; batch adversarial loss: 0.423655\n",
      "epoch 100; iter: 0; batch classifier loss: 0.128987; batch adversarial loss: 0.542280\n",
      "epoch 101; iter: 0; batch classifier loss: 0.180502; batch adversarial loss: 0.399240\n",
      "epoch 102; iter: 0; batch classifier loss: 0.152469; batch adversarial loss: 0.506879\n",
      "epoch 103; iter: 0; batch classifier loss: 0.180715; batch adversarial loss: 0.493963\n",
      "epoch 104; iter: 0; batch classifier loss: 0.263690; batch adversarial loss: 0.362966\n",
      "epoch 105; iter: 0; batch classifier loss: 0.147856; batch adversarial loss: 0.470579\n",
      "epoch 106; iter: 0; batch classifier loss: 0.185873; batch adversarial loss: 0.387987\n",
      "epoch 107; iter: 0; batch classifier loss: 0.139548; batch adversarial loss: 0.506200\n",
      "epoch 108; iter: 0; batch classifier loss: 0.129445; batch adversarial loss: 0.434848\n",
      "epoch 109; iter: 0; batch classifier loss: 0.144717; batch adversarial loss: 0.421793\n",
      "epoch 110; iter: 0; batch classifier loss: 0.175013; batch adversarial loss: 0.422610\n",
      "epoch 111; iter: 0; batch classifier loss: 0.130196; batch adversarial loss: 0.434655\n",
      "epoch 112; iter: 0; batch classifier loss: 0.125878; batch adversarial loss: 0.528866\n",
      "epoch 113; iter: 0; batch classifier loss: 0.133126; batch adversarial loss: 0.459353\n",
      "epoch 114; iter: 0; batch classifier loss: 0.172659; batch adversarial loss: 0.376516\n",
      "epoch 115; iter: 0; batch classifier loss: 0.204753; batch adversarial loss: 0.434777\n",
      "epoch 116; iter: 0; batch classifier loss: 0.139160; batch adversarial loss: 0.411187\n",
      "epoch 117; iter: 0; batch classifier loss: 0.176448; batch adversarial loss: 0.471175\n",
      "epoch 118; iter: 0; batch classifier loss: 0.125649; batch adversarial loss: 0.541852\n",
      "epoch 119; iter: 0; batch classifier loss: 0.112572; batch adversarial loss: 0.542573\n",
      "epoch 120; iter: 0; batch classifier loss: 0.259093; batch adversarial loss: 0.457814\n",
      "epoch 121; iter: 0; batch classifier loss: 0.159579; batch adversarial loss: 0.396898\n",
      "epoch 122; iter: 0; batch classifier loss: 0.164053; batch adversarial loss: 0.435639\n",
      "epoch 123; iter: 0; batch classifier loss: 0.165168; batch adversarial loss: 0.552688\n",
      "epoch 124; iter: 0; batch classifier loss: 0.118840; batch adversarial loss: 0.482956\n",
      "epoch 125; iter: 0; batch classifier loss: 0.132392; batch adversarial loss: 0.483146\n",
      "epoch 126; iter: 0; batch classifier loss: 0.191374; batch adversarial loss: 0.362627\n",
      "epoch 127; iter: 0; batch classifier loss: 0.145243; batch adversarial loss: 0.480322\n",
      "epoch 128; iter: 0; batch classifier loss: 0.124954; batch adversarial loss: 0.433550\n",
      "epoch 129; iter: 0; batch classifier loss: 0.125254; batch adversarial loss: 0.588088\n",
      "epoch 130; iter: 0; batch classifier loss: 0.164941; batch adversarial loss: 0.388106\n",
      "epoch 131; iter: 0; batch classifier loss: 0.114845; batch adversarial loss: 0.593845\n",
      "epoch 132; iter: 0; batch classifier loss: 0.147654; batch adversarial loss: 0.385606\n",
      "epoch 133; iter: 0; batch classifier loss: 0.080852; batch adversarial loss: 0.495367\n",
      "epoch 134; iter: 0; batch classifier loss: 0.162009; batch adversarial loss: 0.444613\n",
      "epoch 135; iter: 0; batch classifier loss: 0.110037; batch adversarial loss: 0.492308\n",
      "epoch 136; iter: 0; batch classifier loss: 0.089469; batch adversarial loss: 0.478759\n",
      "epoch 137; iter: 0; batch classifier loss: 0.102469; batch adversarial loss: 0.394085\n",
      "epoch 138; iter: 0; batch classifier loss: 0.060563; batch adversarial loss: 0.452272\n",
      "epoch 139; iter: 0; batch classifier loss: 0.058895; batch adversarial loss: 0.573117\n",
      "epoch 140; iter: 0; batch classifier loss: 0.067188; batch adversarial loss: 0.502837\n",
      "epoch 141; iter: 0; batch classifier loss: 0.068067; batch adversarial loss: 0.481789\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034940; batch adversarial loss: 0.538807\n",
      "epoch 143; iter: 0; batch classifier loss: 0.069107; batch adversarial loss: 0.454911\n",
      "epoch 144; iter: 0; batch classifier loss: 0.055530; batch adversarial loss: 0.480891\n",
      "epoch 145; iter: 0; batch classifier loss: 0.058261; batch adversarial loss: 0.439965\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038115; batch adversarial loss: 0.445684\n",
      "epoch 147; iter: 0; batch classifier loss: 0.081282; batch adversarial loss: 0.405872\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035173; batch adversarial loss: 0.452665\n",
      "epoch 149; iter: 0; batch classifier loss: 0.042351; batch adversarial loss: 0.469750\n",
      "epoch 150; iter: 0; batch classifier loss: 0.082033; batch adversarial loss: 0.534753\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041857; batch adversarial loss: 0.512025\n",
      "epoch 152; iter: 0; batch classifier loss: 0.057803; batch adversarial loss: 0.537620\n",
      "epoch 153; iter: 0; batch classifier loss: 0.051685; batch adversarial loss: 0.526070\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032082; batch adversarial loss: 0.401516\n",
      "epoch 155; iter: 0; batch classifier loss: 0.065427; batch adversarial loss: 0.424389\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026773; batch adversarial loss: 0.532487\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034869; batch adversarial loss: 0.524234\n",
      "epoch 158; iter: 0; batch classifier loss: 0.054318; batch adversarial loss: 0.365912\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034688; batch adversarial loss: 0.449693\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032828; batch adversarial loss: 0.427442\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034011; batch adversarial loss: 0.462226\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032683; batch adversarial loss: 0.412868\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023990; batch adversarial loss: 0.499004\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033242; batch adversarial loss: 0.450706\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017364; batch adversarial loss: 0.462437\n",
      "epoch 166; iter: 0; batch classifier loss: 0.039809; batch adversarial loss: 0.523216\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017006; batch adversarial loss: 0.419916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.026692; batch adversarial loss: 0.479086\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036102; batch adversarial loss: 0.433896\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016488; batch adversarial loss: 0.429665\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031461; batch adversarial loss: 0.383231\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028412; batch adversarial loss: 0.455680\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018870; batch adversarial loss: 0.413711\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030931; batch adversarial loss: 0.494510\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023554; batch adversarial loss: 0.443554\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034327; batch adversarial loss: 0.568016\n",
      "epoch 177; iter: 0; batch classifier loss: 0.050535; batch adversarial loss: 0.404402\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009639; batch adversarial loss: 0.451677\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030981; batch adversarial loss: 0.465326\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018142; batch adversarial loss: 0.467992\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019767; batch adversarial loss: 0.350189\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021498; batch adversarial loss: 0.376795\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031918; batch adversarial loss: 0.485325\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019716; batch adversarial loss: 0.465450\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014086; batch adversarial loss: 0.484545\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008715; batch adversarial loss: 0.389199\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010617; batch adversarial loss: 0.453956\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014387; batch adversarial loss: 0.499685\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011611; batch adversarial loss: 0.521756\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010136; batch adversarial loss: 0.518302\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015262; batch adversarial loss: 0.514219\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010712; batch adversarial loss: 0.500179\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011185; batch adversarial loss: 0.427192\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018289; batch adversarial loss: 0.431825\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015016; batch adversarial loss: 0.508671\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010873; batch adversarial loss: 0.512152\n",
      "epoch 197; iter: 0; batch classifier loss: 0.038029; batch adversarial loss: 0.501979\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022564; batch adversarial loss: 0.446383\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028074; batch adversarial loss: 0.542761\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690881; batch adversarial loss: 0.758965\n",
      "epoch 1; iter: 0; batch classifier loss: 0.646567; batch adversarial loss: 0.824592\n",
      "epoch 2; iter: 0; batch classifier loss: 0.724150; batch adversarial loss: 0.758452\n",
      "epoch 3; iter: 0; batch classifier loss: 0.651123; batch adversarial loss: 0.678887\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557864; batch adversarial loss: 0.637928\n",
      "epoch 5; iter: 0; batch classifier loss: 0.437334; batch adversarial loss: 0.560302\n",
      "epoch 6; iter: 0; batch classifier loss: 0.309578; batch adversarial loss: 0.590296\n",
      "epoch 7; iter: 0; batch classifier loss: 0.377330; batch adversarial loss: 0.524659\n",
      "epoch 8; iter: 0; batch classifier loss: 0.273916; batch adversarial loss: 0.508075\n",
      "epoch 9; iter: 0; batch classifier loss: 0.212518; batch adversarial loss: 0.589320\n",
      "epoch 10; iter: 0; batch classifier loss: 0.301408; batch adversarial loss: 0.522383\n",
      "epoch 11; iter: 0; batch classifier loss: 0.241968; batch adversarial loss: 0.523638\n",
      "epoch 12; iter: 0; batch classifier loss: 0.319643; batch adversarial loss: 0.508354\n",
      "epoch 13; iter: 0; batch classifier loss: 0.218072; batch adversarial loss: 0.486109\n",
      "epoch 14; iter: 0; batch classifier loss: 0.246074; batch adversarial loss: 0.518591\n",
      "epoch 15; iter: 0; batch classifier loss: 0.173631; batch adversarial loss: 0.476211\n",
      "epoch 16; iter: 0; batch classifier loss: 0.240956; batch adversarial loss: 0.471656\n",
      "epoch 17; iter: 0; batch classifier loss: 0.219340; batch adversarial loss: 0.461166\n",
      "epoch 18; iter: 0; batch classifier loss: 0.263036; batch adversarial loss: 0.451399\n",
      "epoch 19; iter: 0; batch classifier loss: 0.172324; batch adversarial loss: 0.470513\n",
      "epoch 20; iter: 0; batch classifier loss: 0.209935; batch adversarial loss: 0.548633\n",
      "epoch 21; iter: 0; batch classifier loss: 0.185483; batch adversarial loss: 0.522583\n",
      "epoch 22; iter: 0; batch classifier loss: 0.159095; batch adversarial loss: 0.452078\n",
      "epoch 23; iter: 0; batch classifier loss: 0.173795; batch adversarial loss: 0.412650\n",
      "epoch 24; iter: 0; batch classifier loss: 0.184005; batch adversarial loss: 0.543789\n",
      "epoch 25; iter: 0; batch classifier loss: 0.202719; batch adversarial loss: 0.485755\n",
      "epoch 26; iter: 0; batch classifier loss: 0.196596; batch adversarial loss: 0.463296\n",
      "epoch 27; iter: 0; batch classifier loss: 0.126988; batch adversarial loss: 0.504282\n",
      "epoch 28; iter: 0; batch classifier loss: 0.169122; batch adversarial loss: 0.492575\n",
      "epoch 29; iter: 0; batch classifier loss: 0.125777; batch adversarial loss: 0.509014\n",
      "epoch 30; iter: 0; batch classifier loss: 0.141972; batch adversarial loss: 0.490664\n",
      "epoch 31; iter: 0; batch classifier loss: 0.161500; batch adversarial loss: 0.411338\n",
      "epoch 32; iter: 0; batch classifier loss: 0.125542; batch adversarial loss: 0.478676\n",
      "epoch 33; iter: 0; batch classifier loss: 0.153134; batch adversarial loss: 0.472800\n",
      "epoch 34; iter: 0; batch classifier loss: 0.119117; batch adversarial loss: 0.543875\n",
      "epoch 35; iter: 0; batch classifier loss: 0.126060; batch adversarial loss: 0.519742\n",
      "epoch 36; iter: 0; batch classifier loss: 0.114318; batch adversarial loss: 0.451185\n",
      "epoch 37; iter: 0; batch classifier loss: 0.114343; batch adversarial loss: 0.516518\n",
      "epoch 38; iter: 0; batch classifier loss: 0.090978; batch adversarial loss: 0.435035\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107028; batch adversarial loss: 0.434887\n",
      "epoch 40; iter: 0; batch classifier loss: 0.150551; batch adversarial loss: 0.436561\n",
      "epoch 41; iter: 0; batch classifier loss: 0.086285; batch adversarial loss: 0.424852\n",
      "epoch 42; iter: 0; batch classifier loss: 0.100476; batch adversarial loss: 0.483644\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117774; batch adversarial loss: 0.455204\n",
      "epoch 44; iter: 0; batch classifier loss: 0.100807; batch adversarial loss: 0.486926\n",
      "epoch 45; iter: 0; batch classifier loss: 0.110138; batch adversarial loss: 0.522162\n",
      "epoch 46; iter: 0; batch classifier loss: 0.123990; batch adversarial loss: 0.387606\n",
      "epoch 47; iter: 0; batch classifier loss: 0.069852; batch adversarial loss: 0.437130\n",
      "epoch 48; iter: 0; batch classifier loss: 0.084470; batch adversarial loss: 0.395554\n",
      "epoch 49; iter: 0; batch classifier loss: 0.096978; batch adversarial loss: 0.426380\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074484; batch adversarial loss: 0.516963\n",
      "epoch 51; iter: 0; batch classifier loss: 0.080118; batch adversarial loss: 0.496240\n",
      "epoch 52; iter: 0; batch classifier loss: 0.069202; batch adversarial loss: 0.487260\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098213; batch adversarial loss: 0.490029\n",
      "epoch 54; iter: 0; batch classifier loss: 0.107992; batch adversarial loss: 0.465304\n",
      "epoch 55; iter: 0; batch classifier loss: 0.061295; batch adversarial loss: 0.417683\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065095; batch adversarial loss: 0.451758\n",
      "epoch 57; iter: 0; batch classifier loss: 0.089245; batch adversarial loss: 0.409967\n",
      "epoch 58; iter: 0; batch classifier loss: 0.075191; batch adversarial loss: 0.408682\n",
      "epoch 59; iter: 0; batch classifier loss: 0.062031; batch adversarial loss: 0.523795\n",
      "epoch 60; iter: 0; batch classifier loss: 0.111927; batch adversarial loss: 0.419072\n",
      "epoch 61; iter: 0; batch classifier loss: 0.035802; batch adversarial loss: 0.535696\n",
      "epoch 62; iter: 0; batch classifier loss: 0.048818; batch adversarial loss: 0.543693\n",
      "epoch 63; iter: 0; batch classifier loss: 0.074736; batch adversarial loss: 0.478347\n",
      "epoch 64; iter: 0; batch classifier loss: 0.093567; batch adversarial loss: 0.531377\n",
      "epoch 65; iter: 0; batch classifier loss: 0.058845; batch adversarial loss: 0.383103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.043969; batch adversarial loss: 0.380532\n",
      "epoch 67; iter: 0; batch classifier loss: 0.071776; batch adversarial loss: 0.543461\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096606; batch adversarial loss: 0.337023\n",
      "epoch 69; iter: 0; batch classifier loss: 0.070869; batch adversarial loss: 0.496920\n",
      "epoch 70; iter: 0; batch classifier loss: 0.080704; batch adversarial loss: 0.536250\n",
      "epoch 71; iter: 0; batch classifier loss: 0.070488; batch adversarial loss: 0.418405\n",
      "epoch 72; iter: 0; batch classifier loss: 0.063601; batch adversarial loss: 0.457488\n",
      "epoch 73; iter: 0; batch classifier loss: 0.035984; batch adversarial loss: 0.477127\n",
      "epoch 74; iter: 0; batch classifier loss: 0.050765; batch adversarial loss: 0.488619\n",
      "epoch 75; iter: 0; batch classifier loss: 0.080860; batch adversarial loss: 0.477314\n",
      "epoch 76; iter: 0; batch classifier loss: 0.048224; batch adversarial loss: 0.449737\n",
      "epoch 77; iter: 0; batch classifier loss: 0.035403; batch adversarial loss: 0.488366\n",
      "epoch 78; iter: 0; batch classifier loss: 0.040692; batch adversarial loss: 0.457945\n",
      "epoch 79; iter: 0; batch classifier loss: 0.025686; batch adversarial loss: 0.433706\n",
      "epoch 80; iter: 0; batch classifier loss: 0.048312; batch adversarial loss: 0.467948\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055230; batch adversarial loss: 0.388187\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067333; batch adversarial loss: 0.429979\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063620; batch adversarial loss: 0.428502\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070690; batch adversarial loss: 0.489143\n",
      "epoch 85; iter: 0; batch classifier loss: 0.066891; batch adversarial loss: 0.508005\n",
      "epoch 86; iter: 0; batch classifier loss: 0.033838; batch adversarial loss: 0.453356\n",
      "epoch 87; iter: 0; batch classifier loss: 0.050592; batch adversarial loss: 0.436066\n",
      "epoch 88; iter: 0; batch classifier loss: 0.025246; batch adversarial loss: 0.482634\n",
      "epoch 89; iter: 0; batch classifier loss: 0.077627; batch adversarial loss: 0.435342\n",
      "epoch 90; iter: 0; batch classifier loss: 0.055052; batch adversarial loss: 0.433880\n",
      "epoch 91; iter: 0; batch classifier loss: 0.036551; batch adversarial loss: 0.465925\n",
      "epoch 92; iter: 0; batch classifier loss: 0.028025; batch adversarial loss: 0.422088\n",
      "epoch 93; iter: 0; batch classifier loss: 0.034876; batch adversarial loss: 0.501607\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053713; batch adversarial loss: 0.475584\n",
      "epoch 95; iter: 0; batch classifier loss: 0.034555; batch adversarial loss: 0.478935\n",
      "epoch 96; iter: 0; batch classifier loss: 0.042728; batch adversarial loss: 0.519941\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043950; batch adversarial loss: 0.393176\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058965; batch adversarial loss: 0.457577\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049545; batch adversarial loss: 0.441276\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044095; batch adversarial loss: 0.432754\n",
      "epoch 101; iter: 0; batch classifier loss: 0.036348; batch adversarial loss: 0.426951\n",
      "epoch 102; iter: 0; batch classifier loss: 0.030067; batch adversarial loss: 0.405719\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037733; batch adversarial loss: 0.482739\n",
      "epoch 104; iter: 0; batch classifier loss: 0.081089; batch adversarial loss: 0.467899\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040555; batch adversarial loss: 0.381795\n",
      "epoch 106; iter: 0; batch classifier loss: 0.074124; batch adversarial loss: 0.461079\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033431; batch adversarial loss: 0.441774\n",
      "epoch 108; iter: 0; batch classifier loss: 0.029077; batch adversarial loss: 0.401496\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044409; batch adversarial loss: 0.428388\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026349; batch adversarial loss: 0.364029\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028112; batch adversarial loss: 0.422663\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055437; batch adversarial loss: 0.428916\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045465; batch adversarial loss: 0.499942\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044203; batch adversarial loss: 0.440866\n",
      "epoch 115; iter: 0; batch classifier loss: 0.064381; batch adversarial loss: 0.446033\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036104; batch adversarial loss: 0.490511\n",
      "epoch 117; iter: 0; batch classifier loss: 0.019003; batch adversarial loss: 0.454403\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025641; batch adversarial loss: 0.469897\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030380; batch adversarial loss: 0.582436\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027858; batch adversarial loss: 0.402729\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041983; batch adversarial loss: 0.455278\n",
      "epoch 122; iter: 0; batch classifier loss: 0.013709; batch adversarial loss: 0.462098\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023324; batch adversarial loss: 0.470881\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027998; batch adversarial loss: 0.426901\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020420; batch adversarial loss: 0.452510\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021621; batch adversarial loss: 0.399654\n",
      "epoch 127; iter: 0; batch classifier loss: 0.012550; batch adversarial loss: 0.429156\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021311; batch adversarial loss: 0.497870\n",
      "epoch 129; iter: 0; batch classifier loss: 0.014905; batch adversarial loss: 0.408133\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018220; batch adversarial loss: 0.448636\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039137; batch adversarial loss: 0.528070\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037359; batch adversarial loss: 0.459799\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023910; batch adversarial loss: 0.489431\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034518; batch adversarial loss: 0.619607\n",
      "epoch 135; iter: 0; batch classifier loss: 0.017713; batch adversarial loss: 0.508036\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020606; batch adversarial loss: 0.487153\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035735; batch adversarial loss: 0.501461\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031626; batch adversarial loss: 0.433483\n",
      "epoch 139; iter: 0; batch classifier loss: 0.008072; batch adversarial loss: 0.465398\n",
      "epoch 140; iter: 0; batch classifier loss: 0.016284; batch adversarial loss: 0.406267\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040916; batch adversarial loss: 0.440359\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045192; batch adversarial loss: 0.424177\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041301; batch adversarial loss: 0.404398\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025711; batch adversarial loss: 0.390333\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024807; batch adversarial loss: 0.475012\n",
      "epoch 146; iter: 0; batch classifier loss: 0.012703; batch adversarial loss: 0.468454\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036318; batch adversarial loss: 0.517943\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021610; batch adversarial loss: 0.457013\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020727; batch adversarial loss: 0.443733\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020452; batch adversarial loss: 0.475381\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018682; batch adversarial loss: 0.539333\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024556; batch adversarial loss: 0.457737\n",
      "epoch 153; iter: 0; batch classifier loss: 0.050106; batch adversarial loss: 0.502792\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036048; batch adversarial loss: 0.443321\n",
      "epoch 155; iter: 0; batch classifier loss: 0.039313; batch adversarial loss: 0.369294\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016469; batch adversarial loss: 0.415063\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028000; batch adversarial loss: 0.463693\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034782; batch adversarial loss: 0.430985\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018761; batch adversarial loss: 0.404418\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015032; batch adversarial loss: 0.524048\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025531; batch adversarial loss: 0.462695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.025351; batch adversarial loss: 0.480371\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034128; batch adversarial loss: 0.384847\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024221; batch adversarial loss: 0.517071\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019923; batch adversarial loss: 0.375171\n",
      "epoch 166; iter: 0; batch classifier loss: 0.008180; batch adversarial loss: 0.413906\n",
      "epoch 167; iter: 0; batch classifier loss: 0.047075; batch adversarial loss: 0.435093\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014987; batch adversarial loss: 0.451880\n",
      "epoch 169; iter: 0; batch classifier loss: 0.003986; batch adversarial loss: 0.513427\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022967; batch adversarial loss: 0.439434\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022965; batch adversarial loss: 0.440177\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013438; batch adversarial loss: 0.463966\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022133; batch adversarial loss: 0.533391\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038598; batch adversarial loss: 0.526765\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009786; batch adversarial loss: 0.407814\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017584; batch adversarial loss: 0.510799\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008822; batch adversarial loss: 0.460546\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018666; batch adversarial loss: 0.581875\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035223; batch adversarial loss: 0.462356\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032826; batch adversarial loss: 0.476309\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021623; batch adversarial loss: 0.449721\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025439; batch adversarial loss: 0.460694\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034900; batch adversarial loss: 0.422765\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028590; batch adversarial loss: 0.459697\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008122; batch adversarial loss: 0.507963\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016093; batch adversarial loss: 0.447166\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007189; batch adversarial loss: 0.403965\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009327; batch adversarial loss: 0.458510\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010376; batch adversarial loss: 0.465243\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016904; batch adversarial loss: 0.466381\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010114; batch adversarial loss: 0.400246\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037795; batch adversarial loss: 0.450947\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037124; batch adversarial loss: 0.378711\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021851; batch adversarial loss: 0.331600\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022816; batch adversarial loss: 0.377548\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023535; batch adversarial loss: 0.432751\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022033; batch adversarial loss: 0.449891\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002784; batch adversarial loss: 0.490450\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017815; batch adversarial loss: 0.511642\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685687; batch adversarial loss: 0.852382\n",
      "epoch 1; iter: 0; batch classifier loss: 0.555003; batch adversarial loss: 0.946440\n",
      "epoch 2; iter: 0; batch classifier loss: 0.569538; batch adversarial loss: 0.907462\n",
      "epoch 3; iter: 0; batch classifier loss: 0.937056; batch adversarial loss: 0.857243\n",
      "epoch 4; iter: 0; batch classifier loss: 0.983282; batch adversarial loss: 0.772443\n",
      "epoch 5; iter: 0; batch classifier loss: 0.856903; batch adversarial loss: 0.697607\n",
      "epoch 6; iter: 0; batch classifier loss: 0.917029; batch adversarial loss: 0.622822\n",
      "epoch 7; iter: 0; batch classifier loss: 0.800504; batch adversarial loss: 0.570331\n",
      "epoch 8; iter: 0; batch classifier loss: 0.360552; batch adversarial loss: 0.572418\n",
      "epoch 9; iter: 0; batch classifier loss: 0.440374; batch adversarial loss: 0.537921\n",
      "epoch 10; iter: 0; batch classifier loss: 0.359429; batch adversarial loss: 0.557741\n",
      "epoch 11; iter: 0; batch classifier loss: 0.317682; batch adversarial loss: 0.513765\n",
      "epoch 12; iter: 0; batch classifier loss: 0.347111; batch adversarial loss: 0.481802\n",
      "epoch 13; iter: 0; batch classifier loss: 0.338233; batch adversarial loss: 0.514966\n",
      "epoch 14; iter: 0; batch classifier loss: 0.408394; batch adversarial loss: 0.541336\n",
      "epoch 15; iter: 0; batch classifier loss: 0.327720; batch adversarial loss: 0.528955\n",
      "epoch 16; iter: 0; batch classifier loss: 0.315565; batch adversarial loss: 0.549568\n",
      "epoch 17; iter: 0; batch classifier loss: 0.309409; batch adversarial loss: 0.484343\n",
      "epoch 18; iter: 0; batch classifier loss: 0.387363; batch adversarial loss: 0.441109\n",
      "epoch 19; iter: 0; batch classifier loss: 0.398374; batch adversarial loss: 0.461780\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222508; batch adversarial loss: 0.465007\n",
      "epoch 21; iter: 0; batch classifier loss: 0.305006; batch adversarial loss: 0.492906\n",
      "epoch 22; iter: 0; batch classifier loss: 0.249492; batch adversarial loss: 0.475027\n",
      "epoch 23; iter: 0; batch classifier loss: 0.332998; batch adversarial loss: 0.499134\n",
      "epoch 24; iter: 0; batch classifier loss: 0.268311; batch adversarial loss: 0.434201\n",
      "epoch 25; iter: 0; batch classifier loss: 0.297904; batch adversarial loss: 0.457903\n",
      "epoch 26; iter: 0; batch classifier loss: 0.363044; batch adversarial loss: 0.452729\n",
      "epoch 27; iter: 0; batch classifier loss: 0.279278; batch adversarial loss: 0.468695\n",
      "epoch 28; iter: 0; batch classifier loss: 0.222515; batch adversarial loss: 0.493336\n",
      "epoch 29; iter: 0; batch classifier loss: 0.235667; batch adversarial loss: 0.440805\n",
      "epoch 30; iter: 0; batch classifier loss: 0.260197; batch adversarial loss: 0.502672\n",
      "epoch 31; iter: 0; batch classifier loss: 0.277916; batch adversarial loss: 0.497101\n",
      "epoch 32; iter: 0; batch classifier loss: 0.270715; batch adversarial loss: 0.502483\n",
      "epoch 33; iter: 0; batch classifier loss: 0.295757; batch adversarial loss: 0.431637\n",
      "epoch 34; iter: 0; batch classifier loss: 0.276425; batch adversarial loss: 0.405365\n",
      "epoch 35; iter: 0; batch classifier loss: 0.203507; batch adversarial loss: 0.467440\n",
      "epoch 36; iter: 0; batch classifier loss: 0.314224; batch adversarial loss: 0.379627\n",
      "epoch 37; iter: 0; batch classifier loss: 0.254499; batch adversarial loss: 0.523523\n",
      "epoch 38; iter: 0; batch classifier loss: 0.274975; batch adversarial loss: 0.413824\n",
      "epoch 39; iter: 0; batch classifier loss: 0.256906; batch adversarial loss: 0.499989\n",
      "epoch 40; iter: 0; batch classifier loss: 0.265334; batch adversarial loss: 0.393208\n",
      "epoch 41; iter: 0; batch classifier loss: 0.247181; batch adversarial loss: 0.440546\n",
      "epoch 42; iter: 0; batch classifier loss: 0.201552; batch adversarial loss: 0.484462\n",
      "epoch 43; iter: 0; batch classifier loss: 0.233801; batch adversarial loss: 0.395773\n",
      "epoch 44; iter: 0; batch classifier loss: 0.194450; batch adversarial loss: 0.473845\n",
      "epoch 45; iter: 0; batch classifier loss: 0.243975; batch adversarial loss: 0.423124\n",
      "epoch 46; iter: 0; batch classifier loss: 0.242553; batch adversarial loss: 0.516169\n",
      "epoch 47; iter: 0; batch classifier loss: 0.221673; batch adversarial loss: 0.545816\n",
      "epoch 48; iter: 0; batch classifier loss: 0.239624; batch adversarial loss: 0.423019\n",
      "epoch 49; iter: 0; batch classifier loss: 0.172432; batch adversarial loss: 0.518595\n",
      "epoch 50; iter: 0; batch classifier loss: 0.225476; batch adversarial loss: 0.473156\n",
      "epoch 51; iter: 0; batch classifier loss: 0.206579; batch adversarial loss: 0.467239\n",
      "epoch 52; iter: 0; batch classifier loss: 0.184824; batch adversarial loss: 0.495968\n",
      "epoch 53; iter: 0; batch classifier loss: 0.289157; batch adversarial loss: 0.445593\n",
      "epoch 54; iter: 0; batch classifier loss: 0.159087; batch adversarial loss: 0.485505\n",
      "epoch 55; iter: 0; batch classifier loss: 0.162185; batch adversarial loss: 0.431966\n",
      "epoch 56; iter: 0; batch classifier loss: 0.143275; batch adversarial loss: 0.431925\n",
      "epoch 57; iter: 0; batch classifier loss: 0.257049; batch adversarial loss: 0.414219\n",
      "epoch 58; iter: 0; batch classifier loss: 0.216822; batch adversarial loss: 0.495722\n",
      "epoch 59; iter: 0; batch classifier loss: 0.170994; batch adversarial loss: 0.551539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.197841; batch adversarial loss: 0.509583\n",
      "epoch 61; iter: 0; batch classifier loss: 0.245044; batch adversarial loss: 0.364414\n",
      "epoch 62; iter: 0; batch classifier loss: 0.227906; batch adversarial loss: 0.521368\n",
      "epoch 63; iter: 0; batch classifier loss: 0.136851; batch adversarial loss: 0.374211\n",
      "epoch 64; iter: 0; batch classifier loss: 0.133512; batch adversarial loss: 0.532224\n",
      "epoch 65; iter: 0; batch classifier loss: 0.212217; batch adversarial loss: 0.449476\n",
      "epoch 66; iter: 0; batch classifier loss: 0.183370; batch adversarial loss: 0.385631\n",
      "epoch 67; iter: 0; batch classifier loss: 0.205484; batch adversarial loss: 0.473485\n",
      "epoch 68; iter: 0; batch classifier loss: 0.164942; batch adversarial loss: 0.360408\n",
      "epoch 69; iter: 0; batch classifier loss: 0.165556; batch adversarial loss: 0.421106\n",
      "epoch 70; iter: 0; batch classifier loss: 0.147947; batch adversarial loss: 0.544676\n",
      "epoch 71; iter: 0; batch classifier loss: 0.201039; batch adversarial loss: 0.434216\n",
      "epoch 72; iter: 0; batch classifier loss: 0.211919; batch adversarial loss: 0.424422\n",
      "epoch 73; iter: 0; batch classifier loss: 0.161095; batch adversarial loss: 0.459860\n",
      "epoch 74; iter: 0; batch classifier loss: 0.192178; batch adversarial loss: 0.397865\n",
      "epoch 75; iter: 0; batch classifier loss: 0.136848; batch adversarial loss: 0.495773\n",
      "epoch 76; iter: 0; batch classifier loss: 0.202773; batch adversarial loss: 0.458913\n",
      "epoch 77; iter: 0; batch classifier loss: 0.142189; batch adversarial loss: 0.385029\n",
      "epoch 78; iter: 0; batch classifier loss: 0.184775; batch adversarial loss: 0.518323\n",
      "epoch 79; iter: 0; batch classifier loss: 0.234794; batch adversarial loss: 0.360052\n",
      "epoch 80; iter: 0; batch classifier loss: 0.145955; batch adversarial loss: 0.533886\n",
      "epoch 81; iter: 0; batch classifier loss: 0.181814; batch adversarial loss: 0.448770\n",
      "epoch 82; iter: 0; batch classifier loss: 0.240696; batch adversarial loss: 0.395790\n",
      "epoch 83; iter: 0; batch classifier loss: 0.156701; batch adversarial loss: 0.469624\n",
      "epoch 84; iter: 0; batch classifier loss: 0.224021; batch adversarial loss: 0.422150\n",
      "epoch 85; iter: 0; batch classifier loss: 0.184774; batch adversarial loss: 0.434150\n",
      "epoch 86; iter: 0; batch classifier loss: 0.199708; batch adversarial loss: 0.434745\n",
      "epoch 87; iter: 0; batch classifier loss: 0.116826; batch adversarial loss: 0.520294\n",
      "epoch 88; iter: 0; batch classifier loss: 0.154845; batch adversarial loss: 0.409360\n",
      "epoch 89; iter: 0; batch classifier loss: 0.171648; batch adversarial loss: 0.521241\n",
      "epoch 90; iter: 0; batch classifier loss: 0.147707; batch adversarial loss: 0.508107\n",
      "epoch 91; iter: 0; batch classifier loss: 0.145756; batch adversarial loss: 0.371734\n",
      "epoch 92; iter: 0; batch classifier loss: 0.152390; batch adversarial loss: 0.435599\n",
      "epoch 93; iter: 0; batch classifier loss: 0.214962; batch adversarial loss: 0.435009\n",
      "epoch 94; iter: 0; batch classifier loss: 0.151373; batch adversarial loss: 0.483192\n",
      "epoch 95; iter: 0; batch classifier loss: 0.183518; batch adversarial loss: 0.410738\n",
      "epoch 96; iter: 0; batch classifier loss: 0.189032; batch adversarial loss: 0.557069\n",
      "epoch 97; iter: 0; batch classifier loss: 0.180848; batch adversarial loss: 0.544708\n",
      "epoch 98; iter: 0; batch classifier loss: 0.189102; batch adversarial loss: 0.397079\n",
      "epoch 99; iter: 0; batch classifier loss: 0.183687; batch adversarial loss: 0.435213\n",
      "epoch 100; iter: 0; batch classifier loss: 0.141829; batch adversarial loss: 0.483390\n",
      "epoch 101; iter: 0; batch classifier loss: 0.152339; batch adversarial loss: 0.422452\n",
      "epoch 102; iter: 0; batch classifier loss: 0.203102; batch adversarial loss: 0.520043\n",
      "epoch 103; iter: 0; batch classifier loss: 0.140359; batch adversarial loss: 0.420780\n",
      "epoch 104; iter: 0; batch classifier loss: 0.165073; batch adversarial loss: 0.568273\n",
      "epoch 105; iter: 0; batch classifier loss: 0.195400; batch adversarial loss: 0.507406\n",
      "epoch 106; iter: 0; batch classifier loss: 0.154002; batch adversarial loss: 0.434448\n",
      "epoch 107; iter: 0; batch classifier loss: 0.182135; batch adversarial loss: 0.459557\n",
      "epoch 108; iter: 0; batch classifier loss: 0.169299; batch adversarial loss: 0.409300\n",
      "epoch 109; iter: 0; batch classifier loss: 0.150530; batch adversarial loss: 0.421460\n",
      "epoch 110; iter: 0; batch classifier loss: 0.167303; batch adversarial loss: 0.433529\n",
      "epoch 111; iter: 0; batch classifier loss: 0.187190; batch adversarial loss: 0.472068\n",
      "epoch 112; iter: 0; batch classifier loss: 0.174225; batch adversarial loss: 0.446988\n",
      "epoch 113; iter: 0; batch classifier loss: 0.186263; batch adversarial loss: 0.457918\n",
      "epoch 114; iter: 0; batch classifier loss: 0.158487; batch adversarial loss: 0.398863\n",
      "epoch 115; iter: 0; batch classifier loss: 0.192218; batch adversarial loss: 0.373655\n",
      "epoch 116; iter: 0; batch classifier loss: 0.232495; batch adversarial loss: 0.459520\n",
      "epoch 117; iter: 0; batch classifier loss: 0.141533; batch adversarial loss: 0.373184\n",
      "epoch 118; iter: 0; batch classifier loss: 0.135742; batch adversarial loss: 0.498314\n",
      "epoch 119; iter: 0; batch classifier loss: 0.151598; batch adversarial loss: 0.521964\n",
      "epoch 120; iter: 0; batch classifier loss: 0.175127; batch adversarial loss: 0.447020\n",
      "epoch 121; iter: 0; batch classifier loss: 0.178346; batch adversarial loss: 0.397646\n",
      "epoch 122; iter: 0; batch classifier loss: 0.196399; batch adversarial loss: 0.481950\n",
      "epoch 123; iter: 0; batch classifier loss: 0.133813; batch adversarial loss: 0.421809\n",
      "epoch 124; iter: 0; batch classifier loss: 0.148152; batch adversarial loss: 0.407829\n",
      "epoch 125; iter: 0; batch classifier loss: 0.181483; batch adversarial loss: 0.358990\n",
      "epoch 126; iter: 0; batch classifier loss: 0.155180; batch adversarial loss: 0.408625\n",
      "epoch 127; iter: 0; batch classifier loss: 0.128578; batch adversarial loss: 0.532533\n",
      "epoch 128; iter: 0; batch classifier loss: 0.156782; batch adversarial loss: 0.445472\n",
      "epoch 129; iter: 0; batch classifier loss: 0.192147; batch adversarial loss: 0.544988\n",
      "epoch 130; iter: 0; batch classifier loss: 0.127785; batch adversarial loss: 0.484001\n",
      "epoch 131; iter: 0; batch classifier loss: 0.145598; batch adversarial loss: 0.531353\n",
      "epoch 132; iter: 0; batch classifier loss: 0.118705; batch adversarial loss: 0.495237\n",
      "epoch 133; iter: 0; batch classifier loss: 0.216626; batch adversarial loss: 0.520527\n",
      "epoch 134; iter: 0; batch classifier loss: 0.172682; batch adversarial loss: 0.519137\n",
      "epoch 135; iter: 0; batch classifier loss: 0.144110; batch adversarial loss: 0.445511\n",
      "epoch 136; iter: 0; batch classifier loss: 0.126364; batch adversarial loss: 0.335399\n",
      "epoch 137; iter: 0; batch classifier loss: 0.088424; batch adversarial loss: 0.558311\n",
      "epoch 138; iter: 0; batch classifier loss: 0.145188; batch adversarial loss: 0.431686\n",
      "epoch 139; iter: 0; batch classifier loss: 0.136660; batch adversarial loss: 0.579805\n",
      "epoch 140; iter: 0; batch classifier loss: 0.122077; batch adversarial loss: 0.439091\n",
      "epoch 141; iter: 0; batch classifier loss: 0.098515; batch adversarial loss: 0.418443\n",
      "epoch 142; iter: 0; batch classifier loss: 0.065640; batch adversarial loss: 0.441200\n",
      "epoch 143; iter: 0; batch classifier loss: 0.053247; batch adversarial loss: 0.531581\n",
      "epoch 144; iter: 0; batch classifier loss: 0.090969; batch adversarial loss: 0.403310\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023447; batch adversarial loss: 0.468495\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039090; batch adversarial loss: 0.438834\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038350; batch adversarial loss: 0.470536\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025249; batch adversarial loss: 0.426608\n",
      "epoch 149; iter: 0; batch classifier loss: 0.076254; batch adversarial loss: 0.405988\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044421; batch adversarial loss: 0.479730\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039403; batch adversarial loss: 0.561490\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023413; batch adversarial loss: 0.491123\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034844; batch adversarial loss: 0.459179\n",
      "epoch 154; iter: 0; batch classifier loss: 0.063269; batch adversarial loss: 0.475802\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030453; batch adversarial loss: 0.525074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.043560; batch adversarial loss: 0.481329\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019786; batch adversarial loss: 0.460990\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014088; batch adversarial loss: 0.498146\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031059; batch adversarial loss: 0.435585\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027182; batch adversarial loss: 0.414229\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018902; batch adversarial loss: 0.429875\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015433; batch adversarial loss: 0.529488\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022501; batch adversarial loss: 0.603918\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014606; batch adversarial loss: 0.455731\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024902; batch adversarial loss: 0.407335\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015109; batch adversarial loss: 0.487563\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015250; batch adversarial loss: 0.502174\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030922; batch adversarial loss: 0.422938\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017522; batch adversarial loss: 0.440020\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016475; batch adversarial loss: 0.420287\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032987; batch adversarial loss: 0.434412\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017433; batch adversarial loss: 0.460454\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037341; batch adversarial loss: 0.478637\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033278; batch adversarial loss: 0.309872\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028118; batch adversarial loss: 0.508941\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022233; batch adversarial loss: 0.465165\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011902; batch adversarial loss: 0.476950\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006562; batch adversarial loss: 0.463391\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015478; batch adversarial loss: 0.406812\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012877; batch adversarial loss: 0.450820\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035128; batch adversarial loss: 0.388411\n",
      "epoch 182; iter: 0; batch classifier loss: 0.040270; batch adversarial loss: 0.461676\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012573; batch adversarial loss: 0.469076\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009867; batch adversarial loss: 0.477008\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024147; batch adversarial loss: 0.463996\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007194; batch adversarial loss: 0.460640\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022104; batch adversarial loss: 0.533379\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013450; batch adversarial loss: 0.478679\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014249; batch adversarial loss: 0.484693\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022542; batch adversarial loss: 0.354159\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012277; batch adversarial loss: 0.497587\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010333; batch adversarial loss: 0.492918\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008158; batch adversarial loss: 0.434041\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009747; batch adversarial loss: 0.387555\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012243; batch adversarial loss: 0.426447\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026386; batch adversarial loss: 0.472842\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005183; batch adversarial loss: 0.407732\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021297; batch adversarial loss: 0.407670\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014529; batch adversarial loss: 0.446734\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687315; batch adversarial loss: 0.655637\n",
      "epoch 1; iter: 0; batch classifier loss: 0.552396; batch adversarial loss: 0.606744\n",
      "epoch 2; iter: 0; batch classifier loss: 0.467546; batch adversarial loss: 0.615059\n",
      "epoch 3; iter: 0; batch classifier loss: 0.463196; batch adversarial loss: 0.576374\n",
      "epoch 4; iter: 0; batch classifier loss: 0.435137; batch adversarial loss: 0.594042\n",
      "epoch 5; iter: 0; batch classifier loss: 0.384766; batch adversarial loss: 0.586099\n",
      "epoch 6; iter: 0; batch classifier loss: 0.394397; batch adversarial loss: 0.472472\n",
      "epoch 7; iter: 0; batch classifier loss: 0.261468; batch adversarial loss: 0.566519\n",
      "epoch 8; iter: 0; batch classifier loss: 0.339664; batch adversarial loss: 0.600097\n",
      "epoch 9; iter: 0; batch classifier loss: 0.367610; batch adversarial loss: 0.547330\n",
      "epoch 10; iter: 0; batch classifier loss: 0.338325; batch adversarial loss: 0.509207\n",
      "epoch 11; iter: 0; batch classifier loss: 0.301438; batch adversarial loss: 0.512114\n",
      "epoch 12; iter: 0; batch classifier loss: 0.289049; batch adversarial loss: 0.520959\n",
      "epoch 13; iter: 0; batch classifier loss: 0.286794; batch adversarial loss: 0.520862\n",
      "epoch 14; iter: 0; batch classifier loss: 0.284159; batch adversarial loss: 0.521424\n",
      "epoch 15; iter: 0; batch classifier loss: 0.215778; batch adversarial loss: 0.527986\n",
      "epoch 16; iter: 0; batch classifier loss: 0.206400; batch adversarial loss: 0.522808\n",
      "epoch 17; iter: 0; batch classifier loss: 0.248259; batch adversarial loss: 0.503100\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214212; batch adversarial loss: 0.539131\n",
      "epoch 19; iter: 0; batch classifier loss: 0.193097; batch adversarial loss: 0.547526\n",
      "epoch 20; iter: 0; batch classifier loss: 0.238816; batch adversarial loss: 0.442804\n",
      "epoch 21; iter: 0; batch classifier loss: 0.198950; batch adversarial loss: 0.505703\n",
      "epoch 22; iter: 0; batch classifier loss: 0.207647; batch adversarial loss: 0.472240\n",
      "epoch 23; iter: 0; batch classifier loss: 0.232302; batch adversarial loss: 0.424723\n",
      "epoch 24; iter: 0; batch classifier loss: 0.240018; batch adversarial loss: 0.443506\n",
      "epoch 25; iter: 0; batch classifier loss: 0.205938; batch adversarial loss: 0.492057\n",
      "epoch 26; iter: 0; batch classifier loss: 0.154898; batch adversarial loss: 0.403827\n",
      "epoch 27; iter: 0; batch classifier loss: 0.189597; batch adversarial loss: 0.477372\n",
      "epoch 28; iter: 0; batch classifier loss: 0.160661; batch adversarial loss: 0.537757\n",
      "epoch 29; iter: 0; batch classifier loss: 0.213425; batch adversarial loss: 0.489873\n",
      "epoch 30; iter: 0; batch classifier loss: 0.146446; batch adversarial loss: 0.469343\n",
      "epoch 31; iter: 0; batch classifier loss: 0.180892; batch adversarial loss: 0.458547\n",
      "epoch 32; iter: 0; batch classifier loss: 0.176362; batch adversarial loss: 0.512986\n",
      "epoch 33; iter: 0; batch classifier loss: 0.231310; batch adversarial loss: 0.478837\n",
      "epoch 34; iter: 0; batch classifier loss: 0.215567; batch adversarial loss: 0.457148\n",
      "epoch 35; iter: 0; batch classifier loss: 0.175880; batch adversarial loss: 0.486375\n",
      "epoch 36; iter: 0; batch classifier loss: 0.220819; batch adversarial loss: 0.473409\n",
      "epoch 37; iter: 0; batch classifier loss: 0.218821; batch adversarial loss: 0.425066\n",
      "epoch 38; iter: 0; batch classifier loss: 0.240739; batch adversarial loss: 0.461698\n",
      "epoch 39; iter: 0; batch classifier loss: 0.194697; batch adversarial loss: 0.532391\n",
      "epoch 40; iter: 0; batch classifier loss: 0.213089; batch adversarial loss: 0.481776\n",
      "epoch 41; iter: 0; batch classifier loss: 0.255253; batch adversarial loss: 0.404422\n",
      "epoch 42; iter: 0; batch classifier loss: 0.238759; batch adversarial loss: 0.432128\n",
      "epoch 43; iter: 0; batch classifier loss: 0.185402; batch adversarial loss: 0.452934\n",
      "epoch 44; iter: 0; batch classifier loss: 0.162336; batch adversarial loss: 0.414147\n",
      "epoch 45; iter: 0; batch classifier loss: 0.197517; batch adversarial loss: 0.472801\n",
      "epoch 46; iter: 0; batch classifier loss: 0.222226; batch adversarial loss: 0.496197\n",
      "epoch 47; iter: 0; batch classifier loss: 0.264530; batch adversarial loss: 0.449336\n",
      "epoch 48; iter: 0; batch classifier loss: 0.148836; batch adversarial loss: 0.540940\n",
      "epoch 49; iter: 0; batch classifier loss: 0.249316; batch adversarial loss: 0.482451\n",
      "epoch 50; iter: 0; batch classifier loss: 0.095321; batch adversarial loss: 0.530098\n",
      "epoch 51; iter: 0; batch classifier loss: 0.113045; batch adversarial loss: 0.494822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.063676; batch adversarial loss: 0.493712\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095225; batch adversarial loss: 0.497956\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103047; batch adversarial loss: 0.504745\n",
      "epoch 55; iter: 0; batch classifier loss: 0.107872; batch adversarial loss: 0.503224\n",
      "epoch 56; iter: 0; batch classifier loss: 0.223716; batch adversarial loss: 0.484822\n",
      "epoch 57; iter: 0; batch classifier loss: 0.152924; batch adversarial loss: 0.518032\n",
      "epoch 58; iter: 0; batch classifier loss: 0.098689; batch adversarial loss: 0.554002\n",
      "epoch 59; iter: 0; batch classifier loss: 0.106911; batch adversarial loss: 0.457168\n",
      "epoch 60; iter: 0; batch classifier loss: 0.163875; batch adversarial loss: 0.455925\n",
      "epoch 61; iter: 0; batch classifier loss: 0.199216; batch adversarial loss: 0.483233\n",
      "epoch 62; iter: 0; batch classifier loss: 0.126294; batch adversarial loss: 0.472950\n",
      "epoch 63; iter: 0; batch classifier loss: 0.124160; batch adversarial loss: 0.410050\n",
      "epoch 64; iter: 0; batch classifier loss: 0.139819; batch adversarial loss: 0.432829\n",
      "epoch 65; iter: 0; batch classifier loss: 0.125325; batch adversarial loss: 0.423218\n",
      "epoch 66; iter: 0; batch classifier loss: 0.171153; batch adversarial loss: 0.458966\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110062; batch adversarial loss: 0.498271\n",
      "epoch 68; iter: 0; batch classifier loss: 0.134476; batch adversarial loss: 0.494021\n",
      "epoch 69; iter: 0; batch classifier loss: 0.168670; batch adversarial loss: 0.480583\n",
      "epoch 70; iter: 0; batch classifier loss: 0.195834; batch adversarial loss: 0.444869\n",
      "epoch 71; iter: 0; batch classifier loss: 0.153810; batch adversarial loss: 0.482772\n",
      "epoch 72; iter: 0; batch classifier loss: 0.141338; batch adversarial loss: 0.484121\n",
      "epoch 73; iter: 0; batch classifier loss: 0.165104; batch adversarial loss: 0.473636\n",
      "epoch 74; iter: 0; batch classifier loss: 0.176300; batch adversarial loss: 0.460595\n",
      "epoch 75; iter: 0; batch classifier loss: 0.193984; batch adversarial loss: 0.423366\n",
      "epoch 76; iter: 0; batch classifier loss: 0.150608; batch adversarial loss: 0.483325\n",
      "epoch 77; iter: 0; batch classifier loss: 0.141185; batch adversarial loss: 0.461297\n",
      "epoch 78; iter: 0; batch classifier loss: 0.263325; batch adversarial loss: 0.373980\n",
      "epoch 79; iter: 0; batch classifier loss: 0.197376; batch adversarial loss: 0.386282\n",
      "epoch 80; iter: 0; batch classifier loss: 0.133898; batch adversarial loss: 0.398685\n",
      "epoch 81; iter: 0; batch classifier loss: 0.186074; batch adversarial loss: 0.457419\n",
      "epoch 82; iter: 0; batch classifier loss: 0.203688; batch adversarial loss: 0.506512\n",
      "epoch 83; iter: 0; batch classifier loss: 0.145451; batch adversarial loss: 0.579112\n",
      "epoch 84; iter: 0; batch classifier loss: 0.112942; batch adversarial loss: 0.458302\n",
      "epoch 85; iter: 0; batch classifier loss: 0.106236; batch adversarial loss: 0.446262\n",
      "epoch 86; iter: 0; batch classifier loss: 0.122112; batch adversarial loss: 0.470644\n",
      "epoch 87; iter: 0; batch classifier loss: 0.220124; batch adversarial loss: 0.482631\n",
      "epoch 88; iter: 0; batch classifier loss: 0.178251; batch adversarial loss: 0.312221\n",
      "epoch 89; iter: 0; batch classifier loss: 0.116697; batch adversarial loss: 0.578411\n",
      "epoch 90; iter: 0; batch classifier loss: 0.101803; batch adversarial loss: 0.583023\n",
      "epoch 91; iter: 0; batch classifier loss: 0.118134; batch adversarial loss: 0.642485\n",
      "epoch 92; iter: 0; batch classifier loss: 0.118991; batch adversarial loss: 0.469897\n",
      "epoch 93; iter: 0; batch classifier loss: 0.137639; batch adversarial loss: 0.471153\n",
      "epoch 94; iter: 0; batch classifier loss: 0.130572; batch adversarial loss: 0.421013\n",
      "epoch 95; iter: 0; batch classifier loss: 0.104834; batch adversarial loss: 0.470601\n",
      "epoch 96; iter: 0; batch classifier loss: 0.088795; batch adversarial loss: 0.420071\n",
      "epoch 97; iter: 0; batch classifier loss: 0.089051; batch adversarial loss: 0.472247\n",
      "epoch 98; iter: 0; batch classifier loss: 0.076629; batch adversarial loss: 0.519676\n",
      "epoch 99; iter: 0; batch classifier loss: 0.091454; batch adversarial loss: 0.483047\n",
      "epoch 100; iter: 0; batch classifier loss: 0.084119; batch adversarial loss: 0.401314\n",
      "epoch 101; iter: 0; batch classifier loss: 0.096353; batch adversarial loss: 0.425683\n",
      "epoch 102; iter: 0; batch classifier loss: 0.069653; batch adversarial loss: 0.436680\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058302; batch adversarial loss: 0.503733\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045724; batch adversarial loss: 0.463589\n",
      "epoch 105; iter: 0; batch classifier loss: 0.065242; batch adversarial loss: 0.411696\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043486; batch adversarial loss: 0.428248\n",
      "epoch 107; iter: 0; batch classifier loss: 0.073903; batch adversarial loss: 0.380003\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046815; batch adversarial loss: 0.466251\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060937; batch adversarial loss: 0.463302\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046359; batch adversarial loss: 0.452277\n",
      "epoch 111; iter: 0; batch classifier loss: 0.072261; batch adversarial loss: 0.456576\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051499; batch adversarial loss: 0.412510\n",
      "epoch 113; iter: 0; batch classifier loss: 0.036616; batch adversarial loss: 0.385289\n",
      "epoch 114; iter: 0; batch classifier loss: 0.089800; batch adversarial loss: 0.459934\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052213; batch adversarial loss: 0.551331\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035174; batch adversarial loss: 0.366990\n",
      "epoch 117; iter: 0; batch classifier loss: 0.079765; batch adversarial loss: 0.432564\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042147; batch adversarial loss: 0.402444\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034589; batch adversarial loss: 0.435883\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034716; batch adversarial loss: 0.431838\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036932; batch adversarial loss: 0.452595\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043692; batch adversarial loss: 0.529989\n",
      "epoch 123; iter: 0; batch classifier loss: 0.071206; batch adversarial loss: 0.420721\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057392; batch adversarial loss: 0.451033\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027414; batch adversarial loss: 0.454947\n",
      "epoch 126; iter: 0; batch classifier loss: 0.013069; batch adversarial loss: 0.474825\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026165; batch adversarial loss: 0.433314\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028323; batch adversarial loss: 0.491174\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029832; batch adversarial loss: 0.462405\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031193; batch adversarial loss: 0.547325\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030767; batch adversarial loss: 0.469199\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048233; batch adversarial loss: 0.532747\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035545; batch adversarial loss: 0.535635\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036834; batch adversarial loss: 0.414745\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020916; batch adversarial loss: 0.603373\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019263; batch adversarial loss: 0.448059\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031579; batch adversarial loss: 0.499596\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023667; batch adversarial loss: 0.493272\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032255; batch adversarial loss: 0.444811\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036849; batch adversarial loss: 0.505763\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022473; batch adversarial loss: 0.451038\n",
      "epoch 142; iter: 0; batch classifier loss: 0.047288; batch adversarial loss: 0.412518\n",
      "epoch 143; iter: 0; batch classifier loss: 0.007699; batch adversarial loss: 0.523862\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014179; batch adversarial loss: 0.422061\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033424; batch adversarial loss: 0.441619\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027067; batch adversarial loss: 0.516982\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037586; batch adversarial loss: 0.378588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.028396; batch adversarial loss: 0.420086\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026523; batch adversarial loss: 0.390075\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013220; batch adversarial loss: 0.492298\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020031; batch adversarial loss: 0.483198\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011914; batch adversarial loss: 0.477574\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019388; batch adversarial loss: 0.443484\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011764; batch adversarial loss: 0.417354\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036582; batch adversarial loss: 0.431483\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019799; batch adversarial loss: 0.527705\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025885; batch adversarial loss: 0.455712\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030164; batch adversarial loss: 0.511394\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018779; batch adversarial loss: 0.480379\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021775; batch adversarial loss: 0.457771\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031453; batch adversarial loss: 0.435126\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011342; batch adversarial loss: 0.448423\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034054; batch adversarial loss: 0.398433\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017583; batch adversarial loss: 0.413582\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031077; batch adversarial loss: 0.447937\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013926; batch adversarial loss: 0.416947\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013166; batch adversarial loss: 0.575190\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005239; batch adversarial loss: 0.523826\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022951; batch adversarial loss: 0.462166\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029659; batch adversarial loss: 0.432933\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011951; batch adversarial loss: 0.370553\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021492; batch adversarial loss: 0.434177\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018498; batch adversarial loss: 0.488079\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015203; batch adversarial loss: 0.513031\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011869; batch adversarial loss: 0.473851\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011412; batch adversarial loss: 0.498136\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025902; batch adversarial loss: 0.457328\n",
      "epoch 178; iter: 0; batch classifier loss: 0.005166; batch adversarial loss: 0.483136\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014925; batch adversarial loss: 0.428404\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020890; batch adversarial loss: 0.452690\n",
      "epoch 181; iter: 0; batch classifier loss: 0.005982; batch adversarial loss: 0.473199\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014744; batch adversarial loss: 0.588074\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017039; batch adversarial loss: 0.418987\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031747; batch adversarial loss: 0.531274\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020534; batch adversarial loss: 0.547041\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020694; batch adversarial loss: 0.471448\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005613; batch adversarial loss: 0.437222\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007376; batch adversarial loss: 0.488423\n",
      "epoch 189; iter: 0; batch classifier loss: 0.003772; batch adversarial loss: 0.550051\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012140; batch adversarial loss: 0.506401\n",
      "epoch 191; iter: 0; batch classifier loss: 0.003086; batch adversarial loss: 0.498348\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013755; batch adversarial loss: 0.430803\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014638; batch adversarial loss: 0.448842\n",
      "epoch 194; iter: 0; batch classifier loss: 0.002359; batch adversarial loss: 0.446466\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012950; batch adversarial loss: 0.485060\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028718; batch adversarial loss: 0.521673\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022684; batch adversarial loss: 0.465000\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016027; batch adversarial loss: 0.375446\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005404; batch adversarial loss: 0.483522\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663567; batch adversarial loss: 0.805526\n",
      "epoch 1; iter: 0; batch classifier loss: 0.499750; batch adversarial loss: 0.885929\n",
      "epoch 2; iter: 0; batch classifier loss: 0.319476; batch adversarial loss: 0.798716\n",
      "epoch 3; iter: 0; batch classifier loss: 0.316266; batch adversarial loss: 0.776467\n",
      "epoch 4; iter: 0; batch classifier loss: 0.361433; batch adversarial loss: 0.741264\n",
      "epoch 5; iter: 0; batch classifier loss: 0.299613; batch adversarial loss: 0.697084\n",
      "epoch 6; iter: 0; batch classifier loss: 0.283629; batch adversarial loss: 0.685277\n",
      "epoch 7; iter: 0; batch classifier loss: 0.319762; batch adversarial loss: 0.647886\n",
      "epoch 8; iter: 0; batch classifier loss: 0.293474; batch adversarial loss: 0.628524\n",
      "epoch 9; iter: 0; batch classifier loss: 0.275149; batch adversarial loss: 0.605813\n",
      "epoch 10; iter: 0; batch classifier loss: 0.322345; batch adversarial loss: 0.583088\n",
      "epoch 11; iter: 0; batch classifier loss: 0.278662; batch adversarial loss: 0.543944\n",
      "epoch 12; iter: 0; batch classifier loss: 0.255975; batch adversarial loss: 0.527180\n",
      "epoch 13; iter: 0; batch classifier loss: 0.246136; batch adversarial loss: 0.514083\n",
      "epoch 14; iter: 0; batch classifier loss: 0.258680; batch adversarial loss: 0.452117\n",
      "epoch 15; iter: 0; batch classifier loss: 0.181882; batch adversarial loss: 0.486758\n",
      "epoch 16; iter: 0; batch classifier loss: 0.221395; batch adversarial loss: 0.430323\n",
      "epoch 17; iter: 0; batch classifier loss: 0.186269; batch adversarial loss: 0.447014\n",
      "epoch 18; iter: 0; batch classifier loss: 0.194143; batch adversarial loss: 0.428848\n",
      "epoch 19; iter: 0; batch classifier loss: 0.184887; batch adversarial loss: 0.518880\n",
      "epoch 20; iter: 0; batch classifier loss: 0.162656; batch adversarial loss: 0.502241\n",
      "epoch 21; iter: 0; batch classifier loss: 0.170870; batch adversarial loss: 0.477176\n",
      "epoch 22; iter: 0; batch classifier loss: 0.159771; batch adversarial loss: 0.421054\n",
      "epoch 23; iter: 0; batch classifier loss: 0.152557; batch adversarial loss: 0.395241\n",
      "epoch 24; iter: 0; batch classifier loss: 0.200362; batch adversarial loss: 0.353581\n",
      "epoch 25; iter: 0; batch classifier loss: 0.138431; batch adversarial loss: 0.474481\n",
      "epoch 26; iter: 0; batch classifier loss: 0.120721; batch adversarial loss: 0.462231\n",
      "epoch 27; iter: 0; batch classifier loss: 0.176155; batch adversarial loss: 0.449196\n",
      "epoch 28; iter: 0; batch classifier loss: 0.104772; batch adversarial loss: 0.453796\n",
      "epoch 29; iter: 0; batch classifier loss: 0.126110; batch adversarial loss: 0.410833\n",
      "epoch 30; iter: 0; batch classifier loss: 0.122045; batch adversarial loss: 0.459333\n",
      "epoch 31; iter: 0; batch classifier loss: 0.103107; batch adversarial loss: 0.482588\n",
      "epoch 32; iter: 0; batch classifier loss: 0.127355; batch adversarial loss: 0.425136\n",
      "epoch 33; iter: 0; batch classifier loss: 0.092942; batch adversarial loss: 0.412242\n",
      "epoch 34; iter: 0; batch classifier loss: 0.149247; batch adversarial loss: 0.417410\n",
      "epoch 35; iter: 0; batch classifier loss: 0.164382; batch adversarial loss: 0.389199\n",
      "epoch 36; iter: 0; batch classifier loss: 0.161368; batch adversarial loss: 0.410752\n",
      "epoch 37; iter: 0; batch classifier loss: 0.092487; batch adversarial loss: 0.436144\n",
      "epoch 38; iter: 0; batch classifier loss: 0.116087; batch adversarial loss: 0.474844\n",
      "epoch 39; iter: 0; batch classifier loss: 0.093309; batch adversarial loss: 0.391143\n",
      "epoch 40; iter: 0; batch classifier loss: 0.156229; batch adversarial loss: 0.436163\n",
      "epoch 41; iter: 0; batch classifier loss: 0.116332; batch adversarial loss: 0.309981\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131304; batch adversarial loss: 0.387086\n",
      "epoch 43; iter: 0; batch classifier loss: 0.108941; batch adversarial loss: 0.479292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.076474; batch adversarial loss: 0.459786\n",
      "epoch 45; iter: 0; batch classifier loss: 0.095731; batch adversarial loss: 0.421702\n",
      "epoch 46; iter: 0; batch classifier loss: 0.089371; batch adversarial loss: 0.371113\n",
      "epoch 47; iter: 0; batch classifier loss: 0.144823; batch adversarial loss: 0.420853\n",
      "epoch 48; iter: 0; batch classifier loss: 0.113396; batch adversarial loss: 0.381012\n",
      "epoch 49; iter: 0; batch classifier loss: 0.086959; batch adversarial loss: 0.388930\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096367; batch adversarial loss: 0.425781\n",
      "epoch 51; iter: 0; batch classifier loss: 0.108755; batch adversarial loss: 0.389526\n",
      "epoch 52; iter: 0; batch classifier loss: 0.083610; batch adversarial loss: 0.481745\n",
      "epoch 53; iter: 0; batch classifier loss: 0.104344; batch adversarial loss: 0.466541\n",
      "epoch 54; iter: 0; batch classifier loss: 0.143221; batch adversarial loss: 0.379883\n",
      "epoch 55; iter: 0; batch classifier loss: 0.109383; batch adversarial loss: 0.531757\n",
      "epoch 56; iter: 0; batch classifier loss: 0.077728; batch adversarial loss: 0.422818\n",
      "epoch 57; iter: 0; batch classifier loss: 0.090813; batch adversarial loss: 0.424494\n",
      "epoch 58; iter: 0; batch classifier loss: 0.109778; batch adversarial loss: 0.332498\n",
      "epoch 59; iter: 0; batch classifier loss: 0.069156; batch adversarial loss: 0.379468\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079594; batch adversarial loss: 0.452690\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088041; batch adversarial loss: 0.423390\n",
      "epoch 62; iter: 0; batch classifier loss: 0.098996; batch adversarial loss: 0.539519\n",
      "epoch 63; iter: 0; batch classifier loss: 0.123734; batch adversarial loss: 0.419633\n",
      "epoch 64; iter: 0; batch classifier loss: 0.088361; batch adversarial loss: 0.405368\n",
      "epoch 65; iter: 0; batch classifier loss: 0.069754; batch adversarial loss: 0.415163\n",
      "epoch 66; iter: 0; batch classifier loss: 0.079628; batch adversarial loss: 0.399457\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080330; batch adversarial loss: 0.454764\n",
      "epoch 68; iter: 0; batch classifier loss: 0.048202; batch adversarial loss: 0.432082\n",
      "epoch 69; iter: 0; batch classifier loss: 0.044834; batch adversarial loss: 0.379743\n",
      "epoch 70; iter: 0; batch classifier loss: 0.059224; batch adversarial loss: 0.497003\n",
      "epoch 71; iter: 0; batch classifier loss: 0.077392; batch adversarial loss: 0.423713\n",
      "epoch 72; iter: 0; batch classifier loss: 0.058979; batch adversarial loss: 0.466958\n",
      "epoch 73; iter: 0; batch classifier loss: 0.060488; batch adversarial loss: 0.424010\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053931; batch adversarial loss: 0.460624\n",
      "epoch 75; iter: 0; batch classifier loss: 0.062842; batch adversarial loss: 0.437950\n",
      "epoch 76; iter: 0; batch classifier loss: 0.097755; batch adversarial loss: 0.425799\n",
      "epoch 77; iter: 0; batch classifier loss: 0.057216; batch adversarial loss: 0.461977\n",
      "epoch 78; iter: 0; batch classifier loss: 0.055935; batch adversarial loss: 0.439812\n",
      "epoch 79; iter: 0; batch classifier loss: 0.054556; batch adversarial loss: 0.497668\n",
      "epoch 80; iter: 0; batch classifier loss: 0.063517; batch adversarial loss: 0.398848\n",
      "epoch 81; iter: 0; batch classifier loss: 0.045001; batch adversarial loss: 0.387537\n",
      "epoch 82; iter: 0; batch classifier loss: 0.041071; batch adversarial loss: 0.495249\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070174; batch adversarial loss: 0.494993\n",
      "epoch 84; iter: 0; batch classifier loss: 0.037430; batch adversarial loss: 0.469136\n",
      "epoch 85; iter: 0; batch classifier loss: 0.031882; batch adversarial loss: 0.476674\n",
      "epoch 86; iter: 0; batch classifier loss: 0.043963; batch adversarial loss: 0.451732\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057962; batch adversarial loss: 0.415923\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040812; batch adversarial loss: 0.412525\n",
      "epoch 89; iter: 0; batch classifier loss: 0.031305; batch adversarial loss: 0.499806\n",
      "epoch 90; iter: 0; batch classifier loss: 0.081853; batch adversarial loss: 0.394772\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045647; batch adversarial loss: 0.423730\n",
      "epoch 92; iter: 0; batch classifier loss: 0.027218; batch adversarial loss: 0.421834\n",
      "epoch 93; iter: 0; batch classifier loss: 0.027246; batch adversarial loss: 0.462122\n",
      "epoch 94; iter: 0; batch classifier loss: 0.024366; batch adversarial loss: 0.456453\n",
      "epoch 95; iter: 0; batch classifier loss: 0.016851; batch adversarial loss: 0.503902\n",
      "epoch 96; iter: 0; batch classifier loss: 0.073015; batch adversarial loss: 0.430320\n",
      "epoch 97; iter: 0; batch classifier loss: 0.070197; batch adversarial loss: 0.502221\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051008; batch adversarial loss: 0.410078\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039785; batch adversarial loss: 0.410707\n",
      "epoch 100; iter: 0; batch classifier loss: 0.024011; batch adversarial loss: 0.544924\n",
      "epoch 101; iter: 0; batch classifier loss: 0.024824; batch adversarial loss: 0.423447\n",
      "epoch 102; iter: 0; batch classifier loss: 0.021044; batch adversarial loss: 0.488689\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043007; batch adversarial loss: 0.563333\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039436; batch adversarial loss: 0.475106\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035092; batch adversarial loss: 0.403391\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035157; batch adversarial loss: 0.435752\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053072; batch adversarial loss: 0.424335\n",
      "epoch 108; iter: 0; batch classifier loss: 0.022804; batch adversarial loss: 0.458432\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027091; batch adversarial loss: 0.500349\n",
      "epoch 110; iter: 0; batch classifier loss: 0.022527; batch adversarial loss: 0.475368\n",
      "epoch 111; iter: 0; batch classifier loss: 0.082318; batch adversarial loss: 0.590796\n",
      "epoch 112; iter: 0; batch classifier loss: 0.073391; batch adversarial loss: 0.418496\n",
      "epoch 113; iter: 0; batch classifier loss: 0.123338; batch adversarial loss: 0.556839\n",
      "epoch 114; iter: 0; batch classifier loss: 0.073001; batch adversarial loss: 0.656662\n",
      "epoch 115; iter: 0; batch classifier loss: 0.105301; batch adversarial loss: 0.533122\n",
      "epoch 116; iter: 0; batch classifier loss: 0.066651; batch adversarial loss: 0.532457\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055032; batch adversarial loss: 0.509728\n",
      "epoch 118; iter: 0; batch classifier loss: 0.180766; batch adversarial loss: 0.607146\n",
      "epoch 119; iter: 0; batch classifier loss: 0.082508; batch adversarial loss: 0.464593\n",
      "epoch 120; iter: 0; batch classifier loss: 0.123132; batch adversarial loss: 0.492137\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060835; batch adversarial loss: 0.466083\n",
      "epoch 122; iter: 0; batch classifier loss: 0.142841; batch adversarial loss: 0.606450\n",
      "epoch 123; iter: 0; batch classifier loss: 0.111615; batch adversarial loss: 0.534584\n",
      "epoch 124; iter: 0; batch classifier loss: 0.142265; batch adversarial loss: 0.531476\n",
      "epoch 125; iter: 0; batch classifier loss: 0.109956; batch adversarial loss: 0.604803\n",
      "epoch 126; iter: 0; batch classifier loss: 0.150940; batch adversarial loss: 0.624098\n",
      "epoch 127; iter: 0; batch classifier loss: 0.140864; batch adversarial loss: 0.517198\n",
      "epoch 128; iter: 0; batch classifier loss: 0.113140; batch adversarial loss: 0.543132\n",
      "epoch 129; iter: 0; batch classifier loss: 0.226723; batch adversarial loss: 0.632946\n",
      "epoch 130; iter: 0; batch classifier loss: 0.187606; batch adversarial loss: 0.631689\n",
      "epoch 131; iter: 0; batch classifier loss: 0.083347; batch adversarial loss: 0.495879\n",
      "epoch 132; iter: 0; batch classifier loss: 0.112630; batch adversarial loss: 0.486697\n",
      "epoch 133; iter: 0; batch classifier loss: 0.235515; batch adversarial loss: 0.672423\n",
      "epoch 134; iter: 0; batch classifier loss: 0.151000; batch adversarial loss: 0.486182\n",
      "epoch 135; iter: 0; batch classifier loss: 0.182067; batch adversarial loss: 0.503745\n",
      "epoch 136; iter: 0; batch classifier loss: 0.130274; batch adversarial loss: 0.550789\n",
      "epoch 137; iter: 0; batch classifier loss: 0.174577; batch adversarial loss: 0.521822\n",
      "epoch 138; iter: 0; batch classifier loss: 0.187145; batch adversarial loss: 0.616099\n",
      "epoch 139; iter: 0; batch classifier loss: 0.099560; batch adversarial loss: 0.428988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.095138; batch adversarial loss: 0.519554\n",
      "epoch 141; iter: 0; batch classifier loss: 0.171240; batch adversarial loss: 0.628467\n",
      "epoch 142; iter: 0; batch classifier loss: 0.157226; batch adversarial loss: 0.484509\n",
      "epoch 143; iter: 0; batch classifier loss: 0.155065; batch adversarial loss: 0.541312\n",
      "epoch 144; iter: 0; batch classifier loss: 0.078550; batch adversarial loss: 0.397032\n",
      "epoch 145; iter: 0; batch classifier loss: 0.116292; batch adversarial loss: 0.558005\n",
      "epoch 146; iter: 0; batch classifier loss: 0.097169; batch adversarial loss: 0.464640\n",
      "epoch 147; iter: 0; batch classifier loss: 0.092027; batch adversarial loss: 0.391200\n",
      "epoch 148; iter: 0; batch classifier loss: 0.133674; batch adversarial loss: 0.524472\n",
      "epoch 149; iter: 0; batch classifier loss: 0.175752; batch adversarial loss: 0.472825\n",
      "epoch 150; iter: 0; batch classifier loss: 0.121661; batch adversarial loss: 0.516769\n",
      "epoch 151; iter: 0; batch classifier loss: 0.140928; batch adversarial loss: 0.500533\n",
      "epoch 152; iter: 0; batch classifier loss: 0.151533; batch adversarial loss: 0.472739\n",
      "epoch 153; iter: 0; batch classifier loss: 0.096376; batch adversarial loss: 0.436132\n",
      "epoch 154; iter: 0; batch classifier loss: 0.057662; batch adversarial loss: 0.371278\n",
      "epoch 155; iter: 0; batch classifier loss: 0.059935; batch adversarial loss: 0.443975\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030066; batch adversarial loss: 0.442811\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026597; batch adversarial loss: 0.457947\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030217; batch adversarial loss: 0.386773\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027473; batch adversarial loss: 0.454278\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029797; batch adversarial loss: 0.369708\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033344; batch adversarial loss: 0.469673\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032643; batch adversarial loss: 0.476735\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042961; batch adversarial loss: 0.514663\n",
      "epoch 164; iter: 0; batch classifier loss: 0.058162; batch adversarial loss: 0.352719\n",
      "epoch 165; iter: 0; batch classifier loss: 0.055833; batch adversarial loss: 0.497278\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040415; batch adversarial loss: 0.389427\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030372; batch adversarial loss: 0.492258\n",
      "epoch 168; iter: 0; batch classifier loss: 0.047535; batch adversarial loss: 0.368400\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029286; batch adversarial loss: 0.430782\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037498; batch adversarial loss: 0.503539\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031593; batch adversarial loss: 0.447198\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032300; batch adversarial loss: 0.465063\n",
      "epoch 173; iter: 0; batch classifier loss: 0.056770; batch adversarial loss: 0.441298\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037175; batch adversarial loss: 0.480628\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024792; batch adversarial loss: 0.461608\n",
      "epoch 176; iter: 0; batch classifier loss: 0.074029; batch adversarial loss: 0.409341\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049621; batch adversarial loss: 0.443046\n",
      "epoch 178; iter: 0; batch classifier loss: 0.049151; batch adversarial loss: 0.481654\n",
      "epoch 179; iter: 0; batch classifier loss: 0.047463; batch adversarial loss: 0.438402\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041439; batch adversarial loss: 0.532218\n",
      "epoch 181; iter: 0; batch classifier loss: 0.074594; batch adversarial loss: 0.581646\n",
      "epoch 182; iter: 0; batch classifier loss: 0.071311; batch adversarial loss: 0.553801\n",
      "epoch 183; iter: 0; batch classifier loss: 0.088983; batch adversarial loss: 0.479902\n",
      "epoch 184; iter: 0; batch classifier loss: 0.058244; batch adversarial loss: 0.407949\n",
      "epoch 185; iter: 0; batch classifier loss: 0.075298; batch adversarial loss: 0.417318\n",
      "epoch 186; iter: 0; batch classifier loss: 0.075184; batch adversarial loss: 0.461185\n",
      "epoch 187; iter: 0; batch classifier loss: 0.056138; batch adversarial loss: 0.449882\n",
      "epoch 188; iter: 0; batch classifier loss: 0.046427; batch adversarial loss: 0.434464\n",
      "epoch 189; iter: 0; batch classifier loss: 0.074854; batch adversarial loss: 0.341025\n",
      "epoch 190; iter: 0; batch classifier loss: 0.046984; batch adversarial loss: 0.500408\n",
      "epoch 191; iter: 0; batch classifier loss: 0.061475; batch adversarial loss: 0.410536\n",
      "epoch 192; iter: 0; batch classifier loss: 0.052512; batch adversarial loss: 0.478981\n",
      "epoch 193; iter: 0; batch classifier loss: 0.043331; batch adversarial loss: 0.528295\n",
      "epoch 194; iter: 0; batch classifier loss: 0.076321; batch adversarial loss: 0.437809\n",
      "epoch 195; iter: 0; batch classifier loss: 0.037950; batch adversarial loss: 0.456020\n",
      "epoch 196; iter: 0; batch classifier loss: 0.054012; batch adversarial loss: 0.519107\n",
      "epoch 197; iter: 0; batch classifier loss: 0.078613; batch adversarial loss: 0.418548\n",
      "epoch 198; iter: 0; batch classifier loss: 0.073965; batch adversarial loss: 0.477280\n",
      "epoch 199; iter: 0; batch classifier loss: 0.071732; batch adversarial loss: 0.407294\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709281; batch adversarial loss: 0.768716\n",
      "epoch 1; iter: 0; batch classifier loss: 0.494956; batch adversarial loss: 0.704030\n",
      "epoch 2; iter: 0; batch classifier loss: 0.530436; batch adversarial loss: 0.658713\n",
      "epoch 3; iter: 0; batch classifier loss: 0.355251; batch adversarial loss: 0.594075\n",
      "epoch 4; iter: 0; batch classifier loss: 0.374147; batch adversarial loss: 0.572937\n",
      "epoch 5; iter: 0; batch classifier loss: 0.370577; batch adversarial loss: 0.580306\n",
      "epoch 6; iter: 0; batch classifier loss: 0.385484; batch adversarial loss: 0.583204\n",
      "epoch 7; iter: 0; batch classifier loss: 0.341602; batch adversarial loss: 0.568708\n",
      "epoch 8; iter: 0; batch classifier loss: 0.361807; batch adversarial loss: 0.550301\n",
      "epoch 9; iter: 0; batch classifier loss: 0.266428; batch adversarial loss: 0.515103\n",
      "epoch 10; iter: 0; batch classifier loss: 0.258148; batch adversarial loss: 0.515739\n",
      "epoch 11; iter: 0; batch classifier loss: 0.236034; batch adversarial loss: 0.487540\n",
      "epoch 12; iter: 0; batch classifier loss: 0.311576; batch adversarial loss: 0.533416\n",
      "epoch 13; iter: 0; batch classifier loss: 0.297855; batch adversarial loss: 0.525992\n",
      "epoch 14; iter: 0; batch classifier loss: 0.298965; batch adversarial loss: 0.504656\n",
      "epoch 15; iter: 0; batch classifier loss: 0.259380; batch adversarial loss: 0.475735\n",
      "epoch 16; iter: 0; batch classifier loss: 0.247388; batch adversarial loss: 0.521029\n",
      "epoch 17; iter: 0; batch classifier loss: 0.267085; batch adversarial loss: 0.557316\n",
      "epoch 18; iter: 0; batch classifier loss: 0.276758; batch adversarial loss: 0.518327\n",
      "epoch 19; iter: 0; batch classifier loss: 0.282818; batch adversarial loss: 0.493010\n",
      "epoch 20; iter: 0; batch classifier loss: 0.350638; batch adversarial loss: 0.559347\n",
      "epoch 21; iter: 0; batch classifier loss: 0.264469; batch adversarial loss: 0.569796\n",
      "epoch 22; iter: 0; batch classifier loss: 0.313946; batch adversarial loss: 0.497415\n",
      "epoch 23; iter: 0; batch classifier loss: 0.280696; batch adversarial loss: 0.402427\n",
      "epoch 24; iter: 0; batch classifier loss: 0.264578; batch adversarial loss: 0.514610\n",
      "epoch 25; iter: 0; batch classifier loss: 0.243637; batch adversarial loss: 0.446153\n",
      "epoch 26; iter: 0; batch classifier loss: 0.211860; batch adversarial loss: 0.422082\n",
      "epoch 27; iter: 0; batch classifier loss: 0.228338; batch adversarial loss: 0.486650\n",
      "epoch 28; iter: 0; batch classifier loss: 0.286777; batch adversarial loss: 0.432271\n",
      "epoch 29; iter: 0; batch classifier loss: 0.222745; batch adversarial loss: 0.422947\n",
      "epoch 30; iter: 0; batch classifier loss: 0.260693; batch adversarial loss: 0.497320\n",
      "epoch 31; iter: 0; batch classifier loss: 0.336834; batch adversarial loss: 0.426929\n",
      "epoch 32; iter: 0; batch classifier loss: 0.269138; batch adversarial loss: 0.434491\n",
      "epoch 33; iter: 0; batch classifier loss: 0.202122; batch adversarial loss: 0.515095\n",
      "epoch 34; iter: 0; batch classifier loss: 0.300029; batch adversarial loss: 0.363250\n",
      "epoch 35; iter: 0; batch classifier loss: 0.218012; batch adversarial loss: 0.448241\n",
      "epoch 36; iter: 0; batch classifier loss: 0.308742; batch adversarial loss: 0.420169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37; iter: 0; batch classifier loss: 0.249215; batch adversarial loss: 0.398898\n",
      "epoch 38; iter: 0; batch classifier loss: 0.215202; batch adversarial loss: 0.546654\n",
      "epoch 39; iter: 0; batch classifier loss: 0.252776; batch adversarial loss: 0.510791\n",
      "epoch 40; iter: 0; batch classifier loss: 0.263559; batch adversarial loss: 0.519298\n",
      "epoch 41; iter: 0; batch classifier loss: 0.210240; batch adversarial loss: 0.432571\n",
      "epoch 42; iter: 0; batch classifier loss: 0.252937; batch adversarial loss: 0.477470\n",
      "epoch 43; iter: 0; batch classifier loss: 0.205250; batch adversarial loss: 0.388715\n",
      "epoch 44; iter: 0; batch classifier loss: 0.203206; batch adversarial loss: 0.416465\n",
      "epoch 45; iter: 0; batch classifier loss: 0.263444; batch adversarial loss: 0.439153\n",
      "epoch 46; iter: 0; batch classifier loss: 0.278295; batch adversarial loss: 0.506890\n",
      "epoch 47; iter: 0; batch classifier loss: 0.223259; batch adversarial loss: 0.555012\n",
      "epoch 48; iter: 0; batch classifier loss: 0.262116; batch adversarial loss: 0.470449\n",
      "epoch 49; iter: 0; batch classifier loss: 0.208012; batch adversarial loss: 0.481323\n",
      "epoch 50; iter: 0; batch classifier loss: 0.266315; batch adversarial loss: 0.498389\n",
      "epoch 51; iter: 0; batch classifier loss: 0.221418; batch adversarial loss: 0.435519\n",
      "epoch 52; iter: 0; batch classifier loss: 0.242013; batch adversarial loss: 0.390578\n",
      "epoch 53; iter: 0; batch classifier loss: 0.173920; batch adversarial loss: 0.482517\n",
      "epoch 54; iter: 0; batch classifier loss: 0.293388; batch adversarial loss: 0.444498\n",
      "epoch 55; iter: 0; batch classifier loss: 0.302651; batch adversarial loss: 0.505777\n",
      "epoch 56; iter: 0; batch classifier loss: 0.261832; batch adversarial loss: 0.494674\n",
      "epoch 57; iter: 0; batch classifier loss: 0.202366; batch adversarial loss: 0.557324\n",
      "epoch 58; iter: 0; batch classifier loss: 0.186102; batch adversarial loss: 0.603676\n",
      "epoch 59; iter: 0; batch classifier loss: 0.251941; batch adversarial loss: 0.496768\n",
      "epoch 60; iter: 0; batch classifier loss: 0.255386; batch adversarial loss: 0.447465\n",
      "epoch 61; iter: 0; batch classifier loss: 0.252949; batch adversarial loss: 0.458758\n",
      "epoch 62; iter: 0; batch classifier loss: 0.173186; batch adversarial loss: 0.555532\n",
      "epoch 63; iter: 0; batch classifier loss: 0.174930; batch adversarial loss: 0.447441\n",
      "epoch 64; iter: 0; batch classifier loss: 0.210648; batch adversarial loss: 0.458760\n",
      "epoch 65; iter: 0; batch classifier loss: 0.229777; batch adversarial loss: 0.422551\n",
      "epoch 66; iter: 0; batch classifier loss: 0.300759; batch adversarial loss: 0.434845\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110510; batch adversarial loss: 0.471026\n",
      "epoch 68; iter: 0; batch classifier loss: 0.100498; batch adversarial loss: 0.433450\n",
      "epoch 69; iter: 0; batch classifier loss: 0.142155; batch adversarial loss: 0.506393\n",
      "epoch 70; iter: 0; batch classifier loss: 0.248919; batch adversarial loss: 0.385643\n",
      "epoch 71; iter: 0; batch classifier loss: 0.208618; batch adversarial loss: 0.485436\n",
      "epoch 72; iter: 0; batch classifier loss: 0.303739; batch adversarial loss: 0.434501\n",
      "epoch 73; iter: 0; batch classifier loss: 0.147646; batch adversarial loss: 0.471548\n",
      "epoch 74; iter: 0; batch classifier loss: 0.151157; batch adversarial loss: 0.445925\n",
      "epoch 75; iter: 0; batch classifier loss: 0.240382; batch adversarial loss: 0.422350\n",
      "epoch 76; iter: 0; batch classifier loss: 0.233443; batch adversarial loss: 0.508578\n",
      "epoch 77; iter: 0; batch classifier loss: 0.305094; batch adversarial loss: 0.422651\n",
      "epoch 78; iter: 0; batch classifier loss: 0.200130; batch adversarial loss: 0.508294\n",
      "epoch 79; iter: 0; batch classifier loss: 0.263664; batch adversarial loss: 0.434298\n",
      "epoch 80; iter: 0; batch classifier loss: 0.257817; batch adversarial loss: 0.434767\n",
      "epoch 81; iter: 0; batch classifier loss: 0.114518; batch adversarial loss: 0.398011\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065986; batch adversarial loss: 0.472779\n",
      "epoch 83; iter: 0; batch classifier loss: 0.137709; batch adversarial loss: 0.492857\n",
      "epoch 84; iter: 0; batch classifier loss: 0.081596; batch adversarial loss: 0.537539\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088977; batch adversarial loss: 0.455956\n",
      "epoch 86; iter: 0; batch classifier loss: 0.145409; batch adversarial loss: 0.460292\n",
      "epoch 87; iter: 0; batch classifier loss: 0.153192; batch adversarial loss: 0.458250\n",
      "epoch 88; iter: 0; batch classifier loss: 0.186253; batch adversarial loss: 0.440268\n",
      "epoch 89; iter: 0; batch classifier loss: 0.106267; batch adversarial loss: 0.546529\n",
      "epoch 90; iter: 0; batch classifier loss: 0.119932; batch adversarial loss: 0.416783\n",
      "epoch 91; iter: 0; batch classifier loss: 0.123839; batch adversarial loss: 0.450319\n",
      "epoch 92; iter: 0; batch classifier loss: 0.097929; batch adversarial loss: 0.471299\n",
      "epoch 93; iter: 0; batch classifier loss: 0.101664; batch adversarial loss: 0.375910\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056268; batch adversarial loss: 0.385566\n",
      "epoch 95; iter: 0; batch classifier loss: 0.078419; batch adversarial loss: 0.428947\n",
      "epoch 96; iter: 0; batch classifier loss: 0.086381; batch adversarial loss: 0.587348\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072246; batch adversarial loss: 0.381622\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079256; batch adversarial loss: 0.406405\n",
      "epoch 99; iter: 0; batch classifier loss: 0.068091; batch adversarial loss: 0.512069\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057041; batch adversarial loss: 0.532687\n",
      "epoch 101; iter: 0; batch classifier loss: 0.080130; batch adversarial loss: 0.532115\n",
      "epoch 102; iter: 0; batch classifier loss: 0.083971; batch adversarial loss: 0.432758\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039351; batch adversarial loss: 0.375693\n",
      "epoch 104; iter: 0; batch classifier loss: 0.048975; batch adversarial loss: 0.556563\n",
      "epoch 105; iter: 0; batch classifier loss: 0.074216; batch adversarial loss: 0.444324\n",
      "epoch 106; iter: 0; batch classifier loss: 0.076805; batch adversarial loss: 0.443648\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055366; batch adversarial loss: 0.497571\n",
      "epoch 108; iter: 0; batch classifier loss: 0.083744; batch adversarial loss: 0.412292\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045750; batch adversarial loss: 0.460488\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038107; batch adversarial loss: 0.456687\n",
      "epoch 111; iter: 0; batch classifier loss: 0.052474; batch adversarial loss: 0.476808\n",
      "epoch 112; iter: 0; batch classifier loss: 0.071122; batch adversarial loss: 0.477265\n",
      "epoch 113; iter: 0; batch classifier loss: 0.036114; batch adversarial loss: 0.411530\n",
      "epoch 114; iter: 0; batch classifier loss: 0.069476; batch adversarial loss: 0.437576\n",
      "epoch 115; iter: 0; batch classifier loss: 0.086222; batch adversarial loss: 0.429145\n",
      "epoch 116; iter: 0; batch classifier loss: 0.047821; batch adversarial loss: 0.364691\n",
      "epoch 117; iter: 0; batch classifier loss: 0.059883; batch adversarial loss: 0.505033\n",
      "epoch 118; iter: 0; batch classifier loss: 0.018545; batch adversarial loss: 0.490026\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040203; batch adversarial loss: 0.413992\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037597; batch adversarial loss: 0.395487\n",
      "epoch 121; iter: 0; batch classifier loss: 0.055957; batch adversarial loss: 0.442425\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039083; batch adversarial loss: 0.468498\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033995; batch adversarial loss: 0.451046\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043727; batch adversarial loss: 0.501047\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027334; batch adversarial loss: 0.326988\n",
      "epoch 126; iter: 0; batch classifier loss: 0.014370; batch adversarial loss: 0.440295\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053765; batch adversarial loss: 0.464074\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022661; batch adversarial loss: 0.462269\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035144; batch adversarial loss: 0.381776\n",
      "epoch 130; iter: 0; batch classifier loss: 0.009226; batch adversarial loss: 0.454100\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047709; batch adversarial loss: 0.474767\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051972; batch adversarial loss: 0.423089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 133; iter: 0; batch classifier loss: 0.017830; batch adversarial loss: 0.448245\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034349; batch adversarial loss: 0.419504\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020556; batch adversarial loss: 0.473154\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024188; batch adversarial loss: 0.477043\n",
      "epoch 137; iter: 0; batch classifier loss: 0.060591; batch adversarial loss: 0.427672\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018615; batch adversarial loss: 0.493720\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040508; batch adversarial loss: 0.466257\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018228; batch adversarial loss: 0.461758\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027474; batch adversarial loss: 0.421825\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041236; batch adversarial loss: 0.445047\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022687; batch adversarial loss: 0.506237\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037632; batch adversarial loss: 0.526528\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026123; batch adversarial loss: 0.346587\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051812; batch adversarial loss: 0.411761\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035036; batch adversarial loss: 0.493956\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017860; batch adversarial loss: 0.554838\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034560; batch adversarial loss: 0.414712\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011476; batch adversarial loss: 0.471226\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022224; batch adversarial loss: 0.474542\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021040; batch adversarial loss: 0.551833\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027289; batch adversarial loss: 0.366256\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018715; batch adversarial loss: 0.455752\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018145; batch adversarial loss: 0.552155\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019141; batch adversarial loss: 0.460117\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034742; batch adversarial loss: 0.349588\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037064; batch adversarial loss: 0.473736\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021305; batch adversarial loss: 0.405883\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016279; batch adversarial loss: 0.444492\n",
      "epoch 161; iter: 0; batch classifier loss: 0.047126; batch adversarial loss: 0.371915\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043808; batch adversarial loss: 0.446864\n",
      "epoch 163; iter: 0; batch classifier loss: 0.031200; batch adversarial loss: 0.497475\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017382; batch adversarial loss: 0.370541\n",
      "epoch 165; iter: 0; batch classifier loss: 0.004580; batch adversarial loss: 0.534237\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035717; batch adversarial loss: 0.427841\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026842; batch adversarial loss: 0.420655\n",
      "epoch 168; iter: 0; batch classifier loss: 0.006040; batch adversarial loss: 0.510382\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014543; batch adversarial loss: 0.524597\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035575; batch adversarial loss: 0.441834\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013616; batch adversarial loss: 0.443486\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007929; batch adversarial loss: 0.457291\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017792; batch adversarial loss: 0.449566\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025208; batch adversarial loss: 0.429921\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012809; batch adversarial loss: 0.492576\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010193; batch adversarial loss: 0.475572\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025887; batch adversarial loss: 0.415359\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037975; batch adversarial loss: 0.547308\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032243; batch adversarial loss: 0.469442\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034926; batch adversarial loss: 0.361463\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034391; batch adversarial loss: 0.359554\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013156; batch adversarial loss: 0.452850\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020945; batch adversarial loss: 0.452341\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007876; batch adversarial loss: 0.547079\n",
      "epoch 185; iter: 0; batch classifier loss: 0.030677; batch adversarial loss: 0.499615\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012382; batch adversarial loss: 0.442393\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006899; batch adversarial loss: 0.408043\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017298; batch adversarial loss: 0.458627\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010010; batch adversarial loss: 0.387837\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007997; batch adversarial loss: 0.462676\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033568; batch adversarial loss: 0.602924\n",
      "epoch 192; iter: 0; batch classifier loss: 0.051415; batch adversarial loss: 0.373883\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027283; batch adversarial loss: 0.467500\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028867; batch adversarial loss: 0.545117\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014218; batch adversarial loss: 0.545005\n",
      "epoch 196; iter: 0; batch classifier loss: 0.038715; batch adversarial loss: 0.429339\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033972; batch adversarial loss: 0.607219\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038523; batch adversarial loss: 0.412452\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007791; batch adversarial loss: 0.455007\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686524; batch adversarial loss: 0.576242\n",
      "epoch 1; iter: 0; batch classifier loss: 0.436662; batch adversarial loss: 0.624422\n",
      "epoch 2; iter: 0; batch classifier loss: 0.408255; batch adversarial loss: 0.672451\n",
      "epoch 3; iter: 0; batch classifier loss: 0.344582; batch adversarial loss: 0.586950\n",
      "epoch 4; iter: 0; batch classifier loss: 0.407080; batch adversarial loss: 0.583208\n",
      "epoch 5; iter: 0; batch classifier loss: 0.469687; batch adversarial loss: 0.613424\n",
      "epoch 6; iter: 0; batch classifier loss: 0.615835; batch adversarial loss: 0.623705\n",
      "epoch 7; iter: 0; batch classifier loss: 0.427643; batch adversarial loss: 0.560998\n",
      "epoch 8; iter: 0; batch classifier loss: 0.471431; batch adversarial loss: 0.560432\n",
      "epoch 9; iter: 0; batch classifier loss: 0.423525; batch adversarial loss: 0.552064\n",
      "epoch 10; iter: 0; batch classifier loss: 0.371649; batch adversarial loss: 0.549519\n",
      "epoch 11; iter: 0; batch classifier loss: 0.309552; batch adversarial loss: 0.569311\n",
      "epoch 12; iter: 0; batch classifier loss: 0.305839; batch adversarial loss: 0.563397\n",
      "epoch 13; iter: 0; batch classifier loss: 0.306799; batch adversarial loss: 0.460385\n",
      "epoch 14; iter: 0; batch classifier loss: 0.329868; batch adversarial loss: 0.512404\n",
      "epoch 15; iter: 0; batch classifier loss: 0.249959; batch adversarial loss: 0.448233\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281712; batch adversarial loss: 0.461721\n",
      "epoch 17; iter: 0; batch classifier loss: 0.254416; batch adversarial loss: 0.526946\n",
      "epoch 18; iter: 0; batch classifier loss: 0.269783; batch adversarial loss: 0.468455\n",
      "epoch 19; iter: 0; batch classifier loss: 0.275745; batch adversarial loss: 0.469165\n",
      "epoch 20; iter: 0; batch classifier loss: 0.173476; batch adversarial loss: 0.470776\n",
      "epoch 21; iter: 0; batch classifier loss: 0.196123; batch adversarial loss: 0.494031\n",
      "epoch 22; iter: 0; batch classifier loss: 0.203850; batch adversarial loss: 0.548418\n",
      "epoch 23; iter: 0; batch classifier loss: 0.145137; batch adversarial loss: 0.502505\n",
      "epoch 24; iter: 0; batch classifier loss: 0.161260; batch adversarial loss: 0.504522\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174270; batch adversarial loss: 0.498463\n",
      "epoch 26; iter: 0; batch classifier loss: 0.161340; batch adversarial loss: 0.470532\n",
      "epoch 27; iter: 0; batch classifier loss: 0.189603; batch adversarial loss: 0.478159\n",
      "epoch 28; iter: 0; batch classifier loss: 0.179131; batch adversarial loss: 0.486661\n",
      "epoch 29; iter: 0; batch classifier loss: 0.136005; batch adversarial loss: 0.470226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.137245; batch adversarial loss: 0.411487\n",
      "epoch 31; iter: 0; batch classifier loss: 0.133395; batch adversarial loss: 0.571452\n",
      "epoch 32; iter: 0; batch classifier loss: 0.084379; batch adversarial loss: 0.481507\n",
      "epoch 33; iter: 0; batch classifier loss: 0.145281; batch adversarial loss: 0.541633\n",
      "epoch 34; iter: 0; batch classifier loss: 0.135934; batch adversarial loss: 0.451822\n",
      "epoch 35; iter: 0; batch classifier loss: 0.074062; batch adversarial loss: 0.426136\n",
      "epoch 36; iter: 0; batch classifier loss: 0.131294; batch adversarial loss: 0.459438\n",
      "epoch 37; iter: 0; batch classifier loss: 0.092288; batch adversarial loss: 0.539877\n",
      "epoch 38; iter: 0; batch classifier loss: 0.199006; batch adversarial loss: 0.469576\n",
      "epoch 39; iter: 0; batch classifier loss: 0.095207; batch adversarial loss: 0.458207\n",
      "epoch 40; iter: 0; batch classifier loss: 0.184611; batch adversarial loss: 0.507029\n",
      "epoch 41; iter: 0; batch classifier loss: 0.133766; batch adversarial loss: 0.457969\n",
      "epoch 42; iter: 0; batch classifier loss: 0.134669; batch adversarial loss: 0.435769\n",
      "epoch 43; iter: 0; batch classifier loss: 0.090149; batch adversarial loss: 0.434503\n",
      "epoch 44; iter: 0; batch classifier loss: 0.108729; batch adversarial loss: 0.442524\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086752; batch adversarial loss: 0.481452\n",
      "epoch 46; iter: 0; batch classifier loss: 0.078136; batch adversarial loss: 0.501837\n",
      "epoch 47; iter: 0; batch classifier loss: 0.083908; batch adversarial loss: 0.606227\n",
      "epoch 48; iter: 0; batch classifier loss: 0.083445; batch adversarial loss: 0.414115\n",
      "epoch 49; iter: 0; batch classifier loss: 0.102941; batch adversarial loss: 0.420299\n",
      "epoch 50; iter: 0; batch classifier loss: 0.137559; batch adversarial loss: 0.400366\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081694; batch adversarial loss: 0.500250\n",
      "epoch 52; iter: 0; batch classifier loss: 0.058659; batch adversarial loss: 0.539249\n",
      "epoch 53; iter: 0; batch classifier loss: 0.105576; batch adversarial loss: 0.488840\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103107; batch adversarial loss: 0.492309\n",
      "epoch 55; iter: 0; batch classifier loss: 0.100598; batch adversarial loss: 0.456191\n",
      "epoch 56; iter: 0; batch classifier loss: 0.110684; batch adversarial loss: 0.475287\n",
      "epoch 57; iter: 0; batch classifier loss: 0.089921; batch adversarial loss: 0.497173\n",
      "epoch 58; iter: 0; batch classifier loss: 0.094400; batch adversarial loss: 0.456385\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102979; batch adversarial loss: 0.531492\n",
      "epoch 60; iter: 0; batch classifier loss: 0.101830; batch adversarial loss: 0.466535\n",
      "epoch 61; iter: 0; batch classifier loss: 0.096336; batch adversarial loss: 0.474193\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084041; batch adversarial loss: 0.432554\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088857; batch adversarial loss: 0.414066\n",
      "epoch 64; iter: 0; batch classifier loss: 0.042576; batch adversarial loss: 0.472962\n",
      "epoch 65; iter: 0; batch classifier loss: 0.060603; batch adversarial loss: 0.412919\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088089; batch adversarial loss: 0.459856\n",
      "epoch 67; iter: 0; batch classifier loss: 0.077791; batch adversarial loss: 0.464054\n",
      "epoch 68; iter: 0; batch classifier loss: 0.107980; batch adversarial loss: 0.487899\n",
      "epoch 69; iter: 0; batch classifier loss: 0.080166; batch adversarial loss: 0.479834\n",
      "epoch 70; iter: 0; batch classifier loss: 0.050988; batch adversarial loss: 0.434849\n",
      "epoch 71; iter: 0; batch classifier loss: 0.051358; batch adversarial loss: 0.510475\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082765; batch adversarial loss: 0.412471\n",
      "epoch 73; iter: 0; batch classifier loss: 0.088723; batch adversarial loss: 0.457210\n",
      "epoch 74; iter: 0; batch classifier loss: 0.078876; batch adversarial loss: 0.461097\n",
      "epoch 75; iter: 0; batch classifier loss: 0.053369; batch adversarial loss: 0.555968\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055518; batch adversarial loss: 0.567946\n",
      "epoch 77; iter: 0; batch classifier loss: 0.097269; batch adversarial loss: 0.510175\n",
      "epoch 78; iter: 0; batch classifier loss: 0.088828; batch adversarial loss: 0.421728\n",
      "epoch 79; iter: 0; batch classifier loss: 0.081534; batch adversarial loss: 0.527604\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075405; batch adversarial loss: 0.415045\n",
      "epoch 81; iter: 0; batch classifier loss: 0.116846; batch adversarial loss: 0.441864\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065729; batch adversarial loss: 0.532839\n",
      "epoch 83; iter: 0; batch classifier loss: 0.097306; batch adversarial loss: 0.361619\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082358; batch adversarial loss: 0.540880\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061401; batch adversarial loss: 0.438567\n",
      "epoch 86; iter: 0; batch classifier loss: 0.113129; batch adversarial loss: 0.373578\n",
      "epoch 87; iter: 0; batch classifier loss: 0.081843; batch adversarial loss: 0.423983\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058633; batch adversarial loss: 0.439309\n",
      "epoch 89; iter: 0; batch classifier loss: 0.079056; batch adversarial loss: 0.481265\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062975; batch adversarial loss: 0.431763\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077165; batch adversarial loss: 0.444126\n",
      "epoch 92; iter: 0; batch classifier loss: 0.040849; batch adversarial loss: 0.481900\n",
      "epoch 93; iter: 0; batch classifier loss: 0.102745; batch adversarial loss: 0.536214\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038907; batch adversarial loss: 0.426620\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053664; batch adversarial loss: 0.499124\n",
      "epoch 96; iter: 0; batch classifier loss: 0.081391; batch adversarial loss: 0.466728\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055986; batch adversarial loss: 0.399752\n",
      "epoch 98; iter: 0; batch classifier loss: 0.077400; batch adversarial loss: 0.519402\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050704; batch adversarial loss: 0.459173\n",
      "epoch 100; iter: 0; batch classifier loss: 0.069333; batch adversarial loss: 0.403704\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049773; batch adversarial loss: 0.525284\n",
      "epoch 102; iter: 0; batch classifier loss: 0.035948; batch adversarial loss: 0.418026\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056027; batch adversarial loss: 0.466753\n",
      "epoch 104; iter: 0; batch classifier loss: 0.049447; batch adversarial loss: 0.458509\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048722; batch adversarial loss: 0.516357\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040298; batch adversarial loss: 0.505077\n",
      "epoch 107; iter: 0; batch classifier loss: 0.101917; batch adversarial loss: 0.404778\n",
      "epoch 108; iter: 0; batch classifier loss: 0.082681; batch adversarial loss: 0.486521\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046280; batch adversarial loss: 0.523699\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050235; batch adversarial loss: 0.452040\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048902; batch adversarial loss: 0.391949\n",
      "epoch 112; iter: 0; batch classifier loss: 0.074829; batch adversarial loss: 0.470160\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039430; batch adversarial loss: 0.500532\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050138; batch adversarial loss: 0.433696\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057875; batch adversarial loss: 0.441160\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062268; batch adversarial loss: 0.517502\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034527; batch adversarial loss: 0.506493\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041040; batch adversarial loss: 0.469589\n",
      "epoch 119; iter: 0; batch classifier loss: 0.071917; batch adversarial loss: 0.455602\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048155; batch adversarial loss: 0.453802\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026696; batch adversarial loss: 0.453315\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030715; batch adversarial loss: 0.427420\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036050; batch adversarial loss: 0.519913\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044599; batch adversarial loss: 0.411159\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033172; batch adversarial loss: 0.529505\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023111; batch adversarial loss: 0.442553\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047895; batch adversarial loss: 0.496318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.062911; batch adversarial loss: 0.442543\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048263; batch adversarial loss: 0.459177\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036226; batch adversarial loss: 0.425749\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035906; batch adversarial loss: 0.401921\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043511; batch adversarial loss: 0.484483\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015330; batch adversarial loss: 0.443882\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042849; batch adversarial loss: 0.571553\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022051; batch adversarial loss: 0.640815\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037324; batch adversarial loss: 0.442097\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026998; batch adversarial loss: 0.466603\n",
      "epoch 138; iter: 0; batch classifier loss: 0.065544; batch adversarial loss: 0.413351\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014148; batch adversarial loss: 0.519245\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053510; batch adversarial loss: 0.464351\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021635; batch adversarial loss: 0.484939\n",
      "epoch 142; iter: 0; batch classifier loss: 0.112760; batch adversarial loss: 0.433321\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032778; batch adversarial loss: 0.482922\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052276; batch adversarial loss: 0.462334\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046913; batch adversarial loss: 0.446810\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037312; batch adversarial loss: 0.465853\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025425; batch adversarial loss: 0.547012\n",
      "epoch 148; iter: 0; batch classifier loss: 0.055940; batch adversarial loss: 0.535969\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024623; batch adversarial loss: 0.489945\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036844; batch adversarial loss: 0.426792\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022290; batch adversarial loss: 0.560321\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025202; batch adversarial loss: 0.379930\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023889; batch adversarial loss: 0.472481\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029323; batch adversarial loss: 0.493254\n",
      "epoch 155; iter: 0; batch classifier loss: 0.043901; batch adversarial loss: 0.480994\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020523; batch adversarial loss: 0.430977\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028624; batch adversarial loss: 0.515968\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015643; batch adversarial loss: 0.416825\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022521; batch adversarial loss: 0.439464\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020820; batch adversarial loss: 0.381420\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029892; batch adversarial loss: 0.428161\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028425; batch adversarial loss: 0.439787\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039418; batch adversarial loss: 0.398523\n",
      "epoch 164; iter: 0; batch classifier loss: 0.069583; batch adversarial loss: 0.417754\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016279; batch adversarial loss: 0.457251\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013397; batch adversarial loss: 0.480440\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008003; batch adversarial loss: 0.511737\n",
      "epoch 168; iter: 0; batch classifier loss: 0.039083; batch adversarial loss: 0.472085\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017999; batch adversarial loss: 0.458057\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009733; batch adversarial loss: 0.493988\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008341; batch adversarial loss: 0.384629\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025415; batch adversarial loss: 0.471273\n",
      "epoch 173; iter: 0; batch classifier loss: 0.042687; batch adversarial loss: 0.489212\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016079; batch adversarial loss: 0.435603\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024018; batch adversarial loss: 0.451727\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040773; batch adversarial loss: 0.532334\n",
      "epoch 177; iter: 0; batch classifier loss: 0.002349; batch adversarial loss: 0.409742\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023018; batch adversarial loss: 0.428528\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044054; batch adversarial loss: 0.452850\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021969; batch adversarial loss: 0.432997\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007678; batch adversarial loss: 0.449488\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007737; batch adversarial loss: 0.501277\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029553; batch adversarial loss: 0.503462\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031594; batch adversarial loss: 0.358668\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014279; batch adversarial loss: 0.459730\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031820; batch adversarial loss: 0.545630\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024952; batch adversarial loss: 0.484923\n",
      "epoch 188; iter: 0; batch classifier loss: 0.048162; batch adversarial loss: 0.419441\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019682; batch adversarial loss: 0.416673\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011578; batch adversarial loss: 0.530772\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030596; batch adversarial loss: 0.523099\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037298; batch adversarial loss: 0.509446\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035434; batch adversarial loss: 0.500305\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024013; batch adversarial loss: 0.420752\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022647; batch adversarial loss: 0.457718\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008737; batch adversarial loss: 0.440929\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033042; batch adversarial loss: 0.482896\n",
      "epoch 198; iter: 0; batch classifier loss: 0.036384; batch adversarial loss: 0.432267\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015890; batch adversarial loss: 0.541271\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687806; batch adversarial loss: 0.764408\n",
      "epoch 1; iter: 0; batch classifier loss: 0.499911; batch adversarial loss: 0.739993\n",
      "epoch 2; iter: 0; batch classifier loss: 0.468822; batch adversarial loss: 0.710093\n",
      "epoch 3; iter: 0; batch classifier loss: 0.346919; batch adversarial loss: 0.654146\n",
      "epoch 4; iter: 0; batch classifier loss: 0.347296; batch adversarial loss: 0.636824\n",
      "epoch 5; iter: 0; batch classifier loss: 0.384471; batch adversarial loss: 0.626909\n",
      "epoch 6; iter: 0; batch classifier loss: 0.272178; batch adversarial loss: 0.580665\n",
      "epoch 7; iter: 0; batch classifier loss: 0.290054; batch adversarial loss: 0.540663\n",
      "epoch 8; iter: 0; batch classifier loss: 0.295485; batch adversarial loss: 0.515860\n",
      "epoch 9; iter: 0; batch classifier loss: 0.257332; batch adversarial loss: 0.519553\n",
      "epoch 10; iter: 0; batch classifier loss: 0.298100; batch adversarial loss: 0.499897\n",
      "epoch 11; iter: 0; batch classifier loss: 0.219700; batch adversarial loss: 0.468718\n",
      "epoch 12; iter: 0; batch classifier loss: 0.279747; batch adversarial loss: 0.434693\n",
      "epoch 13; iter: 0; batch classifier loss: 0.228138; batch adversarial loss: 0.453334\n",
      "epoch 14; iter: 0; batch classifier loss: 0.161633; batch adversarial loss: 0.468975\n",
      "epoch 15; iter: 0; batch classifier loss: 0.173875; batch adversarial loss: 0.399035\n",
      "epoch 16; iter: 0; batch classifier loss: 0.179599; batch adversarial loss: 0.451180\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265836; batch adversarial loss: 0.455186\n",
      "epoch 18; iter: 0; batch classifier loss: 0.186954; batch adversarial loss: 0.441041\n",
      "epoch 19; iter: 0; batch classifier loss: 0.160160; batch adversarial loss: 0.424472\n",
      "epoch 20; iter: 0; batch classifier loss: 0.216119; batch adversarial loss: 0.396590\n",
      "epoch 21; iter: 0; batch classifier loss: 0.280732; batch adversarial loss: 0.500295\n",
      "epoch 22; iter: 0; batch classifier loss: 0.219444; batch adversarial loss: 0.418655\n",
      "epoch 23; iter: 0; batch classifier loss: 0.216055; batch adversarial loss: 0.443198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.164243; batch adversarial loss: 0.334603\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179726; batch adversarial loss: 0.416237\n",
      "epoch 26; iter: 0; batch classifier loss: 0.144730; batch adversarial loss: 0.346433\n",
      "epoch 27; iter: 0; batch classifier loss: 0.136740; batch adversarial loss: 0.441986\n",
      "epoch 28; iter: 0; batch classifier loss: 0.155399; batch adversarial loss: 0.389585\n",
      "epoch 29; iter: 0; batch classifier loss: 0.157647; batch adversarial loss: 0.455630\n",
      "epoch 30; iter: 0; batch classifier loss: 0.154663; batch adversarial loss: 0.399057\n",
      "epoch 31; iter: 0; batch classifier loss: 0.131317; batch adversarial loss: 0.406275\n",
      "epoch 32; iter: 0; batch classifier loss: 0.120218; batch adversarial loss: 0.437332\n",
      "epoch 33; iter: 0; batch classifier loss: 0.180437; batch adversarial loss: 0.427937\n",
      "epoch 34; iter: 0; batch classifier loss: 0.128998; batch adversarial loss: 0.367386\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142083; batch adversarial loss: 0.417602\n",
      "epoch 36; iter: 0; batch classifier loss: 0.170419; batch adversarial loss: 0.447146\n",
      "epoch 37; iter: 0; batch classifier loss: 0.103889; batch adversarial loss: 0.389388\n",
      "epoch 38; iter: 0; batch classifier loss: 0.137167; batch adversarial loss: 0.458000\n",
      "epoch 39; iter: 0; batch classifier loss: 0.109442; batch adversarial loss: 0.423174\n",
      "epoch 40; iter: 0; batch classifier loss: 0.145885; batch adversarial loss: 0.427936\n",
      "epoch 41; iter: 0; batch classifier loss: 0.103349; batch adversarial loss: 0.441967\n",
      "epoch 42; iter: 0; batch classifier loss: 0.082785; batch adversarial loss: 0.428021\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110958; batch adversarial loss: 0.379099\n",
      "epoch 44; iter: 0; batch classifier loss: 0.120502; batch adversarial loss: 0.447169\n",
      "epoch 45; iter: 0; batch classifier loss: 0.081430; batch adversarial loss: 0.465133\n",
      "epoch 46; iter: 0; batch classifier loss: 0.085629; batch adversarial loss: 0.469423\n",
      "epoch 47; iter: 0; batch classifier loss: 0.110577; batch adversarial loss: 0.443621\n",
      "epoch 48; iter: 0; batch classifier loss: 0.094885; batch adversarial loss: 0.431199\n",
      "epoch 49; iter: 0; batch classifier loss: 0.083080; batch adversarial loss: 0.391717\n",
      "epoch 50; iter: 0; batch classifier loss: 0.104064; batch adversarial loss: 0.371439\n",
      "epoch 51; iter: 0; batch classifier loss: 0.090857; batch adversarial loss: 0.421801\n",
      "epoch 52; iter: 0; batch classifier loss: 0.072283; batch adversarial loss: 0.359784\n",
      "epoch 53; iter: 0; batch classifier loss: 0.093157; batch adversarial loss: 0.377302\n",
      "epoch 54; iter: 0; batch classifier loss: 0.060939; batch adversarial loss: 0.465396\n",
      "epoch 55; iter: 0; batch classifier loss: 0.101384; batch adversarial loss: 0.380404\n",
      "epoch 56; iter: 0; batch classifier loss: 0.088726; batch adversarial loss: 0.355055\n",
      "epoch 57; iter: 0; batch classifier loss: 0.132685; batch adversarial loss: 0.390237\n",
      "epoch 58; iter: 0; batch classifier loss: 0.073744; batch adversarial loss: 0.366429\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083442; batch adversarial loss: 0.381151\n",
      "epoch 60; iter: 0; batch classifier loss: 0.111780; batch adversarial loss: 0.380458\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074016; batch adversarial loss: 0.398198\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080936; batch adversarial loss: 0.478512\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070111; batch adversarial loss: 0.406482\n",
      "epoch 64; iter: 0; batch classifier loss: 0.056589; batch adversarial loss: 0.416980\n",
      "epoch 65; iter: 0; batch classifier loss: 0.084853; batch adversarial loss: 0.457203\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075727; batch adversarial loss: 0.359958\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100747; batch adversarial loss: 0.432940\n",
      "epoch 68; iter: 0; batch classifier loss: 0.059376; batch adversarial loss: 0.486662\n",
      "epoch 69; iter: 0; batch classifier loss: 0.112429; batch adversarial loss: 0.455851\n",
      "epoch 70; iter: 0; batch classifier loss: 0.106869; batch adversarial loss: 0.513783\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083317; batch adversarial loss: 0.459633\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071675; batch adversarial loss: 0.377352\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084829; batch adversarial loss: 0.405253\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076723; batch adversarial loss: 0.409917\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077217; batch adversarial loss: 0.429540\n",
      "epoch 76; iter: 0; batch classifier loss: 0.049249; batch adversarial loss: 0.417825\n",
      "epoch 77; iter: 0; batch classifier loss: 0.053573; batch adversarial loss: 0.462056\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073063; batch adversarial loss: 0.503349\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061695; batch adversarial loss: 0.425542\n",
      "epoch 80; iter: 0; batch classifier loss: 0.099587; batch adversarial loss: 0.536575\n",
      "epoch 81; iter: 0; batch classifier loss: 0.060396; batch adversarial loss: 0.410364\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075494; batch adversarial loss: 0.381616\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068248; batch adversarial loss: 0.495833\n",
      "epoch 84; iter: 0; batch classifier loss: 0.074521; batch adversarial loss: 0.393261\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055749; batch adversarial loss: 0.374216\n",
      "epoch 86; iter: 0; batch classifier loss: 0.059057; batch adversarial loss: 0.433325\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076177; batch adversarial loss: 0.422757\n",
      "epoch 88; iter: 0; batch classifier loss: 0.099942; batch adversarial loss: 0.451581\n",
      "epoch 89; iter: 0; batch classifier loss: 0.049873; batch adversarial loss: 0.552382\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052827; batch adversarial loss: 0.399613\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062769; batch adversarial loss: 0.363883\n",
      "epoch 92; iter: 0; batch classifier loss: 0.083565; batch adversarial loss: 0.377202\n",
      "epoch 93; iter: 0; batch classifier loss: 0.084692; batch adversarial loss: 0.515518\n",
      "epoch 94; iter: 0; batch classifier loss: 0.034830; batch adversarial loss: 0.461377\n",
      "epoch 95; iter: 0; batch classifier loss: 0.061707; batch adversarial loss: 0.409017\n",
      "epoch 96; iter: 0; batch classifier loss: 0.025422; batch adversarial loss: 0.357069\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049795; batch adversarial loss: 0.500556\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036064; batch adversarial loss: 0.565761\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059632; batch adversarial loss: 0.425247\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044053; batch adversarial loss: 0.487096\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057601; batch adversarial loss: 0.486838\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042443; batch adversarial loss: 0.455409\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064782; batch adversarial loss: 0.443786\n",
      "epoch 104; iter: 0; batch classifier loss: 0.035252; batch adversarial loss: 0.328985\n",
      "epoch 105; iter: 0; batch classifier loss: 0.027820; batch adversarial loss: 0.468735\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036100; batch adversarial loss: 0.396140\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027761; batch adversarial loss: 0.438308\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028060; batch adversarial loss: 0.441718\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032003; batch adversarial loss: 0.443349\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044767; batch adversarial loss: 0.439173\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031760; batch adversarial loss: 0.393695\n",
      "epoch 112; iter: 0; batch classifier loss: 0.062972; batch adversarial loss: 0.446224\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048868; batch adversarial loss: 0.365415\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030392; batch adversarial loss: 0.399276\n",
      "epoch 115; iter: 0; batch classifier loss: 0.026778; batch adversarial loss: 0.496622\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021240; batch adversarial loss: 0.506714\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029627; batch adversarial loss: 0.377615\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041470; batch adversarial loss: 0.511875\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030215; batch adversarial loss: 0.452818\n",
      "epoch 120; iter: 0; batch classifier loss: 0.026364; batch adversarial loss: 0.486407\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026285; batch adversarial loss: 0.500782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.029092; batch adversarial loss: 0.492733\n",
      "epoch 123; iter: 0; batch classifier loss: 0.088961; batch adversarial loss: 0.619553\n",
      "epoch 124; iter: 0; batch classifier loss: 0.080778; batch adversarial loss: 0.740783\n",
      "epoch 125; iter: 0; batch classifier loss: 0.095648; batch adversarial loss: 0.580741\n",
      "epoch 126; iter: 0; batch classifier loss: 0.041401; batch adversarial loss: 0.522016\n",
      "epoch 127; iter: 0; batch classifier loss: 0.161482; batch adversarial loss: 0.592077\n",
      "epoch 128; iter: 0; batch classifier loss: 0.071473; batch adversarial loss: 0.539997\n",
      "epoch 129; iter: 0; batch classifier loss: 0.183243; batch adversarial loss: 0.704804\n",
      "epoch 130; iter: 0; batch classifier loss: 0.118030; batch adversarial loss: 0.541945\n",
      "epoch 131; iter: 0; batch classifier loss: 0.195486; batch adversarial loss: 0.737810\n",
      "epoch 132; iter: 0; batch classifier loss: 0.140549; batch adversarial loss: 0.605001\n",
      "epoch 133; iter: 0; batch classifier loss: 0.126270; batch adversarial loss: 0.617550\n",
      "epoch 134; iter: 0; batch classifier loss: 0.114920; batch adversarial loss: 0.594927\n",
      "epoch 135; iter: 0; batch classifier loss: 0.152638; batch adversarial loss: 0.736855\n",
      "epoch 136; iter: 0; batch classifier loss: 0.070666; batch adversarial loss: 0.496513\n",
      "epoch 137; iter: 0; batch classifier loss: 0.096936; batch adversarial loss: 0.532288\n",
      "epoch 138; iter: 0; batch classifier loss: 0.156083; batch adversarial loss: 0.644931\n",
      "epoch 139; iter: 0; batch classifier loss: 0.139229; batch adversarial loss: 0.549927\n",
      "epoch 140; iter: 0; batch classifier loss: 0.193869; batch adversarial loss: 0.650663\n",
      "epoch 141; iter: 0; batch classifier loss: 0.102453; batch adversarial loss: 0.550470\n",
      "epoch 142; iter: 0; batch classifier loss: 0.197808; batch adversarial loss: 0.601370\n",
      "epoch 143; iter: 0; batch classifier loss: 0.086260; batch adversarial loss: 0.493249\n",
      "epoch 144; iter: 0; batch classifier loss: 0.086427; batch adversarial loss: 0.450308\n",
      "epoch 145; iter: 0; batch classifier loss: 0.138180; batch adversarial loss: 0.502297\n",
      "epoch 146; iter: 0; batch classifier loss: 0.165024; batch adversarial loss: 0.621705\n",
      "epoch 147; iter: 0; batch classifier loss: 0.155863; batch adversarial loss: 0.577793\n",
      "epoch 148; iter: 0; batch classifier loss: 0.104696; batch adversarial loss: 0.493382\n",
      "epoch 149; iter: 0; batch classifier loss: 0.169508; batch adversarial loss: 0.633711\n",
      "epoch 150; iter: 0; batch classifier loss: 0.133696; batch adversarial loss: 0.465242\n",
      "epoch 151; iter: 0; batch classifier loss: 0.144301; batch adversarial loss: 0.500544\n",
      "epoch 152; iter: 0; batch classifier loss: 0.222524; batch adversarial loss: 0.655329\n",
      "epoch 153; iter: 0; batch classifier loss: 0.091786; batch adversarial loss: 0.441589\n",
      "epoch 154; iter: 0; batch classifier loss: 0.110039; batch adversarial loss: 0.469167\n",
      "epoch 155; iter: 0; batch classifier loss: 0.172305; batch adversarial loss: 0.545493\n",
      "epoch 156; iter: 0; batch classifier loss: 0.172757; batch adversarial loss: 0.467960\n",
      "epoch 157; iter: 0; batch classifier loss: 0.101222; batch adversarial loss: 0.472372\n",
      "epoch 158; iter: 0; batch classifier loss: 0.098040; batch adversarial loss: 0.461888\n",
      "epoch 159; iter: 0; batch classifier loss: 0.111685; batch adversarial loss: 0.500161\n",
      "epoch 160; iter: 0; batch classifier loss: 0.094839; batch adversarial loss: 0.469248\n",
      "epoch 161; iter: 0; batch classifier loss: 0.119074; batch adversarial loss: 0.491220\n",
      "epoch 162; iter: 0; batch classifier loss: 0.084731; batch adversarial loss: 0.579396\n",
      "epoch 163; iter: 0; batch classifier loss: 0.090780; batch adversarial loss: 0.542614\n",
      "epoch 164; iter: 0; batch classifier loss: 0.144177; batch adversarial loss: 0.492589\n",
      "epoch 165; iter: 0; batch classifier loss: 0.113177; batch adversarial loss: 0.441677\n",
      "epoch 166; iter: 0; batch classifier loss: 0.081411; batch adversarial loss: 0.486966\n",
      "epoch 167; iter: 0; batch classifier loss: 0.153325; batch adversarial loss: 0.448266\n",
      "epoch 168; iter: 0; batch classifier loss: 0.082479; batch adversarial loss: 0.447486\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038928; batch adversarial loss: 0.431180\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028129; batch adversarial loss: 0.419348\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025563; batch adversarial loss: 0.456773\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036301; batch adversarial loss: 0.439265\n",
      "epoch 173; iter: 0; batch classifier loss: 0.047568; batch adversarial loss: 0.439225\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031023; batch adversarial loss: 0.453956\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025979; batch adversarial loss: 0.553346\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023997; batch adversarial loss: 0.469249\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049389; batch adversarial loss: 0.553073\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038613; batch adversarial loss: 0.548817\n",
      "epoch 179; iter: 0; batch classifier loss: 0.041811; batch adversarial loss: 0.510088\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023306; batch adversarial loss: 0.512697\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036115; batch adversarial loss: 0.445750\n",
      "epoch 182; iter: 0; batch classifier loss: 0.041439; batch adversarial loss: 0.352367\n",
      "epoch 183; iter: 0; batch classifier loss: 0.051398; batch adversarial loss: 0.461545\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020774; batch adversarial loss: 0.471073\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015111; batch adversarial loss: 0.467025\n",
      "epoch 186; iter: 0; batch classifier loss: 0.059325; batch adversarial loss: 0.500807\n",
      "epoch 187; iter: 0; batch classifier loss: 0.052583; batch adversarial loss: 0.506626\n",
      "epoch 188; iter: 0; batch classifier loss: 0.048219; batch adversarial loss: 0.489648\n",
      "epoch 189; iter: 0; batch classifier loss: 0.061249; batch adversarial loss: 0.507416\n",
      "epoch 190; iter: 0; batch classifier loss: 0.039347; batch adversarial loss: 0.415283\n",
      "epoch 191; iter: 0; batch classifier loss: 0.067414; batch adversarial loss: 0.524570\n",
      "epoch 192; iter: 0; batch classifier loss: 0.071359; batch adversarial loss: 0.477442\n",
      "epoch 193; iter: 0; batch classifier loss: 0.046322; batch adversarial loss: 0.519639\n",
      "epoch 194; iter: 0; batch classifier loss: 0.096587; batch adversarial loss: 0.471351\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027509; batch adversarial loss: 0.430720\n",
      "epoch 196; iter: 0; batch classifier loss: 0.039062; batch adversarial loss: 0.384012\n",
      "epoch 197; iter: 0; batch classifier loss: 0.060067; batch adversarial loss: 0.411158\n",
      "epoch 198; iter: 0; batch classifier loss: 0.058317; batch adversarial loss: 0.424197\n",
      "epoch 199; iter: 0; batch classifier loss: 0.063849; batch adversarial loss: 0.385972\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687439; batch adversarial loss: 0.873552\n",
      "epoch 1; iter: 0; batch classifier loss: 0.594432; batch adversarial loss: 0.819198\n",
      "epoch 2; iter: 0; batch classifier loss: 0.955021; batch adversarial loss: 0.886635\n",
      "epoch 3; iter: 0; batch classifier loss: 0.812105; batch adversarial loss: 0.759534\n",
      "epoch 4; iter: 0; batch classifier loss: 0.722640; batch adversarial loss: 0.667617\n",
      "epoch 5; iter: 0; batch classifier loss: 0.606813; batch adversarial loss: 0.628043\n",
      "epoch 6; iter: 0; batch classifier loss: 0.458540; batch adversarial loss: 0.569468\n",
      "epoch 7; iter: 0; batch classifier loss: 0.405382; batch adversarial loss: 0.524918\n",
      "epoch 8; iter: 0; batch classifier loss: 0.307977; batch adversarial loss: 0.529427\n",
      "epoch 9; iter: 0; batch classifier loss: 0.298895; batch adversarial loss: 0.524886\n",
      "epoch 10; iter: 0; batch classifier loss: 0.271005; batch adversarial loss: 0.540563\n",
      "epoch 11; iter: 0; batch classifier loss: 0.265978; batch adversarial loss: 0.519392\n",
      "epoch 12; iter: 0; batch classifier loss: 0.265152; batch adversarial loss: 0.441217\n",
      "epoch 13; iter: 0; batch classifier loss: 0.312187; batch adversarial loss: 0.469172\n",
      "epoch 14; iter: 0; batch classifier loss: 0.296940; batch adversarial loss: 0.517656\n",
      "epoch 15; iter: 0; batch classifier loss: 0.200238; batch adversarial loss: 0.502296\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222906; batch adversarial loss: 0.454202\n",
      "epoch 17; iter: 0; batch classifier loss: 0.263692; batch adversarial loss: 0.462978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.230215; batch adversarial loss: 0.504884\n",
      "epoch 19; iter: 0; batch classifier loss: 0.256732; batch adversarial loss: 0.508800\n",
      "epoch 20; iter: 0; batch classifier loss: 0.221265; batch adversarial loss: 0.470877\n",
      "epoch 21; iter: 0; batch classifier loss: 0.218349; batch adversarial loss: 0.447265\n",
      "epoch 22; iter: 0; batch classifier loss: 0.168504; batch adversarial loss: 0.393162\n",
      "epoch 23; iter: 0; batch classifier loss: 0.189888; batch adversarial loss: 0.454373\n",
      "epoch 24; iter: 0; batch classifier loss: 0.200866; batch adversarial loss: 0.468454\n",
      "epoch 25; iter: 0; batch classifier loss: 0.201924; batch adversarial loss: 0.445228\n",
      "epoch 26; iter: 0; batch classifier loss: 0.122888; batch adversarial loss: 0.454023\n",
      "epoch 27; iter: 0; batch classifier loss: 0.260371; batch adversarial loss: 0.415786\n",
      "epoch 28; iter: 0; batch classifier loss: 0.106846; batch adversarial loss: 0.405214\n",
      "epoch 29; iter: 0; batch classifier loss: 0.135678; batch adversarial loss: 0.459182\n",
      "epoch 30; iter: 0; batch classifier loss: 0.123636; batch adversarial loss: 0.505443\n",
      "epoch 31; iter: 0; batch classifier loss: 0.209859; batch adversarial loss: 0.409841\n",
      "epoch 32; iter: 0; batch classifier loss: 0.095119; batch adversarial loss: 0.480797\n",
      "epoch 33; iter: 0; batch classifier loss: 0.128344; batch adversarial loss: 0.458554\n",
      "epoch 34; iter: 0; batch classifier loss: 0.102354; batch adversarial loss: 0.466666\n",
      "epoch 35; iter: 0; batch classifier loss: 0.099919; batch adversarial loss: 0.426076\n",
      "epoch 36; iter: 0; batch classifier loss: 0.158700; batch adversarial loss: 0.525043\n",
      "epoch 37; iter: 0; batch classifier loss: 0.142028; batch adversarial loss: 0.547820\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148059; batch adversarial loss: 0.474961\n",
      "epoch 39; iter: 0; batch classifier loss: 0.130589; batch adversarial loss: 0.492118\n",
      "epoch 40; iter: 0; batch classifier loss: 0.119840; batch adversarial loss: 0.445698\n",
      "epoch 41; iter: 0; batch classifier loss: 0.087646; batch adversarial loss: 0.397765\n",
      "epoch 42; iter: 0; batch classifier loss: 0.154546; batch adversarial loss: 0.433239\n",
      "epoch 43; iter: 0; batch classifier loss: 0.111447; batch adversarial loss: 0.504495\n",
      "epoch 44; iter: 0; batch classifier loss: 0.111696; batch adversarial loss: 0.413042\n",
      "epoch 45; iter: 0; batch classifier loss: 0.101841; batch adversarial loss: 0.412466\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117046; batch adversarial loss: 0.421661\n",
      "epoch 47; iter: 0; batch classifier loss: 0.043386; batch adversarial loss: 0.435754\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082426; batch adversarial loss: 0.508961\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114312; batch adversarial loss: 0.381052\n",
      "epoch 50; iter: 0; batch classifier loss: 0.136182; batch adversarial loss: 0.392566\n",
      "epoch 51; iter: 0; batch classifier loss: 0.077773; batch adversarial loss: 0.456891\n",
      "epoch 52; iter: 0; batch classifier loss: 0.083598; batch adversarial loss: 0.455457\n",
      "epoch 53; iter: 0; batch classifier loss: 0.066517; batch adversarial loss: 0.445764\n",
      "epoch 54; iter: 0; batch classifier loss: 0.099367; batch adversarial loss: 0.473942\n",
      "epoch 55; iter: 0; batch classifier loss: 0.081826; batch adversarial loss: 0.399219\n",
      "epoch 56; iter: 0; batch classifier loss: 0.105424; batch adversarial loss: 0.365662\n",
      "epoch 57; iter: 0; batch classifier loss: 0.075060; batch adversarial loss: 0.427037\n",
      "epoch 58; iter: 0; batch classifier loss: 0.050121; batch adversarial loss: 0.482431\n",
      "epoch 59; iter: 0; batch classifier loss: 0.076827; batch adversarial loss: 0.382838\n",
      "epoch 60; iter: 0; batch classifier loss: 0.083241; batch adversarial loss: 0.398352\n",
      "epoch 61; iter: 0; batch classifier loss: 0.082423; batch adversarial loss: 0.455623\n",
      "epoch 62; iter: 0; batch classifier loss: 0.070351; batch adversarial loss: 0.572306\n",
      "epoch 63; iter: 0; batch classifier loss: 0.065838; batch adversarial loss: 0.401409\n",
      "epoch 64; iter: 0; batch classifier loss: 0.109768; batch adversarial loss: 0.389525\n",
      "epoch 65; iter: 0; batch classifier loss: 0.050211; batch adversarial loss: 0.401746\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062373; batch adversarial loss: 0.511464\n",
      "epoch 67; iter: 0; batch classifier loss: 0.068577; batch adversarial loss: 0.483511\n",
      "epoch 68; iter: 0; batch classifier loss: 0.058406; batch adversarial loss: 0.424470\n",
      "epoch 69; iter: 0; batch classifier loss: 0.066159; batch adversarial loss: 0.399140\n",
      "epoch 70; iter: 0; batch classifier loss: 0.057093; batch adversarial loss: 0.432686\n",
      "epoch 71; iter: 0; batch classifier loss: 0.062718; batch adversarial loss: 0.510813\n",
      "epoch 72; iter: 0; batch classifier loss: 0.036218; batch adversarial loss: 0.510900\n",
      "epoch 73; iter: 0; batch classifier loss: 0.048969; batch adversarial loss: 0.423125\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053711; batch adversarial loss: 0.516463\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071092; batch adversarial loss: 0.446924\n",
      "epoch 76; iter: 0; batch classifier loss: 0.067918; batch adversarial loss: 0.415542\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102142; batch adversarial loss: 0.392041\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062476; batch adversarial loss: 0.571515\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067890; batch adversarial loss: 0.343958\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070015; batch adversarial loss: 0.339867\n",
      "epoch 81; iter: 0; batch classifier loss: 0.108379; batch adversarial loss: 0.288368\n",
      "epoch 82; iter: 0; batch classifier loss: 0.058387; batch adversarial loss: 0.454144\n",
      "epoch 83; iter: 0; batch classifier loss: 0.046341; batch adversarial loss: 0.379511\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051684; batch adversarial loss: 0.485057\n",
      "epoch 85; iter: 0; batch classifier loss: 0.030509; batch adversarial loss: 0.477627\n",
      "epoch 86; iter: 0; batch classifier loss: 0.056993; batch adversarial loss: 0.399035\n",
      "epoch 87; iter: 0; batch classifier loss: 0.030152; batch adversarial loss: 0.452866\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059881; batch adversarial loss: 0.467325\n",
      "epoch 89; iter: 0; batch classifier loss: 0.047774; batch adversarial loss: 0.331691\n",
      "epoch 90; iter: 0; batch classifier loss: 0.087428; batch adversarial loss: 0.491065\n",
      "epoch 91; iter: 0; batch classifier loss: 0.036310; batch adversarial loss: 0.477437\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077441; batch adversarial loss: 0.438385\n",
      "epoch 93; iter: 0; batch classifier loss: 0.023921; batch adversarial loss: 0.485503\n",
      "epoch 94; iter: 0; batch classifier loss: 0.028534; batch adversarial loss: 0.389386\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038655; batch adversarial loss: 0.537274\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049232; batch adversarial loss: 0.470530\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066810; batch adversarial loss: 0.403192\n",
      "epoch 98; iter: 0; batch classifier loss: 0.043852; batch adversarial loss: 0.500606\n",
      "epoch 99; iter: 0; batch classifier loss: 0.034546; batch adversarial loss: 0.416481\n",
      "epoch 100; iter: 0; batch classifier loss: 0.031360; batch adversarial loss: 0.538676\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054043; batch adversarial loss: 0.458293\n",
      "epoch 102; iter: 0; batch classifier loss: 0.035459; batch adversarial loss: 0.372110\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040847; batch adversarial loss: 0.416589\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057836; batch adversarial loss: 0.395599\n",
      "epoch 105; iter: 0; batch classifier loss: 0.028363; batch adversarial loss: 0.515562\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053528; batch adversarial loss: 0.386995\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039357; batch adversarial loss: 0.418919\n",
      "epoch 108; iter: 0; batch classifier loss: 0.022424; batch adversarial loss: 0.510030\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037895; batch adversarial loss: 0.464088\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044281; batch adversarial loss: 0.362236\n",
      "epoch 111; iter: 0; batch classifier loss: 0.020146; batch adversarial loss: 0.467985\n",
      "epoch 112; iter: 0; batch classifier loss: 0.065396; batch adversarial loss: 0.479184\n",
      "epoch 113; iter: 0; batch classifier loss: 0.084850; batch adversarial loss: 0.440590\n",
      "epoch 114; iter: 0; batch classifier loss: 0.055799; batch adversarial loss: 0.492543\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040547; batch adversarial loss: 0.448001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.049140; batch adversarial loss: 0.452052\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025746; batch adversarial loss: 0.447782\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032586; batch adversarial loss: 0.459444\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036310; batch adversarial loss: 0.407633\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041294; batch adversarial loss: 0.514200\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037341; batch adversarial loss: 0.441568\n",
      "epoch 122; iter: 0; batch classifier loss: 0.014879; batch adversarial loss: 0.443966\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044490; batch adversarial loss: 0.514480\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019029; batch adversarial loss: 0.424943\n",
      "epoch 125; iter: 0; batch classifier loss: 0.019310; batch adversarial loss: 0.409940\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042350; batch adversarial loss: 0.392777\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042944; batch adversarial loss: 0.424521\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038693; batch adversarial loss: 0.392404\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056033; batch adversarial loss: 0.553027\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019893; batch adversarial loss: 0.509297\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050014; batch adversarial loss: 0.451375\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046481; batch adversarial loss: 0.484739\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028467; batch adversarial loss: 0.435491\n",
      "epoch 134; iter: 0; batch classifier loss: 0.046753; batch adversarial loss: 0.385495\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042433; batch adversarial loss: 0.483304\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054557; batch adversarial loss: 0.384120\n",
      "epoch 137; iter: 0; batch classifier loss: 0.070080; batch adversarial loss: 0.455707\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037491; batch adversarial loss: 0.446856\n",
      "epoch 139; iter: 0; batch classifier loss: 0.063780; batch adversarial loss: 0.404881\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030500; batch adversarial loss: 0.454835\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046022; batch adversarial loss: 0.343705\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024541; batch adversarial loss: 0.467617\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029932; batch adversarial loss: 0.532306\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025080; batch adversarial loss: 0.427809\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034535; batch adversarial loss: 0.349696\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034053; batch adversarial loss: 0.464614\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010092; batch adversarial loss: 0.391996\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038994; batch adversarial loss: 0.347876\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031301; batch adversarial loss: 0.527030\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028291; batch adversarial loss: 0.440832\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008538; batch adversarial loss: 0.443318\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017999; batch adversarial loss: 0.476247\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031779; batch adversarial loss: 0.399239\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016202; batch adversarial loss: 0.419245\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021991; batch adversarial loss: 0.424183\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024424; batch adversarial loss: 0.465876\n",
      "epoch 157; iter: 0; batch classifier loss: 0.005283; batch adversarial loss: 0.375718\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021242; batch adversarial loss: 0.576132\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014457; batch adversarial loss: 0.487896\n",
      "epoch 160; iter: 0; batch classifier loss: 0.059080; batch adversarial loss: 0.342680\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014666; batch adversarial loss: 0.471963\n",
      "epoch 162; iter: 0; batch classifier loss: 0.042864; batch adversarial loss: 0.383322\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011854; batch adversarial loss: 0.459089\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011377; batch adversarial loss: 0.472115\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012222; batch adversarial loss: 0.392764\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015516; batch adversarial loss: 0.410866\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039585; batch adversarial loss: 0.461232\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045122; batch adversarial loss: 0.457848\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015111; batch adversarial loss: 0.480200\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039498; batch adversarial loss: 0.491186\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030600; batch adversarial loss: 0.434060\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008272; batch adversarial loss: 0.508694\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009074; batch adversarial loss: 0.439941\n",
      "epoch 174; iter: 0; batch classifier loss: 0.006176; batch adversarial loss: 0.390549\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034286; batch adversarial loss: 0.418214\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029896; batch adversarial loss: 0.443924\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010021; batch adversarial loss: 0.446177\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006015; batch adversarial loss: 0.447397\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008914; batch adversarial loss: 0.419826\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032381; batch adversarial loss: 0.415209\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027418; batch adversarial loss: 0.499890\n",
      "epoch 182; iter: 0; batch classifier loss: 0.002139; batch adversarial loss: 0.434118\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017010; batch adversarial loss: 0.554807\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032657; batch adversarial loss: 0.446540\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016888; batch adversarial loss: 0.404066\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032256; batch adversarial loss: 0.451220\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021189; batch adversarial loss: 0.531064\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010624; batch adversarial loss: 0.393979\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016056; batch adversarial loss: 0.402326\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012742; batch adversarial loss: 0.341511\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010567; batch adversarial loss: 0.467934\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033239; batch adversarial loss: 0.397143\n",
      "epoch 193; iter: 0; batch classifier loss: 0.056251; batch adversarial loss: 0.437018\n",
      "epoch 194; iter: 0; batch classifier loss: 0.037944; batch adversarial loss: 0.446507\n",
      "epoch 195; iter: 0; batch classifier loss: 0.038581; batch adversarial loss: 0.363577\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011234; batch adversarial loss: 0.424836\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018915; batch adversarial loss: 0.445411\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016411; batch adversarial loss: 0.517689\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012743; batch adversarial loss: 0.406997\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708604; batch adversarial loss: 0.580429\n",
      "epoch 1; iter: 0; batch classifier loss: 0.521420; batch adversarial loss: 0.602772\n",
      "epoch 2; iter: 0; batch classifier loss: 0.393018; batch adversarial loss: 0.602634\n",
      "epoch 3; iter: 0; batch classifier loss: 0.328323; batch adversarial loss: 0.582757\n",
      "epoch 4; iter: 0; batch classifier loss: 0.363033; batch adversarial loss: 0.658079\n",
      "epoch 5; iter: 0; batch classifier loss: 0.322140; batch adversarial loss: 0.561088\n",
      "epoch 6; iter: 0; batch classifier loss: 0.432797; batch adversarial loss: 0.618438\n",
      "epoch 7; iter: 0; batch classifier loss: 0.467163; batch adversarial loss: 0.569628\n",
      "epoch 8; iter: 0; batch classifier loss: 0.464168; batch adversarial loss: 0.539792\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576148; batch adversarial loss: 0.580142\n",
      "epoch 10; iter: 0; batch classifier loss: 0.589003; batch adversarial loss: 0.581451\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526627; batch adversarial loss: 0.552957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.378448; batch adversarial loss: 0.495649\n",
      "epoch 13; iter: 0; batch classifier loss: 0.317619; batch adversarial loss: 0.483048\n",
      "epoch 14; iter: 0; batch classifier loss: 0.310514; batch adversarial loss: 0.456517\n",
      "epoch 15; iter: 0; batch classifier loss: 0.233503; batch adversarial loss: 0.547797\n",
      "epoch 16; iter: 0; batch classifier loss: 0.261075; batch adversarial loss: 0.439205\n",
      "epoch 17; iter: 0; batch classifier loss: 0.280802; batch adversarial loss: 0.523028\n",
      "epoch 18; iter: 0; batch classifier loss: 0.217334; batch adversarial loss: 0.476250\n",
      "epoch 19; iter: 0; batch classifier loss: 0.247402; batch adversarial loss: 0.500773\n",
      "epoch 20; iter: 0; batch classifier loss: 0.202613; batch adversarial loss: 0.448277\n",
      "epoch 21; iter: 0; batch classifier loss: 0.241782; batch adversarial loss: 0.472654\n",
      "epoch 22; iter: 0; batch classifier loss: 0.237828; batch adversarial loss: 0.457889\n",
      "epoch 23; iter: 0; batch classifier loss: 0.220539; batch adversarial loss: 0.469452\n",
      "epoch 24; iter: 0; batch classifier loss: 0.218272; batch adversarial loss: 0.431298\n",
      "epoch 25; iter: 0; batch classifier loss: 0.282453; batch adversarial loss: 0.388643\n",
      "epoch 26; iter: 0; batch classifier loss: 0.256989; batch adversarial loss: 0.499189\n",
      "epoch 27; iter: 0; batch classifier loss: 0.167447; batch adversarial loss: 0.411517\n",
      "epoch 28; iter: 0; batch classifier loss: 0.157925; batch adversarial loss: 0.474765\n",
      "epoch 29; iter: 0; batch classifier loss: 0.218870; batch adversarial loss: 0.542545\n",
      "epoch 30; iter: 0; batch classifier loss: 0.230697; batch adversarial loss: 0.362359\n",
      "epoch 31; iter: 0; batch classifier loss: 0.228135; batch adversarial loss: 0.446627\n",
      "epoch 32; iter: 0; batch classifier loss: 0.191840; batch adversarial loss: 0.477939\n",
      "epoch 33; iter: 0; batch classifier loss: 0.212870; batch adversarial loss: 0.424995\n",
      "epoch 34; iter: 0; batch classifier loss: 0.273705; batch adversarial loss: 0.491097\n",
      "epoch 35; iter: 0; batch classifier loss: 0.229304; batch adversarial loss: 0.520923\n",
      "epoch 36; iter: 0; batch classifier loss: 0.269413; batch adversarial loss: 0.438774\n",
      "epoch 37; iter: 0; batch classifier loss: 0.222842; batch adversarial loss: 0.419044\n",
      "epoch 38; iter: 0; batch classifier loss: 0.162664; batch adversarial loss: 0.394201\n",
      "epoch 39; iter: 0; batch classifier loss: 0.168981; batch adversarial loss: 0.523927\n",
      "epoch 40; iter: 0; batch classifier loss: 0.156119; batch adversarial loss: 0.405625\n",
      "epoch 41; iter: 0; batch classifier loss: 0.159818; batch adversarial loss: 0.489605\n",
      "epoch 42; iter: 0; batch classifier loss: 0.187340; batch adversarial loss: 0.488820\n",
      "epoch 43; iter: 0; batch classifier loss: 0.198028; batch adversarial loss: 0.412617\n",
      "epoch 44; iter: 0; batch classifier loss: 0.144274; batch adversarial loss: 0.388379\n",
      "epoch 45; iter: 0; batch classifier loss: 0.161396; batch adversarial loss: 0.448016\n",
      "epoch 46; iter: 0; batch classifier loss: 0.119970; batch adversarial loss: 0.546167\n",
      "epoch 47; iter: 0; batch classifier loss: 0.135739; batch adversarial loss: 0.460967\n",
      "epoch 48; iter: 0; batch classifier loss: 0.229175; batch adversarial loss: 0.437151\n",
      "epoch 49; iter: 0; batch classifier loss: 0.135830; batch adversarial loss: 0.446914\n",
      "epoch 50; iter: 0; batch classifier loss: 0.215982; batch adversarial loss: 0.441906\n",
      "epoch 51; iter: 0; batch classifier loss: 0.255553; batch adversarial loss: 0.507829\n",
      "epoch 52; iter: 0; batch classifier loss: 0.183733; batch adversarial loss: 0.388289\n",
      "epoch 53; iter: 0; batch classifier loss: 0.186725; batch adversarial loss: 0.433370\n",
      "epoch 54; iter: 0; batch classifier loss: 0.156176; batch adversarial loss: 0.482065\n",
      "epoch 55; iter: 0; batch classifier loss: 0.152624; batch adversarial loss: 0.433442\n",
      "epoch 56; iter: 0; batch classifier loss: 0.168456; batch adversarial loss: 0.409737\n",
      "epoch 57; iter: 0; batch classifier loss: 0.228945; batch adversarial loss: 0.433287\n",
      "epoch 58; iter: 0; batch classifier loss: 0.193456; batch adversarial loss: 0.480184\n",
      "epoch 59; iter: 0; batch classifier loss: 0.192541; batch adversarial loss: 0.576829\n",
      "epoch 60; iter: 0; batch classifier loss: 0.167026; batch adversarial loss: 0.604135\n",
      "epoch 61; iter: 0; batch classifier loss: 0.223848; batch adversarial loss: 0.455078\n",
      "epoch 62; iter: 0; batch classifier loss: 0.156004; batch adversarial loss: 0.468575\n",
      "epoch 63; iter: 0; batch classifier loss: 0.170382; batch adversarial loss: 0.568617\n",
      "epoch 64; iter: 0; batch classifier loss: 0.203354; batch adversarial loss: 0.571383\n",
      "epoch 65; iter: 0; batch classifier loss: 0.207336; batch adversarial loss: 0.472190\n",
      "epoch 66; iter: 0; batch classifier loss: 0.213409; batch adversarial loss: 0.557551\n",
      "epoch 67; iter: 0; batch classifier loss: 0.138831; batch adversarial loss: 0.433769\n",
      "epoch 68; iter: 0; batch classifier loss: 0.243571; batch adversarial loss: 0.334710\n",
      "epoch 69; iter: 0; batch classifier loss: 0.200773; batch adversarial loss: 0.483384\n",
      "epoch 70; iter: 0; batch classifier loss: 0.247832; batch adversarial loss: 0.458934\n",
      "epoch 71; iter: 0; batch classifier loss: 0.117081; batch adversarial loss: 0.520231\n",
      "epoch 72; iter: 0; batch classifier loss: 0.241126; batch adversarial loss: 0.420956\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101396; batch adversarial loss: 0.521653\n",
      "epoch 74; iter: 0; batch classifier loss: 0.152049; batch adversarial loss: 0.407437\n",
      "epoch 75; iter: 0; batch classifier loss: 0.142601; batch adversarial loss: 0.483713\n",
      "epoch 76; iter: 0; batch classifier loss: 0.210987; batch adversarial loss: 0.297710\n",
      "epoch 77; iter: 0; batch classifier loss: 0.117466; batch adversarial loss: 0.422685\n",
      "epoch 78; iter: 0; batch classifier loss: 0.138541; batch adversarial loss: 0.445429\n",
      "epoch 79; iter: 0; batch classifier loss: 0.179715; batch adversarial loss: 0.557432\n",
      "epoch 80; iter: 0; batch classifier loss: 0.214209; batch adversarial loss: 0.495861\n",
      "epoch 81; iter: 0; batch classifier loss: 0.125424; batch adversarial loss: 0.433790\n",
      "epoch 82; iter: 0; batch classifier loss: 0.136659; batch adversarial loss: 0.455795\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085480; batch adversarial loss: 0.433489\n",
      "epoch 84; iter: 0; batch classifier loss: 0.088147; batch adversarial loss: 0.384583\n",
      "epoch 85; iter: 0; batch classifier loss: 0.194321; batch adversarial loss: 0.482838\n",
      "epoch 86; iter: 0; batch classifier loss: 0.168971; batch adversarial loss: 0.457464\n",
      "epoch 87; iter: 0; batch classifier loss: 0.180150; batch adversarial loss: 0.396350\n",
      "epoch 88; iter: 0; batch classifier loss: 0.165855; batch adversarial loss: 0.494945\n",
      "epoch 89; iter: 0; batch classifier loss: 0.198255; batch adversarial loss: 0.359919\n",
      "epoch 90; iter: 0; batch classifier loss: 0.130707; batch adversarial loss: 0.407062\n",
      "epoch 91; iter: 0; batch classifier loss: 0.155614; batch adversarial loss: 0.434689\n",
      "epoch 92; iter: 0; batch classifier loss: 0.178754; batch adversarial loss: 0.535746\n",
      "epoch 93; iter: 0; batch classifier loss: 0.141828; batch adversarial loss: 0.447967\n",
      "epoch 94; iter: 0; batch classifier loss: 0.170765; batch adversarial loss: 0.500095\n",
      "epoch 95; iter: 0; batch classifier loss: 0.158258; batch adversarial loss: 0.444053\n",
      "epoch 96; iter: 0; batch classifier loss: 0.151196; batch adversarial loss: 0.456418\n",
      "epoch 97; iter: 0; batch classifier loss: 0.083450; batch adversarial loss: 0.505815\n",
      "epoch 98; iter: 0; batch classifier loss: 0.110428; batch adversarial loss: 0.469229\n",
      "epoch 99; iter: 0; batch classifier loss: 0.101972; batch adversarial loss: 0.399544\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074486; batch adversarial loss: 0.397450\n",
      "epoch 101; iter: 0; batch classifier loss: 0.095881; batch adversarial loss: 0.389243\n",
      "epoch 102; iter: 0; batch classifier loss: 0.126736; batch adversarial loss: 0.333817\n",
      "epoch 103; iter: 0; batch classifier loss: 0.128382; batch adversarial loss: 0.560395\n",
      "epoch 104; iter: 0; batch classifier loss: 0.120012; batch adversarial loss: 0.442462\n",
      "epoch 105; iter: 0; batch classifier loss: 0.105015; batch adversarial loss: 0.484817\n",
      "epoch 106; iter: 0; batch classifier loss: 0.060969; batch adversarial loss: 0.455636\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062122; batch adversarial loss: 0.399521\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055375; batch adversarial loss: 0.460830\n",
      "epoch 109; iter: 0; batch classifier loss: 0.078792; batch adversarial loss: 0.480077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.070447; batch adversarial loss: 0.479570\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049616; batch adversarial loss: 0.562565\n",
      "epoch 112; iter: 0; batch classifier loss: 0.089489; batch adversarial loss: 0.473886\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055767; batch adversarial loss: 0.499242\n",
      "epoch 114; iter: 0; batch classifier loss: 0.069417; batch adversarial loss: 0.432931\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043083; batch adversarial loss: 0.450893\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026806; batch adversarial loss: 0.526126\n",
      "epoch 117; iter: 0; batch classifier loss: 0.054895; batch adversarial loss: 0.535221\n",
      "epoch 118; iter: 0; batch classifier loss: 0.101738; batch adversarial loss: 0.440986\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057606; batch adversarial loss: 0.545591\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054946; batch adversarial loss: 0.416612\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038012; batch adversarial loss: 0.360197\n",
      "epoch 122; iter: 0; batch classifier loss: 0.053529; batch adversarial loss: 0.500304\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051611; batch adversarial loss: 0.415539\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023877; batch adversarial loss: 0.414534\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022053; batch adversarial loss: 0.434528\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022906; batch adversarial loss: 0.562303\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037325; batch adversarial loss: 0.412338\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018945; batch adversarial loss: 0.354425\n",
      "epoch 129; iter: 0; batch classifier loss: 0.054468; batch adversarial loss: 0.450635\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034504; batch adversarial loss: 0.509753\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038047; batch adversarial loss: 0.476184\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022904; batch adversarial loss: 0.401432\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049146; batch adversarial loss: 0.515867\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035722; batch adversarial loss: 0.417888\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020164; batch adversarial loss: 0.437722\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041829; batch adversarial loss: 0.447569\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017073; batch adversarial loss: 0.508338\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021617; batch adversarial loss: 0.534907\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019346; batch adversarial loss: 0.512039\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032694; batch adversarial loss: 0.475827\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029765; batch adversarial loss: 0.468248\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037320; batch adversarial loss: 0.539364\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031282; batch adversarial loss: 0.548749\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012611; batch adversarial loss: 0.432097\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048479; batch adversarial loss: 0.336320\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017399; batch adversarial loss: 0.423729\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017165; batch adversarial loss: 0.414512\n",
      "epoch 148; iter: 0; batch classifier loss: 0.008317; batch adversarial loss: 0.415784\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028211; batch adversarial loss: 0.525026\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034346; batch adversarial loss: 0.440076\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008352; batch adversarial loss: 0.480167\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015398; batch adversarial loss: 0.504664\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012370; batch adversarial loss: 0.392407\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016225; batch adversarial loss: 0.451377\n",
      "epoch 155; iter: 0; batch classifier loss: 0.060772; batch adversarial loss: 0.408644\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023204; batch adversarial loss: 0.432284\n",
      "epoch 157; iter: 0; batch classifier loss: 0.075131; batch adversarial loss: 0.467866\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021512; batch adversarial loss: 0.416935\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019239; batch adversarial loss: 0.437229\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007505; batch adversarial loss: 0.378599\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020840; batch adversarial loss: 0.467300\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024748; batch adversarial loss: 0.551617\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018314; batch adversarial loss: 0.441701\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019671; batch adversarial loss: 0.418063\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018996; batch adversarial loss: 0.443334\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015684; batch adversarial loss: 0.403944\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015198; batch adversarial loss: 0.486464\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021064; batch adversarial loss: 0.529606\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021088; batch adversarial loss: 0.503776\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016024; batch adversarial loss: 0.449098\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009182; batch adversarial loss: 0.269537\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015542; batch adversarial loss: 0.381670\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010281; batch adversarial loss: 0.435730\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012584; batch adversarial loss: 0.441908\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013816; batch adversarial loss: 0.462050\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030783; batch adversarial loss: 0.470421\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023533; batch adversarial loss: 0.460981\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015171; batch adversarial loss: 0.508361\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018491; batch adversarial loss: 0.451802\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025609; batch adversarial loss: 0.514392\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021684; batch adversarial loss: 0.492435\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008070; batch adversarial loss: 0.444717\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013473; batch adversarial loss: 0.513377\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009715; batch adversarial loss: 0.416676\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021920; batch adversarial loss: 0.379210\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013300; batch adversarial loss: 0.498382\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024235; batch adversarial loss: 0.487989\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021163; batch adversarial loss: 0.387295\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018608; batch adversarial loss: 0.472189\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019028; batch adversarial loss: 0.418436\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005993; batch adversarial loss: 0.379997\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015119; batch adversarial loss: 0.432238\n",
      "epoch 193; iter: 0; batch classifier loss: 0.002973; batch adversarial loss: 0.432186\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024694; batch adversarial loss: 0.470184\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004649; batch adversarial loss: 0.450416\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016321; batch adversarial loss: 0.438785\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011317; batch adversarial loss: 0.392469\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009099; batch adversarial loss: 0.515006\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016798; batch adversarial loss: 0.537706\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713296; batch adversarial loss: 0.670930\n",
      "epoch 1; iter: 0; batch classifier loss: 0.442271; batch adversarial loss: 0.698115\n",
      "epoch 2; iter: 0; batch classifier loss: 0.413194; batch adversarial loss: 0.695536\n",
      "epoch 3; iter: 0; batch classifier loss: 0.405143; batch adversarial loss: 0.618885\n",
      "epoch 4; iter: 0; batch classifier loss: 0.341100; batch adversarial loss: 0.617487\n",
      "epoch 5; iter: 0; batch classifier loss: 0.339408; batch adversarial loss: 0.581240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.301704; batch adversarial loss: 0.556092\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338310; batch adversarial loss: 0.535766\n",
      "epoch 8; iter: 0; batch classifier loss: 0.238775; batch adversarial loss: 0.506229\n",
      "epoch 9; iter: 0; batch classifier loss: 0.301812; batch adversarial loss: 0.495297\n",
      "epoch 10; iter: 0; batch classifier loss: 0.248707; batch adversarial loss: 0.496272\n",
      "epoch 11; iter: 0; batch classifier loss: 0.216761; batch adversarial loss: 0.486848\n",
      "epoch 12; iter: 0; batch classifier loss: 0.272585; batch adversarial loss: 0.517107\n",
      "epoch 13; iter: 0; batch classifier loss: 0.198364; batch adversarial loss: 0.459437\n",
      "epoch 14; iter: 0; batch classifier loss: 0.159391; batch adversarial loss: 0.427729\n",
      "epoch 15; iter: 0; batch classifier loss: 0.176830; batch adversarial loss: 0.444020\n",
      "epoch 16; iter: 0; batch classifier loss: 0.178822; batch adversarial loss: 0.459652\n",
      "epoch 17; iter: 0; batch classifier loss: 0.197638; batch adversarial loss: 0.434396\n",
      "epoch 18; iter: 0; batch classifier loss: 0.120280; batch adversarial loss: 0.424914\n",
      "epoch 19; iter: 0; batch classifier loss: 0.149722; batch adversarial loss: 0.388827\n",
      "epoch 20; iter: 0; batch classifier loss: 0.141211; batch adversarial loss: 0.480653\n",
      "epoch 21; iter: 0; batch classifier loss: 0.125084; batch adversarial loss: 0.430850\n",
      "epoch 22; iter: 0; batch classifier loss: 0.126289; batch adversarial loss: 0.500691\n",
      "epoch 23; iter: 0; batch classifier loss: 0.130730; batch adversarial loss: 0.399925\n",
      "epoch 24; iter: 0; batch classifier loss: 0.111888; batch adversarial loss: 0.536167\n",
      "epoch 25; iter: 0; batch classifier loss: 0.102234; batch adversarial loss: 0.465151\n",
      "epoch 26; iter: 0; batch classifier loss: 0.106281; batch adversarial loss: 0.405736\n",
      "epoch 27; iter: 0; batch classifier loss: 0.144046; batch adversarial loss: 0.553289\n",
      "epoch 28; iter: 0; batch classifier loss: 0.095990; batch adversarial loss: 0.473356\n",
      "epoch 29; iter: 0; batch classifier loss: 0.192818; batch adversarial loss: 0.585859\n",
      "epoch 30; iter: 0; batch classifier loss: 0.199203; batch adversarial loss: 0.562755\n",
      "epoch 31; iter: 0; batch classifier loss: 0.163108; batch adversarial loss: 0.589729\n",
      "epoch 32; iter: 0; batch classifier loss: 0.100537; batch adversarial loss: 0.436432\n",
      "epoch 33; iter: 0; batch classifier loss: 0.173258; batch adversarial loss: 0.560055\n",
      "epoch 34; iter: 0; batch classifier loss: 0.118321; batch adversarial loss: 0.537700\n",
      "epoch 35; iter: 0; batch classifier loss: 0.209850; batch adversarial loss: 0.580518\n",
      "epoch 36; iter: 0; batch classifier loss: 0.193662; batch adversarial loss: 0.544559\n",
      "epoch 37; iter: 0; batch classifier loss: 0.147548; batch adversarial loss: 0.469908\n",
      "epoch 38; iter: 0; batch classifier loss: 0.189657; batch adversarial loss: 0.500705\n",
      "epoch 39; iter: 0; batch classifier loss: 0.165558; batch adversarial loss: 0.529832\n",
      "epoch 40; iter: 0; batch classifier loss: 0.174047; batch adversarial loss: 0.546278\n",
      "epoch 41; iter: 0; batch classifier loss: 0.150188; batch adversarial loss: 0.480621\n",
      "epoch 42; iter: 0; batch classifier loss: 0.209183; batch adversarial loss: 0.512243\n",
      "epoch 43; iter: 0; batch classifier loss: 0.174798; batch adversarial loss: 0.514558\n",
      "epoch 44; iter: 0; batch classifier loss: 0.181466; batch adversarial loss: 0.529072\n",
      "epoch 45; iter: 0; batch classifier loss: 0.141103; batch adversarial loss: 0.431662\n",
      "epoch 46; iter: 0; batch classifier loss: 0.228684; batch adversarial loss: 0.576878\n",
      "epoch 47; iter: 0; batch classifier loss: 0.129832; batch adversarial loss: 0.397534\n",
      "epoch 48; iter: 0; batch classifier loss: 0.113067; batch adversarial loss: 0.462721\n",
      "epoch 49; iter: 0; batch classifier loss: 0.049490; batch adversarial loss: 0.454141\n",
      "epoch 50; iter: 0; batch classifier loss: 0.078015; batch adversarial loss: 0.492549\n",
      "epoch 51; iter: 0; batch classifier loss: 0.069390; batch adversarial loss: 0.554648\n",
      "epoch 52; iter: 0; batch classifier loss: 0.073072; batch adversarial loss: 0.549422\n",
      "epoch 53; iter: 0; batch classifier loss: 0.068496; batch adversarial loss: 0.440934\n",
      "epoch 54; iter: 0; batch classifier loss: 0.056697; batch adversarial loss: 0.436455\n",
      "epoch 55; iter: 0; batch classifier loss: 0.058698; batch adversarial loss: 0.460487\n",
      "epoch 56; iter: 0; batch classifier loss: 0.068160; batch adversarial loss: 0.432469\n",
      "epoch 57; iter: 0; batch classifier loss: 0.060890; batch adversarial loss: 0.503301\n",
      "epoch 58; iter: 0; batch classifier loss: 0.066528; batch adversarial loss: 0.469114\n",
      "epoch 59; iter: 0; batch classifier loss: 0.117630; batch adversarial loss: 0.505305\n",
      "epoch 60; iter: 0; batch classifier loss: 0.048740; batch adversarial loss: 0.440022\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090930; batch adversarial loss: 0.453385\n",
      "epoch 62; iter: 0; batch classifier loss: 0.073576; batch adversarial loss: 0.505050\n",
      "epoch 63; iter: 0; batch classifier loss: 0.066811; batch adversarial loss: 0.476798\n",
      "epoch 64; iter: 0; batch classifier loss: 0.075884; batch adversarial loss: 0.415265\n",
      "epoch 65; iter: 0; batch classifier loss: 0.120769; batch adversarial loss: 0.426851\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086263; batch adversarial loss: 0.431461\n",
      "epoch 67; iter: 0; batch classifier loss: 0.054900; batch adversarial loss: 0.361289\n",
      "epoch 68; iter: 0; batch classifier loss: 0.030346; batch adversarial loss: 0.446684\n",
      "epoch 69; iter: 0; batch classifier loss: 0.051593; batch adversarial loss: 0.448263\n",
      "epoch 70; iter: 0; batch classifier loss: 0.061346; batch adversarial loss: 0.484834\n",
      "epoch 71; iter: 0; batch classifier loss: 0.085969; batch adversarial loss: 0.440835\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064034; batch adversarial loss: 0.374137\n",
      "epoch 73; iter: 0; batch classifier loss: 0.073443; batch adversarial loss: 0.370775\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076796; batch adversarial loss: 0.485121\n",
      "epoch 75; iter: 0; batch classifier loss: 0.058581; batch adversarial loss: 0.461838\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060356; batch adversarial loss: 0.502940\n",
      "epoch 77; iter: 0; batch classifier loss: 0.039556; batch adversarial loss: 0.554137\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085815; batch adversarial loss: 0.427430\n",
      "epoch 79; iter: 0; batch classifier loss: 0.025245; batch adversarial loss: 0.507601\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078292; batch adversarial loss: 0.496333\n",
      "epoch 81; iter: 0; batch classifier loss: 0.061548; batch adversarial loss: 0.462244\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090969; batch adversarial loss: 0.501987\n",
      "epoch 83; iter: 0; batch classifier loss: 0.069192; batch adversarial loss: 0.554348\n",
      "epoch 84; iter: 0; batch classifier loss: 0.077431; batch adversarial loss: 0.557353\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059032; batch adversarial loss: 0.481670\n",
      "epoch 86; iter: 0; batch classifier loss: 0.030203; batch adversarial loss: 0.475720\n",
      "epoch 87; iter: 0; batch classifier loss: 0.052930; batch adversarial loss: 0.477949\n",
      "epoch 88; iter: 0; batch classifier loss: 0.079820; batch adversarial loss: 0.436195\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050850; batch adversarial loss: 0.513966\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053676; batch adversarial loss: 0.543456\n",
      "epoch 91; iter: 0; batch classifier loss: 0.042405; batch adversarial loss: 0.424522\n",
      "epoch 92; iter: 0; batch classifier loss: 0.049304; batch adversarial loss: 0.481524\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041668; batch adversarial loss: 0.482446\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053451; batch adversarial loss: 0.477625\n",
      "epoch 95; iter: 0; batch classifier loss: 0.030946; batch adversarial loss: 0.499668\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066656; batch adversarial loss: 0.477192\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059479; batch adversarial loss: 0.447112\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048637; batch adversarial loss: 0.412379\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062324; batch adversarial loss: 0.406018\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057681; batch adversarial loss: 0.483602\n",
      "epoch 101; iter: 0; batch classifier loss: 0.098967; batch adversarial loss: 0.540077\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051786; batch adversarial loss: 0.480389\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053978; batch adversarial loss: 0.551494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.039070; batch adversarial loss: 0.404656\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057422; batch adversarial loss: 0.432138\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044615; batch adversarial loss: 0.423250\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066115; batch adversarial loss: 0.427812\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042902; batch adversarial loss: 0.428319\n",
      "epoch 109; iter: 0; batch classifier loss: 0.023799; batch adversarial loss: 0.542779\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023339; batch adversarial loss: 0.429796\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047003; batch adversarial loss: 0.488366\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031028; batch adversarial loss: 0.399022\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052543; batch adversarial loss: 0.391037\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028895; batch adversarial loss: 0.469321\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044885; batch adversarial loss: 0.488180\n",
      "epoch 116; iter: 0; batch classifier loss: 0.059356; batch adversarial loss: 0.504138\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034299; batch adversarial loss: 0.565401\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031338; batch adversarial loss: 0.477847\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065255; batch adversarial loss: 0.444766\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046524; batch adversarial loss: 0.457657\n",
      "epoch 121; iter: 0; batch classifier loss: 0.079289; batch adversarial loss: 0.469874\n",
      "epoch 122; iter: 0; batch classifier loss: 0.103660; batch adversarial loss: 0.471605\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043526; batch adversarial loss: 0.450836\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019128; batch adversarial loss: 0.509559\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046578; batch adversarial loss: 0.443235\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032428; batch adversarial loss: 0.496024\n",
      "epoch 127; iter: 0; batch classifier loss: 0.015911; batch adversarial loss: 0.552617\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058626; batch adversarial loss: 0.434202\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035492; batch adversarial loss: 0.497090\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056469; batch adversarial loss: 0.371315\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029289; batch adversarial loss: 0.485330\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030481; batch adversarial loss: 0.461626\n",
      "epoch 133; iter: 0; batch classifier loss: 0.058622; batch adversarial loss: 0.479802\n",
      "epoch 134; iter: 0; batch classifier loss: 0.022535; batch adversarial loss: 0.506541\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057415; batch adversarial loss: 0.356969\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026639; batch adversarial loss: 0.480371\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043031; batch adversarial loss: 0.419815\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031080; batch adversarial loss: 0.458048\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032161; batch adversarial loss: 0.536344\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023469; batch adversarial loss: 0.449457\n",
      "epoch 141; iter: 0; batch classifier loss: 0.068084; batch adversarial loss: 0.412385\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044819; batch adversarial loss: 0.457231\n",
      "epoch 143; iter: 0; batch classifier loss: 0.010391; batch adversarial loss: 0.425979\n",
      "epoch 144; iter: 0; batch classifier loss: 0.010143; batch adversarial loss: 0.441579\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030448; batch adversarial loss: 0.411200\n",
      "epoch 146; iter: 0; batch classifier loss: 0.070663; batch adversarial loss: 0.459657\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034927; batch adversarial loss: 0.425838\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029704; batch adversarial loss: 0.456105\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040978; batch adversarial loss: 0.393110\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033720; batch adversarial loss: 0.506834\n",
      "epoch 151; iter: 0; batch classifier loss: 0.058775; batch adversarial loss: 0.418078\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018650; batch adversarial loss: 0.507211\n",
      "epoch 153; iter: 0; batch classifier loss: 0.048523; batch adversarial loss: 0.398220\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014960; batch adversarial loss: 0.488048\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020214; batch adversarial loss: 0.467937\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033540; batch adversarial loss: 0.506631\n",
      "epoch 157; iter: 0; batch classifier loss: 0.057150; batch adversarial loss: 0.516464\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024398; batch adversarial loss: 0.453529\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032259; batch adversarial loss: 0.404997\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012066; batch adversarial loss: 0.483295\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018659; batch adversarial loss: 0.432295\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030542; batch adversarial loss: 0.439952\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028130; batch adversarial loss: 0.434955\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025236; batch adversarial loss: 0.425184\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014293; batch adversarial loss: 0.506314\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012888; batch adversarial loss: 0.551487\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041015; batch adversarial loss: 0.429716\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014639; batch adversarial loss: 0.486240\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019184; batch adversarial loss: 0.390964\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034238; batch adversarial loss: 0.419025\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040986; batch adversarial loss: 0.559588\n",
      "epoch 172; iter: 0; batch classifier loss: 0.049857; batch adversarial loss: 0.508223\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025863; batch adversarial loss: 0.410123\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021861; batch adversarial loss: 0.506087\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034342; batch adversarial loss: 0.435132\n",
      "epoch 176; iter: 0; batch classifier loss: 0.039066; batch adversarial loss: 0.485470\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022310; batch adversarial loss: 0.448166\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022538; batch adversarial loss: 0.501417\n",
      "epoch 179; iter: 0; batch classifier loss: 0.042570; batch adversarial loss: 0.575156\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031000; batch adversarial loss: 0.322319\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015486; batch adversarial loss: 0.379739\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010308; batch adversarial loss: 0.500523\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016547; batch adversarial loss: 0.519256\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021291; batch adversarial loss: 0.434621\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006573; batch adversarial loss: 0.494526\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027474; batch adversarial loss: 0.415792\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039023; batch adversarial loss: 0.382531\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011349; batch adversarial loss: 0.462119\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010730; batch adversarial loss: 0.431262\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012801; batch adversarial loss: 0.433918\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017056; batch adversarial loss: 0.448245\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013666; batch adversarial loss: 0.436005\n",
      "epoch 193; iter: 0; batch classifier loss: 0.047775; batch adversarial loss: 0.433768\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026334; batch adversarial loss: 0.466640\n",
      "epoch 195; iter: 0; batch classifier loss: 0.001452; batch adversarial loss: 0.478439\n",
      "epoch 196; iter: 0; batch classifier loss: 0.050839; batch adversarial loss: 0.432351\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007575; batch adversarial loss: 0.489551\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006487; batch adversarial loss: 0.434891\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016412; batch adversarial loss: 0.497980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.702045; batch adversarial loss: 0.492337\n",
      "epoch 1; iter: 0; batch classifier loss: 0.479214; batch adversarial loss: 0.558078\n",
      "epoch 2; iter: 0; batch classifier loss: 0.363273; batch adversarial loss: 0.584187\n",
      "epoch 3; iter: 0; batch classifier loss: 0.331120; batch adversarial loss: 0.639887\n",
      "epoch 4; iter: 0; batch classifier loss: 0.345045; batch adversarial loss: 0.537596\n",
      "epoch 5; iter: 0; batch classifier loss: 0.347765; batch adversarial loss: 0.524506\n",
      "epoch 6; iter: 0; batch classifier loss: 0.337947; batch adversarial loss: 0.611149\n",
      "epoch 7; iter: 0; batch classifier loss: 0.320670; batch adversarial loss: 0.522259\n",
      "epoch 8; iter: 0; batch classifier loss: 0.283537; batch adversarial loss: 0.562891\n",
      "epoch 9; iter: 0; batch classifier loss: 0.335115; batch adversarial loss: 0.531297\n",
      "epoch 10; iter: 0; batch classifier loss: 0.351645; batch adversarial loss: 0.539217\n",
      "epoch 11; iter: 0; batch classifier loss: 0.275702; batch adversarial loss: 0.536620\n",
      "epoch 12; iter: 0; batch classifier loss: 0.411863; batch adversarial loss: 0.565387\n",
      "epoch 13; iter: 0; batch classifier loss: 0.320076; batch adversarial loss: 0.450205\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481230; batch adversarial loss: 0.584281\n",
      "epoch 15; iter: 0; batch classifier loss: 0.451496; batch adversarial loss: 0.470017\n",
      "epoch 16; iter: 0; batch classifier loss: 0.394690; batch adversarial loss: 0.529408\n",
      "epoch 17; iter: 0; batch classifier loss: 0.283532; batch adversarial loss: 0.505551\n",
      "epoch 18; iter: 0; batch classifier loss: 0.259338; batch adversarial loss: 0.429073\n",
      "epoch 19; iter: 0; batch classifier loss: 0.203292; batch adversarial loss: 0.453288\n",
      "epoch 20; iter: 0; batch classifier loss: 0.293883; batch adversarial loss: 0.454683\n",
      "epoch 21; iter: 0; batch classifier loss: 0.163650; batch adversarial loss: 0.570242\n",
      "epoch 22; iter: 0; batch classifier loss: 0.152800; batch adversarial loss: 0.444607\n",
      "epoch 23; iter: 0; batch classifier loss: 0.111146; batch adversarial loss: 0.500157\n",
      "epoch 24; iter: 0; batch classifier loss: 0.123715; batch adversarial loss: 0.425867\n",
      "epoch 25; iter: 0; batch classifier loss: 0.154612; batch adversarial loss: 0.502158\n",
      "epoch 26; iter: 0; batch classifier loss: 0.099693; batch adversarial loss: 0.488849\n",
      "epoch 27; iter: 0; batch classifier loss: 0.136882; batch adversarial loss: 0.480162\n",
      "epoch 28; iter: 0; batch classifier loss: 0.119924; batch adversarial loss: 0.375795\n",
      "epoch 29; iter: 0; batch classifier loss: 0.129345; batch adversarial loss: 0.488808\n",
      "epoch 30; iter: 0; batch classifier loss: 0.130840; batch adversarial loss: 0.474998\n",
      "epoch 31; iter: 0; batch classifier loss: 0.095601; batch adversarial loss: 0.453943\n",
      "epoch 32; iter: 0; batch classifier loss: 0.096225; batch adversarial loss: 0.432893\n",
      "epoch 33; iter: 0; batch classifier loss: 0.127108; batch adversarial loss: 0.390795\n",
      "epoch 34; iter: 0; batch classifier loss: 0.108571; batch adversarial loss: 0.376933\n",
      "epoch 35; iter: 0; batch classifier loss: 0.117118; batch adversarial loss: 0.389545\n",
      "epoch 36; iter: 0; batch classifier loss: 0.160000; batch adversarial loss: 0.427803\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111846; batch adversarial loss: 0.479959\n",
      "epoch 38; iter: 0; batch classifier loss: 0.109771; batch adversarial loss: 0.470754\n",
      "epoch 39; iter: 0; batch classifier loss: 0.114308; batch adversarial loss: 0.474204\n",
      "epoch 40; iter: 0; batch classifier loss: 0.128780; batch adversarial loss: 0.351374\n",
      "epoch 41; iter: 0; batch classifier loss: 0.161190; batch adversarial loss: 0.386562\n",
      "epoch 42; iter: 0; batch classifier loss: 0.087073; batch adversarial loss: 0.464731\n",
      "epoch 43; iter: 0; batch classifier loss: 0.078624; batch adversarial loss: 0.414211\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124814; batch adversarial loss: 0.523906\n",
      "epoch 45; iter: 0; batch classifier loss: 0.072422; batch adversarial loss: 0.431528\n",
      "epoch 46; iter: 0; batch classifier loss: 0.058964; batch adversarial loss: 0.489508\n",
      "epoch 47; iter: 0; batch classifier loss: 0.073094; batch adversarial loss: 0.470441\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081796; batch adversarial loss: 0.398882\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098910; batch adversarial loss: 0.528591\n",
      "epoch 50; iter: 0; batch classifier loss: 0.050370; batch adversarial loss: 0.498220\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083093; batch adversarial loss: 0.459804\n",
      "epoch 52; iter: 0; batch classifier loss: 0.102530; batch adversarial loss: 0.417069\n",
      "epoch 53; iter: 0; batch classifier loss: 0.075600; batch adversarial loss: 0.424822\n",
      "epoch 54; iter: 0; batch classifier loss: 0.136181; batch adversarial loss: 0.445793\n",
      "epoch 55; iter: 0; batch classifier loss: 0.101942; batch adversarial loss: 0.530933\n",
      "epoch 56; iter: 0; batch classifier loss: 0.122673; batch adversarial loss: 0.386204\n",
      "epoch 57; iter: 0; batch classifier loss: 0.063783; batch adversarial loss: 0.549469\n",
      "epoch 58; iter: 0; batch classifier loss: 0.071959; batch adversarial loss: 0.347766\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072738; batch adversarial loss: 0.457348\n",
      "epoch 60; iter: 0; batch classifier loss: 0.051314; batch adversarial loss: 0.476159\n",
      "epoch 61; iter: 0; batch classifier loss: 0.043884; batch adversarial loss: 0.423573\n",
      "epoch 62; iter: 0; batch classifier loss: 0.047202; batch adversarial loss: 0.477261\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070155; batch adversarial loss: 0.471073\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073361; batch adversarial loss: 0.468975\n",
      "epoch 65; iter: 0; batch classifier loss: 0.160092; batch adversarial loss: 0.434831\n",
      "epoch 66; iter: 0; batch classifier loss: 0.058175; batch adversarial loss: 0.454787\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096600; batch adversarial loss: 0.400609\n",
      "epoch 68; iter: 0; batch classifier loss: 0.073587; batch adversarial loss: 0.450871\n",
      "epoch 69; iter: 0; batch classifier loss: 0.049825; batch adversarial loss: 0.455315\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065957; batch adversarial loss: 0.510162\n",
      "epoch 71; iter: 0; batch classifier loss: 0.109084; batch adversarial loss: 0.446476\n",
      "epoch 72; iter: 0; batch classifier loss: 0.051599; batch adversarial loss: 0.456989\n",
      "epoch 73; iter: 0; batch classifier loss: 0.060076; batch adversarial loss: 0.478252\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075585; batch adversarial loss: 0.495823\n",
      "epoch 75; iter: 0; batch classifier loss: 0.047257; batch adversarial loss: 0.547615\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070205; batch adversarial loss: 0.419785\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045633; batch adversarial loss: 0.361311\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074376; batch adversarial loss: 0.472882\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053695; batch adversarial loss: 0.466148\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068046; batch adversarial loss: 0.488282\n",
      "epoch 81; iter: 0; batch classifier loss: 0.099705; batch adversarial loss: 0.488471\n",
      "epoch 82; iter: 0; batch classifier loss: 0.092935; batch adversarial loss: 0.547045\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063579; batch adversarial loss: 0.501497\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085974; batch adversarial loss: 0.509210\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065232; batch adversarial loss: 0.388469\n",
      "epoch 86; iter: 0; batch classifier loss: 0.034582; batch adversarial loss: 0.463525\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073826; batch adversarial loss: 0.457319\n",
      "epoch 88; iter: 0; batch classifier loss: 0.038539; batch adversarial loss: 0.454477\n",
      "epoch 89; iter: 0; batch classifier loss: 0.033784; batch adversarial loss: 0.397549\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051525; batch adversarial loss: 0.432631\n",
      "epoch 91; iter: 0; batch classifier loss: 0.049602; batch adversarial loss: 0.482592\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055108; batch adversarial loss: 0.409436\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044325; batch adversarial loss: 0.437041\n",
      "epoch 94; iter: 0; batch classifier loss: 0.031263; batch adversarial loss: 0.530528\n",
      "epoch 95; iter: 0; batch classifier loss: 0.090167; batch adversarial loss: 0.551137\n",
      "epoch 96; iter: 0; batch classifier loss: 0.076644; batch adversarial loss: 0.454781\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052565; batch adversarial loss: 0.354989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.055785; batch adversarial loss: 0.452058\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057593; batch adversarial loss: 0.444720\n",
      "epoch 100; iter: 0; batch classifier loss: 0.058980; batch adversarial loss: 0.478552\n",
      "epoch 101; iter: 0; batch classifier loss: 0.064862; batch adversarial loss: 0.385283\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050545; batch adversarial loss: 0.493616\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054223; batch adversarial loss: 0.501836\n",
      "epoch 104; iter: 0; batch classifier loss: 0.032803; batch adversarial loss: 0.508048\n",
      "epoch 105; iter: 0; batch classifier loss: 0.068818; batch adversarial loss: 0.495034\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049322; batch adversarial loss: 0.472425\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052185; batch adversarial loss: 0.489144\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056407; batch adversarial loss: 0.579300\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038729; batch adversarial loss: 0.529861\n",
      "epoch 110; iter: 0; batch classifier loss: 0.024122; batch adversarial loss: 0.472943\n",
      "epoch 111; iter: 0; batch classifier loss: 0.120392; batch adversarial loss: 0.455111\n",
      "epoch 112; iter: 0; batch classifier loss: 0.032867; batch adversarial loss: 0.479568\n",
      "epoch 113; iter: 0; batch classifier loss: 0.026139; batch adversarial loss: 0.571147\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028258; batch adversarial loss: 0.544305\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031336; batch adversarial loss: 0.491168\n",
      "epoch 116; iter: 0; batch classifier loss: 0.063953; batch adversarial loss: 0.400373\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043901; batch adversarial loss: 0.475988\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041968; batch adversarial loss: 0.422413\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044869; batch adversarial loss: 0.424136\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039940; batch adversarial loss: 0.460992\n",
      "epoch 121; iter: 0; batch classifier loss: 0.065198; batch adversarial loss: 0.498604\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046470; batch adversarial loss: 0.429109\n",
      "epoch 123; iter: 0; batch classifier loss: 0.058147; batch adversarial loss: 0.511004\n",
      "epoch 124; iter: 0; batch classifier loss: 0.045181; batch adversarial loss: 0.486654\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041759; batch adversarial loss: 0.450406\n",
      "epoch 126; iter: 0; batch classifier loss: 0.049558; batch adversarial loss: 0.493188\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032863; batch adversarial loss: 0.472701\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023528; batch adversarial loss: 0.635598\n",
      "epoch 129; iter: 0; batch classifier loss: 0.074240; batch adversarial loss: 0.420507\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030088; batch adversarial loss: 0.506770\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052244; batch adversarial loss: 0.453753\n",
      "epoch 132; iter: 0; batch classifier loss: 0.062923; batch adversarial loss: 0.467300\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027966; batch adversarial loss: 0.475710\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027367; batch adversarial loss: 0.405635\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014016; batch adversarial loss: 0.465456\n",
      "epoch 136; iter: 0; batch classifier loss: 0.063763; batch adversarial loss: 0.436181\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018538; batch adversarial loss: 0.504265\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031473; batch adversarial loss: 0.373066\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030806; batch adversarial loss: 0.374945\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027746; batch adversarial loss: 0.493036\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027053; batch adversarial loss: 0.455384\n",
      "epoch 142; iter: 0; batch classifier loss: 0.038356; batch adversarial loss: 0.435203\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033075; batch adversarial loss: 0.502848\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031368; batch adversarial loss: 0.358036\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027522; batch adversarial loss: 0.374490\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037325; batch adversarial loss: 0.462213\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026238; batch adversarial loss: 0.483058\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018002; batch adversarial loss: 0.458315\n",
      "epoch 149; iter: 0; batch classifier loss: 0.069221; batch adversarial loss: 0.525414\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023468; batch adversarial loss: 0.468615\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012998; batch adversarial loss: 0.437413\n",
      "epoch 152; iter: 0; batch classifier loss: 0.050727; batch adversarial loss: 0.480244\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017069; batch adversarial loss: 0.421539\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018103; batch adversarial loss: 0.478374\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013243; batch adversarial loss: 0.481748\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019014; batch adversarial loss: 0.435893\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014489; batch adversarial loss: 0.521559\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019790; batch adversarial loss: 0.505964\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033234; batch adversarial loss: 0.470288\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035015; batch adversarial loss: 0.437991\n",
      "epoch 161; iter: 0; batch classifier loss: 0.054301; batch adversarial loss: 0.489679\n",
      "epoch 162; iter: 0; batch classifier loss: 0.056295; batch adversarial loss: 0.449410\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018335; batch adversarial loss: 0.358516\n",
      "epoch 164; iter: 0; batch classifier loss: 0.060448; batch adversarial loss: 0.415797\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025982; batch adversarial loss: 0.396416\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033438; batch adversarial loss: 0.437668\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021947; batch adversarial loss: 0.457247\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031444; batch adversarial loss: 0.498716\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023243; batch adversarial loss: 0.442318\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027844; batch adversarial loss: 0.487632\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026194; batch adversarial loss: 0.428964\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020898; batch adversarial loss: 0.604843\n",
      "epoch 173; iter: 0; batch classifier loss: 0.005409; batch adversarial loss: 0.459222\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019169; batch adversarial loss: 0.492474\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021963; batch adversarial loss: 0.454052\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010702; batch adversarial loss: 0.468175\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027180; batch adversarial loss: 0.481251\n",
      "epoch 178; iter: 0; batch classifier loss: 0.072037; batch adversarial loss: 0.441248\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013732; batch adversarial loss: 0.443357\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037366; batch adversarial loss: 0.456727\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018217; batch adversarial loss: 0.490639\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022318; batch adversarial loss: 0.478052\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032244; batch adversarial loss: 0.447686\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026193; batch adversarial loss: 0.517289\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038272; batch adversarial loss: 0.390348\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021277; batch adversarial loss: 0.372874\n",
      "epoch 187; iter: 0; batch classifier loss: 0.037090; batch adversarial loss: 0.468336\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020904; batch adversarial loss: 0.422409\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022856; batch adversarial loss: 0.361823\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015578; batch adversarial loss: 0.454221\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019079; batch adversarial loss: 0.426160\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030827; batch adversarial loss: 0.508981\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031873; batch adversarial loss: 0.494845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.017942; batch adversarial loss: 0.476820\n",
      "epoch 195; iter: 0; batch classifier loss: 0.038239; batch adversarial loss: 0.468250\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020160; batch adversarial loss: 0.514004\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004739; batch adversarial loss: 0.521293\n",
      "epoch 198; iter: 0; batch classifier loss: 0.042825; batch adversarial loss: 0.444264\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024143; batch adversarial loss: 0.484272\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675600; batch adversarial loss: 0.519022\n",
      "epoch 1; iter: 0; batch classifier loss: 0.386161; batch adversarial loss: 0.587856\n",
      "epoch 2; iter: 0; batch classifier loss: 0.384265; batch adversarial loss: 0.638218\n",
      "epoch 3; iter: 0; batch classifier loss: 0.414779; batch adversarial loss: 0.595871\n",
      "epoch 4; iter: 0; batch classifier loss: 0.336034; batch adversarial loss: 0.595031\n",
      "epoch 5; iter: 0; batch classifier loss: 0.355552; batch adversarial loss: 0.566386\n",
      "epoch 6; iter: 0; batch classifier loss: 0.307090; batch adversarial loss: 0.603218\n",
      "epoch 7; iter: 0; batch classifier loss: 0.311195; batch adversarial loss: 0.547768\n",
      "epoch 8; iter: 0; batch classifier loss: 0.385027; batch adversarial loss: 0.552532\n",
      "epoch 9; iter: 0; batch classifier loss: 0.390967; batch adversarial loss: 0.594676\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485150; batch adversarial loss: 0.548889\n",
      "epoch 11; iter: 0; batch classifier loss: 0.506940; batch adversarial loss: 0.623981\n",
      "epoch 12; iter: 0; batch classifier loss: 0.461764; batch adversarial loss: 0.608980\n",
      "epoch 13; iter: 0; batch classifier loss: 0.592855; batch adversarial loss: 0.517770\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512820; batch adversarial loss: 0.459645\n",
      "epoch 15; iter: 0; batch classifier loss: 0.380914; batch adversarial loss: 0.494335\n",
      "epoch 16; iter: 0; batch classifier loss: 0.317036; batch adversarial loss: 0.400566\n",
      "epoch 17; iter: 0; batch classifier loss: 0.275565; batch adversarial loss: 0.499449\n",
      "epoch 18; iter: 0; batch classifier loss: 0.182490; batch adversarial loss: 0.511090\n",
      "epoch 19; iter: 0; batch classifier loss: 0.162953; batch adversarial loss: 0.506774\n",
      "epoch 20; iter: 0; batch classifier loss: 0.205256; batch adversarial loss: 0.495330\n",
      "epoch 21; iter: 0; batch classifier loss: 0.178111; batch adversarial loss: 0.405239\n",
      "epoch 22; iter: 0; batch classifier loss: 0.195726; batch adversarial loss: 0.475981\n",
      "epoch 23; iter: 0; batch classifier loss: 0.191991; batch adversarial loss: 0.441015\n",
      "epoch 24; iter: 0; batch classifier loss: 0.202177; batch adversarial loss: 0.547233\n",
      "epoch 25; iter: 0; batch classifier loss: 0.168648; batch adversarial loss: 0.514088\n",
      "epoch 26; iter: 0; batch classifier loss: 0.140202; batch adversarial loss: 0.484367\n",
      "epoch 27; iter: 0; batch classifier loss: 0.144511; batch adversarial loss: 0.499771\n",
      "epoch 28; iter: 0; batch classifier loss: 0.178385; batch adversarial loss: 0.550412\n",
      "epoch 29; iter: 0; batch classifier loss: 0.151687; batch adversarial loss: 0.372479\n",
      "epoch 30; iter: 0; batch classifier loss: 0.129601; batch adversarial loss: 0.489124\n",
      "epoch 31; iter: 0; batch classifier loss: 0.142524; batch adversarial loss: 0.548114\n",
      "epoch 32; iter: 0; batch classifier loss: 0.161541; batch adversarial loss: 0.490038\n",
      "epoch 33; iter: 0; batch classifier loss: 0.117211; batch adversarial loss: 0.366718\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148350; batch adversarial loss: 0.425156\n",
      "epoch 35; iter: 0; batch classifier loss: 0.158656; batch adversarial loss: 0.520973\n",
      "epoch 36; iter: 0; batch classifier loss: 0.242129; batch adversarial loss: 0.419362\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113549; batch adversarial loss: 0.432985\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126811; batch adversarial loss: 0.439840\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132250; batch adversarial loss: 0.478823\n",
      "epoch 40; iter: 0; batch classifier loss: 0.135817; batch adversarial loss: 0.557648\n",
      "epoch 41; iter: 0; batch classifier loss: 0.112789; batch adversarial loss: 0.545781\n",
      "epoch 42; iter: 0; batch classifier loss: 0.084292; batch adversarial loss: 0.509731\n",
      "epoch 43; iter: 0; batch classifier loss: 0.149498; batch adversarial loss: 0.469956\n",
      "epoch 44; iter: 0; batch classifier loss: 0.074712; batch adversarial loss: 0.481414\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108839; batch adversarial loss: 0.419012\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126428; batch adversarial loss: 0.492705\n",
      "epoch 47; iter: 0; batch classifier loss: 0.101969; batch adversarial loss: 0.422467\n",
      "epoch 48; iter: 0; batch classifier loss: 0.109634; batch adversarial loss: 0.372595\n",
      "epoch 49; iter: 0; batch classifier loss: 0.139019; batch adversarial loss: 0.543136\n",
      "epoch 50; iter: 0; batch classifier loss: 0.115584; batch adversarial loss: 0.488181\n",
      "epoch 51; iter: 0; batch classifier loss: 0.159877; batch adversarial loss: 0.470543\n",
      "epoch 52; iter: 0; batch classifier loss: 0.130187; batch adversarial loss: 0.387761\n",
      "epoch 53; iter: 0; batch classifier loss: 0.104963; batch adversarial loss: 0.494019\n",
      "epoch 54; iter: 0; batch classifier loss: 0.105646; batch adversarial loss: 0.493740\n",
      "epoch 55; iter: 0; batch classifier loss: 0.100071; batch adversarial loss: 0.383380\n",
      "epoch 56; iter: 0; batch classifier loss: 0.080723; batch adversarial loss: 0.457443\n",
      "epoch 57; iter: 0; batch classifier loss: 0.131735; batch adversarial loss: 0.398189\n",
      "epoch 58; iter: 0; batch classifier loss: 0.089029; batch adversarial loss: 0.445737\n",
      "epoch 59; iter: 0; batch classifier loss: 0.091092; batch adversarial loss: 0.470707\n",
      "epoch 60; iter: 0; batch classifier loss: 0.096239; batch adversarial loss: 0.406828\n",
      "epoch 61; iter: 0; batch classifier loss: 0.092679; batch adversarial loss: 0.403157\n",
      "epoch 62; iter: 0; batch classifier loss: 0.109739; batch adversarial loss: 0.432087\n",
      "epoch 63; iter: 0; batch classifier loss: 0.118357; batch adversarial loss: 0.479364\n",
      "epoch 64; iter: 0; batch classifier loss: 0.135901; batch adversarial loss: 0.441029\n",
      "epoch 65; iter: 0; batch classifier loss: 0.152351; batch adversarial loss: 0.471100\n",
      "epoch 66; iter: 0; batch classifier loss: 0.108759; batch adversarial loss: 0.502319\n",
      "epoch 67; iter: 0; batch classifier loss: 0.072977; batch adversarial loss: 0.527883\n",
      "epoch 68; iter: 0; batch classifier loss: 0.106523; batch adversarial loss: 0.447187\n",
      "epoch 69; iter: 0; batch classifier loss: 0.123582; batch adversarial loss: 0.424286\n",
      "epoch 70; iter: 0; batch classifier loss: 0.142785; batch adversarial loss: 0.423303\n",
      "epoch 71; iter: 0; batch classifier loss: 0.135163; batch adversarial loss: 0.515335\n",
      "epoch 72; iter: 0; batch classifier loss: 0.113298; batch adversarial loss: 0.474868\n",
      "epoch 73; iter: 0; batch classifier loss: 0.099946; batch adversarial loss: 0.428883\n",
      "epoch 74; iter: 0; batch classifier loss: 0.149155; batch adversarial loss: 0.539232\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073513; batch adversarial loss: 0.504398\n",
      "epoch 76; iter: 0; batch classifier loss: 0.133649; batch adversarial loss: 0.318723\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102755; batch adversarial loss: 0.549649\n",
      "epoch 78; iter: 0; batch classifier loss: 0.093610; batch adversarial loss: 0.526187\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080741; batch adversarial loss: 0.497051\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067584; batch adversarial loss: 0.459206\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120427; batch adversarial loss: 0.468418\n",
      "epoch 82; iter: 0; batch classifier loss: 0.100442; batch adversarial loss: 0.414921\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085620; batch adversarial loss: 0.447176\n",
      "epoch 84; iter: 0; batch classifier loss: 0.148781; batch adversarial loss: 0.379410\n",
      "epoch 85; iter: 0; batch classifier loss: 0.128375; batch adversarial loss: 0.508760\n",
      "epoch 86; iter: 0; batch classifier loss: 0.124344; batch adversarial loss: 0.499204\n",
      "epoch 87; iter: 0; batch classifier loss: 0.086788; batch adversarial loss: 0.504192\n",
      "epoch 88; iter: 0; batch classifier loss: 0.102936; batch adversarial loss: 0.387968\n",
      "epoch 89; iter: 0; batch classifier loss: 0.109443; batch adversarial loss: 0.415839\n",
      "epoch 90; iter: 0; batch classifier loss: 0.092409; batch adversarial loss: 0.354813\n",
      "epoch 91; iter: 0; batch classifier loss: 0.107776; batch adversarial loss: 0.397846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.088334; batch adversarial loss: 0.416817\n",
      "epoch 93; iter: 0; batch classifier loss: 0.098599; batch adversarial loss: 0.510566\n",
      "epoch 94; iter: 0; batch classifier loss: 0.095595; batch adversarial loss: 0.508989\n",
      "epoch 95; iter: 0; batch classifier loss: 0.094140; batch adversarial loss: 0.484997\n",
      "epoch 96; iter: 0; batch classifier loss: 0.079302; batch adversarial loss: 0.410118\n",
      "epoch 97; iter: 0; batch classifier loss: 0.115722; batch adversarial loss: 0.424487\n",
      "epoch 98; iter: 0; batch classifier loss: 0.086652; batch adversarial loss: 0.436541\n",
      "epoch 99; iter: 0; batch classifier loss: 0.075508; batch adversarial loss: 0.480975\n",
      "epoch 100; iter: 0; batch classifier loss: 0.098344; batch adversarial loss: 0.461865\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049294; batch adversarial loss: 0.519051\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067446; batch adversarial loss: 0.469601\n",
      "epoch 103; iter: 0; batch classifier loss: 0.085238; batch adversarial loss: 0.426393\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083384; batch adversarial loss: 0.443565\n",
      "epoch 105; iter: 0; batch classifier loss: 0.074540; batch adversarial loss: 0.479969\n",
      "epoch 106; iter: 0; batch classifier loss: 0.101564; batch adversarial loss: 0.473196\n",
      "epoch 107; iter: 0; batch classifier loss: 0.089654; batch adversarial loss: 0.418414\n",
      "epoch 108; iter: 0; batch classifier loss: 0.092275; batch adversarial loss: 0.448167\n",
      "epoch 109; iter: 0; batch classifier loss: 0.081706; batch adversarial loss: 0.504380\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039487; batch adversarial loss: 0.433947\n",
      "epoch 111; iter: 0; batch classifier loss: 0.097460; batch adversarial loss: 0.374526\n",
      "epoch 112; iter: 0; batch classifier loss: 0.078229; batch adversarial loss: 0.518438\n",
      "epoch 113; iter: 0; batch classifier loss: 0.072372; batch adversarial loss: 0.461356\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035588; batch adversarial loss: 0.472262\n",
      "epoch 115; iter: 0; batch classifier loss: 0.076005; batch adversarial loss: 0.417403\n",
      "epoch 116; iter: 0; batch classifier loss: 0.083285; batch adversarial loss: 0.502605\n",
      "epoch 117; iter: 0; batch classifier loss: 0.075673; batch adversarial loss: 0.431012\n",
      "epoch 118; iter: 0; batch classifier loss: 0.064934; batch adversarial loss: 0.502984\n",
      "epoch 119; iter: 0; batch classifier loss: 0.123335; batch adversarial loss: 0.410375\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038085; batch adversarial loss: 0.456885\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049678; batch adversarial loss: 0.409028\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050216; batch adversarial loss: 0.473921\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029948; batch adversarial loss: 0.490308\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054215; batch adversarial loss: 0.523181\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044637; batch adversarial loss: 0.453765\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045168; batch adversarial loss: 0.413530\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045871; batch adversarial loss: 0.416382\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045285; batch adversarial loss: 0.480620\n",
      "epoch 129; iter: 0; batch classifier loss: 0.054662; batch adversarial loss: 0.458188\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031506; batch adversarial loss: 0.347313\n",
      "epoch 131; iter: 0; batch classifier loss: 0.076357; batch adversarial loss: 0.371345\n",
      "epoch 132; iter: 0; batch classifier loss: 0.055775; batch adversarial loss: 0.568485\n",
      "epoch 133; iter: 0; batch classifier loss: 0.054629; batch adversarial loss: 0.494730\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038783; batch adversarial loss: 0.355136\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019504; batch adversarial loss: 0.535322\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030322; batch adversarial loss: 0.346081\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026177; batch adversarial loss: 0.445726\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045015; batch adversarial loss: 0.478374\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021256; batch adversarial loss: 0.462151\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028570; batch adversarial loss: 0.394713\n",
      "epoch 141; iter: 0; batch classifier loss: 0.008797; batch adversarial loss: 0.480541\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034427; batch adversarial loss: 0.436122\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039792; batch adversarial loss: 0.374616\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021876; batch adversarial loss: 0.453446\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015081; batch adversarial loss: 0.457268\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017145; batch adversarial loss: 0.418136\n",
      "epoch 147; iter: 0; batch classifier loss: 0.045837; batch adversarial loss: 0.400435\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036334; batch adversarial loss: 0.435121\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024859; batch adversarial loss: 0.487736\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031232; batch adversarial loss: 0.397895\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044190; batch adversarial loss: 0.410723\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036139; batch adversarial loss: 0.570839\n",
      "epoch 153; iter: 0; batch classifier loss: 0.033567; batch adversarial loss: 0.398078\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039156; batch adversarial loss: 0.306810\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040106; batch adversarial loss: 0.477676\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025686; batch adversarial loss: 0.471844\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012445; batch adversarial loss: 0.439372\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035488; batch adversarial loss: 0.371391\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016090; batch adversarial loss: 0.529056\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041448; batch adversarial loss: 0.402055\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036730; batch adversarial loss: 0.407650\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034403; batch adversarial loss: 0.403592\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026181; batch adversarial loss: 0.472167\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035315; batch adversarial loss: 0.400335\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010451; batch adversarial loss: 0.549436\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019143; batch adversarial loss: 0.462646\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019275; batch adversarial loss: 0.448901\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012105; batch adversarial loss: 0.510193\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015433; batch adversarial loss: 0.547511\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025853; batch adversarial loss: 0.428112\n",
      "epoch 171; iter: 0; batch classifier loss: 0.037266; batch adversarial loss: 0.385906\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031491; batch adversarial loss: 0.388559\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026810; batch adversarial loss: 0.502420\n",
      "epoch 174; iter: 0; batch classifier loss: 0.045133; batch adversarial loss: 0.407286\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034097; batch adversarial loss: 0.412239\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015393; batch adversarial loss: 0.442560\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010705; batch adversarial loss: 0.452674\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018421; batch adversarial loss: 0.471690\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025395; batch adversarial loss: 0.544724\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010479; batch adversarial loss: 0.363881\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034326; batch adversarial loss: 0.437619\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013798; batch adversarial loss: 0.476759\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027067; batch adversarial loss: 0.393283\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025596; batch adversarial loss: 0.395934\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009698; batch adversarial loss: 0.526692\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014834; batch adversarial loss: 0.462435\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014642; batch adversarial loss: 0.423276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.014176; batch adversarial loss: 0.434281\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006899; batch adversarial loss: 0.431098\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037061; batch adversarial loss: 0.485957\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006282; batch adversarial loss: 0.467849\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019958; batch adversarial loss: 0.500268\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029478; batch adversarial loss: 0.444439\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025498; batch adversarial loss: 0.472204\n",
      "epoch 195; iter: 0; batch classifier loss: 0.094401; batch adversarial loss: 0.584051\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014456; batch adversarial loss: 0.478322\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009076; batch adversarial loss: 0.432003\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025729; batch adversarial loss: 0.540593\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011953; batch adversarial loss: 0.529020\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708166; batch adversarial loss: 1.151445\n",
      "epoch 1; iter: 0; batch classifier loss: 0.747173; batch adversarial loss: 1.223775\n",
      "epoch 2; iter: 0; batch classifier loss: 0.944812; batch adversarial loss: 1.259320\n",
      "epoch 3; iter: 0; batch classifier loss: 1.188351; batch adversarial loss: 1.175253\n",
      "epoch 4; iter: 0; batch classifier loss: 1.099637; batch adversarial loss: 1.049257\n",
      "epoch 5; iter: 0; batch classifier loss: 0.963131; batch adversarial loss: 0.936322\n",
      "epoch 6; iter: 0; batch classifier loss: 1.114106; batch adversarial loss: 0.862830\n",
      "epoch 7; iter: 0; batch classifier loss: 1.089133; batch adversarial loss: 0.784985\n",
      "epoch 8; iter: 0; batch classifier loss: 1.197161; batch adversarial loss: 0.722084\n",
      "epoch 9; iter: 0; batch classifier loss: 1.185211; batch adversarial loss: 0.703318\n",
      "epoch 10; iter: 0; batch classifier loss: 0.991295; batch adversarial loss: 0.622954\n",
      "epoch 11; iter: 0; batch classifier loss: 1.019424; batch adversarial loss: 0.583091\n",
      "epoch 12; iter: 0; batch classifier loss: 0.758321; batch adversarial loss: 0.544113\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528219; batch adversarial loss: 0.492602\n",
      "epoch 14; iter: 0; batch classifier loss: 0.319097; batch adversarial loss: 0.543672\n",
      "epoch 15; iter: 0; batch classifier loss: 0.280310; batch adversarial loss: 0.483389\n",
      "epoch 16; iter: 0; batch classifier loss: 0.258113; batch adversarial loss: 0.563233\n",
      "epoch 17; iter: 0; batch classifier loss: 0.242202; batch adversarial loss: 0.498792\n",
      "epoch 18; iter: 0; batch classifier loss: 0.191320; batch adversarial loss: 0.509948\n",
      "epoch 19; iter: 0; batch classifier loss: 0.340175; batch adversarial loss: 0.417714\n",
      "epoch 20; iter: 0; batch classifier loss: 0.249333; batch adversarial loss: 0.547638\n",
      "epoch 21; iter: 0; batch classifier loss: 0.208724; batch adversarial loss: 0.494236\n",
      "epoch 22; iter: 0; batch classifier loss: 0.323441; batch adversarial loss: 0.439134\n",
      "epoch 23; iter: 0; batch classifier loss: 0.254911; batch adversarial loss: 0.501388\n",
      "epoch 24; iter: 0; batch classifier loss: 0.226961; batch adversarial loss: 0.429079\n",
      "epoch 25; iter: 0; batch classifier loss: 0.266441; batch adversarial loss: 0.443534\n",
      "epoch 26; iter: 0; batch classifier loss: 0.170722; batch adversarial loss: 0.491220\n",
      "epoch 27; iter: 0; batch classifier loss: 0.174469; batch adversarial loss: 0.506565\n",
      "epoch 28; iter: 0; batch classifier loss: 0.190651; batch adversarial loss: 0.432578\n",
      "epoch 29; iter: 0; batch classifier loss: 0.247123; batch adversarial loss: 0.509091\n",
      "epoch 30; iter: 0; batch classifier loss: 0.220285; batch adversarial loss: 0.455496\n",
      "epoch 31; iter: 0; batch classifier loss: 0.145528; batch adversarial loss: 0.443736\n",
      "epoch 32; iter: 0; batch classifier loss: 0.210682; batch adversarial loss: 0.419955\n",
      "epoch 33; iter: 0; batch classifier loss: 0.186037; batch adversarial loss: 0.480942\n",
      "epoch 34; iter: 0; batch classifier loss: 0.184941; batch adversarial loss: 0.422879\n",
      "epoch 35; iter: 0; batch classifier loss: 0.166869; batch adversarial loss: 0.413615\n",
      "epoch 36; iter: 0; batch classifier loss: 0.244220; batch adversarial loss: 0.448625\n",
      "epoch 37; iter: 0; batch classifier loss: 0.159739; batch adversarial loss: 0.407569\n",
      "epoch 38; iter: 0; batch classifier loss: 0.214969; batch adversarial loss: 0.482491\n",
      "epoch 39; iter: 0; batch classifier loss: 0.281435; batch adversarial loss: 0.405139\n",
      "epoch 40; iter: 0; batch classifier loss: 0.183648; batch adversarial loss: 0.404060\n",
      "epoch 41; iter: 0; batch classifier loss: 0.270779; batch adversarial loss: 0.457407\n",
      "epoch 42; iter: 0; batch classifier loss: 0.174720; batch adversarial loss: 0.523018\n",
      "epoch 43; iter: 0; batch classifier loss: 0.174731; batch adversarial loss: 0.468765\n",
      "epoch 44; iter: 0; batch classifier loss: 0.149061; batch adversarial loss: 0.554978\n",
      "epoch 45; iter: 0; batch classifier loss: 0.200526; batch adversarial loss: 0.446232\n",
      "epoch 46; iter: 0; batch classifier loss: 0.143714; batch adversarial loss: 0.457273\n",
      "epoch 47; iter: 0; batch classifier loss: 0.162380; batch adversarial loss: 0.462072\n",
      "epoch 48; iter: 0; batch classifier loss: 0.123666; batch adversarial loss: 0.439303\n",
      "epoch 49; iter: 0; batch classifier loss: 0.212177; batch adversarial loss: 0.402866\n",
      "epoch 50; iter: 0; batch classifier loss: 0.127035; batch adversarial loss: 0.505797\n",
      "epoch 51; iter: 0; batch classifier loss: 0.176497; batch adversarial loss: 0.456821\n",
      "epoch 52; iter: 0; batch classifier loss: 0.159075; batch adversarial loss: 0.539888\n",
      "epoch 53; iter: 0; batch classifier loss: 0.224259; batch adversarial loss: 0.481540\n",
      "epoch 54; iter: 0; batch classifier loss: 0.131809; batch adversarial loss: 0.465389\n",
      "epoch 55; iter: 0; batch classifier loss: 0.151554; batch adversarial loss: 0.428671\n",
      "epoch 56; iter: 0; batch classifier loss: 0.145539; batch adversarial loss: 0.405907\n",
      "epoch 57; iter: 0; batch classifier loss: 0.162153; batch adversarial loss: 0.372867\n",
      "epoch 58; iter: 0; batch classifier loss: 0.195279; batch adversarial loss: 0.393553\n",
      "epoch 59; iter: 0; batch classifier loss: 0.111969; batch adversarial loss: 0.440359\n",
      "epoch 60; iter: 0; batch classifier loss: 0.211537; batch adversarial loss: 0.382791\n",
      "epoch 61; iter: 0; batch classifier loss: 0.174885; batch adversarial loss: 0.412089\n",
      "epoch 62; iter: 0; batch classifier loss: 0.121025; batch adversarial loss: 0.470640\n",
      "epoch 63; iter: 0; batch classifier loss: 0.126261; batch adversarial loss: 0.483354\n",
      "epoch 64; iter: 0; batch classifier loss: 0.157925; batch adversarial loss: 0.442872\n",
      "epoch 65; iter: 0; batch classifier loss: 0.183945; batch adversarial loss: 0.384630\n",
      "epoch 66; iter: 0; batch classifier loss: 0.161712; batch adversarial loss: 0.383454\n",
      "epoch 67; iter: 0; batch classifier loss: 0.135201; batch adversarial loss: 0.390982\n",
      "epoch 68; iter: 0; batch classifier loss: 0.103215; batch adversarial loss: 0.497238\n",
      "epoch 69; iter: 0; batch classifier loss: 0.147708; batch adversarial loss: 0.445770\n",
      "epoch 70; iter: 0; batch classifier loss: 0.084756; batch adversarial loss: 0.542664\n",
      "epoch 71; iter: 0; batch classifier loss: 0.150797; batch adversarial loss: 0.424855\n",
      "epoch 72; iter: 0; batch classifier loss: 0.104032; batch adversarial loss: 0.518578\n",
      "epoch 73; iter: 0; batch classifier loss: 0.161848; batch adversarial loss: 0.406231\n",
      "epoch 74; iter: 0; batch classifier loss: 0.141217; batch adversarial loss: 0.482497\n",
      "epoch 75; iter: 0; batch classifier loss: 0.199629; batch adversarial loss: 0.421889\n",
      "epoch 76; iter: 0; batch classifier loss: 0.167181; batch adversarial loss: 0.386056\n",
      "epoch 77; iter: 0; batch classifier loss: 0.128254; batch adversarial loss: 0.467521\n",
      "epoch 78; iter: 0; batch classifier loss: 0.185861; batch adversarial loss: 0.443357\n",
      "epoch 79; iter: 0; batch classifier loss: 0.120534; batch adversarial loss: 0.432927\n",
      "epoch 80; iter: 0; batch classifier loss: 0.151327; batch adversarial loss: 0.479628\n",
      "epoch 81; iter: 0; batch classifier loss: 0.131905; batch adversarial loss: 0.446348\n",
      "epoch 82; iter: 0; batch classifier loss: 0.099142; batch adversarial loss: 0.467052\n",
      "epoch 83; iter: 0; batch classifier loss: 0.123129; batch adversarial loss: 0.495950\n",
      "epoch 84; iter: 0; batch classifier loss: 0.113896; batch adversarial loss: 0.482165\n",
      "epoch 85; iter: 0; batch classifier loss: 0.179474; batch adversarial loss: 0.384178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.149490; batch adversarial loss: 0.455932\n",
      "epoch 87; iter: 0; batch classifier loss: 0.102483; batch adversarial loss: 0.422601\n",
      "epoch 88; iter: 0; batch classifier loss: 0.132776; batch adversarial loss: 0.483450\n",
      "epoch 89; iter: 0; batch classifier loss: 0.159042; batch adversarial loss: 0.417610\n",
      "epoch 90; iter: 0; batch classifier loss: 0.117696; batch adversarial loss: 0.492906\n",
      "epoch 91; iter: 0; batch classifier loss: 0.141174; batch adversarial loss: 0.433997\n",
      "epoch 92; iter: 0; batch classifier loss: 0.131390; batch adversarial loss: 0.393274\n",
      "epoch 93; iter: 0; batch classifier loss: 0.144904; batch adversarial loss: 0.410756\n",
      "epoch 94; iter: 0; batch classifier loss: 0.176624; batch adversarial loss: 0.485723\n",
      "epoch 95; iter: 0; batch classifier loss: 0.141701; batch adversarial loss: 0.467755\n",
      "epoch 96; iter: 0; batch classifier loss: 0.129685; batch adversarial loss: 0.456514\n",
      "epoch 97; iter: 0; batch classifier loss: 0.126192; batch adversarial loss: 0.406875\n",
      "epoch 98; iter: 0; batch classifier loss: 0.137204; batch adversarial loss: 0.465628\n",
      "epoch 99; iter: 0; batch classifier loss: 0.129875; batch adversarial loss: 0.495224\n",
      "epoch 100; iter: 0; batch classifier loss: 0.105504; batch adversarial loss: 0.378518\n",
      "epoch 101; iter: 0; batch classifier loss: 0.100113; batch adversarial loss: 0.445803\n",
      "epoch 102; iter: 0; batch classifier loss: 0.101552; batch adversarial loss: 0.445871\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063958; batch adversarial loss: 0.397137\n",
      "epoch 104; iter: 0; batch classifier loss: 0.179836; batch adversarial loss: 0.489009\n",
      "epoch 105; iter: 0; batch classifier loss: 0.166121; batch adversarial loss: 0.506707\n",
      "epoch 106; iter: 0; batch classifier loss: 0.116654; batch adversarial loss: 0.555955\n",
      "epoch 107; iter: 0; batch classifier loss: 0.134084; batch adversarial loss: 0.481593\n",
      "epoch 108; iter: 0; batch classifier loss: 0.116349; batch adversarial loss: 0.427098\n",
      "epoch 109; iter: 0; batch classifier loss: 0.159260; batch adversarial loss: 0.532444\n",
      "epoch 110; iter: 0; batch classifier loss: 0.108465; batch adversarial loss: 0.484080\n",
      "epoch 111; iter: 0; batch classifier loss: 0.122255; batch adversarial loss: 0.468060\n",
      "epoch 112; iter: 0; batch classifier loss: 0.088448; batch adversarial loss: 0.414923\n",
      "epoch 113; iter: 0; batch classifier loss: 0.106589; batch adversarial loss: 0.504302\n",
      "epoch 114; iter: 0; batch classifier loss: 0.074984; batch adversarial loss: 0.468199\n",
      "epoch 115; iter: 0; batch classifier loss: 0.087734; batch adversarial loss: 0.442836\n",
      "epoch 116; iter: 0; batch classifier loss: 0.144638; batch adversarial loss: 0.395869\n",
      "epoch 117; iter: 0; batch classifier loss: 0.090286; batch adversarial loss: 0.468262\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069031; batch adversarial loss: 0.495646\n",
      "epoch 119; iter: 0; batch classifier loss: 0.122971; batch adversarial loss: 0.438162\n",
      "epoch 120; iter: 0; batch classifier loss: 0.103191; batch adversarial loss: 0.556257\n",
      "epoch 121; iter: 0; batch classifier loss: 0.072978; batch adversarial loss: 0.423888\n",
      "epoch 122; iter: 0; batch classifier loss: 0.086489; batch adversarial loss: 0.407593\n",
      "epoch 123; iter: 0; batch classifier loss: 0.116612; batch adversarial loss: 0.449957\n",
      "epoch 124; iter: 0; batch classifier loss: 0.087437; batch adversarial loss: 0.383933\n",
      "epoch 125; iter: 0; batch classifier loss: 0.113075; batch adversarial loss: 0.496184\n",
      "epoch 126; iter: 0; batch classifier loss: 0.053684; batch adversarial loss: 0.432740\n",
      "epoch 127; iter: 0; batch classifier loss: 0.065735; batch adversarial loss: 0.445402\n",
      "epoch 128; iter: 0; batch classifier loss: 0.100517; batch adversarial loss: 0.486571\n",
      "epoch 129; iter: 0; batch classifier loss: 0.065296; batch adversarial loss: 0.408040\n",
      "epoch 130; iter: 0; batch classifier loss: 0.102145; batch adversarial loss: 0.355593\n",
      "epoch 131; iter: 0; batch classifier loss: 0.095019; batch adversarial loss: 0.442587\n",
      "epoch 132; iter: 0; batch classifier loss: 0.069873; batch adversarial loss: 0.381529\n",
      "epoch 133; iter: 0; batch classifier loss: 0.057365; batch adversarial loss: 0.488239\n",
      "epoch 134; iter: 0; batch classifier loss: 0.058866; batch adversarial loss: 0.475621\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039400; batch adversarial loss: 0.393868\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056033; batch adversarial loss: 0.513006\n",
      "epoch 137; iter: 0; batch classifier loss: 0.050672; batch adversarial loss: 0.410070\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030275; batch adversarial loss: 0.445675\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049564; batch adversarial loss: 0.378164\n",
      "epoch 140; iter: 0; batch classifier loss: 0.073597; batch adversarial loss: 0.392700\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049828; batch adversarial loss: 0.485287\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035172; batch adversarial loss: 0.459024\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043129; batch adversarial loss: 0.529769\n",
      "epoch 144; iter: 0; batch classifier loss: 0.070112; batch adversarial loss: 0.439159\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034782; batch adversarial loss: 0.435976\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030139; batch adversarial loss: 0.407383\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013476; batch adversarial loss: 0.628092\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031753; batch adversarial loss: 0.488074\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040255; batch adversarial loss: 0.448612\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026354; batch adversarial loss: 0.491896\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040857; batch adversarial loss: 0.397940\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019493; batch adversarial loss: 0.443214\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013616; batch adversarial loss: 0.507118\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032394; batch adversarial loss: 0.371424\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010103; batch adversarial loss: 0.569527\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036395; batch adversarial loss: 0.386205\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033317; batch adversarial loss: 0.560709\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024172; batch adversarial loss: 0.508477\n",
      "epoch 159; iter: 0; batch classifier loss: 0.046425; batch adversarial loss: 0.389969\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012848; batch adversarial loss: 0.453996\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023777; batch adversarial loss: 0.425800\n",
      "epoch 162; iter: 0; batch classifier loss: 0.050730; batch adversarial loss: 0.431169\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038684; batch adversarial loss: 0.415319\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016132; batch adversarial loss: 0.399023\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027487; batch adversarial loss: 0.430751\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025338; batch adversarial loss: 0.511393\n",
      "epoch 167; iter: 0; batch classifier loss: 0.044437; batch adversarial loss: 0.529458\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036405; batch adversarial loss: 0.478815\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017506; batch adversarial loss: 0.458550\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010942; batch adversarial loss: 0.510655\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013876; batch adversarial loss: 0.454353\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010303; batch adversarial loss: 0.453814\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012820; batch adversarial loss: 0.493233\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014206; batch adversarial loss: 0.396354\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022940; batch adversarial loss: 0.444299\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035506; batch adversarial loss: 0.431521\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018520; batch adversarial loss: 0.535993\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037102; batch adversarial loss: 0.535844\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009406; batch adversarial loss: 0.392476\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015725; batch adversarial loss: 0.444658\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016566; batch adversarial loss: 0.458764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.032409; batch adversarial loss: 0.334797\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010700; batch adversarial loss: 0.414078\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010773; batch adversarial loss: 0.431161\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006630; batch adversarial loss: 0.442759\n",
      "epoch 186; iter: 0; batch classifier loss: 0.003833; batch adversarial loss: 0.417763\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018932; batch adversarial loss: 0.436828\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009652; batch adversarial loss: 0.436477\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015610; batch adversarial loss: 0.396228\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022156; batch adversarial loss: 0.466789\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029117; batch adversarial loss: 0.411789\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023969; batch adversarial loss: 0.406449\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010681; batch adversarial loss: 0.525169\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014172; batch adversarial loss: 0.377984\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023196; batch adversarial loss: 0.459271\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009866; batch adversarial loss: 0.397621\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032017; batch adversarial loss: 0.456259\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020428; batch adversarial loss: 0.386261\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012842; batch adversarial loss: 0.490348\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687150; batch adversarial loss: 0.797378\n",
      "epoch 1; iter: 0; batch classifier loss: 0.425769; batch adversarial loss: 0.764548\n",
      "epoch 2; iter: 0; batch classifier loss: 0.437029; batch adversarial loss: 0.718747\n",
      "epoch 3; iter: 0; batch classifier loss: 0.313519; batch adversarial loss: 0.667964\n",
      "epoch 4; iter: 0; batch classifier loss: 0.319772; batch adversarial loss: 0.632090\n",
      "epoch 5; iter: 0; batch classifier loss: 0.302614; batch adversarial loss: 0.608331\n",
      "epoch 6; iter: 0; batch classifier loss: 0.335503; batch adversarial loss: 0.570469\n",
      "epoch 7; iter: 0; batch classifier loss: 0.315651; batch adversarial loss: 0.551331\n",
      "epoch 8; iter: 0; batch classifier loss: 0.261413; batch adversarial loss: 0.516360\n",
      "epoch 9; iter: 0; batch classifier loss: 0.223485; batch adversarial loss: 0.510088\n",
      "epoch 10; iter: 0; batch classifier loss: 0.242807; batch adversarial loss: 0.531218\n",
      "epoch 11; iter: 0; batch classifier loss: 0.301379; batch adversarial loss: 0.539251\n",
      "epoch 12; iter: 0; batch classifier loss: 0.205364; batch adversarial loss: 0.480117\n",
      "epoch 13; iter: 0; batch classifier loss: 0.160924; batch adversarial loss: 0.553784\n",
      "epoch 14; iter: 0; batch classifier loss: 0.254695; batch adversarial loss: 0.530429\n",
      "epoch 15; iter: 0; batch classifier loss: 0.221350; batch adversarial loss: 0.463438\n",
      "epoch 16; iter: 0; batch classifier loss: 0.186561; batch adversarial loss: 0.440500\n",
      "epoch 17; iter: 0; batch classifier loss: 0.203207; batch adversarial loss: 0.460494\n",
      "epoch 18; iter: 0; batch classifier loss: 0.147970; batch adversarial loss: 0.495015\n",
      "epoch 19; iter: 0; batch classifier loss: 0.152369; batch adversarial loss: 0.498914\n",
      "epoch 20; iter: 0; batch classifier loss: 0.170995; batch adversarial loss: 0.432958\n",
      "epoch 21; iter: 0; batch classifier loss: 0.173503; batch adversarial loss: 0.430703\n",
      "epoch 22; iter: 0; batch classifier loss: 0.149214; batch adversarial loss: 0.445580\n",
      "epoch 23; iter: 0; batch classifier loss: 0.217917; batch adversarial loss: 0.417238\n",
      "epoch 24; iter: 0; batch classifier loss: 0.215990; batch adversarial loss: 0.464459\n",
      "epoch 25; iter: 0; batch classifier loss: 0.266534; batch adversarial loss: 0.435808\n",
      "epoch 26; iter: 0; batch classifier loss: 0.267645; batch adversarial loss: 0.546402\n",
      "epoch 27; iter: 0; batch classifier loss: 0.439160; batch adversarial loss: 0.450169\n",
      "epoch 28; iter: 0; batch classifier loss: 0.257607; batch adversarial loss: 0.510046\n",
      "epoch 29; iter: 0; batch classifier loss: 0.184331; batch adversarial loss: 0.518839\n",
      "epoch 30; iter: 0; batch classifier loss: 0.109354; batch adversarial loss: 0.452583\n",
      "epoch 31; iter: 0; batch classifier loss: 0.185079; batch adversarial loss: 0.408378\n",
      "epoch 32; iter: 0; batch classifier loss: 0.156290; batch adversarial loss: 0.415304\n",
      "epoch 33; iter: 0; batch classifier loss: 0.127168; batch adversarial loss: 0.547766\n",
      "epoch 34; iter: 0; batch classifier loss: 0.089336; batch adversarial loss: 0.371827\n",
      "epoch 35; iter: 0; batch classifier loss: 0.128047; batch adversarial loss: 0.414446\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140143; batch adversarial loss: 0.420527\n",
      "epoch 37; iter: 0; batch classifier loss: 0.134730; batch adversarial loss: 0.387007\n",
      "epoch 38; iter: 0; batch classifier loss: 0.085811; batch adversarial loss: 0.531566\n",
      "epoch 39; iter: 0; batch classifier loss: 0.119147; batch adversarial loss: 0.423197\n",
      "epoch 40; iter: 0; batch classifier loss: 0.103489; batch adversarial loss: 0.488656\n",
      "epoch 41; iter: 0; batch classifier loss: 0.086149; batch adversarial loss: 0.457908\n",
      "epoch 42; iter: 0; batch classifier loss: 0.194782; batch adversarial loss: 0.519395\n",
      "epoch 43; iter: 0; batch classifier loss: 0.111819; batch adversarial loss: 0.439048\n",
      "epoch 44; iter: 0; batch classifier loss: 0.128945; batch adversarial loss: 0.459640\n",
      "epoch 45; iter: 0; batch classifier loss: 0.139205; batch adversarial loss: 0.408603\n",
      "epoch 46; iter: 0; batch classifier loss: 0.132223; batch adversarial loss: 0.413304\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095554; batch adversarial loss: 0.481683\n",
      "epoch 48; iter: 0; batch classifier loss: 0.079371; batch adversarial loss: 0.452877\n",
      "epoch 49; iter: 0; batch classifier loss: 0.070576; batch adversarial loss: 0.450030\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087706; batch adversarial loss: 0.489680\n",
      "epoch 51; iter: 0; batch classifier loss: 0.062103; batch adversarial loss: 0.452947\n",
      "epoch 52; iter: 0; batch classifier loss: 0.079677; batch adversarial loss: 0.579405\n",
      "epoch 53; iter: 0; batch classifier loss: 0.075586; batch adversarial loss: 0.392494\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074666; batch adversarial loss: 0.405370\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079486; batch adversarial loss: 0.508792\n",
      "epoch 56; iter: 0; batch classifier loss: 0.083085; batch adversarial loss: 0.482532\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079226; batch adversarial loss: 0.454882\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090888; batch adversarial loss: 0.431815\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070418; batch adversarial loss: 0.377999\n",
      "epoch 60; iter: 0; batch classifier loss: 0.061530; batch adversarial loss: 0.442300\n",
      "epoch 61; iter: 0; batch classifier loss: 0.067108; batch adversarial loss: 0.493615\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101919; batch adversarial loss: 0.319640\n",
      "epoch 63; iter: 0; batch classifier loss: 0.090450; batch adversarial loss: 0.472665\n",
      "epoch 64; iter: 0; batch classifier loss: 0.048050; batch adversarial loss: 0.405851\n",
      "epoch 65; iter: 0; batch classifier loss: 0.086112; batch adversarial loss: 0.470553\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084340; batch adversarial loss: 0.539989\n",
      "epoch 67; iter: 0; batch classifier loss: 0.104673; batch adversarial loss: 0.380171\n",
      "epoch 68; iter: 0; batch classifier loss: 0.059076; batch adversarial loss: 0.419321\n",
      "epoch 69; iter: 0; batch classifier loss: 0.069507; batch adversarial loss: 0.450204\n",
      "epoch 70; iter: 0; batch classifier loss: 0.113351; batch adversarial loss: 0.421678\n",
      "epoch 71; iter: 0; batch classifier loss: 0.065105; batch adversarial loss: 0.367007\n",
      "epoch 72; iter: 0; batch classifier loss: 0.101216; batch adversarial loss: 0.540779\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077541; batch adversarial loss: 0.350192\n",
      "epoch 74; iter: 0; batch classifier loss: 0.084654; batch adversarial loss: 0.462612\n",
      "epoch 75; iter: 0; batch classifier loss: 0.045328; batch adversarial loss: 0.504873\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075361; batch adversarial loss: 0.473273\n",
      "epoch 77; iter: 0; batch classifier loss: 0.074978; batch adversarial loss: 0.383559\n",
      "epoch 78; iter: 0; batch classifier loss: 0.065830; batch adversarial loss: 0.445556\n",
      "epoch 79; iter: 0; batch classifier loss: 0.081290; batch adversarial loss: 0.466828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.102088; batch adversarial loss: 0.403954\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081384; batch adversarial loss: 0.444955\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075153; batch adversarial loss: 0.393671\n",
      "epoch 83; iter: 0; batch classifier loss: 0.049151; batch adversarial loss: 0.555042\n",
      "epoch 84; iter: 0; batch classifier loss: 0.054199; batch adversarial loss: 0.491443\n",
      "epoch 85; iter: 0; batch classifier loss: 0.042275; batch adversarial loss: 0.401236\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068679; batch adversarial loss: 0.411791\n",
      "epoch 87; iter: 0; batch classifier loss: 0.060851; batch adversarial loss: 0.460418\n",
      "epoch 88; iter: 0; batch classifier loss: 0.038462; batch adversarial loss: 0.424466\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057277; batch adversarial loss: 0.432671\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075793; batch adversarial loss: 0.471502\n",
      "epoch 91; iter: 0; batch classifier loss: 0.080016; batch adversarial loss: 0.457862\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050704; batch adversarial loss: 0.405373\n",
      "epoch 93; iter: 0; batch classifier loss: 0.026540; batch adversarial loss: 0.550338\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053183; batch adversarial loss: 0.546748\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051589; batch adversarial loss: 0.419010\n",
      "epoch 96; iter: 0; batch classifier loss: 0.028170; batch adversarial loss: 0.383630\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039897; batch adversarial loss: 0.434464\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048043; batch adversarial loss: 0.417347\n",
      "epoch 99; iter: 0; batch classifier loss: 0.035896; batch adversarial loss: 0.435897\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057119; batch adversarial loss: 0.444708\n",
      "epoch 101; iter: 0; batch classifier loss: 0.034843; batch adversarial loss: 0.505292\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041708; batch adversarial loss: 0.390434\n",
      "epoch 103; iter: 0; batch classifier loss: 0.073789; batch adversarial loss: 0.549191\n",
      "epoch 104; iter: 0; batch classifier loss: 0.024670; batch adversarial loss: 0.540683\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050531; batch adversarial loss: 0.424676\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045209; batch adversarial loss: 0.447613\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049596; batch adversarial loss: 0.403039\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060580; batch adversarial loss: 0.451501\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044587; batch adversarial loss: 0.396944\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026187; batch adversarial loss: 0.514863\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031301; batch adversarial loss: 0.451908\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059212; batch adversarial loss: 0.448279\n",
      "epoch 113; iter: 0; batch classifier loss: 0.021560; batch adversarial loss: 0.466811\n",
      "epoch 114; iter: 0; batch classifier loss: 0.021106; batch adversarial loss: 0.453991\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027995; batch adversarial loss: 0.478217\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054356; batch adversarial loss: 0.422523\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038944; batch adversarial loss: 0.476846\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042376; batch adversarial loss: 0.448044\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021950; batch adversarial loss: 0.515377\n",
      "epoch 120; iter: 0; batch classifier loss: 0.059458; batch adversarial loss: 0.473870\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029180; batch adversarial loss: 0.442604\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062274; batch adversarial loss: 0.466736\n",
      "epoch 123; iter: 0; batch classifier loss: 0.060262; batch adversarial loss: 0.461454\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032372; batch adversarial loss: 0.412343\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053764; batch adversarial loss: 0.464972\n",
      "epoch 126; iter: 0; batch classifier loss: 0.052263; batch adversarial loss: 0.491666\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036540; batch adversarial loss: 0.450070\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042033; batch adversarial loss: 0.443308\n",
      "epoch 129; iter: 0; batch classifier loss: 0.014715; batch adversarial loss: 0.483372\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043912; batch adversarial loss: 0.394690\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028249; batch adversarial loss: 0.450489\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024832; batch adversarial loss: 0.484020\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031432; batch adversarial loss: 0.465533\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036322; batch adversarial loss: 0.429150\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044645; batch adversarial loss: 0.405772\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041258; batch adversarial loss: 0.409277\n",
      "epoch 137; iter: 0; batch classifier loss: 0.066626; batch adversarial loss: 0.407729\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044114; batch adversarial loss: 0.343401\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049484; batch adversarial loss: 0.431960\n",
      "epoch 140; iter: 0; batch classifier loss: 0.060893; batch adversarial loss: 0.570503\n",
      "epoch 141; iter: 0; batch classifier loss: 0.059686; batch adversarial loss: 0.507267\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050424; batch adversarial loss: 0.492458\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014917; batch adversarial loss: 0.406896\n",
      "epoch 144; iter: 0; batch classifier loss: 0.015894; batch adversarial loss: 0.434531\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040369; batch adversarial loss: 0.339021\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019210; batch adversarial loss: 0.336567\n",
      "epoch 147; iter: 0; batch classifier loss: 0.050417; batch adversarial loss: 0.461697\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046145; batch adversarial loss: 0.563952\n",
      "epoch 149; iter: 0; batch classifier loss: 0.076845; batch adversarial loss: 0.528649\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031142; batch adversarial loss: 0.415313\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008743; batch adversarial loss: 0.454332\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013169; batch adversarial loss: 0.406872\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011178; batch adversarial loss: 0.490419\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017739; batch adversarial loss: 0.417106\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026685; batch adversarial loss: 0.408493\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033561; batch adversarial loss: 0.481444\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034554; batch adversarial loss: 0.533103\n",
      "epoch 158; iter: 0; batch classifier loss: 0.041436; batch adversarial loss: 0.411088\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031180; batch adversarial loss: 0.579225\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009262; batch adversarial loss: 0.452341\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024930; batch adversarial loss: 0.386548\n",
      "epoch 162; iter: 0; batch classifier loss: 0.035986; batch adversarial loss: 0.488483\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037332; batch adversarial loss: 0.493106\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032783; batch adversarial loss: 0.441044\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012686; batch adversarial loss: 0.511378\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037766; batch adversarial loss: 0.494864\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021032; batch adversarial loss: 0.467776\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033605; batch adversarial loss: 0.460689\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009133; batch adversarial loss: 0.496688\n",
      "epoch 170; iter: 0; batch classifier loss: 0.007732; batch adversarial loss: 0.501159\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017514; batch adversarial loss: 0.409782\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025832; batch adversarial loss: 0.490503\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019146; batch adversarial loss: 0.409145\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022749; batch adversarial loss: 0.546791\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030049; batch adversarial loss: 0.441842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.019882; batch adversarial loss: 0.382212\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030453; batch adversarial loss: 0.445476\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026774; batch adversarial loss: 0.426939\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007606; batch adversarial loss: 0.367583\n",
      "epoch 180; iter: 0; batch classifier loss: 0.044082; batch adversarial loss: 0.442366\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024550; batch adversarial loss: 0.465840\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007342; batch adversarial loss: 0.406670\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022488; batch adversarial loss: 0.454257\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011285; batch adversarial loss: 0.475241\n",
      "epoch 185; iter: 0; batch classifier loss: 0.004726; batch adversarial loss: 0.483773\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022677; batch adversarial loss: 0.559701\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010129; batch adversarial loss: 0.431343\n",
      "epoch 188; iter: 0; batch classifier loss: 0.042509; batch adversarial loss: 0.497310\n",
      "epoch 189; iter: 0; batch classifier loss: 0.054253; batch adversarial loss: 0.531098\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019769; batch adversarial loss: 0.513889\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011620; batch adversarial loss: 0.413700\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032716; batch adversarial loss: 0.417604\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025638; batch adversarial loss: 0.415133\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026285; batch adversarial loss: 0.593993\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017237; batch adversarial loss: 0.507900\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020047; batch adversarial loss: 0.439381\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009675; batch adversarial loss: 0.434860\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027107; batch adversarial loss: 0.470481\n",
      "epoch 199; iter: 0; batch classifier loss: 0.046324; batch adversarial loss: 0.469621\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699314; batch adversarial loss: 0.502915\n",
      "epoch 1; iter: 0; batch classifier loss: 0.380822; batch adversarial loss: 0.633845\n",
      "epoch 2; iter: 0; batch classifier loss: 0.419843; batch adversarial loss: 0.607659\n",
      "epoch 3; iter: 0; batch classifier loss: 0.294927; batch adversarial loss: 0.572986\n",
      "epoch 4; iter: 0; batch classifier loss: 0.380235; batch adversarial loss: 0.564924\n",
      "epoch 5; iter: 0; batch classifier loss: 0.363764; batch adversarial loss: 0.594007\n",
      "epoch 6; iter: 0; batch classifier loss: 0.326222; batch adversarial loss: 0.573800\n",
      "epoch 7; iter: 0; batch classifier loss: 0.316021; batch adversarial loss: 0.484514\n",
      "epoch 8; iter: 0; batch classifier loss: 0.325103; batch adversarial loss: 0.555824\n",
      "epoch 9; iter: 0; batch classifier loss: 0.373471; batch adversarial loss: 0.509494\n",
      "epoch 10; iter: 0; batch classifier loss: 0.413457; batch adversarial loss: 0.540074\n",
      "epoch 11; iter: 0; batch classifier loss: 0.502227; batch adversarial loss: 0.583088\n",
      "epoch 12; iter: 0; batch classifier loss: 0.569737; batch adversarial loss: 0.562801\n",
      "epoch 13; iter: 0; batch classifier loss: 0.415676; batch adversarial loss: 0.428732\n",
      "epoch 14; iter: 0; batch classifier loss: 0.338197; batch adversarial loss: 0.521454\n",
      "epoch 15; iter: 0; batch classifier loss: 0.230207; batch adversarial loss: 0.495936\n",
      "epoch 16; iter: 0; batch classifier loss: 0.263018; batch adversarial loss: 0.563933\n",
      "epoch 17; iter: 0; batch classifier loss: 0.247053; batch adversarial loss: 0.470238\n",
      "epoch 18; iter: 0; batch classifier loss: 0.184631; batch adversarial loss: 0.515509\n",
      "epoch 19; iter: 0; batch classifier loss: 0.189376; batch adversarial loss: 0.480784\n",
      "epoch 20; iter: 0; batch classifier loss: 0.224940; batch adversarial loss: 0.468779\n",
      "epoch 21; iter: 0; batch classifier loss: 0.184058; batch adversarial loss: 0.454198\n",
      "epoch 22; iter: 0; batch classifier loss: 0.109198; batch adversarial loss: 0.420748\n",
      "epoch 23; iter: 0; batch classifier loss: 0.230010; batch adversarial loss: 0.419882\n",
      "epoch 24; iter: 0; batch classifier loss: 0.146551; batch adversarial loss: 0.477590\n",
      "epoch 25; iter: 0; batch classifier loss: 0.142678; batch adversarial loss: 0.435213\n",
      "epoch 26; iter: 0; batch classifier loss: 0.144249; batch adversarial loss: 0.422688\n",
      "epoch 27; iter: 0; batch classifier loss: 0.118366; batch adversarial loss: 0.447521\n",
      "epoch 28; iter: 0; batch classifier loss: 0.112181; batch adversarial loss: 0.390657\n",
      "epoch 29; iter: 0; batch classifier loss: 0.122105; batch adversarial loss: 0.487422\n",
      "epoch 30; iter: 0; batch classifier loss: 0.116966; batch adversarial loss: 0.418434\n",
      "epoch 31; iter: 0; batch classifier loss: 0.148456; batch adversarial loss: 0.525913\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126280; batch adversarial loss: 0.548168\n",
      "epoch 33; iter: 0; batch classifier loss: 0.159214; batch adversarial loss: 0.433743\n",
      "epoch 34; iter: 0; batch classifier loss: 0.101480; batch adversarial loss: 0.442721\n",
      "epoch 35; iter: 0; batch classifier loss: 0.111755; batch adversarial loss: 0.423252\n",
      "epoch 36; iter: 0; batch classifier loss: 0.089065; batch adversarial loss: 0.450895\n",
      "epoch 37; iter: 0; batch classifier loss: 0.137896; batch adversarial loss: 0.463416\n",
      "epoch 38; iter: 0; batch classifier loss: 0.156748; batch adversarial loss: 0.339442\n",
      "epoch 39; iter: 0; batch classifier loss: 0.122494; batch adversarial loss: 0.453841\n",
      "epoch 40; iter: 0; batch classifier loss: 0.094414; batch adversarial loss: 0.505016\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106423; batch adversarial loss: 0.402405\n",
      "epoch 42; iter: 0; batch classifier loss: 0.129534; batch adversarial loss: 0.407618\n",
      "epoch 43; iter: 0; batch classifier loss: 0.137570; batch adversarial loss: 0.436029\n",
      "epoch 44; iter: 0; batch classifier loss: 0.083798; batch adversarial loss: 0.497504\n",
      "epoch 45; iter: 0; batch classifier loss: 0.100989; batch adversarial loss: 0.490674\n",
      "epoch 46; iter: 0; batch classifier loss: 0.092361; batch adversarial loss: 0.435564\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112927; batch adversarial loss: 0.445033\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125633; batch adversarial loss: 0.427173\n",
      "epoch 49; iter: 0; batch classifier loss: 0.103208; batch adversarial loss: 0.493895\n",
      "epoch 50; iter: 0; batch classifier loss: 0.119778; batch adversarial loss: 0.503461\n",
      "epoch 51; iter: 0; batch classifier loss: 0.149685; batch adversarial loss: 0.529373\n",
      "epoch 52; iter: 0; batch classifier loss: 0.090141; batch adversarial loss: 0.509174\n",
      "epoch 53; iter: 0; batch classifier loss: 0.130498; batch adversarial loss: 0.451115\n",
      "epoch 54; iter: 0; batch classifier loss: 0.119836; batch adversarial loss: 0.454620\n",
      "epoch 55; iter: 0; batch classifier loss: 0.126905; batch adversarial loss: 0.471413\n",
      "epoch 56; iter: 0; batch classifier loss: 0.177201; batch adversarial loss: 0.462037\n",
      "epoch 57; iter: 0; batch classifier loss: 0.106826; batch adversarial loss: 0.542795\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103834; batch adversarial loss: 0.400196\n",
      "epoch 59; iter: 0; batch classifier loss: 0.157628; batch adversarial loss: 0.462033\n",
      "epoch 60; iter: 0; batch classifier loss: 0.083554; batch adversarial loss: 0.434293\n",
      "epoch 61; iter: 0; batch classifier loss: 0.064005; batch adversarial loss: 0.531641\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093293; batch adversarial loss: 0.442797\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085215; batch adversarial loss: 0.395659\n",
      "epoch 64; iter: 0; batch classifier loss: 0.071393; batch adversarial loss: 0.458252\n",
      "epoch 65; iter: 0; batch classifier loss: 0.072422; batch adversarial loss: 0.557252\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091186; batch adversarial loss: 0.443405\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069904; batch adversarial loss: 0.439232\n",
      "epoch 68; iter: 0; batch classifier loss: 0.106068; batch adversarial loss: 0.490991\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065646; batch adversarial loss: 0.486259\n",
      "epoch 70; iter: 0; batch classifier loss: 0.053885; batch adversarial loss: 0.410704\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115557; batch adversarial loss: 0.520038\n",
      "epoch 72; iter: 0; batch classifier loss: 0.063212; batch adversarial loss: 0.440888\n",
      "epoch 73; iter: 0; batch classifier loss: 0.082653; batch adversarial loss: 0.445364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.084382; batch adversarial loss: 0.387904\n",
      "epoch 75; iter: 0; batch classifier loss: 0.068569; batch adversarial loss: 0.460933\n",
      "epoch 76; iter: 0; batch classifier loss: 0.116427; batch adversarial loss: 0.449213\n",
      "epoch 77; iter: 0; batch classifier loss: 0.106043; batch adversarial loss: 0.536300\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059574; batch adversarial loss: 0.435063\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085538; batch adversarial loss: 0.536002\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083500; batch adversarial loss: 0.461061\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055829; batch adversarial loss: 0.468636\n",
      "epoch 82; iter: 0; batch classifier loss: 0.081085; batch adversarial loss: 0.547080\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054550; batch adversarial loss: 0.458207\n",
      "epoch 84; iter: 0; batch classifier loss: 0.083883; batch adversarial loss: 0.404798\n",
      "epoch 85; iter: 0; batch classifier loss: 0.049528; batch adversarial loss: 0.436453\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061274; batch adversarial loss: 0.440512\n",
      "epoch 87; iter: 0; batch classifier loss: 0.109317; batch adversarial loss: 0.456812\n",
      "epoch 88; iter: 0; batch classifier loss: 0.079512; batch adversarial loss: 0.468714\n",
      "epoch 89; iter: 0; batch classifier loss: 0.119795; batch adversarial loss: 0.523222\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066630; batch adversarial loss: 0.430768\n",
      "epoch 91; iter: 0; batch classifier loss: 0.054885; batch adversarial loss: 0.525647\n",
      "epoch 92; iter: 0; batch classifier loss: 0.108009; batch adversarial loss: 0.448929\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051030; batch adversarial loss: 0.456835\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039333; batch adversarial loss: 0.539739\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045978; batch adversarial loss: 0.435049\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068547; batch adversarial loss: 0.493828\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060014; batch adversarial loss: 0.449326\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048403; batch adversarial loss: 0.411066\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042734; batch adversarial loss: 0.467580\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060351; batch adversarial loss: 0.494783\n",
      "epoch 101; iter: 0; batch classifier loss: 0.096361; batch adversarial loss: 0.409619\n",
      "epoch 102; iter: 0; batch classifier loss: 0.082441; batch adversarial loss: 0.378062\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041956; batch adversarial loss: 0.389381\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041737; batch adversarial loss: 0.450974\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055334; batch adversarial loss: 0.395033\n",
      "epoch 106; iter: 0; batch classifier loss: 0.022731; batch adversarial loss: 0.467239\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061969; batch adversarial loss: 0.554445\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060551; batch adversarial loss: 0.559270\n",
      "epoch 109; iter: 0; batch classifier loss: 0.023458; batch adversarial loss: 0.435707\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064839; batch adversarial loss: 0.468893\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044293; batch adversarial loss: 0.458032\n",
      "epoch 112; iter: 0; batch classifier loss: 0.049706; batch adversarial loss: 0.497974\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035692; batch adversarial loss: 0.509677\n",
      "epoch 114; iter: 0; batch classifier loss: 0.066858; batch adversarial loss: 0.364276\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035631; batch adversarial loss: 0.502690\n",
      "epoch 116; iter: 0; batch classifier loss: 0.065886; batch adversarial loss: 0.451242\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053047; batch adversarial loss: 0.485666\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033676; batch adversarial loss: 0.527740\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045761; batch adversarial loss: 0.438010\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039486; batch adversarial loss: 0.521004\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050212; batch adversarial loss: 0.403199\n",
      "epoch 122; iter: 0; batch classifier loss: 0.113421; batch adversarial loss: 0.453433\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014293; batch adversarial loss: 0.552285\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042886; batch adversarial loss: 0.447968\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031923; batch adversarial loss: 0.452876\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045522; batch adversarial loss: 0.432648\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050105; batch adversarial loss: 0.407708\n",
      "epoch 128; iter: 0; batch classifier loss: 0.059596; batch adversarial loss: 0.416613\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037074; batch adversarial loss: 0.403215\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031350; batch adversarial loss: 0.450428\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047543; batch adversarial loss: 0.438532\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029410; batch adversarial loss: 0.575971\n",
      "epoch 133; iter: 0; batch classifier loss: 0.087581; batch adversarial loss: 0.422732\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062639; batch adversarial loss: 0.478657\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029446; batch adversarial loss: 0.501206\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049416; batch adversarial loss: 0.373599\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034982; batch adversarial loss: 0.397250\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014311; batch adversarial loss: 0.419255\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030350; batch adversarial loss: 0.464056\n",
      "epoch 140; iter: 0; batch classifier loss: 0.049052; batch adversarial loss: 0.440207\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036304; batch adversarial loss: 0.511291\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026857; batch adversarial loss: 0.427518\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043183; batch adversarial loss: 0.424532\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025123; batch adversarial loss: 0.447905\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030551; batch adversarial loss: 0.409313\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010792; batch adversarial loss: 0.474691\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031028; batch adversarial loss: 0.384418\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030174; batch adversarial loss: 0.503899\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038188; batch adversarial loss: 0.595968\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033079; batch adversarial loss: 0.347173\n",
      "epoch 151; iter: 0; batch classifier loss: 0.010444; batch adversarial loss: 0.411529\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038599; batch adversarial loss: 0.456447\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019954; batch adversarial loss: 0.468866\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021688; batch adversarial loss: 0.445848\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020165; batch adversarial loss: 0.487227\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016694; batch adversarial loss: 0.481110\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020600; batch adversarial loss: 0.419973\n",
      "epoch 158; iter: 0; batch classifier loss: 0.050985; batch adversarial loss: 0.452390\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024151; batch adversarial loss: 0.426457\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009336; batch adversarial loss: 0.413192\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018680; batch adversarial loss: 0.492417\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025922; batch adversarial loss: 0.508604\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025199; batch adversarial loss: 0.399916\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018306; batch adversarial loss: 0.466354\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022713; batch adversarial loss: 0.403869\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023690; batch adversarial loss: 0.462981\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014734; batch adversarial loss: 0.373750\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016378; batch adversarial loss: 0.554633\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018089; batch adversarial loss: 0.451632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.014161; batch adversarial loss: 0.462827\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013805; batch adversarial loss: 0.466999\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033349; batch adversarial loss: 0.404535\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015104; batch adversarial loss: 0.364941\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017268; batch adversarial loss: 0.432902\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025394; batch adversarial loss: 0.389514\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024137; batch adversarial loss: 0.426791\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013151; batch adversarial loss: 0.471535\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013968; batch adversarial loss: 0.466213\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027991; batch adversarial loss: 0.485333\n",
      "epoch 180; iter: 0; batch classifier loss: 0.005339; batch adversarial loss: 0.469171\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033583; batch adversarial loss: 0.513176\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013801; batch adversarial loss: 0.412673\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028454; batch adversarial loss: 0.523838\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030411; batch adversarial loss: 0.504464\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010644; batch adversarial loss: 0.398971\n",
      "epoch 186; iter: 0; batch classifier loss: 0.077404; batch adversarial loss: 0.500739\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034881; batch adversarial loss: 0.445011\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033715; batch adversarial loss: 0.485331\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013228; batch adversarial loss: 0.534070\n",
      "epoch 190; iter: 0; batch classifier loss: 0.053727; batch adversarial loss: 0.534734\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020174; batch adversarial loss: 0.559493\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025168; batch adversarial loss: 0.436592\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020963; batch adversarial loss: 0.442725\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011184; batch adversarial loss: 0.390883\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021091; batch adversarial loss: 0.535403\n",
      "epoch 196; iter: 0; batch classifier loss: 0.043283; batch adversarial loss: 0.463038\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011283; batch adversarial loss: 0.376020\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018595; batch adversarial loss: 0.416260\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023943; batch adversarial loss: 0.425167\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663414; batch adversarial loss: 0.740323\n",
      "epoch 1; iter: 0; batch classifier loss: 0.452354; batch adversarial loss: 0.649549\n",
      "epoch 2; iter: 0; batch classifier loss: 0.401705; batch adversarial loss: 0.630042\n",
      "epoch 3; iter: 0; batch classifier loss: 0.363330; batch adversarial loss: 0.622458\n",
      "epoch 4; iter: 0; batch classifier loss: 0.307833; batch adversarial loss: 0.567932\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343312; batch adversarial loss: 0.551008\n",
      "epoch 6; iter: 0; batch classifier loss: 0.347337; batch adversarial loss: 0.557942\n",
      "epoch 7; iter: 0; batch classifier loss: 0.327892; batch adversarial loss: 0.542455\n",
      "epoch 8; iter: 0; batch classifier loss: 0.305131; batch adversarial loss: 0.558953\n",
      "epoch 9; iter: 0; batch classifier loss: 0.335174; batch adversarial loss: 0.559397\n",
      "epoch 10; iter: 0; batch classifier loss: 0.279846; batch adversarial loss: 0.537801\n",
      "epoch 11; iter: 0; batch classifier loss: 0.357461; batch adversarial loss: 0.555334\n",
      "epoch 12; iter: 0; batch classifier loss: 0.354886; batch adversarial loss: 0.501875\n",
      "epoch 13; iter: 0; batch classifier loss: 0.301581; batch adversarial loss: 0.506266\n",
      "epoch 14; iter: 0; batch classifier loss: 0.289918; batch adversarial loss: 0.500605\n",
      "epoch 15; iter: 0; batch classifier loss: 0.305576; batch adversarial loss: 0.464778\n",
      "epoch 16; iter: 0; batch classifier loss: 0.401984; batch adversarial loss: 0.484587\n",
      "epoch 17; iter: 0; batch classifier loss: 0.364581; batch adversarial loss: 0.437105\n",
      "epoch 18; iter: 0; batch classifier loss: 0.269992; batch adversarial loss: 0.479629\n",
      "epoch 19; iter: 0; batch classifier loss: 0.213060; batch adversarial loss: 0.487458\n",
      "epoch 20; iter: 0; batch classifier loss: 0.244773; batch adversarial loss: 0.555209\n",
      "epoch 21; iter: 0; batch classifier loss: 0.300567; batch adversarial loss: 0.513757\n",
      "epoch 22; iter: 0; batch classifier loss: 0.312308; batch adversarial loss: 0.424903\n",
      "epoch 23; iter: 0; batch classifier loss: 0.175584; batch adversarial loss: 0.487283\n",
      "epoch 24; iter: 0; batch classifier loss: 0.209783; batch adversarial loss: 0.528824\n",
      "epoch 25; iter: 0; batch classifier loss: 0.226664; batch adversarial loss: 0.449365\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193373; batch adversarial loss: 0.435596\n",
      "epoch 27; iter: 0; batch classifier loss: 0.239215; batch adversarial loss: 0.458275\n",
      "epoch 28; iter: 0; batch classifier loss: 0.246921; batch adversarial loss: 0.454731\n",
      "epoch 29; iter: 0; batch classifier loss: 0.139097; batch adversarial loss: 0.502558\n",
      "epoch 30; iter: 0; batch classifier loss: 0.285389; batch adversarial loss: 0.404358\n",
      "epoch 31; iter: 0; batch classifier loss: 0.212576; batch adversarial loss: 0.573067\n",
      "epoch 32; iter: 0; batch classifier loss: 0.199528; batch adversarial loss: 0.428960\n",
      "epoch 33; iter: 0; batch classifier loss: 0.192028; batch adversarial loss: 0.547142\n",
      "epoch 34; iter: 0; batch classifier loss: 0.201977; batch adversarial loss: 0.420401\n",
      "epoch 35; iter: 0; batch classifier loss: 0.180696; batch adversarial loss: 0.438641\n",
      "epoch 36; iter: 0; batch classifier loss: 0.234109; batch adversarial loss: 0.477482\n",
      "epoch 37; iter: 0; batch classifier loss: 0.233493; batch adversarial loss: 0.370995\n",
      "epoch 38; iter: 0; batch classifier loss: 0.230914; batch adversarial loss: 0.451084\n",
      "epoch 39; iter: 0; batch classifier loss: 0.221753; batch adversarial loss: 0.400215\n",
      "epoch 40; iter: 0; batch classifier loss: 0.291701; batch adversarial loss: 0.485562\n",
      "epoch 41; iter: 0; batch classifier loss: 0.213937; batch adversarial loss: 0.505480\n",
      "epoch 42; iter: 0; batch classifier loss: 0.253450; batch adversarial loss: 0.390065\n",
      "epoch 43; iter: 0; batch classifier loss: 0.261787; batch adversarial loss: 0.511302\n",
      "epoch 44; iter: 0; batch classifier loss: 0.267201; batch adversarial loss: 0.454142\n",
      "epoch 45; iter: 0; batch classifier loss: 0.190087; batch adversarial loss: 0.514063\n",
      "epoch 46; iter: 0; batch classifier loss: 0.223546; batch adversarial loss: 0.488574\n",
      "epoch 47; iter: 0; batch classifier loss: 0.239482; batch adversarial loss: 0.389193\n",
      "epoch 48; iter: 0; batch classifier loss: 0.196503; batch adversarial loss: 0.482484\n",
      "epoch 49; iter: 0; batch classifier loss: 0.174452; batch adversarial loss: 0.483002\n",
      "epoch 50; iter: 0; batch classifier loss: 0.327912; batch adversarial loss: 0.411974\n",
      "epoch 51; iter: 0; batch classifier loss: 0.235588; batch adversarial loss: 0.500741\n",
      "epoch 52; iter: 0; batch classifier loss: 0.212865; batch adversarial loss: 0.456877\n",
      "epoch 53; iter: 0; batch classifier loss: 0.160045; batch adversarial loss: 0.496105\n",
      "epoch 54; iter: 0; batch classifier loss: 0.302322; batch adversarial loss: 0.519224\n",
      "epoch 55; iter: 0; batch classifier loss: 0.190449; batch adversarial loss: 0.530104\n",
      "epoch 56; iter: 0; batch classifier loss: 0.227615; batch adversarial loss: 0.396563\n",
      "epoch 57; iter: 0; batch classifier loss: 0.263583; batch adversarial loss: 0.480348\n",
      "epoch 58; iter: 0; batch classifier loss: 0.307959; batch adversarial loss: 0.448482\n",
      "epoch 59; iter: 0; batch classifier loss: 0.261708; batch adversarial loss: 0.447980\n",
      "epoch 60; iter: 0; batch classifier loss: 0.221948; batch adversarial loss: 0.399271\n",
      "epoch 61; iter: 0; batch classifier loss: 0.235254; batch adversarial loss: 0.446573\n",
      "epoch 62; iter: 0; batch classifier loss: 0.197738; batch adversarial loss: 0.434894\n",
      "epoch 63; iter: 0; batch classifier loss: 0.167747; batch adversarial loss: 0.483143\n",
      "epoch 64; iter: 0; batch classifier loss: 0.125889; batch adversarial loss: 0.543288\n",
      "epoch 65; iter: 0; batch classifier loss: 0.212413; batch adversarial loss: 0.446049\n",
      "epoch 66; iter: 0; batch classifier loss: 0.226552; batch adversarial loss: 0.433493\n",
      "epoch 67; iter: 0; batch classifier loss: 0.163994; batch adversarial loss: 0.508935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.182944; batch adversarial loss: 0.459861\n",
      "epoch 69; iter: 0; batch classifier loss: 0.162881; batch adversarial loss: 0.459282\n",
      "epoch 70; iter: 0; batch classifier loss: 0.149483; batch adversarial loss: 0.470675\n",
      "epoch 71; iter: 0; batch classifier loss: 0.267863; batch adversarial loss: 0.422539\n",
      "epoch 72; iter: 0; batch classifier loss: 0.191765; batch adversarial loss: 0.434277\n",
      "epoch 73; iter: 0; batch classifier loss: 0.108122; batch adversarial loss: 0.520606\n",
      "epoch 74; iter: 0; batch classifier loss: 0.126681; batch adversarial loss: 0.446316\n",
      "epoch 75; iter: 0; batch classifier loss: 0.204968; batch adversarial loss: 0.458590\n",
      "epoch 76; iter: 0; batch classifier loss: 0.219602; batch adversarial loss: 0.385002\n",
      "epoch 77; iter: 0; batch classifier loss: 0.189693; batch adversarial loss: 0.359618\n",
      "epoch 78; iter: 0; batch classifier loss: 0.247863; batch adversarial loss: 0.556625\n",
      "epoch 79; iter: 0; batch classifier loss: 0.266458; batch adversarial loss: 0.396525\n",
      "epoch 80; iter: 0; batch classifier loss: 0.257919; batch adversarial loss: 0.507144\n",
      "epoch 81; iter: 0; batch classifier loss: 0.204326; batch adversarial loss: 0.520317\n",
      "epoch 82; iter: 0; batch classifier loss: 0.196195; batch adversarial loss: 0.421904\n",
      "epoch 83; iter: 0; batch classifier loss: 0.179444; batch adversarial loss: 0.483986\n",
      "epoch 84; iter: 0; batch classifier loss: 0.192780; batch adversarial loss: 0.434549\n",
      "epoch 85; iter: 0; batch classifier loss: 0.207909; batch adversarial loss: 0.421423\n",
      "epoch 86; iter: 0; batch classifier loss: 0.231089; batch adversarial loss: 0.422251\n",
      "epoch 87; iter: 0; batch classifier loss: 0.210069; batch adversarial loss: 0.458739\n",
      "epoch 88; iter: 0; batch classifier loss: 0.217115; batch adversarial loss: 0.446628\n",
      "epoch 89; iter: 0; batch classifier loss: 0.078522; batch adversarial loss: 0.495051\n",
      "epoch 90; iter: 0; batch classifier loss: 0.121747; batch adversarial loss: 0.394460\n",
      "epoch 91; iter: 0; batch classifier loss: 0.148269; batch adversarial loss: 0.415185\n",
      "epoch 92; iter: 0; batch classifier loss: 0.174973; batch adversarial loss: 0.446652\n",
      "epoch 93; iter: 0; batch classifier loss: 0.143016; batch adversarial loss: 0.519190\n",
      "epoch 94; iter: 0; batch classifier loss: 0.145611; batch adversarial loss: 0.474199\n",
      "epoch 95; iter: 0; batch classifier loss: 0.191572; batch adversarial loss: 0.398795\n",
      "epoch 96; iter: 0; batch classifier loss: 0.237167; batch adversarial loss: 0.458757\n",
      "epoch 97; iter: 0; batch classifier loss: 0.154250; batch adversarial loss: 0.627957\n",
      "epoch 98; iter: 0; batch classifier loss: 0.147205; batch adversarial loss: 0.407136\n",
      "epoch 99; iter: 0; batch classifier loss: 0.156337; batch adversarial loss: 0.508002\n",
      "epoch 100; iter: 0; batch classifier loss: 0.090081; batch adversarial loss: 0.434840\n",
      "epoch 101; iter: 0; batch classifier loss: 0.114783; batch adversarial loss: 0.444237\n",
      "epoch 102; iter: 0; batch classifier loss: 0.091326; batch adversarial loss: 0.490665\n",
      "epoch 103; iter: 0; batch classifier loss: 0.112483; batch adversarial loss: 0.466316\n",
      "epoch 104; iter: 0; batch classifier loss: 0.089292; batch adversarial loss: 0.331154\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064226; batch adversarial loss: 0.504995\n",
      "epoch 106; iter: 0; batch classifier loss: 0.095831; batch adversarial loss: 0.389806\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055150; batch adversarial loss: 0.476430\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044745; batch adversarial loss: 0.462187\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067637; batch adversarial loss: 0.467213\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044815; batch adversarial loss: 0.468828\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051986; batch adversarial loss: 0.466070\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037722; batch adversarial loss: 0.504243\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058326; batch adversarial loss: 0.484903\n",
      "epoch 114; iter: 0; batch classifier loss: 0.087028; batch adversarial loss: 0.447749\n",
      "epoch 115; iter: 0; batch classifier loss: 0.075494; batch adversarial loss: 0.414045\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043625; batch adversarial loss: 0.395861\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029896; batch adversarial loss: 0.479520\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043517; batch adversarial loss: 0.515215\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065060; batch adversarial loss: 0.348228\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033734; batch adversarial loss: 0.472763\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028579; batch adversarial loss: 0.403805\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032724; batch adversarial loss: 0.462460\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044226; batch adversarial loss: 0.436516\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032709; batch adversarial loss: 0.480544\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048711; batch adversarial loss: 0.414067\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044525; batch adversarial loss: 0.424184\n",
      "epoch 127; iter: 0; batch classifier loss: 0.055743; batch adversarial loss: 0.472001\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063910; batch adversarial loss: 0.368475\n",
      "epoch 129; iter: 0; batch classifier loss: 0.014372; batch adversarial loss: 0.489254\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032495; batch adversarial loss: 0.411651\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030643; batch adversarial loss: 0.399589\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053602; batch adversarial loss: 0.525870\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027827; batch adversarial loss: 0.469451\n",
      "epoch 134; iter: 0; batch classifier loss: 0.093079; batch adversarial loss: 0.510519\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049716; batch adversarial loss: 0.392864\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038546; batch adversarial loss: 0.429224\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024632; batch adversarial loss: 0.366982\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041847; batch adversarial loss: 0.358605\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016632; batch adversarial loss: 0.473297\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045008; batch adversarial loss: 0.449671\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044249; batch adversarial loss: 0.534861\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039038; batch adversarial loss: 0.477258\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023336; batch adversarial loss: 0.408541\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014343; batch adversarial loss: 0.465894\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019075; batch adversarial loss: 0.422788\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021550; batch adversarial loss: 0.424822\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039792; batch adversarial loss: 0.409901\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035235; batch adversarial loss: 0.476899\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029685; batch adversarial loss: 0.499218\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033276; batch adversarial loss: 0.516015\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013841; batch adversarial loss: 0.485013\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028486; batch adversarial loss: 0.482397\n",
      "epoch 153; iter: 0; batch classifier loss: 0.006731; batch adversarial loss: 0.451830\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014835; batch adversarial loss: 0.492964\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018900; batch adversarial loss: 0.501853\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019978; batch adversarial loss: 0.455170\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029652; batch adversarial loss: 0.537162\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023346; batch adversarial loss: 0.547562\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017872; batch adversarial loss: 0.473527\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036864; batch adversarial loss: 0.447762\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012055; batch adversarial loss: 0.430069\n",
      "epoch 162; iter: 0; batch classifier loss: 0.005067; batch adversarial loss: 0.532663\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009953; batch adversarial loss: 0.432910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.015778; batch adversarial loss: 0.397662\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015981; batch adversarial loss: 0.386322\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019471; batch adversarial loss: 0.490355\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041994; batch adversarial loss: 0.340504\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028520; batch adversarial loss: 0.447077\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021638; batch adversarial loss: 0.422124\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025153; batch adversarial loss: 0.404348\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012634; batch adversarial loss: 0.407418\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008938; batch adversarial loss: 0.398939\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015167; batch adversarial loss: 0.418515\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016551; batch adversarial loss: 0.486725\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030636; batch adversarial loss: 0.463812\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008908; batch adversarial loss: 0.475500\n",
      "epoch 177; iter: 0; batch classifier loss: 0.004345; batch adversarial loss: 0.431410\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011552; batch adversarial loss: 0.462328\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008405; batch adversarial loss: 0.478523\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037198; batch adversarial loss: 0.436980\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012707; batch adversarial loss: 0.411832\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009939; batch adversarial loss: 0.445564\n",
      "epoch 183; iter: 0; batch classifier loss: 0.048397; batch adversarial loss: 0.347343\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018170; batch adversarial loss: 0.484498\n",
      "epoch 185; iter: 0; batch classifier loss: 0.064906; batch adversarial loss: 0.454766\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020515; batch adversarial loss: 0.431700\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015560; batch adversarial loss: 0.473881\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010370; batch adversarial loss: 0.407902\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008696; batch adversarial loss: 0.422120\n",
      "epoch 190; iter: 0; batch classifier loss: 0.033423; batch adversarial loss: 0.360142\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037756; batch adversarial loss: 0.426262\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030935; batch adversarial loss: 0.489391\n",
      "epoch 193; iter: 0; batch classifier loss: 0.040803; batch adversarial loss: 0.524349\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008813; batch adversarial loss: 0.516411\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005004; batch adversarial loss: 0.436195\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017565; batch adversarial loss: 0.353410\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021414; batch adversarial loss: 0.487374\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008241; batch adversarial loss: 0.412583\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016528; batch adversarial loss: 0.481096\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726238; batch adversarial loss: 0.618326\n",
      "epoch 1; iter: 0; batch classifier loss: 0.468991; batch adversarial loss: 0.591377\n",
      "epoch 2; iter: 0; batch classifier loss: 0.380793; batch adversarial loss: 0.624849\n",
      "epoch 3; iter: 0; batch classifier loss: 0.348132; batch adversarial loss: 0.594635\n",
      "epoch 4; iter: 0; batch classifier loss: 0.375068; batch adversarial loss: 0.585756\n",
      "epoch 5; iter: 0; batch classifier loss: 0.381405; batch adversarial loss: 0.570754\n",
      "epoch 6; iter: 0; batch classifier loss: 0.364917; batch adversarial loss: 0.590645\n",
      "epoch 7; iter: 0; batch classifier loss: 0.421080; batch adversarial loss: 0.598058\n",
      "epoch 8; iter: 0; batch classifier loss: 0.403074; batch adversarial loss: 0.577725\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565305; batch adversarial loss: 0.612005\n",
      "epoch 10; iter: 0; batch classifier loss: 0.531483; batch adversarial loss: 0.550042\n",
      "epoch 11; iter: 0; batch classifier loss: 0.409247; batch adversarial loss: 0.514149\n",
      "epoch 12; iter: 0; batch classifier loss: 0.374079; batch adversarial loss: 0.505459\n",
      "epoch 13; iter: 0; batch classifier loss: 0.369413; batch adversarial loss: 0.498577\n",
      "epoch 14; iter: 0; batch classifier loss: 0.235394; batch adversarial loss: 0.483715\n",
      "epoch 15; iter: 0; batch classifier loss: 0.310843; batch adversarial loss: 0.499193\n",
      "epoch 16; iter: 0; batch classifier loss: 0.323726; batch adversarial loss: 0.416332\n",
      "epoch 17; iter: 0; batch classifier loss: 0.264705; batch adversarial loss: 0.428673\n",
      "epoch 18; iter: 0; batch classifier loss: 0.327746; batch adversarial loss: 0.482217\n",
      "epoch 19; iter: 0; batch classifier loss: 0.218266; batch adversarial loss: 0.427656\n",
      "epoch 20; iter: 0; batch classifier loss: 0.304547; batch adversarial loss: 0.456421\n",
      "epoch 21; iter: 0; batch classifier loss: 0.249646; batch adversarial loss: 0.490360\n",
      "epoch 22; iter: 0; batch classifier loss: 0.178153; batch adversarial loss: 0.563972\n",
      "epoch 23; iter: 0; batch classifier loss: 0.228071; batch adversarial loss: 0.469009\n",
      "epoch 24; iter: 0; batch classifier loss: 0.250092; batch adversarial loss: 0.472155\n",
      "epoch 25; iter: 0; batch classifier loss: 0.123780; batch adversarial loss: 0.464076\n",
      "epoch 26; iter: 0; batch classifier loss: 0.197030; batch adversarial loss: 0.452537\n",
      "epoch 27; iter: 0; batch classifier loss: 0.193369; batch adversarial loss: 0.509891\n",
      "epoch 28; iter: 0; batch classifier loss: 0.200759; batch adversarial loss: 0.470526\n",
      "epoch 29; iter: 0; batch classifier loss: 0.187888; batch adversarial loss: 0.468725\n",
      "epoch 30; iter: 0; batch classifier loss: 0.194379; batch adversarial loss: 0.415848\n",
      "epoch 31; iter: 0; batch classifier loss: 0.191553; batch adversarial loss: 0.442489\n",
      "epoch 32; iter: 0; batch classifier loss: 0.167788; batch adversarial loss: 0.525695\n",
      "epoch 33; iter: 0; batch classifier loss: 0.131733; batch adversarial loss: 0.433078\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148978; batch adversarial loss: 0.533379\n",
      "epoch 35; iter: 0; batch classifier loss: 0.151319; batch adversarial loss: 0.411073\n",
      "epoch 36; iter: 0; batch classifier loss: 0.157613; batch adversarial loss: 0.367124\n",
      "epoch 37; iter: 0; batch classifier loss: 0.144771; batch adversarial loss: 0.436228\n",
      "epoch 38; iter: 0; batch classifier loss: 0.149812; batch adversarial loss: 0.353886\n",
      "epoch 39; iter: 0; batch classifier loss: 0.141933; batch adversarial loss: 0.481753\n",
      "epoch 40; iter: 0; batch classifier loss: 0.205812; batch adversarial loss: 0.395226\n",
      "epoch 41; iter: 0; batch classifier loss: 0.150042; batch adversarial loss: 0.574160\n",
      "epoch 42; iter: 0; batch classifier loss: 0.139190; batch adversarial loss: 0.527702\n",
      "epoch 43; iter: 0; batch classifier loss: 0.136956; batch adversarial loss: 0.383286\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119844; batch adversarial loss: 0.499671\n",
      "epoch 45; iter: 0; batch classifier loss: 0.136143; batch adversarial loss: 0.524685\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116688; batch adversarial loss: 0.437962\n",
      "epoch 47; iter: 0; batch classifier loss: 0.115698; batch adversarial loss: 0.437796\n",
      "epoch 48; iter: 0; batch classifier loss: 0.071428; batch adversarial loss: 0.435846\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080764; batch adversarial loss: 0.541848\n",
      "epoch 50; iter: 0; batch classifier loss: 0.130897; batch adversarial loss: 0.436227\n",
      "epoch 51; iter: 0; batch classifier loss: 0.104959; batch adversarial loss: 0.473373\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100697; batch adversarial loss: 0.468576\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122173; batch adversarial loss: 0.359935\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095173; batch adversarial loss: 0.504901\n",
      "epoch 55; iter: 0; batch classifier loss: 0.097839; batch adversarial loss: 0.509061\n",
      "epoch 56; iter: 0; batch classifier loss: 0.061718; batch adversarial loss: 0.517042\n",
      "epoch 57; iter: 0; batch classifier loss: 0.077385; batch adversarial loss: 0.418475\n",
      "epoch 58; iter: 0; batch classifier loss: 0.091156; batch adversarial loss: 0.549699\n",
      "epoch 59; iter: 0; batch classifier loss: 0.098611; batch adversarial loss: 0.410133\n",
      "epoch 60; iter: 0; batch classifier loss: 0.067065; batch adversarial loss: 0.508070\n",
      "epoch 61; iter: 0; batch classifier loss: 0.091592; batch adversarial loss: 0.510332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.069072; batch adversarial loss: 0.461720\n",
      "epoch 63; iter: 0; batch classifier loss: 0.118617; batch adversarial loss: 0.486107\n",
      "epoch 64; iter: 0; batch classifier loss: 0.058664; batch adversarial loss: 0.432741\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088627; batch adversarial loss: 0.427051\n",
      "epoch 66; iter: 0; batch classifier loss: 0.100931; batch adversarial loss: 0.364329\n",
      "epoch 67; iter: 0; batch classifier loss: 0.055425; batch adversarial loss: 0.366190\n",
      "epoch 68; iter: 0; batch classifier loss: 0.077314; batch adversarial loss: 0.524159\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061940; batch adversarial loss: 0.417469\n",
      "epoch 70; iter: 0; batch classifier loss: 0.061120; batch adversarial loss: 0.595107\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079887; batch adversarial loss: 0.391440\n",
      "epoch 72; iter: 0; batch classifier loss: 0.084184; batch adversarial loss: 0.445811\n",
      "epoch 73; iter: 0; batch classifier loss: 0.049910; batch adversarial loss: 0.450580\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067204; batch adversarial loss: 0.487021\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096123; batch adversarial loss: 0.566030\n",
      "epoch 76; iter: 0; batch classifier loss: 0.066436; batch adversarial loss: 0.412893\n",
      "epoch 77; iter: 0; batch classifier loss: 0.090193; batch adversarial loss: 0.387296\n",
      "epoch 78; iter: 0; batch classifier loss: 0.087608; batch adversarial loss: 0.437702\n",
      "epoch 79; iter: 0; batch classifier loss: 0.047504; batch adversarial loss: 0.476678\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056322; batch adversarial loss: 0.476068\n",
      "epoch 81; iter: 0; batch classifier loss: 0.063397; batch adversarial loss: 0.382586\n",
      "epoch 82; iter: 0; batch classifier loss: 0.076613; batch adversarial loss: 0.475948\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063476; batch adversarial loss: 0.386054\n",
      "epoch 84; iter: 0; batch classifier loss: 0.078293; batch adversarial loss: 0.460528\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073743; batch adversarial loss: 0.499328\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070103; batch adversarial loss: 0.434441\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073619; batch adversarial loss: 0.393457\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070740; batch adversarial loss: 0.506413\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057845; batch adversarial loss: 0.484257\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052953; batch adversarial loss: 0.465145\n",
      "epoch 91; iter: 0; batch classifier loss: 0.035434; batch adversarial loss: 0.432473\n",
      "epoch 92; iter: 0; batch classifier loss: 0.040825; batch adversarial loss: 0.592929\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067353; batch adversarial loss: 0.422974\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049217; batch adversarial loss: 0.432023\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070196; batch adversarial loss: 0.365209\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096848; batch adversarial loss: 0.398366\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039446; batch adversarial loss: 0.407402\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051459; batch adversarial loss: 0.452617\n",
      "epoch 99; iter: 0; batch classifier loss: 0.028829; batch adversarial loss: 0.500171\n",
      "epoch 100; iter: 0; batch classifier loss: 0.095228; batch adversarial loss: 0.398365\n",
      "epoch 101; iter: 0; batch classifier loss: 0.064404; batch adversarial loss: 0.461126\n",
      "epoch 102; iter: 0; batch classifier loss: 0.039024; batch adversarial loss: 0.491744\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044285; batch adversarial loss: 0.567314\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044821; batch adversarial loss: 0.488411\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056699; batch adversarial loss: 0.429654\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044107; batch adversarial loss: 0.377658\n",
      "epoch 107; iter: 0; batch classifier loss: 0.023531; batch adversarial loss: 0.434475\n",
      "epoch 108; iter: 0; batch classifier loss: 0.024491; batch adversarial loss: 0.416073\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057063; batch adversarial loss: 0.436877\n",
      "epoch 110; iter: 0; batch classifier loss: 0.076872; batch adversarial loss: 0.442545\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042539; batch adversarial loss: 0.470136\n",
      "epoch 112; iter: 0; batch classifier loss: 0.017455; batch adversarial loss: 0.559335\n",
      "epoch 113; iter: 0; batch classifier loss: 0.021437; batch adversarial loss: 0.446578\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044741; batch adversarial loss: 0.449118\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043880; batch adversarial loss: 0.391808\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036344; batch adversarial loss: 0.386563\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040167; batch adversarial loss: 0.399468\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024288; batch adversarial loss: 0.479815\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023691; batch adversarial loss: 0.458510\n",
      "epoch 120; iter: 0; batch classifier loss: 0.012925; batch adversarial loss: 0.471173\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035140; batch adversarial loss: 0.578354\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036805; batch adversarial loss: 0.363912\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025399; batch adversarial loss: 0.468352\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032863; batch adversarial loss: 0.400703\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051736; batch adversarial loss: 0.459643\n",
      "epoch 126; iter: 0; batch classifier loss: 0.018272; batch adversarial loss: 0.494223\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024944; batch adversarial loss: 0.536013\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027537; batch adversarial loss: 0.478840\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059551; batch adversarial loss: 0.509199\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028216; batch adversarial loss: 0.421577\n",
      "epoch 131; iter: 0; batch classifier loss: 0.082405; batch adversarial loss: 0.499439\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025504; batch adversarial loss: 0.467251\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020168; batch adversarial loss: 0.437493\n",
      "epoch 134; iter: 0; batch classifier loss: 0.009062; batch adversarial loss: 0.372263\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026890; batch adversarial loss: 0.510794\n",
      "epoch 136; iter: 0; batch classifier loss: 0.050686; batch adversarial loss: 0.532026\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038537; batch adversarial loss: 0.532898\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032752; batch adversarial loss: 0.403985\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032126; batch adversarial loss: 0.395285\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028372; batch adversarial loss: 0.416137\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021232; batch adversarial loss: 0.493534\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039771; batch adversarial loss: 0.428348\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036458; batch adversarial loss: 0.535562\n",
      "epoch 144; iter: 0; batch classifier loss: 0.035811; batch adversarial loss: 0.416898\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022802; batch adversarial loss: 0.498344\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022164; batch adversarial loss: 0.351877\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036574; batch adversarial loss: 0.373557\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015612; batch adversarial loss: 0.471669\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031315; batch adversarial loss: 0.530467\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022572; batch adversarial loss: 0.459131\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025411; batch adversarial loss: 0.385329\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037620; batch adversarial loss: 0.425400\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018621; batch adversarial loss: 0.368954\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030099; batch adversarial loss: 0.518306\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033640; batch adversarial loss: 0.378370\n",
      "epoch 156; iter: 0; batch classifier loss: 0.058083; batch adversarial loss: 0.436175\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042272; batch adversarial loss: 0.401522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.064319; batch adversarial loss: 0.420988\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010976; batch adversarial loss: 0.407957\n",
      "epoch 160; iter: 0; batch classifier loss: 0.045364; batch adversarial loss: 0.415753\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020752; batch adversarial loss: 0.485744\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026250; batch adversarial loss: 0.385110\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036196; batch adversarial loss: 0.500943\n",
      "epoch 164; iter: 0; batch classifier loss: 0.048768; batch adversarial loss: 0.498833\n",
      "epoch 165; iter: 0; batch classifier loss: 0.007689; batch adversarial loss: 0.441856\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011089; batch adversarial loss: 0.464986\n",
      "epoch 167; iter: 0; batch classifier loss: 0.040571; batch adversarial loss: 0.460123\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024743; batch adversarial loss: 0.467588\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019738; batch adversarial loss: 0.372176\n",
      "epoch 170; iter: 0; batch classifier loss: 0.036729; batch adversarial loss: 0.443568\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014836; batch adversarial loss: 0.450755\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008825; batch adversarial loss: 0.407970\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040063; batch adversarial loss: 0.431401\n",
      "epoch 174; iter: 0; batch classifier loss: 0.045878; batch adversarial loss: 0.573173\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022414; batch adversarial loss: 0.394020\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010966; batch adversarial loss: 0.568173\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010753; batch adversarial loss: 0.393435\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022285; batch adversarial loss: 0.434366\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013691; batch adversarial loss: 0.498237\n",
      "epoch 180; iter: 0; batch classifier loss: 0.044297; batch adversarial loss: 0.380087\n",
      "epoch 181; iter: 0; batch classifier loss: 0.082025; batch adversarial loss: 0.342917\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033457; batch adversarial loss: 0.477430\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020761; batch adversarial loss: 0.393848\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012635; batch adversarial loss: 0.447303\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020813; batch adversarial loss: 0.405817\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023294; batch adversarial loss: 0.468101\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032981; batch adversarial loss: 0.476483\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033561; batch adversarial loss: 0.400204\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027511; batch adversarial loss: 0.441953\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017438; batch adversarial loss: 0.457260\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010231; batch adversarial loss: 0.394493\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019037; batch adversarial loss: 0.466360\n",
      "epoch 193; iter: 0; batch classifier loss: 0.036922; batch adversarial loss: 0.392759\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021209; batch adversarial loss: 0.460724\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014845; batch adversarial loss: 0.443437\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005020; batch adversarial loss: 0.383047\n",
      "epoch 197; iter: 0; batch classifier loss: 0.042215; batch adversarial loss: 0.387883\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030488; batch adversarial loss: 0.366081\n",
      "epoch 199; iter: 0; batch classifier loss: 0.029969; batch adversarial loss: 0.456076\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709550; batch adversarial loss: 0.695769\n",
      "epoch 1; iter: 0; batch classifier loss: 0.488106; batch adversarial loss: 0.692702\n",
      "epoch 2; iter: 0; batch classifier loss: 0.449654; batch adversarial loss: 0.653865\n",
      "epoch 3; iter: 0; batch classifier loss: 0.370893; batch adversarial loss: 0.640073\n",
      "epoch 4; iter: 0; batch classifier loss: 0.357051; batch adversarial loss: 0.595020\n",
      "epoch 5; iter: 0; batch classifier loss: 0.255133; batch adversarial loss: 0.607535\n",
      "epoch 6; iter: 0; batch classifier loss: 0.353701; batch adversarial loss: 0.504262\n",
      "epoch 7; iter: 0; batch classifier loss: 0.264717; batch adversarial loss: 0.533148\n",
      "epoch 8; iter: 0; batch classifier loss: 0.245295; batch adversarial loss: 0.507672\n",
      "epoch 9; iter: 0; batch classifier loss: 0.251420; batch adversarial loss: 0.482857\n",
      "epoch 10; iter: 0; batch classifier loss: 0.291456; batch adversarial loss: 0.491794\n",
      "epoch 11; iter: 0; batch classifier loss: 0.183159; batch adversarial loss: 0.453262\n",
      "epoch 12; iter: 0; batch classifier loss: 0.245510; batch adversarial loss: 0.480470\n",
      "epoch 13; iter: 0; batch classifier loss: 0.182028; batch adversarial loss: 0.461350\n",
      "epoch 14; iter: 0; batch classifier loss: 0.163145; batch adversarial loss: 0.431413\n",
      "epoch 15; iter: 0; batch classifier loss: 0.130984; batch adversarial loss: 0.429771\n",
      "epoch 16; iter: 0; batch classifier loss: 0.184277; batch adversarial loss: 0.421732\n",
      "epoch 17; iter: 0; batch classifier loss: 0.201795; batch adversarial loss: 0.487267\n",
      "epoch 18; iter: 0; batch classifier loss: 0.114898; batch adversarial loss: 0.436241\n",
      "epoch 19; iter: 0; batch classifier loss: 0.140658; batch adversarial loss: 0.459651\n",
      "epoch 20; iter: 0; batch classifier loss: 0.145531; batch adversarial loss: 0.450827\n",
      "epoch 21; iter: 0; batch classifier loss: 0.118169; batch adversarial loss: 0.507031\n",
      "epoch 22; iter: 0; batch classifier loss: 0.128217; batch adversarial loss: 0.499287\n",
      "epoch 23; iter: 0; batch classifier loss: 0.133808; batch adversarial loss: 0.473415\n",
      "epoch 24; iter: 0; batch classifier loss: 0.110202; batch adversarial loss: 0.473755\n",
      "epoch 25; iter: 0; batch classifier loss: 0.163540; batch adversarial loss: 0.439563\n",
      "epoch 26; iter: 0; batch classifier loss: 0.136096; batch adversarial loss: 0.469669\n",
      "epoch 27; iter: 0; batch classifier loss: 0.150621; batch adversarial loss: 0.441947\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184574; batch adversarial loss: 0.560610\n",
      "epoch 29; iter: 0; batch classifier loss: 0.143756; batch adversarial loss: 0.550334\n",
      "epoch 30; iter: 0; batch classifier loss: 0.104899; batch adversarial loss: 0.509233\n",
      "epoch 31; iter: 0; batch classifier loss: 0.172446; batch adversarial loss: 0.459295\n",
      "epoch 32; iter: 0; batch classifier loss: 0.224690; batch adversarial loss: 0.557808\n",
      "epoch 33; iter: 0; batch classifier loss: 0.155564; batch adversarial loss: 0.614288\n",
      "epoch 34; iter: 0; batch classifier loss: 0.184674; batch adversarial loss: 0.509425\n",
      "epoch 35; iter: 0; batch classifier loss: 0.155206; batch adversarial loss: 0.494245\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141728; batch adversarial loss: 0.458737\n",
      "epoch 37; iter: 0; batch classifier loss: 0.167025; batch adversarial loss: 0.447141\n",
      "epoch 38; iter: 0; batch classifier loss: 0.121137; batch adversarial loss: 0.460546\n",
      "epoch 39; iter: 0; batch classifier loss: 0.173371; batch adversarial loss: 0.475398\n",
      "epoch 40; iter: 0; batch classifier loss: 0.173932; batch adversarial loss: 0.503656\n",
      "epoch 41; iter: 0; batch classifier loss: 0.200115; batch adversarial loss: 0.487215\n",
      "epoch 42; iter: 0; batch classifier loss: 0.236352; batch adversarial loss: 0.426484\n",
      "epoch 43; iter: 0; batch classifier loss: 0.193445; batch adversarial loss: 0.463463\n",
      "epoch 44; iter: 0; batch classifier loss: 0.092650; batch adversarial loss: 0.453720\n",
      "epoch 45; iter: 0; batch classifier loss: 0.082660; batch adversarial loss: 0.501698\n",
      "epoch 46; iter: 0; batch classifier loss: 0.073779; batch adversarial loss: 0.472903\n",
      "epoch 47; iter: 0; batch classifier loss: 0.073006; batch adversarial loss: 0.453813\n",
      "epoch 48; iter: 0; batch classifier loss: 0.133115; batch adversarial loss: 0.339121\n",
      "epoch 49; iter: 0; batch classifier loss: 0.093090; batch adversarial loss: 0.459607\n",
      "epoch 50; iter: 0; batch classifier loss: 0.101350; batch adversarial loss: 0.476102\n",
      "epoch 51; iter: 0; batch classifier loss: 0.064304; batch adversarial loss: 0.475584\n",
      "epoch 52; iter: 0; batch classifier loss: 0.092102; batch adversarial loss: 0.465379\n",
      "epoch 53; iter: 0; batch classifier loss: 0.050811; batch adversarial loss: 0.531410\n",
      "epoch 54; iter: 0; batch classifier loss: 0.068769; batch adversarial loss: 0.495422\n",
      "epoch 55; iter: 0; batch classifier loss: 0.073251; batch adversarial loss: 0.456742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.064859; batch adversarial loss: 0.526266\n",
      "epoch 57; iter: 0; batch classifier loss: 0.057534; batch adversarial loss: 0.523153\n",
      "epoch 58; iter: 0; batch classifier loss: 0.081072; batch adversarial loss: 0.462030\n",
      "epoch 59; iter: 0; batch classifier loss: 0.085067; batch adversarial loss: 0.378518\n",
      "epoch 60; iter: 0; batch classifier loss: 0.049247; batch adversarial loss: 0.392825\n",
      "epoch 61; iter: 0; batch classifier loss: 0.051568; batch adversarial loss: 0.524251\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084046; batch adversarial loss: 0.485852\n",
      "epoch 63; iter: 0; batch classifier loss: 0.029725; batch adversarial loss: 0.488988\n",
      "epoch 64; iter: 0; batch classifier loss: 0.112019; batch adversarial loss: 0.433727\n",
      "epoch 65; iter: 0; batch classifier loss: 0.043626; batch adversarial loss: 0.429812\n",
      "epoch 66; iter: 0; batch classifier loss: 0.100222; batch adversarial loss: 0.457193\n",
      "epoch 67; iter: 0; batch classifier loss: 0.057330; batch adversarial loss: 0.477773\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071853; batch adversarial loss: 0.388762\n",
      "epoch 69; iter: 0; batch classifier loss: 0.097344; batch adversarial loss: 0.456072\n",
      "epoch 70; iter: 0; batch classifier loss: 0.128989; batch adversarial loss: 0.403444\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104539; batch adversarial loss: 0.433633\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077352; batch adversarial loss: 0.478120\n",
      "epoch 73; iter: 0; batch classifier loss: 0.043663; batch adversarial loss: 0.437402\n",
      "epoch 74; iter: 0; batch classifier loss: 0.073157; batch adversarial loss: 0.413136\n",
      "epoch 75; iter: 0; batch classifier loss: 0.074310; batch adversarial loss: 0.412616\n",
      "epoch 76; iter: 0; batch classifier loss: 0.107179; batch adversarial loss: 0.436376\n",
      "epoch 77; iter: 0; batch classifier loss: 0.127075; batch adversarial loss: 0.465534\n",
      "epoch 78; iter: 0; batch classifier loss: 0.087498; batch adversarial loss: 0.380083\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076047; batch adversarial loss: 0.382440\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078488; batch adversarial loss: 0.464831\n",
      "epoch 81; iter: 0; batch classifier loss: 0.080334; batch adversarial loss: 0.426820\n",
      "epoch 82; iter: 0; batch classifier loss: 0.080961; batch adversarial loss: 0.453178\n",
      "epoch 83; iter: 0; batch classifier loss: 0.082209; batch adversarial loss: 0.414709\n",
      "epoch 84; iter: 0; batch classifier loss: 0.050561; batch adversarial loss: 0.450307\n",
      "epoch 85; iter: 0; batch classifier loss: 0.081690; batch adversarial loss: 0.510609\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069808; batch adversarial loss: 0.441150\n",
      "epoch 87; iter: 0; batch classifier loss: 0.123019; batch adversarial loss: 0.348144\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055621; batch adversarial loss: 0.456830\n",
      "epoch 89; iter: 0; batch classifier loss: 0.064432; batch adversarial loss: 0.496743\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075142; batch adversarial loss: 0.523311\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077002; batch adversarial loss: 0.496119\n",
      "epoch 92; iter: 0; batch classifier loss: 0.054414; batch adversarial loss: 0.382431\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046087; batch adversarial loss: 0.394939\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049599; batch adversarial loss: 0.434884\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073482; batch adversarial loss: 0.438171\n",
      "epoch 96; iter: 0; batch classifier loss: 0.072693; batch adversarial loss: 0.358848\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072637; batch adversarial loss: 0.406352\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042416; batch adversarial loss: 0.460083\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055623; batch adversarial loss: 0.484697\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048607; batch adversarial loss: 0.485520\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062016; batch adversarial loss: 0.540079\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056215; batch adversarial loss: 0.480262\n",
      "epoch 103; iter: 0; batch classifier loss: 0.112114; batch adversarial loss: 0.455429\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071972; batch adversarial loss: 0.405277\n",
      "epoch 105; iter: 0; batch classifier loss: 0.126290; batch adversarial loss: 0.444292\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049881; batch adversarial loss: 0.442591\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069025; batch adversarial loss: 0.477095\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060581; batch adversarial loss: 0.378594\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058662; batch adversarial loss: 0.526095\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047137; batch adversarial loss: 0.469772\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039136; batch adversarial loss: 0.405598\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025900; batch adversarial loss: 0.459702\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045589; batch adversarial loss: 0.470826\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047549; batch adversarial loss: 0.428485\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048889; batch adversarial loss: 0.376349\n",
      "epoch 116; iter: 0; batch classifier loss: 0.058803; batch adversarial loss: 0.406537\n",
      "epoch 117; iter: 0; batch classifier loss: 0.070194; batch adversarial loss: 0.394073\n",
      "epoch 118; iter: 0; batch classifier loss: 0.062212; batch adversarial loss: 0.390819\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047470; batch adversarial loss: 0.455405\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040285; batch adversarial loss: 0.478368\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053878; batch adversarial loss: 0.532174\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031670; batch adversarial loss: 0.476267\n",
      "epoch 123; iter: 0; batch classifier loss: 0.077912; batch adversarial loss: 0.460704\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046559; batch adversarial loss: 0.494503\n",
      "epoch 125; iter: 0; batch classifier loss: 0.067732; batch adversarial loss: 0.476528\n",
      "epoch 126; iter: 0; batch classifier loss: 0.058117; batch adversarial loss: 0.481434\n",
      "epoch 127; iter: 0; batch classifier loss: 0.054043; batch adversarial loss: 0.395362\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049175; batch adversarial loss: 0.429225\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027105; batch adversarial loss: 0.469156\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035909; batch adversarial loss: 0.493261\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017739; batch adversarial loss: 0.488365\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037929; batch adversarial loss: 0.506920\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053582; batch adversarial loss: 0.410396\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062510; batch adversarial loss: 0.414181\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030525; batch adversarial loss: 0.509673\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021997; batch adversarial loss: 0.415500\n",
      "epoch 137; iter: 0; batch classifier loss: 0.070664; batch adversarial loss: 0.446280\n",
      "epoch 138; iter: 0; batch classifier loss: 0.058494; batch adversarial loss: 0.568077\n",
      "epoch 139; iter: 0; batch classifier loss: 0.063538; batch adversarial loss: 0.425945\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037569; batch adversarial loss: 0.397268\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031863; batch adversarial loss: 0.477880\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035889; batch adversarial loss: 0.541677\n",
      "epoch 143; iter: 0; batch classifier loss: 0.063089; batch adversarial loss: 0.424407\n",
      "epoch 144; iter: 0; batch classifier loss: 0.023983; batch adversarial loss: 0.417779\n",
      "epoch 145; iter: 0; batch classifier loss: 0.053665; batch adversarial loss: 0.444622\n",
      "epoch 146; iter: 0; batch classifier loss: 0.092370; batch adversarial loss: 0.352190\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021857; batch adversarial loss: 0.462174\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035320; batch adversarial loss: 0.381608\n",
      "epoch 149; iter: 0; batch classifier loss: 0.050038; batch adversarial loss: 0.421164\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033173; batch adversarial loss: 0.397066\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024881; batch adversarial loss: 0.423447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.040052; batch adversarial loss: 0.533710\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029978; batch adversarial loss: 0.429434\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016694; batch adversarial loss: 0.516704\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040999; batch adversarial loss: 0.463486\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011282; batch adversarial loss: 0.461627\n",
      "epoch 157; iter: 0; batch classifier loss: 0.045315; batch adversarial loss: 0.460922\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025382; batch adversarial loss: 0.529139\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023043; batch adversarial loss: 0.433772\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030905; batch adversarial loss: 0.559286\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022032; batch adversarial loss: 0.428109\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025925; batch adversarial loss: 0.458195\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025011; batch adversarial loss: 0.495699\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028038; batch adversarial loss: 0.367932\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019472; batch adversarial loss: 0.495653\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015957; batch adversarial loss: 0.435716\n",
      "epoch 167; iter: 0; batch classifier loss: 0.004743; batch adversarial loss: 0.537750\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013114; batch adversarial loss: 0.445997\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035480; batch adversarial loss: 0.463821\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021517; batch adversarial loss: 0.447814\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014037; batch adversarial loss: 0.527832\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040769; batch adversarial loss: 0.457999\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029287; batch adversarial loss: 0.414823\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041998; batch adversarial loss: 0.473237\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012580; batch adversarial loss: 0.469711\n",
      "epoch 176; iter: 0; batch classifier loss: 0.002341; batch adversarial loss: 0.465308\n",
      "epoch 177; iter: 0; batch classifier loss: 0.007879; batch adversarial loss: 0.501910\n",
      "epoch 178; iter: 0; batch classifier loss: 0.049810; batch adversarial loss: 0.375725\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019177; batch adversarial loss: 0.431066\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014941; batch adversarial loss: 0.392884\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030452; batch adversarial loss: 0.507768\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025682; batch adversarial loss: 0.403039\n",
      "epoch 183; iter: 0; batch classifier loss: 0.003283; batch adversarial loss: 0.468122\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012426; batch adversarial loss: 0.384888\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011993; batch adversarial loss: 0.444825\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040006; batch adversarial loss: 0.440089\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027014; batch adversarial loss: 0.433805\n",
      "epoch 188; iter: 0; batch classifier loss: 0.067440; batch adversarial loss: 0.454801\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034045; batch adversarial loss: 0.441770\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026561; batch adversarial loss: 0.455905\n",
      "epoch 191; iter: 0; batch classifier loss: 0.057231; batch adversarial loss: 0.415794\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018591; batch adversarial loss: 0.530978\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005694; batch adversarial loss: 0.430863\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022112; batch adversarial loss: 0.435812\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014638; batch adversarial loss: 0.464252\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006592; batch adversarial loss: 0.463133\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011171; batch adversarial loss: 0.398832\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012103; batch adversarial loss: 0.373847\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012355; batch adversarial loss: 0.471291\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708052; batch adversarial loss: 0.596744\n",
      "epoch 1; iter: 0; batch classifier loss: 0.441573; batch adversarial loss: 0.626715\n",
      "epoch 2; iter: 0; batch classifier loss: 0.388349; batch adversarial loss: 0.595675\n",
      "epoch 3; iter: 0; batch classifier loss: 0.444522; batch adversarial loss: 0.575129\n",
      "epoch 4; iter: 0; batch classifier loss: 0.504799; batch adversarial loss: 0.589795\n",
      "epoch 5; iter: 0; batch classifier loss: 0.456351; batch adversarial loss: 0.509499\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340223; batch adversarial loss: 0.578593\n",
      "epoch 7; iter: 0; batch classifier loss: 0.318520; batch adversarial loss: 0.535942\n",
      "epoch 8; iter: 0; batch classifier loss: 0.402076; batch adversarial loss: 0.558904\n",
      "epoch 9; iter: 0; batch classifier loss: 0.367074; batch adversarial loss: 0.502956\n",
      "epoch 10; iter: 0; batch classifier loss: 0.491911; batch adversarial loss: 0.527934\n",
      "epoch 11; iter: 0; batch classifier loss: 0.453888; batch adversarial loss: 0.453953\n",
      "epoch 12; iter: 0; batch classifier loss: 0.345789; batch adversarial loss: 0.480784\n",
      "epoch 13; iter: 0; batch classifier loss: 0.391442; batch adversarial loss: 0.524301\n",
      "epoch 14; iter: 0; batch classifier loss: 0.355702; batch adversarial loss: 0.518900\n",
      "epoch 15; iter: 0; batch classifier loss: 0.333667; batch adversarial loss: 0.491144\n",
      "epoch 16; iter: 0; batch classifier loss: 0.237822; batch adversarial loss: 0.429064\n",
      "epoch 17; iter: 0; batch classifier loss: 0.316390; batch adversarial loss: 0.507155\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197245; batch adversarial loss: 0.523697\n",
      "epoch 19; iter: 0; batch classifier loss: 0.350379; batch adversarial loss: 0.458740\n",
      "epoch 20; iter: 0; batch classifier loss: 0.189298; batch adversarial loss: 0.471899\n",
      "epoch 21; iter: 0; batch classifier loss: 0.275180; batch adversarial loss: 0.437868\n",
      "epoch 22; iter: 0; batch classifier loss: 0.232503; batch adversarial loss: 0.507942\n",
      "epoch 23; iter: 0; batch classifier loss: 0.175623; batch adversarial loss: 0.425233\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194535; batch adversarial loss: 0.397052\n",
      "epoch 25; iter: 0; batch classifier loss: 0.239317; batch adversarial loss: 0.476840\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193485; batch adversarial loss: 0.516673\n",
      "epoch 27; iter: 0; batch classifier loss: 0.220381; batch adversarial loss: 0.518194\n",
      "epoch 28; iter: 0; batch classifier loss: 0.199270; batch adversarial loss: 0.595667\n",
      "epoch 29; iter: 0; batch classifier loss: 0.223575; batch adversarial loss: 0.373295\n",
      "epoch 30; iter: 0; batch classifier loss: 0.209127; batch adversarial loss: 0.448934\n",
      "epoch 31; iter: 0; batch classifier loss: 0.240173; batch adversarial loss: 0.491435\n",
      "epoch 32; iter: 0; batch classifier loss: 0.256790; batch adversarial loss: 0.410558\n",
      "epoch 33; iter: 0; batch classifier loss: 0.192562; batch adversarial loss: 0.445518\n",
      "epoch 34; iter: 0; batch classifier loss: 0.186263; batch adversarial loss: 0.454663\n",
      "epoch 35; iter: 0; batch classifier loss: 0.242267; batch adversarial loss: 0.542542\n",
      "epoch 36; iter: 0; batch classifier loss: 0.192314; batch adversarial loss: 0.386367\n",
      "epoch 37; iter: 0; batch classifier loss: 0.172633; batch adversarial loss: 0.443250\n",
      "epoch 38; iter: 0; batch classifier loss: 0.268203; batch adversarial loss: 0.493431\n",
      "epoch 39; iter: 0; batch classifier loss: 0.232016; batch adversarial loss: 0.583093\n",
      "epoch 40; iter: 0; batch classifier loss: 0.155645; batch adversarial loss: 0.449858\n",
      "epoch 41; iter: 0; batch classifier loss: 0.217460; batch adversarial loss: 0.422478\n",
      "epoch 42; iter: 0; batch classifier loss: 0.194053; batch adversarial loss: 0.327427\n",
      "epoch 43; iter: 0; batch classifier loss: 0.250377; batch adversarial loss: 0.449818\n",
      "epoch 44; iter: 0; batch classifier loss: 0.224015; batch adversarial loss: 0.520450\n",
      "epoch 45; iter: 0; batch classifier loss: 0.283598; batch adversarial loss: 0.439062\n",
      "epoch 46; iter: 0; batch classifier loss: 0.301880; batch adversarial loss: 0.396115\n",
      "epoch 47; iter: 0; batch classifier loss: 0.237402; batch adversarial loss: 0.375046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.244642; batch adversarial loss: 0.481655\n",
      "epoch 49; iter: 0; batch classifier loss: 0.220277; batch adversarial loss: 0.450586\n",
      "epoch 50; iter: 0; batch classifier loss: 0.196099; batch adversarial loss: 0.445102\n",
      "epoch 51; iter: 0; batch classifier loss: 0.228050; batch adversarial loss: 0.500104\n",
      "epoch 52; iter: 0; batch classifier loss: 0.239125; batch adversarial loss: 0.543335\n",
      "epoch 53; iter: 0; batch classifier loss: 0.258606; batch adversarial loss: 0.451272\n",
      "epoch 54; iter: 0; batch classifier loss: 0.301541; batch adversarial loss: 0.425144\n",
      "epoch 55; iter: 0; batch classifier loss: 0.216985; batch adversarial loss: 0.519537\n",
      "epoch 56; iter: 0; batch classifier loss: 0.260454; batch adversarial loss: 0.436227\n",
      "epoch 57; iter: 0; batch classifier loss: 0.250724; batch adversarial loss: 0.543076\n",
      "epoch 58; iter: 0; batch classifier loss: 0.256956; batch adversarial loss: 0.471296\n",
      "epoch 59; iter: 0; batch classifier loss: 0.213552; batch adversarial loss: 0.471521\n",
      "epoch 60; iter: 0; batch classifier loss: 0.119945; batch adversarial loss: 0.410595\n",
      "epoch 61; iter: 0; batch classifier loss: 0.070200; batch adversarial loss: 0.381467\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080462; batch adversarial loss: 0.406030\n",
      "epoch 63; iter: 0; batch classifier loss: 0.077189; batch adversarial loss: 0.492421\n",
      "epoch 64; iter: 0; batch classifier loss: 0.064516; batch adversarial loss: 0.583042\n",
      "epoch 65; iter: 0; batch classifier loss: 0.081590; batch adversarial loss: 0.497899\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060669; batch adversarial loss: 0.349845\n",
      "epoch 67; iter: 0; batch classifier loss: 0.062556; batch adversarial loss: 0.380556\n",
      "epoch 68; iter: 0; batch classifier loss: 0.072461; batch adversarial loss: 0.418606\n",
      "epoch 69; iter: 0; batch classifier loss: 0.131066; batch adversarial loss: 0.450816\n",
      "epoch 70; iter: 0; batch classifier loss: 0.093637; batch adversarial loss: 0.398225\n",
      "epoch 71; iter: 0; batch classifier loss: 0.044538; batch adversarial loss: 0.465730\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071590; batch adversarial loss: 0.400628\n",
      "epoch 73; iter: 0; batch classifier loss: 0.090123; batch adversarial loss: 0.444915\n",
      "epoch 74; iter: 0; batch classifier loss: 0.065554; batch adversarial loss: 0.444040\n",
      "epoch 75; iter: 0; batch classifier loss: 0.056280; batch adversarial loss: 0.465127\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063968; batch adversarial loss: 0.529016\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069101; batch adversarial loss: 0.426065\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090478; batch adversarial loss: 0.423022\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057274; batch adversarial loss: 0.385660\n",
      "epoch 80; iter: 0; batch classifier loss: 0.063842; batch adversarial loss: 0.342106\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084160; batch adversarial loss: 0.463372\n",
      "epoch 82; iter: 0; batch classifier loss: 0.087316; batch adversarial loss: 0.456685\n",
      "epoch 83; iter: 0; batch classifier loss: 0.051505; batch adversarial loss: 0.416840\n",
      "epoch 84; iter: 0; batch classifier loss: 0.122646; batch adversarial loss: 0.385783\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083428; batch adversarial loss: 0.441087\n",
      "epoch 86; iter: 0; batch classifier loss: 0.055922; batch adversarial loss: 0.435202\n",
      "epoch 87; iter: 0; batch classifier loss: 0.118211; batch adversarial loss: 0.398507\n",
      "epoch 88; iter: 0; batch classifier loss: 0.060019; batch adversarial loss: 0.455636\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073453; batch adversarial loss: 0.492286\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059240; batch adversarial loss: 0.589906\n",
      "epoch 91; iter: 0; batch classifier loss: 0.029993; batch adversarial loss: 0.416926\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057244; batch adversarial loss: 0.486812\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051913; batch adversarial loss: 0.552759\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051742; batch adversarial loss: 0.369754\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047731; batch adversarial loss: 0.419479\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064521; batch adversarial loss: 0.403592\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057169; batch adversarial loss: 0.409477\n",
      "epoch 98; iter: 0; batch classifier loss: 0.081851; batch adversarial loss: 0.398389\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042601; batch adversarial loss: 0.470609\n",
      "epoch 100; iter: 0; batch classifier loss: 0.084745; batch adversarial loss: 0.367163\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039102; batch adversarial loss: 0.445275\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052526; batch adversarial loss: 0.453375\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053168; batch adversarial loss: 0.433743\n",
      "epoch 104; iter: 0; batch classifier loss: 0.087605; batch adversarial loss: 0.322339\n",
      "epoch 105; iter: 0; batch classifier loss: 0.071110; batch adversarial loss: 0.403534\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059894; batch adversarial loss: 0.459709\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056056; batch adversarial loss: 0.448238\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044979; batch adversarial loss: 0.363050\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054964; batch adversarial loss: 0.511052\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064973; batch adversarial loss: 0.411245\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058793; batch adversarial loss: 0.356176\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055489; batch adversarial loss: 0.393678\n",
      "epoch 113; iter: 0; batch classifier loss: 0.067773; batch adversarial loss: 0.381715\n",
      "epoch 114; iter: 0; batch classifier loss: 0.064182; batch adversarial loss: 0.366827\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042552; batch adversarial loss: 0.398009\n",
      "epoch 116; iter: 0; batch classifier loss: 0.061656; batch adversarial loss: 0.400983\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043953; batch adversarial loss: 0.400446\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056018; batch adversarial loss: 0.430854\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039921; batch adversarial loss: 0.365457\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036865; batch adversarial loss: 0.453217\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038705; batch adversarial loss: 0.414328\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048529; batch adversarial loss: 0.408793\n",
      "epoch 123; iter: 0; batch classifier loss: 0.056082; batch adversarial loss: 0.412583\n",
      "epoch 124; iter: 0; batch classifier loss: 0.047576; batch adversarial loss: 0.432567\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043988; batch adversarial loss: 0.339984\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063560; batch adversarial loss: 0.506755\n",
      "epoch 127; iter: 0; batch classifier loss: 0.080267; batch adversarial loss: 0.397448\n",
      "epoch 128; iter: 0; batch classifier loss: 0.057635; batch adversarial loss: 0.433339\n",
      "epoch 129; iter: 0; batch classifier loss: 0.084194; batch adversarial loss: 0.471702\n",
      "epoch 130; iter: 0; batch classifier loss: 0.096145; batch adversarial loss: 0.432673\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023084; batch adversarial loss: 0.472494\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058385; batch adversarial loss: 0.466218\n",
      "epoch 133; iter: 0; batch classifier loss: 0.062428; batch adversarial loss: 0.467048\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062224; batch adversarial loss: 0.430848\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046038; batch adversarial loss: 0.478471\n",
      "epoch 136; iter: 0; batch classifier loss: 0.047393; batch adversarial loss: 0.487679\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049118; batch adversarial loss: 0.469508\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024482; batch adversarial loss: 0.423047\n",
      "epoch 139; iter: 0; batch classifier loss: 0.074691; batch adversarial loss: 0.489133\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036100; batch adversarial loss: 0.404655\n",
      "epoch 141; iter: 0; batch classifier loss: 0.055890; batch adversarial loss: 0.422159\n",
      "epoch 142; iter: 0; batch classifier loss: 0.056193; batch adversarial loss: 0.351415\n",
      "epoch 143; iter: 0; batch classifier loss: 0.045463; batch adversarial loss: 0.432853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.022493; batch adversarial loss: 0.426757\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042285; batch adversarial loss: 0.389116\n",
      "epoch 146; iter: 0; batch classifier loss: 0.054934; batch adversarial loss: 0.379040\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038631; batch adversarial loss: 0.456745\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028002; batch adversarial loss: 0.469433\n",
      "epoch 149; iter: 0; batch classifier loss: 0.060651; batch adversarial loss: 0.436953\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035200; batch adversarial loss: 0.409000\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029704; batch adversarial loss: 0.533407\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045034; batch adversarial loss: 0.490646\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026971; batch adversarial loss: 0.393205\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044863; batch adversarial loss: 0.527565\n",
      "epoch 155; iter: 0; batch classifier loss: 0.047988; batch adversarial loss: 0.406162\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018502; batch adversarial loss: 0.497449\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042493; batch adversarial loss: 0.430380\n",
      "epoch 158; iter: 0; batch classifier loss: 0.062419; batch adversarial loss: 0.421615\n",
      "epoch 159; iter: 0; batch classifier loss: 0.059368; batch adversarial loss: 0.315545\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014727; batch adversarial loss: 0.371710\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022122; batch adversarial loss: 0.461878\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017593; batch adversarial loss: 0.400225\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037206; batch adversarial loss: 0.400876\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010956; batch adversarial loss: 0.477669\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022879; batch adversarial loss: 0.421656\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013841; batch adversarial loss: 0.520361\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031887; batch adversarial loss: 0.411605\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017904; batch adversarial loss: 0.327000\n",
      "epoch 169; iter: 0; batch classifier loss: 0.061491; batch adversarial loss: 0.403463\n",
      "epoch 170; iter: 0; batch classifier loss: 0.041001; batch adversarial loss: 0.390235\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030826; batch adversarial loss: 0.411426\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026196; batch adversarial loss: 0.539881\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020494; batch adversarial loss: 0.462982\n",
      "epoch 174; iter: 0; batch classifier loss: 0.034178; batch adversarial loss: 0.486353\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032785; batch adversarial loss: 0.443894\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023274; batch adversarial loss: 0.426635\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018806; batch adversarial loss: 0.408479\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020994; batch adversarial loss: 0.444513\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039704; batch adversarial loss: 0.424271\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010619; batch adversarial loss: 0.284794\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029017; batch adversarial loss: 0.522583\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020499; batch adversarial loss: 0.439589\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017384; batch adversarial loss: 0.532607\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015865; batch adversarial loss: 0.411700\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008827; batch adversarial loss: 0.548385\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027134; batch adversarial loss: 0.413913\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021409; batch adversarial loss: 0.541784\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019070; batch adversarial loss: 0.414281\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011737; batch adversarial loss: 0.431997\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022838; batch adversarial loss: 0.481901\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011350; batch adversarial loss: 0.474443\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009436; batch adversarial loss: 0.440474\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032265; batch adversarial loss: 0.447579\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004537; batch adversarial loss: 0.433007\n",
      "epoch 195; iter: 0; batch classifier loss: 0.035043; batch adversarial loss: 0.431592\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019369; batch adversarial loss: 0.437970\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027607; batch adversarial loss: 0.424119\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027253; batch adversarial loss: 0.468388\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033995; batch adversarial loss: 0.360883\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722083; batch adversarial loss: 0.792663\n",
      "epoch 1; iter: 0; batch classifier loss: 0.449497; batch adversarial loss: 0.763441\n",
      "epoch 2; iter: 0; batch classifier loss: 0.394578; batch adversarial loss: 0.727172\n",
      "epoch 3; iter: 0; batch classifier loss: 0.341947; batch adversarial loss: 0.694946\n",
      "epoch 4; iter: 0; batch classifier loss: 0.260662; batch adversarial loss: 0.656413\n",
      "epoch 5; iter: 0; batch classifier loss: 0.354451; batch adversarial loss: 0.622910\n",
      "epoch 6; iter: 0; batch classifier loss: 0.254504; batch adversarial loss: 0.609825\n",
      "epoch 7; iter: 0; batch classifier loss: 0.296833; batch adversarial loss: 0.595431\n",
      "epoch 8; iter: 0; batch classifier loss: 0.260132; batch adversarial loss: 0.511208\n",
      "epoch 9; iter: 0; batch classifier loss: 0.259388; batch adversarial loss: 0.526090\n",
      "epoch 10; iter: 0; batch classifier loss: 0.306570; batch adversarial loss: 0.524308\n",
      "epoch 11; iter: 0; batch classifier loss: 0.292740; batch adversarial loss: 0.512794\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282202; batch adversarial loss: 0.466736\n",
      "epoch 13; iter: 0; batch classifier loss: 0.266738; batch adversarial loss: 0.485092\n",
      "epoch 14; iter: 0; batch classifier loss: 0.191789; batch adversarial loss: 0.498784\n",
      "epoch 15; iter: 0; batch classifier loss: 0.223913; batch adversarial loss: 0.493972\n",
      "epoch 16; iter: 0; batch classifier loss: 0.215704; batch adversarial loss: 0.440896\n",
      "epoch 17; iter: 0; batch classifier loss: 0.233517; batch adversarial loss: 0.397997\n",
      "epoch 18; iter: 0; batch classifier loss: 0.229624; batch adversarial loss: 0.428033\n",
      "epoch 19; iter: 0; batch classifier loss: 0.251508; batch adversarial loss: 0.412927\n",
      "epoch 20; iter: 0; batch classifier loss: 0.217457; batch adversarial loss: 0.471107\n",
      "epoch 21; iter: 0; batch classifier loss: 0.214069; batch adversarial loss: 0.436698\n",
      "epoch 22; iter: 0; batch classifier loss: 0.214408; batch adversarial loss: 0.444120\n",
      "epoch 23; iter: 0; batch classifier loss: 0.270407; batch adversarial loss: 0.380667\n",
      "epoch 24; iter: 0; batch classifier loss: 0.240864; batch adversarial loss: 0.347629\n",
      "epoch 25; iter: 0; batch classifier loss: 0.225075; batch adversarial loss: 0.366463\n",
      "epoch 26; iter: 0; batch classifier loss: 0.224746; batch adversarial loss: 0.376084\n",
      "epoch 27; iter: 0; batch classifier loss: 0.180641; batch adversarial loss: 0.463843\n",
      "epoch 28; iter: 0; batch classifier loss: 0.224579; batch adversarial loss: 0.399342\n",
      "epoch 29; iter: 0; batch classifier loss: 0.147768; batch adversarial loss: 0.356870\n",
      "epoch 30; iter: 0; batch classifier loss: 0.161507; batch adversarial loss: 0.393982\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156565; batch adversarial loss: 0.402944\n",
      "epoch 32; iter: 0; batch classifier loss: 0.147283; batch adversarial loss: 0.343429\n",
      "epoch 33; iter: 0; batch classifier loss: 0.144229; batch adversarial loss: 0.375890\n",
      "epoch 34; iter: 0; batch classifier loss: 0.195843; batch adversarial loss: 0.426581\n",
      "epoch 35; iter: 0; batch classifier loss: 0.120406; batch adversarial loss: 0.355546\n",
      "epoch 36; iter: 0; batch classifier loss: 0.198846; batch adversarial loss: 0.475916\n",
      "epoch 37; iter: 0; batch classifier loss: 0.119698; batch adversarial loss: 0.400600\n",
      "epoch 38; iter: 0; batch classifier loss: 0.111966; batch adversarial loss: 0.435738\n",
      "epoch 39; iter: 0; batch classifier loss: 0.090354; batch adversarial loss: 0.411137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.110391; batch adversarial loss: 0.356541\n",
      "epoch 41; iter: 0; batch classifier loss: 0.103819; batch adversarial loss: 0.418740\n",
      "epoch 42; iter: 0; batch classifier loss: 0.120686; batch adversarial loss: 0.412293\n",
      "epoch 43; iter: 0; batch classifier loss: 0.129835; batch adversarial loss: 0.380866\n",
      "epoch 44; iter: 0; batch classifier loss: 0.080677; batch adversarial loss: 0.412001\n",
      "epoch 45; iter: 0; batch classifier loss: 0.156969; batch adversarial loss: 0.411423\n",
      "epoch 46; iter: 0; batch classifier loss: 0.074676; batch adversarial loss: 0.363520\n",
      "epoch 47; iter: 0; batch classifier loss: 0.108541; batch adversarial loss: 0.393479\n",
      "epoch 48; iter: 0; batch classifier loss: 0.142278; batch adversarial loss: 0.412319\n",
      "epoch 49; iter: 0; batch classifier loss: 0.152710; batch adversarial loss: 0.473617\n",
      "epoch 50; iter: 0; batch classifier loss: 0.129227; batch adversarial loss: 0.400068\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092255; batch adversarial loss: 0.402019\n",
      "epoch 52; iter: 0; batch classifier loss: 0.120282; batch adversarial loss: 0.437090\n",
      "epoch 53; iter: 0; batch classifier loss: 0.147997; batch adversarial loss: 0.374428\n",
      "epoch 54; iter: 0; batch classifier loss: 0.121394; batch adversarial loss: 0.481571\n",
      "epoch 55; iter: 0; batch classifier loss: 0.104650; batch adversarial loss: 0.462741\n",
      "epoch 56; iter: 0; batch classifier loss: 0.079880; batch adversarial loss: 0.454882\n",
      "epoch 57; iter: 0; batch classifier loss: 0.071003; batch adversarial loss: 0.526343\n",
      "epoch 58; iter: 0; batch classifier loss: 0.109116; batch adversarial loss: 0.448177\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088177; batch adversarial loss: 0.456135\n",
      "epoch 60; iter: 0; batch classifier loss: 0.090362; batch adversarial loss: 0.413791\n",
      "epoch 61; iter: 0; batch classifier loss: 0.083064; batch adversarial loss: 0.526717\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084135; batch adversarial loss: 0.439228\n",
      "epoch 63; iter: 0; batch classifier loss: 0.082040; batch adversarial loss: 0.426372\n",
      "epoch 64; iter: 0; batch classifier loss: 0.077669; batch adversarial loss: 0.397864\n",
      "epoch 65; iter: 0; batch classifier loss: 0.049895; batch adversarial loss: 0.407199\n",
      "epoch 66; iter: 0; batch classifier loss: 0.067827; batch adversarial loss: 0.454599\n",
      "epoch 67; iter: 0; batch classifier loss: 0.174745; batch adversarial loss: 0.488671\n",
      "epoch 68; iter: 0; batch classifier loss: 0.085388; batch adversarial loss: 0.427147\n",
      "epoch 69; iter: 0; batch classifier loss: 0.085078; batch adversarial loss: 0.509902\n",
      "epoch 70; iter: 0; batch classifier loss: 0.095638; batch adversarial loss: 0.453658\n",
      "epoch 71; iter: 0; batch classifier loss: 0.090023; batch adversarial loss: 0.448155\n",
      "epoch 72; iter: 0; batch classifier loss: 0.061670; batch adversarial loss: 0.368381\n",
      "epoch 73; iter: 0; batch classifier loss: 0.107655; batch adversarial loss: 0.410909\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076523; batch adversarial loss: 0.426782\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061708; batch adversarial loss: 0.391225\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064831; batch adversarial loss: 0.459851\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069652; batch adversarial loss: 0.458310\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072592; batch adversarial loss: 0.437400\n",
      "epoch 79; iter: 0; batch classifier loss: 0.091759; batch adversarial loss: 0.334119\n",
      "epoch 80; iter: 0; batch classifier loss: 0.072382; batch adversarial loss: 0.415021\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065497; batch adversarial loss: 0.394042\n",
      "epoch 82; iter: 0; batch classifier loss: 0.087327; batch adversarial loss: 0.381420\n",
      "epoch 83; iter: 0; batch classifier loss: 0.096249; batch adversarial loss: 0.440979\n",
      "epoch 84; iter: 0; batch classifier loss: 0.093273; batch adversarial loss: 0.438211\n",
      "epoch 85; iter: 0; batch classifier loss: 0.089097; batch adversarial loss: 0.349676\n",
      "epoch 86; iter: 0; batch classifier loss: 0.056717; batch adversarial loss: 0.363015\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082154; batch adversarial loss: 0.418976\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054685; batch adversarial loss: 0.458355\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052460; batch adversarial loss: 0.377776\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048636; batch adversarial loss: 0.471656\n",
      "epoch 91; iter: 0; batch classifier loss: 0.051218; batch adversarial loss: 0.403669\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058357; batch adversarial loss: 0.494127\n",
      "epoch 93; iter: 0; batch classifier loss: 0.076412; batch adversarial loss: 0.389638\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077654; batch adversarial loss: 0.442694\n",
      "epoch 95; iter: 0; batch classifier loss: 0.046994; batch adversarial loss: 0.433205\n",
      "epoch 96; iter: 0; batch classifier loss: 0.072789; batch adversarial loss: 0.466506\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050955; batch adversarial loss: 0.411473\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059318; batch adversarial loss: 0.377715\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046476; batch adversarial loss: 0.495220\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050645; batch adversarial loss: 0.471663\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041489; batch adversarial loss: 0.467944\n",
      "epoch 102; iter: 0; batch classifier loss: 0.035690; batch adversarial loss: 0.500949\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058714; batch adversarial loss: 0.414603\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063269; batch adversarial loss: 0.438127\n",
      "epoch 105; iter: 0; batch classifier loss: 0.022040; batch adversarial loss: 0.499006\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033266; batch adversarial loss: 0.400366\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037152; batch adversarial loss: 0.375704\n",
      "epoch 108; iter: 0; batch classifier loss: 0.027654; batch adversarial loss: 0.454752\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048799; batch adversarial loss: 0.502693\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025399; batch adversarial loss: 0.372667\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028463; batch adversarial loss: 0.429430\n",
      "epoch 112; iter: 0; batch classifier loss: 0.012640; batch adversarial loss: 0.442084\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052775; batch adversarial loss: 0.424913\n",
      "epoch 114; iter: 0; batch classifier loss: 0.023779; batch adversarial loss: 0.481574\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028029; batch adversarial loss: 0.475050\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030059; batch adversarial loss: 0.413927\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034703; batch adversarial loss: 0.547905\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041634; batch adversarial loss: 0.486795\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039891; batch adversarial loss: 0.418353\n",
      "epoch 120; iter: 0; batch classifier loss: 0.058079; batch adversarial loss: 0.516062\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036867; batch adversarial loss: 0.523458\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042951; batch adversarial loss: 0.479558\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050403; batch adversarial loss: 0.396365\n",
      "epoch 124; iter: 0; batch classifier loss: 0.076138; batch adversarial loss: 0.556717\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051193; batch adversarial loss: 0.456946\n",
      "epoch 126; iter: 0; batch classifier loss: 0.121664; batch adversarial loss: 0.544749\n",
      "epoch 127; iter: 0; batch classifier loss: 0.108574; batch adversarial loss: 0.638349\n",
      "epoch 128; iter: 0; batch classifier loss: 0.273207; batch adversarial loss: 0.883198\n",
      "epoch 129; iter: 0; batch classifier loss: 0.082402; batch adversarial loss: 0.604860\n",
      "epoch 130; iter: 0; batch classifier loss: 0.092202; batch adversarial loss: 0.637561\n",
      "epoch 131; iter: 0; batch classifier loss: 0.151729; batch adversarial loss: 0.693871\n",
      "epoch 132; iter: 0; batch classifier loss: 0.189997; batch adversarial loss: 0.648939\n",
      "epoch 133; iter: 0; batch classifier loss: 0.099037; batch adversarial loss: 0.558481\n",
      "epoch 134; iter: 0; batch classifier loss: 0.113302; batch adversarial loss: 0.577728\n",
      "epoch 135; iter: 0; batch classifier loss: 0.192493; batch adversarial loss: 0.825448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.118231; batch adversarial loss: 0.545582\n",
      "epoch 137; iter: 0; batch classifier loss: 0.127877; batch adversarial loss: 0.540342\n",
      "epoch 138; iter: 0; batch classifier loss: 0.161034; batch adversarial loss: 0.568033\n",
      "epoch 139; iter: 0; batch classifier loss: 0.173466; batch adversarial loss: 0.649297\n",
      "epoch 140; iter: 0; batch classifier loss: 0.178224; batch adversarial loss: 0.643782\n",
      "epoch 141; iter: 0; batch classifier loss: 0.187763; batch adversarial loss: 0.618298\n",
      "epoch 142; iter: 0; batch classifier loss: 0.172774; batch adversarial loss: 0.616232\n",
      "epoch 143; iter: 0; batch classifier loss: 0.137082; batch adversarial loss: 0.561284\n",
      "epoch 144; iter: 0; batch classifier loss: 0.155825; batch adversarial loss: 0.547176\n",
      "epoch 145; iter: 0; batch classifier loss: 0.164489; batch adversarial loss: 0.567796\n",
      "epoch 146; iter: 0; batch classifier loss: 0.134905; batch adversarial loss: 0.596618\n",
      "epoch 147; iter: 0; batch classifier loss: 0.171454; batch adversarial loss: 0.625564\n",
      "epoch 148; iter: 0; batch classifier loss: 0.130850; batch adversarial loss: 0.572128\n",
      "epoch 149; iter: 0; batch classifier loss: 0.172048; batch adversarial loss: 0.620988\n",
      "epoch 150; iter: 0; batch classifier loss: 0.102785; batch adversarial loss: 0.462817\n",
      "epoch 151; iter: 0; batch classifier loss: 0.142070; batch adversarial loss: 0.539532\n",
      "epoch 152; iter: 0; batch classifier loss: 0.168631; batch adversarial loss: 0.523543\n",
      "epoch 153; iter: 0; batch classifier loss: 0.187914; batch adversarial loss: 0.588711\n",
      "epoch 154; iter: 0; batch classifier loss: 0.112505; batch adversarial loss: 0.481182\n",
      "epoch 155; iter: 0; batch classifier loss: 0.127385; batch adversarial loss: 0.448429\n",
      "epoch 156; iter: 0; batch classifier loss: 0.180963; batch adversarial loss: 0.582421\n",
      "epoch 157; iter: 0; batch classifier loss: 0.148931; batch adversarial loss: 0.543176\n",
      "epoch 158; iter: 0; batch classifier loss: 0.084838; batch adversarial loss: 0.439900\n",
      "epoch 159; iter: 0; batch classifier loss: 0.174563; batch adversarial loss: 0.599619\n",
      "epoch 160; iter: 0; batch classifier loss: 0.126292; batch adversarial loss: 0.549866\n",
      "epoch 161; iter: 0; batch classifier loss: 0.091189; batch adversarial loss: 0.482315\n",
      "epoch 162; iter: 0; batch classifier loss: 0.080001; batch adversarial loss: 0.414437\n",
      "epoch 163; iter: 0; batch classifier loss: 0.176069; batch adversarial loss: 0.666380\n",
      "epoch 164; iter: 0; batch classifier loss: 0.178042; batch adversarial loss: 0.563797\n",
      "epoch 165; iter: 0; batch classifier loss: 0.080369; batch adversarial loss: 0.430887\n",
      "epoch 166; iter: 0; batch classifier loss: 0.144150; batch adversarial loss: 0.613501\n",
      "epoch 167; iter: 0; batch classifier loss: 0.068702; batch adversarial loss: 0.473984\n",
      "epoch 168; iter: 0; batch classifier loss: 0.105423; batch adversarial loss: 0.410478\n",
      "epoch 169; iter: 0; batch classifier loss: 0.141823; batch adversarial loss: 0.410422\n",
      "epoch 170; iter: 0; batch classifier loss: 0.077819; batch adversarial loss: 0.456627\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030955; batch adversarial loss: 0.517732\n",
      "epoch 172; iter: 0; batch classifier loss: 0.046613; batch adversarial loss: 0.443509\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023966; batch adversarial loss: 0.496036\n",
      "epoch 174; iter: 0; batch classifier loss: 0.050892; batch adversarial loss: 0.476186\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030947; batch adversarial loss: 0.450161\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035122; batch adversarial loss: 0.472050\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022223; batch adversarial loss: 0.465244\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020055; batch adversarial loss: 0.453777\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037169; batch adversarial loss: 0.514428\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037798; batch adversarial loss: 0.449416\n",
      "epoch 181; iter: 0; batch classifier loss: 0.043955; batch adversarial loss: 0.549914\n",
      "epoch 182; iter: 0; batch classifier loss: 0.057429; batch adversarial loss: 0.419849\n",
      "epoch 183; iter: 0; batch classifier loss: 0.039685; batch adversarial loss: 0.410229\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038440; batch adversarial loss: 0.493431\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027110; batch adversarial loss: 0.487242\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016329; batch adversarial loss: 0.503336\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034104; batch adversarial loss: 0.407001\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014116; batch adversarial loss: 0.465185\n",
      "epoch 189; iter: 0; batch classifier loss: 0.039211; batch adversarial loss: 0.458989\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025493; batch adversarial loss: 0.442585\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020498; batch adversarial loss: 0.555059\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028440; batch adversarial loss: 0.429726\n",
      "epoch 193; iter: 0; batch classifier loss: 0.079609; batch adversarial loss: 0.485299\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041667; batch adversarial loss: 0.389915\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029942; batch adversarial loss: 0.478297\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029998; batch adversarial loss: 0.450548\n",
      "epoch 197; iter: 0; batch classifier loss: 0.059247; batch adversarial loss: 0.559134\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030372; batch adversarial loss: 0.513375\n",
      "epoch 199; iter: 0; batch classifier loss: 0.039413; batch adversarial loss: 0.534794\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708287; batch adversarial loss: 0.715839\n",
      "epoch 1; iter: 0; batch classifier loss: 0.509415; batch adversarial loss: 0.705433\n",
      "epoch 2; iter: 0; batch classifier loss: 0.394612; batch adversarial loss: 0.685596\n",
      "epoch 3; iter: 0; batch classifier loss: 0.414965; batch adversarial loss: 0.656494\n",
      "epoch 4; iter: 0; batch classifier loss: 0.373893; batch adversarial loss: 0.605917\n",
      "epoch 5; iter: 0; batch classifier loss: 0.342994; batch adversarial loss: 0.556272\n",
      "epoch 6; iter: 0; batch classifier loss: 0.304288; batch adversarial loss: 0.557848\n",
      "epoch 7; iter: 0; batch classifier loss: 0.281911; batch adversarial loss: 0.553810\n",
      "epoch 8; iter: 0; batch classifier loss: 0.260284; batch adversarial loss: 0.508248\n",
      "epoch 9; iter: 0; batch classifier loss: 0.174739; batch adversarial loss: 0.473240\n",
      "epoch 10; iter: 0; batch classifier loss: 0.215703; batch adversarial loss: 0.491297\n",
      "epoch 11; iter: 0; batch classifier loss: 0.208802; batch adversarial loss: 0.517100\n",
      "epoch 12; iter: 0; batch classifier loss: 0.203900; batch adversarial loss: 0.507254\n",
      "epoch 13; iter: 0; batch classifier loss: 0.143186; batch adversarial loss: 0.549213\n",
      "epoch 14; iter: 0; batch classifier loss: 0.168730; batch adversarial loss: 0.473185\n",
      "epoch 15; iter: 0; batch classifier loss: 0.167744; batch adversarial loss: 0.535955\n",
      "epoch 16; iter: 0; batch classifier loss: 0.213177; batch adversarial loss: 0.447192\n",
      "epoch 17; iter: 0; batch classifier loss: 0.187163; batch adversarial loss: 0.422668\n",
      "epoch 18; iter: 0; batch classifier loss: 0.155359; batch adversarial loss: 0.440681\n",
      "epoch 19; iter: 0; batch classifier loss: 0.107226; batch adversarial loss: 0.420204\n",
      "epoch 20; iter: 0; batch classifier loss: 0.173604; batch adversarial loss: 0.454671\n",
      "epoch 21; iter: 0; batch classifier loss: 0.138505; batch adversarial loss: 0.483907\n",
      "epoch 22; iter: 0; batch classifier loss: 0.148169; batch adversarial loss: 0.543674\n",
      "epoch 23; iter: 0; batch classifier loss: 0.143096; batch adversarial loss: 0.522184\n",
      "epoch 24; iter: 0; batch classifier loss: 0.163408; batch adversarial loss: 0.547071\n",
      "epoch 25; iter: 0; batch classifier loss: 0.198356; batch adversarial loss: 0.531086\n",
      "epoch 26; iter: 0; batch classifier loss: 0.141418; batch adversarial loss: 0.514674\n",
      "epoch 27; iter: 0; batch classifier loss: 0.135754; batch adversarial loss: 0.486021\n",
      "epoch 28; iter: 0; batch classifier loss: 0.214699; batch adversarial loss: 0.532539\n",
      "epoch 29; iter: 0; batch classifier loss: 0.245489; batch adversarial loss: 0.561894\n",
      "epoch 30; iter: 0; batch classifier loss: 0.199828; batch adversarial loss: 0.490624\n",
      "epoch 31; iter: 0; batch classifier loss: 0.135927; batch adversarial loss: 0.459719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.187631; batch adversarial loss: 0.497295\n",
      "epoch 33; iter: 0; batch classifier loss: 0.262834; batch adversarial loss: 0.537015\n",
      "epoch 34; iter: 0; batch classifier loss: 0.190633; batch adversarial loss: 0.436364\n",
      "epoch 35; iter: 0; batch classifier loss: 0.296500; batch adversarial loss: 0.515144\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187916; batch adversarial loss: 0.498811\n",
      "epoch 37; iter: 0; batch classifier loss: 0.075596; batch adversarial loss: 0.482594\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115430; batch adversarial loss: 0.453327\n",
      "epoch 39; iter: 0; batch classifier loss: 0.089626; batch adversarial loss: 0.491086\n",
      "epoch 40; iter: 0; batch classifier loss: 0.083544; batch adversarial loss: 0.476615\n",
      "epoch 41; iter: 0; batch classifier loss: 0.081659; batch adversarial loss: 0.461882\n",
      "epoch 42; iter: 0; batch classifier loss: 0.068286; batch adversarial loss: 0.454555\n",
      "epoch 43; iter: 0; batch classifier loss: 0.083490; batch adversarial loss: 0.481935\n",
      "epoch 44; iter: 0; batch classifier loss: 0.073097; batch adversarial loss: 0.464637\n",
      "epoch 45; iter: 0; batch classifier loss: 0.095781; batch adversarial loss: 0.464980\n",
      "epoch 46; iter: 0; batch classifier loss: 0.062949; batch adversarial loss: 0.379413\n",
      "epoch 47; iter: 0; batch classifier loss: 0.077618; batch adversarial loss: 0.477478\n",
      "epoch 48; iter: 0; batch classifier loss: 0.073066; batch adversarial loss: 0.447611\n",
      "epoch 49; iter: 0; batch classifier loss: 0.078642; batch adversarial loss: 0.443467\n",
      "epoch 50; iter: 0; batch classifier loss: 0.078399; batch adversarial loss: 0.373938\n",
      "epoch 51; iter: 0; batch classifier loss: 0.047179; batch adversarial loss: 0.521948\n",
      "epoch 52; iter: 0; batch classifier loss: 0.086561; batch adversarial loss: 0.409971\n",
      "epoch 53; iter: 0; batch classifier loss: 0.075575; batch adversarial loss: 0.486108\n",
      "epoch 54; iter: 0; batch classifier loss: 0.121047; batch adversarial loss: 0.372039\n",
      "epoch 55; iter: 0; batch classifier loss: 0.073528; batch adversarial loss: 0.440294\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103338; batch adversarial loss: 0.510846\n",
      "epoch 57; iter: 0; batch classifier loss: 0.056750; batch adversarial loss: 0.447252\n",
      "epoch 58; iter: 0; batch classifier loss: 0.085149; batch adversarial loss: 0.401527\n",
      "epoch 59; iter: 0; batch classifier loss: 0.040242; batch adversarial loss: 0.433496\n",
      "epoch 60; iter: 0; batch classifier loss: 0.064595; batch adversarial loss: 0.538376\n",
      "epoch 61; iter: 0; batch classifier loss: 0.068541; batch adversarial loss: 0.471697\n",
      "epoch 62; iter: 0; batch classifier loss: 0.071973; batch adversarial loss: 0.452216\n",
      "epoch 63; iter: 0; batch classifier loss: 0.063789; batch adversarial loss: 0.437625\n",
      "epoch 64; iter: 0; batch classifier loss: 0.059404; batch adversarial loss: 0.382399\n",
      "epoch 65; iter: 0; batch classifier loss: 0.059879; batch adversarial loss: 0.392661\n",
      "epoch 66; iter: 0; batch classifier loss: 0.070772; batch adversarial loss: 0.402075\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079914; batch adversarial loss: 0.401129\n",
      "epoch 68; iter: 0; batch classifier loss: 0.077617; batch adversarial loss: 0.545714\n",
      "epoch 69; iter: 0; batch classifier loss: 0.063428; batch adversarial loss: 0.490623\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090079; batch adversarial loss: 0.518860\n",
      "epoch 71; iter: 0; batch classifier loss: 0.056470; batch adversarial loss: 0.533349\n",
      "epoch 72; iter: 0; batch classifier loss: 0.038080; batch adversarial loss: 0.552582\n",
      "epoch 73; iter: 0; batch classifier loss: 0.055221; batch adversarial loss: 0.473098\n",
      "epoch 74; iter: 0; batch classifier loss: 0.099211; batch adversarial loss: 0.487966\n",
      "epoch 75; iter: 0; batch classifier loss: 0.064322; batch adversarial loss: 0.442919\n",
      "epoch 76; iter: 0; batch classifier loss: 0.062546; batch adversarial loss: 0.488109\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055862; batch adversarial loss: 0.432733\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082143; batch adversarial loss: 0.418372\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065637; batch adversarial loss: 0.453457\n",
      "epoch 80; iter: 0; batch classifier loss: 0.042913; batch adversarial loss: 0.533714\n",
      "epoch 81; iter: 0; batch classifier loss: 0.027560; batch adversarial loss: 0.527670\n",
      "epoch 82; iter: 0; batch classifier loss: 0.056761; batch adversarial loss: 0.416151\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071545; batch adversarial loss: 0.400023\n",
      "epoch 84; iter: 0; batch classifier loss: 0.039362; batch adversarial loss: 0.543931\n",
      "epoch 85; iter: 0; batch classifier loss: 0.036604; batch adversarial loss: 0.520024\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061026; batch adversarial loss: 0.368495\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057319; batch adversarial loss: 0.459381\n",
      "epoch 88; iter: 0; batch classifier loss: 0.108347; batch adversarial loss: 0.416435\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066246; batch adversarial loss: 0.471456\n",
      "epoch 90; iter: 0; batch classifier loss: 0.114631; batch adversarial loss: 0.489863\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048268; batch adversarial loss: 0.423693\n",
      "epoch 92; iter: 0; batch classifier loss: 0.028070; batch adversarial loss: 0.439841\n",
      "epoch 93; iter: 0; batch classifier loss: 0.039806; batch adversarial loss: 0.450670\n",
      "epoch 94; iter: 0; batch classifier loss: 0.032742; batch adversarial loss: 0.403087\n",
      "epoch 95; iter: 0; batch classifier loss: 0.044707; batch adversarial loss: 0.411749\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043914; batch adversarial loss: 0.447459\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044654; batch adversarial loss: 0.399648\n",
      "epoch 98; iter: 0; batch classifier loss: 0.016642; batch adversarial loss: 0.491332\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052270; batch adversarial loss: 0.429220\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049410; batch adversarial loss: 0.464883\n",
      "epoch 101; iter: 0; batch classifier loss: 0.067921; batch adversarial loss: 0.440145\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051503; batch adversarial loss: 0.418504\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049432; batch adversarial loss: 0.442288\n",
      "epoch 104; iter: 0; batch classifier loss: 0.023609; batch adversarial loss: 0.462029\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030653; batch adversarial loss: 0.456822\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046741; batch adversarial loss: 0.523130\n",
      "epoch 107; iter: 0; batch classifier loss: 0.014855; batch adversarial loss: 0.474324\n",
      "epoch 108; iter: 0; batch classifier loss: 0.085855; batch adversarial loss: 0.509969\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054349; batch adversarial loss: 0.435442\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064368; batch adversarial loss: 0.570711\n",
      "epoch 111; iter: 0; batch classifier loss: 0.017469; batch adversarial loss: 0.482067\n",
      "epoch 112; iter: 0; batch classifier loss: 0.082447; batch adversarial loss: 0.411667\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052883; batch adversarial loss: 0.430548\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035009; batch adversarial loss: 0.456769\n",
      "epoch 115; iter: 0; batch classifier loss: 0.016212; batch adversarial loss: 0.491768\n",
      "epoch 116; iter: 0; batch classifier loss: 0.068520; batch adversarial loss: 0.360257\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039057; batch adversarial loss: 0.360308\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031234; batch adversarial loss: 0.351242\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031035; batch adversarial loss: 0.429740\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030091; batch adversarial loss: 0.448492\n",
      "epoch 121; iter: 0; batch classifier loss: 0.022856; batch adversarial loss: 0.410470\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046849; batch adversarial loss: 0.502033\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053942; batch adversarial loss: 0.514075\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044111; batch adversarial loss: 0.426202\n",
      "epoch 125; iter: 0; batch classifier loss: 0.120542; batch adversarial loss: 0.425984\n",
      "epoch 126; iter: 0; batch classifier loss: 0.059779; batch adversarial loss: 0.489212\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046863; batch adversarial loss: 0.536826\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039149; batch adversarial loss: 0.465924\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022078; batch adversarial loss: 0.402842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.051215; batch adversarial loss: 0.530023\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035672; batch adversarial loss: 0.428880\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019361; batch adversarial loss: 0.496839\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033966; batch adversarial loss: 0.494103\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049829; batch adversarial loss: 0.430744\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040866; batch adversarial loss: 0.410722\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018660; batch adversarial loss: 0.326974\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040907; batch adversarial loss: 0.582625\n",
      "epoch 138; iter: 0; batch classifier loss: 0.055063; batch adversarial loss: 0.421354\n",
      "epoch 139; iter: 0; batch classifier loss: 0.053439; batch adversarial loss: 0.404619\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023579; batch adversarial loss: 0.466072\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045127; batch adversarial loss: 0.385395\n",
      "epoch 142; iter: 0; batch classifier loss: 0.047418; batch adversarial loss: 0.399652\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041880; batch adversarial loss: 0.376227\n",
      "epoch 144; iter: 0; batch classifier loss: 0.035041; batch adversarial loss: 0.385410\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040627; batch adversarial loss: 0.480723\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026264; batch adversarial loss: 0.435905\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014675; batch adversarial loss: 0.524998\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032744; batch adversarial loss: 0.468328\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035508; batch adversarial loss: 0.465601\n",
      "epoch 150; iter: 0; batch classifier loss: 0.080346; batch adversarial loss: 0.428418\n",
      "epoch 151; iter: 0; batch classifier loss: 0.046502; batch adversarial loss: 0.538631\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025361; batch adversarial loss: 0.326732\n",
      "epoch 153; iter: 0; batch classifier loss: 0.048498; batch adversarial loss: 0.505080\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021337; batch adversarial loss: 0.478427\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030372; batch adversarial loss: 0.495486\n",
      "epoch 156; iter: 0; batch classifier loss: 0.066178; batch adversarial loss: 0.574690\n",
      "epoch 157; iter: 0; batch classifier loss: 0.052271; batch adversarial loss: 0.532620\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023015; batch adversarial loss: 0.459391\n",
      "epoch 159; iter: 0; batch classifier loss: 0.007898; batch adversarial loss: 0.481353\n",
      "epoch 160; iter: 0; batch classifier loss: 0.045309; batch adversarial loss: 0.489029\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016927; batch adversarial loss: 0.434409\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031695; batch adversarial loss: 0.494812\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042435; batch adversarial loss: 0.482341\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034494; batch adversarial loss: 0.417539\n",
      "epoch 165; iter: 0; batch classifier loss: 0.068093; batch adversarial loss: 0.454198\n",
      "epoch 166; iter: 0; batch classifier loss: 0.047908; batch adversarial loss: 0.407893\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018250; batch adversarial loss: 0.413226\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032247; batch adversarial loss: 0.455623\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044245; batch adversarial loss: 0.447072\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038409; batch adversarial loss: 0.446378\n",
      "epoch 171; iter: 0; batch classifier loss: 0.081098; batch adversarial loss: 0.431508\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015249; batch adversarial loss: 0.457726\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034056; batch adversarial loss: 0.533839\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026050; batch adversarial loss: 0.499565\n",
      "epoch 175; iter: 0; batch classifier loss: 0.043571; batch adversarial loss: 0.471908\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012296; batch adversarial loss: 0.446523\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021756; batch adversarial loss: 0.426933\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032665; batch adversarial loss: 0.438309\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018147; batch adversarial loss: 0.432743\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008219; batch adversarial loss: 0.404081\n",
      "epoch 181; iter: 0; batch classifier loss: 0.061498; batch adversarial loss: 0.370332\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018083; batch adversarial loss: 0.417916\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012046; batch adversarial loss: 0.494882\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003734; batch adversarial loss: 0.523249\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032564; batch adversarial loss: 0.410385\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014094; batch adversarial loss: 0.560427\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011658; batch adversarial loss: 0.516681\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007357; batch adversarial loss: 0.529548\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012645; batch adversarial loss: 0.464960\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007309; batch adversarial loss: 0.577584\n",
      "epoch 191; iter: 0; batch classifier loss: 0.040819; batch adversarial loss: 0.549960\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012974; batch adversarial loss: 0.464663\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015270; batch adversarial loss: 0.383763\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033187; batch adversarial loss: 0.398830\n",
      "epoch 195; iter: 0; batch classifier loss: 0.054799; batch adversarial loss: 0.443312\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015454; batch adversarial loss: 0.472994\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025518; batch adversarial loss: 0.405580\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029560; batch adversarial loss: 0.436159\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011094; batch adversarial loss: 0.426114\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702023; batch adversarial loss: 0.577713\n",
      "epoch 1; iter: 0; batch classifier loss: 0.394051; batch adversarial loss: 0.602369\n",
      "epoch 2; iter: 0; batch classifier loss: 0.383659; batch adversarial loss: 0.575571\n",
      "epoch 3; iter: 0; batch classifier loss: 0.257904; batch adversarial loss: 0.572568\n",
      "epoch 4; iter: 0; batch classifier loss: 0.459025; batch adversarial loss: 0.595256\n",
      "epoch 5; iter: 0; batch classifier loss: 0.348216; batch adversarial loss: 0.644787\n",
      "epoch 6; iter: 0; batch classifier loss: 0.288657; batch adversarial loss: 0.563807\n",
      "epoch 7; iter: 0; batch classifier loss: 0.277185; batch adversarial loss: 0.543514\n",
      "epoch 8; iter: 0; batch classifier loss: 0.292873; batch adversarial loss: 0.529859\n",
      "epoch 9; iter: 0; batch classifier loss: 0.308761; batch adversarial loss: 0.514840\n",
      "epoch 10; iter: 0; batch classifier loss: 0.369604; batch adversarial loss: 0.521950\n",
      "epoch 11; iter: 0; batch classifier loss: 0.384927; batch adversarial loss: 0.626013\n",
      "epoch 12; iter: 0; batch classifier loss: 0.235919; batch adversarial loss: 0.501184\n",
      "epoch 13; iter: 0; batch classifier loss: 0.204981; batch adversarial loss: 0.564612\n",
      "epoch 14; iter: 0; batch classifier loss: 0.344126; batch adversarial loss: 0.585311\n",
      "epoch 15; iter: 0; batch classifier loss: 0.252743; batch adversarial loss: 0.536691\n",
      "epoch 16; iter: 0; batch classifier loss: 0.318144; batch adversarial loss: 0.528046\n",
      "epoch 17; iter: 0; batch classifier loss: 0.284212; batch adversarial loss: 0.504236\n",
      "epoch 18; iter: 0; batch classifier loss: 0.306640; batch adversarial loss: 0.516675\n",
      "epoch 19; iter: 0; batch classifier loss: 0.332823; batch adversarial loss: 0.557920\n",
      "epoch 20; iter: 0; batch classifier loss: 0.260007; batch adversarial loss: 0.465073\n",
      "epoch 21; iter: 0; batch classifier loss: 0.268530; batch adversarial loss: 0.464997\n",
      "epoch 22; iter: 0; batch classifier loss: 0.322936; batch adversarial loss: 0.465517\n",
      "epoch 23; iter: 0; batch classifier loss: 0.365054; batch adversarial loss: 0.524450\n",
      "epoch 24; iter: 0; batch classifier loss: 0.343595; batch adversarial loss: 0.402731\n",
      "epoch 25; iter: 0; batch classifier loss: 0.219493; batch adversarial loss: 0.466469\n",
      "epoch 26; iter: 0; batch classifier loss: 0.126701; batch adversarial loss: 0.409119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.126354; batch adversarial loss: 0.461979\n",
      "epoch 28; iter: 0; batch classifier loss: 0.125357; batch adversarial loss: 0.513435\n",
      "epoch 29; iter: 0; batch classifier loss: 0.091156; batch adversarial loss: 0.450191\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138595; batch adversarial loss: 0.382235\n",
      "epoch 31; iter: 0; batch classifier loss: 0.122666; batch adversarial loss: 0.439249\n",
      "epoch 32; iter: 0; batch classifier loss: 0.093715; batch adversarial loss: 0.412424\n",
      "epoch 33; iter: 0; batch classifier loss: 0.160200; batch adversarial loss: 0.541156\n",
      "epoch 34; iter: 0; batch classifier loss: 0.134338; batch adversarial loss: 0.534925\n",
      "epoch 35; iter: 0; batch classifier loss: 0.113599; batch adversarial loss: 0.514153\n",
      "epoch 36; iter: 0; batch classifier loss: 0.098953; batch adversarial loss: 0.439867\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113918; batch adversarial loss: 0.478955\n",
      "epoch 38; iter: 0; batch classifier loss: 0.078900; batch adversarial loss: 0.465334\n",
      "epoch 39; iter: 0; batch classifier loss: 0.079307; batch adversarial loss: 0.442656\n",
      "epoch 40; iter: 0; batch classifier loss: 0.107030; batch adversarial loss: 0.423202\n",
      "epoch 41; iter: 0; batch classifier loss: 0.114088; batch adversarial loss: 0.438660\n",
      "epoch 42; iter: 0; batch classifier loss: 0.074403; batch adversarial loss: 0.463435\n",
      "epoch 43; iter: 0; batch classifier loss: 0.129465; batch adversarial loss: 0.405462\n",
      "epoch 44; iter: 0; batch classifier loss: 0.071372; batch adversarial loss: 0.469418\n",
      "epoch 45; iter: 0; batch classifier loss: 0.151548; batch adversarial loss: 0.505940\n",
      "epoch 46; iter: 0; batch classifier loss: 0.096725; batch adversarial loss: 0.397157\n",
      "epoch 47; iter: 0; batch classifier loss: 0.087543; batch adversarial loss: 0.484459\n",
      "epoch 48; iter: 0; batch classifier loss: 0.105005; batch adversarial loss: 0.431809\n",
      "epoch 49; iter: 0; batch classifier loss: 0.075551; batch adversarial loss: 0.589387\n",
      "epoch 50; iter: 0; batch classifier loss: 0.079081; batch adversarial loss: 0.483043\n",
      "epoch 51; iter: 0; batch classifier loss: 0.078999; batch adversarial loss: 0.426625\n",
      "epoch 52; iter: 0; batch classifier loss: 0.158903; batch adversarial loss: 0.428661\n",
      "epoch 53; iter: 0; batch classifier loss: 0.090204; batch adversarial loss: 0.412014\n",
      "epoch 54; iter: 0; batch classifier loss: 0.130806; batch adversarial loss: 0.434141\n",
      "epoch 55; iter: 0; batch classifier loss: 0.082463; batch adversarial loss: 0.528455\n",
      "epoch 56; iter: 0; batch classifier loss: 0.167499; batch adversarial loss: 0.378431\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095484; batch adversarial loss: 0.456411\n",
      "epoch 58; iter: 0; batch classifier loss: 0.075492; batch adversarial loss: 0.459328\n",
      "epoch 59; iter: 0; batch classifier loss: 0.064883; batch adversarial loss: 0.575337\n",
      "epoch 60; iter: 0; batch classifier loss: 0.104602; batch adversarial loss: 0.506767\n",
      "epoch 61; iter: 0; batch classifier loss: 0.125052; batch adversarial loss: 0.370726\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089733; batch adversarial loss: 0.483977\n",
      "epoch 63; iter: 0; batch classifier loss: 0.108310; batch adversarial loss: 0.475219\n",
      "epoch 64; iter: 0; batch classifier loss: 0.089968; batch adversarial loss: 0.495013\n",
      "epoch 65; iter: 0; batch classifier loss: 0.107069; batch adversarial loss: 0.373774\n",
      "epoch 66; iter: 0; batch classifier loss: 0.099163; batch adversarial loss: 0.517612\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079049; batch adversarial loss: 0.468781\n",
      "epoch 68; iter: 0; batch classifier loss: 0.149064; batch adversarial loss: 0.501644\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078171; batch adversarial loss: 0.532714\n",
      "epoch 70; iter: 0; batch classifier loss: 0.162905; batch adversarial loss: 0.450925\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064390; batch adversarial loss: 0.555425\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082332; batch adversarial loss: 0.440700\n",
      "epoch 73; iter: 0; batch classifier loss: 0.115608; batch adversarial loss: 0.433124\n",
      "epoch 74; iter: 0; batch classifier loss: 0.074171; batch adversarial loss: 0.442974\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061268; batch adversarial loss: 0.491411\n",
      "epoch 76; iter: 0; batch classifier loss: 0.087648; batch adversarial loss: 0.541421\n",
      "epoch 77; iter: 0; batch classifier loss: 0.081734; batch adversarial loss: 0.448686\n",
      "epoch 78; iter: 0; batch classifier loss: 0.120927; batch adversarial loss: 0.420876\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065151; batch adversarial loss: 0.495730\n",
      "epoch 80; iter: 0; batch classifier loss: 0.081603; batch adversarial loss: 0.445701\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096257; batch adversarial loss: 0.487285\n",
      "epoch 82; iter: 0; batch classifier loss: 0.159175; batch adversarial loss: 0.490675\n",
      "epoch 83; iter: 0; batch classifier loss: 0.094705; batch adversarial loss: 0.562983\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075014; batch adversarial loss: 0.452852\n",
      "epoch 85; iter: 0; batch classifier loss: 0.155187; batch adversarial loss: 0.455923\n",
      "epoch 86; iter: 0; batch classifier loss: 0.075032; batch adversarial loss: 0.475872\n",
      "epoch 87; iter: 0; batch classifier loss: 0.099860; batch adversarial loss: 0.481847\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078171; batch adversarial loss: 0.467557\n",
      "epoch 89; iter: 0; batch classifier loss: 0.087105; batch adversarial loss: 0.429408\n",
      "epoch 90; iter: 0; batch classifier loss: 0.084399; batch adversarial loss: 0.449330\n",
      "epoch 91; iter: 0; batch classifier loss: 0.081073; batch adversarial loss: 0.530426\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082596; batch adversarial loss: 0.469803\n",
      "epoch 93; iter: 0; batch classifier loss: 0.093910; batch adversarial loss: 0.357079\n",
      "epoch 94; iter: 0; batch classifier loss: 0.086937; batch adversarial loss: 0.424591\n",
      "epoch 95; iter: 0; batch classifier loss: 0.092249; batch adversarial loss: 0.486950\n",
      "epoch 96; iter: 0; batch classifier loss: 0.119726; batch adversarial loss: 0.473068\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063581; batch adversarial loss: 0.573485\n",
      "epoch 98; iter: 0; batch classifier loss: 0.102391; batch adversarial loss: 0.455273\n",
      "epoch 99; iter: 0; batch classifier loss: 0.087321; batch adversarial loss: 0.472137\n",
      "epoch 100; iter: 0; batch classifier loss: 0.096862; batch adversarial loss: 0.471115\n",
      "epoch 101; iter: 0; batch classifier loss: 0.069833; batch adversarial loss: 0.536495\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079229; batch adversarial loss: 0.447185\n",
      "epoch 103; iter: 0; batch classifier loss: 0.141747; batch adversarial loss: 0.551741\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069896; batch adversarial loss: 0.503476\n",
      "epoch 105; iter: 0; batch classifier loss: 0.089854; batch adversarial loss: 0.451446\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052922; batch adversarial loss: 0.482153\n",
      "epoch 107; iter: 0; batch classifier loss: 0.085220; batch adversarial loss: 0.546786\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041550; batch adversarial loss: 0.431158\n",
      "epoch 109; iter: 0; batch classifier loss: 0.094089; batch adversarial loss: 0.508826\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023585; batch adversarial loss: 0.526702\n",
      "epoch 111; iter: 0; batch classifier loss: 0.085028; batch adversarial loss: 0.523941\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053240; batch adversarial loss: 0.416364\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047569; batch adversarial loss: 0.492319\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037006; batch adversarial loss: 0.468685\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051943; batch adversarial loss: 0.444939\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054288; batch adversarial loss: 0.516816\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036784; batch adversarial loss: 0.454118\n",
      "epoch 118; iter: 0; batch classifier loss: 0.058050; batch adversarial loss: 0.482736\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043840; batch adversarial loss: 0.461974\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041476; batch adversarial loss: 0.484382\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029296; batch adversarial loss: 0.395137\n",
      "epoch 122; iter: 0; batch classifier loss: 0.092892; batch adversarial loss: 0.434537\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024820; batch adversarial loss: 0.466414\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055714; batch adversarial loss: 0.449094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.062646; batch adversarial loss: 0.499871\n",
      "epoch 126; iter: 0; batch classifier loss: 0.056858; batch adversarial loss: 0.410134\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036738; batch adversarial loss: 0.497605\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024017; batch adversarial loss: 0.425524\n",
      "epoch 129; iter: 0; batch classifier loss: 0.054172; batch adversarial loss: 0.536765\n",
      "epoch 130; iter: 0; batch classifier loss: 0.055333; batch adversarial loss: 0.385744\n",
      "epoch 131; iter: 0; batch classifier loss: 0.066639; batch adversarial loss: 0.482900\n",
      "epoch 132; iter: 0; batch classifier loss: 0.071572; batch adversarial loss: 0.472010\n",
      "epoch 133; iter: 0; batch classifier loss: 0.065202; batch adversarial loss: 0.543476\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018356; batch adversarial loss: 0.495948\n",
      "epoch 135; iter: 0; batch classifier loss: 0.088296; batch adversarial loss: 0.506154\n",
      "epoch 136; iter: 0; batch classifier loss: 0.051016; batch adversarial loss: 0.535020\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041408; batch adversarial loss: 0.473946\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034250; batch adversarial loss: 0.445617\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050082; batch adversarial loss: 0.462929\n",
      "epoch 140; iter: 0; batch classifier loss: 0.054860; batch adversarial loss: 0.360470\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033056; batch adversarial loss: 0.464725\n",
      "epoch 142; iter: 0; batch classifier loss: 0.058989; batch adversarial loss: 0.528926\n",
      "epoch 143; iter: 0; batch classifier loss: 0.089299; batch adversarial loss: 0.550973\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048912; batch adversarial loss: 0.500215\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016375; batch adversarial loss: 0.484475\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022358; batch adversarial loss: 0.424724\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033392; batch adversarial loss: 0.512726\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014685; batch adversarial loss: 0.440427\n",
      "epoch 149; iter: 0; batch classifier loss: 0.058338; batch adversarial loss: 0.496319\n",
      "epoch 150; iter: 0; batch classifier loss: 0.041481; batch adversarial loss: 0.354973\n",
      "epoch 151; iter: 0; batch classifier loss: 0.059598; batch adversarial loss: 0.395217\n",
      "epoch 152; iter: 0; batch classifier loss: 0.052886; batch adversarial loss: 0.465163\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030353; batch adversarial loss: 0.407208\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046530; batch adversarial loss: 0.381330\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025400; batch adversarial loss: 0.438444\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041531; batch adversarial loss: 0.442930\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014460; batch adversarial loss: 0.406210\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018200; batch adversarial loss: 0.423685\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014289; batch adversarial loss: 0.533440\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030484; batch adversarial loss: 0.412220\n",
      "epoch 161; iter: 0; batch classifier loss: 0.044980; batch adversarial loss: 0.448988\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021118; batch adversarial loss: 0.485131\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013375; batch adversarial loss: 0.479338\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018846; batch adversarial loss: 0.455224\n",
      "epoch 165; iter: 0; batch classifier loss: 0.045572; batch adversarial loss: 0.516999\n",
      "epoch 166; iter: 0; batch classifier loss: 0.056400; batch adversarial loss: 0.440495\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032966; batch adversarial loss: 0.453305\n",
      "epoch 168; iter: 0; batch classifier loss: 0.053194; batch adversarial loss: 0.511789\n",
      "epoch 169; iter: 0; batch classifier loss: 0.041519; batch adversarial loss: 0.544280\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015165; batch adversarial loss: 0.431579\n",
      "epoch 171; iter: 0; batch classifier loss: 0.049478; batch adversarial loss: 0.484499\n",
      "epoch 172; iter: 0; batch classifier loss: 0.071655; batch adversarial loss: 0.465657\n",
      "epoch 173; iter: 0; batch classifier loss: 0.005974; batch adversarial loss: 0.483876\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027845; batch adversarial loss: 0.491880\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013547; batch adversarial loss: 0.421710\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010739; batch adversarial loss: 0.485442\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030070; batch adversarial loss: 0.447246\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024732; batch adversarial loss: 0.398255\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030418; batch adversarial loss: 0.465959\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018024; batch adversarial loss: 0.408149\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017412; batch adversarial loss: 0.485380\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034607; batch adversarial loss: 0.331646\n",
      "epoch 183; iter: 0; batch classifier loss: 0.058294; batch adversarial loss: 0.400223\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020094; batch adversarial loss: 0.438611\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023436; batch adversarial loss: 0.419729\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015588; batch adversarial loss: 0.557099\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035716; batch adversarial loss: 0.464627\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013016; batch adversarial loss: 0.452201\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026000; batch adversarial loss: 0.546002\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016863; batch adversarial loss: 0.420878\n",
      "epoch 191; iter: 0; batch classifier loss: 0.053880; batch adversarial loss: 0.369023\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023174; batch adversarial loss: 0.533149\n",
      "epoch 193; iter: 0; batch classifier loss: 0.047167; batch adversarial loss: 0.464548\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036368; batch adversarial loss: 0.528362\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028831; batch adversarial loss: 0.475689\n",
      "epoch 196; iter: 0; batch classifier loss: 0.036420; batch adversarial loss: 0.442909\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039127; batch adversarial loss: 0.449444\n",
      "epoch 198; iter: 0; batch classifier loss: 0.054793; batch adversarial loss: 0.513944\n",
      "epoch 199; iter: 0; batch classifier loss: 0.045912; batch adversarial loss: 0.483045\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704616; batch adversarial loss: 0.865703\n",
      "epoch 1; iter: 0; batch classifier loss: 0.485997; batch adversarial loss: 0.839939\n",
      "epoch 2; iter: 0; batch classifier loss: 0.499299; batch adversarial loss: 0.809834\n",
      "epoch 3; iter: 0; batch classifier loss: 0.701921; batch adversarial loss: 0.776665\n",
      "epoch 4; iter: 0; batch classifier loss: 0.867240; batch adversarial loss: 0.722903\n",
      "epoch 5; iter: 0; batch classifier loss: 0.810882; batch adversarial loss: 0.647609\n",
      "epoch 6; iter: 0; batch classifier loss: 0.721755; batch adversarial loss: 0.574215\n",
      "epoch 7; iter: 0; batch classifier loss: 0.399503; batch adversarial loss: 0.585283\n",
      "epoch 8; iter: 0; batch classifier loss: 0.271833; batch adversarial loss: 0.581816\n",
      "epoch 9; iter: 0; batch classifier loss: 0.351744; batch adversarial loss: 0.537705\n",
      "epoch 10; iter: 0; batch classifier loss: 0.335709; batch adversarial loss: 0.519092\n",
      "epoch 11; iter: 0; batch classifier loss: 0.268198; batch adversarial loss: 0.547899\n",
      "epoch 12; iter: 0; batch classifier loss: 0.338617; batch adversarial loss: 0.551128\n",
      "epoch 13; iter: 0; batch classifier loss: 0.333735; batch adversarial loss: 0.562494\n",
      "epoch 14; iter: 0; batch classifier loss: 0.354290; batch adversarial loss: 0.494108\n",
      "epoch 15; iter: 0; batch classifier loss: 0.317146; batch adversarial loss: 0.498934\n",
      "epoch 16; iter: 0; batch classifier loss: 0.349920; batch adversarial loss: 0.518091\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348293; batch adversarial loss: 0.562720\n",
      "epoch 18; iter: 0; batch classifier loss: 0.309967; batch adversarial loss: 0.495310\n",
      "epoch 19; iter: 0; batch classifier loss: 0.299595; batch adversarial loss: 0.547494\n",
      "epoch 20; iter: 0; batch classifier loss: 0.267870; batch adversarial loss: 0.489656\n",
      "epoch 21; iter: 0; batch classifier loss: 0.291489; batch adversarial loss: 0.483166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.305777; batch adversarial loss: 0.429031\n",
      "epoch 23; iter: 0; batch classifier loss: 0.297518; batch adversarial loss: 0.487442\n",
      "epoch 24; iter: 0; batch classifier loss: 0.304937; batch adversarial loss: 0.462890\n",
      "epoch 25; iter: 0; batch classifier loss: 0.236683; batch adversarial loss: 0.493038\n",
      "epoch 26; iter: 0; batch classifier loss: 0.203730; batch adversarial loss: 0.380451\n",
      "epoch 27; iter: 0; batch classifier loss: 0.174807; batch adversarial loss: 0.463459\n",
      "epoch 28; iter: 0; batch classifier loss: 0.175402; batch adversarial loss: 0.525129\n",
      "epoch 29; iter: 0; batch classifier loss: 0.211945; batch adversarial loss: 0.487446\n",
      "epoch 30; iter: 0; batch classifier loss: 0.222475; batch adversarial loss: 0.508918\n",
      "epoch 31; iter: 0; batch classifier loss: 0.261726; batch adversarial loss: 0.496464\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154167; batch adversarial loss: 0.379518\n",
      "epoch 33; iter: 0; batch classifier loss: 0.182528; batch adversarial loss: 0.481465\n",
      "epoch 34; iter: 0; batch classifier loss: 0.177081; batch adversarial loss: 0.448242\n",
      "epoch 35; iter: 0; batch classifier loss: 0.152336; batch adversarial loss: 0.500911\n",
      "epoch 36; iter: 0; batch classifier loss: 0.179615; batch adversarial loss: 0.391536\n",
      "epoch 37; iter: 0; batch classifier loss: 0.152705; batch adversarial loss: 0.528207\n",
      "epoch 38; iter: 0; batch classifier loss: 0.159121; batch adversarial loss: 0.379622\n",
      "epoch 39; iter: 0; batch classifier loss: 0.143732; batch adversarial loss: 0.444734\n",
      "epoch 40; iter: 0; batch classifier loss: 0.108835; batch adversarial loss: 0.466696\n",
      "epoch 41; iter: 0; batch classifier loss: 0.128609; batch adversarial loss: 0.471199\n",
      "epoch 42; iter: 0; batch classifier loss: 0.127737; batch adversarial loss: 0.483329\n",
      "epoch 43; iter: 0; batch classifier loss: 0.078057; batch adversarial loss: 0.487408\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136525; batch adversarial loss: 0.482505\n",
      "epoch 45; iter: 0; batch classifier loss: 0.136065; batch adversarial loss: 0.464980\n",
      "epoch 46; iter: 0; batch classifier loss: 0.115668; batch adversarial loss: 0.365725\n",
      "epoch 47; iter: 0; batch classifier loss: 0.118341; batch adversarial loss: 0.492552\n",
      "epoch 48; iter: 0; batch classifier loss: 0.140466; batch adversarial loss: 0.496672\n",
      "epoch 49; iter: 0; batch classifier loss: 0.075265; batch adversarial loss: 0.521140\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087229; batch adversarial loss: 0.407769\n",
      "epoch 51; iter: 0; batch classifier loss: 0.055108; batch adversarial loss: 0.445879\n",
      "epoch 52; iter: 0; batch classifier loss: 0.058256; batch adversarial loss: 0.475357\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094479; batch adversarial loss: 0.562765\n",
      "epoch 54; iter: 0; batch classifier loss: 0.118037; batch adversarial loss: 0.446586\n",
      "epoch 55; iter: 0; batch classifier loss: 0.115101; batch adversarial loss: 0.460805\n",
      "epoch 56; iter: 0; batch classifier loss: 0.073076; batch adversarial loss: 0.427500\n",
      "epoch 57; iter: 0; batch classifier loss: 0.144965; batch adversarial loss: 0.450113\n",
      "epoch 58; iter: 0; batch classifier loss: 0.056821; batch adversarial loss: 0.480833\n",
      "epoch 59; iter: 0; batch classifier loss: 0.093432; batch adversarial loss: 0.371001\n",
      "epoch 60; iter: 0; batch classifier loss: 0.096200; batch adversarial loss: 0.417356\n",
      "epoch 61; iter: 0; batch classifier loss: 0.047758; batch adversarial loss: 0.567808\n",
      "epoch 62; iter: 0; batch classifier loss: 0.049294; batch adversarial loss: 0.473880\n",
      "epoch 63; iter: 0; batch classifier loss: 0.083905; batch adversarial loss: 0.351722\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073732; batch adversarial loss: 0.473207\n",
      "epoch 65; iter: 0; batch classifier loss: 0.073808; batch adversarial loss: 0.538861\n",
      "epoch 66; iter: 0; batch classifier loss: 0.056808; batch adversarial loss: 0.483223\n",
      "epoch 67; iter: 0; batch classifier loss: 0.035945; batch adversarial loss: 0.562995\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094235; batch adversarial loss: 0.481514\n",
      "epoch 69; iter: 0; batch classifier loss: 0.069367; batch adversarial loss: 0.543791\n",
      "epoch 70; iter: 0; batch classifier loss: 0.048579; batch adversarial loss: 0.406824\n",
      "epoch 71; iter: 0; batch classifier loss: 0.059845; batch adversarial loss: 0.496546\n",
      "epoch 72; iter: 0; batch classifier loss: 0.116331; batch adversarial loss: 0.503380\n",
      "epoch 73; iter: 0; batch classifier loss: 0.042585; batch adversarial loss: 0.337059\n",
      "epoch 74; iter: 0; batch classifier loss: 0.046095; batch adversarial loss: 0.474308\n",
      "epoch 75; iter: 0; batch classifier loss: 0.029329; batch adversarial loss: 0.475711\n",
      "epoch 76; iter: 0; batch classifier loss: 0.044003; batch adversarial loss: 0.471592\n",
      "epoch 77; iter: 0; batch classifier loss: 0.042932; batch adversarial loss: 0.488244\n",
      "epoch 78; iter: 0; batch classifier loss: 0.051859; batch adversarial loss: 0.462090\n",
      "epoch 79; iter: 0; batch classifier loss: 0.115922; batch adversarial loss: 0.372668\n",
      "epoch 80; iter: 0; batch classifier loss: 0.027237; batch adversarial loss: 0.484855\n",
      "epoch 81; iter: 0; batch classifier loss: 0.037521; batch adversarial loss: 0.448789\n",
      "epoch 82; iter: 0; batch classifier loss: 0.026325; batch adversarial loss: 0.397159\n",
      "epoch 83; iter: 0; batch classifier loss: 0.027566; batch adversarial loss: 0.462429\n",
      "epoch 84; iter: 0; batch classifier loss: 0.049384; batch adversarial loss: 0.489653\n",
      "epoch 85; iter: 0; batch classifier loss: 0.036759; batch adversarial loss: 0.520481\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052543; batch adversarial loss: 0.422368\n",
      "epoch 87; iter: 0; batch classifier loss: 0.052500; batch adversarial loss: 0.392763\n",
      "epoch 88; iter: 0; batch classifier loss: 0.037865; batch adversarial loss: 0.514095\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053383; batch adversarial loss: 0.408018\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060157; batch adversarial loss: 0.529217\n",
      "epoch 91; iter: 0; batch classifier loss: 0.028108; batch adversarial loss: 0.426756\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044433; batch adversarial loss: 0.467479\n",
      "epoch 93; iter: 0; batch classifier loss: 0.034673; batch adversarial loss: 0.396728\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043313; batch adversarial loss: 0.391382\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048715; batch adversarial loss: 0.490595\n",
      "epoch 96; iter: 0; batch classifier loss: 0.019316; batch adversarial loss: 0.558974\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073977; batch adversarial loss: 0.490502\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047680; batch adversarial loss: 0.466984\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053380; batch adversarial loss: 0.473443\n",
      "epoch 100; iter: 0; batch classifier loss: 0.097927; batch adversarial loss: 0.466170\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042357; batch adversarial loss: 0.404386\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031613; batch adversarial loss: 0.534571\n",
      "epoch 103; iter: 0; batch classifier loss: 0.029687; batch adversarial loss: 0.467163\n",
      "epoch 104; iter: 0; batch classifier loss: 0.032780; batch adversarial loss: 0.465471\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044104; batch adversarial loss: 0.547894\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042910; batch adversarial loss: 0.442258\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040340; batch adversarial loss: 0.422212\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028011; batch adversarial loss: 0.562025\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040022; batch adversarial loss: 0.461895\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031200; batch adversarial loss: 0.439019\n",
      "epoch 111; iter: 0; batch classifier loss: 0.024220; batch adversarial loss: 0.458222\n",
      "epoch 112; iter: 0; batch classifier loss: 0.015687; batch adversarial loss: 0.455972\n",
      "epoch 113; iter: 0; batch classifier loss: 0.019595; batch adversarial loss: 0.366603\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027441; batch adversarial loss: 0.396628\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046034; batch adversarial loss: 0.508005\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026164; batch adversarial loss: 0.444289\n",
      "epoch 117; iter: 0; batch classifier loss: 0.012535; batch adversarial loss: 0.384196\n",
      "epoch 118; iter: 0; batch classifier loss: 0.023210; batch adversarial loss: 0.544327\n",
      "epoch 119; iter: 0; batch classifier loss: 0.020828; batch adversarial loss: 0.374383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.045416; batch adversarial loss: 0.351276\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048559; batch adversarial loss: 0.412744\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025434; batch adversarial loss: 0.452364\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041752; batch adversarial loss: 0.472115\n",
      "epoch 124; iter: 0; batch classifier loss: 0.013999; batch adversarial loss: 0.457297\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058436; batch adversarial loss: 0.484669\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051283; batch adversarial loss: 0.482384\n",
      "epoch 127; iter: 0; batch classifier loss: 0.015884; batch adversarial loss: 0.454392\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036583; batch adversarial loss: 0.444897\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016925; batch adversarial loss: 0.512390\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019004; batch adversarial loss: 0.484932\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038429; batch adversarial loss: 0.445345\n",
      "epoch 132; iter: 0; batch classifier loss: 0.014827; batch adversarial loss: 0.414721\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018725; batch adversarial loss: 0.469865\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025194; batch adversarial loss: 0.499611\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020581; batch adversarial loss: 0.399830\n",
      "epoch 136; iter: 0; batch classifier loss: 0.006472; batch adversarial loss: 0.430596\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015724; batch adversarial loss: 0.485578\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014823; batch adversarial loss: 0.392231\n",
      "epoch 139; iter: 0; batch classifier loss: 0.011791; batch adversarial loss: 0.477299\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018282; batch adversarial loss: 0.412458\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045402; batch adversarial loss: 0.402502\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023657; batch adversarial loss: 0.451714\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025839; batch adversarial loss: 0.473027\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032061; batch adversarial loss: 0.442104\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038863; batch adversarial loss: 0.423489\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051900; batch adversarial loss: 0.483963\n",
      "epoch 147; iter: 0; batch classifier loss: 0.009626; batch adversarial loss: 0.443199\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045924; batch adversarial loss: 0.399500\n",
      "epoch 149; iter: 0; batch classifier loss: 0.047547; batch adversarial loss: 0.484843\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021014; batch adversarial loss: 0.434845\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015099; batch adversarial loss: 0.465231\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019241; batch adversarial loss: 0.415586\n",
      "epoch 153; iter: 0; batch classifier loss: 0.037474; batch adversarial loss: 0.452385\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020039; batch adversarial loss: 0.447875\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016428; batch adversarial loss: 0.537326\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018797; batch adversarial loss: 0.605644\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028191; batch adversarial loss: 0.434590\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013072; batch adversarial loss: 0.479245\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030342; batch adversarial loss: 0.421444\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015282; batch adversarial loss: 0.403109\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030736; batch adversarial loss: 0.424383\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041456; batch adversarial loss: 0.489380\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040603; batch adversarial loss: 0.392213\n",
      "epoch 164; iter: 0; batch classifier loss: 0.006267; batch adversarial loss: 0.455222\n",
      "epoch 165; iter: 0; batch classifier loss: 0.005183; batch adversarial loss: 0.449552\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015371; batch adversarial loss: 0.527900\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026981; batch adversarial loss: 0.442593\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016774; batch adversarial loss: 0.477384\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033320; batch adversarial loss: 0.509988\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034715; batch adversarial loss: 0.472067\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013271; batch adversarial loss: 0.496244\n",
      "epoch 172; iter: 0; batch classifier loss: 0.003653; batch adversarial loss: 0.508487\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022845; batch adversarial loss: 0.422426\n",
      "epoch 174; iter: 0; batch classifier loss: 0.044008; batch adversarial loss: 0.542385\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017098; batch adversarial loss: 0.449244\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020336; batch adversarial loss: 0.334444\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018067; batch adversarial loss: 0.417786\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013935; batch adversarial loss: 0.472304\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038888; batch adversarial loss: 0.378887\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013287; batch adversarial loss: 0.466306\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021694; batch adversarial loss: 0.404213\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020957; batch adversarial loss: 0.439844\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031166; batch adversarial loss: 0.468321\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019093; batch adversarial loss: 0.501190\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011532; batch adversarial loss: 0.348424\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005733; batch adversarial loss: 0.389154\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013148; batch adversarial loss: 0.559533\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015742; batch adversarial loss: 0.461563\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006679; batch adversarial loss: 0.419268\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016635; batch adversarial loss: 0.491550\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008096; batch adversarial loss: 0.518354\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013519; batch adversarial loss: 0.453928\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012894; batch adversarial loss: 0.387560\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020501; batch adversarial loss: 0.416098\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011237; batch adversarial loss: 0.543422\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005268; batch adversarial loss: 0.469792\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031917; batch adversarial loss: 0.406177\n",
      "epoch 198; iter: 0; batch classifier loss: 0.042152; batch adversarial loss: 0.379669\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015479; batch adversarial loss: 0.467241\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697911; batch adversarial loss: 0.914998\n",
      "epoch 1; iter: 0; batch classifier loss: 0.530833; batch adversarial loss: 0.894208\n",
      "epoch 2; iter: 0; batch classifier loss: 0.774278; batch adversarial loss: 0.919859\n",
      "epoch 3; iter: 0; batch classifier loss: 0.858666; batch adversarial loss: 0.837845\n",
      "epoch 4; iter: 0; batch classifier loss: 1.003902; batch adversarial loss: 0.770562\n",
      "epoch 5; iter: 0; batch classifier loss: 0.962793; batch adversarial loss: 0.681777\n",
      "epoch 6; iter: 0; batch classifier loss: 0.822622; batch adversarial loss: 0.624445\n",
      "epoch 7; iter: 0; batch classifier loss: 0.538712; batch adversarial loss: 0.586615\n",
      "epoch 8; iter: 0; batch classifier loss: 0.395582; batch adversarial loss: 0.533848\n",
      "epoch 9; iter: 0; batch classifier loss: 0.350666; batch adversarial loss: 0.547158\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374325; batch adversarial loss: 0.505214\n",
      "epoch 11; iter: 0; batch classifier loss: 0.337802; batch adversarial loss: 0.530554\n",
      "epoch 12; iter: 0; batch classifier loss: 0.305854; batch adversarial loss: 0.551435\n",
      "epoch 13; iter: 0; batch classifier loss: 0.390557; batch adversarial loss: 0.520463\n",
      "epoch 14; iter: 0; batch classifier loss: 0.347742; batch adversarial loss: 0.460092\n",
      "epoch 15; iter: 0; batch classifier loss: 0.373170; batch adversarial loss: 0.499390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.340553; batch adversarial loss: 0.499646\n",
      "epoch 17; iter: 0; batch classifier loss: 0.331874; batch adversarial loss: 0.508911\n",
      "epoch 18; iter: 0; batch classifier loss: 0.391914; batch adversarial loss: 0.474812\n",
      "epoch 19; iter: 0; batch classifier loss: 0.292712; batch adversarial loss: 0.507801\n",
      "epoch 20; iter: 0; batch classifier loss: 0.337715; batch adversarial loss: 0.430694\n",
      "epoch 21; iter: 0; batch classifier loss: 0.344563; batch adversarial loss: 0.426350\n",
      "epoch 22; iter: 0; batch classifier loss: 0.257609; batch adversarial loss: 0.523149\n",
      "epoch 23; iter: 0; batch classifier loss: 0.317759; batch adversarial loss: 0.467165\n",
      "epoch 24; iter: 0; batch classifier loss: 0.297178; batch adversarial loss: 0.433624\n",
      "epoch 25; iter: 0; batch classifier loss: 0.306512; batch adversarial loss: 0.476473\n",
      "epoch 26; iter: 0; batch classifier loss: 0.252322; batch adversarial loss: 0.410437\n",
      "epoch 27; iter: 0; batch classifier loss: 0.242943; batch adversarial loss: 0.513066\n",
      "epoch 28; iter: 0; batch classifier loss: 0.334226; batch adversarial loss: 0.435212\n",
      "epoch 29; iter: 0; batch classifier loss: 0.226307; batch adversarial loss: 0.497384\n",
      "epoch 30; iter: 0; batch classifier loss: 0.300442; batch adversarial loss: 0.500917\n",
      "epoch 31; iter: 0; batch classifier loss: 0.254930; batch adversarial loss: 0.440614\n",
      "epoch 32; iter: 0; batch classifier loss: 0.195023; batch adversarial loss: 0.414540\n",
      "epoch 33; iter: 0; batch classifier loss: 0.261999; batch adversarial loss: 0.429916\n",
      "epoch 34; iter: 0; batch classifier loss: 0.255057; batch adversarial loss: 0.426343\n",
      "epoch 35; iter: 0; batch classifier loss: 0.192270; batch adversarial loss: 0.450945\n",
      "epoch 36; iter: 0; batch classifier loss: 0.229787; batch adversarial loss: 0.474511\n",
      "epoch 37; iter: 0; batch classifier loss: 0.237499; batch adversarial loss: 0.457798\n",
      "epoch 38; iter: 0; batch classifier loss: 0.193456; batch adversarial loss: 0.496315\n",
      "epoch 39; iter: 0; batch classifier loss: 0.218190; batch adversarial loss: 0.488764\n",
      "epoch 40; iter: 0; batch classifier loss: 0.251186; batch adversarial loss: 0.500304\n",
      "epoch 41; iter: 0; batch classifier loss: 0.173860; batch adversarial loss: 0.419012\n",
      "epoch 42; iter: 0; batch classifier loss: 0.204570; batch adversarial loss: 0.491555\n",
      "epoch 43; iter: 0; batch classifier loss: 0.179294; batch adversarial loss: 0.411204\n",
      "epoch 44; iter: 0; batch classifier loss: 0.184309; batch adversarial loss: 0.496888\n",
      "epoch 45; iter: 0; batch classifier loss: 0.233714; batch adversarial loss: 0.499333\n",
      "epoch 46; iter: 0; batch classifier loss: 0.149657; batch adversarial loss: 0.441738\n",
      "epoch 47; iter: 0; batch classifier loss: 0.216504; batch adversarial loss: 0.481071\n",
      "epoch 48; iter: 0; batch classifier loss: 0.215498; batch adversarial loss: 0.389793\n",
      "epoch 49; iter: 0; batch classifier loss: 0.257093; batch adversarial loss: 0.461364\n",
      "epoch 50; iter: 0; batch classifier loss: 0.170148; batch adversarial loss: 0.573937\n",
      "epoch 51; iter: 0; batch classifier loss: 0.174262; batch adversarial loss: 0.430048\n",
      "epoch 52; iter: 0; batch classifier loss: 0.109117; batch adversarial loss: 0.430608\n",
      "epoch 53; iter: 0; batch classifier loss: 0.137037; batch adversarial loss: 0.409840\n",
      "epoch 54; iter: 0; batch classifier loss: 0.144851; batch adversarial loss: 0.414818\n",
      "epoch 55; iter: 0; batch classifier loss: 0.129459; batch adversarial loss: 0.357649\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119916; batch adversarial loss: 0.451139\n",
      "epoch 57; iter: 0; batch classifier loss: 0.172753; batch adversarial loss: 0.376787\n",
      "epoch 58; iter: 0; batch classifier loss: 0.153965; batch adversarial loss: 0.400518\n",
      "epoch 59; iter: 0; batch classifier loss: 0.141016; batch adversarial loss: 0.551897\n",
      "epoch 60; iter: 0; batch classifier loss: 0.135273; batch adversarial loss: 0.467921\n",
      "epoch 61; iter: 0; batch classifier loss: 0.193321; batch adversarial loss: 0.369623\n",
      "epoch 62; iter: 0; batch classifier loss: 0.176002; batch adversarial loss: 0.503025\n",
      "epoch 63; iter: 0; batch classifier loss: 0.116410; batch adversarial loss: 0.476256\n",
      "epoch 64; iter: 0; batch classifier loss: 0.109730; batch adversarial loss: 0.470079\n",
      "epoch 65; iter: 0; batch classifier loss: 0.089709; batch adversarial loss: 0.514230\n",
      "epoch 66; iter: 0; batch classifier loss: 0.113181; batch adversarial loss: 0.421615\n",
      "epoch 67; iter: 0; batch classifier loss: 0.098334; batch adversarial loss: 0.496068\n",
      "epoch 68; iter: 0; batch classifier loss: 0.091327; batch adversarial loss: 0.405480\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075383; batch adversarial loss: 0.420929\n",
      "epoch 70; iter: 0; batch classifier loss: 0.117402; batch adversarial loss: 0.403503\n",
      "epoch 71; iter: 0; batch classifier loss: 0.044863; batch adversarial loss: 0.504542\n",
      "epoch 72; iter: 0; batch classifier loss: 0.086461; batch adversarial loss: 0.514372\n",
      "epoch 73; iter: 0; batch classifier loss: 0.117508; batch adversarial loss: 0.398456\n",
      "epoch 74; iter: 0; batch classifier loss: 0.100129; batch adversarial loss: 0.456835\n",
      "epoch 75; iter: 0; batch classifier loss: 0.060493; batch adversarial loss: 0.396878\n",
      "epoch 76; iter: 0; batch classifier loss: 0.050051; batch adversarial loss: 0.449478\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056877; batch adversarial loss: 0.410365\n",
      "epoch 78; iter: 0; batch classifier loss: 0.076457; batch adversarial loss: 0.432592\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063025; batch adversarial loss: 0.478939\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088660; batch adversarial loss: 0.389339\n",
      "epoch 81; iter: 0; batch classifier loss: 0.082916; batch adversarial loss: 0.518992\n",
      "epoch 82; iter: 0; batch classifier loss: 0.089350; batch adversarial loss: 0.550257\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086826; batch adversarial loss: 0.443327\n",
      "epoch 84; iter: 0; batch classifier loss: 0.044460; batch adversarial loss: 0.449310\n",
      "epoch 85; iter: 0; batch classifier loss: 0.036614; batch adversarial loss: 0.407232\n",
      "epoch 86; iter: 0; batch classifier loss: 0.035745; batch adversarial loss: 0.468245\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057207; batch adversarial loss: 0.433815\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078234; batch adversarial loss: 0.409135\n",
      "epoch 89; iter: 0; batch classifier loss: 0.072836; batch adversarial loss: 0.518248\n",
      "epoch 90; iter: 0; batch classifier loss: 0.046409; batch adversarial loss: 0.472357\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048327; batch adversarial loss: 0.415408\n",
      "epoch 92; iter: 0; batch classifier loss: 0.046451; batch adversarial loss: 0.405118\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055178; batch adversarial loss: 0.461589\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058154; batch adversarial loss: 0.428751\n",
      "epoch 95; iter: 0; batch classifier loss: 0.021341; batch adversarial loss: 0.455402\n",
      "epoch 96; iter: 0; batch classifier loss: 0.029593; batch adversarial loss: 0.375526\n",
      "epoch 97; iter: 0; batch classifier loss: 0.036643; batch adversarial loss: 0.475381\n",
      "epoch 98; iter: 0; batch classifier loss: 0.016155; batch adversarial loss: 0.415698\n",
      "epoch 99; iter: 0; batch classifier loss: 0.021369; batch adversarial loss: 0.460380\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065465; batch adversarial loss: 0.396230\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048702; batch adversarial loss: 0.467006\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043005; batch adversarial loss: 0.425510\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054149; batch adversarial loss: 0.437169\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038091; batch adversarial loss: 0.411670\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058384; batch adversarial loss: 0.489692\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055910; batch adversarial loss: 0.377082\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024531; batch adversarial loss: 0.497960\n",
      "epoch 108; iter: 0; batch classifier loss: 0.026610; batch adversarial loss: 0.356268\n",
      "epoch 109; iter: 0; batch classifier loss: 0.034916; batch adversarial loss: 0.420939\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037466; batch adversarial loss: 0.381185\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031898; batch adversarial loss: 0.442632\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031217; batch adversarial loss: 0.388010\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044334; batch adversarial loss: 0.492791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.058567; batch adversarial loss: 0.583921\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048216; batch adversarial loss: 0.413099\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038643; batch adversarial loss: 0.456407\n",
      "epoch 117; iter: 0; batch classifier loss: 0.009400; batch adversarial loss: 0.466680\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033333; batch adversarial loss: 0.513626\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032068; batch adversarial loss: 0.434121\n",
      "epoch 120; iter: 0; batch classifier loss: 0.017931; batch adversarial loss: 0.425636\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027114; batch adversarial loss: 0.478518\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028556; batch adversarial loss: 0.350395\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021428; batch adversarial loss: 0.381966\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035928; batch adversarial loss: 0.535115\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033841; batch adversarial loss: 0.544437\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033815; batch adversarial loss: 0.432475\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035849; batch adversarial loss: 0.407882\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053805; batch adversarial loss: 0.384327\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039234; batch adversarial loss: 0.496557\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048571; batch adversarial loss: 0.481870\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027158; batch adversarial loss: 0.461735\n",
      "epoch 132; iter: 0; batch classifier loss: 0.055137; batch adversarial loss: 0.502895\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028670; batch adversarial loss: 0.413592\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030626; batch adversarial loss: 0.526934\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022459; batch adversarial loss: 0.432517\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022985; batch adversarial loss: 0.545063\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034701; batch adversarial loss: 0.337891\n",
      "epoch 138; iter: 0; batch classifier loss: 0.012321; batch adversarial loss: 0.390343\n",
      "epoch 139; iter: 0; batch classifier loss: 0.012532; batch adversarial loss: 0.526076\n",
      "epoch 140; iter: 0; batch classifier loss: 0.042736; batch adversarial loss: 0.447870\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028136; batch adversarial loss: 0.523586\n",
      "epoch 142; iter: 0; batch classifier loss: 0.011043; batch adversarial loss: 0.449212\n",
      "epoch 143; iter: 0; batch classifier loss: 0.009286; batch adversarial loss: 0.411709\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031744; batch adversarial loss: 0.333000\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035946; batch adversarial loss: 0.464223\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013860; batch adversarial loss: 0.537835\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031007; batch adversarial loss: 0.484534\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021061; batch adversarial loss: 0.547934\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029156; batch adversarial loss: 0.386758\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011652; batch adversarial loss: 0.405948\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029554; batch adversarial loss: 0.410687\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017541; batch adversarial loss: 0.551398\n",
      "epoch 153; iter: 0; batch classifier loss: 0.006491; batch adversarial loss: 0.420809\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022207; batch adversarial loss: 0.578843\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011641; batch adversarial loss: 0.453305\n",
      "epoch 156; iter: 0; batch classifier loss: 0.089057; batch adversarial loss: 0.493930\n",
      "epoch 157; iter: 0; batch classifier loss: 0.004071; batch adversarial loss: 0.457756\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019618; batch adversarial loss: 0.403233\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024429; batch adversarial loss: 0.376713\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016642; batch adversarial loss: 0.405093\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026117; batch adversarial loss: 0.405975\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033993; batch adversarial loss: 0.472322\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030645; batch adversarial loss: 0.437505\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010045; batch adversarial loss: 0.444150\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041851; batch adversarial loss: 0.554077\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034412; batch adversarial loss: 0.416653\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026898; batch adversarial loss: 0.550934\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020963; batch adversarial loss: 0.425911\n",
      "epoch 169; iter: 0; batch classifier loss: 0.041044; batch adversarial loss: 0.508892\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012312; batch adversarial loss: 0.432533\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028802; batch adversarial loss: 0.421691\n",
      "epoch 172; iter: 0; batch classifier loss: 0.051424; batch adversarial loss: 0.450333\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008418; batch adversarial loss: 0.423881\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015994; batch adversarial loss: 0.444773\n",
      "epoch 175; iter: 0; batch classifier loss: 0.044135; batch adversarial loss: 0.352728\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020371; batch adversarial loss: 0.483160\n",
      "epoch 177; iter: 0; batch classifier loss: 0.007489; batch adversarial loss: 0.388782\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014156; batch adversarial loss: 0.420653\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013847; batch adversarial loss: 0.447826\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019376; batch adversarial loss: 0.421991\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014262; batch adversarial loss: 0.475863\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013494; batch adversarial loss: 0.424031\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011007; batch adversarial loss: 0.504447\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020867; batch adversarial loss: 0.394230\n",
      "epoch 185; iter: 0; batch classifier loss: 0.052828; batch adversarial loss: 0.531144\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014090; batch adversarial loss: 0.398451\n",
      "epoch 187; iter: 0; batch classifier loss: 0.003743; batch adversarial loss: 0.385129\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021098; batch adversarial loss: 0.314083\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012402; batch adversarial loss: 0.452336\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036197; batch adversarial loss: 0.486769\n",
      "epoch 191; iter: 0; batch classifier loss: 0.040796; batch adversarial loss: 0.390676\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026989; batch adversarial loss: 0.502064\n",
      "epoch 193; iter: 0; batch classifier loss: 0.044685; batch adversarial loss: 0.470037\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028101; batch adversarial loss: 0.390407\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014908; batch adversarial loss: 0.449184\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025883; batch adversarial loss: 0.378291\n",
      "epoch 197; iter: 0; batch classifier loss: 0.044541; batch adversarial loss: 0.422329\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003307; batch adversarial loss: 0.495668\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012441; batch adversarial loss: 0.485744\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693187; batch adversarial loss: 0.719061\n",
      "epoch 1; iter: 0; batch classifier loss: 0.476683; batch adversarial loss: 0.672452\n",
      "epoch 2; iter: 0; batch classifier loss: 0.404760; batch adversarial loss: 0.651779\n",
      "epoch 3; iter: 0; batch classifier loss: 0.356919; batch adversarial loss: 0.608427\n",
      "epoch 4; iter: 0; batch classifier loss: 0.360195; batch adversarial loss: 0.588796\n",
      "epoch 5; iter: 0; batch classifier loss: 0.316033; batch adversarial loss: 0.601347\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315225; batch adversarial loss: 0.571204\n",
      "epoch 7; iter: 0; batch classifier loss: 0.354373; batch adversarial loss: 0.521894\n",
      "epoch 8; iter: 0; batch classifier loss: 0.410490; batch adversarial loss: 0.564015\n",
      "epoch 9; iter: 0; batch classifier loss: 0.453210; batch adversarial loss: 0.524243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.558166; batch adversarial loss: 0.516474\n",
      "epoch 11; iter: 0; batch classifier loss: 0.401902; batch adversarial loss: 0.518534\n",
      "epoch 12; iter: 0; batch classifier loss: 0.525204; batch adversarial loss: 0.541263\n",
      "epoch 13; iter: 0; batch classifier loss: 0.347785; batch adversarial loss: 0.515632\n",
      "epoch 14; iter: 0; batch classifier loss: 0.428319; batch adversarial loss: 0.486265\n",
      "epoch 15; iter: 0; batch classifier loss: 0.295344; batch adversarial loss: 0.556516\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281332; batch adversarial loss: 0.525223\n",
      "epoch 17; iter: 0; batch classifier loss: 0.293352; batch adversarial loss: 0.564049\n",
      "epoch 18; iter: 0; batch classifier loss: 0.340510; batch adversarial loss: 0.454115\n",
      "epoch 19; iter: 0; batch classifier loss: 0.234252; batch adversarial loss: 0.498243\n",
      "epoch 20; iter: 0; batch classifier loss: 0.334696; batch adversarial loss: 0.475904\n",
      "epoch 21; iter: 0; batch classifier loss: 0.244911; batch adversarial loss: 0.474897\n",
      "epoch 22; iter: 0; batch classifier loss: 0.374601; batch adversarial loss: 0.494357\n",
      "epoch 23; iter: 0; batch classifier loss: 0.267348; batch adversarial loss: 0.486024\n",
      "epoch 24; iter: 0; batch classifier loss: 0.263362; batch adversarial loss: 0.439972\n",
      "epoch 25; iter: 0; batch classifier loss: 0.265217; batch adversarial loss: 0.479339\n",
      "epoch 26; iter: 0; batch classifier loss: 0.259357; batch adversarial loss: 0.510239\n",
      "epoch 27; iter: 0; batch classifier loss: 0.210431; batch adversarial loss: 0.455124\n",
      "epoch 28; iter: 0; batch classifier loss: 0.241910; batch adversarial loss: 0.483715\n",
      "epoch 29; iter: 0; batch classifier loss: 0.244424; batch adversarial loss: 0.450406\n",
      "epoch 30; iter: 0; batch classifier loss: 0.274326; batch adversarial loss: 0.426940\n",
      "epoch 31; iter: 0; batch classifier loss: 0.279493; batch adversarial loss: 0.488945\n",
      "epoch 32; iter: 0; batch classifier loss: 0.268602; batch adversarial loss: 0.461486\n",
      "epoch 33; iter: 0; batch classifier loss: 0.249523; batch adversarial loss: 0.496292\n",
      "epoch 34; iter: 0; batch classifier loss: 0.205575; batch adversarial loss: 0.493080\n",
      "epoch 35; iter: 0; batch classifier loss: 0.217442; batch adversarial loss: 0.402187\n",
      "epoch 36; iter: 0; batch classifier loss: 0.280558; batch adversarial loss: 0.432256\n",
      "epoch 37; iter: 0; batch classifier loss: 0.250507; batch adversarial loss: 0.521286\n",
      "epoch 38; iter: 0; batch classifier loss: 0.309618; batch adversarial loss: 0.458151\n",
      "epoch 39; iter: 0; batch classifier loss: 0.235987; batch adversarial loss: 0.425931\n",
      "epoch 40; iter: 0; batch classifier loss: 0.234113; batch adversarial loss: 0.534738\n",
      "epoch 41; iter: 0; batch classifier loss: 0.236867; batch adversarial loss: 0.423468\n",
      "epoch 42; iter: 0; batch classifier loss: 0.242872; batch adversarial loss: 0.515328\n",
      "epoch 43; iter: 0; batch classifier loss: 0.230246; batch adversarial loss: 0.505782\n",
      "epoch 44; iter: 0; batch classifier loss: 0.258094; batch adversarial loss: 0.475974\n",
      "epoch 45; iter: 0; batch classifier loss: 0.347223; batch adversarial loss: 0.352397\n",
      "epoch 46; iter: 0; batch classifier loss: 0.338267; batch adversarial loss: 0.394144\n",
      "epoch 47; iter: 0; batch classifier loss: 0.325317; batch adversarial loss: 0.461079\n",
      "epoch 48; iter: 0; batch classifier loss: 0.314156; batch adversarial loss: 0.444437\n",
      "epoch 49; iter: 0; batch classifier loss: 0.271084; batch adversarial loss: 0.500155\n",
      "epoch 50; iter: 0; batch classifier loss: 0.271354; batch adversarial loss: 0.413560\n",
      "epoch 51; iter: 0; batch classifier loss: 0.271236; batch adversarial loss: 0.459160\n",
      "epoch 52; iter: 0; batch classifier loss: 0.221150; batch adversarial loss: 0.555093\n",
      "epoch 53; iter: 0; batch classifier loss: 0.232787; batch adversarial loss: 0.436462\n",
      "epoch 54; iter: 0; batch classifier loss: 0.273353; batch adversarial loss: 0.447359\n",
      "epoch 55; iter: 0; batch classifier loss: 0.273004; batch adversarial loss: 0.532236\n",
      "epoch 56; iter: 0; batch classifier loss: 0.259954; batch adversarial loss: 0.471108\n",
      "epoch 57; iter: 0; batch classifier loss: 0.347502; batch adversarial loss: 0.483265\n",
      "epoch 58; iter: 0; batch classifier loss: 0.104751; batch adversarial loss: 0.494513\n",
      "epoch 59; iter: 0; batch classifier loss: 0.138845; batch adversarial loss: 0.470531\n",
      "epoch 60; iter: 0; batch classifier loss: 0.124218; batch adversarial loss: 0.468780\n",
      "epoch 61; iter: 0; batch classifier loss: 0.187819; batch adversarial loss: 0.426055\n",
      "epoch 62; iter: 0; batch classifier loss: 0.234467; batch adversarial loss: 0.447779\n",
      "epoch 63; iter: 0; batch classifier loss: 0.175680; batch adversarial loss: 0.423991\n",
      "epoch 64; iter: 0; batch classifier loss: 0.193165; batch adversarial loss: 0.495504\n",
      "epoch 65; iter: 0; batch classifier loss: 0.285144; batch adversarial loss: 0.510908\n",
      "epoch 66; iter: 0; batch classifier loss: 0.242234; batch adversarial loss: 0.447385\n",
      "epoch 67; iter: 0; batch classifier loss: 0.207394; batch adversarial loss: 0.483947\n",
      "epoch 68; iter: 0; batch classifier loss: 0.240061; batch adversarial loss: 0.409960\n",
      "epoch 69; iter: 0; batch classifier loss: 0.174679; batch adversarial loss: 0.531330\n",
      "epoch 70; iter: 0; batch classifier loss: 0.189853; batch adversarial loss: 0.447613\n",
      "epoch 71; iter: 0; batch classifier loss: 0.303921; batch adversarial loss: 0.410321\n",
      "epoch 72; iter: 0; batch classifier loss: 0.142772; batch adversarial loss: 0.386095\n",
      "epoch 73; iter: 0; batch classifier loss: 0.118162; batch adversarial loss: 0.324476\n",
      "epoch 74; iter: 0; batch classifier loss: 0.243275; batch adversarial loss: 0.336054\n",
      "epoch 75; iter: 0; batch classifier loss: 0.211997; batch adversarial loss: 0.458944\n",
      "epoch 76; iter: 0; batch classifier loss: 0.254784; batch adversarial loss: 0.361129\n",
      "epoch 77; iter: 0; batch classifier loss: 0.179590; batch adversarial loss: 0.556420\n",
      "epoch 78; iter: 0; batch classifier loss: 0.271458; batch adversarial loss: 0.470393\n",
      "epoch 79; iter: 0; batch classifier loss: 0.186015; batch adversarial loss: 0.484002\n",
      "epoch 80; iter: 0; batch classifier loss: 0.302429; batch adversarial loss: 0.506681\n",
      "epoch 81; iter: 0; batch classifier loss: 0.172634; batch adversarial loss: 0.434576\n",
      "epoch 82; iter: 0; batch classifier loss: 0.141344; batch adversarial loss: 0.421996\n",
      "epoch 83; iter: 0; batch classifier loss: 0.244046; batch adversarial loss: 0.410023\n",
      "epoch 84; iter: 0; batch classifier loss: 0.283090; batch adversarial loss: 0.472674\n",
      "epoch 85; iter: 0; batch classifier loss: 0.189457; batch adversarial loss: 0.421181\n",
      "epoch 86; iter: 0; batch classifier loss: 0.179807; batch adversarial loss: 0.484926\n",
      "epoch 87; iter: 0; batch classifier loss: 0.272600; batch adversarial loss: 0.447063\n",
      "epoch 88; iter: 0; batch classifier loss: 0.271118; batch adversarial loss: 0.471205\n",
      "epoch 89; iter: 0; batch classifier loss: 0.136632; batch adversarial loss: 0.519593\n",
      "epoch 90; iter: 0; batch classifier loss: 0.225574; batch adversarial loss: 0.398048\n",
      "epoch 91; iter: 0; batch classifier loss: 0.195475; batch adversarial loss: 0.555470\n",
      "epoch 92; iter: 0; batch classifier loss: 0.205609; batch adversarial loss: 0.386081\n",
      "epoch 93; iter: 0; batch classifier loss: 0.217949; batch adversarial loss: 0.580623\n",
      "epoch 94; iter: 0; batch classifier loss: 0.201894; batch adversarial loss: 0.544337\n",
      "epoch 95; iter: 0; batch classifier loss: 0.222797; batch adversarial loss: 0.446527\n",
      "epoch 96; iter: 0; batch classifier loss: 0.166863; batch adversarial loss: 0.568392\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050835; batch adversarial loss: 0.482948\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074683; batch adversarial loss: 0.503030\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065900; batch adversarial loss: 0.396889\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065954; batch adversarial loss: 0.411582\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071383; batch adversarial loss: 0.401269\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031587; batch adversarial loss: 0.445561\n",
      "epoch 103; iter: 0; batch classifier loss: 0.083114; batch adversarial loss: 0.463919\n",
      "epoch 104; iter: 0; batch classifier loss: 0.030958; batch adversarial loss: 0.462729\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038666; batch adversarial loss: 0.394975\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033787; batch adversarial loss: 0.487776\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053865; batch adversarial loss: 0.461442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.035738; batch adversarial loss: 0.487579\n",
      "epoch 109; iter: 0; batch classifier loss: 0.086380; batch adversarial loss: 0.445810\n",
      "epoch 110; iter: 0; batch classifier loss: 0.054813; batch adversarial loss: 0.466531\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050751; batch adversarial loss: 0.443819\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047631; batch adversarial loss: 0.392632\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057692; batch adversarial loss: 0.541786\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052765; batch adversarial loss: 0.389648\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070732; batch adversarial loss: 0.445612\n",
      "epoch 116; iter: 0; batch classifier loss: 0.063164; batch adversarial loss: 0.349314\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061763; batch adversarial loss: 0.397810\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054271; batch adversarial loss: 0.452466\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065665; batch adversarial loss: 0.396403\n",
      "epoch 120; iter: 0; batch classifier loss: 0.060186; batch adversarial loss: 0.356402\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060845; batch adversarial loss: 0.461386\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043555; batch adversarial loss: 0.392128\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050076; batch adversarial loss: 0.474640\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054725; batch adversarial loss: 0.432197\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056342; batch adversarial loss: 0.415783\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057186; batch adversarial loss: 0.451095\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033214; batch adversarial loss: 0.472652\n",
      "epoch 128; iter: 0; batch classifier loss: 0.083016; batch adversarial loss: 0.388868\n",
      "epoch 129; iter: 0; batch classifier loss: 0.053586; batch adversarial loss: 0.483528\n",
      "epoch 130; iter: 0; batch classifier loss: 0.084997; batch adversarial loss: 0.408051\n",
      "epoch 131; iter: 0; batch classifier loss: 0.071407; batch adversarial loss: 0.426778\n",
      "epoch 132; iter: 0; batch classifier loss: 0.080418; batch adversarial loss: 0.468246\n",
      "epoch 133; iter: 0; batch classifier loss: 0.078125; batch adversarial loss: 0.359559\n",
      "epoch 134; iter: 0; batch classifier loss: 0.056283; batch adversarial loss: 0.414392\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041794; batch adversarial loss: 0.392490\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029890; batch adversarial loss: 0.433317\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045080; batch adversarial loss: 0.401613\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022369; batch adversarial loss: 0.396356\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050895; batch adversarial loss: 0.462678\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053145; batch adversarial loss: 0.398864\n",
      "epoch 141; iter: 0; batch classifier loss: 0.065953; batch adversarial loss: 0.436402\n",
      "epoch 142; iter: 0; batch classifier loss: 0.097848; batch adversarial loss: 0.461661\n",
      "epoch 143; iter: 0; batch classifier loss: 0.053958; batch adversarial loss: 0.424003\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030236; batch adversarial loss: 0.446194\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040641; batch adversarial loss: 0.477723\n",
      "epoch 146; iter: 0; batch classifier loss: 0.046231; batch adversarial loss: 0.347429\n",
      "epoch 147; iter: 0; batch classifier loss: 0.049778; batch adversarial loss: 0.498866\n",
      "epoch 148; iter: 0; batch classifier loss: 0.072195; batch adversarial loss: 0.456497\n",
      "epoch 149; iter: 0; batch classifier loss: 0.072359; batch adversarial loss: 0.426084\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027754; batch adversarial loss: 0.420655\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039462; batch adversarial loss: 0.351986\n",
      "epoch 152; iter: 0; batch classifier loss: 0.063426; batch adversarial loss: 0.483230\n",
      "epoch 153; iter: 0; batch classifier loss: 0.069493; batch adversarial loss: 0.458371\n",
      "epoch 154; iter: 0; batch classifier loss: 0.060345; batch adversarial loss: 0.461366\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036835; batch adversarial loss: 0.463773\n",
      "epoch 156; iter: 0; batch classifier loss: 0.053301; batch adversarial loss: 0.473873\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030315; batch adversarial loss: 0.427983\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034266; batch adversarial loss: 0.429373\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023992; batch adversarial loss: 0.403799\n",
      "epoch 160; iter: 0; batch classifier loss: 0.090323; batch adversarial loss: 0.411701\n",
      "epoch 161; iter: 0; batch classifier loss: 0.070881; batch adversarial loss: 0.398819\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030472; batch adversarial loss: 0.364358\n",
      "epoch 163; iter: 0; batch classifier loss: 0.054226; batch adversarial loss: 0.441769\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021565; batch adversarial loss: 0.384464\n",
      "epoch 165; iter: 0; batch classifier loss: 0.046707; batch adversarial loss: 0.480641\n",
      "epoch 166; iter: 0; batch classifier loss: 0.039880; batch adversarial loss: 0.489734\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042299; batch adversarial loss: 0.416490\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045960; batch adversarial loss: 0.468125\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028343; batch adversarial loss: 0.443365\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039398; batch adversarial loss: 0.431647\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036804; batch adversarial loss: 0.427621\n",
      "epoch 172; iter: 0; batch classifier loss: 0.066381; batch adversarial loss: 0.361283\n",
      "epoch 173; iter: 0; batch classifier loss: 0.051445; batch adversarial loss: 0.408576\n",
      "epoch 174; iter: 0; batch classifier loss: 0.044713; batch adversarial loss: 0.410368\n",
      "epoch 175; iter: 0; batch classifier loss: 0.055089; batch adversarial loss: 0.352763\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040974; batch adversarial loss: 0.378658\n",
      "epoch 177; iter: 0; batch classifier loss: 0.061011; batch adversarial loss: 0.381148\n",
      "epoch 178; iter: 0; batch classifier loss: 0.080154; batch adversarial loss: 0.430968\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040495; batch adversarial loss: 0.534825\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032085; batch adversarial loss: 0.454750\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035811; batch adversarial loss: 0.550215\n",
      "epoch 182; iter: 0; batch classifier loss: 0.045449; batch adversarial loss: 0.469392\n",
      "epoch 183; iter: 0; batch classifier loss: 0.057670; batch adversarial loss: 0.512756\n",
      "epoch 184; iter: 0; batch classifier loss: 0.043582; batch adversarial loss: 0.429747\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028775; batch adversarial loss: 0.375689\n",
      "epoch 186; iter: 0; batch classifier loss: 0.050076; batch adversarial loss: 0.499832\n",
      "epoch 187; iter: 0; batch classifier loss: 0.044460; batch adversarial loss: 0.539256\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026879; batch adversarial loss: 0.469121\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033636; batch adversarial loss: 0.449459\n",
      "epoch 190; iter: 0; batch classifier loss: 0.040098; batch adversarial loss: 0.507602\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034103; batch adversarial loss: 0.482612\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018324; batch adversarial loss: 0.515562\n",
      "epoch 193; iter: 0; batch classifier loss: 0.034366; batch adversarial loss: 0.362780\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041279; batch adversarial loss: 0.457824\n",
      "epoch 195; iter: 0; batch classifier loss: 0.068471; batch adversarial loss: 0.405854\n",
      "epoch 196; iter: 0; batch classifier loss: 0.078681; batch adversarial loss: 0.394659\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034117; batch adversarial loss: 0.481810\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025923; batch adversarial loss: 0.495416\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017408; batch adversarial loss: 0.396230\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683368; batch adversarial loss: 0.928905\n",
      "epoch 1; iter: 0; batch classifier loss: 0.549140; batch adversarial loss: 0.926551\n",
      "epoch 2; iter: 0; batch classifier loss: 0.651757; batch adversarial loss: 0.932048\n",
      "epoch 3; iter: 0; batch classifier loss: 0.723646; batch adversarial loss: 0.878838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 1.018845; batch adversarial loss: 0.786316\n",
      "epoch 5; iter: 0; batch classifier loss: 0.754196; batch adversarial loss: 0.719333\n",
      "epoch 6; iter: 0; batch classifier loss: 0.872051; batch adversarial loss: 0.643841\n",
      "epoch 7; iter: 0; batch classifier loss: 0.416563; batch adversarial loss: 0.589864\n",
      "epoch 8; iter: 0; batch classifier loss: 0.271184; batch adversarial loss: 0.565819\n",
      "epoch 9; iter: 0; batch classifier loss: 0.332565; batch adversarial loss: 0.530266\n",
      "epoch 10; iter: 0; batch classifier loss: 0.305595; batch adversarial loss: 0.507472\n",
      "epoch 11; iter: 0; batch classifier loss: 0.282498; batch adversarial loss: 0.501349\n",
      "epoch 12; iter: 0; batch classifier loss: 0.233087; batch adversarial loss: 0.518338\n",
      "epoch 13; iter: 0; batch classifier loss: 0.201310; batch adversarial loss: 0.523796\n",
      "epoch 14; iter: 0; batch classifier loss: 0.304169; batch adversarial loss: 0.471624\n",
      "epoch 15; iter: 0; batch classifier loss: 0.201614; batch adversarial loss: 0.465570\n",
      "epoch 16; iter: 0; batch classifier loss: 0.165473; batch adversarial loss: 0.529353\n",
      "epoch 17; iter: 0; batch classifier loss: 0.272982; batch adversarial loss: 0.469725\n",
      "epoch 18; iter: 0; batch classifier loss: 0.156861; batch adversarial loss: 0.455501\n",
      "epoch 19; iter: 0; batch classifier loss: 0.170944; batch adversarial loss: 0.497653\n",
      "epoch 20; iter: 0; batch classifier loss: 0.133070; batch adversarial loss: 0.472512\n",
      "epoch 21; iter: 0; batch classifier loss: 0.137171; batch adversarial loss: 0.453866\n",
      "epoch 22; iter: 0; batch classifier loss: 0.146731; batch adversarial loss: 0.453904\n",
      "epoch 23; iter: 0; batch classifier loss: 0.125995; batch adversarial loss: 0.442834\n",
      "epoch 24; iter: 0; batch classifier loss: 0.079648; batch adversarial loss: 0.451528\n",
      "epoch 25; iter: 0; batch classifier loss: 0.125393; batch adversarial loss: 0.416710\n",
      "epoch 26; iter: 0; batch classifier loss: 0.146540; batch adversarial loss: 0.490836\n",
      "epoch 27; iter: 0; batch classifier loss: 0.128637; batch adversarial loss: 0.492427\n",
      "epoch 28; iter: 0; batch classifier loss: 0.159515; batch adversarial loss: 0.463339\n",
      "epoch 29; iter: 0; batch classifier loss: 0.108093; batch adversarial loss: 0.464003\n",
      "epoch 30; iter: 0; batch classifier loss: 0.102637; batch adversarial loss: 0.501863\n",
      "epoch 31; iter: 0; batch classifier loss: 0.090679; batch adversarial loss: 0.381474\n",
      "epoch 32; iter: 0; batch classifier loss: 0.135814; batch adversarial loss: 0.397919\n",
      "epoch 33; iter: 0; batch classifier loss: 0.080820; batch adversarial loss: 0.459433\n",
      "epoch 34; iter: 0; batch classifier loss: 0.153397; batch adversarial loss: 0.469127\n",
      "epoch 35; iter: 0; batch classifier loss: 0.107540; batch adversarial loss: 0.487644\n",
      "epoch 36; iter: 0; batch classifier loss: 0.101127; batch adversarial loss: 0.431350\n",
      "epoch 37; iter: 0; batch classifier loss: 0.112014; batch adversarial loss: 0.481192\n",
      "epoch 38; iter: 0; batch classifier loss: 0.095718; batch adversarial loss: 0.367211\n",
      "epoch 39; iter: 0; batch classifier loss: 0.117990; batch adversarial loss: 0.408294\n",
      "epoch 40; iter: 0; batch classifier loss: 0.088595; batch adversarial loss: 0.400990\n",
      "epoch 41; iter: 0; batch classifier loss: 0.090768; batch adversarial loss: 0.403032\n",
      "epoch 42; iter: 0; batch classifier loss: 0.096635; batch adversarial loss: 0.488106\n",
      "epoch 43; iter: 0; batch classifier loss: 0.052733; batch adversarial loss: 0.385134\n",
      "epoch 44; iter: 0; batch classifier loss: 0.083454; batch adversarial loss: 0.470675\n",
      "epoch 45; iter: 0; batch classifier loss: 0.114713; batch adversarial loss: 0.530577\n",
      "epoch 46; iter: 0; batch classifier loss: 0.062951; batch adversarial loss: 0.478855\n",
      "epoch 47; iter: 0; batch classifier loss: 0.092439; batch adversarial loss: 0.400519\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100342; batch adversarial loss: 0.423640\n",
      "epoch 49; iter: 0; batch classifier loss: 0.132920; batch adversarial loss: 0.455366\n",
      "epoch 50; iter: 0; batch classifier loss: 0.083234; batch adversarial loss: 0.431817\n",
      "epoch 51; iter: 0; batch classifier loss: 0.086425; batch adversarial loss: 0.449986\n",
      "epoch 52; iter: 0; batch classifier loss: 0.105208; batch adversarial loss: 0.509423\n",
      "epoch 53; iter: 0; batch classifier loss: 0.071304; batch adversarial loss: 0.330273\n",
      "epoch 54; iter: 0; batch classifier loss: 0.067658; batch adversarial loss: 0.453520\n",
      "epoch 55; iter: 0; batch classifier loss: 0.128762; batch adversarial loss: 0.490180\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067990; batch adversarial loss: 0.434456\n",
      "epoch 57; iter: 0; batch classifier loss: 0.058999; batch adversarial loss: 0.430062\n",
      "epoch 58; iter: 0; batch classifier loss: 0.087795; batch adversarial loss: 0.503974\n",
      "epoch 59; iter: 0; batch classifier loss: 0.057874; batch adversarial loss: 0.502147\n",
      "epoch 60; iter: 0; batch classifier loss: 0.062880; batch adversarial loss: 0.397180\n",
      "epoch 61; iter: 0; batch classifier loss: 0.102855; batch adversarial loss: 0.454927\n",
      "epoch 62; iter: 0; batch classifier loss: 0.057753; batch adversarial loss: 0.501734\n",
      "epoch 63; iter: 0; batch classifier loss: 0.059662; batch adversarial loss: 0.481211\n",
      "epoch 64; iter: 0; batch classifier loss: 0.092082; batch adversarial loss: 0.419872\n",
      "epoch 65; iter: 0; batch classifier loss: 0.042565; batch adversarial loss: 0.554076\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068778; batch adversarial loss: 0.473668\n",
      "epoch 67; iter: 0; batch classifier loss: 0.063037; batch adversarial loss: 0.373135\n",
      "epoch 68; iter: 0; batch classifier loss: 0.066546; batch adversarial loss: 0.396406\n",
      "epoch 69; iter: 0; batch classifier loss: 0.055807; batch adversarial loss: 0.539857\n",
      "epoch 70; iter: 0; batch classifier loss: 0.047588; batch adversarial loss: 0.361558\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089048; batch adversarial loss: 0.433454\n",
      "epoch 72; iter: 0; batch classifier loss: 0.035071; batch adversarial loss: 0.402039\n",
      "epoch 73; iter: 0; batch classifier loss: 0.056756; batch adversarial loss: 0.395809\n",
      "epoch 74; iter: 0; batch classifier loss: 0.062943; batch adversarial loss: 0.432187\n",
      "epoch 75; iter: 0; batch classifier loss: 0.032578; batch adversarial loss: 0.376273\n",
      "epoch 76; iter: 0; batch classifier loss: 0.028489; batch adversarial loss: 0.379700\n",
      "epoch 77; iter: 0; batch classifier loss: 0.075264; batch adversarial loss: 0.431135\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064820; batch adversarial loss: 0.529108\n",
      "epoch 79; iter: 0; batch classifier loss: 0.106727; batch adversarial loss: 0.467151\n",
      "epoch 80; iter: 0; batch classifier loss: 0.051146; batch adversarial loss: 0.413915\n",
      "epoch 81; iter: 0; batch classifier loss: 0.037345; batch adversarial loss: 0.444631\n",
      "epoch 82; iter: 0; batch classifier loss: 0.049339; batch adversarial loss: 0.423809\n",
      "epoch 83; iter: 0; batch classifier loss: 0.041960; batch adversarial loss: 0.355952\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056622; batch adversarial loss: 0.411575\n",
      "epoch 85; iter: 0; batch classifier loss: 0.080253; batch adversarial loss: 0.464321\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051744; batch adversarial loss: 0.506174\n",
      "epoch 87; iter: 0; batch classifier loss: 0.031979; batch adversarial loss: 0.390167\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069402; batch adversarial loss: 0.366429\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063485; batch adversarial loss: 0.419565\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073395; batch adversarial loss: 0.449849\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056516; batch adversarial loss: 0.464290\n",
      "epoch 92; iter: 0; batch classifier loss: 0.046243; batch adversarial loss: 0.494396\n",
      "epoch 93; iter: 0; batch classifier loss: 0.079031; batch adversarial loss: 0.475610\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079395; batch adversarial loss: 0.459856\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054330; batch adversarial loss: 0.417597\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068880; batch adversarial loss: 0.360337\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081080; batch adversarial loss: 0.475523\n",
      "epoch 98; iter: 0; batch classifier loss: 0.066182; batch adversarial loss: 0.449412\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038006; batch adversarial loss: 0.551661\n",
      "epoch 100; iter: 0; batch classifier loss: 0.098506; batch adversarial loss: 0.482590\n",
      "epoch 101; iter: 0; batch classifier loss: 0.080684; batch adversarial loss: 0.424858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.069809; batch adversarial loss: 0.421746\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041576; batch adversarial loss: 0.411852\n",
      "epoch 104; iter: 0; batch classifier loss: 0.029398; batch adversarial loss: 0.462594\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054311; batch adversarial loss: 0.441610\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058605; batch adversarial loss: 0.444182\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056988; batch adversarial loss: 0.379075\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056622; batch adversarial loss: 0.421828\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042923; batch adversarial loss: 0.432412\n",
      "epoch 110; iter: 0; batch classifier loss: 0.066556; batch adversarial loss: 0.433313\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042582; batch adversarial loss: 0.419932\n",
      "epoch 112; iter: 0; batch classifier loss: 0.087451; batch adversarial loss: 0.420046\n",
      "epoch 113; iter: 0; batch classifier loss: 0.060513; batch adversarial loss: 0.529793\n",
      "epoch 114; iter: 0; batch classifier loss: 0.102135; batch adversarial loss: 0.467398\n",
      "epoch 115; iter: 0; batch classifier loss: 0.047767; batch adversarial loss: 0.452619\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056304; batch adversarial loss: 0.430396\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045174; batch adversarial loss: 0.446677\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052774; batch adversarial loss: 0.397155\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051442; batch adversarial loss: 0.334822\n",
      "epoch 120; iter: 0; batch classifier loss: 0.095030; batch adversarial loss: 0.412982\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060111; batch adversarial loss: 0.535545\n",
      "epoch 122; iter: 0; batch classifier loss: 0.072071; batch adversarial loss: 0.453285\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057302; batch adversarial loss: 0.415430\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052362; batch adversarial loss: 0.506084\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039595; batch adversarial loss: 0.478154\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034014; batch adversarial loss: 0.437412\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033626; batch adversarial loss: 0.427976\n",
      "epoch 128; iter: 0; batch classifier loss: 0.072381; batch adversarial loss: 0.385238\n",
      "epoch 129; iter: 0; batch classifier loss: 0.072004; batch adversarial loss: 0.442974\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035803; batch adversarial loss: 0.418687\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032915; batch adversarial loss: 0.295894\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051704; batch adversarial loss: 0.431389\n",
      "epoch 133; iter: 0; batch classifier loss: 0.058781; batch adversarial loss: 0.372682\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049488; batch adversarial loss: 0.473332\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030495; batch adversarial loss: 0.521921\n",
      "epoch 136; iter: 0; batch classifier loss: 0.064129; batch adversarial loss: 0.461095\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044432; batch adversarial loss: 0.409274\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021768; batch adversarial loss: 0.412725\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046355; batch adversarial loss: 0.456781\n",
      "epoch 140; iter: 0; batch classifier loss: 0.062042; batch adversarial loss: 0.373891\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027170; batch adversarial loss: 0.322718\n",
      "epoch 142; iter: 0; batch classifier loss: 0.055520; batch adversarial loss: 0.413763\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039557; batch adversarial loss: 0.457431\n",
      "epoch 144; iter: 0; batch classifier loss: 0.081512; batch adversarial loss: 0.494304\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048145; batch adversarial loss: 0.434482\n",
      "epoch 146; iter: 0; batch classifier loss: 0.058050; batch adversarial loss: 0.431876\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046346; batch adversarial loss: 0.422135\n",
      "epoch 148; iter: 0; batch classifier loss: 0.060364; batch adversarial loss: 0.426891\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027159; batch adversarial loss: 0.463061\n",
      "epoch 150; iter: 0; batch classifier loss: 0.094498; batch adversarial loss: 0.507789\n",
      "epoch 151; iter: 0; batch classifier loss: 0.052449; batch adversarial loss: 0.418436\n",
      "epoch 152; iter: 0; batch classifier loss: 0.051201; batch adversarial loss: 0.507481\n",
      "epoch 153; iter: 0; batch classifier loss: 0.048509; batch adversarial loss: 0.402294\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028736; batch adversarial loss: 0.459201\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041376; batch adversarial loss: 0.428897\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037019; batch adversarial loss: 0.476012\n",
      "epoch 157; iter: 0; batch classifier loss: 0.081301; batch adversarial loss: 0.371118\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042014; batch adversarial loss: 0.469325\n",
      "epoch 159; iter: 0; batch classifier loss: 0.046520; batch adversarial loss: 0.480184\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032043; batch adversarial loss: 0.410123\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038135; batch adversarial loss: 0.486903\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023991; batch adversarial loss: 0.363806\n",
      "epoch 163; iter: 0; batch classifier loss: 0.065466; batch adversarial loss: 0.509592\n",
      "epoch 164; iter: 0; batch classifier loss: 0.041414; batch adversarial loss: 0.366355\n",
      "epoch 165; iter: 0; batch classifier loss: 0.046541; batch adversarial loss: 0.406945\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021245; batch adversarial loss: 0.404293\n",
      "epoch 167; iter: 0; batch classifier loss: 0.075230; batch adversarial loss: 0.475612\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029855; batch adversarial loss: 0.386833\n",
      "epoch 169; iter: 0; batch classifier loss: 0.068722; batch adversarial loss: 0.522542\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040147; batch adversarial loss: 0.377547\n",
      "epoch 171; iter: 0; batch classifier loss: 0.048939; batch adversarial loss: 0.350622\n",
      "epoch 172; iter: 0; batch classifier loss: 0.042147; batch adversarial loss: 0.489644\n",
      "epoch 173; iter: 0; batch classifier loss: 0.066717; batch adversarial loss: 0.387871\n",
      "epoch 174; iter: 0; batch classifier loss: 0.058524; batch adversarial loss: 0.371945\n",
      "epoch 175; iter: 0; batch classifier loss: 0.053744; batch adversarial loss: 0.425449\n",
      "epoch 176; iter: 0; batch classifier loss: 0.057879; batch adversarial loss: 0.451200\n",
      "epoch 177; iter: 0; batch classifier loss: 0.061446; batch adversarial loss: 0.436669\n",
      "epoch 178; iter: 0; batch classifier loss: 0.057549; batch adversarial loss: 0.518917\n",
      "epoch 179; iter: 0; batch classifier loss: 0.051324; batch adversarial loss: 0.349728\n",
      "epoch 180; iter: 0; batch classifier loss: 0.079574; batch adversarial loss: 0.448474\n",
      "epoch 181; iter: 0; batch classifier loss: 0.051841; batch adversarial loss: 0.469700\n",
      "epoch 182; iter: 0; batch classifier loss: 0.048595; batch adversarial loss: 0.515562\n",
      "epoch 183; iter: 0; batch classifier loss: 0.061838; batch adversarial loss: 0.454181\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028032; batch adversarial loss: 0.448612\n",
      "epoch 185; iter: 0; batch classifier loss: 0.070795; batch adversarial loss: 0.439509\n",
      "epoch 186; iter: 0; batch classifier loss: 0.063764; batch adversarial loss: 0.461043\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036073; batch adversarial loss: 0.455264\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033591; batch adversarial loss: 0.518924\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034059; batch adversarial loss: 0.414633\n",
      "epoch 190; iter: 0; batch classifier loss: 0.050723; batch adversarial loss: 0.408732\n",
      "epoch 191; iter: 0; batch classifier loss: 0.043184; batch adversarial loss: 0.323000\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026209; batch adversarial loss: 0.512374\n",
      "epoch 193; iter: 0; batch classifier loss: 0.045450; batch adversarial loss: 0.397295\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030821; batch adversarial loss: 0.387473\n",
      "epoch 195; iter: 0; batch classifier loss: 0.046914; batch adversarial loss: 0.502744\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037546; batch adversarial loss: 0.479114\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033144; batch adversarial loss: 0.484528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.029634; batch adversarial loss: 0.444527\n",
      "epoch 199; iter: 0; batch classifier loss: 0.041323; batch adversarial loss: 0.404509\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678561; batch adversarial loss: 0.864326\n",
      "epoch 1; iter: 0; batch classifier loss: 0.571021; batch adversarial loss: 0.974923\n",
      "epoch 2; iter: 0; batch classifier loss: 0.934468; batch adversarial loss: 1.041647\n",
      "epoch 3; iter: 0; batch classifier loss: 0.953892; batch adversarial loss: 0.919956\n",
      "epoch 4; iter: 0; batch classifier loss: 0.953514; batch adversarial loss: 0.825318\n",
      "epoch 5; iter: 0; batch classifier loss: 1.108956; batch adversarial loss: 0.768508\n",
      "epoch 6; iter: 0; batch classifier loss: 0.987607; batch adversarial loss: 0.675312\n",
      "epoch 7; iter: 0; batch classifier loss: 0.810303; batch adversarial loss: 0.621893\n",
      "epoch 8; iter: 0; batch classifier loss: 0.496883; batch adversarial loss: 0.590108\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434871; batch adversarial loss: 0.526529\n",
      "epoch 10; iter: 0; batch classifier loss: 0.372720; batch adversarial loss: 0.517858\n",
      "epoch 11; iter: 0; batch classifier loss: 0.322507; batch adversarial loss: 0.555183\n",
      "epoch 12; iter: 0; batch classifier loss: 0.281443; batch adversarial loss: 0.529308\n",
      "epoch 13; iter: 0; batch classifier loss: 0.304247; batch adversarial loss: 0.481340\n",
      "epoch 14; iter: 0; batch classifier loss: 0.280871; batch adversarial loss: 0.533419\n",
      "epoch 15; iter: 0; batch classifier loss: 0.226623; batch adversarial loss: 0.533783\n",
      "epoch 16; iter: 0; batch classifier loss: 0.231353; batch adversarial loss: 0.509020\n",
      "epoch 17; iter: 0; batch classifier loss: 0.282848; batch adversarial loss: 0.501460\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251539; batch adversarial loss: 0.505602\n",
      "epoch 19; iter: 0; batch classifier loss: 0.327551; batch adversarial loss: 0.440106\n",
      "epoch 20; iter: 0; batch classifier loss: 0.223646; batch adversarial loss: 0.477359\n",
      "epoch 21; iter: 0; batch classifier loss: 0.229094; batch adversarial loss: 0.448924\n",
      "epoch 22; iter: 0; batch classifier loss: 0.158234; batch adversarial loss: 0.490222\n",
      "epoch 23; iter: 0; batch classifier loss: 0.153666; batch adversarial loss: 0.491608\n",
      "epoch 24; iter: 0; batch classifier loss: 0.174556; batch adversarial loss: 0.447629\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177218; batch adversarial loss: 0.451674\n",
      "epoch 26; iter: 0; batch classifier loss: 0.150076; batch adversarial loss: 0.458856\n",
      "epoch 27; iter: 0; batch classifier loss: 0.151161; batch adversarial loss: 0.425700\n",
      "epoch 28; iter: 0; batch classifier loss: 0.180098; batch adversarial loss: 0.456325\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178763; batch adversarial loss: 0.450261\n",
      "epoch 30; iter: 0; batch classifier loss: 0.187172; batch adversarial loss: 0.462820\n",
      "epoch 31; iter: 0; batch classifier loss: 0.167790; batch adversarial loss: 0.518033\n",
      "epoch 32; iter: 0; batch classifier loss: 0.178683; batch adversarial loss: 0.420652\n",
      "epoch 33; iter: 0; batch classifier loss: 0.198945; batch adversarial loss: 0.460423\n",
      "epoch 34; iter: 0; batch classifier loss: 0.151039; batch adversarial loss: 0.473719\n",
      "epoch 35; iter: 0; batch classifier loss: 0.132028; batch adversarial loss: 0.410218\n",
      "epoch 36; iter: 0; batch classifier loss: 0.110307; batch adversarial loss: 0.440799\n",
      "epoch 37; iter: 0; batch classifier loss: 0.176620; batch adversarial loss: 0.457338\n",
      "epoch 38; iter: 0; batch classifier loss: 0.119256; batch adversarial loss: 0.489318\n",
      "epoch 39; iter: 0; batch classifier loss: 0.098224; batch adversarial loss: 0.332021\n",
      "epoch 40; iter: 0; batch classifier loss: 0.101739; batch adversarial loss: 0.383358\n",
      "epoch 41; iter: 0; batch classifier loss: 0.085945; batch adversarial loss: 0.466971\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117702; batch adversarial loss: 0.404962\n",
      "epoch 43; iter: 0; batch classifier loss: 0.112908; batch adversarial loss: 0.480690\n",
      "epoch 44; iter: 0; batch classifier loss: 0.102146; batch adversarial loss: 0.541504\n",
      "epoch 45; iter: 0; batch classifier loss: 0.049631; batch adversarial loss: 0.438109\n",
      "epoch 46; iter: 0; batch classifier loss: 0.090505; batch adversarial loss: 0.450579\n",
      "epoch 47; iter: 0; batch classifier loss: 0.091616; batch adversarial loss: 0.580313\n",
      "epoch 48; iter: 0; batch classifier loss: 0.064821; batch adversarial loss: 0.464778\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114545; batch adversarial loss: 0.346301\n",
      "epoch 50; iter: 0; batch classifier loss: 0.116623; batch adversarial loss: 0.456577\n",
      "epoch 51; iter: 0; batch classifier loss: 0.125551; batch adversarial loss: 0.433455\n",
      "epoch 52; iter: 0; batch classifier loss: 0.134006; batch adversarial loss: 0.445198\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084420; batch adversarial loss: 0.438558\n",
      "epoch 54; iter: 0; batch classifier loss: 0.053238; batch adversarial loss: 0.559456\n",
      "epoch 55; iter: 0; batch classifier loss: 0.063389; batch adversarial loss: 0.596608\n",
      "epoch 56; iter: 0; batch classifier loss: 0.051798; batch adversarial loss: 0.417479\n",
      "epoch 57; iter: 0; batch classifier loss: 0.083736; batch adversarial loss: 0.445138\n",
      "epoch 58; iter: 0; batch classifier loss: 0.062000; batch adversarial loss: 0.406699\n",
      "epoch 59; iter: 0; batch classifier loss: 0.101329; batch adversarial loss: 0.506514\n",
      "epoch 60; iter: 0; batch classifier loss: 0.070028; batch adversarial loss: 0.442414\n",
      "epoch 61; iter: 0; batch classifier loss: 0.097134; batch adversarial loss: 0.344257\n",
      "epoch 62; iter: 0; batch classifier loss: 0.088327; batch adversarial loss: 0.437089\n",
      "epoch 63; iter: 0; batch classifier loss: 0.078678; batch adversarial loss: 0.461371\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078305; batch adversarial loss: 0.570099\n",
      "epoch 65; iter: 0; batch classifier loss: 0.072238; batch adversarial loss: 0.499422\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086836; batch adversarial loss: 0.383218\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059239; batch adversarial loss: 0.487195\n",
      "epoch 68; iter: 0; batch classifier loss: 0.054653; batch adversarial loss: 0.509873\n",
      "epoch 69; iter: 0; batch classifier loss: 0.051163; batch adversarial loss: 0.541032\n",
      "epoch 70; iter: 0; batch classifier loss: 0.113313; batch adversarial loss: 0.338879\n",
      "epoch 71; iter: 0; batch classifier loss: 0.066532; batch adversarial loss: 0.426846\n",
      "epoch 72; iter: 0; batch classifier loss: 0.083348; batch adversarial loss: 0.429900\n",
      "epoch 73; iter: 0; batch classifier loss: 0.038333; batch adversarial loss: 0.545520\n",
      "epoch 74; iter: 0; batch classifier loss: 0.070883; batch adversarial loss: 0.397790\n",
      "epoch 75; iter: 0; batch classifier loss: 0.046033; batch adversarial loss: 0.428781\n",
      "epoch 76; iter: 0; batch classifier loss: 0.087415; batch adversarial loss: 0.471260\n",
      "epoch 77; iter: 0; batch classifier loss: 0.070377; batch adversarial loss: 0.374208\n",
      "epoch 78; iter: 0; batch classifier loss: 0.034899; batch adversarial loss: 0.550012\n",
      "epoch 79; iter: 0; batch classifier loss: 0.046514; batch adversarial loss: 0.424813\n",
      "epoch 80; iter: 0; batch classifier loss: 0.105033; batch adversarial loss: 0.441639\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069211; batch adversarial loss: 0.459245\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060033; batch adversarial loss: 0.535549\n",
      "epoch 83; iter: 0; batch classifier loss: 0.067035; batch adversarial loss: 0.505686\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051300; batch adversarial loss: 0.463161\n",
      "epoch 85; iter: 0; batch classifier loss: 0.045502; batch adversarial loss: 0.498969\n",
      "epoch 86; iter: 0; batch classifier loss: 0.035252; batch adversarial loss: 0.447822\n",
      "epoch 87; iter: 0; batch classifier loss: 0.034628; batch adversarial loss: 0.398347\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042535; batch adversarial loss: 0.457350\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060631; batch adversarial loss: 0.475869\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054725; batch adversarial loss: 0.514584\n",
      "epoch 91; iter: 0; batch classifier loss: 0.071723; batch adversarial loss: 0.455155\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051363; batch adversarial loss: 0.402678\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071241; batch adversarial loss: 0.398385\n",
      "epoch 94; iter: 0; batch classifier loss: 0.029585; batch adversarial loss: 0.434173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.057589; batch adversarial loss: 0.496786\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065473; batch adversarial loss: 0.391479\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071745; batch adversarial loss: 0.365148\n",
      "epoch 98; iter: 0; batch classifier loss: 0.029820; batch adversarial loss: 0.421660\n",
      "epoch 99; iter: 0; batch classifier loss: 0.033990; batch adversarial loss: 0.415286\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062131; batch adversarial loss: 0.490463\n",
      "epoch 101; iter: 0; batch classifier loss: 0.018496; batch adversarial loss: 0.431842\n",
      "epoch 102; iter: 0; batch classifier loss: 0.030090; batch adversarial loss: 0.427573\n",
      "epoch 103; iter: 0; batch classifier loss: 0.067825; batch adversarial loss: 0.371895\n",
      "epoch 104; iter: 0; batch classifier loss: 0.030844; batch adversarial loss: 0.501396\n",
      "epoch 105; iter: 0; batch classifier loss: 0.027713; batch adversarial loss: 0.496325\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037142; batch adversarial loss: 0.387131\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051059; batch adversarial loss: 0.376919\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064770; batch adversarial loss: 0.384145\n",
      "epoch 109; iter: 0; batch classifier loss: 0.035978; batch adversarial loss: 0.548693\n",
      "epoch 110; iter: 0; batch classifier loss: 0.013921; batch adversarial loss: 0.467922\n",
      "epoch 111; iter: 0; batch classifier loss: 0.081294; batch adversarial loss: 0.458766\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027783; batch adversarial loss: 0.475548\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047850; batch adversarial loss: 0.405876\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027748; batch adversarial loss: 0.436908\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035845; batch adversarial loss: 0.382877\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029519; batch adversarial loss: 0.423327\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051514; batch adversarial loss: 0.445299\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030897; batch adversarial loss: 0.429682\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025249; batch adversarial loss: 0.447449\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033313; batch adversarial loss: 0.474731\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047406; batch adversarial loss: 0.472037\n",
      "epoch 122; iter: 0; batch classifier loss: 0.023901; batch adversarial loss: 0.426827\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033331; batch adversarial loss: 0.436473\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031403; batch adversarial loss: 0.494825\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025047; batch adversarial loss: 0.454174\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026360; batch adversarial loss: 0.552548\n",
      "epoch 127; iter: 0; batch classifier loss: 0.010966; batch adversarial loss: 0.452897\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023042; batch adversarial loss: 0.454187\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022912; batch adversarial loss: 0.547913\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041768; batch adversarial loss: 0.337111\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025086; batch adversarial loss: 0.509792\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039771; batch adversarial loss: 0.476384\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022275; batch adversarial loss: 0.461917\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016882; batch adversarial loss: 0.459530\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041374; batch adversarial loss: 0.413490\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034028; batch adversarial loss: 0.449824\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028030; batch adversarial loss: 0.373183\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013934; batch adversarial loss: 0.485535\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034614; batch adversarial loss: 0.545585\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027068; batch adversarial loss: 0.424799\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019392; batch adversarial loss: 0.457034\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033084; batch adversarial loss: 0.469033\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028575; batch adversarial loss: 0.471628\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029094; batch adversarial loss: 0.461224\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012323; batch adversarial loss: 0.485697\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030193; batch adversarial loss: 0.462875\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016233; batch adversarial loss: 0.466473\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025489; batch adversarial loss: 0.556868\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039944; batch adversarial loss: 0.431616\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021845; batch adversarial loss: 0.487744\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025909; batch adversarial loss: 0.442302\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015924; batch adversarial loss: 0.524517\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031085; batch adversarial loss: 0.488474\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016471; batch adversarial loss: 0.404392\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015052; batch adversarial loss: 0.374089\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033596; batch adversarial loss: 0.406703\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038420; batch adversarial loss: 0.506250\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025388; batch adversarial loss: 0.401331\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011763; batch adversarial loss: 0.417712\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009598; batch adversarial loss: 0.407294\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019799; batch adversarial loss: 0.468486\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012914; batch adversarial loss: 0.431135\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032022; batch adversarial loss: 0.455756\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021682; batch adversarial loss: 0.466204\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031394; batch adversarial loss: 0.490957\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011671; batch adversarial loss: 0.472282\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018659; batch adversarial loss: 0.460750\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032678; batch adversarial loss: 0.434672\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009041; batch adversarial loss: 0.273507\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015594; batch adversarial loss: 0.491085\n",
      "epoch 171; iter: 0; batch classifier loss: 0.039785; batch adversarial loss: 0.402837\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007654; batch adversarial loss: 0.350945\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027510; batch adversarial loss: 0.454238\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015080; batch adversarial loss: 0.389529\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021016; batch adversarial loss: 0.361514\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019890; batch adversarial loss: 0.440355\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031905; batch adversarial loss: 0.490624\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009244; batch adversarial loss: 0.528828\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014266; batch adversarial loss: 0.438951\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006780; batch adversarial loss: 0.512340\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007254; batch adversarial loss: 0.351043\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037550; batch adversarial loss: 0.496766\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016946; batch adversarial loss: 0.530290\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006911; batch adversarial loss: 0.476094\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036972; batch adversarial loss: 0.427560\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014215; batch adversarial loss: 0.489735\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014981; batch adversarial loss: 0.467982\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021142; batch adversarial loss: 0.446044\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013108; batch adversarial loss: 0.402273\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008000; batch adversarial loss: 0.499825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.003799; batch adversarial loss: 0.479950\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006568; batch adversarial loss: 0.485445\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004808; batch adversarial loss: 0.389064\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028578; batch adversarial loss: 0.400959\n",
      "epoch 195; iter: 0; batch classifier loss: 0.002756; batch adversarial loss: 0.443419\n",
      "epoch 196; iter: 0; batch classifier loss: 0.046632; batch adversarial loss: 0.433382\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014317; batch adversarial loss: 0.489065\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022280; batch adversarial loss: 0.538670\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004950; batch adversarial loss: 0.496667\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714845; batch adversarial loss: 0.773413\n",
      "epoch 1; iter: 0; batch classifier loss: 0.558227; batch adversarial loss: 0.735291\n",
      "epoch 2; iter: 0; batch classifier loss: 0.615407; batch adversarial loss: 0.674864\n",
      "epoch 3; iter: 0; batch classifier loss: 0.481128; batch adversarial loss: 0.606273\n",
      "epoch 4; iter: 0; batch classifier loss: 0.409257; batch adversarial loss: 0.581506\n",
      "epoch 5; iter: 0; batch classifier loss: 0.313956; batch adversarial loss: 0.619323\n",
      "epoch 6; iter: 0; batch classifier loss: 0.411192; batch adversarial loss: 0.559612\n",
      "epoch 7; iter: 0; batch classifier loss: 0.403924; batch adversarial loss: 0.574140\n",
      "epoch 8; iter: 0; batch classifier loss: 0.388144; batch adversarial loss: 0.525869\n",
      "epoch 9; iter: 0; batch classifier loss: 0.353951; batch adversarial loss: 0.542811\n",
      "epoch 10; iter: 0; batch classifier loss: 0.317617; batch adversarial loss: 0.483666\n",
      "epoch 11; iter: 0; batch classifier loss: 0.340675; batch adversarial loss: 0.517793\n",
      "epoch 12; iter: 0; batch classifier loss: 0.253200; batch adversarial loss: 0.459822\n",
      "epoch 13; iter: 0; batch classifier loss: 0.293486; batch adversarial loss: 0.505861\n",
      "epoch 14; iter: 0; batch classifier loss: 0.324630; batch adversarial loss: 0.539011\n",
      "epoch 15; iter: 0; batch classifier loss: 0.372002; batch adversarial loss: 0.482515\n",
      "epoch 16; iter: 0; batch classifier loss: 0.350579; batch adversarial loss: 0.536804\n",
      "epoch 17; iter: 0; batch classifier loss: 0.332237; batch adversarial loss: 0.508584\n",
      "epoch 18; iter: 0; batch classifier loss: 0.258053; batch adversarial loss: 0.468710\n",
      "epoch 19; iter: 0; batch classifier loss: 0.327890; batch adversarial loss: 0.465286\n",
      "epoch 20; iter: 0; batch classifier loss: 0.260299; batch adversarial loss: 0.527621\n",
      "epoch 21; iter: 0; batch classifier loss: 0.235941; batch adversarial loss: 0.468369\n",
      "epoch 22; iter: 0; batch classifier loss: 0.289649; batch adversarial loss: 0.450605\n",
      "epoch 23; iter: 0; batch classifier loss: 0.202735; batch adversarial loss: 0.514948\n",
      "epoch 24; iter: 0; batch classifier loss: 0.293701; batch adversarial loss: 0.435868\n",
      "epoch 25; iter: 0; batch classifier loss: 0.272378; batch adversarial loss: 0.466227\n",
      "epoch 26; iter: 0; batch classifier loss: 0.267218; batch adversarial loss: 0.501915\n",
      "epoch 27; iter: 0; batch classifier loss: 0.325878; batch adversarial loss: 0.442297\n",
      "epoch 28; iter: 0; batch classifier loss: 0.268836; batch adversarial loss: 0.359743\n",
      "epoch 29; iter: 0; batch classifier loss: 0.191753; batch adversarial loss: 0.464533\n",
      "epoch 30; iter: 0; batch classifier loss: 0.191359; batch adversarial loss: 0.541094\n",
      "epoch 31; iter: 0; batch classifier loss: 0.327378; batch adversarial loss: 0.467987\n",
      "epoch 32; iter: 0; batch classifier loss: 0.229698; batch adversarial loss: 0.486441\n",
      "epoch 33; iter: 0; batch classifier loss: 0.260938; batch adversarial loss: 0.514517\n",
      "epoch 34; iter: 0; batch classifier loss: 0.220745; batch adversarial loss: 0.469257\n",
      "epoch 35; iter: 0; batch classifier loss: 0.210763; batch adversarial loss: 0.471764\n",
      "epoch 36; iter: 0; batch classifier loss: 0.217815; batch adversarial loss: 0.417581\n",
      "epoch 37; iter: 0; batch classifier loss: 0.207032; batch adversarial loss: 0.442052\n",
      "epoch 38; iter: 0; batch classifier loss: 0.258943; batch adversarial loss: 0.492772\n",
      "epoch 39; iter: 0; batch classifier loss: 0.241120; batch adversarial loss: 0.456721\n",
      "epoch 40; iter: 0; batch classifier loss: 0.277763; batch adversarial loss: 0.539894\n",
      "epoch 41; iter: 0; batch classifier loss: 0.267458; batch adversarial loss: 0.371894\n",
      "epoch 42; iter: 0; batch classifier loss: 0.234345; batch adversarial loss: 0.453244\n",
      "epoch 43; iter: 0; batch classifier loss: 0.232600; batch adversarial loss: 0.482584\n",
      "epoch 44; iter: 0; batch classifier loss: 0.245947; batch adversarial loss: 0.390877\n",
      "epoch 45; iter: 0; batch classifier loss: 0.201698; batch adversarial loss: 0.542084\n",
      "epoch 46; iter: 0; batch classifier loss: 0.288773; batch adversarial loss: 0.489797\n",
      "epoch 47; iter: 0; batch classifier loss: 0.238673; batch adversarial loss: 0.463135\n",
      "epoch 48; iter: 0; batch classifier loss: 0.206396; batch adversarial loss: 0.507516\n",
      "epoch 49; iter: 0; batch classifier loss: 0.170326; batch adversarial loss: 0.502782\n",
      "epoch 50; iter: 0; batch classifier loss: 0.216179; batch adversarial loss: 0.441613\n",
      "epoch 51; iter: 0; batch classifier loss: 0.261249; batch adversarial loss: 0.516475\n",
      "epoch 52; iter: 0; batch classifier loss: 0.221127; batch adversarial loss: 0.413863\n",
      "epoch 53; iter: 0; batch classifier loss: 0.214659; batch adversarial loss: 0.446877\n",
      "epoch 54; iter: 0; batch classifier loss: 0.266500; batch adversarial loss: 0.471653\n",
      "epoch 55; iter: 0; batch classifier loss: 0.264315; batch adversarial loss: 0.460162\n",
      "epoch 56; iter: 0; batch classifier loss: 0.240124; batch adversarial loss: 0.547004\n",
      "epoch 57; iter: 0; batch classifier loss: 0.271825; batch adversarial loss: 0.365456\n",
      "epoch 58; iter: 0; batch classifier loss: 0.233337; batch adversarial loss: 0.468248\n",
      "epoch 59; iter: 0; batch classifier loss: 0.252897; batch adversarial loss: 0.459878\n",
      "epoch 60; iter: 0; batch classifier loss: 0.219424; batch adversarial loss: 0.460039\n",
      "epoch 61; iter: 0; batch classifier loss: 0.245535; batch adversarial loss: 0.434432\n",
      "epoch 62; iter: 0; batch classifier loss: 0.232038; batch adversarial loss: 0.468734\n",
      "epoch 63; iter: 0; batch classifier loss: 0.205602; batch adversarial loss: 0.472708\n",
      "epoch 64; iter: 0; batch classifier loss: 0.262047; batch adversarial loss: 0.374835\n",
      "epoch 65; iter: 0; batch classifier loss: 0.187382; batch adversarial loss: 0.434732\n",
      "epoch 66; iter: 0; batch classifier loss: 0.291522; batch adversarial loss: 0.423263\n",
      "epoch 67; iter: 0; batch classifier loss: 0.277337; batch adversarial loss: 0.434958\n",
      "epoch 68; iter: 0; batch classifier loss: 0.157244; batch adversarial loss: 0.494928\n",
      "epoch 69; iter: 0; batch classifier loss: 0.164617; batch adversarial loss: 0.519685\n",
      "epoch 70; iter: 0; batch classifier loss: 0.332806; batch adversarial loss: 0.460041\n",
      "epoch 71; iter: 0; batch classifier loss: 0.207340; batch adversarial loss: 0.446296\n",
      "epoch 72; iter: 0; batch classifier loss: 0.269889; batch adversarial loss: 0.399983\n",
      "epoch 73; iter: 0; batch classifier loss: 0.283255; batch adversarial loss: 0.495624\n",
      "epoch 74; iter: 0; batch classifier loss: 0.246175; batch adversarial loss: 0.470418\n",
      "epoch 75; iter: 0; batch classifier loss: 0.151814; batch adversarial loss: 0.470875\n",
      "epoch 76; iter: 0; batch classifier loss: 0.108111; batch adversarial loss: 0.532344\n",
      "epoch 77; iter: 0; batch classifier loss: 0.195681; batch adversarial loss: 0.457102\n",
      "epoch 78; iter: 0; batch classifier loss: 0.186433; batch adversarial loss: 0.481226\n",
      "epoch 79; iter: 0; batch classifier loss: 0.186617; batch adversarial loss: 0.495697\n",
      "epoch 80; iter: 0; batch classifier loss: 0.135172; batch adversarial loss: 0.518780\n",
      "epoch 81; iter: 0; batch classifier loss: 0.172141; batch adversarial loss: 0.484195\n",
      "epoch 82; iter: 0; batch classifier loss: 0.321216; batch adversarial loss: 0.520241\n",
      "epoch 83; iter: 0; batch classifier loss: 0.270114; batch adversarial loss: 0.495321\n",
      "epoch 84; iter: 0; batch classifier loss: 0.224708; batch adversarial loss: 0.422569\n",
      "epoch 85; iter: 0; batch classifier loss: 0.225954; batch adversarial loss: 0.446726\n",
      "epoch 86; iter: 0; batch classifier loss: 0.254795; batch adversarial loss: 0.385223\n",
      "epoch 87; iter: 0; batch classifier loss: 0.107947; batch adversarial loss: 0.555739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.229911; batch adversarial loss: 0.397810\n",
      "epoch 89; iter: 0; batch classifier loss: 0.210596; batch adversarial loss: 0.458576\n",
      "epoch 90; iter: 0; batch classifier loss: 0.208189; batch adversarial loss: 0.446935\n",
      "epoch 91; iter: 0; batch classifier loss: 0.249755; batch adversarial loss: 0.410565\n",
      "epoch 92; iter: 0; batch classifier loss: 0.225150; batch adversarial loss: 0.483688\n",
      "epoch 93; iter: 0; batch classifier loss: 0.290695; batch adversarial loss: 0.373795\n",
      "epoch 94; iter: 0; batch classifier loss: 0.151737; batch adversarial loss: 0.483339\n",
      "epoch 95; iter: 0; batch classifier loss: 0.155119; batch adversarial loss: 0.336639\n",
      "epoch 96; iter: 0; batch classifier loss: 0.108169; batch adversarial loss: 0.495200\n",
      "epoch 97; iter: 0; batch classifier loss: 0.269789; batch adversarial loss: 0.407606\n",
      "epoch 98; iter: 0; batch classifier loss: 0.233945; batch adversarial loss: 0.521573\n",
      "epoch 99; iter: 0; batch classifier loss: 0.248333; batch adversarial loss: 0.422359\n",
      "epoch 100; iter: 0; batch classifier loss: 0.226920; batch adversarial loss: 0.399963\n",
      "epoch 101; iter: 0; batch classifier loss: 0.200675; batch adversarial loss: 0.471290\n",
      "epoch 102; iter: 0; batch classifier loss: 0.209919; batch adversarial loss: 0.532619\n",
      "epoch 103; iter: 0; batch classifier loss: 0.227139; batch adversarial loss: 0.519841\n",
      "epoch 104; iter: 0; batch classifier loss: 0.192695; batch adversarial loss: 0.471562\n",
      "epoch 105; iter: 0; batch classifier loss: 0.209914; batch adversarial loss: 0.507392\n",
      "epoch 106; iter: 0; batch classifier loss: 0.285793; batch adversarial loss: 0.434693\n",
      "epoch 107; iter: 0; batch classifier loss: 0.113600; batch adversarial loss: 0.470781\n",
      "epoch 108; iter: 0; batch classifier loss: 0.077292; batch adversarial loss: 0.518732\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045953; batch adversarial loss: 0.627144\n",
      "epoch 110; iter: 0; batch classifier loss: 0.077835; batch adversarial loss: 0.464085\n",
      "epoch 111; iter: 0; batch classifier loss: 0.110155; batch adversarial loss: 0.396403\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075015; batch adversarial loss: 0.340540\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056650; batch adversarial loss: 0.479374\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057679; batch adversarial loss: 0.412942\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070476; batch adversarial loss: 0.519328\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053458; batch adversarial loss: 0.421977\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047116; batch adversarial loss: 0.484737\n",
      "epoch 118; iter: 0; batch classifier loss: 0.068889; batch adversarial loss: 0.344928\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065326; batch adversarial loss: 0.432754\n",
      "epoch 120; iter: 0; batch classifier loss: 0.079271; batch adversarial loss: 0.452262\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045683; batch adversarial loss: 0.500396\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029380; batch adversarial loss: 0.569677\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038109; batch adversarial loss: 0.432879\n",
      "epoch 124; iter: 0; batch classifier loss: 0.099214; batch adversarial loss: 0.451701\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046048; batch adversarial loss: 0.429029\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036091; batch adversarial loss: 0.472089\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033209; batch adversarial loss: 0.475472\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042008; batch adversarial loss: 0.503949\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043389; batch adversarial loss: 0.496365\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037619; batch adversarial loss: 0.479651\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040715; batch adversarial loss: 0.456768\n",
      "epoch 132; iter: 0; batch classifier loss: 0.052622; batch adversarial loss: 0.512332\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034736; batch adversarial loss: 0.487556\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043134; batch adversarial loss: 0.422129\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026849; batch adversarial loss: 0.495771\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022922; batch adversarial loss: 0.483766\n",
      "epoch 137; iter: 0; batch classifier loss: 0.088495; batch adversarial loss: 0.393669\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023400; batch adversarial loss: 0.469393\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028024; batch adversarial loss: 0.355409\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047537; batch adversarial loss: 0.465607\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038701; batch adversarial loss: 0.442791\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043492; batch adversarial loss: 0.574390\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015408; batch adversarial loss: 0.479263\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033082; batch adversarial loss: 0.383848\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012709; batch adversarial loss: 0.488251\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016373; batch adversarial loss: 0.425404\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014279; batch adversarial loss: 0.498207\n",
      "epoch 148; iter: 0; batch classifier loss: 0.066511; batch adversarial loss: 0.489671\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033766; batch adversarial loss: 0.524771\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033913; batch adversarial loss: 0.445651\n",
      "epoch 151; iter: 0; batch classifier loss: 0.055941; batch adversarial loss: 0.426726\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020491; batch adversarial loss: 0.515223\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022322; batch adversarial loss: 0.374613\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023299; batch adversarial loss: 0.522019\n",
      "epoch 155; iter: 0; batch classifier loss: 0.006952; batch adversarial loss: 0.424957\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015796; batch adversarial loss: 0.453918\n",
      "epoch 157; iter: 0; batch classifier loss: 0.049117; batch adversarial loss: 0.461916\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029621; batch adversarial loss: 0.485079\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040578; batch adversarial loss: 0.492523\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014853; batch adversarial loss: 0.453480\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025759; batch adversarial loss: 0.496914\n",
      "epoch 162; iter: 0; batch classifier loss: 0.048135; batch adversarial loss: 0.568596\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028056; batch adversarial loss: 0.424981\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026038; batch adversarial loss: 0.428299\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031907; batch adversarial loss: 0.458365\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017397; batch adversarial loss: 0.475908\n",
      "epoch 167; iter: 0; batch classifier loss: 0.055419; batch adversarial loss: 0.443311\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038194; batch adversarial loss: 0.526372\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019472; batch adversarial loss: 0.491445\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016974; batch adversarial loss: 0.496499\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007931; batch adversarial loss: 0.459772\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009955; batch adversarial loss: 0.421113\n",
      "epoch 173; iter: 0; batch classifier loss: 0.043692; batch adversarial loss: 0.392983\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027975; batch adversarial loss: 0.397884\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022381; batch adversarial loss: 0.460330\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011238; batch adversarial loss: 0.488381\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023217; batch adversarial loss: 0.532567\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021681; batch adversarial loss: 0.445318\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012834; batch adversarial loss: 0.428080\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032372; batch adversarial loss: 0.426448\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039106; batch adversarial loss: 0.467920\n",
      "epoch 182; iter: 0; batch classifier loss: 0.003565; batch adversarial loss: 0.528394\n",
      "epoch 183; iter: 0; batch classifier loss: 0.040232; batch adversarial loss: 0.420297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.017088; batch adversarial loss: 0.364520\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008745; batch adversarial loss: 0.478542\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015070; batch adversarial loss: 0.387575\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011308; batch adversarial loss: 0.435186\n",
      "epoch 188; iter: 0; batch classifier loss: 0.038021; batch adversarial loss: 0.471491\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006046; batch adversarial loss: 0.477573\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016259; batch adversarial loss: 0.424847\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013361; batch adversarial loss: 0.489016\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017505; batch adversarial loss: 0.450932\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021700; batch adversarial loss: 0.384364\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010712; batch adversarial loss: 0.477549\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016278; batch adversarial loss: 0.397900\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009988; batch adversarial loss: 0.494939\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011696; batch adversarial loss: 0.590022\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006118; batch adversarial loss: 0.543581\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010922; batch adversarial loss: 0.402327\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698167; batch adversarial loss: 0.597979\n",
      "epoch 1; iter: 0; batch classifier loss: 0.429948; batch adversarial loss: 0.604146\n",
      "epoch 2; iter: 0; batch classifier loss: 0.369131; batch adversarial loss: 0.602172\n",
      "epoch 3; iter: 0; batch classifier loss: 0.287945; batch adversarial loss: 0.567890\n",
      "epoch 4; iter: 0; batch classifier loss: 0.370219; batch adversarial loss: 0.572481\n",
      "epoch 5; iter: 0; batch classifier loss: 0.365446; batch adversarial loss: 0.584817\n",
      "epoch 6; iter: 0; batch classifier loss: 0.316041; batch adversarial loss: 0.544325\n",
      "epoch 7; iter: 0; batch classifier loss: 0.355270; batch adversarial loss: 0.471031\n",
      "epoch 8; iter: 0; batch classifier loss: 0.293496; batch adversarial loss: 0.487995\n",
      "epoch 9; iter: 0; batch classifier loss: 0.229761; batch adversarial loss: 0.607682\n",
      "epoch 10; iter: 0; batch classifier loss: 0.346224; batch adversarial loss: 0.503035\n",
      "epoch 11; iter: 0; batch classifier loss: 0.259421; batch adversarial loss: 0.524694\n",
      "epoch 12; iter: 0; batch classifier loss: 0.234882; batch adversarial loss: 0.462474\n",
      "epoch 13; iter: 0; batch classifier loss: 0.279003; batch adversarial loss: 0.549262\n",
      "epoch 14; iter: 0; batch classifier loss: 0.249711; batch adversarial loss: 0.442563\n",
      "epoch 15; iter: 0; batch classifier loss: 0.133616; batch adversarial loss: 0.477733\n",
      "epoch 16; iter: 0; batch classifier loss: 0.250928; batch adversarial loss: 0.443833\n",
      "epoch 17; iter: 0; batch classifier loss: 0.203291; batch adversarial loss: 0.444647\n",
      "epoch 18; iter: 0; batch classifier loss: 0.153610; batch adversarial loss: 0.501730\n",
      "epoch 19; iter: 0; batch classifier loss: 0.218299; batch adversarial loss: 0.459566\n",
      "epoch 20; iter: 0; batch classifier loss: 0.225579; batch adversarial loss: 0.474572\n",
      "epoch 21; iter: 0; batch classifier loss: 0.131445; batch adversarial loss: 0.428156\n",
      "epoch 22; iter: 0; batch classifier loss: 0.225259; batch adversarial loss: 0.522433\n",
      "epoch 23; iter: 0; batch classifier loss: 0.212191; batch adversarial loss: 0.415438\n",
      "epoch 24; iter: 0; batch classifier loss: 0.135999; batch adversarial loss: 0.544840\n",
      "epoch 25; iter: 0; batch classifier loss: 0.156539; batch adversarial loss: 0.503760\n",
      "epoch 26; iter: 0; batch classifier loss: 0.171318; batch adversarial loss: 0.437447\n",
      "epoch 27; iter: 0; batch classifier loss: 0.122932; batch adversarial loss: 0.441370\n",
      "epoch 28; iter: 0; batch classifier loss: 0.133349; batch adversarial loss: 0.453555\n",
      "epoch 29; iter: 0; batch classifier loss: 0.129676; batch adversarial loss: 0.538391\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151826; batch adversarial loss: 0.406825\n",
      "epoch 31; iter: 0; batch classifier loss: 0.150881; batch adversarial loss: 0.362544\n",
      "epoch 32; iter: 0; batch classifier loss: 0.102021; batch adversarial loss: 0.543026\n",
      "epoch 33; iter: 0; batch classifier loss: 0.099026; batch adversarial loss: 0.430161\n",
      "epoch 34; iter: 0; batch classifier loss: 0.172256; batch adversarial loss: 0.447583\n",
      "epoch 35; iter: 0; batch classifier loss: 0.124424; batch adversarial loss: 0.412583\n",
      "epoch 36; iter: 0; batch classifier loss: 0.132882; batch adversarial loss: 0.484630\n",
      "epoch 37; iter: 0; batch classifier loss: 0.095023; batch adversarial loss: 0.476442\n",
      "epoch 38; iter: 0; batch classifier loss: 0.143581; batch adversarial loss: 0.404730\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148612; batch adversarial loss: 0.475443\n",
      "epoch 40; iter: 0; batch classifier loss: 0.060085; batch adversarial loss: 0.448452\n",
      "epoch 41; iter: 0; batch classifier loss: 0.112241; batch adversarial loss: 0.461817\n",
      "epoch 42; iter: 0; batch classifier loss: 0.173974; batch adversarial loss: 0.487331\n",
      "epoch 43; iter: 0; batch classifier loss: 0.086880; batch adversarial loss: 0.527532\n",
      "epoch 44; iter: 0; batch classifier loss: 0.094068; batch adversarial loss: 0.406650\n",
      "epoch 45; iter: 0; batch classifier loss: 0.082034; batch adversarial loss: 0.426413\n",
      "epoch 46; iter: 0; batch classifier loss: 0.131247; batch adversarial loss: 0.548387\n",
      "epoch 47; iter: 0; batch classifier loss: 0.099098; batch adversarial loss: 0.513290\n",
      "epoch 48; iter: 0; batch classifier loss: 0.090925; batch adversarial loss: 0.536904\n",
      "epoch 49; iter: 0; batch classifier loss: 0.085916; batch adversarial loss: 0.420510\n",
      "epoch 50; iter: 0; batch classifier loss: 0.093753; batch adversarial loss: 0.562059\n",
      "epoch 51; iter: 0; batch classifier loss: 0.141486; batch adversarial loss: 0.460880\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082850; batch adversarial loss: 0.367475\n",
      "epoch 53; iter: 0; batch classifier loss: 0.168629; batch adversarial loss: 0.336363\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095656; batch adversarial loss: 0.657185\n",
      "epoch 55; iter: 0; batch classifier loss: 0.099289; batch adversarial loss: 0.442570\n",
      "epoch 56; iter: 0; batch classifier loss: 0.124839; batch adversarial loss: 0.453618\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086656; batch adversarial loss: 0.489430\n",
      "epoch 58; iter: 0; batch classifier loss: 0.133120; batch adversarial loss: 0.449188\n",
      "epoch 59; iter: 0; batch classifier loss: 0.094839; batch adversarial loss: 0.441772\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097619; batch adversarial loss: 0.479848\n",
      "epoch 61; iter: 0; batch classifier loss: 0.115467; batch adversarial loss: 0.365876\n",
      "epoch 62; iter: 0; batch classifier loss: 0.145604; batch adversarial loss: 0.468169\n",
      "epoch 63; iter: 0; batch classifier loss: 0.134650; batch adversarial loss: 0.407568\n",
      "epoch 64; iter: 0; batch classifier loss: 0.093338; batch adversarial loss: 0.451218\n",
      "epoch 65; iter: 0; batch classifier loss: 0.119896; batch adversarial loss: 0.383988\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075812; batch adversarial loss: 0.488320\n",
      "epoch 67; iter: 0; batch classifier loss: 0.114243; batch adversarial loss: 0.436163\n",
      "epoch 68; iter: 0; batch classifier loss: 0.098884; batch adversarial loss: 0.448615\n",
      "epoch 69; iter: 0; batch classifier loss: 0.126529; batch adversarial loss: 0.430817\n",
      "epoch 70; iter: 0; batch classifier loss: 0.091723; batch adversarial loss: 0.379707\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063291; batch adversarial loss: 0.543332\n",
      "epoch 72; iter: 0; batch classifier loss: 0.047598; batch adversarial loss: 0.526106\n",
      "epoch 73; iter: 0; batch classifier loss: 0.091462; batch adversarial loss: 0.451857\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054459; batch adversarial loss: 0.515512\n",
      "epoch 75; iter: 0; batch classifier loss: 0.081876; batch adversarial loss: 0.437522\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081125; batch adversarial loss: 0.500358\n",
      "epoch 77; iter: 0; batch classifier loss: 0.089541; batch adversarial loss: 0.553937\n",
      "epoch 78; iter: 0; batch classifier loss: 0.100484; batch adversarial loss: 0.533312\n",
      "epoch 79; iter: 0; batch classifier loss: 0.193123; batch adversarial loss: 0.419136\n",
      "epoch 80; iter: 0; batch classifier loss: 0.152414; batch adversarial loss: 0.476956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.105879; batch adversarial loss: 0.470858\n",
      "epoch 82; iter: 0; batch classifier loss: 0.055782; batch adversarial loss: 0.452992\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063053; batch adversarial loss: 0.510306\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075585; batch adversarial loss: 0.406790\n",
      "epoch 85; iter: 0; batch classifier loss: 0.066589; batch adversarial loss: 0.410517\n",
      "epoch 86; iter: 0; batch classifier loss: 0.092873; batch adversarial loss: 0.453510\n",
      "epoch 87; iter: 0; batch classifier loss: 0.075084; batch adversarial loss: 0.504992\n",
      "epoch 88; iter: 0; batch classifier loss: 0.080411; batch adversarial loss: 0.402758\n",
      "epoch 89; iter: 0; batch classifier loss: 0.055949; batch adversarial loss: 0.551246\n",
      "epoch 90; iter: 0; batch classifier loss: 0.084363; batch adversarial loss: 0.446879\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075353; batch adversarial loss: 0.462578\n",
      "epoch 92; iter: 0; batch classifier loss: 0.095743; batch adversarial loss: 0.405488\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043521; batch adversarial loss: 0.451702\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056415; batch adversarial loss: 0.530851\n",
      "epoch 95; iter: 0; batch classifier loss: 0.090623; batch adversarial loss: 0.358216\n",
      "epoch 96; iter: 0; batch classifier loss: 0.032230; batch adversarial loss: 0.477173\n",
      "epoch 97; iter: 0; batch classifier loss: 0.022329; batch adversarial loss: 0.459792\n",
      "epoch 98; iter: 0; batch classifier loss: 0.065554; batch adversarial loss: 0.468525\n",
      "epoch 99; iter: 0; batch classifier loss: 0.082153; batch adversarial loss: 0.382248\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062394; batch adversarial loss: 0.333863\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062519; batch adversarial loss: 0.471059\n",
      "epoch 102; iter: 0; batch classifier loss: 0.034892; batch adversarial loss: 0.449205\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049911; batch adversarial loss: 0.452006\n",
      "epoch 104; iter: 0; batch classifier loss: 0.029506; batch adversarial loss: 0.443357\n",
      "epoch 105; iter: 0; batch classifier loss: 0.039082; batch adversarial loss: 0.500617\n",
      "epoch 106; iter: 0; batch classifier loss: 0.082871; batch adversarial loss: 0.494573\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059216; batch adversarial loss: 0.491197\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060217; batch adversarial loss: 0.480138\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053765; batch adversarial loss: 0.536142\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047246; batch adversarial loss: 0.396192\n",
      "epoch 111; iter: 0; batch classifier loss: 0.076221; batch adversarial loss: 0.450835\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043493; batch adversarial loss: 0.539120\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044024; batch adversarial loss: 0.441660\n",
      "epoch 114; iter: 0; batch classifier loss: 0.045824; batch adversarial loss: 0.419429\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050632; batch adversarial loss: 0.490695\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057216; batch adversarial loss: 0.544509\n",
      "epoch 117; iter: 0; batch classifier loss: 0.022209; batch adversarial loss: 0.602402\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040388; batch adversarial loss: 0.497712\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040611; batch adversarial loss: 0.496932\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022542; batch adversarial loss: 0.459472\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032041; batch adversarial loss: 0.439689\n",
      "epoch 122; iter: 0; batch classifier loss: 0.020532; batch adversarial loss: 0.527297\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021285; batch adversarial loss: 0.488326\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037374; batch adversarial loss: 0.364131\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047411; batch adversarial loss: 0.482701\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026592; batch adversarial loss: 0.493096\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019260; batch adversarial loss: 0.458458\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021558; batch adversarial loss: 0.412057\n",
      "epoch 129; iter: 0; batch classifier loss: 0.073655; batch adversarial loss: 0.424278\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061395; batch adversarial loss: 0.433179\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022712; batch adversarial loss: 0.443934\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016178; batch adversarial loss: 0.432041\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029449; batch adversarial loss: 0.478255\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018281; batch adversarial loss: 0.543644\n",
      "epoch 135; iter: 0; batch classifier loss: 0.061871; batch adversarial loss: 0.432396\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029554; batch adversarial loss: 0.386031\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044785; batch adversarial loss: 0.401063\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036339; batch adversarial loss: 0.508662\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021478; batch adversarial loss: 0.413448\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025571; batch adversarial loss: 0.430329\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049552; batch adversarial loss: 0.339304\n",
      "epoch 142; iter: 0; batch classifier loss: 0.008633; batch adversarial loss: 0.473303\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028985; batch adversarial loss: 0.369014\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029245; batch adversarial loss: 0.481882\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011125; batch adversarial loss: 0.442831\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024980; batch adversarial loss: 0.460006\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017239; batch adversarial loss: 0.490855\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017986; batch adversarial loss: 0.417533\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028397; batch adversarial loss: 0.477396\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023831; batch adversarial loss: 0.428498\n",
      "epoch 151; iter: 0; batch classifier loss: 0.009177; batch adversarial loss: 0.499789\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028510; batch adversarial loss: 0.451236\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024278; batch adversarial loss: 0.394064\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022901; batch adversarial loss: 0.506261\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026064; batch adversarial loss: 0.493428\n",
      "epoch 156; iter: 0; batch classifier loss: 0.006683; batch adversarial loss: 0.518663\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046101; batch adversarial loss: 0.427819\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009940; batch adversarial loss: 0.491372\n",
      "epoch 159; iter: 0; batch classifier loss: 0.009657; batch adversarial loss: 0.497656\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019766; batch adversarial loss: 0.483603\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022929; batch adversarial loss: 0.432539\n",
      "epoch 162; iter: 0; batch classifier loss: 0.080720; batch adversarial loss: 0.382908\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015649; batch adversarial loss: 0.417251\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020168; batch adversarial loss: 0.402378\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041202; batch adversarial loss: 0.469639\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046010; batch adversarial loss: 0.433139\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018712; batch adversarial loss: 0.328158\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018396; batch adversarial loss: 0.491273\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010850; batch adversarial loss: 0.455182\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015668; batch adversarial loss: 0.459185\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024009; batch adversarial loss: 0.425660\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024496; batch adversarial loss: 0.394109\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021082; batch adversarial loss: 0.385386\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020551; batch adversarial loss: 0.440157\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023841; batch adversarial loss: 0.436357\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021940; batch adversarial loss: 0.491674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.036959; batch adversarial loss: 0.535653\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032577; batch adversarial loss: 0.392047\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024619; batch adversarial loss: 0.455641\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013891; batch adversarial loss: 0.428123\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039980; batch adversarial loss: 0.448613\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020500; batch adversarial loss: 0.487231\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018006; batch adversarial loss: 0.481004\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021583; batch adversarial loss: 0.479772\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023967; batch adversarial loss: 0.380392\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028853; batch adversarial loss: 0.519413\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010561; batch adversarial loss: 0.486064\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021833; batch adversarial loss: 0.443108\n",
      "epoch 189; iter: 0; batch classifier loss: 0.002710; batch adversarial loss: 0.467384\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028046; batch adversarial loss: 0.503121\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029188; batch adversarial loss: 0.461986\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016306; batch adversarial loss: 0.539130\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015075; batch adversarial loss: 0.401401\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012249; batch adversarial loss: 0.488455\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019679; batch adversarial loss: 0.518240\n",
      "epoch 196; iter: 0; batch classifier loss: 0.003042; batch adversarial loss: 0.413811\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016168; batch adversarial loss: 0.423167\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013088; batch adversarial loss: 0.430861\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009759; batch adversarial loss: 0.491387\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717131; batch adversarial loss: 0.865340\n",
      "epoch 1; iter: 0; batch classifier loss: 0.568570; batch adversarial loss: 0.783307\n",
      "epoch 2; iter: 0; batch classifier loss: 0.748146; batch adversarial loss: 0.774098\n",
      "epoch 3; iter: 0; batch classifier loss: 0.676744; batch adversarial loss: 0.694430\n",
      "epoch 4; iter: 0; batch classifier loss: 0.626980; batch adversarial loss: 0.692302\n",
      "epoch 5; iter: 0; batch classifier loss: 0.351930; batch adversarial loss: 0.603977\n",
      "epoch 6; iter: 0; batch classifier loss: 0.369606; batch adversarial loss: 0.582674\n",
      "epoch 7; iter: 0; batch classifier loss: 0.292027; batch adversarial loss: 0.574364\n",
      "epoch 8; iter: 0; batch classifier loss: 0.343567; batch adversarial loss: 0.561099\n",
      "epoch 9; iter: 0; batch classifier loss: 0.439761; batch adversarial loss: 0.553268\n",
      "epoch 10; iter: 0; batch classifier loss: 0.324043; batch adversarial loss: 0.514924\n",
      "epoch 11; iter: 0; batch classifier loss: 0.299562; batch adversarial loss: 0.582696\n",
      "epoch 12; iter: 0; batch classifier loss: 0.295748; batch adversarial loss: 0.521465\n",
      "epoch 13; iter: 0; batch classifier loss: 0.260268; batch adversarial loss: 0.520338\n",
      "epoch 14; iter: 0; batch classifier loss: 0.203275; batch adversarial loss: 0.597409\n",
      "epoch 15; iter: 0; batch classifier loss: 0.295544; batch adversarial loss: 0.459285\n",
      "epoch 16; iter: 0; batch classifier loss: 0.232703; batch adversarial loss: 0.516959\n",
      "epoch 17; iter: 0; batch classifier loss: 0.236397; batch adversarial loss: 0.508161\n",
      "epoch 18; iter: 0; batch classifier loss: 0.210706; batch adversarial loss: 0.494143\n",
      "epoch 19; iter: 0; batch classifier loss: 0.222714; batch adversarial loss: 0.526235\n",
      "epoch 20; iter: 0; batch classifier loss: 0.194994; batch adversarial loss: 0.476084\n",
      "epoch 21; iter: 0; batch classifier loss: 0.181524; batch adversarial loss: 0.474581\n",
      "epoch 22; iter: 0; batch classifier loss: 0.187839; batch adversarial loss: 0.550077\n",
      "epoch 23; iter: 0; batch classifier loss: 0.164827; batch adversarial loss: 0.533012\n",
      "epoch 24; iter: 0; batch classifier loss: 0.135898; batch adversarial loss: 0.433314\n",
      "epoch 25; iter: 0; batch classifier loss: 0.164864; batch adversarial loss: 0.438577\n",
      "epoch 26; iter: 0; batch classifier loss: 0.141344; batch adversarial loss: 0.571827\n",
      "epoch 27; iter: 0; batch classifier loss: 0.142482; batch adversarial loss: 0.508506\n",
      "epoch 28; iter: 0; batch classifier loss: 0.139734; batch adversarial loss: 0.501827\n",
      "epoch 29; iter: 0; batch classifier loss: 0.130140; batch adversarial loss: 0.397497\n",
      "epoch 30; iter: 0; batch classifier loss: 0.154192; batch adversarial loss: 0.586438\n",
      "epoch 31; iter: 0; batch classifier loss: 0.223025; batch adversarial loss: 0.461559\n",
      "epoch 32; iter: 0; batch classifier loss: 0.124418; batch adversarial loss: 0.493252\n",
      "epoch 33; iter: 0; batch classifier loss: 0.097763; batch adversarial loss: 0.559743\n",
      "epoch 34; iter: 0; batch classifier loss: 0.101562; batch adversarial loss: 0.485677\n",
      "epoch 35; iter: 0; batch classifier loss: 0.178461; batch adversarial loss: 0.564850\n",
      "epoch 36; iter: 0; batch classifier loss: 0.097394; batch adversarial loss: 0.428448\n",
      "epoch 37; iter: 0; batch classifier loss: 0.206720; batch adversarial loss: 0.472503\n",
      "epoch 38; iter: 0; batch classifier loss: 0.096910; batch adversarial loss: 0.392736\n",
      "epoch 39; iter: 0; batch classifier loss: 0.140805; batch adversarial loss: 0.486509\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099684; batch adversarial loss: 0.540260\n",
      "epoch 41; iter: 0; batch classifier loss: 0.089867; batch adversarial loss: 0.536399\n",
      "epoch 42; iter: 0; batch classifier loss: 0.091223; batch adversarial loss: 0.500501\n",
      "epoch 43; iter: 0; batch classifier loss: 0.084178; batch adversarial loss: 0.388875\n",
      "epoch 44; iter: 0; batch classifier loss: 0.072419; batch adversarial loss: 0.447808\n",
      "epoch 45; iter: 0; batch classifier loss: 0.087630; batch adversarial loss: 0.548786\n",
      "epoch 46; iter: 0; batch classifier loss: 0.111663; batch adversarial loss: 0.462433\n",
      "epoch 47; iter: 0; batch classifier loss: 0.108568; batch adversarial loss: 0.444694\n",
      "epoch 48; iter: 0; batch classifier loss: 0.103744; batch adversarial loss: 0.522276\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074877; batch adversarial loss: 0.386769\n",
      "epoch 50; iter: 0; batch classifier loss: 0.083375; batch adversarial loss: 0.523296\n",
      "epoch 51; iter: 0; batch classifier loss: 0.046667; batch adversarial loss: 0.439109\n",
      "epoch 52; iter: 0; batch classifier loss: 0.069131; batch adversarial loss: 0.431723\n",
      "epoch 53; iter: 0; batch classifier loss: 0.117525; batch adversarial loss: 0.434322\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096798; batch adversarial loss: 0.355533\n",
      "epoch 55; iter: 0; batch classifier loss: 0.057294; batch adversarial loss: 0.492157\n",
      "epoch 56; iter: 0; batch classifier loss: 0.068635; batch adversarial loss: 0.438364\n",
      "epoch 57; iter: 0; batch classifier loss: 0.066941; batch adversarial loss: 0.468415\n",
      "epoch 58; iter: 0; batch classifier loss: 0.107184; batch adversarial loss: 0.441617\n",
      "epoch 59; iter: 0; batch classifier loss: 0.065229; batch adversarial loss: 0.496987\n",
      "epoch 60; iter: 0; batch classifier loss: 0.068181; batch adversarial loss: 0.534406\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113908; batch adversarial loss: 0.415749\n",
      "epoch 62; iter: 0; batch classifier loss: 0.073566; batch adversarial loss: 0.395872\n",
      "epoch 63; iter: 0; batch classifier loss: 0.056532; batch adversarial loss: 0.495855\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073902; batch adversarial loss: 0.475303\n",
      "epoch 65; iter: 0; batch classifier loss: 0.040337; batch adversarial loss: 0.456129\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060262; batch adversarial loss: 0.430048\n",
      "epoch 67; iter: 0; batch classifier loss: 0.056154; batch adversarial loss: 0.388451\n",
      "epoch 68; iter: 0; batch classifier loss: 0.072691; batch adversarial loss: 0.436842\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071614; batch adversarial loss: 0.554908\n",
      "epoch 70; iter: 0; batch classifier loss: 0.045057; batch adversarial loss: 0.461334\n",
      "epoch 71; iter: 0; batch classifier loss: 0.056528; batch adversarial loss: 0.511705\n",
      "epoch 72; iter: 0; batch classifier loss: 0.029441; batch adversarial loss: 0.427262\n",
      "epoch 73; iter: 0; batch classifier loss: 0.051911; batch adversarial loss: 0.427337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.040255; batch adversarial loss: 0.493607\n",
      "epoch 75; iter: 0; batch classifier loss: 0.083229; batch adversarial loss: 0.424849\n",
      "epoch 76; iter: 0; batch classifier loss: 0.052551; batch adversarial loss: 0.538692\n",
      "epoch 77; iter: 0; batch classifier loss: 0.031668; batch adversarial loss: 0.468062\n",
      "epoch 78; iter: 0; batch classifier loss: 0.077682; batch adversarial loss: 0.404661\n",
      "epoch 79; iter: 0; batch classifier loss: 0.050526; batch adversarial loss: 0.502571\n",
      "epoch 80; iter: 0; batch classifier loss: 0.040454; batch adversarial loss: 0.446960\n",
      "epoch 81; iter: 0; batch classifier loss: 0.093029; batch adversarial loss: 0.440293\n",
      "epoch 82; iter: 0; batch classifier loss: 0.034341; batch adversarial loss: 0.470236\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079794; batch adversarial loss: 0.454908\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068583; batch adversarial loss: 0.677877\n",
      "epoch 85; iter: 0; batch classifier loss: 0.039182; batch adversarial loss: 0.472029\n",
      "epoch 86; iter: 0; batch classifier loss: 0.027054; batch adversarial loss: 0.417419\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055044; batch adversarial loss: 0.459063\n",
      "epoch 88; iter: 0; batch classifier loss: 0.044781; batch adversarial loss: 0.511334\n",
      "epoch 89; iter: 0; batch classifier loss: 0.026587; batch adversarial loss: 0.464171\n",
      "epoch 90; iter: 0; batch classifier loss: 0.031772; batch adversarial loss: 0.532007\n",
      "epoch 91; iter: 0; batch classifier loss: 0.034032; batch adversarial loss: 0.463015\n",
      "epoch 92; iter: 0; batch classifier loss: 0.037654; batch adversarial loss: 0.392316\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048759; batch adversarial loss: 0.442431\n",
      "epoch 94; iter: 0; batch classifier loss: 0.064413; batch adversarial loss: 0.409040\n",
      "epoch 95; iter: 0; batch classifier loss: 0.025163; batch adversarial loss: 0.461941\n",
      "epoch 96; iter: 0; batch classifier loss: 0.022306; batch adversarial loss: 0.483496\n",
      "epoch 97; iter: 0; batch classifier loss: 0.033063; batch adversarial loss: 0.473740\n",
      "epoch 98; iter: 0; batch classifier loss: 0.032625; batch adversarial loss: 0.528082\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045272; batch adversarial loss: 0.521107\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061476; batch adversarial loss: 0.422313\n",
      "epoch 101; iter: 0; batch classifier loss: 0.030954; batch adversarial loss: 0.498706\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050180; batch adversarial loss: 0.526891\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045362; batch adversarial loss: 0.536825\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031407; batch adversarial loss: 0.469373\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042490; batch adversarial loss: 0.469816\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037893; batch adversarial loss: 0.449288\n",
      "epoch 107; iter: 0; batch classifier loss: 0.091704; batch adversarial loss: 0.460134\n",
      "epoch 108; iter: 0; batch classifier loss: 0.009113; batch adversarial loss: 0.473862\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037886; batch adversarial loss: 0.457848\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041323; batch adversarial loss: 0.417453\n",
      "epoch 111; iter: 0; batch classifier loss: 0.019383; batch adversarial loss: 0.453665\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031185; batch adversarial loss: 0.494027\n",
      "epoch 113; iter: 0; batch classifier loss: 0.032277; batch adversarial loss: 0.340760\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042085; batch adversarial loss: 0.483228\n",
      "epoch 115; iter: 0; batch classifier loss: 0.023168; batch adversarial loss: 0.370411\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040076; batch adversarial loss: 0.446536\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035254; batch adversarial loss: 0.404806\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051338; batch adversarial loss: 0.501963\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026348; batch adversarial loss: 0.437049\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045913; batch adversarial loss: 0.433918\n",
      "epoch 121; iter: 0; batch classifier loss: 0.022091; batch adversarial loss: 0.524495\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017643; batch adversarial loss: 0.402964\n",
      "epoch 123; iter: 0; batch classifier loss: 0.012409; batch adversarial loss: 0.509675\n",
      "epoch 124; iter: 0; batch classifier loss: 0.069323; batch adversarial loss: 0.376991\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044314; batch adversarial loss: 0.535475\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028666; batch adversarial loss: 0.404882\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043213; batch adversarial loss: 0.454237\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039810; batch adversarial loss: 0.494152\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031340; batch adversarial loss: 0.454298\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029710; batch adversarial loss: 0.455595\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034775; batch adversarial loss: 0.513657\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039875; batch adversarial loss: 0.427307\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034853; batch adversarial loss: 0.421681\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032685; batch adversarial loss: 0.552998\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024409; batch adversarial loss: 0.513684\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013020; batch adversarial loss: 0.471464\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045536; batch adversarial loss: 0.477128\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041236; batch adversarial loss: 0.526967\n",
      "epoch 139; iter: 0; batch classifier loss: 0.008990; batch adversarial loss: 0.482818\n",
      "epoch 140; iter: 0; batch classifier loss: 0.057980; batch adversarial loss: 0.573444\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025310; batch adversarial loss: 0.498425\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028632; batch adversarial loss: 0.454568\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013931; batch adversarial loss: 0.459026\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027211; batch adversarial loss: 0.479086\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026462; batch adversarial loss: 0.369234\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017580; batch adversarial loss: 0.480069\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016156; batch adversarial loss: 0.470297\n",
      "epoch 148; iter: 0; batch classifier loss: 0.048449; batch adversarial loss: 0.542836\n",
      "epoch 149; iter: 0; batch classifier loss: 0.042521; batch adversarial loss: 0.553629\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029153; batch adversarial loss: 0.438942\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021749; batch adversarial loss: 0.508557\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028901; batch adversarial loss: 0.448035\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036762; batch adversarial loss: 0.410803\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026491; batch adversarial loss: 0.366478\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024743; batch adversarial loss: 0.426207\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016005; batch adversarial loss: 0.423705\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032786; batch adversarial loss: 0.422652\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034352; batch adversarial loss: 0.491331\n",
      "epoch 159; iter: 0; batch classifier loss: 0.005473; batch adversarial loss: 0.480207\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017340; batch adversarial loss: 0.414877\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021155; batch adversarial loss: 0.546056\n",
      "epoch 162; iter: 0; batch classifier loss: 0.004870; batch adversarial loss: 0.413651\n",
      "epoch 163; iter: 0; batch classifier loss: 0.005559; batch adversarial loss: 0.435785\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022519; batch adversarial loss: 0.446346\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017019; batch adversarial loss: 0.460067\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023261; batch adversarial loss: 0.483461\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028912; batch adversarial loss: 0.430035\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026621; batch adversarial loss: 0.545711\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019641; batch adversarial loss: 0.374810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.005548; batch adversarial loss: 0.490602\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019003; batch adversarial loss: 0.456801\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018565; batch adversarial loss: 0.473402\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011305; batch adversarial loss: 0.454816\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017532; batch adversarial loss: 0.456928\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014885; batch adversarial loss: 0.469779\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023739; batch adversarial loss: 0.462125\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031061; batch adversarial loss: 0.546948\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017447; batch adversarial loss: 0.499498\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020291; batch adversarial loss: 0.544283\n",
      "epoch 180; iter: 0; batch classifier loss: 0.047313; batch adversarial loss: 0.486466\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011847; batch adversarial loss: 0.521093\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012085; batch adversarial loss: 0.565453\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011912; batch adversarial loss: 0.548047\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036454; batch adversarial loss: 0.502670\n",
      "epoch 185; iter: 0; batch classifier loss: 0.030132; batch adversarial loss: 0.490901\n",
      "epoch 186; iter: 0; batch classifier loss: 0.037435; batch adversarial loss: 0.405415\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019546; batch adversarial loss: 0.442153\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015116; batch adversarial loss: 0.492100\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010622; batch adversarial loss: 0.476968\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006222; batch adversarial loss: 0.492427\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033831; batch adversarial loss: 0.411823\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007370; batch adversarial loss: 0.473855\n",
      "epoch 193; iter: 0; batch classifier loss: 0.033292; batch adversarial loss: 0.463188\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012967; batch adversarial loss: 0.512105\n",
      "epoch 195; iter: 0; batch classifier loss: 0.033753; batch adversarial loss: 0.469737\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008531; batch adversarial loss: 0.440373\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020860; batch adversarial loss: 0.455841\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012143; batch adversarial loss: 0.535051\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028173; batch adversarial loss: 0.454192\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701444; batch adversarial loss: 0.633172\n",
      "epoch 1; iter: 0; batch classifier loss: 0.415189; batch adversarial loss: 0.619468\n",
      "epoch 2; iter: 0; batch classifier loss: 0.416610; batch adversarial loss: 0.593769\n",
      "epoch 3; iter: 0; batch classifier loss: 0.324392; batch adversarial loss: 0.568167\n",
      "epoch 4; iter: 0; batch classifier loss: 0.279874; batch adversarial loss: 0.553572\n",
      "epoch 5; iter: 0; batch classifier loss: 0.267820; batch adversarial loss: 0.565239\n",
      "epoch 6; iter: 0; batch classifier loss: 0.277192; batch adversarial loss: 0.539851\n",
      "epoch 7; iter: 0; batch classifier loss: 0.307231; batch adversarial loss: 0.490597\n",
      "epoch 8; iter: 0; batch classifier loss: 0.238884; batch adversarial loss: 0.534309\n",
      "epoch 9; iter: 0; batch classifier loss: 0.255690; batch adversarial loss: 0.519185\n",
      "epoch 10; iter: 0; batch classifier loss: 0.204199; batch adversarial loss: 0.539676\n",
      "epoch 11; iter: 0; batch classifier loss: 0.248983; batch adversarial loss: 0.488716\n",
      "epoch 12; iter: 0; batch classifier loss: 0.214963; batch adversarial loss: 0.426001\n",
      "epoch 13; iter: 0; batch classifier loss: 0.238871; batch adversarial loss: 0.523918\n",
      "epoch 14; iter: 0; batch classifier loss: 0.240805; batch adversarial loss: 0.516270\n",
      "epoch 15; iter: 0; batch classifier loss: 0.294057; batch adversarial loss: 0.557397\n",
      "epoch 16; iter: 0; batch classifier loss: 0.225530; batch adversarial loss: 0.449570\n",
      "epoch 17; iter: 0; batch classifier loss: 0.195121; batch adversarial loss: 0.568778\n",
      "epoch 18; iter: 0; batch classifier loss: 0.210947; batch adversarial loss: 0.523466\n",
      "epoch 19; iter: 0; batch classifier loss: 0.211412; batch adversarial loss: 0.553012\n",
      "epoch 20; iter: 0; batch classifier loss: 0.279749; batch adversarial loss: 0.538711\n",
      "epoch 21; iter: 0; batch classifier loss: 0.256992; batch adversarial loss: 0.598315\n",
      "epoch 22; iter: 0; batch classifier loss: 0.209667; batch adversarial loss: 0.505486\n",
      "epoch 23; iter: 0; batch classifier loss: 0.263824; batch adversarial loss: 0.499594\n",
      "epoch 24; iter: 0; batch classifier loss: 0.364872; batch adversarial loss: 0.529781\n",
      "epoch 25; iter: 0; batch classifier loss: 0.390457; batch adversarial loss: 0.531725\n",
      "epoch 26; iter: 0; batch classifier loss: 0.274820; batch adversarial loss: 0.488614\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171484; batch adversarial loss: 0.502380\n",
      "epoch 28; iter: 0; batch classifier loss: 0.166105; batch adversarial loss: 0.451554\n",
      "epoch 29; iter: 0; batch classifier loss: 0.132477; batch adversarial loss: 0.460090\n",
      "epoch 30; iter: 0; batch classifier loss: 0.130405; batch adversarial loss: 0.487054\n",
      "epoch 31; iter: 0; batch classifier loss: 0.115764; batch adversarial loss: 0.440344\n",
      "epoch 32; iter: 0; batch classifier loss: 0.091653; batch adversarial loss: 0.531608\n",
      "epoch 33; iter: 0; batch classifier loss: 0.102739; batch adversarial loss: 0.516374\n",
      "epoch 34; iter: 0; batch classifier loss: 0.094299; batch adversarial loss: 0.399505\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130041; batch adversarial loss: 0.415550\n",
      "epoch 36; iter: 0; batch classifier loss: 0.098036; batch adversarial loss: 0.451135\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111335; batch adversarial loss: 0.488632\n",
      "epoch 38; iter: 0; batch classifier loss: 0.076527; batch adversarial loss: 0.451242\n",
      "epoch 39; iter: 0; batch classifier loss: 0.073665; batch adversarial loss: 0.501922\n",
      "epoch 40; iter: 0; batch classifier loss: 0.066560; batch adversarial loss: 0.515460\n",
      "epoch 41; iter: 0; batch classifier loss: 0.087726; batch adversarial loss: 0.386693\n",
      "epoch 42; iter: 0; batch classifier loss: 0.057817; batch adversarial loss: 0.493455\n",
      "epoch 43; iter: 0; batch classifier loss: 0.096147; batch adversarial loss: 0.441648\n",
      "epoch 44; iter: 0; batch classifier loss: 0.096189; batch adversarial loss: 0.499430\n",
      "epoch 45; iter: 0; batch classifier loss: 0.065115; batch adversarial loss: 0.439415\n",
      "epoch 46; iter: 0; batch classifier loss: 0.088138; batch adversarial loss: 0.544721\n",
      "epoch 47; iter: 0; batch classifier loss: 0.108084; batch adversarial loss: 0.423861\n",
      "epoch 48; iter: 0; batch classifier loss: 0.057556; batch adversarial loss: 0.499540\n",
      "epoch 49; iter: 0; batch classifier loss: 0.049749; batch adversarial loss: 0.414888\n",
      "epoch 50; iter: 0; batch classifier loss: 0.078233; batch adversarial loss: 0.513809\n",
      "epoch 51; iter: 0; batch classifier loss: 0.115141; batch adversarial loss: 0.427039\n",
      "epoch 52; iter: 0; batch classifier loss: 0.087834; batch adversarial loss: 0.539219\n",
      "epoch 53; iter: 0; batch classifier loss: 0.123472; batch adversarial loss: 0.508321\n",
      "epoch 54; iter: 0; batch classifier loss: 0.104332; batch adversarial loss: 0.560398\n",
      "epoch 55; iter: 0; batch classifier loss: 0.051899; batch adversarial loss: 0.446236\n",
      "epoch 56; iter: 0; batch classifier loss: 0.097478; batch adversarial loss: 0.554528\n",
      "epoch 57; iter: 0; batch classifier loss: 0.049933; batch adversarial loss: 0.471274\n",
      "epoch 58; iter: 0; batch classifier loss: 0.135990; batch adversarial loss: 0.468584\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087713; batch adversarial loss: 0.493900\n",
      "epoch 60; iter: 0; batch classifier loss: 0.037268; batch adversarial loss: 0.507732\n",
      "epoch 61; iter: 0; batch classifier loss: 0.044421; batch adversarial loss: 0.486515\n",
      "epoch 62; iter: 0; batch classifier loss: 0.075331; batch adversarial loss: 0.461771\n",
      "epoch 63; iter: 0; batch classifier loss: 0.073416; batch adversarial loss: 0.440151\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070199; batch adversarial loss: 0.517401\n",
      "epoch 65; iter: 0; batch classifier loss: 0.069198; batch adversarial loss: 0.367380\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062762; batch adversarial loss: 0.422032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67; iter: 0; batch classifier loss: 0.054870; batch adversarial loss: 0.501114\n",
      "epoch 68; iter: 0; batch classifier loss: 0.049506; batch adversarial loss: 0.429080\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071992; batch adversarial loss: 0.458899\n",
      "epoch 70; iter: 0; batch classifier loss: 0.061331; batch adversarial loss: 0.450269\n",
      "epoch 71; iter: 0; batch classifier loss: 0.074975; batch adversarial loss: 0.496789\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072643; batch adversarial loss: 0.486285\n",
      "epoch 73; iter: 0; batch classifier loss: 0.026786; batch adversarial loss: 0.529345\n",
      "epoch 74; iter: 0; batch classifier loss: 0.035852; batch adversarial loss: 0.446235\n",
      "epoch 75; iter: 0; batch classifier loss: 0.051768; batch adversarial loss: 0.427041\n",
      "epoch 76; iter: 0; batch classifier loss: 0.042148; batch adversarial loss: 0.506588\n",
      "epoch 77; iter: 0; batch classifier loss: 0.031389; batch adversarial loss: 0.469605\n",
      "epoch 78; iter: 0; batch classifier loss: 0.081486; batch adversarial loss: 0.509714\n",
      "epoch 79; iter: 0; batch classifier loss: 0.058523; batch adversarial loss: 0.454879\n",
      "epoch 80; iter: 0; batch classifier loss: 0.055122; batch adversarial loss: 0.444053\n",
      "epoch 81; iter: 0; batch classifier loss: 0.047350; batch adversarial loss: 0.483486\n",
      "epoch 82; iter: 0; batch classifier loss: 0.043879; batch adversarial loss: 0.506716\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085331; batch adversarial loss: 0.474815\n",
      "epoch 84; iter: 0; batch classifier loss: 0.069725; batch adversarial loss: 0.544122\n",
      "epoch 85; iter: 0; batch classifier loss: 0.049175; batch adversarial loss: 0.439690\n",
      "epoch 86; iter: 0; batch classifier loss: 0.106019; batch adversarial loss: 0.353581\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076599; batch adversarial loss: 0.521811\n",
      "epoch 88; iter: 0; batch classifier loss: 0.096650; batch adversarial loss: 0.423603\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080397; batch adversarial loss: 0.366659\n",
      "epoch 90; iter: 0; batch classifier loss: 0.081057; batch adversarial loss: 0.542131\n",
      "epoch 91; iter: 0; batch classifier loss: 0.042553; batch adversarial loss: 0.399355\n",
      "epoch 92; iter: 0; batch classifier loss: 0.067134; batch adversarial loss: 0.530544\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064832; batch adversarial loss: 0.443768\n",
      "epoch 94; iter: 0; batch classifier loss: 0.035138; batch adversarial loss: 0.524875\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070424; batch adversarial loss: 0.506908\n",
      "epoch 96; iter: 0; batch classifier loss: 0.040073; batch adversarial loss: 0.526867\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049496; batch adversarial loss: 0.394940\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049478; batch adversarial loss: 0.496639\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046920; batch adversarial loss: 0.473059\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037170; batch adversarial loss: 0.517484\n",
      "epoch 101; iter: 0; batch classifier loss: 0.035052; batch adversarial loss: 0.476111\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043320; batch adversarial loss: 0.527451\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046969; batch adversarial loss: 0.387008\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062968; batch adversarial loss: 0.509452\n",
      "epoch 105; iter: 0; batch classifier loss: 0.036078; batch adversarial loss: 0.444528\n",
      "epoch 106; iter: 0; batch classifier loss: 0.023608; batch adversarial loss: 0.525879\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062435; batch adversarial loss: 0.481027\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044681; batch adversarial loss: 0.461063\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041651; batch adversarial loss: 0.470519\n",
      "epoch 110; iter: 0; batch classifier loss: 0.027421; batch adversarial loss: 0.439321\n",
      "epoch 111; iter: 0; batch classifier loss: 0.070575; batch adversarial loss: 0.384336\n",
      "epoch 112; iter: 0; batch classifier loss: 0.023039; batch adversarial loss: 0.445110\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046221; batch adversarial loss: 0.457393\n",
      "epoch 114; iter: 0; batch classifier loss: 0.072669; batch adversarial loss: 0.455789\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038156; batch adversarial loss: 0.434393\n",
      "epoch 116; iter: 0; batch classifier loss: 0.025083; batch adversarial loss: 0.418382\n",
      "epoch 117; iter: 0; batch classifier loss: 0.096589; batch adversarial loss: 0.495848\n",
      "epoch 118; iter: 0; batch classifier loss: 0.055110; batch adversarial loss: 0.434568\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031183; batch adversarial loss: 0.520088\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037964; batch adversarial loss: 0.515411\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047041; batch adversarial loss: 0.536147\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017832; batch adversarial loss: 0.568576\n",
      "epoch 123; iter: 0; batch classifier loss: 0.068216; batch adversarial loss: 0.476096\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031226; batch adversarial loss: 0.467442\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068046; batch adversarial loss: 0.387378\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063786; batch adversarial loss: 0.521137\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047794; batch adversarial loss: 0.441782\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052521; batch adversarial loss: 0.490530\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039994; batch adversarial loss: 0.542482\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042757; batch adversarial loss: 0.510746\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030639; batch adversarial loss: 0.502635\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028040; batch adversarial loss: 0.348394\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030612; batch adversarial loss: 0.512273\n",
      "epoch 134; iter: 0; batch classifier loss: 0.092300; batch adversarial loss: 0.513121\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038060; batch adversarial loss: 0.505975\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057214; batch adversarial loss: 0.524836\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033515; batch adversarial loss: 0.472308\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032046; batch adversarial loss: 0.346076\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015457; batch adversarial loss: 0.476919\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020409; batch adversarial loss: 0.433218\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028564; batch adversarial loss: 0.469954\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025917; batch adversarial loss: 0.591955\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037054; batch adversarial loss: 0.546195\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021392; batch adversarial loss: 0.413487\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033058; batch adversarial loss: 0.467720\n",
      "epoch 146; iter: 0; batch classifier loss: 0.008186; batch adversarial loss: 0.425522\n",
      "epoch 147; iter: 0; batch classifier loss: 0.049473; batch adversarial loss: 0.415191\n",
      "epoch 148; iter: 0; batch classifier loss: 0.066921; batch adversarial loss: 0.397938\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013863; batch adversarial loss: 0.446121\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052594; batch adversarial loss: 0.407653\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037024; batch adversarial loss: 0.459156\n",
      "epoch 152; iter: 0; batch classifier loss: 0.056854; batch adversarial loss: 0.421455\n",
      "epoch 153; iter: 0; batch classifier loss: 0.077033; batch adversarial loss: 0.591000\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016429; batch adversarial loss: 0.437272\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017650; batch adversarial loss: 0.560804\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012577; batch adversarial loss: 0.461571\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040461; batch adversarial loss: 0.434914\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018319; batch adversarial loss: 0.505747\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031588; batch adversarial loss: 0.420472\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013772; batch adversarial loss: 0.434677\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012037; batch adversarial loss: 0.456258\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023243; batch adversarial loss: 0.449811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 163; iter: 0; batch classifier loss: 0.019967; batch adversarial loss: 0.405438\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027843; batch adversarial loss: 0.437957\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014599; batch adversarial loss: 0.469729\n",
      "epoch 166; iter: 0; batch classifier loss: 0.070993; batch adversarial loss: 0.394269\n",
      "epoch 167; iter: 0; batch classifier loss: 0.054650; batch adversarial loss: 0.403267\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027245; batch adversarial loss: 0.427847\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017915; batch adversarial loss: 0.478503\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040379; batch adversarial loss: 0.500668\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033086; batch adversarial loss: 0.475696\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031952; batch adversarial loss: 0.551153\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030370; batch adversarial loss: 0.446341\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017976; batch adversarial loss: 0.457880\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038281; batch adversarial loss: 0.521337\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040167; batch adversarial loss: 0.504451\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013022; batch adversarial loss: 0.391218\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018410; batch adversarial loss: 0.467738\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009497; batch adversarial loss: 0.477409\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014452; batch adversarial loss: 0.444556\n",
      "epoch 181; iter: 0; batch classifier loss: 0.044631; batch adversarial loss: 0.504371\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012872; batch adversarial loss: 0.560917\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025947; batch adversarial loss: 0.413113\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028579; batch adversarial loss: 0.491724\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009242; batch adversarial loss: 0.452416\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028626; batch adversarial loss: 0.459398\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023591; batch adversarial loss: 0.509347\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024176; batch adversarial loss: 0.469697\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011256; batch adversarial loss: 0.519046\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019098; batch adversarial loss: 0.410570\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024818; batch adversarial loss: 0.489418\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020234; batch adversarial loss: 0.542997\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022200; batch adversarial loss: 0.396499\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027087; batch adversarial loss: 0.411550\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036134; batch adversarial loss: 0.447086\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033868; batch adversarial loss: 0.410042\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019808; batch adversarial loss: 0.507851\n",
      "epoch 198; iter: 0; batch classifier loss: 0.033520; batch adversarial loss: 0.394768\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011146; batch adversarial loss: 0.556727\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684020; batch adversarial loss: 0.728011\n",
      "epoch 1; iter: 0; batch classifier loss: 0.489061; batch adversarial loss: 0.669894\n",
      "epoch 2; iter: 0; batch classifier loss: 0.402168; batch adversarial loss: 0.640904\n",
      "epoch 3; iter: 0; batch classifier loss: 0.312065; batch adversarial loss: 0.615878\n",
      "epoch 4; iter: 0; batch classifier loss: 0.304020; batch adversarial loss: 0.602000\n",
      "epoch 5; iter: 0; batch classifier loss: 0.321106; batch adversarial loss: 0.568362\n",
      "epoch 6; iter: 0; batch classifier loss: 0.359618; batch adversarial loss: 0.543624\n",
      "epoch 7; iter: 0; batch classifier loss: 0.304372; batch adversarial loss: 0.591841\n",
      "epoch 8; iter: 0; batch classifier loss: 0.342866; batch adversarial loss: 0.578537\n",
      "epoch 9; iter: 0; batch classifier loss: 0.310664; batch adversarial loss: 0.508395\n",
      "epoch 10; iter: 0; batch classifier loss: 0.326668; batch adversarial loss: 0.525647\n",
      "epoch 11; iter: 0; batch classifier loss: 0.430874; batch adversarial loss: 0.496747\n",
      "epoch 12; iter: 0; batch classifier loss: 0.347849; batch adversarial loss: 0.493741\n",
      "epoch 13; iter: 0; batch classifier loss: 0.392307; batch adversarial loss: 0.532522\n",
      "epoch 14; iter: 0; batch classifier loss: 0.304320; batch adversarial loss: 0.501047\n",
      "epoch 15; iter: 0; batch classifier loss: 0.336456; batch adversarial loss: 0.489146\n",
      "epoch 16; iter: 0; batch classifier loss: 0.332256; batch adversarial loss: 0.467705\n",
      "epoch 17; iter: 0; batch classifier loss: 0.346161; batch adversarial loss: 0.456091\n",
      "epoch 18; iter: 0; batch classifier loss: 0.386908; batch adversarial loss: 0.468131\n",
      "epoch 19; iter: 0; batch classifier loss: 0.306500; batch adversarial loss: 0.489334\n",
      "epoch 20; iter: 0; batch classifier loss: 0.305061; batch adversarial loss: 0.457395\n",
      "epoch 21; iter: 0; batch classifier loss: 0.333163; batch adversarial loss: 0.438048\n",
      "epoch 22; iter: 0; batch classifier loss: 0.238629; batch adversarial loss: 0.479664\n",
      "epoch 23; iter: 0; batch classifier loss: 0.229880; batch adversarial loss: 0.477185\n",
      "epoch 24; iter: 0; batch classifier loss: 0.203200; batch adversarial loss: 0.507698\n",
      "epoch 25; iter: 0; batch classifier loss: 0.217048; batch adversarial loss: 0.579038\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208568; batch adversarial loss: 0.492176\n",
      "epoch 27; iter: 0; batch classifier loss: 0.201973; batch adversarial loss: 0.535985\n",
      "epoch 28; iter: 0; batch classifier loss: 0.224055; batch adversarial loss: 0.492689\n",
      "epoch 29; iter: 0; batch classifier loss: 0.180141; batch adversarial loss: 0.539138\n",
      "epoch 30; iter: 0; batch classifier loss: 0.161338; batch adversarial loss: 0.505865\n",
      "epoch 31; iter: 0; batch classifier loss: 0.168745; batch adversarial loss: 0.507938\n",
      "epoch 32; iter: 0; batch classifier loss: 0.134475; batch adversarial loss: 0.503044\n",
      "epoch 33; iter: 0; batch classifier loss: 0.150019; batch adversarial loss: 0.350093\n",
      "epoch 34; iter: 0; batch classifier loss: 0.166807; batch adversarial loss: 0.488745\n",
      "epoch 35; iter: 0; batch classifier loss: 0.172162; batch adversarial loss: 0.507644\n",
      "epoch 36; iter: 0; batch classifier loss: 0.171747; batch adversarial loss: 0.412016\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166661; batch adversarial loss: 0.474611\n",
      "epoch 38; iter: 0; batch classifier loss: 0.124537; batch adversarial loss: 0.466104\n",
      "epoch 39; iter: 0; batch classifier loss: 0.190103; batch adversarial loss: 0.492114\n",
      "epoch 40; iter: 0; batch classifier loss: 0.133317; batch adversarial loss: 0.587349\n",
      "epoch 41; iter: 0; batch classifier loss: 0.146139; batch adversarial loss: 0.437541\n",
      "epoch 42; iter: 0; batch classifier loss: 0.121631; batch adversarial loss: 0.493779\n",
      "epoch 43; iter: 0; batch classifier loss: 0.080841; batch adversarial loss: 0.460693\n",
      "epoch 44; iter: 0; batch classifier loss: 0.182640; batch adversarial loss: 0.415182\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102782; batch adversarial loss: 0.484832\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127198; batch adversarial loss: 0.485073\n",
      "epoch 47; iter: 0; batch classifier loss: 0.121724; batch adversarial loss: 0.471641\n",
      "epoch 48; iter: 0; batch classifier loss: 0.093741; batch adversarial loss: 0.569835\n",
      "epoch 49; iter: 0; batch classifier loss: 0.128317; batch adversarial loss: 0.446643\n",
      "epoch 50; iter: 0; batch classifier loss: 0.097647; batch adversarial loss: 0.376939\n",
      "epoch 51; iter: 0; batch classifier loss: 0.086774; batch adversarial loss: 0.523831\n",
      "epoch 52; iter: 0; batch classifier loss: 0.148704; batch adversarial loss: 0.459652\n",
      "epoch 53; iter: 0; batch classifier loss: 0.105968; batch adversarial loss: 0.494515\n",
      "epoch 54; iter: 0; batch classifier loss: 0.077618; batch adversarial loss: 0.498603\n",
      "epoch 55; iter: 0; batch classifier loss: 0.131017; batch adversarial loss: 0.413955\n",
      "epoch 56; iter: 0; batch classifier loss: 0.086558; batch adversarial loss: 0.448128\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073196; batch adversarial loss: 0.411954\n",
      "epoch 58; iter: 0; batch classifier loss: 0.092925; batch adversarial loss: 0.492029\n",
      "epoch 59; iter: 0; batch classifier loss: 0.054247; batch adversarial loss: 0.464973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.114807; batch adversarial loss: 0.361879\n",
      "epoch 61; iter: 0; batch classifier loss: 0.059500; batch adversarial loss: 0.556186\n",
      "epoch 62; iter: 0; batch classifier loss: 0.102322; batch adversarial loss: 0.455924\n",
      "epoch 63; iter: 0; batch classifier loss: 0.106894; batch adversarial loss: 0.484871\n",
      "epoch 64; iter: 0; batch classifier loss: 0.132376; batch adversarial loss: 0.453560\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070301; batch adversarial loss: 0.497915\n",
      "epoch 66; iter: 0; batch classifier loss: 0.070985; batch adversarial loss: 0.468294\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110401; batch adversarial loss: 0.401435\n",
      "epoch 68; iter: 0; batch classifier loss: 0.141297; batch adversarial loss: 0.453224\n",
      "epoch 69; iter: 0; batch classifier loss: 0.084446; batch adversarial loss: 0.414188\n",
      "epoch 70; iter: 0; batch classifier loss: 0.072224; batch adversarial loss: 0.456966\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092965; batch adversarial loss: 0.412271\n",
      "epoch 72; iter: 0; batch classifier loss: 0.086800; batch adversarial loss: 0.495121\n",
      "epoch 73; iter: 0; batch classifier loss: 0.104549; batch adversarial loss: 0.409150\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079805; batch adversarial loss: 0.510709\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061443; batch adversarial loss: 0.425243\n",
      "epoch 76; iter: 0; batch classifier loss: 0.059699; batch adversarial loss: 0.497780\n",
      "epoch 77; iter: 0; batch classifier loss: 0.083262; batch adversarial loss: 0.450330\n",
      "epoch 78; iter: 0; batch classifier loss: 0.048408; batch adversarial loss: 0.527087\n",
      "epoch 79; iter: 0; batch classifier loss: 0.110384; batch adversarial loss: 0.450936\n",
      "epoch 80; iter: 0; batch classifier loss: 0.039397; batch adversarial loss: 0.489233\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067670; batch adversarial loss: 0.382181\n",
      "epoch 82; iter: 0; batch classifier loss: 0.081066; batch adversarial loss: 0.545572\n",
      "epoch 83; iter: 0; batch classifier loss: 0.044110; batch adversarial loss: 0.484969\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056982; batch adversarial loss: 0.451261\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076404; batch adversarial loss: 0.414972\n",
      "epoch 86; iter: 0; batch classifier loss: 0.071867; batch adversarial loss: 0.389904\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071510; batch adversarial loss: 0.530774\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057691; batch adversarial loss: 0.440638\n",
      "epoch 89; iter: 0; batch classifier loss: 0.061713; batch adversarial loss: 0.603295\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063916; batch adversarial loss: 0.469700\n",
      "epoch 91; iter: 0; batch classifier loss: 0.049213; batch adversarial loss: 0.490600\n",
      "epoch 92; iter: 0; batch classifier loss: 0.085402; batch adversarial loss: 0.426681\n",
      "epoch 93; iter: 0; batch classifier loss: 0.066556; batch adversarial loss: 0.429213\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083299; batch adversarial loss: 0.546086\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054187; batch adversarial loss: 0.483954\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043499; batch adversarial loss: 0.473666\n",
      "epoch 97; iter: 0; batch classifier loss: 0.025863; batch adversarial loss: 0.509564\n",
      "epoch 98; iter: 0; batch classifier loss: 0.028809; batch adversarial loss: 0.385999\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047950; batch adversarial loss: 0.487610\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045541; batch adversarial loss: 0.406216\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056253; batch adversarial loss: 0.566410\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063075; batch adversarial loss: 0.421438\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061906; batch adversarial loss: 0.438939\n",
      "epoch 104; iter: 0; batch classifier loss: 0.055569; batch adversarial loss: 0.373858\n",
      "epoch 105; iter: 0; batch classifier loss: 0.039093; batch adversarial loss: 0.555627\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058393; batch adversarial loss: 0.492623\n",
      "epoch 107; iter: 0; batch classifier loss: 0.042981; batch adversarial loss: 0.437021\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046910; batch adversarial loss: 0.410160\n",
      "epoch 109; iter: 0; batch classifier loss: 0.079036; batch adversarial loss: 0.479234\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059036; batch adversarial loss: 0.479482\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039081; batch adversarial loss: 0.484271\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041007; batch adversarial loss: 0.451372\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046914; batch adversarial loss: 0.397950\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029387; batch adversarial loss: 0.431676\n",
      "epoch 115; iter: 0; batch classifier loss: 0.025647; batch adversarial loss: 0.458466\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027765; batch adversarial loss: 0.517933\n",
      "epoch 117; iter: 0; batch classifier loss: 0.069976; batch adversarial loss: 0.474615\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049210; batch adversarial loss: 0.457588\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042321; batch adversarial loss: 0.402119\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030807; batch adversarial loss: 0.478820\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050728; batch adversarial loss: 0.389719\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039108; batch adversarial loss: 0.478847\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050137; batch adversarial loss: 0.421068\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031331; batch adversarial loss: 0.467244\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034079; batch adversarial loss: 0.510174\n",
      "epoch 126; iter: 0; batch classifier loss: 0.077502; batch adversarial loss: 0.435805\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035282; batch adversarial loss: 0.379874\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027464; batch adversarial loss: 0.642739\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038420; batch adversarial loss: 0.431491\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051606; batch adversarial loss: 0.381348\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050519; batch adversarial loss: 0.456841\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030265; batch adversarial loss: 0.451386\n",
      "epoch 133; iter: 0; batch classifier loss: 0.017492; batch adversarial loss: 0.481109\n",
      "epoch 134; iter: 0; batch classifier loss: 0.061347; batch adversarial loss: 0.485807\n",
      "epoch 135; iter: 0; batch classifier loss: 0.010274; batch adversarial loss: 0.419720\n",
      "epoch 136; iter: 0; batch classifier loss: 0.009900; batch adversarial loss: 0.470945\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020560; batch adversarial loss: 0.481042\n",
      "epoch 138; iter: 0; batch classifier loss: 0.058166; batch adversarial loss: 0.467060\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046425; batch adversarial loss: 0.532397\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024111; batch adversarial loss: 0.527383\n",
      "epoch 141; iter: 0; batch classifier loss: 0.014381; batch adversarial loss: 0.600870\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045252; batch adversarial loss: 0.484494\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025550; batch adversarial loss: 0.500106\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028709; batch adversarial loss: 0.348720\n",
      "epoch 145; iter: 0; batch classifier loss: 0.063177; batch adversarial loss: 0.503741\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034270; batch adversarial loss: 0.449587\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033991; batch adversarial loss: 0.514420\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030185; batch adversarial loss: 0.417136\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029195; batch adversarial loss: 0.586158\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023889; batch adversarial loss: 0.515021\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018893; batch adversarial loss: 0.568699\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027757; batch adversarial loss: 0.434966\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024429; batch adversarial loss: 0.549924\n",
      "epoch 154; iter: 0; batch classifier loss: 0.049203; batch adversarial loss: 0.385991\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031988; batch adversarial loss: 0.429235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.029910; batch adversarial loss: 0.453718\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022257; batch adversarial loss: 0.441196\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020995; batch adversarial loss: 0.436798\n",
      "epoch 159; iter: 0; batch classifier loss: 0.044209; batch adversarial loss: 0.472244\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035918; batch adversarial loss: 0.395570\n",
      "epoch 161; iter: 0; batch classifier loss: 0.074190; batch adversarial loss: 0.436482\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027401; batch adversarial loss: 0.427843\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020166; batch adversarial loss: 0.492525\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016028; batch adversarial loss: 0.525673\n",
      "epoch 165; iter: 0; batch classifier loss: 0.051236; batch adversarial loss: 0.503288\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030568; batch adversarial loss: 0.372961\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030483; batch adversarial loss: 0.379993\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027347; batch adversarial loss: 0.490220\n",
      "epoch 169; iter: 0; batch classifier loss: 0.043197; batch adversarial loss: 0.494878\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013540; batch adversarial loss: 0.421887\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036764; batch adversarial loss: 0.465590\n",
      "epoch 172; iter: 0; batch classifier loss: 0.043982; batch adversarial loss: 0.453106\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029215; batch adversarial loss: 0.614144\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016291; batch adversarial loss: 0.421205\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012015; batch adversarial loss: 0.462023\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013829; batch adversarial loss: 0.548531\n",
      "epoch 177; iter: 0; batch classifier loss: 0.007680; batch adversarial loss: 0.415326\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016416; batch adversarial loss: 0.574123\n",
      "epoch 179; iter: 0; batch classifier loss: 0.005222; batch adversarial loss: 0.449463\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014054; batch adversarial loss: 0.278565\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012336; batch adversarial loss: 0.444483\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022647; batch adversarial loss: 0.465454\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019251; batch adversarial loss: 0.443218\n",
      "epoch 184; iter: 0; batch classifier loss: 0.048423; batch adversarial loss: 0.400543\n",
      "epoch 185; iter: 0; batch classifier loss: 0.004685; batch adversarial loss: 0.474040\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023550; batch adversarial loss: 0.534703\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026032; batch adversarial loss: 0.398140\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034914; batch adversarial loss: 0.398958\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018368; batch adversarial loss: 0.410351\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011710; batch adversarial loss: 0.407641\n",
      "epoch 191; iter: 0; batch classifier loss: 0.045492; batch adversarial loss: 0.477352\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032072; batch adversarial loss: 0.512128\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012053; batch adversarial loss: 0.396685\n",
      "epoch 194; iter: 0; batch classifier loss: 0.047574; batch adversarial loss: 0.491365\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011739; batch adversarial loss: 0.464376\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012544; batch adversarial loss: 0.452859\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013020; batch adversarial loss: 0.560211\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019340; batch adversarial loss: 0.508786\n",
      "epoch 199; iter: 0; batch classifier loss: 0.038498; batch adversarial loss: 0.484384\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695018; batch adversarial loss: 0.613552\n",
      "epoch 1; iter: 0; batch classifier loss: 0.426428; batch adversarial loss: 0.628022\n",
      "epoch 2; iter: 0; batch classifier loss: 0.344977; batch adversarial loss: 0.595242\n",
      "epoch 3; iter: 0; batch classifier loss: 0.392650; batch adversarial loss: 0.566639\n",
      "epoch 4; iter: 0; batch classifier loss: 0.330787; batch adversarial loss: 0.566088\n",
      "epoch 5; iter: 0; batch classifier loss: 0.350980; batch adversarial loss: 0.514043\n",
      "epoch 6; iter: 0; batch classifier loss: 0.285383; batch adversarial loss: 0.586272\n",
      "epoch 7; iter: 0; batch classifier loss: 0.400216; batch adversarial loss: 0.515659\n",
      "epoch 8; iter: 0; batch classifier loss: 0.330320; batch adversarial loss: 0.526446\n",
      "epoch 9; iter: 0; batch classifier loss: 0.379347; batch adversarial loss: 0.543495\n",
      "epoch 10; iter: 0; batch classifier loss: 0.465526; batch adversarial loss: 0.491519\n",
      "epoch 11; iter: 0; batch classifier loss: 0.479915; batch adversarial loss: 0.522727\n",
      "epoch 12; iter: 0; batch classifier loss: 0.653083; batch adversarial loss: 0.551250\n",
      "epoch 13; iter: 0; batch classifier loss: 0.462485; batch adversarial loss: 0.528195\n",
      "epoch 14; iter: 0; batch classifier loss: 0.423034; batch adversarial loss: 0.505263\n",
      "epoch 15; iter: 0; batch classifier loss: 0.236936; batch adversarial loss: 0.512538\n",
      "epoch 16; iter: 0; batch classifier loss: 0.253049; batch adversarial loss: 0.488578\n",
      "epoch 17; iter: 0; batch classifier loss: 0.198293; batch adversarial loss: 0.491257\n",
      "epoch 18; iter: 0; batch classifier loss: 0.261201; batch adversarial loss: 0.564640\n",
      "epoch 19; iter: 0; batch classifier loss: 0.211003; batch adversarial loss: 0.507276\n",
      "epoch 20; iter: 0; batch classifier loss: 0.173750; batch adversarial loss: 0.459141\n",
      "epoch 21; iter: 0; batch classifier loss: 0.201379; batch adversarial loss: 0.416370\n",
      "epoch 22; iter: 0; batch classifier loss: 0.213613; batch adversarial loss: 0.489547\n",
      "epoch 23; iter: 0; batch classifier loss: 0.172807; batch adversarial loss: 0.503010\n",
      "epoch 24; iter: 0; batch classifier loss: 0.193643; batch adversarial loss: 0.380285\n",
      "epoch 25; iter: 0; batch classifier loss: 0.170353; batch adversarial loss: 0.475774\n",
      "epoch 26; iter: 0; batch classifier loss: 0.242754; batch adversarial loss: 0.447472\n",
      "epoch 27; iter: 0; batch classifier loss: 0.176110; batch adversarial loss: 0.389817\n",
      "epoch 28; iter: 0; batch classifier loss: 0.138245; batch adversarial loss: 0.425292\n",
      "epoch 29; iter: 0; batch classifier loss: 0.086375; batch adversarial loss: 0.455895\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138714; batch adversarial loss: 0.426070\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156923; batch adversarial loss: 0.426977\n",
      "epoch 32; iter: 0; batch classifier loss: 0.105892; batch adversarial loss: 0.535884\n",
      "epoch 33; iter: 0; batch classifier loss: 0.137953; batch adversarial loss: 0.395931\n",
      "epoch 34; iter: 0; batch classifier loss: 0.166065; batch adversarial loss: 0.358648\n",
      "epoch 35; iter: 0; batch classifier loss: 0.157994; batch adversarial loss: 0.403301\n",
      "epoch 36; iter: 0; batch classifier loss: 0.134627; batch adversarial loss: 0.469819\n",
      "epoch 37; iter: 0; batch classifier loss: 0.075140; batch adversarial loss: 0.550738\n",
      "epoch 38; iter: 0; batch classifier loss: 0.081453; batch adversarial loss: 0.556634\n",
      "epoch 39; iter: 0; batch classifier loss: 0.129786; batch adversarial loss: 0.377130\n",
      "epoch 40; iter: 0; batch classifier loss: 0.100301; batch adversarial loss: 0.507615\n",
      "epoch 41; iter: 0; batch classifier loss: 0.079214; batch adversarial loss: 0.482253\n",
      "epoch 42; iter: 0; batch classifier loss: 0.142164; batch adversarial loss: 0.465259\n",
      "epoch 43; iter: 0; batch classifier loss: 0.131736; batch adversarial loss: 0.381558\n",
      "epoch 44; iter: 0; batch classifier loss: 0.100446; batch adversarial loss: 0.494367\n",
      "epoch 45; iter: 0; batch classifier loss: 0.084336; batch adversarial loss: 0.421466\n",
      "epoch 46; iter: 0; batch classifier loss: 0.082304; batch adversarial loss: 0.422092\n",
      "epoch 47; iter: 0; batch classifier loss: 0.125359; batch adversarial loss: 0.534911\n",
      "epoch 48; iter: 0; batch classifier loss: 0.128240; batch adversarial loss: 0.424418\n",
      "epoch 49; iter: 0; batch classifier loss: 0.143387; batch adversarial loss: 0.436733\n",
      "epoch 50; iter: 0; batch classifier loss: 0.100602; batch adversarial loss: 0.478670\n",
      "epoch 51; iter: 0; batch classifier loss: 0.085611; batch adversarial loss: 0.474133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.085887; batch adversarial loss: 0.555818\n",
      "epoch 53; iter: 0; batch classifier loss: 0.097462; batch adversarial loss: 0.485555\n",
      "epoch 54; iter: 0; batch classifier loss: 0.118550; batch adversarial loss: 0.439587\n",
      "epoch 55; iter: 0; batch classifier loss: 0.099722; batch adversarial loss: 0.513027\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098414; batch adversarial loss: 0.454975\n",
      "epoch 57; iter: 0; batch classifier loss: 0.090954; batch adversarial loss: 0.421566\n",
      "epoch 58; iter: 0; batch classifier loss: 0.083550; batch adversarial loss: 0.454902\n",
      "epoch 59; iter: 0; batch classifier loss: 0.073904; batch adversarial loss: 0.460574\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105067; batch adversarial loss: 0.380402\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074512; batch adversarial loss: 0.430137\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104311; batch adversarial loss: 0.436716\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095813; batch adversarial loss: 0.424616\n",
      "epoch 64; iter: 0; batch classifier loss: 0.085153; batch adversarial loss: 0.436583\n",
      "epoch 65; iter: 0; batch classifier loss: 0.067194; batch adversarial loss: 0.406900\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066102; batch adversarial loss: 0.494139\n",
      "epoch 67; iter: 0; batch classifier loss: 0.050529; batch adversarial loss: 0.510291\n",
      "epoch 68; iter: 0; batch classifier loss: 0.084850; batch adversarial loss: 0.471407\n",
      "epoch 69; iter: 0; batch classifier loss: 0.080727; batch adversarial loss: 0.500234\n",
      "epoch 70; iter: 0; batch classifier loss: 0.101003; batch adversarial loss: 0.427292\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089852; batch adversarial loss: 0.453434\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077328; batch adversarial loss: 0.424584\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067141; batch adversarial loss: 0.576111\n",
      "epoch 74; iter: 0; batch classifier loss: 0.056727; batch adversarial loss: 0.453254\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067208; batch adversarial loss: 0.484010\n",
      "epoch 76; iter: 0; batch classifier loss: 0.057783; batch adversarial loss: 0.410539\n",
      "epoch 77; iter: 0; batch classifier loss: 0.072998; batch adversarial loss: 0.437730\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080915; batch adversarial loss: 0.422257\n",
      "epoch 79; iter: 0; batch classifier loss: 0.078955; batch adversarial loss: 0.494487\n",
      "epoch 80; iter: 0; batch classifier loss: 0.063899; batch adversarial loss: 0.495929\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068785; batch adversarial loss: 0.402992\n",
      "epoch 82; iter: 0; batch classifier loss: 0.076561; batch adversarial loss: 0.508495\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059045; batch adversarial loss: 0.419994\n",
      "epoch 84; iter: 0; batch classifier loss: 0.064992; batch adversarial loss: 0.377320\n",
      "epoch 85; iter: 0; batch classifier loss: 0.041401; batch adversarial loss: 0.467732\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074421; batch adversarial loss: 0.393069\n",
      "epoch 87; iter: 0; batch classifier loss: 0.037717; batch adversarial loss: 0.431575\n",
      "epoch 88; iter: 0; batch classifier loss: 0.065343; batch adversarial loss: 0.397337\n",
      "epoch 89; iter: 0; batch classifier loss: 0.076527; batch adversarial loss: 0.381471\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042819; batch adversarial loss: 0.510604\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068673; batch adversarial loss: 0.416575\n",
      "epoch 92; iter: 0; batch classifier loss: 0.108804; batch adversarial loss: 0.484459\n",
      "epoch 93; iter: 0; batch classifier loss: 0.068481; batch adversarial loss: 0.391437\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047623; batch adversarial loss: 0.395504\n",
      "epoch 95; iter: 0; batch classifier loss: 0.069232; batch adversarial loss: 0.411682\n",
      "epoch 96; iter: 0; batch classifier loss: 0.113728; batch adversarial loss: 0.399365\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071036; batch adversarial loss: 0.426093\n",
      "epoch 98; iter: 0; batch classifier loss: 0.064716; batch adversarial loss: 0.411990\n",
      "epoch 99; iter: 0; batch classifier loss: 0.096681; batch adversarial loss: 0.405653\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064519; batch adversarial loss: 0.344520\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055055; batch adversarial loss: 0.433788\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054201; batch adversarial loss: 0.447224\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039715; batch adversarial loss: 0.386970\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036754; batch adversarial loss: 0.430859\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052438; batch adversarial loss: 0.537942\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047061; batch adversarial loss: 0.544208\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041277; batch adversarial loss: 0.435385\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053139; batch adversarial loss: 0.443608\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026928; batch adversarial loss: 0.456336\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023088; batch adversarial loss: 0.384498\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032547; batch adversarial loss: 0.470528\n",
      "epoch 112; iter: 0; batch classifier loss: 0.028795; batch adversarial loss: 0.477044\n",
      "epoch 113; iter: 0; batch classifier loss: 0.021380; batch adversarial loss: 0.542204\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054385; batch adversarial loss: 0.399794\n",
      "epoch 115; iter: 0; batch classifier loss: 0.023325; batch adversarial loss: 0.523938\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028384; batch adversarial loss: 0.460512\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047454; batch adversarial loss: 0.459535\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024886; batch adversarial loss: 0.457755\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048697; batch adversarial loss: 0.525980\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054417; batch adversarial loss: 0.455391\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057392; batch adversarial loss: 0.559344\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031483; batch adversarial loss: 0.423748\n",
      "epoch 123; iter: 0; batch classifier loss: 0.070217; batch adversarial loss: 0.483415\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033589; batch adversarial loss: 0.409969\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025031; batch adversarial loss: 0.466520\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042929; batch adversarial loss: 0.379806\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051116; batch adversarial loss: 0.450208\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040660; batch adversarial loss: 0.484978\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039237; batch adversarial loss: 0.541128\n",
      "epoch 130; iter: 0; batch classifier loss: 0.073410; batch adversarial loss: 0.587111\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015751; batch adversarial loss: 0.484332\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022311; batch adversarial loss: 0.428111\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045648; batch adversarial loss: 0.529558\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053279; batch adversarial loss: 0.451098\n",
      "epoch 135; iter: 0; batch classifier loss: 0.052043; batch adversarial loss: 0.409667\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041156; batch adversarial loss: 0.475942\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038770; batch adversarial loss: 0.431976\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027432; batch adversarial loss: 0.507914\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036604; batch adversarial loss: 0.366386\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036337; batch adversarial loss: 0.416875\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036256; batch adversarial loss: 0.399378\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025749; batch adversarial loss: 0.406860\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041983; batch adversarial loss: 0.394595\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041920; batch adversarial loss: 0.407903\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041494; batch adversarial loss: 0.458097\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019175; batch adversarial loss: 0.399704\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024233; batch adversarial loss: 0.512698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.029609; batch adversarial loss: 0.407826\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032315; batch adversarial loss: 0.422997\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054857; batch adversarial loss: 0.435772\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024172; batch adversarial loss: 0.474564\n",
      "epoch 152; iter: 0; batch classifier loss: 0.012597; batch adversarial loss: 0.396510\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038944; batch adversarial loss: 0.455278\n",
      "epoch 154; iter: 0; batch classifier loss: 0.077445; batch adversarial loss: 0.309669\n",
      "epoch 155; iter: 0; batch classifier loss: 0.068005; batch adversarial loss: 0.502282\n",
      "epoch 156; iter: 0; batch classifier loss: 0.051273; batch adversarial loss: 0.471723\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024938; batch adversarial loss: 0.540710\n",
      "epoch 158; iter: 0; batch classifier loss: 0.063879; batch adversarial loss: 0.493451\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034948; batch adversarial loss: 0.363705\n",
      "epoch 160; iter: 0; batch classifier loss: 0.040784; batch adversarial loss: 0.515703\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038983; batch adversarial loss: 0.409054\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027797; batch adversarial loss: 0.515530\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020459; batch adversarial loss: 0.418530\n",
      "epoch 164; iter: 0; batch classifier loss: 0.061237; batch adversarial loss: 0.472372\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018710; batch adversarial loss: 0.514930\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035077; batch adversarial loss: 0.472714\n",
      "epoch 167; iter: 0; batch classifier loss: 0.058065; batch adversarial loss: 0.451572\n",
      "epoch 168; iter: 0; batch classifier loss: 0.004316; batch adversarial loss: 0.444053\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020447; batch adversarial loss: 0.429584\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033664; batch adversarial loss: 0.386655\n",
      "epoch 171; iter: 0; batch classifier loss: 0.052527; batch adversarial loss: 0.454453\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019716; batch adversarial loss: 0.510901\n",
      "epoch 173; iter: 0; batch classifier loss: 0.053581; batch adversarial loss: 0.458991\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012343; batch adversarial loss: 0.410583\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020603; batch adversarial loss: 0.395469\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018113; batch adversarial loss: 0.395818\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046101; batch adversarial loss: 0.437375\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008249; batch adversarial loss: 0.412448\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027852; batch adversarial loss: 0.451527\n",
      "epoch 180; iter: 0; batch classifier loss: 0.044204; batch adversarial loss: 0.499100\n",
      "epoch 181; iter: 0; batch classifier loss: 0.047067; batch adversarial loss: 0.498782\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033508; batch adversarial loss: 0.497205\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015213; batch adversarial loss: 0.389547\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017130; batch adversarial loss: 0.446611\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029579; batch adversarial loss: 0.539160\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033313; batch adversarial loss: 0.434957\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039475; batch adversarial loss: 0.480227\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017636; batch adversarial loss: 0.449312\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031666; batch adversarial loss: 0.453022\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026139; batch adversarial loss: 0.396037\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033488; batch adversarial loss: 0.363496\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010185; batch adversarial loss: 0.399190\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015160; batch adversarial loss: 0.531361\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023698; batch adversarial loss: 0.407515\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036001; batch adversarial loss: 0.409961\n",
      "epoch 196; iter: 0; batch classifier loss: 0.045669; batch adversarial loss: 0.444732\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012258; batch adversarial loss: 0.420028\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020019; batch adversarial loss: 0.377476\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027417; batch adversarial loss: 0.464643\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698592; batch adversarial loss: 0.999117\n",
      "epoch 1; iter: 0; batch classifier loss: 0.644662; batch adversarial loss: 1.112327\n",
      "epoch 2; iter: 0; batch classifier loss: 0.789561; batch adversarial loss: 1.092251\n",
      "epoch 3; iter: 0; batch classifier loss: 0.852091; batch adversarial loss: 1.014432\n",
      "epoch 4; iter: 0; batch classifier loss: 1.014653; batch adversarial loss: 0.920793\n",
      "epoch 5; iter: 0; batch classifier loss: 0.928119; batch adversarial loss: 0.837768\n",
      "epoch 6; iter: 0; batch classifier loss: 0.824624; batch adversarial loss: 0.764001\n",
      "epoch 7; iter: 0; batch classifier loss: 0.915325; batch adversarial loss: 0.696756\n",
      "epoch 8; iter: 0; batch classifier loss: 0.654447; batch adversarial loss: 0.625186\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416387; batch adversarial loss: 0.604513\n",
      "epoch 10; iter: 0; batch classifier loss: 0.317474; batch adversarial loss: 0.580696\n",
      "epoch 11; iter: 0; batch classifier loss: 0.254077; batch adversarial loss: 0.527655\n",
      "epoch 12; iter: 0; batch classifier loss: 0.290901; batch adversarial loss: 0.556146\n",
      "epoch 13; iter: 0; batch classifier loss: 0.211537; batch adversarial loss: 0.530670\n",
      "epoch 14; iter: 0; batch classifier loss: 0.261660; batch adversarial loss: 0.528319\n",
      "epoch 15; iter: 0; batch classifier loss: 0.211445; batch adversarial loss: 0.485252\n",
      "epoch 16; iter: 0; batch classifier loss: 0.253611; batch adversarial loss: 0.505322\n",
      "epoch 17; iter: 0; batch classifier loss: 0.130821; batch adversarial loss: 0.504054\n",
      "epoch 18; iter: 0; batch classifier loss: 0.212126; batch adversarial loss: 0.523030\n",
      "epoch 19; iter: 0; batch classifier loss: 0.164652; batch adversarial loss: 0.487310\n",
      "epoch 20; iter: 0; batch classifier loss: 0.214263; batch adversarial loss: 0.519245\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202167; batch adversarial loss: 0.474268\n",
      "epoch 22; iter: 0; batch classifier loss: 0.148124; batch adversarial loss: 0.508790\n",
      "epoch 23; iter: 0; batch classifier loss: 0.176747; batch adversarial loss: 0.497596\n",
      "epoch 24; iter: 0; batch classifier loss: 0.147819; batch adversarial loss: 0.454612\n",
      "epoch 25; iter: 0; batch classifier loss: 0.113865; batch adversarial loss: 0.468399\n",
      "epoch 26; iter: 0; batch classifier loss: 0.121971; batch adversarial loss: 0.408567\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171221; batch adversarial loss: 0.462556\n",
      "epoch 28; iter: 0; batch classifier loss: 0.135146; batch adversarial loss: 0.429922\n",
      "epoch 29; iter: 0; batch classifier loss: 0.135868; batch adversarial loss: 0.389602\n",
      "epoch 30; iter: 0; batch classifier loss: 0.130512; batch adversarial loss: 0.474457\n",
      "epoch 31; iter: 0; batch classifier loss: 0.110417; batch adversarial loss: 0.476913\n",
      "epoch 32; iter: 0; batch classifier loss: 0.104811; batch adversarial loss: 0.564993\n",
      "epoch 33; iter: 0; batch classifier loss: 0.084745; batch adversarial loss: 0.436831\n",
      "epoch 34; iter: 0; batch classifier loss: 0.064916; batch adversarial loss: 0.448957\n",
      "epoch 35; iter: 0; batch classifier loss: 0.078528; batch adversarial loss: 0.506948\n",
      "epoch 36; iter: 0; batch classifier loss: 0.117000; batch adversarial loss: 0.396302\n",
      "epoch 37; iter: 0; batch classifier loss: 0.102452; batch adversarial loss: 0.367563\n",
      "epoch 38; iter: 0; batch classifier loss: 0.122306; batch adversarial loss: 0.485074\n",
      "epoch 39; iter: 0; batch classifier loss: 0.073253; batch adversarial loss: 0.379239\n",
      "epoch 40; iter: 0; batch classifier loss: 0.122218; batch adversarial loss: 0.379188\n",
      "epoch 41; iter: 0; batch classifier loss: 0.078641; batch adversarial loss: 0.316555\n",
      "epoch 42; iter: 0; batch classifier loss: 0.126679; batch adversarial loss: 0.406582\n",
      "epoch 43; iter: 0; batch classifier loss: 0.076503; batch adversarial loss: 0.493179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.091864; batch adversarial loss: 0.455901\n",
      "epoch 45; iter: 0; batch classifier loss: 0.076075; batch adversarial loss: 0.391065\n",
      "epoch 46; iter: 0; batch classifier loss: 0.080473; batch adversarial loss: 0.451259\n",
      "epoch 47; iter: 0; batch classifier loss: 0.044196; batch adversarial loss: 0.405496\n",
      "epoch 48; iter: 0; batch classifier loss: 0.117516; batch adversarial loss: 0.575126\n",
      "epoch 49; iter: 0; batch classifier loss: 0.132430; batch adversarial loss: 0.420217\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098143; batch adversarial loss: 0.334116\n",
      "epoch 51; iter: 0; batch classifier loss: 0.080194; batch adversarial loss: 0.466135\n",
      "epoch 52; iter: 0; batch classifier loss: 0.080930; batch adversarial loss: 0.554676\n",
      "epoch 53; iter: 0; batch classifier loss: 0.078433; batch adversarial loss: 0.504640\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112841; batch adversarial loss: 0.488195\n",
      "epoch 55; iter: 0; batch classifier loss: 0.034187; batch adversarial loss: 0.446528\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082785; batch adversarial loss: 0.374956\n",
      "epoch 57; iter: 0; batch classifier loss: 0.127731; batch adversarial loss: 0.439714\n",
      "epoch 58; iter: 0; batch classifier loss: 0.085037; batch adversarial loss: 0.476314\n",
      "epoch 59; iter: 0; batch classifier loss: 0.082151; batch adversarial loss: 0.390699\n",
      "epoch 60; iter: 0; batch classifier loss: 0.098962; batch adversarial loss: 0.541949\n",
      "epoch 61; iter: 0; batch classifier loss: 0.091983; batch adversarial loss: 0.457923\n",
      "epoch 62; iter: 0; batch classifier loss: 0.088007; batch adversarial loss: 0.462277\n",
      "epoch 63; iter: 0; batch classifier loss: 0.064748; batch adversarial loss: 0.455489\n",
      "epoch 64; iter: 0; batch classifier loss: 0.050442; batch adversarial loss: 0.435935\n",
      "epoch 65; iter: 0; batch classifier loss: 0.056216; batch adversarial loss: 0.480789\n",
      "epoch 66; iter: 0; batch classifier loss: 0.054131; batch adversarial loss: 0.511677\n",
      "epoch 67; iter: 0; batch classifier loss: 0.070418; batch adversarial loss: 0.467430\n",
      "epoch 68; iter: 0; batch classifier loss: 0.039969; batch adversarial loss: 0.479133\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065242; batch adversarial loss: 0.461803\n",
      "epoch 70; iter: 0; batch classifier loss: 0.073861; batch adversarial loss: 0.493561\n",
      "epoch 71; iter: 0; batch classifier loss: 0.059357; batch adversarial loss: 0.515957\n",
      "epoch 72; iter: 0; batch classifier loss: 0.081190; batch adversarial loss: 0.493799\n",
      "epoch 73; iter: 0; batch classifier loss: 0.041660; batch adversarial loss: 0.404709\n",
      "epoch 74; iter: 0; batch classifier loss: 0.073230; batch adversarial loss: 0.409378\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075950; batch adversarial loss: 0.411600\n",
      "epoch 76; iter: 0; batch classifier loss: 0.053716; batch adversarial loss: 0.397613\n",
      "epoch 77; iter: 0; batch classifier loss: 0.033022; batch adversarial loss: 0.508849\n",
      "epoch 78; iter: 0; batch classifier loss: 0.030829; batch adversarial loss: 0.425144\n",
      "epoch 79; iter: 0; batch classifier loss: 0.081739; batch adversarial loss: 0.359272\n",
      "epoch 80; iter: 0; batch classifier loss: 0.026488; batch adversarial loss: 0.517269\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076319; batch adversarial loss: 0.524321\n",
      "epoch 82; iter: 0; batch classifier loss: 0.076578; batch adversarial loss: 0.514151\n",
      "epoch 83; iter: 0; batch classifier loss: 0.036855; batch adversarial loss: 0.604123\n",
      "epoch 84; iter: 0; batch classifier loss: 0.074443; batch adversarial loss: 0.482494\n",
      "epoch 85; iter: 0; batch classifier loss: 0.049487; batch adversarial loss: 0.476709\n",
      "epoch 86; iter: 0; batch classifier loss: 0.044926; batch adversarial loss: 0.452190\n",
      "epoch 87; iter: 0; batch classifier loss: 0.039912; batch adversarial loss: 0.492909\n",
      "epoch 88; iter: 0; batch classifier loss: 0.035351; batch adversarial loss: 0.507626\n",
      "epoch 89; iter: 0; batch classifier loss: 0.047885; batch adversarial loss: 0.446069\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061122; batch adversarial loss: 0.425511\n",
      "epoch 91; iter: 0; batch classifier loss: 0.044620; batch adversarial loss: 0.523209\n",
      "epoch 92; iter: 0; batch classifier loss: 0.078244; batch adversarial loss: 0.503681\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056747; batch adversarial loss: 0.389070\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039788; batch adversarial loss: 0.458518\n",
      "epoch 95; iter: 0; batch classifier loss: 0.041325; batch adversarial loss: 0.457617\n",
      "epoch 96; iter: 0; batch classifier loss: 0.040663; batch adversarial loss: 0.389367\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050092; batch adversarial loss: 0.421919\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044517; batch adversarial loss: 0.460445\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078237; batch adversarial loss: 0.435472\n",
      "epoch 100; iter: 0; batch classifier loss: 0.027561; batch adversarial loss: 0.517090\n",
      "epoch 101; iter: 0; batch classifier loss: 0.032963; batch adversarial loss: 0.548353\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033293; batch adversarial loss: 0.469318\n",
      "epoch 103; iter: 0; batch classifier loss: 0.024972; batch adversarial loss: 0.493342\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031001; batch adversarial loss: 0.413369\n",
      "epoch 105; iter: 0; batch classifier loss: 0.036503; batch adversarial loss: 0.434032\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043744; batch adversarial loss: 0.354453\n",
      "epoch 107; iter: 0; batch classifier loss: 0.017452; batch adversarial loss: 0.503451\n",
      "epoch 108; iter: 0; batch classifier loss: 0.027688; batch adversarial loss: 0.418268\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036046; batch adversarial loss: 0.506833\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052356; batch adversarial loss: 0.500237\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053193; batch adversarial loss: 0.453576\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057876; batch adversarial loss: 0.421185\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033164; batch adversarial loss: 0.490156\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049071; batch adversarial loss: 0.475530\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024730; batch adversarial loss: 0.405748\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056010; batch adversarial loss: 0.461449\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052011; batch adversarial loss: 0.441765\n",
      "epoch 118; iter: 0; batch classifier loss: 0.038273; batch adversarial loss: 0.406129\n",
      "epoch 119; iter: 0; batch classifier loss: 0.012977; batch adversarial loss: 0.438251\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047885; batch adversarial loss: 0.426663\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033361; batch adversarial loss: 0.475691\n",
      "epoch 122; iter: 0; batch classifier loss: 0.064555; batch adversarial loss: 0.561166\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049618; batch adversarial loss: 0.427158\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046323; batch adversarial loss: 0.465790\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033182; batch adversarial loss: 0.430589\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022316; batch adversarial loss: 0.399923\n",
      "epoch 127; iter: 0; batch classifier loss: 0.015294; batch adversarial loss: 0.434501\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049904; batch adversarial loss: 0.517940\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037324; batch adversarial loss: 0.432085\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027132; batch adversarial loss: 0.370658\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055286; batch adversarial loss: 0.517405\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026624; batch adversarial loss: 0.528168\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037578; batch adversarial loss: 0.487305\n",
      "epoch 134; iter: 0; batch classifier loss: 0.022459; batch adversarial loss: 0.451640\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025908; batch adversarial loss: 0.490632\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044931; batch adversarial loss: 0.461066\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030009; batch adversarial loss: 0.491123\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016924; batch adversarial loss: 0.450991\n",
      "epoch 139; iter: 0; batch classifier loss: 0.081984; batch adversarial loss: 0.454098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.030498; batch adversarial loss: 0.442385\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023546; batch adversarial loss: 0.429390\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030940; batch adversarial loss: 0.368604\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031399; batch adversarial loss: 0.478330\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019352; batch adversarial loss: 0.435642\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036473; batch adversarial loss: 0.460048\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040796; batch adversarial loss: 0.461852\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030130; batch adversarial loss: 0.405252\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019597; batch adversarial loss: 0.441453\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023001; batch adversarial loss: 0.522631\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028600; batch adversarial loss: 0.433497\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024294; batch adversarial loss: 0.498712\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022101; batch adversarial loss: 0.432537\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019870; batch adversarial loss: 0.472549\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021251; batch adversarial loss: 0.464695\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028802; batch adversarial loss: 0.387544\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026369; batch adversarial loss: 0.440608\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032568; batch adversarial loss: 0.431434\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029988; batch adversarial loss: 0.505635\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025010; batch adversarial loss: 0.458671\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010616; batch adversarial loss: 0.450653\n",
      "epoch 161; iter: 0; batch classifier loss: 0.045453; batch adversarial loss: 0.449079\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023208; batch adversarial loss: 0.503837\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024937; batch adversarial loss: 0.429259\n",
      "epoch 164; iter: 0; batch classifier loss: 0.064700; batch adversarial loss: 0.501064\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021562; batch adversarial loss: 0.485324\n",
      "epoch 166; iter: 0; batch classifier loss: 0.051771; batch adversarial loss: 0.439077\n",
      "epoch 167; iter: 0; batch classifier loss: 0.051689; batch adversarial loss: 0.444192\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020054; batch adversarial loss: 0.483784\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021496; batch adversarial loss: 0.460173\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016107; batch adversarial loss: 0.448843\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029293; batch adversarial loss: 0.407368\n",
      "epoch 172; iter: 0; batch classifier loss: 0.035764; batch adversarial loss: 0.506548\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023959; batch adversarial loss: 0.418633\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008886; batch adversarial loss: 0.438803\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021769; batch adversarial loss: 0.488229\n",
      "epoch 176; iter: 0; batch classifier loss: 0.048707; batch adversarial loss: 0.516928\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017886; batch adversarial loss: 0.438853\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034639; batch adversarial loss: 0.468569\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028234; batch adversarial loss: 0.461451\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031005; batch adversarial loss: 0.485660\n",
      "epoch 181; iter: 0; batch classifier loss: 0.003107; batch adversarial loss: 0.487668\n",
      "epoch 182; iter: 0; batch classifier loss: 0.044819; batch adversarial loss: 0.506301\n",
      "epoch 183; iter: 0; batch classifier loss: 0.039994; batch adversarial loss: 0.463196\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033055; batch adversarial loss: 0.460498\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029159; batch adversarial loss: 0.362838\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033436; batch adversarial loss: 0.491762\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027827; batch adversarial loss: 0.429848\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013231; batch adversarial loss: 0.426328\n",
      "epoch 189; iter: 0; batch classifier loss: 0.032025; batch adversarial loss: 0.418701\n",
      "epoch 190; iter: 0; batch classifier loss: 0.038379; batch adversarial loss: 0.437635\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018452; batch adversarial loss: 0.436784\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027468; batch adversarial loss: 0.416926\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014281; batch adversarial loss: 0.447907\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023422; batch adversarial loss: 0.529880\n",
      "epoch 195; iter: 0; batch classifier loss: 0.033375; batch adversarial loss: 0.503572\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026710; batch adversarial loss: 0.593803\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017002; batch adversarial loss: 0.467975\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017596; batch adversarial loss: 0.428193\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021377; batch adversarial loss: 0.380731\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689335; batch adversarial loss: 0.615168\n",
      "epoch 1; iter: 0; batch classifier loss: 0.447263; batch adversarial loss: 0.600404\n",
      "epoch 2; iter: 0; batch classifier loss: 0.342950; batch adversarial loss: 0.574905\n",
      "epoch 3; iter: 0; batch classifier loss: 0.447914; batch adversarial loss: 0.596093\n",
      "epoch 4; iter: 0; batch classifier loss: 0.305440; batch adversarial loss: 0.567883\n",
      "epoch 5; iter: 0; batch classifier loss: 0.403695; batch adversarial loss: 0.535213\n",
      "epoch 6; iter: 0; batch classifier loss: 0.271758; batch adversarial loss: 0.506742\n",
      "epoch 7; iter: 0; batch classifier loss: 0.283174; batch adversarial loss: 0.550165\n",
      "epoch 8; iter: 0; batch classifier loss: 0.283439; batch adversarial loss: 0.547121\n",
      "epoch 9; iter: 0; batch classifier loss: 0.278153; batch adversarial loss: 0.543194\n",
      "epoch 10; iter: 0; batch classifier loss: 0.319988; batch adversarial loss: 0.518063\n",
      "epoch 11; iter: 0; batch classifier loss: 0.292408; batch adversarial loss: 0.527100\n",
      "epoch 12; iter: 0; batch classifier loss: 0.333207; batch adversarial loss: 0.563450\n",
      "epoch 13; iter: 0; batch classifier loss: 0.272656; batch adversarial loss: 0.491823\n",
      "epoch 14; iter: 0; batch classifier loss: 0.343742; batch adversarial loss: 0.583093\n",
      "epoch 15; iter: 0; batch classifier loss: 0.241406; batch adversarial loss: 0.488041\n",
      "epoch 16; iter: 0; batch classifier loss: 0.228800; batch adversarial loss: 0.487074\n",
      "epoch 17; iter: 0; batch classifier loss: 0.314545; batch adversarial loss: 0.584420\n",
      "epoch 18; iter: 0; batch classifier loss: 0.391172; batch adversarial loss: 0.491419\n",
      "epoch 19; iter: 0; batch classifier loss: 0.383031; batch adversarial loss: 0.510107\n",
      "epoch 20; iter: 0; batch classifier loss: 0.434774; batch adversarial loss: 0.500322\n",
      "epoch 21; iter: 0; batch classifier loss: 0.408255; batch adversarial loss: 0.540442\n",
      "epoch 22; iter: 0; batch classifier loss: 0.180750; batch adversarial loss: 0.434327\n",
      "epoch 23; iter: 0; batch classifier loss: 0.205217; batch adversarial loss: 0.441999\n",
      "epoch 24; iter: 0; batch classifier loss: 0.180985; batch adversarial loss: 0.489476\n",
      "epoch 25; iter: 0; batch classifier loss: 0.147436; batch adversarial loss: 0.491021\n",
      "epoch 26; iter: 0; batch classifier loss: 0.189420; batch adversarial loss: 0.470280\n",
      "epoch 27; iter: 0; batch classifier loss: 0.121427; batch adversarial loss: 0.525742\n",
      "epoch 28; iter: 0; batch classifier loss: 0.152736; batch adversarial loss: 0.484742\n",
      "epoch 29; iter: 0; batch classifier loss: 0.145490; batch adversarial loss: 0.498243\n",
      "epoch 30; iter: 0; batch classifier loss: 0.132578; batch adversarial loss: 0.504918\n",
      "epoch 31; iter: 0; batch classifier loss: 0.176179; batch adversarial loss: 0.495407\n",
      "epoch 32; iter: 0; batch classifier loss: 0.124898; batch adversarial loss: 0.417310\n",
      "epoch 33; iter: 0; batch classifier loss: 0.176708; batch adversarial loss: 0.397340\n",
      "epoch 34; iter: 0; batch classifier loss: 0.112785; batch adversarial loss: 0.423822\n",
      "epoch 35; iter: 0; batch classifier loss: 0.151000; batch adversarial loss: 0.454625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.121011; batch adversarial loss: 0.531381\n",
      "epoch 37; iter: 0; batch classifier loss: 0.125695; batch adversarial loss: 0.434636\n",
      "epoch 38; iter: 0; batch classifier loss: 0.092287; batch adversarial loss: 0.400726\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131895; batch adversarial loss: 0.427225\n",
      "epoch 40; iter: 0; batch classifier loss: 0.164504; batch adversarial loss: 0.468156\n",
      "epoch 41; iter: 0; batch classifier loss: 0.128630; batch adversarial loss: 0.446406\n",
      "epoch 42; iter: 0; batch classifier loss: 0.111567; batch adversarial loss: 0.454813\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117364; batch adversarial loss: 0.478571\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119466; batch adversarial loss: 0.476560\n",
      "epoch 45; iter: 0; batch classifier loss: 0.079376; batch adversarial loss: 0.579740\n",
      "epoch 46; iter: 0; batch classifier loss: 0.180572; batch adversarial loss: 0.448977\n",
      "epoch 47; iter: 0; batch classifier loss: 0.133302; batch adversarial loss: 0.442467\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099527; batch adversarial loss: 0.427480\n",
      "epoch 49; iter: 0; batch classifier loss: 0.097654; batch adversarial loss: 0.532788\n",
      "epoch 50; iter: 0; batch classifier loss: 0.171487; batch adversarial loss: 0.452373\n",
      "epoch 51; iter: 0; batch classifier loss: 0.150039; batch adversarial loss: 0.421770\n",
      "epoch 52; iter: 0; batch classifier loss: 0.159782; batch adversarial loss: 0.451931\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122078; batch adversarial loss: 0.498599\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112282; batch adversarial loss: 0.437028\n",
      "epoch 55; iter: 0; batch classifier loss: 0.163084; batch adversarial loss: 0.487861\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119308; batch adversarial loss: 0.439797\n",
      "epoch 57; iter: 0; batch classifier loss: 0.132270; batch adversarial loss: 0.480898\n",
      "epoch 58; iter: 0; batch classifier loss: 0.129193; batch adversarial loss: 0.518904\n",
      "epoch 59; iter: 0; batch classifier loss: 0.140655; batch adversarial loss: 0.527086\n",
      "epoch 60; iter: 0; batch classifier loss: 0.136382; batch adversarial loss: 0.437959\n",
      "epoch 61; iter: 0; batch classifier loss: 0.153311; batch adversarial loss: 0.466430\n",
      "epoch 62; iter: 0; batch classifier loss: 0.128947; batch adversarial loss: 0.456734\n",
      "epoch 63; iter: 0; batch classifier loss: 0.111726; batch adversarial loss: 0.514420\n",
      "epoch 64; iter: 0; batch classifier loss: 0.144741; batch adversarial loss: 0.478277\n",
      "epoch 65; iter: 0; batch classifier loss: 0.120252; batch adversarial loss: 0.469107\n",
      "epoch 66; iter: 0; batch classifier loss: 0.118888; batch adversarial loss: 0.467597\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171332; batch adversarial loss: 0.507897\n",
      "epoch 68; iter: 0; batch classifier loss: 0.150492; batch adversarial loss: 0.466338\n",
      "epoch 69; iter: 0; batch classifier loss: 0.152767; batch adversarial loss: 0.436663\n",
      "epoch 70; iter: 0; batch classifier loss: 0.131971; batch adversarial loss: 0.401775\n",
      "epoch 71; iter: 0; batch classifier loss: 0.145372; batch adversarial loss: 0.486536\n",
      "epoch 72; iter: 0; batch classifier loss: 0.174479; batch adversarial loss: 0.474313\n",
      "epoch 73; iter: 0; batch classifier loss: 0.080755; batch adversarial loss: 0.368103\n",
      "epoch 74; iter: 0; batch classifier loss: 0.172076; batch adversarial loss: 0.402821\n",
      "epoch 75; iter: 0; batch classifier loss: 0.171929; batch adversarial loss: 0.544714\n",
      "epoch 76; iter: 0; batch classifier loss: 0.126234; batch adversarial loss: 0.419552\n",
      "epoch 77; iter: 0; batch classifier loss: 0.128766; batch adversarial loss: 0.480970\n",
      "epoch 78; iter: 0; batch classifier loss: 0.137108; batch adversarial loss: 0.439439\n",
      "epoch 79; iter: 0; batch classifier loss: 0.112153; batch adversarial loss: 0.462866\n",
      "epoch 80; iter: 0; batch classifier loss: 0.120834; batch adversarial loss: 0.437927\n",
      "epoch 81; iter: 0; batch classifier loss: 0.126088; batch adversarial loss: 0.433960\n",
      "epoch 82; iter: 0; batch classifier loss: 0.102620; batch adversarial loss: 0.394467\n",
      "epoch 83; iter: 0; batch classifier loss: 0.126106; batch adversarial loss: 0.392407\n",
      "epoch 84; iter: 0; batch classifier loss: 0.107508; batch adversarial loss: 0.480413\n",
      "epoch 85; iter: 0; batch classifier loss: 0.148165; batch adversarial loss: 0.489551\n",
      "epoch 86; iter: 0; batch classifier loss: 0.166332; batch adversarial loss: 0.480925\n",
      "epoch 87; iter: 0; batch classifier loss: 0.119496; batch adversarial loss: 0.520055\n",
      "epoch 88; iter: 0; batch classifier loss: 0.133999; batch adversarial loss: 0.501064\n",
      "epoch 89; iter: 0; batch classifier loss: 0.127183; batch adversarial loss: 0.517596\n",
      "epoch 90; iter: 0; batch classifier loss: 0.155954; batch adversarial loss: 0.464283\n",
      "epoch 91; iter: 0; batch classifier loss: 0.142486; batch adversarial loss: 0.507547\n",
      "epoch 92; iter: 0; batch classifier loss: 0.114938; batch adversarial loss: 0.439788\n",
      "epoch 93; iter: 0; batch classifier loss: 0.139319; batch adversarial loss: 0.397390\n",
      "epoch 94; iter: 0; batch classifier loss: 0.154177; batch adversarial loss: 0.446447\n",
      "epoch 95; iter: 0; batch classifier loss: 0.096690; batch adversarial loss: 0.482897\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096084; batch adversarial loss: 0.350439\n",
      "epoch 97; iter: 0; batch classifier loss: 0.116920; batch adversarial loss: 0.431656\n",
      "epoch 98; iter: 0; batch classifier loss: 0.139127; batch adversarial loss: 0.427595\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054468; batch adversarial loss: 0.426039\n",
      "epoch 100; iter: 0; batch classifier loss: 0.081127; batch adversarial loss: 0.467354\n",
      "epoch 101; iter: 0; batch classifier loss: 0.125522; batch adversarial loss: 0.467498\n",
      "epoch 102; iter: 0; batch classifier loss: 0.087023; batch adversarial loss: 0.485566\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062232; batch adversarial loss: 0.510747\n",
      "epoch 104; iter: 0; batch classifier loss: 0.119939; batch adversarial loss: 0.499433\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051600; batch adversarial loss: 0.457583\n",
      "epoch 106; iter: 0; batch classifier loss: 0.060630; batch adversarial loss: 0.388798\n",
      "epoch 107; iter: 0; batch classifier loss: 0.054889; batch adversarial loss: 0.424727\n",
      "epoch 108; iter: 0; batch classifier loss: 0.096900; batch adversarial loss: 0.473864\n",
      "epoch 109; iter: 0; batch classifier loss: 0.072285; batch adversarial loss: 0.500973\n",
      "epoch 110; iter: 0; batch classifier loss: 0.115571; batch adversarial loss: 0.467167\n",
      "epoch 111; iter: 0; batch classifier loss: 0.063480; batch adversarial loss: 0.458083\n",
      "epoch 112; iter: 0; batch classifier loss: 0.073932; batch adversarial loss: 0.579359\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037316; batch adversarial loss: 0.492458\n",
      "epoch 114; iter: 0; batch classifier loss: 0.101379; batch adversarial loss: 0.434910\n",
      "epoch 115; iter: 0; batch classifier loss: 0.080230; batch adversarial loss: 0.496431\n",
      "epoch 116; iter: 0; batch classifier loss: 0.063450; batch adversarial loss: 0.375719\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060697; batch adversarial loss: 0.507960\n",
      "epoch 118; iter: 0; batch classifier loss: 0.062601; batch adversarial loss: 0.394869\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038131; batch adversarial loss: 0.402173\n",
      "epoch 120; iter: 0; batch classifier loss: 0.080480; batch adversarial loss: 0.457838\n",
      "epoch 121; iter: 0; batch classifier loss: 0.074434; batch adversarial loss: 0.489017\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046286; batch adversarial loss: 0.445892\n",
      "epoch 123; iter: 0; batch classifier loss: 0.065131; batch adversarial loss: 0.442411\n",
      "epoch 124; iter: 0; batch classifier loss: 0.105297; batch adversarial loss: 0.501115\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045587; batch adversarial loss: 0.445769\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040785; batch adversarial loss: 0.466902\n",
      "epoch 127; iter: 0; batch classifier loss: 0.113832; batch adversarial loss: 0.314088\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032737; batch adversarial loss: 0.447690\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032408; batch adversarial loss: 0.484096\n",
      "epoch 130; iter: 0; batch classifier loss: 0.113528; batch adversarial loss: 0.531879\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028317; batch adversarial loss: 0.484288\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023412; batch adversarial loss: 0.489110\n",
      "epoch 133; iter: 0; batch classifier loss: 0.063921; batch adversarial loss: 0.471665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.045949; batch adversarial loss: 0.516475\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040841; batch adversarial loss: 0.533800\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040671; batch adversarial loss: 0.411048\n",
      "epoch 137; iter: 0; batch classifier loss: 0.076846; batch adversarial loss: 0.390050\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041672; batch adversarial loss: 0.454863\n",
      "epoch 139; iter: 0; batch classifier loss: 0.074747; batch adversarial loss: 0.461417\n",
      "epoch 140; iter: 0; batch classifier loss: 0.069174; batch adversarial loss: 0.424274\n",
      "epoch 141; iter: 0; batch classifier loss: 0.060405; batch adversarial loss: 0.395334\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021425; batch adversarial loss: 0.404176\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022601; batch adversarial loss: 0.405022\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052519; batch adversarial loss: 0.479532\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027899; batch adversarial loss: 0.490040\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035693; batch adversarial loss: 0.449864\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026653; batch adversarial loss: 0.553126\n",
      "epoch 148; iter: 0; batch classifier loss: 0.053592; batch adversarial loss: 0.478399\n",
      "epoch 149; iter: 0; batch classifier loss: 0.064672; batch adversarial loss: 0.483886\n",
      "epoch 150; iter: 0; batch classifier loss: 0.061173; batch adversarial loss: 0.459825\n",
      "epoch 151; iter: 0; batch classifier loss: 0.055125; batch adversarial loss: 0.401122\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044023; batch adversarial loss: 0.411993\n",
      "epoch 153; iter: 0; batch classifier loss: 0.093449; batch adversarial loss: 0.560592\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031625; batch adversarial loss: 0.378556\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040888; batch adversarial loss: 0.465025\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018765; batch adversarial loss: 0.479156\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032683; batch adversarial loss: 0.439691\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042760; batch adversarial loss: 0.414991\n",
      "epoch 159; iter: 0; batch classifier loss: 0.060935; batch adversarial loss: 0.475934\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036023; batch adversarial loss: 0.476564\n",
      "epoch 161; iter: 0; batch classifier loss: 0.044042; batch adversarial loss: 0.430736\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020108; batch adversarial loss: 0.449189\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019260; batch adversarial loss: 0.423791\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022763; batch adversarial loss: 0.521873\n",
      "epoch 165; iter: 0; batch classifier loss: 0.049655; batch adversarial loss: 0.432548\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019655; batch adversarial loss: 0.397959\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033493; batch adversarial loss: 0.505325\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024971; batch adversarial loss: 0.424819\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013000; batch adversarial loss: 0.409317\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021695; batch adversarial loss: 0.438445\n",
      "epoch 171; iter: 0; batch classifier loss: 0.034887; batch adversarial loss: 0.430062\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029807; batch adversarial loss: 0.416934\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028907; batch adversarial loss: 0.467589\n",
      "epoch 174; iter: 0; batch classifier loss: 0.055896; batch adversarial loss: 0.417011\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020983; batch adversarial loss: 0.448789\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016271; batch adversarial loss: 0.393412\n",
      "epoch 177; iter: 0; batch classifier loss: 0.045308; batch adversarial loss: 0.429990\n",
      "epoch 178; iter: 0; batch classifier loss: 0.056872; batch adversarial loss: 0.478415\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021234; batch adversarial loss: 0.436142\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039296; batch adversarial loss: 0.394814\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015284; batch adversarial loss: 0.547842\n",
      "epoch 182; iter: 0; batch classifier loss: 0.045029; batch adversarial loss: 0.465664\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026678; batch adversarial loss: 0.415523\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020624; batch adversarial loss: 0.533193\n",
      "epoch 185; iter: 0; batch classifier loss: 0.049940; batch adversarial loss: 0.466565\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027367; batch adversarial loss: 0.400987\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017121; batch adversarial loss: 0.429625\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015623; batch adversarial loss: 0.382490\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023506; batch adversarial loss: 0.424015\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037164; batch adversarial loss: 0.417744\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015162; batch adversarial loss: 0.522380\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016767; batch adversarial loss: 0.394247\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022686; batch adversarial loss: 0.336399\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013926; batch adversarial loss: 0.448386\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019412; batch adversarial loss: 0.382943\n",
      "epoch 196; iter: 0; batch classifier loss: 0.036587; batch adversarial loss: 0.508538\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018382; batch adversarial loss: 0.503317\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041426; batch adversarial loss: 0.401098\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019663; batch adversarial loss: 0.450141\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682237; batch adversarial loss: 0.784984\n",
      "epoch 1; iter: 0; batch classifier loss: 0.494620; batch adversarial loss: 0.747761\n",
      "epoch 2; iter: 0; batch classifier loss: 0.476913; batch adversarial loss: 0.706815\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576553; batch adversarial loss: 0.656880\n",
      "epoch 4; iter: 0; batch classifier loss: 0.434443; batch adversarial loss: 0.620583\n",
      "epoch 5; iter: 0; batch classifier loss: 0.416184; batch adversarial loss: 0.578017\n",
      "epoch 6; iter: 0; batch classifier loss: 0.335867; batch adversarial loss: 0.573895\n",
      "epoch 7; iter: 0; batch classifier loss: 0.246788; batch adversarial loss: 0.564105\n",
      "epoch 8; iter: 0; batch classifier loss: 0.315253; batch adversarial loss: 0.508507\n",
      "epoch 9; iter: 0; batch classifier loss: 0.333498; batch adversarial loss: 0.534317\n",
      "epoch 10; iter: 0; batch classifier loss: 0.219162; batch adversarial loss: 0.553072\n",
      "epoch 11; iter: 0; batch classifier loss: 0.320678; batch adversarial loss: 0.555041\n",
      "epoch 12; iter: 0; batch classifier loss: 0.320522; batch adversarial loss: 0.501202\n",
      "epoch 13; iter: 0; batch classifier loss: 0.262031; batch adversarial loss: 0.480356\n",
      "epoch 14; iter: 0; batch classifier loss: 0.271532; batch adversarial loss: 0.486976\n",
      "epoch 15; iter: 0; batch classifier loss: 0.268158; batch adversarial loss: 0.544692\n",
      "epoch 16; iter: 0; batch classifier loss: 0.268949; batch adversarial loss: 0.497823\n",
      "epoch 17; iter: 0; batch classifier loss: 0.278041; batch adversarial loss: 0.583398\n",
      "epoch 18; iter: 0; batch classifier loss: 0.239027; batch adversarial loss: 0.490096\n",
      "epoch 19; iter: 0; batch classifier loss: 0.315913; batch adversarial loss: 0.487690\n",
      "epoch 20; iter: 0; batch classifier loss: 0.283160; batch adversarial loss: 0.494485\n",
      "epoch 21; iter: 0; batch classifier loss: 0.341448; batch adversarial loss: 0.454651\n",
      "epoch 22; iter: 0; batch classifier loss: 0.231111; batch adversarial loss: 0.495458\n",
      "epoch 23; iter: 0; batch classifier loss: 0.313114; batch adversarial loss: 0.468937\n",
      "epoch 24; iter: 0; batch classifier loss: 0.242707; batch adversarial loss: 0.405158\n",
      "epoch 25; iter: 0; batch classifier loss: 0.219430; batch adversarial loss: 0.446398\n",
      "epoch 26; iter: 0; batch classifier loss: 0.203687; batch adversarial loss: 0.450812\n",
      "epoch 27; iter: 0; batch classifier loss: 0.193487; batch adversarial loss: 0.530267\n",
      "epoch 28; iter: 0; batch classifier loss: 0.221777; batch adversarial loss: 0.365291\n",
      "epoch 29; iter: 0; batch classifier loss: 0.217637; batch adversarial loss: 0.477872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.190905; batch adversarial loss: 0.493527\n",
      "epoch 31; iter: 0; batch classifier loss: 0.283677; batch adversarial loss: 0.464553\n",
      "epoch 32; iter: 0; batch classifier loss: 0.180839; batch adversarial loss: 0.522557\n",
      "epoch 33; iter: 0; batch classifier loss: 0.197452; batch adversarial loss: 0.461714\n",
      "epoch 34; iter: 0; batch classifier loss: 0.163879; batch adversarial loss: 0.526683\n",
      "epoch 35; iter: 0; batch classifier loss: 0.187311; batch adversarial loss: 0.400703\n",
      "epoch 36; iter: 0; batch classifier loss: 0.235017; batch adversarial loss: 0.503257\n",
      "epoch 37; iter: 0; batch classifier loss: 0.216724; batch adversarial loss: 0.438289\n",
      "epoch 38; iter: 0; batch classifier loss: 0.205638; batch adversarial loss: 0.322247\n",
      "epoch 39; iter: 0; batch classifier loss: 0.133455; batch adversarial loss: 0.452720\n",
      "epoch 40; iter: 0; batch classifier loss: 0.191767; batch adversarial loss: 0.515251\n",
      "epoch 41; iter: 0; batch classifier loss: 0.190567; batch adversarial loss: 0.445989\n",
      "epoch 42; iter: 0; batch classifier loss: 0.136164; batch adversarial loss: 0.444071\n",
      "epoch 43; iter: 0; batch classifier loss: 0.183258; batch adversarial loss: 0.524516\n",
      "epoch 44; iter: 0; batch classifier loss: 0.114881; batch adversarial loss: 0.499041\n",
      "epoch 45; iter: 0; batch classifier loss: 0.184832; batch adversarial loss: 0.492255\n",
      "epoch 46; iter: 0; batch classifier loss: 0.151838; batch adversarial loss: 0.418122\n",
      "epoch 47; iter: 0; batch classifier loss: 0.167802; batch adversarial loss: 0.400399\n",
      "epoch 48; iter: 0; batch classifier loss: 0.097019; batch adversarial loss: 0.534983\n",
      "epoch 49; iter: 0; batch classifier loss: 0.130009; batch adversarial loss: 0.447022\n",
      "epoch 50; iter: 0; batch classifier loss: 0.088302; batch adversarial loss: 0.452626\n",
      "epoch 51; iter: 0; batch classifier loss: 0.140827; batch adversarial loss: 0.436495\n",
      "epoch 52; iter: 0; batch classifier loss: 0.081326; batch adversarial loss: 0.377693\n",
      "epoch 53; iter: 0; batch classifier loss: 0.105393; batch adversarial loss: 0.467711\n",
      "epoch 54; iter: 0; batch classifier loss: 0.077168; batch adversarial loss: 0.519367\n",
      "epoch 55; iter: 0; batch classifier loss: 0.100987; batch adversarial loss: 0.354901\n",
      "epoch 56; iter: 0; batch classifier loss: 0.137081; batch adversarial loss: 0.427714\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082489; batch adversarial loss: 0.557291\n",
      "epoch 58; iter: 0; batch classifier loss: 0.081353; batch adversarial loss: 0.460360\n",
      "epoch 59; iter: 0; batch classifier loss: 0.114087; batch adversarial loss: 0.397939\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072922; batch adversarial loss: 0.433593\n",
      "epoch 61; iter: 0; batch classifier loss: 0.092770; batch adversarial loss: 0.368990\n",
      "epoch 62; iter: 0; batch classifier loss: 0.109101; batch adversarial loss: 0.397763\n",
      "epoch 63; iter: 0; batch classifier loss: 0.065682; batch adversarial loss: 0.427951\n",
      "epoch 64; iter: 0; batch classifier loss: 0.058473; batch adversarial loss: 0.484467\n",
      "epoch 65; iter: 0; batch classifier loss: 0.048362; batch adversarial loss: 0.480379\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084996; batch adversarial loss: 0.403427\n",
      "epoch 67; iter: 0; batch classifier loss: 0.062816; batch adversarial loss: 0.489959\n",
      "epoch 68; iter: 0; batch classifier loss: 0.136592; batch adversarial loss: 0.417559\n",
      "epoch 69; iter: 0; batch classifier loss: 0.059244; batch adversarial loss: 0.485309\n",
      "epoch 70; iter: 0; batch classifier loss: 0.054986; batch adversarial loss: 0.437463\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058830; batch adversarial loss: 0.466146\n",
      "epoch 72; iter: 0; batch classifier loss: 0.051521; batch adversarial loss: 0.468467\n",
      "epoch 73; iter: 0; batch classifier loss: 0.121603; batch adversarial loss: 0.566849\n",
      "epoch 74; iter: 0; batch classifier loss: 0.102068; batch adversarial loss: 0.412615\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073025; batch adversarial loss: 0.492088\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070488; batch adversarial loss: 0.566615\n",
      "epoch 77; iter: 0; batch classifier loss: 0.054909; batch adversarial loss: 0.531360\n",
      "epoch 78; iter: 0; batch classifier loss: 0.047453; batch adversarial loss: 0.453398\n",
      "epoch 79; iter: 0; batch classifier loss: 0.106888; batch adversarial loss: 0.499294\n",
      "epoch 80; iter: 0; batch classifier loss: 0.047075; batch adversarial loss: 0.425048\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075157; batch adversarial loss: 0.409609\n",
      "epoch 82; iter: 0; batch classifier loss: 0.034306; batch adversarial loss: 0.532175\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078384; batch adversarial loss: 0.360773\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082669; batch adversarial loss: 0.447807\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067827; batch adversarial loss: 0.359730\n",
      "epoch 86; iter: 0; batch classifier loss: 0.129899; batch adversarial loss: 0.544196\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055823; batch adversarial loss: 0.525911\n",
      "epoch 88; iter: 0; batch classifier loss: 0.017079; batch adversarial loss: 0.400830\n",
      "epoch 89; iter: 0; batch classifier loss: 0.044452; batch adversarial loss: 0.552220\n",
      "epoch 90; iter: 0; batch classifier loss: 0.036270; batch adversarial loss: 0.455238\n",
      "epoch 91; iter: 0; batch classifier loss: 0.018399; batch adversarial loss: 0.413852\n",
      "epoch 92; iter: 0; batch classifier loss: 0.028725; batch adversarial loss: 0.411535\n",
      "epoch 93; iter: 0; batch classifier loss: 0.029769; batch adversarial loss: 0.405100\n",
      "epoch 94; iter: 0; batch classifier loss: 0.024262; batch adversarial loss: 0.430173\n",
      "epoch 95; iter: 0; batch classifier loss: 0.049785; batch adversarial loss: 0.449714\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058457; batch adversarial loss: 0.452541\n",
      "epoch 97; iter: 0; batch classifier loss: 0.032184; batch adversarial loss: 0.491660\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061977; batch adversarial loss: 0.433986\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049796; batch adversarial loss: 0.504652\n",
      "epoch 100; iter: 0; batch classifier loss: 0.018429; batch adversarial loss: 0.405031\n",
      "epoch 101; iter: 0; batch classifier loss: 0.027430; batch adversarial loss: 0.419220\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054080; batch adversarial loss: 0.397418\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050891; batch adversarial loss: 0.363127\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059052; batch adversarial loss: 0.430572\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066876; batch adversarial loss: 0.359936\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031334; batch adversarial loss: 0.537003\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033810; batch adversarial loss: 0.502483\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049951; batch adversarial loss: 0.392169\n",
      "epoch 109; iter: 0; batch classifier loss: 0.016291; batch adversarial loss: 0.436010\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051151; batch adversarial loss: 0.462946\n",
      "epoch 111; iter: 0; batch classifier loss: 0.013431; batch adversarial loss: 0.454293\n",
      "epoch 112; iter: 0; batch classifier loss: 0.020157; batch adversarial loss: 0.432418\n",
      "epoch 113; iter: 0; batch classifier loss: 0.076361; batch adversarial loss: 0.434244\n",
      "epoch 114; iter: 0; batch classifier loss: 0.031639; batch adversarial loss: 0.442068\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035265; batch adversarial loss: 0.465705\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035681; batch adversarial loss: 0.459415\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027816; batch adversarial loss: 0.319428\n",
      "epoch 118; iter: 0; batch classifier loss: 0.038667; batch adversarial loss: 0.494331\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035965; batch adversarial loss: 0.640757\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025247; batch adversarial loss: 0.493262\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031247; batch adversarial loss: 0.432591\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035117; batch adversarial loss: 0.446775\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025320; batch adversarial loss: 0.446438\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025644; batch adversarial loss: 0.384511\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034215; batch adversarial loss: 0.446767\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035869; batch adversarial loss: 0.419659\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047913; batch adversarial loss: 0.518569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.015370; batch adversarial loss: 0.485581\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025145; batch adversarial loss: 0.475171\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024321; batch adversarial loss: 0.437218\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028007; batch adversarial loss: 0.456156\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020420; batch adversarial loss: 0.524650\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019177; batch adversarial loss: 0.358657\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042167; batch adversarial loss: 0.471528\n",
      "epoch 135; iter: 0; batch classifier loss: 0.015896; batch adversarial loss: 0.418174\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017686; batch adversarial loss: 0.361023\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043206; batch adversarial loss: 0.418367\n",
      "epoch 138; iter: 0; batch classifier loss: 0.007672; batch adversarial loss: 0.465403\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010874; batch adversarial loss: 0.370201\n",
      "epoch 140; iter: 0; batch classifier loss: 0.012767; batch adversarial loss: 0.457616\n",
      "epoch 141; iter: 0; batch classifier loss: 0.010001; batch adversarial loss: 0.432356\n",
      "epoch 142; iter: 0; batch classifier loss: 0.010131; batch adversarial loss: 0.395892\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013629; batch adversarial loss: 0.544475\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022248; batch adversarial loss: 0.456975\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027903; batch adversarial loss: 0.416517\n",
      "epoch 146; iter: 0; batch classifier loss: 0.006869; batch adversarial loss: 0.432740\n",
      "epoch 147; iter: 0; batch classifier loss: 0.054547; batch adversarial loss: 0.478607\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025741; batch adversarial loss: 0.413353\n",
      "epoch 149; iter: 0; batch classifier loss: 0.009240; batch adversarial loss: 0.493127\n",
      "epoch 150; iter: 0; batch classifier loss: 0.008070; batch adversarial loss: 0.450452\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031321; batch adversarial loss: 0.390458\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010762; batch adversarial loss: 0.507837\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018259; batch adversarial loss: 0.397565\n",
      "epoch 154; iter: 0; batch classifier loss: 0.007341; batch adversarial loss: 0.393603\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010659; batch adversarial loss: 0.476898\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012538; batch adversarial loss: 0.456606\n",
      "epoch 157; iter: 0; batch classifier loss: 0.007844; batch adversarial loss: 0.510459\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010732; batch adversarial loss: 0.525490\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017286; batch adversarial loss: 0.435466\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029921; batch adversarial loss: 0.403773\n",
      "epoch 161; iter: 0; batch classifier loss: 0.005990; batch adversarial loss: 0.590254\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015129; batch adversarial loss: 0.460148\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018914; batch adversarial loss: 0.501927\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019862; batch adversarial loss: 0.560486\n",
      "epoch 165; iter: 0; batch classifier loss: 0.004331; batch adversarial loss: 0.376473\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046186; batch adversarial loss: 0.378292\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007399; batch adversarial loss: 0.460711\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016330; batch adversarial loss: 0.508997\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026491; batch adversarial loss: 0.415121\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037953; batch adversarial loss: 0.582032\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007519; batch adversarial loss: 0.523531\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015809; batch adversarial loss: 0.412114\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011759; batch adversarial loss: 0.423491\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022871; batch adversarial loss: 0.464901\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018788; batch adversarial loss: 0.486100\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027147; batch adversarial loss: 0.428421\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012614; batch adversarial loss: 0.479329\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008642; batch adversarial loss: 0.404875\n",
      "epoch 179; iter: 0; batch classifier loss: 0.055715; batch adversarial loss: 0.453869\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031725; batch adversarial loss: 0.555248\n",
      "epoch 181; iter: 0; batch classifier loss: 0.004424; batch adversarial loss: 0.548692\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038846; batch adversarial loss: 0.543276\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005967; batch adversarial loss: 0.407231\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024749; batch adversarial loss: 0.437773\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016147; batch adversarial loss: 0.397694\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015256; batch adversarial loss: 0.423593\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029637; batch adversarial loss: 0.530475\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023755; batch adversarial loss: 0.436738\n",
      "epoch 189; iter: 0; batch classifier loss: 0.002498; batch adversarial loss: 0.475597\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028650; batch adversarial loss: 0.529063\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015080; batch adversarial loss: 0.475537\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015589; batch adversarial loss: 0.414489\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030598; batch adversarial loss: 0.463149\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011439; batch adversarial loss: 0.557058\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021682; batch adversarial loss: 0.493009\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013139; batch adversarial loss: 0.348955\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005958; batch adversarial loss: 0.390006\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017077; batch adversarial loss: 0.480027\n",
      "epoch 199; iter: 0; batch classifier loss: 0.048785; batch adversarial loss: 0.464714\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705140; batch adversarial loss: 0.861757\n",
      "epoch 1; iter: 0; batch classifier loss: 0.471091; batch adversarial loss: 0.870439\n",
      "epoch 2; iter: 0; batch classifier loss: 0.374393; batch adversarial loss: 0.803144\n",
      "epoch 3; iter: 0; batch classifier loss: 0.362726; batch adversarial loss: 0.722014\n",
      "epoch 4; iter: 0; batch classifier loss: 0.331273; batch adversarial loss: 0.674014\n",
      "epoch 5; iter: 0; batch classifier loss: 0.290896; batch adversarial loss: 0.683318\n",
      "epoch 6; iter: 0; batch classifier loss: 0.276692; batch adversarial loss: 0.622567\n",
      "epoch 7; iter: 0; batch classifier loss: 0.298614; batch adversarial loss: 0.601141\n",
      "epoch 8; iter: 0; batch classifier loss: 0.299835; batch adversarial loss: 0.574420\n",
      "epoch 9; iter: 0; batch classifier loss: 0.349797; batch adversarial loss: 0.585242\n",
      "epoch 10; iter: 0; batch classifier loss: 0.273449; batch adversarial loss: 0.587738\n",
      "epoch 11; iter: 0; batch classifier loss: 0.265353; batch adversarial loss: 0.511540\n",
      "epoch 12; iter: 0; batch classifier loss: 0.245803; batch adversarial loss: 0.523225\n",
      "epoch 13; iter: 0; batch classifier loss: 0.185714; batch adversarial loss: 0.524381\n",
      "epoch 14; iter: 0; batch classifier loss: 0.285374; batch adversarial loss: 0.451650\n",
      "epoch 15; iter: 0; batch classifier loss: 0.190953; batch adversarial loss: 0.454251\n",
      "epoch 16; iter: 0; batch classifier loss: 0.212790; batch adversarial loss: 0.428596\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269786; batch adversarial loss: 0.425242\n",
      "epoch 18; iter: 0; batch classifier loss: 0.272406; batch adversarial loss: 0.434028\n",
      "epoch 19; iter: 0; batch classifier loss: 0.211845; batch adversarial loss: 0.423355\n",
      "epoch 20; iter: 0; batch classifier loss: 0.237976; batch adversarial loss: 0.507540\n",
      "epoch 21; iter: 0; batch classifier loss: 0.291099; batch adversarial loss: 0.396592\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189850; batch adversarial loss: 0.410803\n",
      "epoch 23; iter: 0; batch classifier loss: 0.228209; batch adversarial loss: 0.407671\n",
      "epoch 24; iter: 0; batch classifier loss: 0.289747; batch adversarial loss: 0.432087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25; iter: 0; batch classifier loss: 0.218963; batch adversarial loss: 0.411525\n",
      "epoch 26; iter: 0; batch classifier loss: 0.270218; batch adversarial loss: 0.379672\n",
      "epoch 27; iter: 0; batch classifier loss: 0.189988; batch adversarial loss: 0.410520\n",
      "epoch 28; iter: 0; batch classifier loss: 0.133920; batch adversarial loss: 0.415883\n",
      "epoch 29; iter: 0; batch classifier loss: 0.176923; batch adversarial loss: 0.298221\n",
      "epoch 30; iter: 0; batch classifier loss: 0.187748; batch adversarial loss: 0.382834\n",
      "epoch 31; iter: 0; batch classifier loss: 0.190016; batch adversarial loss: 0.405336\n",
      "epoch 32; iter: 0; batch classifier loss: 0.180425; batch adversarial loss: 0.420307\n",
      "epoch 33; iter: 0; batch classifier loss: 0.221731; batch adversarial loss: 0.435585\n",
      "epoch 34; iter: 0; batch classifier loss: 0.165722; batch adversarial loss: 0.387028\n",
      "epoch 35; iter: 0; batch classifier loss: 0.169365; batch adversarial loss: 0.408912\n",
      "epoch 36; iter: 0; batch classifier loss: 0.135146; batch adversarial loss: 0.382095\n",
      "epoch 37; iter: 0; batch classifier loss: 0.133821; batch adversarial loss: 0.344026\n",
      "epoch 38; iter: 0; batch classifier loss: 0.124728; batch adversarial loss: 0.355820\n",
      "epoch 39; iter: 0; batch classifier loss: 0.157269; batch adversarial loss: 0.400495\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099167; batch adversarial loss: 0.383068\n",
      "epoch 41; iter: 0; batch classifier loss: 0.138051; batch adversarial loss: 0.452282\n",
      "epoch 42; iter: 0; batch classifier loss: 0.096993; batch adversarial loss: 0.367738\n",
      "epoch 43; iter: 0; batch classifier loss: 0.153769; batch adversarial loss: 0.425666\n",
      "epoch 44; iter: 0; batch classifier loss: 0.099207; batch adversarial loss: 0.324848\n",
      "epoch 45; iter: 0; batch classifier loss: 0.146546; batch adversarial loss: 0.364797\n",
      "epoch 46; iter: 0; batch classifier loss: 0.120316; batch adversarial loss: 0.433462\n",
      "epoch 47; iter: 0; batch classifier loss: 0.139634; batch adversarial loss: 0.466832\n",
      "epoch 48; iter: 0; batch classifier loss: 0.129387; batch adversarial loss: 0.461639\n",
      "epoch 49; iter: 0; batch classifier loss: 0.134149; batch adversarial loss: 0.486643\n",
      "epoch 50; iter: 0; batch classifier loss: 0.127879; batch adversarial loss: 0.397602\n",
      "epoch 51; iter: 0; batch classifier loss: 0.122754; batch adversarial loss: 0.428688\n",
      "epoch 52; iter: 0; batch classifier loss: 0.079518; batch adversarial loss: 0.333733\n",
      "epoch 53; iter: 0; batch classifier loss: 0.123316; batch adversarial loss: 0.384887\n",
      "epoch 54; iter: 0; batch classifier loss: 0.080867; batch adversarial loss: 0.421095\n",
      "epoch 55; iter: 0; batch classifier loss: 0.075530; batch adversarial loss: 0.413505\n",
      "epoch 56; iter: 0; batch classifier loss: 0.060643; batch adversarial loss: 0.418953\n",
      "epoch 57; iter: 0; batch classifier loss: 0.098111; batch adversarial loss: 0.333386\n",
      "epoch 58; iter: 0; batch classifier loss: 0.063414; batch adversarial loss: 0.374291\n",
      "epoch 59; iter: 0; batch classifier loss: 0.078260; batch adversarial loss: 0.353877\n",
      "epoch 60; iter: 0; batch classifier loss: 0.071607; batch adversarial loss: 0.457939\n",
      "epoch 61; iter: 0; batch classifier loss: 0.092614; batch adversarial loss: 0.443416\n",
      "epoch 62; iter: 0; batch classifier loss: 0.096041; batch adversarial loss: 0.415831\n",
      "epoch 63; iter: 0; batch classifier loss: 0.067363; batch adversarial loss: 0.391329\n",
      "epoch 64; iter: 0; batch classifier loss: 0.067511; batch adversarial loss: 0.398690\n",
      "epoch 65; iter: 0; batch classifier loss: 0.084362; batch adversarial loss: 0.379785\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091685; batch adversarial loss: 0.393006\n",
      "epoch 67; iter: 0; batch classifier loss: 0.090559; batch adversarial loss: 0.425513\n",
      "epoch 68; iter: 0; batch classifier loss: 0.086902; batch adversarial loss: 0.373126\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087854; batch adversarial loss: 0.412086\n",
      "epoch 70; iter: 0; batch classifier loss: 0.037651; batch adversarial loss: 0.442366\n",
      "epoch 71; iter: 0; batch classifier loss: 0.137588; batch adversarial loss: 0.446538\n",
      "epoch 72; iter: 0; batch classifier loss: 0.092825; batch adversarial loss: 0.442926\n",
      "epoch 73; iter: 0; batch classifier loss: 0.055191; batch adversarial loss: 0.479997\n",
      "epoch 74; iter: 0; batch classifier loss: 0.085118; batch adversarial loss: 0.491982\n",
      "epoch 75; iter: 0; batch classifier loss: 0.098317; batch adversarial loss: 0.444255\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058922; batch adversarial loss: 0.397779\n",
      "epoch 77; iter: 0; batch classifier loss: 0.053936; batch adversarial loss: 0.441525\n",
      "epoch 78; iter: 0; batch classifier loss: 0.070312; batch adversarial loss: 0.497594\n",
      "epoch 79; iter: 0; batch classifier loss: 0.042350; batch adversarial loss: 0.443575\n",
      "epoch 80; iter: 0; batch classifier loss: 0.110376; batch adversarial loss: 0.427591\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069163; batch adversarial loss: 0.407084\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091250; batch adversarial loss: 0.485280\n",
      "epoch 83; iter: 0; batch classifier loss: 0.091501; batch adversarial loss: 0.338581\n",
      "epoch 84; iter: 0; batch classifier loss: 0.119630; batch adversarial loss: 0.483829\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083864; batch adversarial loss: 0.387620\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069303; batch adversarial loss: 0.450233\n",
      "epoch 87; iter: 0; batch classifier loss: 0.063483; batch adversarial loss: 0.513291\n",
      "epoch 88; iter: 0; batch classifier loss: 0.066665; batch adversarial loss: 0.403562\n",
      "epoch 89; iter: 0; batch classifier loss: 0.071921; batch adversarial loss: 0.394371\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064940; batch adversarial loss: 0.418640\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055913; batch adversarial loss: 0.422722\n",
      "epoch 92; iter: 0; batch classifier loss: 0.047978; batch adversarial loss: 0.434755\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078888; batch adversarial loss: 0.405038\n",
      "epoch 94; iter: 0; batch classifier loss: 0.063187; batch adversarial loss: 0.320090\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070226; batch adversarial loss: 0.462508\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055507; batch adversarial loss: 0.370584\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042078; batch adversarial loss: 0.484383\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074619; batch adversarial loss: 0.470635\n",
      "epoch 99; iter: 0; batch classifier loss: 0.035708; batch adversarial loss: 0.385870\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046337; batch adversarial loss: 0.525112\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044496; batch adversarial loss: 0.450055\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042876; batch adversarial loss: 0.434130\n",
      "epoch 103; iter: 0; batch classifier loss: 0.051223; batch adversarial loss: 0.356690\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036390; batch adversarial loss: 0.502687\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050290; batch adversarial loss: 0.496290\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067234; batch adversarial loss: 0.450923\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039850; batch adversarial loss: 0.504526\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045135; batch adversarial loss: 0.423316\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062591; batch adversarial loss: 0.464468\n",
      "epoch 110; iter: 0; batch classifier loss: 0.080359; batch adversarial loss: 0.523491\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037143; batch adversarial loss: 0.393036\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042961; batch adversarial loss: 0.515234\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045366; batch adversarial loss: 0.416920\n",
      "epoch 114; iter: 0; batch classifier loss: 0.070420; batch adversarial loss: 0.532538\n",
      "epoch 115; iter: 0; batch classifier loss: 0.016333; batch adversarial loss: 0.448458\n",
      "epoch 116; iter: 0; batch classifier loss: 0.011318; batch adversarial loss: 0.435900\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047415; batch adversarial loss: 0.421737\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044325; batch adversarial loss: 0.474113\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039602; batch adversarial loss: 0.534511\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041803; batch adversarial loss: 0.563639\n",
      "epoch 121; iter: 0; batch classifier loss: 0.075828; batch adversarial loss: 0.489937\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049227; batch adversarial loss: 0.549233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.065976; batch adversarial loss: 0.628661\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050017; batch adversarial loss: 0.541098\n",
      "epoch 125; iter: 0; batch classifier loss: 0.094288; batch adversarial loss: 0.592110\n",
      "epoch 126; iter: 0; batch classifier loss: 0.136393; batch adversarial loss: 0.653636\n",
      "epoch 127; iter: 0; batch classifier loss: 0.086926; batch adversarial loss: 0.580415\n",
      "epoch 128; iter: 0; batch classifier loss: 0.123628; batch adversarial loss: 0.721229\n",
      "epoch 129; iter: 0; batch classifier loss: 0.072789; batch adversarial loss: 0.475752\n",
      "epoch 130; iter: 0; batch classifier loss: 0.074921; batch adversarial loss: 0.476092\n",
      "epoch 131; iter: 0; batch classifier loss: 0.131827; batch adversarial loss: 0.697089\n",
      "epoch 132; iter: 0; batch classifier loss: 0.140357; batch adversarial loss: 0.643462\n",
      "epoch 133; iter: 0; batch classifier loss: 0.163869; batch adversarial loss: 0.628571\n",
      "epoch 134; iter: 0; batch classifier loss: 0.105758; batch adversarial loss: 0.509399\n",
      "epoch 135; iter: 0; batch classifier loss: 0.119634; batch adversarial loss: 0.487149\n",
      "epoch 136; iter: 0; batch classifier loss: 0.102771; batch adversarial loss: 0.522920\n",
      "epoch 137; iter: 0; batch classifier loss: 0.146857; batch adversarial loss: 0.580444\n",
      "epoch 138; iter: 0; batch classifier loss: 0.168115; batch adversarial loss: 0.544286\n",
      "epoch 139; iter: 0; batch classifier loss: 0.174123; batch adversarial loss: 0.673932\n",
      "epoch 140; iter: 0; batch classifier loss: 0.161615; batch adversarial loss: 0.640496\n",
      "epoch 141; iter: 0; batch classifier loss: 0.217592; batch adversarial loss: 0.570984\n",
      "epoch 142; iter: 0; batch classifier loss: 0.200138; batch adversarial loss: 0.511842\n",
      "epoch 143; iter: 0; batch classifier loss: 0.184307; batch adversarial loss: 0.649500\n",
      "epoch 144; iter: 0; batch classifier loss: 0.134813; batch adversarial loss: 0.539932\n",
      "epoch 145; iter: 0; batch classifier loss: 0.160204; batch adversarial loss: 0.523489\n",
      "epoch 146; iter: 0; batch classifier loss: 0.161682; batch adversarial loss: 0.527629\n",
      "epoch 147; iter: 0; batch classifier loss: 0.138627; batch adversarial loss: 0.455995\n",
      "epoch 148; iter: 0; batch classifier loss: 0.108336; batch adversarial loss: 0.458564\n",
      "epoch 149; iter: 0; batch classifier loss: 0.095850; batch adversarial loss: 0.451756\n",
      "epoch 150; iter: 0; batch classifier loss: 0.108706; batch adversarial loss: 0.444753\n",
      "epoch 151; iter: 0; batch classifier loss: 0.144947; batch adversarial loss: 0.511662\n",
      "epoch 152; iter: 0; batch classifier loss: 0.094448; batch adversarial loss: 0.474229\n",
      "epoch 153; iter: 0; batch classifier loss: 0.064098; batch adversarial loss: 0.460492\n",
      "epoch 154; iter: 0; batch classifier loss: 0.116387; batch adversarial loss: 0.515114\n",
      "epoch 155; iter: 0; batch classifier loss: 0.078880; batch adversarial loss: 0.430774\n",
      "epoch 156; iter: 0; batch classifier loss: 0.089046; batch adversarial loss: 0.429737\n",
      "epoch 157; iter: 0; batch classifier loss: 0.127096; batch adversarial loss: 0.543596\n",
      "epoch 158; iter: 0; batch classifier loss: 0.092331; batch adversarial loss: 0.402286\n",
      "epoch 159; iter: 0; batch classifier loss: 0.104817; batch adversarial loss: 0.451815\n",
      "epoch 160; iter: 0; batch classifier loss: 0.163074; batch adversarial loss: 0.497644\n",
      "epoch 161; iter: 0; batch classifier loss: 0.115121; batch adversarial loss: 0.495025\n",
      "epoch 162; iter: 0; batch classifier loss: 0.062093; batch adversarial loss: 0.411698\n",
      "epoch 163; iter: 0; batch classifier loss: 0.044256; batch adversarial loss: 0.537357\n",
      "epoch 164; iter: 0; batch classifier loss: 0.047721; batch adversarial loss: 0.480129\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035473; batch adversarial loss: 0.506640\n",
      "epoch 166; iter: 0; batch classifier loss: 0.042727; batch adversarial loss: 0.423592\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041570; batch adversarial loss: 0.404359\n",
      "epoch 168; iter: 0; batch classifier loss: 0.044742; batch adversarial loss: 0.483694\n",
      "epoch 169; iter: 0; batch classifier loss: 0.057539; batch adversarial loss: 0.558597\n",
      "epoch 170; iter: 0; batch classifier loss: 0.043820; batch adversarial loss: 0.401502\n",
      "epoch 171; iter: 0; batch classifier loss: 0.048450; batch adversarial loss: 0.539957\n",
      "epoch 172; iter: 0; batch classifier loss: 0.053113; batch adversarial loss: 0.453493\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017026; batch adversarial loss: 0.480409\n",
      "epoch 174; iter: 0; batch classifier loss: 0.064190; batch adversarial loss: 0.353677\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029437; batch adversarial loss: 0.416508\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034897; batch adversarial loss: 0.426258\n",
      "epoch 177; iter: 0; batch classifier loss: 0.052865; batch adversarial loss: 0.457664\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029780; batch adversarial loss: 0.409547\n",
      "epoch 179; iter: 0; batch classifier loss: 0.052279; batch adversarial loss: 0.445100\n",
      "epoch 180; iter: 0; batch classifier loss: 0.057804; batch adversarial loss: 0.341719\n",
      "epoch 181; iter: 0; batch classifier loss: 0.070796; batch adversarial loss: 0.384260\n",
      "epoch 182; iter: 0; batch classifier loss: 0.052682; batch adversarial loss: 0.367622\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042353; batch adversarial loss: 0.453216\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027545; batch adversarial loss: 0.416744\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038918; batch adversarial loss: 0.454035\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024759; batch adversarial loss: 0.398302\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042037; batch adversarial loss: 0.450349\n",
      "epoch 188; iter: 0; batch classifier loss: 0.042004; batch adversarial loss: 0.523034\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028760; batch adversarial loss: 0.449512\n",
      "epoch 190; iter: 0; batch classifier loss: 0.075419; batch adversarial loss: 0.491006\n",
      "epoch 191; iter: 0; batch classifier loss: 0.053568; batch adversarial loss: 0.460366\n",
      "epoch 192; iter: 0; batch classifier loss: 0.054172; batch adversarial loss: 0.467001\n",
      "epoch 193; iter: 0; batch classifier loss: 0.056047; batch adversarial loss: 0.455356\n",
      "epoch 194; iter: 0; batch classifier loss: 0.083732; batch adversarial loss: 0.456995\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031161; batch adversarial loss: 0.399721\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016122; batch adversarial loss: 0.449628\n",
      "epoch 197; iter: 0; batch classifier loss: 0.064884; batch adversarial loss: 0.450250\n",
      "epoch 198; iter: 0; batch classifier loss: 0.049835; batch adversarial loss: 0.358136\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030956; batch adversarial loss: 0.461932\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695449; batch adversarial loss: 0.800560\n",
      "epoch 1; iter: 0; batch classifier loss: 0.429230; batch adversarial loss: 0.753117\n",
      "epoch 2; iter: 0; batch classifier loss: 0.311192; batch adversarial loss: 0.715852\n",
      "epoch 3; iter: 0; batch classifier loss: 0.339145; batch adversarial loss: 0.671032\n",
      "epoch 4; iter: 0; batch classifier loss: 0.375892; batch adversarial loss: 0.632270\n",
      "epoch 5; iter: 0; batch classifier loss: 0.404458; batch adversarial loss: 0.604941\n",
      "epoch 6; iter: 0; batch classifier loss: 0.337692; batch adversarial loss: 0.575862\n",
      "epoch 7; iter: 0; batch classifier loss: 0.255167; batch adversarial loss: 0.552416\n",
      "epoch 8; iter: 0; batch classifier loss: 0.354417; batch adversarial loss: 0.533554\n",
      "epoch 9; iter: 0; batch classifier loss: 0.236772; batch adversarial loss: 0.517820\n",
      "epoch 10; iter: 0; batch classifier loss: 0.217130; batch adversarial loss: 0.522991\n",
      "epoch 11; iter: 0; batch classifier loss: 0.189619; batch adversarial loss: 0.513546\n",
      "epoch 12; iter: 0; batch classifier loss: 0.236276; batch adversarial loss: 0.486885\n",
      "epoch 13; iter: 0; batch classifier loss: 0.260191; batch adversarial loss: 0.453797\n",
      "epoch 14; iter: 0; batch classifier loss: 0.214257; batch adversarial loss: 0.467215\n",
      "epoch 15; iter: 0; batch classifier loss: 0.159792; batch adversarial loss: 0.480404\n",
      "epoch 16; iter: 0; batch classifier loss: 0.212895; batch adversarial loss: 0.490428\n",
      "epoch 17; iter: 0; batch classifier loss: 0.201628; batch adversarial loss: 0.443871\n",
      "epoch 18; iter: 0; batch classifier loss: 0.155024; batch adversarial loss: 0.524646\n",
      "epoch 19; iter: 0; batch classifier loss: 0.238329; batch adversarial loss: 0.416308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.158423; batch adversarial loss: 0.444215\n",
      "epoch 21; iter: 0; batch classifier loss: 0.213108; batch adversarial loss: 0.454245\n",
      "epoch 22; iter: 0; batch classifier loss: 0.141068; batch adversarial loss: 0.427477\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168075; batch adversarial loss: 0.419220\n",
      "epoch 24; iter: 0; batch classifier loss: 0.179199; batch adversarial loss: 0.407195\n",
      "epoch 25; iter: 0; batch classifier loss: 0.181538; batch adversarial loss: 0.403362\n",
      "epoch 26; iter: 0; batch classifier loss: 0.158806; batch adversarial loss: 0.426434\n",
      "epoch 27; iter: 0; batch classifier loss: 0.170533; batch adversarial loss: 0.492366\n",
      "epoch 28; iter: 0; batch classifier loss: 0.146825; batch adversarial loss: 0.451719\n",
      "epoch 29; iter: 0; batch classifier loss: 0.152117; batch adversarial loss: 0.402379\n",
      "epoch 30; iter: 0; batch classifier loss: 0.179182; batch adversarial loss: 0.418259\n",
      "epoch 31; iter: 0; batch classifier loss: 0.136543; batch adversarial loss: 0.356710\n",
      "epoch 32; iter: 0; batch classifier loss: 0.198802; batch adversarial loss: 0.400792\n",
      "epoch 33; iter: 0; batch classifier loss: 0.164868; batch adversarial loss: 0.445063\n",
      "epoch 34; iter: 0; batch classifier loss: 0.130825; batch adversarial loss: 0.396966\n",
      "epoch 35; iter: 0; batch classifier loss: 0.152186; batch adversarial loss: 0.445167\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128564; batch adversarial loss: 0.385555\n",
      "epoch 37; iter: 0; batch classifier loss: 0.137085; batch adversarial loss: 0.335309\n",
      "epoch 38; iter: 0; batch classifier loss: 0.142736; batch adversarial loss: 0.507516\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106031; batch adversarial loss: 0.480645\n",
      "epoch 40; iter: 0; batch classifier loss: 0.080941; batch adversarial loss: 0.314239\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125514; batch adversarial loss: 0.350933\n",
      "epoch 42; iter: 0; batch classifier loss: 0.185795; batch adversarial loss: 0.413859\n",
      "epoch 43; iter: 0; batch classifier loss: 0.140632; batch adversarial loss: 0.329988\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136907; batch adversarial loss: 0.376223\n",
      "epoch 45; iter: 0; batch classifier loss: 0.122112; batch adversarial loss: 0.431585\n",
      "epoch 46; iter: 0; batch classifier loss: 0.133032; batch adversarial loss: 0.360610\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100767; batch adversarial loss: 0.484976\n",
      "epoch 48; iter: 0; batch classifier loss: 0.157976; batch adversarial loss: 0.462539\n",
      "epoch 49; iter: 0; batch classifier loss: 0.127223; batch adversarial loss: 0.513207\n",
      "epoch 50; iter: 0; batch classifier loss: 0.133260; batch adversarial loss: 0.474158\n",
      "epoch 51; iter: 0; batch classifier loss: 0.088599; batch adversarial loss: 0.435721\n",
      "epoch 52; iter: 0; batch classifier loss: 0.123701; batch adversarial loss: 0.400968\n",
      "epoch 53; iter: 0; batch classifier loss: 0.063447; batch adversarial loss: 0.447336\n",
      "epoch 54; iter: 0; batch classifier loss: 0.060927; batch adversarial loss: 0.402965\n",
      "epoch 55; iter: 0; batch classifier loss: 0.101084; batch adversarial loss: 0.364105\n",
      "epoch 56; iter: 0; batch classifier loss: 0.090166; batch adversarial loss: 0.437580\n",
      "epoch 57; iter: 0; batch classifier loss: 0.077971; batch adversarial loss: 0.541672\n",
      "epoch 58; iter: 0; batch classifier loss: 0.043707; batch adversarial loss: 0.379828\n",
      "epoch 59; iter: 0; batch classifier loss: 0.089274; batch adversarial loss: 0.406810\n",
      "epoch 60; iter: 0; batch classifier loss: 0.054980; batch adversarial loss: 0.389690\n",
      "epoch 61; iter: 0; batch classifier loss: 0.083377; batch adversarial loss: 0.444180\n",
      "epoch 62; iter: 0; batch classifier loss: 0.072917; batch adversarial loss: 0.413824\n",
      "epoch 63; iter: 0; batch classifier loss: 0.135706; batch adversarial loss: 0.380206\n",
      "epoch 64; iter: 0; batch classifier loss: 0.087636; batch adversarial loss: 0.425502\n",
      "epoch 65; iter: 0; batch classifier loss: 0.086943; batch adversarial loss: 0.439708\n",
      "epoch 66; iter: 0; batch classifier loss: 0.071604; batch adversarial loss: 0.323719\n",
      "epoch 67; iter: 0; batch classifier loss: 0.098447; batch adversarial loss: 0.443877\n",
      "epoch 68; iter: 0; batch classifier loss: 0.104550; batch adversarial loss: 0.470432\n",
      "epoch 69; iter: 0; batch classifier loss: 0.043016; batch adversarial loss: 0.405362\n",
      "epoch 70; iter: 0; batch classifier loss: 0.091887; batch adversarial loss: 0.416592\n",
      "epoch 71; iter: 0; batch classifier loss: 0.112031; batch adversarial loss: 0.464623\n",
      "epoch 72; iter: 0; batch classifier loss: 0.147630; batch adversarial loss: 0.441699\n",
      "epoch 73; iter: 0; batch classifier loss: 0.043442; batch adversarial loss: 0.410381\n",
      "epoch 74; iter: 0; batch classifier loss: 0.058796; batch adversarial loss: 0.444840\n",
      "epoch 75; iter: 0; batch classifier loss: 0.065583; batch adversarial loss: 0.432872\n",
      "epoch 76; iter: 0; batch classifier loss: 0.071912; batch adversarial loss: 0.468638\n",
      "epoch 77; iter: 0; batch classifier loss: 0.042349; batch adversarial loss: 0.374763\n",
      "epoch 78; iter: 0; batch classifier loss: 0.076168; batch adversarial loss: 0.406824\n",
      "epoch 79; iter: 0; batch classifier loss: 0.059661; batch adversarial loss: 0.402672\n",
      "epoch 80; iter: 0; batch classifier loss: 0.030918; batch adversarial loss: 0.466328\n",
      "epoch 81; iter: 0; batch classifier loss: 0.094716; batch adversarial loss: 0.468947\n",
      "epoch 82; iter: 0; batch classifier loss: 0.078918; batch adversarial loss: 0.472395\n",
      "epoch 83; iter: 0; batch classifier loss: 0.073511; batch adversarial loss: 0.462499\n",
      "epoch 84; iter: 0; batch classifier loss: 0.083851; batch adversarial loss: 0.427989\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070961; batch adversarial loss: 0.382569\n",
      "epoch 86; iter: 0; batch classifier loss: 0.049623; batch adversarial loss: 0.449194\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056327; batch adversarial loss: 0.469772\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073132; batch adversarial loss: 0.528698\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042432; batch adversarial loss: 0.424124\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064899; batch adversarial loss: 0.432659\n",
      "epoch 91; iter: 0; batch classifier loss: 0.099116; batch adversarial loss: 0.403093\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063542; batch adversarial loss: 0.363693\n",
      "epoch 93; iter: 0; batch classifier loss: 0.082006; batch adversarial loss: 0.361135\n",
      "epoch 94; iter: 0; batch classifier loss: 0.040425; batch adversarial loss: 0.441776\n",
      "epoch 95; iter: 0; batch classifier loss: 0.089657; batch adversarial loss: 0.347459\n",
      "epoch 96; iter: 0; batch classifier loss: 0.102685; batch adversarial loss: 0.434975\n",
      "epoch 97; iter: 0; batch classifier loss: 0.067109; batch adversarial loss: 0.424398\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072780; batch adversarial loss: 0.462378\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063725; batch adversarial loss: 0.407461\n",
      "epoch 100; iter: 0; batch classifier loss: 0.081763; batch adversarial loss: 0.330486\n",
      "epoch 101; iter: 0; batch classifier loss: 0.053215; batch adversarial loss: 0.367805\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047240; batch adversarial loss: 0.369837\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048312; batch adversarial loss: 0.367902\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050693; batch adversarial loss: 0.423365\n",
      "epoch 105; iter: 0; batch classifier loss: 0.079043; batch adversarial loss: 0.487750\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059565; batch adversarial loss: 0.379305\n",
      "epoch 107; iter: 0; batch classifier loss: 0.078063; batch adversarial loss: 0.419720\n",
      "epoch 108; iter: 0; batch classifier loss: 0.063210; batch adversarial loss: 0.440339\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044343; batch adversarial loss: 0.403830\n",
      "epoch 110; iter: 0; batch classifier loss: 0.075104; batch adversarial loss: 0.536359\n",
      "epoch 111; iter: 0; batch classifier loss: 0.074292; batch adversarial loss: 0.472000\n",
      "epoch 112; iter: 0; batch classifier loss: 0.032167; batch adversarial loss: 0.438083\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048954; batch adversarial loss: 0.395942\n",
      "epoch 114; iter: 0; batch classifier loss: 0.085150; batch adversarial loss: 0.504501\n",
      "epoch 115; iter: 0; batch classifier loss: 0.055031; batch adversarial loss: 0.344110\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036532; batch adversarial loss: 0.405508\n",
      "epoch 117; iter: 0; batch classifier loss: 0.113835; batch adversarial loss: 0.505781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.090340; batch adversarial loss: 0.398662\n",
      "epoch 119; iter: 0; batch classifier loss: 0.063404; batch adversarial loss: 0.378517\n",
      "epoch 120; iter: 0; batch classifier loss: 0.052682; batch adversarial loss: 0.436879\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060737; batch adversarial loss: 0.495991\n",
      "epoch 122; iter: 0; batch classifier loss: 0.076303; batch adversarial loss: 0.378626\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036169; batch adversarial loss: 0.391355\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052011; batch adversarial loss: 0.424439\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049948; batch adversarial loss: 0.443043\n",
      "epoch 126; iter: 0; batch classifier loss: 0.049678; batch adversarial loss: 0.488205\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043208; batch adversarial loss: 0.435623\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053987; batch adversarial loss: 0.448712\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037170; batch adversarial loss: 0.452127\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035665; batch adversarial loss: 0.384350\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051175; batch adversarial loss: 0.517786\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045920; batch adversarial loss: 0.363622\n",
      "epoch 133; iter: 0; batch classifier loss: 0.048113; batch adversarial loss: 0.553083\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029917; batch adversarial loss: 0.431629\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047809; batch adversarial loss: 0.441120\n",
      "epoch 136; iter: 0; batch classifier loss: 0.053317; batch adversarial loss: 0.512833\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037718; batch adversarial loss: 0.433929\n",
      "epoch 138; iter: 0; batch classifier loss: 0.066821; batch adversarial loss: 0.539974\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037697; batch adversarial loss: 0.398020\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046648; batch adversarial loss: 0.385152\n",
      "epoch 141; iter: 0; batch classifier loss: 0.055159; batch adversarial loss: 0.434317\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041183; batch adversarial loss: 0.399412\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029442; batch adversarial loss: 0.410047\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039385; batch adversarial loss: 0.407804\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028626; batch adversarial loss: 0.465765\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032085; batch adversarial loss: 0.350273\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030698; batch adversarial loss: 0.423079\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028917; batch adversarial loss: 0.470407\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044074; batch adversarial loss: 0.481366\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038322; batch adversarial loss: 0.437057\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033664; batch adversarial loss: 0.487610\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024692; batch adversarial loss: 0.485934\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028261; batch adversarial loss: 0.409193\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025842; batch adversarial loss: 0.443509\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041161; batch adversarial loss: 0.494018\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016966; batch adversarial loss: 0.403124\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034322; batch adversarial loss: 0.426879\n",
      "epoch 158; iter: 0; batch classifier loss: 0.057875; batch adversarial loss: 0.475860\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040530; batch adversarial loss: 0.410652\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024153; batch adversarial loss: 0.420380\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024303; batch adversarial loss: 0.384105\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012095; batch adversarial loss: 0.520289\n",
      "epoch 163; iter: 0; batch classifier loss: 0.073894; batch adversarial loss: 0.374523\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037862; batch adversarial loss: 0.422577\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029498; batch adversarial loss: 0.603595\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015408; batch adversarial loss: 0.392267\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025669; batch adversarial loss: 0.487985\n",
      "epoch 168; iter: 0; batch classifier loss: 0.055778; batch adversarial loss: 0.578788\n",
      "epoch 169; iter: 0; batch classifier loss: 0.059286; batch adversarial loss: 0.361423\n",
      "epoch 170; iter: 0; batch classifier loss: 0.113723; batch adversarial loss: 0.714238\n",
      "epoch 171; iter: 0; batch classifier loss: 0.044296; batch adversarial loss: 0.450545\n",
      "epoch 172; iter: 0; batch classifier loss: 0.119505; batch adversarial loss: 0.628653\n",
      "epoch 173; iter: 0; batch classifier loss: 0.100072; batch adversarial loss: 0.614731\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022829; batch adversarial loss: 0.353216\n",
      "epoch 175; iter: 0; batch classifier loss: 0.145068; batch adversarial loss: 0.742744\n",
      "epoch 176; iter: 0; batch classifier loss: 0.116580; batch adversarial loss: 0.593862\n",
      "epoch 177; iter: 0; batch classifier loss: 0.149912; batch adversarial loss: 0.623720\n",
      "epoch 178; iter: 0; batch classifier loss: 0.162905; batch adversarial loss: 0.704805\n",
      "epoch 179; iter: 0; batch classifier loss: 0.183661; batch adversarial loss: 0.718490\n",
      "epoch 180; iter: 0; batch classifier loss: 0.197111; batch adversarial loss: 0.763957\n",
      "epoch 181; iter: 0; batch classifier loss: 0.119691; batch adversarial loss: 0.587975\n",
      "epoch 182; iter: 0; batch classifier loss: 0.190793; batch adversarial loss: 0.785622\n",
      "epoch 183; iter: 0; batch classifier loss: 0.240313; batch adversarial loss: 0.905783\n",
      "epoch 184; iter: 0; batch classifier loss: 0.201738; batch adversarial loss: 0.736917\n",
      "epoch 185; iter: 0; batch classifier loss: 0.160106; batch adversarial loss: 0.646054\n",
      "epoch 186; iter: 0; batch classifier loss: 0.131891; batch adversarial loss: 0.619157\n",
      "epoch 187; iter: 0; batch classifier loss: 0.184633; batch adversarial loss: 0.577222\n",
      "epoch 188; iter: 0; batch classifier loss: 0.119593; batch adversarial loss: 0.615158\n",
      "epoch 189; iter: 0; batch classifier loss: 0.248070; batch adversarial loss: 0.692370\n",
      "epoch 190; iter: 0; batch classifier loss: 0.185981; batch adversarial loss: 0.621849\n",
      "epoch 191; iter: 0; batch classifier loss: 0.234225; batch adversarial loss: 0.627646\n",
      "epoch 192; iter: 0; batch classifier loss: 0.149139; batch adversarial loss: 0.648889\n",
      "epoch 193; iter: 0; batch classifier loss: 0.210460; batch adversarial loss: 0.670420\n",
      "epoch 194; iter: 0; batch classifier loss: 0.279738; batch adversarial loss: 0.847728\n",
      "epoch 195; iter: 0; batch classifier loss: 0.238705; batch adversarial loss: 0.741947\n",
      "epoch 196; iter: 0; batch classifier loss: 0.176415; batch adversarial loss: 0.574254\n",
      "epoch 197; iter: 0; batch classifier loss: 0.131890; batch adversarial loss: 0.545952\n",
      "epoch 198; iter: 0; batch classifier loss: 0.139052; batch adversarial loss: 0.605995\n",
      "epoch 199; iter: 0; batch classifier loss: 0.227641; batch adversarial loss: 0.728789\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706630; batch adversarial loss: 0.628331\n",
      "epoch 1; iter: 0; batch classifier loss: 0.420843; batch adversarial loss: 0.599332\n",
      "epoch 2; iter: 0; batch classifier loss: 0.446325; batch adversarial loss: 0.642897\n",
      "epoch 3; iter: 0; batch classifier loss: 0.464152; batch adversarial loss: 0.590394\n",
      "epoch 4; iter: 0; batch classifier loss: 0.501809; batch adversarial loss: 0.579927\n",
      "epoch 5; iter: 0; batch classifier loss: 0.392719; batch adversarial loss: 0.593880\n",
      "epoch 6; iter: 0; batch classifier loss: 0.447835; batch adversarial loss: 0.529995\n",
      "epoch 7; iter: 0; batch classifier loss: 0.452805; batch adversarial loss: 0.571460\n",
      "epoch 8; iter: 0; batch classifier loss: 0.468289; batch adversarial loss: 0.557190\n",
      "epoch 9; iter: 0; batch classifier loss: 0.383074; batch adversarial loss: 0.575240\n",
      "epoch 10; iter: 0; batch classifier loss: 0.398969; batch adversarial loss: 0.520425\n",
      "epoch 11; iter: 0; batch classifier loss: 0.331422; batch adversarial loss: 0.452272\n",
      "epoch 12; iter: 0; batch classifier loss: 0.295373; batch adversarial loss: 0.502759\n",
      "epoch 13; iter: 0; batch classifier loss: 0.306059; batch adversarial loss: 0.578856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.256182; batch adversarial loss: 0.561000\n",
      "epoch 15; iter: 0; batch classifier loss: 0.311953; batch adversarial loss: 0.476750\n",
      "epoch 16; iter: 0; batch classifier loss: 0.240584; batch adversarial loss: 0.498448\n",
      "epoch 17; iter: 0; batch classifier loss: 0.292022; batch adversarial loss: 0.465671\n",
      "epoch 18; iter: 0; batch classifier loss: 0.264112; batch adversarial loss: 0.488897\n",
      "epoch 19; iter: 0; batch classifier loss: 0.272459; batch adversarial loss: 0.466898\n",
      "epoch 20; iter: 0; batch classifier loss: 0.194757; batch adversarial loss: 0.476513\n",
      "epoch 21; iter: 0; batch classifier loss: 0.224574; batch adversarial loss: 0.523038\n",
      "epoch 22; iter: 0; batch classifier loss: 0.238105; batch adversarial loss: 0.557817\n",
      "epoch 23; iter: 0; batch classifier loss: 0.251218; batch adversarial loss: 0.539065\n",
      "epoch 24; iter: 0; batch classifier loss: 0.190317; batch adversarial loss: 0.446217\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179462; batch adversarial loss: 0.489210\n",
      "epoch 26; iter: 0; batch classifier loss: 0.217281; batch adversarial loss: 0.424060\n",
      "epoch 27; iter: 0; batch classifier loss: 0.137321; batch adversarial loss: 0.442685\n",
      "epoch 28; iter: 0; batch classifier loss: 0.122888; batch adversarial loss: 0.477765\n",
      "epoch 29; iter: 0; batch classifier loss: 0.205272; batch adversarial loss: 0.414873\n",
      "epoch 30; iter: 0; batch classifier loss: 0.184099; batch adversarial loss: 0.460533\n",
      "epoch 31; iter: 0; batch classifier loss: 0.187255; batch adversarial loss: 0.443187\n",
      "epoch 32; iter: 0; batch classifier loss: 0.156890; batch adversarial loss: 0.453994\n",
      "epoch 33; iter: 0; batch classifier loss: 0.134171; batch adversarial loss: 0.564044\n",
      "epoch 34; iter: 0; batch classifier loss: 0.103347; batch adversarial loss: 0.535521\n",
      "epoch 35; iter: 0; batch classifier loss: 0.156255; batch adversarial loss: 0.455687\n",
      "epoch 36; iter: 0; batch classifier loss: 0.169821; batch adversarial loss: 0.529463\n",
      "epoch 37; iter: 0; batch classifier loss: 0.159652; batch adversarial loss: 0.412887\n",
      "epoch 38; iter: 0; batch classifier loss: 0.110636; batch adversarial loss: 0.539261\n",
      "epoch 39; iter: 0; batch classifier loss: 0.173996; batch adversarial loss: 0.462043\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116848; batch adversarial loss: 0.476579\n",
      "epoch 41; iter: 0; batch classifier loss: 0.184687; batch adversarial loss: 0.440239\n",
      "epoch 42; iter: 0; batch classifier loss: 0.148824; batch adversarial loss: 0.473916\n",
      "epoch 43; iter: 0; batch classifier loss: 0.071926; batch adversarial loss: 0.473484\n",
      "epoch 44; iter: 0; batch classifier loss: 0.114451; batch adversarial loss: 0.444614\n",
      "epoch 45; iter: 0; batch classifier loss: 0.132215; batch adversarial loss: 0.470752\n",
      "epoch 46; iter: 0; batch classifier loss: 0.083127; batch adversarial loss: 0.555195\n",
      "epoch 47; iter: 0; batch classifier loss: 0.108993; batch adversarial loss: 0.485307\n",
      "epoch 48; iter: 0; batch classifier loss: 0.111584; batch adversarial loss: 0.430929\n",
      "epoch 49; iter: 0; batch classifier loss: 0.070751; batch adversarial loss: 0.529846\n",
      "epoch 50; iter: 0; batch classifier loss: 0.130323; batch adversarial loss: 0.416832\n",
      "epoch 51; iter: 0; batch classifier loss: 0.105288; batch adversarial loss: 0.384715\n",
      "epoch 52; iter: 0; batch classifier loss: 0.135706; batch adversarial loss: 0.546013\n",
      "epoch 53; iter: 0; batch classifier loss: 0.159863; batch adversarial loss: 0.427606\n",
      "epoch 54; iter: 0; batch classifier loss: 0.129424; batch adversarial loss: 0.477561\n",
      "epoch 55; iter: 0; batch classifier loss: 0.154891; batch adversarial loss: 0.526464\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081057; batch adversarial loss: 0.511322\n",
      "epoch 57; iter: 0; batch classifier loss: 0.118132; batch adversarial loss: 0.448831\n",
      "epoch 58; iter: 0; batch classifier loss: 0.098638; batch adversarial loss: 0.440550\n",
      "epoch 59; iter: 0; batch classifier loss: 0.118257; batch adversarial loss: 0.469430\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081130; batch adversarial loss: 0.409753\n",
      "epoch 61; iter: 0; batch classifier loss: 0.095679; batch adversarial loss: 0.378210\n",
      "epoch 62; iter: 0; batch classifier loss: 0.110677; batch adversarial loss: 0.457096\n",
      "epoch 63; iter: 0; batch classifier loss: 0.075515; batch adversarial loss: 0.494396\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073533; batch adversarial loss: 0.395764\n",
      "epoch 65; iter: 0; batch classifier loss: 0.104781; batch adversarial loss: 0.455323\n",
      "epoch 66; iter: 0; batch classifier loss: 0.095944; batch adversarial loss: 0.480951\n",
      "epoch 67; iter: 0; batch classifier loss: 0.087427; batch adversarial loss: 0.527705\n",
      "epoch 68; iter: 0; batch classifier loss: 0.133889; batch adversarial loss: 0.455048\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094176; batch adversarial loss: 0.377132\n",
      "epoch 70; iter: 0; batch classifier loss: 0.100054; batch adversarial loss: 0.423245\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092396; batch adversarial loss: 0.429652\n",
      "epoch 72; iter: 0; batch classifier loss: 0.045475; batch adversarial loss: 0.488875\n",
      "epoch 73; iter: 0; batch classifier loss: 0.102488; batch adversarial loss: 0.380979\n",
      "epoch 74; iter: 0; batch classifier loss: 0.074814; batch adversarial loss: 0.505093\n",
      "epoch 75; iter: 0; batch classifier loss: 0.108372; batch adversarial loss: 0.572977\n",
      "epoch 76; iter: 0; batch classifier loss: 0.077566; batch adversarial loss: 0.477059\n",
      "epoch 77; iter: 0; batch classifier loss: 0.081173; batch adversarial loss: 0.466751\n",
      "epoch 78; iter: 0; batch classifier loss: 0.065814; batch adversarial loss: 0.488531\n",
      "epoch 79; iter: 0; batch classifier loss: 0.109587; batch adversarial loss: 0.468575\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075305; batch adversarial loss: 0.437964\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055594; batch adversarial loss: 0.421049\n",
      "epoch 82; iter: 0; batch classifier loss: 0.037669; batch adversarial loss: 0.452962\n",
      "epoch 83; iter: 0; batch classifier loss: 0.104632; batch adversarial loss: 0.459033\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085037; batch adversarial loss: 0.482198\n",
      "epoch 85; iter: 0; batch classifier loss: 0.041913; batch adversarial loss: 0.452214\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083975; batch adversarial loss: 0.436961\n",
      "epoch 87; iter: 0; batch classifier loss: 0.084676; batch adversarial loss: 0.508787\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041853; batch adversarial loss: 0.429248\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052234; batch adversarial loss: 0.400489\n",
      "epoch 90; iter: 0; batch classifier loss: 0.091769; batch adversarial loss: 0.527730\n",
      "epoch 91; iter: 0; batch classifier loss: 0.058952; batch adversarial loss: 0.483822\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050363; batch adversarial loss: 0.465150\n",
      "epoch 93; iter: 0; batch classifier loss: 0.057361; batch adversarial loss: 0.412888\n",
      "epoch 94; iter: 0; batch classifier loss: 0.103541; batch adversarial loss: 0.522209\n",
      "epoch 95; iter: 0; batch classifier loss: 0.028451; batch adversarial loss: 0.376910\n",
      "epoch 96; iter: 0; batch classifier loss: 0.069563; batch adversarial loss: 0.488708\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055210; batch adversarial loss: 0.485765\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074250; batch adversarial loss: 0.469630\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043178; batch adversarial loss: 0.358593\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039138; batch adversarial loss: 0.461778\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048292; batch adversarial loss: 0.349057\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048230; batch adversarial loss: 0.377202\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057473; batch adversarial loss: 0.458719\n",
      "epoch 104; iter: 0; batch classifier loss: 0.080647; batch adversarial loss: 0.464360\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041485; batch adversarial loss: 0.565242\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044906; batch adversarial loss: 0.503468\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044418; batch adversarial loss: 0.407330\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057271; batch adversarial loss: 0.497653\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029627; batch adversarial loss: 0.512624\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044147; batch adversarial loss: 0.511379\n",
      "epoch 111; iter: 0; batch classifier loss: 0.056442; batch adversarial loss: 0.449278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.043973; batch adversarial loss: 0.575331\n",
      "epoch 113; iter: 0; batch classifier loss: 0.075547; batch adversarial loss: 0.455605\n",
      "epoch 114; iter: 0; batch classifier loss: 0.091538; batch adversarial loss: 0.419642\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050299; batch adversarial loss: 0.464069\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027703; batch adversarial loss: 0.420707\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039093; batch adversarial loss: 0.459987\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052252; batch adversarial loss: 0.477013\n",
      "epoch 119; iter: 0; batch classifier loss: 0.018647; batch adversarial loss: 0.421784\n",
      "epoch 120; iter: 0; batch classifier loss: 0.058080; batch adversarial loss: 0.450858\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034042; batch adversarial loss: 0.457223\n",
      "epoch 122; iter: 0; batch classifier loss: 0.022125; batch adversarial loss: 0.504453\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026858; batch adversarial loss: 0.400015\n",
      "epoch 124; iter: 0; batch classifier loss: 0.034263; batch adversarial loss: 0.405564\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046872; batch adversarial loss: 0.433608\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037942; batch adversarial loss: 0.404636\n",
      "epoch 127; iter: 0; batch classifier loss: 0.057350; batch adversarial loss: 0.463865\n",
      "epoch 128; iter: 0; batch classifier loss: 0.016660; batch adversarial loss: 0.538802\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028475; batch adversarial loss: 0.423388\n",
      "epoch 130; iter: 0; batch classifier loss: 0.010227; batch adversarial loss: 0.539107\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034528; batch adversarial loss: 0.487200\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038131; batch adversarial loss: 0.584862\n",
      "epoch 133; iter: 0; batch classifier loss: 0.072882; batch adversarial loss: 0.358458\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015684; batch adversarial loss: 0.501920\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028270; batch adversarial loss: 0.577224\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031365; batch adversarial loss: 0.513972\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038983; batch adversarial loss: 0.487100\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027724; batch adversarial loss: 0.482870\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038652; batch adversarial loss: 0.435195\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038611; batch adversarial loss: 0.447143\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031685; batch adversarial loss: 0.382978\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020695; batch adversarial loss: 0.543328\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023280; batch adversarial loss: 0.371085\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024340; batch adversarial loss: 0.472553\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026431; batch adversarial loss: 0.473768\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019183; batch adversarial loss: 0.526956\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017099; batch adversarial loss: 0.422077\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026023; batch adversarial loss: 0.519455\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039260; batch adversarial loss: 0.427920\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023398; batch adversarial loss: 0.449430\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018396; batch adversarial loss: 0.386535\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036978; batch adversarial loss: 0.408480\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021650; batch adversarial loss: 0.503334\n",
      "epoch 154; iter: 0; batch classifier loss: 0.009420; batch adversarial loss: 0.469276\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012627; batch adversarial loss: 0.444531\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033238; batch adversarial loss: 0.442158\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016176; batch adversarial loss: 0.474893\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037261; batch adversarial loss: 0.544984\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018341; batch adversarial loss: 0.483644\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035097; batch adversarial loss: 0.484196\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023352; batch adversarial loss: 0.414399\n",
      "epoch 162; iter: 0; batch classifier loss: 0.006461; batch adversarial loss: 0.475309\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013891; batch adversarial loss: 0.447713\n",
      "epoch 164; iter: 0; batch classifier loss: 0.007658; batch adversarial loss: 0.366477\n",
      "epoch 165; iter: 0; batch classifier loss: 0.007212; batch adversarial loss: 0.448183\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025607; batch adversarial loss: 0.365060\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041309; batch adversarial loss: 0.389130\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030890; batch adversarial loss: 0.479209\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012520; batch adversarial loss: 0.397831\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021662; batch adversarial loss: 0.461973\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040208; batch adversarial loss: 0.410874\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019914; batch adversarial loss: 0.515654\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028508; batch adversarial loss: 0.391186\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016127; batch adversarial loss: 0.488781\n",
      "epoch 175; iter: 0; batch classifier loss: 0.052404; batch adversarial loss: 0.519314\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013822; batch adversarial loss: 0.378133\n",
      "epoch 177; iter: 0; batch classifier loss: 0.035319; batch adversarial loss: 0.471532\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029320; batch adversarial loss: 0.410427\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025287; batch adversarial loss: 0.399280\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037974; batch adversarial loss: 0.415061\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011758; batch adversarial loss: 0.463409\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028076; batch adversarial loss: 0.509763\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026429; batch adversarial loss: 0.422803\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016215; batch adversarial loss: 0.473698\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011726; batch adversarial loss: 0.472941\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032592; batch adversarial loss: 0.425471\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015111; batch adversarial loss: 0.436941\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020944; batch adversarial loss: 0.480680\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010694; batch adversarial loss: 0.523923\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004870; batch adversarial loss: 0.308776\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021014; batch adversarial loss: 0.381555\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021109; batch adversarial loss: 0.475131\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008180; batch adversarial loss: 0.462368\n",
      "epoch 194; iter: 0; batch classifier loss: 0.043899; batch adversarial loss: 0.449117\n",
      "epoch 195; iter: 0; batch classifier loss: 0.003165; batch adversarial loss: 0.385377\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021117; batch adversarial loss: 0.332832\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024034; batch adversarial loss: 0.459374\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016842; batch adversarial loss: 0.549286\n",
      "epoch 199; iter: 0; batch classifier loss: 0.003221; batch adversarial loss: 0.444953\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714591; batch adversarial loss: 0.603866\n",
      "epoch 1; iter: 0; batch classifier loss: 0.390892; batch adversarial loss: 0.609058\n",
      "epoch 2; iter: 0; batch classifier loss: 0.472561; batch adversarial loss: 0.608805\n",
      "epoch 3; iter: 0; batch classifier loss: 0.361609; batch adversarial loss: 0.583865\n",
      "epoch 4; iter: 0; batch classifier loss: 0.390829; batch adversarial loss: 0.537557\n",
      "epoch 5; iter: 0; batch classifier loss: 0.328671; batch adversarial loss: 0.585506\n",
      "epoch 6; iter: 0; batch classifier loss: 0.328042; batch adversarial loss: 0.548529\n",
      "epoch 7; iter: 0; batch classifier loss: 0.456680; batch adversarial loss: 0.566669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.415629; batch adversarial loss: 0.557178\n",
      "epoch 9; iter: 0; batch classifier loss: 0.446288; batch adversarial loss: 0.486930\n",
      "epoch 10; iter: 0; batch classifier loss: 0.447077; batch adversarial loss: 0.578914\n",
      "epoch 11; iter: 0; batch classifier loss: 0.596575; batch adversarial loss: 0.534734\n",
      "epoch 12; iter: 0; batch classifier loss: 0.594529; batch adversarial loss: 0.560060\n",
      "epoch 13; iter: 0; batch classifier loss: 0.433809; batch adversarial loss: 0.522372\n",
      "epoch 14; iter: 0; batch classifier loss: 0.374647; batch adversarial loss: 0.475939\n",
      "epoch 15; iter: 0; batch classifier loss: 0.314324; batch adversarial loss: 0.472728\n",
      "epoch 16; iter: 0; batch classifier loss: 0.267716; batch adversarial loss: 0.434649\n",
      "epoch 17; iter: 0; batch classifier loss: 0.214524; batch adversarial loss: 0.530625\n",
      "epoch 18; iter: 0; batch classifier loss: 0.219215; batch adversarial loss: 0.525030\n",
      "epoch 19; iter: 0; batch classifier loss: 0.242933; batch adversarial loss: 0.502359\n",
      "epoch 20; iter: 0; batch classifier loss: 0.259549; batch adversarial loss: 0.469119\n",
      "epoch 21; iter: 0; batch classifier loss: 0.187363; batch adversarial loss: 0.511729\n",
      "epoch 22; iter: 0; batch classifier loss: 0.214221; batch adversarial loss: 0.444896\n",
      "epoch 23; iter: 0; batch classifier loss: 0.192250; batch adversarial loss: 0.452758\n",
      "epoch 24; iter: 0; batch classifier loss: 0.270600; batch adversarial loss: 0.431744\n",
      "epoch 25; iter: 0; batch classifier loss: 0.140668; batch adversarial loss: 0.496912\n",
      "epoch 26; iter: 0; batch classifier loss: 0.163857; batch adversarial loss: 0.346047\n",
      "epoch 27; iter: 0; batch classifier loss: 0.202741; batch adversarial loss: 0.434805\n",
      "epoch 28; iter: 0; batch classifier loss: 0.214861; batch adversarial loss: 0.507129\n",
      "epoch 29; iter: 0; batch classifier loss: 0.157806; batch adversarial loss: 0.471775\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138215; batch adversarial loss: 0.484125\n",
      "epoch 31; iter: 0; batch classifier loss: 0.137649; batch adversarial loss: 0.406976\n",
      "epoch 32; iter: 0; batch classifier loss: 0.208485; batch adversarial loss: 0.460973\n",
      "epoch 33; iter: 0; batch classifier loss: 0.137280; batch adversarial loss: 0.486399\n",
      "epoch 34; iter: 0; batch classifier loss: 0.154026; batch adversarial loss: 0.487875\n",
      "epoch 35; iter: 0; batch classifier loss: 0.111921; batch adversarial loss: 0.466247\n",
      "epoch 36; iter: 0; batch classifier loss: 0.158494; batch adversarial loss: 0.505610\n",
      "epoch 37; iter: 0; batch classifier loss: 0.118165; batch adversarial loss: 0.471282\n",
      "epoch 38; iter: 0; batch classifier loss: 0.195251; batch adversarial loss: 0.465587\n",
      "epoch 39; iter: 0; batch classifier loss: 0.182536; batch adversarial loss: 0.441643\n",
      "epoch 40; iter: 0; batch classifier loss: 0.140704; batch adversarial loss: 0.491445\n",
      "epoch 41; iter: 0; batch classifier loss: 0.104781; batch adversarial loss: 0.470153\n",
      "epoch 42; iter: 0; batch classifier loss: 0.142530; batch adversarial loss: 0.512379\n",
      "epoch 43; iter: 0; batch classifier loss: 0.146535; batch adversarial loss: 0.455735\n",
      "epoch 44; iter: 0; batch classifier loss: 0.187443; batch adversarial loss: 0.485681\n",
      "epoch 45; iter: 0; batch classifier loss: 0.129563; batch adversarial loss: 0.450212\n",
      "epoch 46; iter: 0; batch classifier loss: 0.123072; batch adversarial loss: 0.423313\n",
      "epoch 47; iter: 0; batch classifier loss: 0.128277; batch adversarial loss: 0.535141\n",
      "epoch 48; iter: 0; batch classifier loss: 0.138323; batch adversarial loss: 0.425211\n",
      "epoch 49; iter: 0; batch classifier loss: 0.168203; batch adversarial loss: 0.486087\n",
      "epoch 50; iter: 0; batch classifier loss: 0.135756; batch adversarial loss: 0.428046\n",
      "epoch 51; iter: 0; batch classifier loss: 0.173942; batch adversarial loss: 0.465833\n",
      "epoch 52; iter: 0; batch classifier loss: 0.159668; batch adversarial loss: 0.401245\n",
      "epoch 53; iter: 0; batch classifier loss: 0.183186; batch adversarial loss: 0.482847\n",
      "epoch 54; iter: 0; batch classifier loss: 0.138549; batch adversarial loss: 0.381384\n",
      "epoch 55; iter: 0; batch classifier loss: 0.161936; batch adversarial loss: 0.527510\n",
      "epoch 56; iter: 0; batch classifier loss: 0.175272; batch adversarial loss: 0.397832\n",
      "epoch 57; iter: 0; batch classifier loss: 0.193955; batch adversarial loss: 0.440422\n",
      "epoch 58; iter: 0; batch classifier loss: 0.126361; batch adversarial loss: 0.445037\n",
      "epoch 59; iter: 0; batch classifier loss: 0.165760; batch adversarial loss: 0.425536\n",
      "epoch 60; iter: 0; batch classifier loss: 0.138562; batch adversarial loss: 0.476022\n",
      "epoch 61; iter: 0; batch classifier loss: 0.174520; batch adversarial loss: 0.404851\n",
      "epoch 62; iter: 0; batch classifier loss: 0.196370; batch adversarial loss: 0.354768\n",
      "epoch 63; iter: 0; batch classifier loss: 0.224352; batch adversarial loss: 0.462378\n",
      "epoch 64; iter: 0; batch classifier loss: 0.154820; batch adversarial loss: 0.446293\n",
      "epoch 65; iter: 0; batch classifier loss: 0.125054; batch adversarial loss: 0.528725\n",
      "epoch 66; iter: 0; batch classifier loss: 0.129838; batch adversarial loss: 0.545568\n",
      "epoch 67; iter: 0; batch classifier loss: 0.170325; batch adversarial loss: 0.558357\n",
      "epoch 68; iter: 0; batch classifier loss: 0.200083; batch adversarial loss: 0.457772\n",
      "epoch 69; iter: 0; batch classifier loss: 0.137248; batch adversarial loss: 0.470692\n",
      "epoch 70; iter: 0; batch classifier loss: 0.204779; batch adversarial loss: 0.480263\n",
      "epoch 71; iter: 0; batch classifier loss: 0.204178; batch adversarial loss: 0.470724\n",
      "epoch 72; iter: 0; batch classifier loss: 0.186393; batch adversarial loss: 0.543530\n",
      "epoch 73; iter: 0; batch classifier loss: 0.147085; batch adversarial loss: 0.428467\n",
      "epoch 74; iter: 0; batch classifier loss: 0.137430; batch adversarial loss: 0.532998\n",
      "epoch 75; iter: 0; batch classifier loss: 0.181676; batch adversarial loss: 0.437915\n",
      "epoch 76; iter: 0; batch classifier loss: 0.189943; batch adversarial loss: 0.481775\n",
      "epoch 77; iter: 0; batch classifier loss: 0.296313; batch adversarial loss: 0.400371\n",
      "epoch 78; iter: 0; batch classifier loss: 0.162015; batch adversarial loss: 0.453622\n",
      "epoch 79; iter: 0; batch classifier loss: 0.227898; batch adversarial loss: 0.420359\n",
      "epoch 80; iter: 0; batch classifier loss: 0.150573; batch adversarial loss: 0.519712\n",
      "epoch 81; iter: 0; batch classifier loss: 0.179073; batch adversarial loss: 0.471050\n",
      "epoch 82; iter: 0; batch classifier loss: 0.148371; batch adversarial loss: 0.471489\n",
      "epoch 83; iter: 0; batch classifier loss: 0.183853; batch adversarial loss: 0.451175\n",
      "epoch 84; iter: 0; batch classifier loss: 0.202432; batch adversarial loss: 0.397623\n",
      "epoch 85; iter: 0; batch classifier loss: 0.208458; batch adversarial loss: 0.486278\n",
      "epoch 86; iter: 0; batch classifier loss: 0.249575; batch adversarial loss: 0.405039\n",
      "epoch 87; iter: 0; batch classifier loss: 0.267684; batch adversarial loss: 0.422728\n",
      "epoch 88; iter: 0; batch classifier loss: 0.167266; batch adversarial loss: 0.523791\n",
      "epoch 89; iter: 0; batch classifier loss: 0.208746; batch adversarial loss: 0.372256\n",
      "epoch 90; iter: 0; batch classifier loss: 0.135563; batch adversarial loss: 0.408098\n",
      "epoch 91; iter: 0; batch classifier loss: 0.187697; batch adversarial loss: 0.424671\n",
      "epoch 92; iter: 0; batch classifier loss: 0.176183; batch adversarial loss: 0.430998\n",
      "epoch 93; iter: 0; batch classifier loss: 0.222206; batch adversarial loss: 0.444509\n",
      "epoch 94; iter: 0; batch classifier loss: 0.200401; batch adversarial loss: 0.498018\n",
      "epoch 95; iter: 0; batch classifier loss: 0.149101; batch adversarial loss: 0.440320\n",
      "epoch 96; iter: 0; batch classifier loss: 0.188001; batch adversarial loss: 0.491425\n",
      "epoch 97; iter: 0; batch classifier loss: 0.180225; batch adversarial loss: 0.442173\n",
      "epoch 98; iter: 0; batch classifier loss: 0.181321; batch adversarial loss: 0.482818\n",
      "epoch 99; iter: 0; batch classifier loss: 0.218331; batch adversarial loss: 0.445206\n",
      "epoch 100; iter: 0; batch classifier loss: 0.238875; batch adversarial loss: 0.494568\n",
      "epoch 101; iter: 0; batch classifier loss: 0.249770; batch adversarial loss: 0.469449\n",
      "epoch 102; iter: 0; batch classifier loss: 0.198738; batch adversarial loss: 0.469293\n",
      "epoch 103; iter: 0; batch classifier loss: 0.279596; batch adversarial loss: 0.469263\n",
      "epoch 104; iter: 0; batch classifier loss: 0.190422; batch adversarial loss: 0.509847\n",
      "epoch 105; iter: 0; batch classifier loss: 0.221365; batch adversarial loss: 0.348602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.199730; batch adversarial loss: 0.459122\n",
      "epoch 107; iter: 0; batch classifier loss: 0.234850; batch adversarial loss: 0.480197\n",
      "epoch 108; iter: 0; batch classifier loss: 0.241200; batch adversarial loss: 0.540746\n",
      "epoch 109; iter: 0; batch classifier loss: 0.165764; batch adversarial loss: 0.461446\n",
      "epoch 110; iter: 0; batch classifier loss: 0.221849; batch adversarial loss: 0.461127\n",
      "epoch 111; iter: 0; batch classifier loss: 0.231194; batch adversarial loss: 0.458673\n",
      "epoch 112; iter: 0; batch classifier loss: 0.215435; batch adversarial loss: 0.506515\n",
      "epoch 113; iter: 0; batch classifier loss: 0.291010; batch adversarial loss: 0.422811\n",
      "epoch 114; iter: 0; batch classifier loss: 0.345702; batch adversarial loss: 0.422405\n",
      "epoch 115; iter: 0; batch classifier loss: 0.185490; batch adversarial loss: 0.483311\n",
      "epoch 116; iter: 0; batch classifier loss: 0.329953; batch adversarial loss: 0.507100\n",
      "epoch 117; iter: 0; batch classifier loss: 0.189985; batch adversarial loss: 0.494650\n",
      "epoch 118; iter: 0; batch classifier loss: 0.157642; batch adversarial loss: 0.433818\n",
      "epoch 119; iter: 0; batch classifier loss: 0.102926; batch adversarial loss: 0.397647\n",
      "epoch 120; iter: 0; batch classifier loss: 0.130807; batch adversarial loss: 0.417328\n",
      "epoch 121; iter: 0; batch classifier loss: 0.167424; batch adversarial loss: 0.487675\n",
      "epoch 122; iter: 0; batch classifier loss: 0.178221; batch adversarial loss: 0.424325\n",
      "epoch 123; iter: 0; batch classifier loss: 0.210276; batch adversarial loss: 0.539348\n",
      "epoch 124; iter: 0; batch classifier loss: 0.162897; batch adversarial loss: 0.525805\n",
      "epoch 125; iter: 0; batch classifier loss: 0.243063; batch adversarial loss: 0.467799\n",
      "epoch 126; iter: 0; batch classifier loss: 0.254219; batch adversarial loss: 0.362099\n",
      "epoch 127; iter: 0; batch classifier loss: 0.171212; batch adversarial loss: 0.410936\n",
      "epoch 128; iter: 0; batch classifier loss: 0.218746; batch adversarial loss: 0.419367\n",
      "epoch 129; iter: 0; batch classifier loss: 0.188658; batch adversarial loss: 0.458292\n",
      "epoch 130; iter: 0; batch classifier loss: 0.232443; batch adversarial loss: 0.385485\n",
      "epoch 131; iter: 0; batch classifier loss: 0.165472; batch adversarial loss: 0.447925\n",
      "epoch 132; iter: 0; batch classifier loss: 0.210201; batch adversarial loss: 0.490765\n",
      "epoch 133; iter: 0; batch classifier loss: 0.169208; batch adversarial loss: 0.593786\n",
      "epoch 134; iter: 0; batch classifier loss: 0.215748; batch adversarial loss: 0.370268\n",
      "epoch 135; iter: 0; batch classifier loss: 0.148802; batch adversarial loss: 0.413189\n",
      "epoch 136; iter: 0; batch classifier loss: 0.158272; batch adversarial loss: 0.395548\n",
      "epoch 137; iter: 0; batch classifier loss: 0.130008; batch adversarial loss: 0.386386\n",
      "epoch 138; iter: 0; batch classifier loss: 0.114200; batch adversarial loss: 0.540393\n",
      "epoch 139; iter: 0; batch classifier loss: 0.144359; batch adversarial loss: 0.370960\n",
      "epoch 140; iter: 0; batch classifier loss: 0.095886; batch adversarial loss: 0.488535\n",
      "epoch 141; iter: 0; batch classifier loss: 0.071577; batch adversarial loss: 0.441223\n",
      "epoch 142; iter: 0; batch classifier loss: 0.055850; batch adversarial loss: 0.501423\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050267; batch adversarial loss: 0.572949\n",
      "epoch 144; iter: 0; batch classifier loss: 0.050778; batch adversarial loss: 0.473476\n",
      "epoch 145; iter: 0; batch classifier loss: 0.050104; batch adversarial loss: 0.381181\n",
      "epoch 146; iter: 0; batch classifier loss: 0.063809; batch adversarial loss: 0.425719\n",
      "epoch 147; iter: 0; batch classifier loss: 0.068544; batch adversarial loss: 0.358098\n",
      "epoch 148; iter: 0; batch classifier loss: 0.047433; batch adversarial loss: 0.440277\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039923; batch adversarial loss: 0.527027\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054073; batch adversarial loss: 0.475324\n",
      "epoch 151; iter: 0; batch classifier loss: 0.097570; batch adversarial loss: 0.422478\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034214; batch adversarial loss: 0.480691\n",
      "epoch 153; iter: 0; batch classifier loss: 0.061781; batch adversarial loss: 0.511736\n",
      "epoch 154; iter: 0; batch classifier loss: 0.085155; batch adversarial loss: 0.507162\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049262; batch adversarial loss: 0.486078\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044593; batch adversarial loss: 0.467978\n",
      "epoch 157; iter: 0; batch classifier loss: 0.043549; batch adversarial loss: 0.466256\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029566; batch adversarial loss: 0.613653\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031834; batch adversarial loss: 0.410092\n",
      "epoch 160; iter: 0; batch classifier loss: 0.059101; batch adversarial loss: 0.411510\n",
      "epoch 161; iter: 0; batch classifier loss: 0.054573; batch adversarial loss: 0.487948\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014164; batch adversarial loss: 0.444924\n",
      "epoch 163; iter: 0; batch classifier loss: 0.059703; batch adversarial loss: 0.399490\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029123; batch adversarial loss: 0.499082\n",
      "epoch 165; iter: 0; batch classifier loss: 0.064001; batch adversarial loss: 0.380513\n",
      "epoch 166; iter: 0; batch classifier loss: 0.053869; batch adversarial loss: 0.445970\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036502; batch adversarial loss: 0.508213\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038881; batch adversarial loss: 0.480290\n",
      "epoch 169; iter: 0; batch classifier loss: 0.045075; batch adversarial loss: 0.487732\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035767; batch adversarial loss: 0.426281\n",
      "epoch 171; iter: 0; batch classifier loss: 0.043632; batch adversarial loss: 0.445719\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017656; batch adversarial loss: 0.416822\n",
      "epoch 173; iter: 0; batch classifier loss: 0.052422; batch adversarial loss: 0.420949\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021523; batch adversarial loss: 0.424116\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015651; batch adversarial loss: 0.513911\n",
      "epoch 176; iter: 0; batch classifier loss: 0.038502; batch adversarial loss: 0.369915\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021207; batch adversarial loss: 0.418751\n",
      "epoch 178; iter: 0; batch classifier loss: 0.036261; batch adversarial loss: 0.417043\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027302; batch adversarial loss: 0.450810\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018996; batch adversarial loss: 0.504718\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035659; batch adversarial loss: 0.557291\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032650; batch adversarial loss: 0.413813\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025286; batch adversarial loss: 0.401900\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007285; batch adversarial loss: 0.504034\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024883; batch adversarial loss: 0.503568\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008664; batch adversarial loss: 0.457098\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019442; batch adversarial loss: 0.435696\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031770; batch adversarial loss: 0.414768\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025213; batch adversarial loss: 0.462846\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032925; batch adversarial loss: 0.407591\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018509; batch adversarial loss: 0.524745\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014607; batch adversarial loss: 0.425190\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018797; batch adversarial loss: 0.455821\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018268; batch adversarial loss: 0.543774\n",
      "epoch 195; iter: 0; batch classifier loss: 0.059724; batch adversarial loss: 0.463279\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008903; batch adversarial loss: 0.486705\n",
      "epoch 197; iter: 0; batch classifier loss: 0.050919; batch adversarial loss: 0.470043\n",
      "epoch 198; iter: 0; batch classifier loss: 0.040631; batch adversarial loss: 0.460144\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022208; batch adversarial loss: 0.496369\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698073; batch adversarial loss: 0.596913\n",
      "epoch 1; iter: 0; batch classifier loss: 0.420052; batch adversarial loss: 0.613985\n",
      "epoch 2; iter: 0; batch classifier loss: 0.413273; batch adversarial loss: 0.589287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.324001; batch adversarial loss: 0.608306\n",
      "epoch 4; iter: 0; batch classifier loss: 0.301134; batch adversarial loss: 0.518293\n",
      "epoch 5; iter: 0; batch classifier loss: 0.312828; batch adversarial loss: 0.538455\n",
      "epoch 6; iter: 0; batch classifier loss: 0.350148; batch adversarial loss: 0.552688\n",
      "epoch 7; iter: 0; batch classifier loss: 0.296224; batch adversarial loss: 0.580430\n",
      "epoch 8; iter: 0; batch classifier loss: 0.310932; batch adversarial loss: 0.570466\n",
      "epoch 9; iter: 0; batch classifier loss: 0.223142; batch adversarial loss: 0.605670\n",
      "epoch 10; iter: 0; batch classifier loss: 0.251665; batch adversarial loss: 0.512166\n",
      "epoch 11; iter: 0; batch classifier loss: 0.278944; batch adversarial loss: 0.570149\n",
      "epoch 12; iter: 0; batch classifier loss: 0.225302; batch adversarial loss: 0.572987\n",
      "epoch 13; iter: 0; batch classifier loss: 0.271649; batch adversarial loss: 0.492121\n",
      "epoch 14; iter: 0; batch classifier loss: 0.151499; batch adversarial loss: 0.450789\n",
      "epoch 15; iter: 0; batch classifier loss: 0.220068; batch adversarial loss: 0.494749\n",
      "epoch 16; iter: 0; batch classifier loss: 0.254297; batch adversarial loss: 0.424544\n",
      "epoch 17; iter: 0; batch classifier loss: 0.310450; batch adversarial loss: 0.506067\n",
      "epoch 18; iter: 0; batch classifier loss: 0.320578; batch adversarial loss: 0.596688\n",
      "epoch 19; iter: 0; batch classifier loss: 0.404878; batch adversarial loss: 0.560493\n",
      "epoch 20; iter: 0; batch classifier loss: 0.442272; batch adversarial loss: 0.536098\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502449; batch adversarial loss: 0.461891\n",
      "epoch 22; iter: 0; batch classifier loss: 0.388019; batch adversarial loss: 0.481541\n",
      "epoch 23; iter: 0; batch classifier loss: 0.252392; batch adversarial loss: 0.437629\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182920; batch adversarial loss: 0.487498\n",
      "epoch 25; iter: 0; batch classifier loss: 0.155028; batch adversarial loss: 0.552662\n",
      "epoch 26; iter: 0; batch classifier loss: 0.127770; batch adversarial loss: 0.478857\n",
      "epoch 27; iter: 0; batch classifier loss: 0.133532; batch adversarial loss: 0.440772\n",
      "epoch 28; iter: 0; batch classifier loss: 0.116925; batch adversarial loss: 0.533455\n",
      "epoch 29; iter: 0; batch classifier loss: 0.085104; batch adversarial loss: 0.409737\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172707; batch adversarial loss: 0.412728\n",
      "epoch 31; iter: 0; batch classifier loss: 0.110779; batch adversarial loss: 0.487629\n",
      "epoch 32; iter: 0; batch classifier loss: 0.113375; batch adversarial loss: 0.482627\n",
      "epoch 33; iter: 0; batch classifier loss: 0.113545; batch adversarial loss: 0.437284\n",
      "epoch 34; iter: 0; batch classifier loss: 0.079994; batch adversarial loss: 0.465300\n",
      "epoch 35; iter: 0; batch classifier loss: 0.084417; batch adversarial loss: 0.436456\n",
      "epoch 36; iter: 0; batch classifier loss: 0.079906; batch adversarial loss: 0.490750\n",
      "epoch 37; iter: 0; batch classifier loss: 0.106372; batch adversarial loss: 0.481758\n",
      "epoch 38; iter: 0; batch classifier loss: 0.075154; batch adversarial loss: 0.441174\n",
      "epoch 39; iter: 0; batch classifier loss: 0.100861; batch adversarial loss: 0.558641\n",
      "epoch 40; iter: 0; batch classifier loss: 0.084025; batch adversarial loss: 0.443514\n",
      "epoch 41; iter: 0; batch classifier loss: 0.063968; batch adversarial loss: 0.450720\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146282; batch adversarial loss: 0.394130\n",
      "epoch 43; iter: 0; batch classifier loss: 0.155399; batch adversarial loss: 0.495582\n",
      "epoch 44; iter: 0; batch classifier loss: 0.122280; batch adversarial loss: 0.446619\n",
      "epoch 45; iter: 0; batch classifier loss: 0.105848; batch adversarial loss: 0.496549\n",
      "epoch 46; iter: 0; batch classifier loss: 0.091938; batch adversarial loss: 0.404595\n",
      "epoch 47; iter: 0; batch classifier loss: 0.072414; batch adversarial loss: 0.496586\n",
      "epoch 48; iter: 0; batch classifier loss: 0.090769; batch adversarial loss: 0.490241\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080723; batch adversarial loss: 0.487194\n",
      "epoch 50; iter: 0; batch classifier loss: 0.088859; batch adversarial loss: 0.417335\n",
      "epoch 51; iter: 0; batch classifier loss: 0.097333; batch adversarial loss: 0.434261\n",
      "epoch 52; iter: 0; batch classifier loss: 0.092864; batch adversarial loss: 0.497925\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095314; batch adversarial loss: 0.522287\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108500; batch adversarial loss: 0.454152\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084816; batch adversarial loss: 0.561746\n",
      "epoch 56; iter: 0; batch classifier loss: 0.110184; batch adversarial loss: 0.427578\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107601; batch adversarial loss: 0.391566\n",
      "epoch 58; iter: 0; batch classifier loss: 0.065912; batch adversarial loss: 0.434390\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102239; batch adversarial loss: 0.422979\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087239; batch adversarial loss: 0.502350\n",
      "epoch 61; iter: 0; batch classifier loss: 0.069381; batch adversarial loss: 0.443578\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082769; batch adversarial loss: 0.468771\n",
      "epoch 63; iter: 0; batch classifier loss: 0.124315; batch adversarial loss: 0.348165\n",
      "epoch 64; iter: 0; batch classifier loss: 0.055036; batch adversarial loss: 0.419232\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077540; batch adversarial loss: 0.506923\n",
      "epoch 66; iter: 0; batch classifier loss: 0.103174; batch adversarial loss: 0.472244\n",
      "epoch 67; iter: 0; batch classifier loss: 0.125680; batch adversarial loss: 0.522059\n",
      "epoch 68; iter: 0; batch classifier loss: 0.144209; batch adversarial loss: 0.493234\n",
      "epoch 69; iter: 0; batch classifier loss: 0.093644; batch adversarial loss: 0.495064\n",
      "epoch 70; iter: 0; batch classifier loss: 0.099093; batch adversarial loss: 0.423202\n",
      "epoch 71; iter: 0; batch classifier loss: 0.074583; batch adversarial loss: 0.404701\n",
      "epoch 72; iter: 0; batch classifier loss: 0.052469; batch adversarial loss: 0.510117\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077318; batch adversarial loss: 0.475849\n",
      "epoch 74; iter: 0; batch classifier loss: 0.105238; batch adversarial loss: 0.501557\n",
      "epoch 75; iter: 0; batch classifier loss: 0.106156; batch adversarial loss: 0.447946\n",
      "epoch 76; iter: 0; batch classifier loss: 0.102420; batch adversarial loss: 0.434795\n",
      "epoch 77; iter: 0; batch classifier loss: 0.124750; batch adversarial loss: 0.539162\n",
      "epoch 78; iter: 0; batch classifier loss: 0.089079; batch adversarial loss: 0.472673\n",
      "epoch 79; iter: 0; batch classifier loss: 0.052088; batch adversarial loss: 0.496143\n",
      "epoch 80; iter: 0; batch classifier loss: 0.119277; batch adversarial loss: 0.505008\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066654; batch adversarial loss: 0.483871\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074512; batch adversarial loss: 0.413946\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085166; batch adversarial loss: 0.458412\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046482; batch adversarial loss: 0.537481\n",
      "epoch 85; iter: 0; batch classifier loss: 0.095163; batch adversarial loss: 0.401992\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084355; batch adversarial loss: 0.424506\n",
      "epoch 87; iter: 0; batch classifier loss: 0.044164; batch adversarial loss: 0.487460\n",
      "epoch 88; iter: 0; batch classifier loss: 0.154708; batch adversarial loss: 0.472696\n",
      "epoch 89; iter: 0; batch classifier loss: 0.091367; batch adversarial loss: 0.464084\n",
      "epoch 90; iter: 0; batch classifier loss: 0.070697; batch adversarial loss: 0.551446\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077540; batch adversarial loss: 0.419180\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062839; batch adversarial loss: 0.448646\n",
      "epoch 93; iter: 0; batch classifier loss: 0.042581; batch adversarial loss: 0.460011\n",
      "epoch 94; iter: 0; batch classifier loss: 0.102539; batch adversarial loss: 0.550436\n",
      "epoch 95; iter: 0; batch classifier loss: 0.055989; batch adversarial loss: 0.401245\n",
      "epoch 96; iter: 0; batch classifier loss: 0.129593; batch adversarial loss: 0.447788\n",
      "epoch 97; iter: 0; batch classifier loss: 0.101086; batch adversarial loss: 0.426784\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058241; batch adversarial loss: 0.456708\n",
      "epoch 99; iter: 0; batch classifier loss: 0.090916; batch adversarial loss: 0.569496\n",
      "epoch 100; iter: 0; batch classifier loss: 0.101243; batch adversarial loss: 0.481041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.062237; batch adversarial loss: 0.436607\n",
      "epoch 102; iter: 0; batch classifier loss: 0.028776; batch adversarial loss: 0.394958\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066899; batch adversarial loss: 0.465712\n",
      "epoch 104; iter: 0; batch classifier loss: 0.093741; batch adversarial loss: 0.601054\n",
      "epoch 105; iter: 0; batch classifier loss: 0.025957; batch adversarial loss: 0.464113\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057243; batch adversarial loss: 0.516433\n",
      "epoch 107; iter: 0; batch classifier loss: 0.064271; batch adversarial loss: 0.535336\n",
      "epoch 108; iter: 0; batch classifier loss: 0.070157; batch adversarial loss: 0.441183\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038944; batch adversarial loss: 0.423297\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051660; batch adversarial loss: 0.434318\n",
      "epoch 111; iter: 0; batch classifier loss: 0.023030; batch adversarial loss: 0.405278\n",
      "epoch 112; iter: 0; batch classifier loss: 0.077684; batch adversarial loss: 0.450599\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038728; batch adversarial loss: 0.427589\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028765; batch adversarial loss: 0.595945\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037779; batch adversarial loss: 0.504805\n",
      "epoch 116; iter: 0; batch classifier loss: 0.047747; batch adversarial loss: 0.426957\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060793; batch adversarial loss: 0.483718\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047139; batch adversarial loss: 0.498577\n",
      "epoch 119; iter: 0; batch classifier loss: 0.070496; batch adversarial loss: 0.487495\n",
      "epoch 120; iter: 0; batch classifier loss: 0.080178; batch adversarial loss: 0.340216\n",
      "epoch 121; iter: 0; batch classifier loss: 0.062214; batch adversarial loss: 0.542609\n",
      "epoch 122; iter: 0; batch classifier loss: 0.018179; batch adversarial loss: 0.436392\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039955; batch adversarial loss: 0.475368\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046193; batch adversarial loss: 0.459664\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038959; batch adversarial loss: 0.561649\n",
      "epoch 126; iter: 0; batch classifier loss: 0.088386; batch adversarial loss: 0.453343\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051578; batch adversarial loss: 0.441414\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053382; batch adversarial loss: 0.414332\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059393; batch adversarial loss: 0.409607\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036479; batch adversarial loss: 0.459196\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041945; batch adversarial loss: 0.523246\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036566; batch adversarial loss: 0.514312\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032793; batch adversarial loss: 0.440382\n",
      "epoch 134; iter: 0; batch classifier loss: 0.041940; batch adversarial loss: 0.437255\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040066; batch adversarial loss: 0.459524\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029992; batch adversarial loss: 0.406372\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027494; batch adversarial loss: 0.521898\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021861; batch adversarial loss: 0.451042\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049278; batch adversarial loss: 0.529041\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017481; batch adversarial loss: 0.467791\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035938; batch adversarial loss: 0.410610\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027724; batch adversarial loss: 0.443039\n",
      "epoch 143; iter: 0; batch classifier loss: 0.012149; batch adversarial loss: 0.592532\n",
      "epoch 144; iter: 0; batch classifier loss: 0.011790; batch adversarial loss: 0.521060\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020373; batch adversarial loss: 0.493505\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019983; batch adversarial loss: 0.479413\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015657; batch adversarial loss: 0.421687\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046992; batch adversarial loss: 0.398530\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029973; batch adversarial loss: 0.502083\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035819; batch adversarial loss: 0.421216\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035805; batch adversarial loss: 0.552794\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020746; batch adversarial loss: 0.438529\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024982; batch adversarial loss: 0.436325\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017591; batch adversarial loss: 0.485139\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013009; batch adversarial loss: 0.352082\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015863; batch adversarial loss: 0.449144\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019881; batch adversarial loss: 0.489226\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018372; batch adversarial loss: 0.454545\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038242; batch adversarial loss: 0.529665\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014737; batch adversarial loss: 0.543525\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033767; batch adversarial loss: 0.401730\n",
      "epoch 162; iter: 0; batch classifier loss: 0.035139; batch adversarial loss: 0.493481\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017208; batch adversarial loss: 0.479965\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014768; batch adversarial loss: 0.389475\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015531; batch adversarial loss: 0.498047\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012652; batch adversarial loss: 0.569377\n",
      "epoch 167; iter: 0; batch classifier loss: 0.055410; batch adversarial loss: 0.493775\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016126; batch adversarial loss: 0.485795\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008395; batch adversarial loss: 0.499653\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037209; batch adversarial loss: 0.413468\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007661; batch adversarial loss: 0.392968\n",
      "epoch 172; iter: 0; batch classifier loss: 0.047494; batch adversarial loss: 0.442119\n",
      "epoch 173; iter: 0; batch classifier loss: 0.050938; batch adversarial loss: 0.566505\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021022; batch adversarial loss: 0.501313\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018501; batch adversarial loss: 0.510035\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024156; batch adversarial loss: 0.449714\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036571; batch adversarial loss: 0.546661\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012847; batch adversarial loss: 0.472831\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021768; batch adversarial loss: 0.485003\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039803; batch adversarial loss: 0.482790\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021554; batch adversarial loss: 0.494142\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029290; batch adversarial loss: 0.458072\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008068; batch adversarial loss: 0.510186\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015068; batch adversarial loss: 0.500826\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022538; batch adversarial loss: 0.410860\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018243; batch adversarial loss: 0.480461\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013041; batch adversarial loss: 0.509978\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010336; batch adversarial loss: 0.393752\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015707; batch adversarial loss: 0.512694\n",
      "epoch 190; iter: 0; batch classifier loss: 0.033475; batch adversarial loss: 0.507030\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025907; batch adversarial loss: 0.417239\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036105; batch adversarial loss: 0.426471\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022255; batch adversarial loss: 0.427797\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014824; batch adversarial loss: 0.491707\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013707; batch adversarial loss: 0.423288\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016223; batch adversarial loss: 0.488075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.030990; batch adversarial loss: 0.541276\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037072; batch adversarial loss: 0.336090\n",
      "epoch 199; iter: 0; batch classifier loss: 0.058432; batch adversarial loss: 0.481015\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717917; batch adversarial loss: 0.775262\n",
      "epoch 1; iter: 0; batch classifier loss: 0.490369; batch adversarial loss: 0.772039\n",
      "epoch 2; iter: 0; batch classifier loss: 0.364555; batch adversarial loss: 0.749042\n",
      "epoch 3; iter: 0; batch classifier loss: 0.363158; batch adversarial loss: 0.696344\n",
      "epoch 4; iter: 0; batch classifier loss: 0.332869; batch adversarial loss: 0.688923\n",
      "epoch 5; iter: 0; batch classifier loss: 0.327275; batch adversarial loss: 0.627563\n",
      "epoch 6; iter: 0; batch classifier loss: 0.368764; batch adversarial loss: 0.571013\n",
      "epoch 7; iter: 0; batch classifier loss: 0.372338; batch adversarial loss: 0.550099\n",
      "epoch 8; iter: 0; batch classifier loss: 0.327195; batch adversarial loss: 0.531852\n",
      "epoch 9; iter: 0; batch classifier loss: 0.255924; batch adversarial loss: 0.555834\n",
      "epoch 10; iter: 0; batch classifier loss: 0.366026; batch adversarial loss: 0.476442\n",
      "epoch 11; iter: 0; batch classifier loss: 0.209438; batch adversarial loss: 0.495469\n",
      "epoch 12; iter: 0; batch classifier loss: 0.212639; batch adversarial loss: 0.472477\n",
      "epoch 13; iter: 0; batch classifier loss: 0.258731; batch adversarial loss: 0.458268\n",
      "epoch 14; iter: 0; batch classifier loss: 0.220698; batch adversarial loss: 0.410037\n",
      "epoch 15; iter: 0; batch classifier loss: 0.247263; batch adversarial loss: 0.453474\n",
      "epoch 16; iter: 0; batch classifier loss: 0.180626; batch adversarial loss: 0.443456\n",
      "epoch 17; iter: 0; batch classifier loss: 0.132898; batch adversarial loss: 0.462790\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214582; batch adversarial loss: 0.394488\n",
      "epoch 19; iter: 0; batch classifier loss: 0.137535; batch adversarial loss: 0.420984\n",
      "epoch 20; iter: 0; batch classifier loss: 0.176673; batch adversarial loss: 0.435741\n",
      "epoch 21; iter: 0; batch classifier loss: 0.141644; batch adversarial loss: 0.464959\n",
      "epoch 22; iter: 0; batch classifier loss: 0.137510; batch adversarial loss: 0.449175\n",
      "epoch 23; iter: 0; batch classifier loss: 0.147655; batch adversarial loss: 0.446610\n",
      "epoch 24; iter: 0; batch classifier loss: 0.137534; batch adversarial loss: 0.415795\n",
      "epoch 25; iter: 0; batch classifier loss: 0.141601; batch adversarial loss: 0.432936\n",
      "epoch 26; iter: 0; batch classifier loss: 0.127290; batch adversarial loss: 0.405000\n",
      "epoch 27; iter: 0; batch classifier loss: 0.136427; batch adversarial loss: 0.463828\n",
      "epoch 28; iter: 0; batch classifier loss: 0.098206; batch adversarial loss: 0.420528\n",
      "epoch 29; iter: 0; batch classifier loss: 0.124131; batch adversarial loss: 0.342441\n",
      "epoch 30; iter: 0; batch classifier loss: 0.155585; batch adversarial loss: 0.459523\n",
      "epoch 31; iter: 0; batch classifier loss: 0.112109; batch adversarial loss: 0.382103\n",
      "epoch 32; iter: 0; batch classifier loss: 0.122194; batch adversarial loss: 0.486342\n",
      "epoch 33; iter: 0; batch classifier loss: 0.127146; batch adversarial loss: 0.533375\n",
      "epoch 34; iter: 0; batch classifier loss: 0.074531; batch adversarial loss: 0.386203\n",
      "epoch 35; iter: 0; batch classifier loss: 0.113253; batch adversarial loss: 0.466673\n",
      "epoch 36; iter: 0; batch classifier loss: 0.179750; batch adversarial loss: 0.590047\n",
      "epoch 37; iter: 0; batch classifier loss: 0.084196; batch adversarial loss: 0.489681\n",
      "epoch 38; iter: 0; batch classifier loss: 0.075219; batch adversarial loss: 0.385394\n",
      "epoch 39; iter: 0; batch classifier loss: 0.152262; batch adversarial loss: 0.445648\n",
      "epoch 40; iter: 0; batch classifier loss: 0.098377; batch adversarial loss: 0.443158\n",
      "epoch 41; iter: 0; batch classifier loss: 0.156886; batch adversarial loss: 0.530638\n",
      "epoch 42; iter: 0; batch classifier loss: 0.144798; batch adversarial loss: 0.399828\n",
      "epoch 43; iter: 0; batch classifier loss: 0.167987; batch adversarial loss: 0.530752\n",
      "epoch 44; iter: 0; batch classifier loss: 0.117307; batch adversarial loss: 0.466673\n",
      "epoch 45; iter: 0; batch classifier loss: 0.115764; batch adversarial loss: 0.530127\n",
      "epoch 46; iter: 0; batch classifier loss: 0.179826; batch adversarial loss: 0.498482\n",
      "epoch 47; iter: 0; batch classifier loss: 0.099525; batch adversarial loss: 0.339228\n",
      "epoch 48; iter: 0; batch classifier loss: 0.170814; batch adversarial loss: 0.410624\n",
      "epoch 49; iter: 0; batch classifier loss: 0.159172; batch adversarial loss: 0.463857\n",
      "epoch 50; iter: 0; batch classifier loss: 0.194317; batch adversarial loss: 0.425413\n",
      "epoch 51; iter: 0; batch classifier loss: 0.153749; batch adversarial loss: 0.496495\n",
      "epoch 52; iter: 0; batch classifier loss: 0.181067; batch adversarial loss: 0.469595\n",
      "epoch 53; iter: 0; batch classifier loss: 0.210423; batch adversarial loss: 0.478739\n",
      "epoch 54; iter: 0; batch classifier loss: 0.148954; batch adversarial loss: 0.522580\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079906; batch adversarial loss: 0.439622\n",
      "epoch 56; iter: 0; batch classifier loss: 0.071109; batch adversarial loss: 0.468802\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061979; batch adversarial loss: 0.495861\n",
      "epoch 58; iter: 0; batch classifier loss: 0.075613; batch adversarial loss: 0.355836\n",
      "epoch 59; iter: 0; batch classifier loss: 0.056683; batch adversarial loss: 0.507301\n",
      "epoch 60; iter: 0; batch classifier loss: 0.091454; batch adversarial loss: 0.410699\n",
      "epoch 61; iter: 0; batch classifier loss: 0.070992; batch adversarial loss: 0.391626\n",
      "epoch 62; iter: 0; batch classifier loss: 0.077358; batch adversarial loss: 0.484074\n",
      "epoch 63; iter: 0; batch classifier loss: 0.063470; batch adversarial loss: 0.426084\n",
      "epoch 64; iter: 0; batch classifier loss: 0.081749; batch adversarial loss: 0.453382\n",
      "epoch 65; iter: 0; batch classifier loss: 0.084223; batch adversarial loss: 0.409128\n",
      "epoch 66; iter: 0; batch classifier loss: 0.053057; batch adversarial loss: 0.481974\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061790; batch adversarial loss: 0.365699\n",
      "epoch 68; iter: 0; batch classifier loss: 0.051746; batch adversarial loss: 0.417346\n",
      "epoch 69; iter: 0; batch classifier loss: 0.059240; batch adversarial loss: 0.463318\n",
      "epoch 70; iter: 0; batch classifier loss: 0.077615; batch adversarial loss: 0.483367\n",
      "epoch 71; iter: 0; batch classifier loss: 0.068383; batch adversarial loss: 0.535237\n",
      "epoch 72; iter: 0; batch classifier loss: 0.068898; batch adversarial loss: 0.398909\n",
      "epoch 73; iter: 0; batch classifier loss: 0.057634; batch adversarial loss: 0.411942\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069663; batch adversarial loss: 0.533279\n",
      "epoch 75; iter: 0; batch classifier loss: 0.078129; batch adversarial loss: 0.298637\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064080; batch adversarial loss: 0.469341\n",
      "epoch 77; iter: 0; batch classifier loss: 0.066023; batch adversarial loss: 0.390915\n",
      "epoch 78; iter: 0; batch classifier loss: 0.126053; batch adversarial loss: 0.404969\n",
      "epoch 79; iter: 0; batch classifier loss: 0.096006; batch adversarial loss: 0.526328\n",
      "epoch 80; iter: 0; batch classifier loss: 0.042155; batch adversarial loss: 0.368880\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055617; batch adversarial loss: 0.530201\n",
      "epoch 82; iter: 0; batch classifier loss: 0.070057; batch adversarial loss: 0.504771\n",
      "epoch 83; iter: 0; batch classifier loss: 0.046065; batch adversarial loss: 0.598467\n",
      "epoch 84; iter: 0; batch classifier loss: 0.035851; batch adversarial loss: 0.451549\n",
      "epoch 85; iter: 0; batch classifier loss: 0.047471; batch adversarial loss: 0.448513\n",
      "epoch 86; iter: 0; batch classifier loss: 0.042431; batch adversarial loss: 0.498514\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062412; batch adversarial loss: 0.451710\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058814; batch adversarial loss: 0.522896\n",
      "epoch 89; iter: 0; batch classifier loss: 0.033654; batch adversarial loss: 0.431001\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075090; batch adversarial loss: 0.482040\n",
      "epoch 91; iter: 0; batch classifier loss: 0.036366; batch adversarial loss: 0.429283\n",
      "epoch 92; iter: 0; batch classifier loss: 0.078084; batch adversarial loss: 0.499948\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058438; batch adversarial loss: 0.475948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.055671; batch adversarial loss: 0.504401\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070153; batch adversarial loss: 0.485911\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065116; batch adversarial loss: 0.454836\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043394; batch adversarial loss: 0.445746\n",
      "epoch 98; iter: 0; batch classifier loss: 0.101344; batch adversarial loss: 0.421802\n",
      "epoch 99; iter: 0; batch classifier loss: 0.103092; batch adversarial loss: 0.401225\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038134; batch adversarial loss: 0.519500\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042686; batch adversarial loss: 0.513008\n",
      "epoch 102; iter: 0; batch classifier loss: 0.074040; batch adversarial loss: 0.506257\n",
      "epoch 103; iter: 0; batch classifier loss: 0.097004; batch adversarial loss: 0.452038\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062185; batch adversarial loss: 0.470166\n",
      "epoch 105; iter: 0; batch classifier loss: 0.069248; batch adversarial loss: 0.483402\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049041; batch adversarial loss: 0.438178\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028750; batch adversarial loss: 0.410559\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058071; batch adversarial loss: 0.508994\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044392; batch adversarial loss: 0.503075\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041364; batch adversarial loss: 0.510105\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055595; batch adversarial loss: 0.409801\n",
      "epoch 112; iter: 0; batch classifier loss: 0.066314; batch adversarial loss: 0.473733\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051446; batch adversarial loss: 0.441010\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051079; batch adversarial loss: 0.430550\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043085; batch adversarial loss: 0.500851\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057759; batch adversarial loss: 0.380121\n",
      "epoch 117; iter: 0; batch classifier loss: 0.072455; batch adversarial loss: 0.434879\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044553; batch adversarial loss: 0.375557\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054580; batch adversarial loss: 0.504207\n",
      "epoch 120; iter: 0; batch classifier loss: 0.067636; batch adversarial loss: 0.446159\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039373; batch adversarial loss: 0.401905\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059333; batch adversarial loss: 0.400693\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053151; batch adversarial loss: 0.395576\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046875; batch adversarial loss: 0.478493\n",
      "epoch 125; iter: 0; batch classifier loss: 0.055086; batch adversarial loss: 0.592525\n",
      "epoch 126; iter: 0; batch classifier loss: 0.088860; batch adversarial loss: 0.476969\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029901; batch adversarial loss: 0.429736\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041407; batch adversarial loss: 0.524036\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037473; batch adversarial loss: 0.462149\n",
      "epoch 130; iter: 0; batch classifier loss: 0.063519; batch adversarial loss: 0.489693\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026879; batch adversarial loss: 0.418280\n",
      "epoch 132; iter: 0; batch classifier loss: 0.018917; batch adversarial loss: 0.394815\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034722; batch adversarial loss: 0.469128\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026515; batch adversarial loss: 0.541979\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028241; batch adversarial loss: 0.473106\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041772; batch adversarial loss: 0.511082\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054272; batch adversarial loss: 0.397446\n",
      "epoch 138; iter: 0; batch classifier loss: 0.061799; batch adversarial loss: 0.456642\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040255; batch adversarial loss: 0.376437\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028854; batch adversarial loss: 0.470352\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031848; batch adversarial loss: 0.408620\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039154; batch adversarial loss: 0.407155\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032347; batch adversarial loss: 0.475253\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017250; batch adversarial loss: 0.470645\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040850; batch adversarial loss: 0.494669\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038862; batch adversarial loss: 0.476588\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039160; batch adversarial loss: 0.433832\n",
      "epoch 148; iter: 0; batch classifier loss: 0.069757; batch adversarial loss: 0.391256\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030013; batch adversarial loss: 0.399076\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014087; batch adversarial loss: 0.480641\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034520; batch adversarial loss: 0.394571\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039143; batch adversarial loss: 0.492718\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027454; batch adversarial loss: 0.455720\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019260; batch adversarial loss: 0.424051\n",
      "epoch 155; iter: 0; batch classifier loss: 0.043655; batch adversarial loss: 0.520892\n",
      "epoch 156; iter: 0; batch classifier loss: 0.047860; batch adversarial loss: 0.524725\n",
      "epoch 157; iter: 0; batch classifier loss: 0.054634; batch adversarial loss: 0.416821\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015641; batch adversarial loss: 0.372229\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030565; batch adversarial loss: 0.429430\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016941; batch adversarial loss: 0.491748\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029517; batch adversarial loss: 0.435016\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028199; batch adversarial loss: 0.457815\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038848; batch adversarial loss: 0.477046\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030099; batch adversarial loss: 0.438682\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024291; batch adversarial loss: 0.489781\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027186; batch adversarial loss: 0.452311\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021279; batch adversarial loss: 0.297877\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023018; batch adversarial loss: 0.379423\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040664; batch adversarial loss: 0.425938\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029095; batch adversarial loss: 0.510591\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027033; batch adversarial loss: 0.433726\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028782; batch adversarial loss: 0.400428\n",
      "epoch 173; iter: 0; batch classifier loss: 0.004786; batch adversarial loss: 0.436335\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019837; batch adversarial loss: 0.428577\n",
      "epoch 175; iter: 0; batch classifier loss: 0.065246; batch adversarial loss: 0.434314\n",
      "epoch 176; iter: 0; batch classifier loss: 0.036527; batch adversarial loss: 0.461726\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028478; batch adversarial loss: 0.534059\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007431; batch adversarial loss: 0.462304\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020681; batch adversarial loss: 0.396650\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032390; batch adversarial loss: 0.487994\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014842; batch adversarial loss: 0.479663\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034864; batch adversarial loss: 0.426323\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021555; batch adversarial loss: 0.428107\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037220; batch adversarial loss: 0.528339\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016915; batch adversarial loss: 0.512868\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041123; batch adversarial loss: 0.362159\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035863; batch adversarial loss: 0.495888\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016931; batch adversarial loss: 0.389564\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014824; batch adversarial loss: 0.376844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.064724; batch adversarial loss: 0.394200\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025949; batch adversarial loss: 0.463084\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015028; batch adversarial loss: 0.457048\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017877; batch adversarial loss: 0.480223\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025242; batch adversarial loss: 0.438749\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015525; batch adversarial loss: 0.411618\n",
      "epoch 196; iter: 0; batch classifier loss: 0.040721; batch adversarial loss: 0.431623\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025095; batch adversarial loss: 0.355178\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028212; batch adversarial loss: 0.483560\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035353; batch adversarial loss: 0.335666\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711829; batch adversarial loss: 0.711339\n",
      "epoch 1; iter: 0; batch classifier loss: 0.538729; batch adversarial loss: 0.696010\n",
      "epoch 2; iter: 0; batch classifier loss: 0.408076; batch adversarial loss: 0.676048\n",
      "epoch 3; iter: 0; batch classifier loss: 0.379703; batch adversarial loss: 0.611474\n",
      "epoch 4; iter: 0; batch classifier loss: 0.280547; batch adversarial loss: 0.594193\n",
      "epoch 5; iter: 0; batch classifier loss: 0.257921; batch adversarial loss: 0.565061\n",
      "epoch 6; iter: 0; batch classifier loss: 0.308467; batch adversarial loss: 0.521207\n",
      "epoch 7; iter: 0; batch classifier loss: 0.281699; batch adversarial loss: 0.499873\n",
      "epoch 8; iter: 0; batch classifier loss: 0.231501; batch adversarial loss: 0.488703\n",
      "epoch 9; iter: 0; batch classifier loss: 0.257246; batch adversarial loss: 0.476108\n",
      "epoch 10; iter: 0; batch classifier loss: 0.193122; batch adversarial loss: 0.543694\n",
      "epoch 11; iter: 0; batch classifier loss: 0.211340; batch adversarial loss: 0.455436\n",
      "epoch 12; iter: 0; batch classifier loss: 0.228708; batch adversarial loss: 0.472613\n",
      "epoch 13; iter: 0; batch classifier loss: 0.223810; batch adversarial loss: 0.512825\n",
      "epoch 14; iter: 0; batch classifier loss: 0.213188; batch adversarial loss: 0.449748\n",
      "epoch 15; iter: 0; batch classifier loss: 0.174371; batch adversarial loss: 0.472661\n",
      "epoch 16; iter: 0; batch classifier loss: 0.174474; batch adversarial loss: 0.452064\n",
      "epoch 17; iter: 0; batch classifier loss: 0.174574; batch adversarial loss: 0.453674\n",
      "epoch 18; iter: 0; batch classifier loss: 0.153340; batch adversarial loss: 0.467117\n",
      "epoch 19; iter: 0; batch classifier loss: 0.150642; batch adversarial loss: 0.484858\n",
      "epoch 20; iter: 0; batch classifier loss: 0.162473; batch adversarial loss: 0.427667\n",
      "epoch 21; iter: 0; batch classifier loss: 0.205806; batch adversarial loss: 0.457801\n",
      "epoch 22; iter: 0; batch classifier loss: 0.151168; batch adversarial loss: 0.433750\n",
      "epoch 23; iter: 0; batch classifier loss: 0.134609; batch adversarial loss: 0.466712\n",
      "epoch 24; iter: 0; batch classifier loss: 0.126150; batch adversarial loss: 0.381346\n",
      "epoch 25; iter: 0; batch classifier loss: 0.173468; batch adversarial loss: 0.464570\n",
      "epoch 26; iter: 0; batch classifier loss: 0.136050; batch adversarial loss: 0.453033\n",
      "epoch 27; iter: 0; batch classifier loss: 0.189425; batch adversarial loss: 0.372672\n",
      "epoch 28; iter: 0; batch classifier loss: 0.169172; batch adversarial loss: 0.342743\n",
      "epoch 29; iter: 0; batch classifier loss: 0.096119; batch adversarial loss: 0.455325\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151775; batch adversarial loss: 0.377615\n",
      "epoch 31; iter: 0; batch classifier loss: 0.203386; batch adversarial loss: 0.361254\n",
      "epoch 32; iter: 0; batch classifier loss: 0.151499; batch adversarial loss: 0.397286\n",
      "epoch 33; iter: 0; batch classifier loss: 0.202020; batch adversarial loss: 0.479827\n",
      "epoch 34; iter: 0; batch classifier loss: 0.131533; batch adversarial loss: 0.435804\n",
      "epoch 35; iter: 0; batch classifier loss: 0.102365; batch adversarial loss: 0.378404\n",
      "epoch 36; iter: 0; batch classifier loss: 0.146089; batch adversarial loss: 0.445955\n",
      "epoch 37; iter: 0; batch classifier loss: 0.097963; batch adversarial loss: 0.341692\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117464; batch adversarial loss: 0.418628\n",
      "epoch 39; iter: 0; batch classifier loss: 0.118794; batch adversarial loss: 0.409853\n",
      "epoch 40; iter: 0; batch classifier loss: 0.144757; batch adversarial loss: 0.388121\n",
      "epoch 41; iter: 0; batch classifier loss: 0.139736; batch adversarial loss: 0.473495\n",
      "epoch 42; iter: 0; batch classifier loss: 0.140764; batch adversarial loss: 0.345018\n",
      "epoch 43; iter: 0; batch classifier loss: 0.169045; batch adversarial loss: 0.439626\n",
      "epoch 44; iter: 0; batch classifier loss: 0.151620; batch adversarial loss: 0.392164\n",
      "epoch 45; iter: 0; batch classifier loss: 0.078193; batch adversarial loss: 0.389683\n",
      "epoch 46; iter: 0; batch classifier loss: 0.093025; batch adversarial loss: 0.481843\n",
      "epoch 47; iter: 0; batch classifier loss: 0.071592; batch adversarial loss: 0.402533\n",
      "epoch 48; iter: 0; batch classifier loss: 0.124922; batch adversarial loss: 0.449178\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099863; batch adversarial loss: 0.355788\n",
      "epoch 50; iter: 0; batch classifier loss: 0.110299; batch adversarial loss: 0.391159\n",
      "epoch 51; iter: 0; batch classifier loss: 0.090021; batch adversarial loss: 0.329884\n",
      "epoch 52; iter: 0; batch classifier loss: 0.137614; batch adversarial loss: 0.371690\n",
      "epoch 53; iter: 0; batch classifier loss: 0.081838; batch adversarial loss: 0.408893\n",
      "epoch 54; iter: 0; batch classifier loss: 0.101300; batch adversarial loss: 0.394943\n",
      "epoch 55; iter: 0; batch classifier loss: 0.124225; batch adversarial loss: 0.351615\n",
      "epoch 56; iter: 0; batch classifier loss: 0.110567; batch adversarial loss: 0.357895\n",
      "epoch 57; iter: 0; batch classifier loss: 0.096430; batch adversarial loss: 0.462209\n",
      "epoch 58; iter: 0; batch classifier loss: 0.131798; batch adversarial loss: 0.546623\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099754; batch adversarial loss: 0.393045\n",
      "epoch 60; iter: 0; batch classifier loss: 0.078781; batch adversarial loss: 0.456669\n",
      "epoch 61; iter: 0; batch classifier loss: 0.056379; batch adversarial loss: 0.370264\n",
      "epoch 62; iter: 0; batch classifier loss: 0.076972; batch adversarial loss: 0.413007\n",
      "epoch 63; iter: 0; batch classifier loss: 0.091167; batch adversarial loss: 0.357905\n",
      "epoch 64; iter: 0; batch classifier loss: 0.110997; batch adversarial loss: 0.424715\n",
      "epoch 65; iter: 0; batch classifier loss: 0.101804; batch adversarial loss: 0.430696\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062310; batch adversarial loss: 0.452790\n",
      "epoch 67; iter: 0; batch classifier loss: 0.055283; batch adversarial loss: 0.346488\n",
      "epoch 68; iter: 0; batch classifier loss: 0.054410; batch adversarial loss: 0.460701\n",
      "epoch 69; iter: 0; batch classifier loss: 0.058580; batch adversarial loss: 0.387607\n",
      "epoch 70; iter: 0; batch classifier loss: 0.085715; batch adversarial loss: 0.502517\n",
      "epoch 71; iter: 0; batch classifier loss: 0.110679; batch adversarial loss: 0.389292\n",
      "epoch 72; iter: 0; batch classifier loss: 0.122444; batch adversarial loss: 0.444425\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101264; batch adversarial loss: 0.478838\n",
      "epoch 74; iter: 0; batch classifier loss: 0.073930; batch adversarial loss: 0.480240\n",
      "epoch 75; iter: 0; batch classifier loss: 0.126328; batch adversarial loss: 0.378594\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072273; batch adversarial loss: 0.454051\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069158; batch adversarial loss: 0.392314\n",
      "epoch 78; iter: 0; batch classifier loss: 0.057659; batch adversarial loss: 0.411785\n",
      "epoch 79; iter: 0; batch classifier loss: 0.084568; batch adversarial loss: 0.475708\n",
      "epoch 80; iter: 0; batch classifier loss: 0.077866; batch adversarial loss: 0.364629\n",
      "epoch 81; iter: 0; batch classifier loss: 0.051764; batch adversarial loss: 0.382067\n",
      "epoch 82; iter: 0; batch classifier loss: 0.080521; batch adversarial loss: 0.377782\n",
      "epoch 83; iter: 0; batch classifier loss: 0.096964; batch adversarial loss: 0.418738\n",
      "epoch 84; iter: 0; batch classifier loss: 0.061390; batch adversarial loss: 0.526690\n",
      "epoch 85; iter: 0; batch classifier loss: 0.058310; batch adversarial loss: 0.437691\n",
      "epoch 86; iter: 0; batch classifier loss: 0.032259; batch adversarial loss: 0.483354\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054802; batch adversarial loss: 0.537352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.058719; batch adversarial loss: 0.418316\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057297; batch adversarial loss: 0.391736\n",
      "epoch 90; iter: 0; batch classifier loss: 0.049954; batch adversarial loss: 0.471993\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045779; batch adversarial loss: 0.442614\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062324; batch adversarial loss: 0.402302\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071160; batch adversarial loss: 0.471355\n",
      "epoch 94; iter: 0; batch classifier loss: 0.078239; batch adversarial loss: 0.450934\n",
      "epoch 95; iter: 0; batch classifier loss: 0.076806; batch adversarial loss: 0.455831\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062825; batch adversarial loss: 0.376320\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047852; batch adversarial loss: 0.503070\n",
      "epoch 98; iter: 0; batch classifier loss: 0.070201; batch adversarial loss: 0.332800\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043270; batch adversarial loss: 0.371543\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048284; batch adversarial loss: 0.438387\n",
      "epoch 101; iter: 0; batch classifier loss: 0.030177; batch adversarial loss: 0.442104\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052480; batch adversarial loss: 0.477827\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047267; batch adversarial loss: 0.556235\n",
      "epoch 104; iter: 0; batch classifier loss: 0.013686; batch adversarial loss: 0.464653\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060949; batch adversarial loss: 0.505745\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062292; batch adversarial loss: 0.385482\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051213; batch adversarial loss: 0.416222\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046194; batch adversarial loss: 0.392189\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037527; batch adversarial loss: 0.516041\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051521; batch adversarial loss: 0.454026\n",
      "epoch 111; iter: 0; batch classifier loss: 0.024734; batch adversarial loss: 0.414957\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026710; batch adversarial loss: 0.502050\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025757; batch adversarial loss: 0.429123\n",
      "epoch 114; iter: 0; batch classifier loss: 0.071244; batch adversarial loss: 0.399862\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029949; batch adversarial loss: 0.405369\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044858; batch adversarial loss: 0.529989\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036265; batch adversarial loss: 0.513873\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036068; batch adversarial loss: 0.404776\n",
      "epoch 119; iter: 0; batch classifier loss: 0.080720; batch adversarial loss: 0.505562\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031900; batch adversarial loss: 0.411021\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029201; batch adversarial loss: 0.384157\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035003; batch adversarial loss: 0.591712\n",
      "epoch 123; iter: 0; batch classifier loss: 0.063429; batch adversarial loss: 0.620371\n",
      "epoch 124; iter: 0; batch classifier loss: 0.076824; batch adversarial loss: 0.567659\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050823; batch adversarial loss: 0.485099\n",
      "epoch 126; iter: 0; batch classifier loss: 0.101690; batch adversarial loss: 0.577661\n",
      "epoch 127; iter: 0; batch classifier loss: 0.073734; batch adversarial loss: 0.526429\n",
      "epoch 128; iter: 0; batch classifier loss: 0.110907; batch adversarial loss: 0.598776\n",
      "epoch 129; iter: 0; batch classifier loss: 0.214350; batch adversarial loss: 0.778771\n",
      "epoch 130; iter: 0; batch classifier loss: 0.098502; batch adversarial loss: 0.626285\n",
      "epoch 131; iter: 0; batch classifier loss: 0.167445; batch adversarial loss: 0.671148\n",
      "epoch 132; iter: 0; batch classifier loss: 0.147507; batch adversarial loss: 0.735523\n",
      "epoch 133; iter: 0; batch classifier loss: 0.196224; batch adversarial loss: 0.691348\n",
      "epoch 134; iter: 0; batch classifier loss: 0.136327; batch adversarial loss: 0.617564\n",
      "epoch 135; iter: 0; batch classifier loss: 0.110723; batch adversarial loss: 0.463045\n",
      "epoch 136; iter: 0; batch classifier loss: 0.170215; batch adversarial loss: 0.714110\n",
      "epoch 137; iter: 0; batch classifier loss: 0.128189; batch adversarial loss: 0.561140\n",
      "epoch 138; iter: 0; batch classifier loss: 0.091255; batch adversarial loss: 0.583400\n",
      "epoch 139; iter: 0; batch classifier loss: 0.216313; batch adversarial loss: 0.639773\n",
      "epoch 140; iter: 0; batch classifier loss: 0.191741; batch adversarial loss: 0.636296\n",
      "epoch 141; iter: 0; batch classifier loss: 0.157546; batch adversarial loss: 0.505500\n",
      "epoch 142; iter: 0; batch classifier loss: 0.118115; batch adversarial loss: 0.558669\n",
      "epoch 143; iter: 0; batch classifier loss: 0.115836; batch adversarial loss: 0.511614\n",
      "epoch 144; iter: 0; batch classifier loss: 0.169137; batch adversarial loss: 0.657125\n",
      "epoch 145; iter: 0; batch classifier loss: 0.139351; batch adversarial loss: 0.559685\n",
      "epoch 146; iter: 0; batch classifier loss: 0.194937; batch adversarial loss: 0.648261\n",
      "epoch 147; iter: 0; batch classifier loss: 0.150403; batch adversarial loss: 0.659805\n",
      "epoch 148; iter: 0; batch classifier loss: 0.170117; batch adversarial loss: 0.611512\n",
      "epoch 149; iter: 0; batch classifier loss: 0.125933; batch adversarial loss: 0.500159\n",
      "epoch 150; iter: 0; batch classifier loss: 0.215104; batch adversarial loss: 0.617384\n",
      "epoch 151; iter: 0; batch classifier loss: 0.128450; batch adversarial loss: 0.520729\n",
      "epoch 152; iter: 0; batch classifier loss: 0.116666; batch adversarial loss: 0.551310\n",
      "epoch 153; iter: 0; batch classifier loss: 0.219060; batch adversarial loss: 0.679820\n",
      "epoch 154; iter: 0; batch classifier loss: 0.132844; batch adversarial loss: 0.478563\n",
      "epoch 155; iter: 0; batch classifier loss: 0.137020; batch adversarial loss: 0.550954\n",
      "epoch 156; iter: 0; batch classifier loss: 0.075159; batch adversarial loss: 0.425433\n",
      "epoch 157; iter: 0; batch classifier loss: 0.167654; batch adversarial loss: 0.586547\n",
      "epoch 158; iter: 0; batch classifier loss: 0.145833; batch adversarial loss: 0.533323\n",
      "epoch 159; iter: 0; batch classifier loss: 0.116964; batch adversarial loss: 0.580408\n",
      "epoch 160; iter: 0; batch classifier loss: 0.166946; batch adversarial loss: 0.510312\n",
      "epoch 161; iter: 0; batch classifier loss: 0.145012; batch adversarial loss: 0.561514\n",
      "epoch 162; iter: 0; batch classifier loss: 0.192425; batch adversarial loss: 0.552572\n",
      "epoch 163; iter: 0; batch classifier loss: 0.143271; batch adversarial loss: 0.463858\n",
      "epoch 164; iter: 0; batch classifier loss: 0.112087; batch adversarial loss: 0.465961\n",
      "epoch 165; iter: 0; batch classifier loss: 0.081988; batch adversarial loss: 0.471539\n",
      "epoch 166; iter: 0; batch classifier loss: 0.135436; batch adversarial loss: 0.475684\n",
      "epoch 167; iter: 0; batch classifier loss: 0.139155; batch adversarial loss: 0.532403\n",
      "epoch 168; iter: 0; batch classifier loss: 0.141171; batch adversarial loss: 0.424143\n",
      "epoch 169; iter: 0; batch classifier loss: 0.071133; batch adversarial loss: 0.346520\n",
      "epoch 170; iter: 0; batch classifier loss: 0.173959; batch adversarial loss: 0.589403\n",
      "epoch 171; iter: 0; batch classifier loss: 0.100463; batch adversarial loss: 0.398788\n",
      "epoch 172; iter: 0; batch classifier loss: 0.148118; batch adversarial loss: 0.318101\n",
      "epoch 173; iter: 0; batch classifier loss: 0.052733; batch adversarial loss: 0.443496\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018451; batch adversarial loss: 0.434608\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041887; batch adversarial loss: 0.445463\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017315; batch adversarial loss: 0.443172\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032748; batch adversarial loss: 0.488749\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015183; batch adversarial loss: 0.489657\n",
      "epoch 179; iter: 0; batch classifier loss: 0.052986; batch adversarial loss: 0.491165\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031046; batch adversarial loss: 0.375739\n",
      "epoch 181; iter: 0; batch classifier loss: 0.062558; batch adversarial loss: 0.433446\n",
      "epoch 182; iter: 0; batch classifier loss: 0.039479; batch adversarial loss: 0.470663\n",
      "epoch 183; iter: 0; batch classifier loss: 0.051586; batch adversarial loss: 0.431625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.067887; batch adversarial loss: 0.473689\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033756; batch adversarial loss: 0.449565\n",
      "epoch 186; iter: 0; batch classifier loss: 0.056045; batch adversarial loss: 0.530952\n",
      "epoch 187; iter: 0; batch classifier loss: 0.052535; batch adversarial loss: 0.425289\n",
      "epoch 188; iter: 0; batch classifier loss: 0.059343; batch adversarial loss: 0.450013\n",
      "epoch 189; iter: 0; batch classifier loss: 0.064295; batch adversarial loss: 0.438171\n",
      "epoch 190; iter: 0; batch classifier loss: 0.072925; batch adversarial loss: 0.423684\n",
      "epoch 191; iter: 0; batch classifier loss: 0.080713; batch adversarial loss: 0.372113\n",
      "epoch 192; iter: 0; batch classifier loss: 0.092145; batch adversarial loss: 0.522680\n",
      "epoch 193; iter: 0; batch classifier loss: 0.085200; batch adversarial loss: 0.590509\n",
      "epoch 194; iter: 0; batch classifier loss: 0.070674; batch adversarial loss: 0.394691\n",
      "epoch 195; iter: 0; batch classifier loss: 0.049752; batch adversarial loss: 0.414334\n",
      "epoch 196; iter: 0; batch classifier loss: 0.070468; batch adversarial loss: 0.465630\n",
      "epoch 197; iter: 0; batch classifier loss: 0.064597; batch adversarial loss: 0.418795\n",
      "epoch 198; iter: 0; batch classifier loss: 0.083119; batch adversarial loss: 0.442315\n",
      "epoch 199; iter: 0; batch classifier loss: 0.064658; batch adversarial loss: 0.569025\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703899; batch adversarial loss: 1.026410\n",
      "epoch 1; iter: 0; batch classifier loss: 0.805503; batch adversarial loss: 1.244043\n",
      "epoch 2; iter: 0; batch classifier loss: 1.064939; batch adversarial loss: 1.297592\n",
      "epoch 3; iter: 0; batch classifier loss: 1.150462; batch adversarial loss: 1.216642\n",
      "epoch 4; iter: 0; batch classifier loss: 1.182945; batch adversarial loss: 1.112860\n",
      "epoch 5; iter: 0; batch classifier loss: 0.961618; batch adversarial loss: 0.939103\n",
      "epoch 6; iter: 0; batch classifier loss: 0.881934; batch adversarial loss: 0.848962\n",
      "epoch 7; iter: 0; batch classifier loss: 0.946161; batch adversarial loss: 0.806195\n",
      "epoch 8; iter: 0; batch classifier loss: 0.835989; batch adversarial loss: 0.789570\n",
      "epoch 9; iter: 0; batch classifier loss: 0.724710; batch adversarial loss: 0.708570\n",
      "epoch 10; iter: 0; batch classifier loss: 0.720342; batch adversarial loss: 0.635748\n",
      "epoch 11; iter: 0; batch classifier loss: 0.532038; batch adversarial loss: 0.586777\n",
      "epoch 12; iter: 0; batch classifier loss: 0.577148; batch adversarial loss: 0.579468\n",
      "epoch 13; iter: 0; batch classifier loss: 0.498668; batch adversarial loss: 0.608740\n",
      "epoch 14; iter: 0; batch classifier loss: 0.335232; batch adversarial loss: 0.510872\n",
      "epoch 15; iter: 0; batch classifier loss: 0.340811; batch adversarial loss: 0.516031\n",
      "epoch 16; iter: 0; batch classifier loss: 0.337235; batch adversarial loss: 0.474720\n",
      "epoch 17; iter: 0; batch classifier loss: 0.253087; batch adversarial loss: 0.467391\n",
      "epoch 18; iter: 0; batch classifier loss: 0.276039; batch adversarial loss: 0.496628\n",
      "epoch 19; iter: 0; batch classifier loss: 0.247156; batch adversarial loss: 0.495809\n",
      "epoch 20; iter: 0; batch classifier loss: 0.266344; batch adversarial loss: 0.473899\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202608; batch adversarial loss: 0.541150\n",
      "epoch 22; iter: 0; batch classifier loss: 0.201304; batch adversarial loss: 0.473186\n",
      "epoch 23; iter: 0; batch classifier loss: 0.201408; batch adversarial loss: 0.523943\n",
      "epoch 24; iter: 0; batch classifier loss: 0.225929; batch adversarial loss: 0.508070\n",
      "epoch 25; iter: 0; batch classifier loss: 0.190666; batch adversarial loss: 0.430759\n",
      "epoch 26; iter: 0; batch classifier loss: 0.164581; batch adversarial loss: 0.456164\n",
      "epoch 27; iter: 0; batch classifier loss: 0.139008; batch adversarial loss: 0.515931\n",
      "epoch 28; iter: 0; batch classifier loss: 0.193592; batch adversarial loss: 0.463346\n",
      "epoch 29; iter: 0; batch classifier loss: 0.158139; batch adversarial loss: 0.488396\n",
      "epoch 30; iter: 0; batch classifier loss: 0.185544; batch adversarial loss: 0.478449\n",
      "epoch 31; iter: 0; batch classifier loss: 0.133648; batch adversarial loss: 0.454638\n",
      "epoch 32; iter: 0; batch classifier loss: 0.182946; batch adversarial loss: 0.463921\n",
      "epoch 33; iter: 0; batch classifier loss: 0.201845; batch adversarial loss: 0.479826\n",
      "epoch 34; iter: 0; batch classifier loss: 0.139155; batch adversarial loss: 0.426051\n",
      "epoch 35; iter: 0; batch classifier loss: 0.173001; batch adversarial loss: 0.439541\n",
      "epoch 36; iter: 0; batch classifier loss: 0.135022; batch adversarial loss: 0.505818\n",
      "epoch 37; iter: 0; batch classifier loss: 0.140373; batch adversarial loss: 0.398088\n",
      "epoch 38; iter: 0; batch classifier loss: 0.129385; batch adversarial loss: 0.444410\n",
      "epoch 39; iter: 0; batch classifier loss: 0.123220; batch adversarial loss: 0.483205\n",
      "epoch 40; iter: 0; batch classifier loss: 0.166073; batch adversarial loss: 0.470795\n",
      "epoch 41; iter: 0; batch classifier loss: 0.156745; batch adversarial loss: 0.434444\n",
      "epoch 42; iter: 0; batch classifier loss: 0.178407; batch adversarial loss: 0.460992\n",
      "epoch 43; iter: 0; batch classifier loss: 0.161314; batch adversarial loss: 0.467559\n",
      "epoch 44; iter: 0; batch classifier loss: 0.113449; batch adversarial loss: 0.415843\n",
      "epoch 45; iter: 0; batch classifier loss: 0.181516; batch adversarial loss: 0.364608\n",
      "epoch 46; iter: 0; batch classifier loss: 0.119190; batch adversarial loss: 0.445767\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114326; batch adversarial loss: 0.449038\n",
      "epoch 48; iter: 0; batch classifier loss: 0.176777; batch adversarial loss: 0.403468\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101170; batch adversarial loss: 0.405184\n",
      "epoch 50; iter: 0; batch classifier loss: 0.090739; batch adversarial loss: 0.551085\n",
      "epoch 51; iter: 0; batch classifier loss: 0.085809; batch adversarial loss: 0.404593\n",
      "epoch 52; iter: 0; batch classifier loss: 0.138293; batch adversarial loss: 0.433908\n",
      "epoch 53; iter: 0; batch classifier loss: 0.114082; batch adversarial loss: 0.470992\n",
      "epoch 54; iter: 0; batch classifier loss: 0.130469; batch adversarial loss: 0.398748\n",
      "epoch 55; iter: 0; batch classifier loss: 0.115513; batch adversarial loss: 0.370084\n",
      "epoch 56; iter: 0; batch classifier loss: 0.114388; batch adversarial loss: 0.437622\n",
      "epoch 57; iter: 0; batch classifier loss: 0.106495; batch adversarial loss: 0.538407\n",
      "epoch 58; iter: 0; batch classifier loss: 0.152888; batch adversarial loss: 0.454142\n",
      "epoch 59; iter: 0; batch classifier loss: 0.116574; batch adversarial loss: 0.360900\n",
      "epoch 60; iter: 0; batch classifier loss: 0.093375; batch adversarial loss: 0.461188\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114537; batch adversarial loss: 0.358911\n",
      "epoch 62; iter: 0; batch classifier loss: 0.158049; batch adversarial loss: 0.488063\n",
      "epoch 63; iter: 0; batch classifier loss: 0.125082; batch adversarial loss: 0.387055\n",
      "epoch 64; iter: 0; batch classifier loss: 0.135587; batch adversarial loss: 0.474576\n",
      "epoch 65; iter: 0; batch classifier loss: 0.097041; batch adversarial loss: 0.322688\n",
      "epoch 66; iter: 0; batch classifier loss: 0.109970; batch adversarial loss: 0.452786\n",
      "epoch 67; iter: 0; batch classifier loss: 0.111262; batch adversarial loss: 0.533908\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081859; batch adversarial loss: 0.490577\n",
      "epoch 69; iter: 0; batch classifier loss: 0.130737; batch adversarial loss: 0.433930\n",
      "epoch 70; iter: 0; batch classifier loss: 0.101685; batch adversarial loss: 0.391287\n",
      "epoch 71; iter: 0; batch classifier loss: 0.081284; batch adversarial loss: 0.581667\n",
      "epoch 72; iter: 0; batch classifier loss: 0.067866; batch adversarial loss: 0.432780\n",
      "epoch 73; iter: 0; batch classifier loss: 0.058014; batch adversarial loss: 0.507174\n",
      "epoch 74; iter: 0; batch classifier loss: 0.085913; batch adversarial loss: 0.435539\n",
      "epoch 75; iter: 0; batch classifier loss: 0.118048; batch adversarial loss: 0.520363\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064697; batch adversarial loss: 0.514540\n",
      "epoch 77; iter: 0; batch classifier loss: 0.122442; batch adversarial loss: 0.429146\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054629; batch adversarial loss: 0.494281\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063416; batch adversarial loss: 0.431814\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054995; batch adversarial loss: 0.450353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.115030; batch adversarial loss: 0.397640\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074454; batch adversarial loss: 0.606811\n",
      "epoch 83; iter: 0; batch classifier loss: 0.107559; batch adversarial loss: 0.473439\n",
      "epoch 84; iter: 0; batch classifier loss: 0.078726; batch adversarial loss: 0.465183\n",
      "epoch 85; iter: 0; batch classifier loss: 0.089695; batch adversarial loss: 0.483357\n",
      "epoch 86; iter: 0; batch classifier loss: 0.122047; batch adversarial loss: 0.502806\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073976; batch adversarial loss: 0.490738\n",
      "epoch 88; iter: 0; batch classifier loss: 0.048820; batch adversarial loss: 0.562741\n",
      "epoch 89; iter: 0; batch classifier loss: 0.095574; batch adversarial loss: 0.426994\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066993; batch adversarial loss: 0.457137\n",
      "epoch 91; iter: 0; batch classifier loss: 0.034707; batch adversarial loss: 0.456265\n",
      "epoch 92; iter: 0; batch classifier loss: 0.104563; batch adversarial loss: 0.394840\n",
      "epoch 93; iter: 0; batch classifier loss: 0.088429; batch adversarial loss: 0.437212\n",
      "epoch 94; iter: 0; batch classifier loss: 0.059307; batch adversarial loss: 0.509445\n",
      "epoch 95; iter: 0; batch classifier loss: 0.101553; batch adversarial loss: 0.339478\n",
      "epoch 96; iter: 0; batch classifier loss: 0.060524; batch adversarial loss: 0.455675\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072229; batch adversarial loss: 0.470372\n",
      "epoch 98; iter: 0; batch classifier loss: 0.117795; batch adversarial loss: 0.412951\n",
      "epoch 99; iter: 0; batch classifier loss: 0.085166; batch adversarial loss: 0.433330\n",
      "epoch 100; iter: 0; batch classifier loss: 0.135493; batch adversarial loss: 0.485143\n",
      "epoch 101; iter: 0; batch classifier loss: 0.094071; batch adversarial loss: 0.476885\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068650; batch adversarial loss: 0.518891\n",
      "epoch 103; iter: 0; batch classifier loss: 0.065814; batch adversarial loss: 0.446174\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050266; batch adversarial loss: 0.551966\n",
      "epoch 105; iter: 0; batch classifier loss: 0.108225; batch adversarial loss: 0.486317\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042316; batch adversarial loss: 0.548508\n",
      "epoch 107; iter: 0; batch classifier loss: 0.092325; batch adversarial loss: 0.422881\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048534; batch adversarial loss: 0.424749\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030986; batch adversarial loss: 0.430910\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061654; batch adversarial loss: 0.450512\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058004; batch adversarial loss: 0.434305\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054712; batch adversarial loss: 0.464111\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043012; batch adversarial loss: 0.487433\n",
      "epoch 114; iter: 0; batch classifier loss: 0.095422; batch adversarial loss: 0.442628\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051510; batch adversarial loss: 0.510728\n",
      "epoch 116; iter: 0; batch classifier loss: 0.068723; batch adversarial loss: 0.663009\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049853; batch adversarial loss: 0.416422\n",
      "epoch 118; iter: 0; batch classifier loss: 0.073257; batch adversarial loss: 0.532263\n",
      "epoch 119; iter: 0; batch classifier loss: 0.058721; batch adversarial loss: 0.436563\n",
      "epoch 120; iter: 0; batch classifier loss: 0.066741; batch adversarial loss: 0.497512\n",
      "epoch 121; iter: 0; batch classifier loss: 0.064823; batch adversarial loss: 0.372452\n",
      "epoch 122; iter: 0; batch classifier loss: 0.058023; batch adversarial loss: 0.504130\n",
      "epoch 123; iter: 0; batch classifier loss: 0.073109; batch adversarial loss: 0.453468\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027212; batch adversarial loss: 0.452240\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058615; batch adversarial loss: 0.384546\n",
      "epoch 126; iter: 0; batch classifier loss: 0.080019; batch adversarial loss: 0.424971\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036651; batch adversarial loss: 0.548108\n",
      "epoch 128; iter: 0; batch classifier loss: 0.061119; batch adversarial loss: 0.462401\n",
      "epoch 129; iter: 0; batch classifier loss: 0.104986; batch adversarial loss: 0.397386\n",
      "epoch 130; iter: 0; batch classifier loss: 0.077309; batch adversarial loss: 0.457046\n",
      "epoch 131; iter: 0; batch classifier loss: 0.108405; batch adversarial loss: 0.502261\n",
      "epoch 132; iter: 0; batch classifier loss: 0.065655; batch adversarial loss: 0.461299\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035967; batch adversarial loss: 0.407067\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051370; batch adversarial loss: 0.502594\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023084; batch adversarial loss: 0.525067\n",
      "epoch 136; iter: 0; batch classifier loss: 0.058547; batch adversarial loss: 0.466569\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044466; batch adversarial loss: 0.440817\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041332; batch adversarial loss: 0.492227\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042927; batch adversarial loss: 0.480198\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038297; batch adversarial loss: 0.392078\n",
      "epoch 141; iter: 0; batch classifier loss: 0.050638; batch adversarial loss: 0.434358\n",
      "epoch 142; iter: 0; batch classifier loss: 0.076014; batch adversarial loss: 0.417689\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025553; batch adversarial loss: 0.408208\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037717; batch adversarial loss: 0.446855\n",
      "epoch 145; iter: 0; batch classifier loss: 0.074907; batch adversarial loss: 0.609884\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045214; batch adversarial loss: 0.484400\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043844; batch adversarial loss: 0.455803\n",
      "epoch 148; iter: 0; batch classifier loss: 0.060488; batch adversarial loss: 0.406158\n",
      "epoch 149; iter: 0; batch classifier loss: 0.055566; batch adversarial loss: 0.448167\n",
      "epoch 150; iter: 0; batch classifier loss: 0.046761; batch adversarial loss: 0.440846\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042573; batch adversarial loss: 0.445632\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036736; batch adversarial loss: 0.458652\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012944; batch adversarial loss: 0.476126\n",
      "epoch 154; iter: 0; batch classifier loss: 0.067461; batch adversarial loss: 0.456043\n",
      "epoch 155; iter: 0; batch classifier loss: 0.066783; batch adversarial loss: 0.425874\n",
      "epoch 156; iter: 0; batch classifier loss: 0.053551; batch adversarial loss: 0.494006\n",
      "epoch 157; iter: 0; batch classifier loss: 0.047950; batch adversarial loss: 0.496996\n",
      "epoch 158; iter: 0; batch classifier loss: 0.064027; batch adversarial loss: 0.474798\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025072; batch adversarial loss: 0.452267\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035844; batch adversarial loss: 0.451705\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034987; batch adversarial loss: 0.375328\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036965; batch adversarial loss: 0.457456\n",
      "epoch 163; iter: 0; batch classifier loss: 0.047617; batch adversarial loss: 0.384757\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031415; batch adversarial loss: 0.418797\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031011; batch adversarial loss: 0.434184\n",
      "epoch 166; iter: 0; batch classifier loss: 0.048626; batch adversarial loss: 0.518994\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024121; batch adversarial loss: 0.441274\n",
      "epoch 168; iter: 0; batch classifier loss: 0.039667; batch adversarial loss: 0.395888\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025735; batch adversarial loss: 0.549911\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028672; batch adversarial loss: 0.546075\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040877; batch adversarial loss: 0.441624\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027173; batch adversarial loss: 0.445180\n",
      "epoch 173; iter: 0; batch classifier loss: 0.003096; batch adversarial loss: 0.475575\n",
      "epoch 174; iter: 0; batch classifier loss: 0.048015; batch adversarial loss: 0.373861\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037182; batch adversarial loss: 0.456708\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031189; batch adversarial loss: 0.524817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.064076; batch adversarial loss: 0.424284\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023600; batch adversarial loss: 0.465908\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011038; batch adversarial loss: 0.387320\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030473; batch adversarial loss: 0.498071\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027227; batch adversarial loss: 0.449313\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019698; batch adversarial loss: 0.431383\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017760; batch adversarial loss: 0.437082\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028906; batch adversarial loss: 0.514773\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016700; batch adversarial loss: 0.455389\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028805; batch adversarial loss: 0.437518\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016331; batch adversarial loss: 0.458465\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015446; batch adversarial loss: 0.416790\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025806; batch adversarial loss: 0.471392\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015916; batch adversarial loss: 0.458290\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016184; batch adversarial loss: 0.460414\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020806; batch adversarial loss: 0.544969\n",
      "epoch 193; iter: 0; batch classifier loss: 0.053180; batch adversarial loss: 0.379572\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016059; batch adversarial loss: 0.453615\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030902; batch adversarial loss: 0.450010\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007994; batch adversarial loss: 0.415493\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024543; batch adversarial loss: 0.508631\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029346; batch adversarial loss: 0.479362\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030334; batch adversarial loss: 0.537212\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716880; batch adversarial loss: 0.711542\n",
      "epoch 1; iter: 0; batch classifier loss: 0.461675; batch adversarial loss: 0.667631\n",
      "epoch 2; iter: 0; batch classifier loss: 0.366768; batch adversarial loss: 0.647771\n",
      "epoch 3; iter: 0; batch classifier loss: 0.513808; batch adversarial loss: 0.603602\n",
      "epoch 4; iter: 0; batch classifier loss: 0.356486; batch adversarial loss: 0.613651\n",
      "epoch 5; iter: 0; batch classifier loss: 0.428929; batch adversarial loss: 0.571592\n",
      "epoch 6; iter: 0; batch classifier loss: 0.366153; batch adversarial loss: 0.592993\n",
      "epoch 7; iter: 0; batch classifier loss: 0.378819; batch adversarial loss: 0.571115\n",
      "epoch 8; iter: 0; batch classifier loss: 0.463824; batch adversarial loss: 0.530533\n",
      "epoch 9; iter: 0; batch classifier loss: 0.403400; batch adversarial loss: 0.554717\n",
      "epoch 10; iter: 0; batch classifier loss: 0.369496; batch adversarial loss: 0.541479\n",
      "epoch 11; iter: 0; batch classifier loss: 0.344122; batch adversarial loss: 0.542834\n",
      "epoch 12; iter: 0; batch classifier loss: 0.299248; batch adversarial loss: 0.535467\n",
      "epoch 13; iter: 0; batch classifier loss: 0.439605; batch adversarial loss: 0.485664\n",
      "epoch 14; iter: 0; batch classifier loss: 0.309599; batch adversarial loss: 0.512030\n",
      "epoch 15; iter: 0; batch classifier loss: 0.457275; batch adversarial loss: 0.452964\n",
      "epoch 16; iter: 0; batch classifier loss: 0.382253; batch adversarial loss: 0.530017\n",
      "epoch 17; iter: 0; batch classifier loss: 0.364862; batch adversarial loss: 0.463772\n",
      "epoch 18; iter: 0; batch classifier loss: 0.329603; batch adversarial loss: 0.497528\n",
      "epoch 19; iter: 0; batch classifier loss: 0.379034; batch adversarial loss: 0.462494\n",
      "epoch 20; iter: 0; batch classifier loss: 0.287619; batch adversarial loss: 0.459015\n",
      "epoch 21; iter: 0; batch classifier loss: 0.282327; batch adversarial loss: 0.490831\n",
      "epoch 22; iter: 0; batch classifier loss: 0.263700; batch adversarial loss: 0.424870\n",
      "epoch 23; iter: 0; batch classifier loss: 0.294111; batch adversarial loss: 0.484128\n",
      "epoch 24; iter: 0; batch classifier loss: 0.315247; batch adversarial loss: 0.426934\n",
      "epoch 25; iter: 0; batch classifier loss: 0.279177; batch adversarial loss: 0.545793\n",
      "epoch 26; iter: 0; batch classifier loss: 0.217936; batch adversarial loss: 0.485118\n",
      "epoch 27; iter: 0; batch classifier loss: 0.283116; batch adversarial loss: 0.481088\n",
      "epoch 28; iter: 0; batch classifier loss: 0.273160; batch adversarial loss: 0.410489\n",
      "epoch 29; iter: 0; batch classifier loss: 0.237281; batch adversarial loss: 0.410588\n",
      "epoch 30; iter: 0; batch classifier loss: 0.173696; batch adversarial loss: 0.464583\n",
      "epoch 31; iter: 0; batch classifier loss: 0.211004; batch adversarial loss: 0.505601\n",
      "epoch 32; iter: 0; batch classifier loss: 0.210778; batch adversarial loss: 0.404840\n",
      "epoch 33; iter: 0; batch classifier loss: 0.244285; batch adversarial loss: 0.395821\n",
      "epoch 34; iter: 0; batch classifier loss: 0.223856; batch adversarial loss: 0.461588\n",
      "epoch 35; iter: 0; batch classifier loss: 0.193037; batch adversarial loss: 0.486175\n",
      "epoch 36; iter: 0; batch classifier loss: 0.236172; batch adversarial loss: 0.436950\n",
      "epoch 37; iter: 0; batch classifier loss: 0.209873; batch adversarial loss: 0.482352\n",
      "epoch 38; iter: 0; batch classifier loss: 0.234917; batch adversarial loss: 0.420699\n",
      "epoch 39; iter: 0; batch classifier loss: 0.180232; batch adversarial loss: 0.473286\n",
      "epoch 40; iter: 0; batch classifier loss: 0.192197; batch adversarial loss: 0.448447\n",
      "epoch 41; iter: 0; batch classifier loss: 0.245508; batch adversarial loss: 0.478298\n",
      "epoch 42; iter: 0; batch classifier loss: 0.230549; batch adversarial loss: 0.541135\n",
      "epoch 43; iter: 0; batch classifier loss: 0.276687; batch adversarial loss: 0.460376\n",
      "epoch 44; iter: 0; batch classifier loss: 0.235017; batch adversarial loss: 0.460700\n",
      "epoch 45; iter: 0; batch classifier loss: 0.183965; batch adversarial loss: 0.448320\n",
      "epoch 46; iter: 0; batch classifier loss: 0.224099; batch adversarial loss: 0.472154\n",
      "epoch 47; iter: 0; batch classifier loss: 0.196186; batch adversarial loss: 0.483511\n",
      "epoch 48; iter: 0; batch classifier loss: 0.164522; batch adversarial loss: 0.457986\n",
      "epoch 49; iter: 0; batch classifier loss: 0.216050; batch adversarial loss: 0.471644\n",
      "epoch 50; iter: 0; batch classifier loss: 0.294264; batch adversarial loss: 0.388532\n",
      "epoch 51; iter: 0; batch classifier loss: 0.140627; batch adversarial loss: 0.448414\n",
      "epoch 52; iter: 0; batch classifier loss: 0.148125; batch adversarial loss: 0.423099\n",
      "epoch 53; iter: 0; batch classifier loss: 0.207895; batch adversarial loss: 0.554773\n",
      "epoch 54; iter: 0; batch classifier loss: 0.125760; batch adversarial loss: 0.398102\n",
      "epoch 55; iter: 0; batch classifier loss: 0.187894; batch adversarial loss: 0.352444\n",
      "epoch 56; iter: 0; batch classifier loss: 0.212931; batch adversarial loss: 0.388307\n",
      "epoch 57; iter: 0; batch classifier loss: 0.124910; batch adversarial loss: 0.458462\n",
      "epoch 58; iter: 0; batch classifier loss: 0.129527; batch adversarial loss: 0.494505\n",
      "epoch 59; iter: 0; batch classifier loss: 0.228144; batch adversarial loss: 0.494773\n",
      "epoch 60; iter: 0; batch classifier loss: 0.147506; batch adversarial loss: 0.544337\n",
      "epoch 61; iter: 0; batch classifier loss: 0.120392; batch adversarial loss: 0.481540\n",
      "epoch 62; iter: 0; batch classifier loss: 0.131896; batch adversarial loss: 0.483486\n",
      "epoch 63; iter: 0; batch classifier loss: 0.209503; batch adversarial loss: 0.469438\n",
      "epoch 64; iter: 0; batch classifier loss: 0.198348; batch adversarial loss: 0.375180\n",
      "epoch 65; iter: 0; batch classifier loss: 0.176992; batch adversarial loss: 0.423733\n",
      "epoch 66; iter: 0; batch classifier loss: 0.154000; batch adversarial loss: 0.484631\n",
      "epoch 67; iter: 0; batch classifier loss: 0.146330; batch adversarial loss: 0.410071\n",
      "epoch 68; iter: 0; batch classifier loss: 0.180805; batch adversarial loss: 0.470317\n",
      "epoch 69; iter: 0; batch classifier loss: 0.142498; batch adversarial loss: 0.446896\n",
      "epoch 70; iter: 0; batch classifier loss: 0.114194; batch adversarial loss: 0.422536\n",
      "epoch 71; iter: 0; batch classifier loss: 0.193991; batch adversarial loss: 0.422438\n",
      "epoch 72; iter: 0; batch classifier loss: 0.125106; batch adversarial loss: 0.553474\n",
      "epoch 73; iter: 0; batch classifier loss: 0.195693; batch adversarial loss: 0.422531\n",
      "epoch 74; iter: 0; batch classifier loss: 0.149939; batch adversarial loss: 0.458849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.171460; batch adversarial loss: 0.434828\n",
      "epoch 76; iter: 0; batch classifier loss: 0.212725; batch adversarial loss: 0.470933\n",
      "epoch 77; iter: 0; batch classifier loss: 0.138567; batch adversarial loss: 0.398762\n",
      "epoch 78; iter: 0; batch classifier loss: 0.129561; batch adversarial loss: 0.436403\n",
      "epoch 79; iter: 0; batch classifier loss: 0.149994; batch adversarial loss: 0.301196\n",
      "epoch 80; iter: 0; batch classifier loss: 0.183513; batch adversarial loss: 0.386446\n",
      "epoch 81; iter: 0; batch classifier loss: 0.127203; batch adversarial loss: 0.554493\n",
      "epoch 82; iter: 0; batch classifier loss: 0.148161; batch adversarial loss: 0.397555\n",
      "epoch 83; iter: 0; batch classifier loss: 0.106256; batch adversarial loss: 0.509007\n",
      "epoch 84; iter: 0; batch classifier loss: 0.106726; batch adversarial loss: 0.495025\n",
      "epoch 85; iter: 0; batch classifier loss: 0.110775; batch adversarial loss: 0.432553\n",
      "epoch 86; iter: 0; batch classifier loss: 0.177707; batch adversarial loss: 0.383529\n",
      "epoch 87; iter: 0; batch classifier loss: 0.078778; batch adversarial loss: 0.471216\n",
      "epoch 88; iter: 0; batch classifier loss: 0.183788; batch adversarial loss: 0.536247\n",
      "epoch 89; iter: 0; batch classifier loss: 0.076809; batch adversarial loss: 0.492033\n",
      "epoch 90; iter: 0; batch classifier loss: 0.093514; batch adversarial loss: 0.526904\n",
      "epoch 91; iter: 0; batch classifier loss: 0.079203; batch adversarial loss: 0.552931\n",
      "epoch 92; iter: 0; batch classifier loss: 0.140313; batch adversarial loss: 0.432720\n",
      "epoch 93; iter: 0; batch classifier loss: 0.094588; batch adversarial loss: 0.481351\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048147; batch adversarial loss: 0.463868\n",
      "epoch 95; iter: 0; batch classifier loss: 0.099550; batch adversarial loss: 0.446028\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058383; batch adversarial loss: 0.566263\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073897; batch adversarial loss: 0.480433\n",
      "epoch 98; iter: 0; batch classifier loss: 0.084681; batch adversarial loss: 0.580954\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058586; batch adversarial loss: 0.425167\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043018; batch adversarial loss: 0.437328\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043224; batch adversarial loss: 0.578158\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053356; batch adversarial loss: 0.465244\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035457; batch adversarial loss: 0.348456\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059529; batch adversarial loss: 0.486995\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076115; batch adversarial loss: 0.458777\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053358; batch adversarial loss: 0.421786\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059702; batch adversarial loss: 0.537672\n",
      "epoch 108; iter: 0; batch classifier loss: 0.080057; batch adversarial loss: 0.459784\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048063; batch adversarial loss: 0.370141\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040411; batch adversarial loss: 0.442253\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036661; batch adversarial loss: 0.481025\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053360; batch adversarial loss: 0.420707\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053467; batch adversarial loss: 0.446732\n",
      "epoch 114; iter: 0; batch classifier loss: 0.019739; batch adversarial loss: 0.487343\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050899; batch adversarial loss: 0.383028\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048441; batch adversarial loss: 0.421822\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031608; batch adversarial loss: 0.379806\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031933; batch adversarial loss: 0.448218\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035001; batch adversarial loss: 0.554178\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032423; batch adversarial loss: 0.343687\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046958; batch adversarial loss: 0.534364\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028596; batch adversarial loss: 0.416546\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030694; batch adversarial loss: 0.511309\n",
      "epoch 124; iter: 0; batch classifier loss: 0.013979; batch adversarial loss: 0.381149\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062390; batch adversarial loss: 0.493060\n",
      "epoch 126; iter: 0; batch classifier loss: 0.081662; batch adversarial loss: 0.413455\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023076; batch adversarial loss: 0.413627\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021319; batch adversarial loss: 0.425650\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016058; batch adversarial loss: 0.430180\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016070; batch adversarial loss: 0.436002\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030000; batch adversarial loss: 0.426783\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039161; batch adversarial loss: 0.340060\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028551; batch adversarial loss: 0.467537\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043346; batch adversarial loss: 0.461619\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026423; batch adversarial loss: 0.498988\n",
      "epoch 136; iter: 0; batch classifier loss: 0.050231; batch adversarial loss: 0.533784\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035152; batch adversarial loss: 0.465790\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028881; batch adversarial loss: 0.489318\n",
      "epoch 139; iter: 0; batch classifier loss: 0.055858; batch adversarial loss: 0.434197\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025685; batch adversarial loss: 0.475465\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035074; batch adversarial loss: 0.439549\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036973; batch adversarial loss: 0.451845\n",
      "epoch 143; iter: 0; batch classifier loss: 0.012518; batch adversarial loss: 0.425912\n",
      "epoch 144; iter: 0; batch classifier loss: 0.044575; batch adversarial loss: 0.522200\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015941; batch adversarial loss: 0.448495\n",
      "epoch 146; iter: 0; batch classifier loss: 0.012774; batch adversarial loss: 0.580690\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038268; batch adversarial loss: 0.359093\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029529; batch adversarial loss: 0.492731\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044768; batch adversarial loss: 0.491061\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016435; batch adversarial loss: 0.413804\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018324; batch adversarial loss: 0.515558\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019618; batch adversarial loss: 0.412454\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021590; batch adversarial loss: 0.442435\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033866; batch adversarial loss: 0.432643\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015973; batch adversarial loss: 0.506248\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021018; batch adversarial loss: 0.435394\n",
      "epoch 157; iter: 0; batch classifier loss: 0.052503; batch adversarial loss: 0.554363\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018567; batch adversarial loss: 0.415724\n",
      "epoch 159; iter: 0; batch classifier loss: 0.057490; batch adversarial loss: 0.439651\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036759; batch adversarial loss: 0.451112\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017494; batch adversarial loss: 0.368684\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019081; batch adversarial loss: 0.554541\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012799; batch adversarial loss: 0.463506\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020506; batch adversarial loss: 0.549708\n",
      "epoch 165; iter: 0; batch classifier loss: 0.048983; batch adversarial loss: 0.401147\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015124; batch adversarial loss: 0.387739\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018868; batch adversarial loss: 0.452247\n",
      "epoch 168; iter: 0; batch classifier loss: 0.050856; batch adversarial loss: 0.525676\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012734; batch adversarial loss: 0.425103\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013264; batch adversarial loss: 0.551653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.016710; batch adversarial loss: 0.468156\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014373; batch adversarial loss: 0.589537\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026297; batch adversarial loss: 0.457782\n",
      "epoch 174; iter: 0; batch classifier loss: 0.050574; batch adversarial loss: 0.424411\n",
      "epoch 175; iter: 0; batch classifier loss: 0.052913; batch adversarial loss: 0.397707\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021570; batch adversarial loss: 0.554410\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023289; batch adversarial loss: 0.410574\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016746; batch adversarial loss: 0.435006\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014026; batch adversarial loss: 0.438751\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022509; batch adversarial loss: 0.474655\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008945; batch adversarial loss: 0.404070\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008551; batch adversarial loss: 0.426412\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020664; batch adversarial loss: 0.427704\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020775; batch adversarial loss: 0.465056\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033531; batch adversarial loss: 0.493432\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023319; batch adversarial loss: 0.449415\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005988; batch adversarial loss: 0.510107\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009224; batch adversarial loss: 0.410362\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029140; batch adversarial loss: 0.407513\n",
      "epoch 190; iter: 0; batch classifier loss: 0.038711; batch adversarial loss: 0.531243\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018699; batch adversarial loss: 0.446091\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029772; batch adversarial loss: 0.479046\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025376; batch adversarial loss: 0.516110\n",
      "epoch 194; iter: 0; batch classifier loss: 0.039080; batch adversarial loss: 0.468785\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024186; batch adversarial loss: 0.439357\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014451; batch adversarial loss: 0.433902\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012725; batch adversarial loss: 0.442234\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014349; batch adversarial loss: 0.447806\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011215; batch adversarial loss: 0.359613\n",
      "epoch 0; iter: 0; batch classifier loss: 0.736115; batch adversarial loss: 0.734959\n",
      "epoch 1; iter: 0; batch classifier loss: 0.532952; batch adversarial loss: 0.635235\n",
      "epoch 2; iter: 0; batch classifier loss: 0.410097; batch adversarial loss: 0.594905\n",
      "epoch 3; iter: 0; batch classifier loss: 0.376775; batch adversarial loss: 0.573059\n",
      "epoch 4; iter: 0; batch classifier loss: 0.299112; batch adversarial loss: 0.614198\n",
      "epoch 5; iter: 0; batch classifier loss: 0.364320; batch adversarial loss: 0.565741\n",
      "epoch 6; iter: 0; batch classifier loss: 0.318404; batch adversarial loss: 0.617946\n",
      "epoch 7; iter: 0; batch classifier loss: 0.367234; batch adversarial loss: 0.569848\n",
      "epoch 8; iter: 0; batch classifier loss: 0.286282; batch adversarial loss: 0.622566\n",
      "epoch 9; iter: 0; batch classifier loss: 0.301867; batch adversarial loss: 0.511906\n",
      "epoch 10; iter: 0; batch classifier loss: 0.232794; batch adversarial loss: 0.580598\n",
      "epoch 11; iter: 0; batch classifier loss: 0.259472; batch adversarial loss: 0.509807\n",
      "epoch 12; iter: 0; batch classifier loss: 0.265502; batch adversarial loss: 0.502025\n",
      "epoch 13; iter: 0; batch classifier loss: 0.277183; batch adversarial loss: 0.490276\n",
      "epoch 14; iter: 0; batch classifier loss: 0.300670; batch adversarial loss: 0.574852\n",
      "epoch 15; iter: 0; batch classifier loss: 0.272322; batch adversarial loss: 0.456489\n",
      "epoch 16; iter: 0; batch classifier loss: 0.226480; batch adversarial loss: 0.444233\n",
      "epoch 17; iter: 0; batch classifier loss: 0.278407; batch adversarial loss: 0.469833\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197877; batch adversarial loss: 0.446009\n",
      "epoch 19; iter: 0; batch classifier loss: 0.203803; batch adversarial loss: 0.563577\n",
      "epoch 20; iter: 0; batch classifier loss: 0.272686; batch adversarial loss: 0.454979\n",
      "epoch 21; iter: 0; batch classifier loss: 0.214832; batch adversarial loss: 0.576871\n",
      "epoch 22; iter: 0; batch classifier loss: 0.205888; batch adversarial loss: 0.418393\n",
      "epoch 23; iter: 0; batch classifier loss: 0.231210; batch adversarial loss: 0.497575\n",
      "epoch 24; iter: 0; batch classifier loss: 0.149772; batch adversarial loss: 0.518090\n",
      "epoch 25; iter: 0; batch classifier loss: 0.183391; batch adversarial loss: 0.479937\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180274; batch adversarial loss: 0.429334\n",
      "epoch 27; iter: 0; batch classifier loss: 0.200600; batch adversarial loss: 0.480002\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173370; batch adversarial loss: 0.408847\n",
      "epoch 29; iter: 0; batch classifier loss: 0.138799; batch adversarial loss: 0.583380\n",
      "epoch 30; iter: 0; batch classifier loss: 0.164370; batch adversarial loss: 0.487914\n",
      "epoch 31; iter: 0; batch classifier loss: 0.197672; batch adversarial loss: 0.437247\n",
      "epoch 32; iter: 0; batch classifier loss: 0.223935; batch adversarial loss: 0.449681\n",
      "epoch 33; iter: 0; batch classifier loss: 0.259522; batch adversarial loss: 0.467839\n",
      "epoch 34; iter: 0; batch classifier loss: 0.167591; batch adversarial loss: 0.436132\n",
      "epoch 35; iter: 0; batch classifier loss: 0.185992; batch adversarial loss: 0.576045\n",
      "epoch 36; iter: 0; batch classifier loss: 0.254597; batch adversarial loss: 0.389786\n",
      "epoch 37; iter: 0; batch classifier loss: 0.173427; batch adversarial loss: 0.519223\n",
      "epoch 38; iter: 0; batch classifier loss: 0.200388; batch adversarial loss: 0.389587\n",
      "epoch 39; iter: 0; batch classifier loss: 0.152190; batch adversarial loss: 0.452626\n",
      "epoch 40; iter: 0; batch classifier loss: 0.195507; batch adversarial loss: 0.422756\n",
      "epoch 41; iter: 0; batch classifier loss: 0.188473; batch adversarial loss: 0.411164\n",
      "epoch 42; iter: 0; batch classifier loss: 0.170057; batch adversarial loss: 0.394609\n",
      "epoch 43; iter: 0; batch classifier loss: 0.201334; batch adversarial loss: 0.490757\n",
      "epoch 44; iter: 0; batch classifier loss: 0.197542; batch adversarial loss: 0.418721\n",
      "epoch 45; iter: 0; batch classifier loss: 0.170668; batch adversarial loss: 0.421928\n",
      "epoch 46; iter: 0; batch classifier loss: 0.153758; batch adversarial loss: 0.439071\n",
      "epoch 47; iter: 0; batch classifier loss: 0.190454; batch adversarial loss: 0.426267\n",
      "epoch 48; iter: 0; batch classifier loss: 0.172217; batch adversarial loss: 0.476980\n",
      "epoch 49; iter: 0; batch classifier loss: 0.226941; batch adversarial loss: 0.435837\n",
      "epoch 50; iter: 0; batch classifier loss: 0.198790; batch adversarial loss: 0.493221\n",
      "epoch 51; iter: 0; batch classifier loss: 0.151008; batch adversarial loss: 0.501826\n",
      "epoch 52; iter: 0; batch classifier loss: 0.180520; batch adversarial loss: 0.410403\n",
      "epoch 53; iter: 0; batch classifier loss: 0.194958; batch adversarial loss: 0.351620\n",
      "epoch 54; iter: 0; batch classifier loss: 0.193718; batch adversarial loss: 0.424528\n",
      "epoch 55; iter: 0; batch classifier loss: 0.259260; batch adversarial loss: 0.458498\n",
      "epoch 56; iter: 0; batch classifier loss: 0.188064; batch adversarial loss: 0.386751\n",
      "epoch 57; iter: 0; batch classifier loss: 0.207214; batch adversarial loss: 0.470856\n",
      "epoch 58; iter: 0; batch classifier loss: 0.192792; batch adversarial loss: 0.434667\n",
      "epoch 59; iter: 0; batch classifier loss: 0.148951; batch adversarial loss: 0.532409\n",
      "epoch 60; iter: 0; batch classifier loss: 0.170652; batch adversarial loss: 0.568148\n",
      "epoch 61; iter: 0; batch classifier loss: 0.218062; batch adversarial loss: 0.482313\n",
      "epoch 62; iter: 0; batch classifier loss: 0.147830; batch adversarial loss: 0.422783\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097367; batch adversarial loss: 0.410427\n",
      "epoch 64; iter: 0; batch classifier loss: 0.109259; batch adversarial loss: 0.504064\n",
      "epoch 65; iter: 0; batch classifier loss: 0.223726; batch adversarial loss: 0.444741\n",
      "epoch 66; iter: 0; batch classifier loss: 0.170036; batch adversarial loss: 0.458248\n",
      "epoch 67; iter: 0; batch classifier loss: 0.207144; batch adversarial loss: 0.483527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.158556; batch adversarial loss: 0.509689\n",
      "epoch 69; iter: 0; batch classifier loss: 0.196007; batch adversarial loss: 0.422138\n",
      "epoch 70; iter: 0; batch classifier loss: 0.153699; batch adversarial loss: 0.422472\n",
      "epoch 71; iter: 0; batch classifier loss: 0.184821; batch adversarial loss: 0.446026\n",
      "epoch 72; iter: 0; batch classifier loss: 0.226399; batch adversarial loss: 0.385714\n",
      "epoch 73; iter: 0; batch classifier loss: 0.198140; batch adversarial loss: 0.435339\n",
      "epoch 74; iter: 0; batch classifier loss: 0.171989; batch adversarial loss: 0.397803\n",
      "epoch 75; iter: 0; batch classifier loss: 0.169641; batch adversarial loss: 0.447381\n",
      "epoch 76; iter: 0; batch classifier loss: 0.163451; batch adversarial loss: 0.521176\n",
      "epoch 77; iter: 0; batch classifier loss: 0.172484; batch adversarial loss: 0.422639\n",
      "epoch 78; iter: 0; batch classifier loss: 0.134773; batch adversarial loss: 0.445708\n",
      "epoch 79; iter: 0; batch classifier loss: 0.135802; batch adversarial loss: 0.530906\n",
      "epoch 80; iter: 0; batch classifier loss: 0.167644; batch adversarial loss: 0.387352\n",
      "epoch 81; iter: 0; batch classifier loss: 0.166760; batch adversarial loss: 0.398761\n",
      "epoch 82; iter: 0; batch classifier loss: 0.158183; batch adversarial loss: 0.421584\n",
      "epoch 83; iter: 0; batch classifier loss: 0.201748; batch adversarial loss: 0.482804\n",
      "epoch 84; iter: 0; batch classifier loss: 0.187440; batch adversarial loss: 0.434746\n",
      "epoch 85; iter: 0; batch classifier loss: 0.142996; batch adversarial loss: 0.545577\n",
      "epoch 86; iter: 0; batch classifier loss: 0.192565; batch adversarial loss: 0.422111\n",
      "epoch 87; iter: 0; batch classifier loss: 0.177771; batch adversarial loss: 0.374159\n",
      "epoch 88; iter: 0; batch classifier loss: 0.132960; batch adversarial loss: 0.495310\n",
      "epoch 89; iter: 0; batch classifier loss: 0.202729; batch adversarial loss: 0.421174\n",
      "epoch 90; iter: 0; batch classifier loss: 0.166882; batch adversarial loss: 0.386179\n",
      "epoch 91; iter: 0; batch classifier loss: 0.168642; batch adversarial loss: 0.470283\n",
      "epoch 92; iter: 0; batch classifier loss: 0.186868; batch adversarial loss: 0.372850\n",
      "epoch 93; iter: 0; batch classifier loss: 0.204908; batch adversarial loss: 0.398372\n",
      "epoch 94; iter: 0; batch classifier loss: 0.272826; batch adversarial loss: 0.422156\n",
      "epoch 95; iter: 0; batch classifier loss: 0.169849; batch adversarial loss: 0.459115\n",
      "epoch 96; iter: 0; batch classifier loss: 0.212098; batch adversarial loss: 0.556364\n",
      "epoch 97; iter: 0; batch classifier loss: 0.179999; batch adversarial loss: 0.433961\n",
      "epoch 98; iter: 0; batch classifier loss: 0.121635; batch adversarial loss: 0.496168\n",
      "epoch 99; iter: 0; batch classifier loss: 0.138820; batch adversarial loss: 0.448016\n",
      "epoch 100; iter: 0; batch classifier loss: 0.131585; batch adversarial loss: 0.460283\n",
      "epoch 101; iter: 0; batch classifier loss: 0.127155; batch adversarial loss: 0.482229\n",
      "epoch 102; iter: 0; batch classifier loss: 0.161022; batch adversarial loss: 0.532050\n",
      "epoch 103; iter: 0; batch classifier loss: 0.129915; batch adversarial loss: 0.471405\n",
      "epoch 104; iter: 0; batch classifier loss: 0.121949; batch adversarial loss: 0.407122\n",
      "epoch 105; iter: 0; batch classifier loss: 0.093367; batch adversarial loss: 0.505119\n",
      "epoch 106; iter: 0; batch classifier loss: 0.079383; batch adversarial loss: 0.380877\n",
      "epoch 107; iter: 0; batch classifier loss: 0.092228; batch adversarial loss: 0.433948\n",
      "epoch 108; iter: 0; batch classifier loss: 0.129151; batch adversarial loss: 0.521074\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060868; batch adversarial loss: 0.460403\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068662; batch adversarial loss: 0.403264\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054445; batch adversarial loss: 0.497869\n",
      "epoch 112; iter: 0; batch classifier loss: 0.095358; batch adversarial loss: 0.418299\n",
      "epoch 113; iter: 0; batch classifier loss: 0.050919; batch adversarial loss: 0.406891\n",
      "epoch 114; iter: 0; batch classifier loss: 0.075236; batch adversarial loss: 0.423318\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070138; batch adversarial loss: 0.454255\n",
      "epoch 116; iter: 0; batch classifier loss: 0.092537; batch adversarial loss: 0.465192\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051989; batch adversarial loss: 0.479524\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051863; batch adversarial loss: 0.466913\n",
      "epoch 119; iter: 0; batch classifier loss: 0.105421; batch adversarial loss: 0.309294\n",
      "epoch 120; iter: 0; batch classifier loss: 0.061250; batch adversarial loss: 0.451695\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033636; batch adversarial loss: 0.479389\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048213; batch adversarial loss: 0.396483\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043722; batch adversarial loss: 0.504701\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037925; batch adversarial loss: 0.484080\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039724; batch adversarial loss: 0.391824\n",
      "epoch 126; iter: 0; batch classifier loss: 0.053403; batch adversarial loss: 0.543347\n",
      "epoch 127; iter: 0; batch classifier loss: 0.065024; batch adversarial loss: 0.498315\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018886; batch adversarial loss: 0.416555\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025579; batch adversarial loss: 0.519918\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041657; batch adversarial loss: 0.422619\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020367; batch adversarial loss: 0.431707\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046895; batch adversarial loss: 0.469465\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025799; batch adversarial loss: 0.461997\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024541; batch adversarial loss: 0.464943\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046539; batch adversarial loss: 0.528579\n",
      "epoch 136; iter: 0; batch classifier loss: 0.045659; batch adversarial loss: 0.447405\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024600; batch adversarial loss: 0.471039\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032407; batch adversarial loss: 0.438792\n",
      "epoch 139; iter: 0; batch classifier loss: 0.055264; batch adversarial loss: 0.457732\n",
      "epoch 140; iter: 0; batch classifier loss: 0.058205; batch adversarial loss: 0.452912\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019796; batch adversarial loss: 0.445522\n",
      "epoch 142; iter: 0; batch classifier loss: 0.009401; batch adversarial loss: 0.430778\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032784; batch adversarial loss: 0.432303\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030436; batch adversarial loss: 0.403206\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020931; batch adversarial loss: 0.440969\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010032; batch adversarial loss: 0.493769\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014759; batch adversarial loss: 0.430131\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014779; batch adversarial loss: 0.410737\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024644; batch adversarial loss: 0.338477\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031385; batch adversarial loss: 0.458386\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019153; batch adversarial loss: 0.431645\n",
      "epoch 152; iter: 0; batch classifier loss: 0.009591; batch adversarial loss: 0.484317\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017008; batch adversarial loss: 0.451178\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029017; batch adversarial loss: 0.496645\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019776; batch adversarial loss: 0.494333\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029824; batch adversarial loss: 0.568011\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019818; batch adversarial loss: 0.459808\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034556; batch adversarial loss: 0.408826\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015607; batch adversarial loss: 0.493204\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019916; batch adversarial loss: 0.458198\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021836; batch adversarial loss: 0.482221\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017641; batch adversarial loss: 0.555713\n",
      "epoch 163; iter: 0; batch classifier loss: 0.008350; batch adversarial loss: 0.489653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.015428; batch adversarial loss: 0.442961\n",
      "epoch 165; iter: 0; batch classifier loss: 0.049859; batch adversarial loss: 0.479221\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012625; batch adversarial loss: 0.508505\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014169; batch adversarial loss: 0.394570\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021356; batch adversarial loss: 0.479578\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008957; batch adversarial loss: 0.395352\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025292; batch adversarial loss: 0.488023\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018600; batch adversarial loss: 0.427471\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024885; batch adversarial loss: 0.451439\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018197; batch adversarial loss: 0.422546\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031505; batch adversarial loss: 0.454283\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032940; batch adversarial loss: 0.319432\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010564; batch adversarial loss: 0.413861\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025125; batch adversarial loss: 0.465681\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016417; batch adversarial loss: 0.485159\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019415; batch adversarial loss: 0.435773\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013360; batch adversarial loss: 0.494416\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022428; batch adversarial loss: 0.435460\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017922; batch adversarial loss: 0.439949\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011484; batch adversarial loss: 0.488577\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014302; batch adversarial loss: 0.465327\n",
      "epoch 185; iter: 0; batch classifier loss: 0.003060; batch adversarial loss: 0.509333\n",
      "epoch 186; iter: 0; batch classifier loss: 0.043490; batch adversarial loss: 0.434818\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009925; batch adversarial loss: 0.524803\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013820; batch adversarial loss: 0.444732\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018376; batch adversarial loss: 0.415291\n",
      "epoch 190; iter: 0; batch classifier loss: 0.048341; batch adversarial loss: 0.544593\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013071; batch adversarial loss: 0.526073\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013112; batch adversarial loss: 0.433453\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020946; batch adversarial loss: 0.444351\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008731; batch adversarial loss: 0.386406\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010437; batch adversarial loss: 0.422664\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027608; batch adversarial loss: 0.426381\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014421; batch adversarial loss: 0.450477\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014388; batch adversarial loss: 0.443894\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017471; batch adversarial loss: 0.349014\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713215; batch adversarial loss: 0.632904\n",
      "epoch 1; iter: 0; batch classifier loss: 0.392726; batch adversarial loss: 0.631746\n",
      "epoch 2; iter: 0; batch classifier loss: 0.341946; batch adversarial loss: 0.596592\n",
      "epoch 3; iter: 0; batch classifier loss: 0.347980; batch adversarial loss: 0.589421\n",
      "epoch 4; iter: 0; batch classifier loss: 0.351229; batch adversarial loss: 0.527061\n",
      "epoch 5; iter: 0; batch classifier loss: 0.297369; batch adversarial loss: 0.537834\n",
      "epoch 6; iter: 0; batch classifier loss: 0.375173; batch adversarial loss: 0.503786\n",
      "epoch 7; iter: 0; batch classifier loss: 0.270517; batch adversarial loss: 0.498686\n",
      "epoch 8; iter: 0; batch classifier loss: 0.262837; batch adversarial loss: 0.520026\n",
      "epoch 9; iter: 0; batch classifier loss: 0.216436; batch adversarial loss: 0.511277\n",
      "epoch 10; iter: 0; batch classifier loss: 0.191871; batch adversarial loss: 0.490234\n",
      "epoch 11; iter: 0; batch classifier loss: 0.273763; batch adversarial loss: 0.468589\n",
      "epoch 12; iter: 0; batch classifier loss: 0.230356; batch adversarial loss: 0.573577\n",
      "epoch 13; iter: 0; batch classifier loss: 0.178359; batch adversarial loss: 0.468612\n",
      "epoch 14; iter: 0; batch classifier loss: 0.233947; batch adversarial loss: 0.413490\n",
      "epoch 15; iter: 0; batch classifier loss: 0.169056; batch adversarial loss: 0.559074\n",
      "epoch 16; iter: 0; batch classifier loss: 0.177824; batch adversarial loss: 0.532928\n",
      "epoch 17; iter: 0; batch classifier loss: 0.198281; batch adversarial loss: 0.542714\n",
      "epoch 18; iter: 0; batch classifier loss: 0.230168; batch adversarial loss: 0.513609\n",
      "epoch 19; iter: 0; batch classifier loss: 0.226155; batch adversarial loss: 0.574882\n",
      "epoch 20; iter: 0; batch classifier loss: 0.155087; batch adversarial loss: 0.499947\n",
      "epoch 21; iter: 0; batch classifier loss: 0.190640; batch adversarial loss: 0.485196\n",
      "epoch 22; iter: 0; batch classifier loss: 0.235032; batch adversarial loss: 0.572906\n",
      "epoch 23; iter: 0; batch classifier loss: 0.200250; batch adversarial loss: 0.456828\n",
      "epoch 24; iter: 0; batch classifier loss: 0.198040; batch adversarial loss: 0.569877\n",
      "epoch 25; iter: 0; batch classifier loss: 0.259472; batch adversarial loss: 0.556372\n",
      "epoch 26; iter: 0; batch classifier loss: 0.269501; batch adversarial loss: 0.523746\n",
      "epoch 27; iter: 0; batch classifier loss: 0.175816; batch adversarial loss: 0.532305\n",
      "epoch 28; iter: 0; batch classifier loss: 0.264870; batch adversarial loss: 0.555260\n",
      "epoch 29; iter: 0; batch classifier loss: 0.241338; batch adversarial loss: 0.511963\n",
      "epoch 30; iter: 0; batch classifier loss: 0.239140; batch adversarial loss: 0.464461\n",
      "epoch 31; iter: 0; batch classifier loss: 0.306771; batch adversarial loss: 0.435602\n",
      "epoch 32; iter: 0; batch classifier loss: 0.302032; batch adversarial loss: 0.501175\n",
      "epoch 33; iter: 0; batch classifier loss: 0.171391; batch adversarial loss: 0.448855\n",
      "epoch 34; iter: 0; batch classifier loss: 0.121670; batch adversarial loss: 0.526526\n",
      "epoch 35; iter: 0; batch classifier loss: 0.104275; batch adversarial loss: 0.509893\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140593; batch adversarial loss: 0.484066\n",
      "epoch 37; iter: 0; batch classifier loss: 0.090089; batch adversarial loss: 0.431558\n",
      "epoch 38; iter: 0; batch classifier loss: 0.089980; batch adversarial loss: 0.507060\n",
      "epoch 39; iter: 0; batch classifier loss: 0.085631; batch adversarial loss: 0.418251\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095372; batch adversarial loss: 0.443258\n",
      "epoch 41; iter: 0; batch classifier loss: 0.113076; batch adversarial loss: 0.458137\n",
      "epoch 42; iter: 0; batch classifier loss: 0.122395; batch adversarial loss: 0.494604\n",
      "epoch 43; iter: 0; batch classifier loss: 0.052982; batch adversarial loss: 0.450763\n",
      "epoch 44; iter: 0; batch classifier loss: 0.087989; batch adversarial loss: 0.421411\n",
      "epoch 45; iter: 0; batch classifier loss: 0.163396; batch adversarial loss: 0.422299\n",
      "epoch 46; iter: 0; batch classifier loss: 0.081426; batch adversarial loss: 0.460357\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112513; batch adversarial loss: 0.537119\n",
      "epoch 48; iter: 0; batch classifier loss: 0.086635; batch adversarial loss: 0.545707\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114474; batch adversarial loss: 0.466721\n",
      "epoch 50; iter: 0; batch classifier loss: 0.073353; batch adversarial loss: 0.419391\n",
      "epoch 51; iter: 0; batch classifier loss: 0.087161; batch adversarial loss: 0.413559\n",
      "epoch 52; iter: 0; batch classifier loss: 0.052700; batch adversarial loss: 0.452362\n",
      "epoch 53; iter: 0; batch classifier loss: 0.135082; batch adversarial loss: 0.476710\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114868; batch adversarial loss: 0.395614\n",
      "epoch 55; iter: 0; batch classifier loss: 0.133401; batch adversarial loss: 0.594925\n",
      "epoch 56; iter: 0; batch classifier loss: 0.042268; batch adversarial loss: 0.520876\n",
      "epoch 57; iter: 0; batch classifier loss: 0.114102; batch adversarial loss: 0.451788\n",
      "epoch 58; iter: 0; batch classifier loss: 0.136913; batch adversarial loss: 0.383298\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099146; batch adversarial loss: 0.426394\n",
      "epoch 60; iter: 0; batch classifier loss: 0.056783; batch adversarial loss: 0.431474\n",
      "epoch 61; iter: 0; batch classifier loss: 0.124341; batch adversarial loss: 0.490735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.068730; batch adversarial loss: 0.416295\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103408; batch adversarial loss: 0.413967\n",
      "epoch 64; iter: 0; batch classifier loss: 0.066390; batch adversarial loss: 0.413370\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074724; batch adversarial loss: 0.552078\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092826; batch adversarial loss: 0.512099\n",
      "epoch 67; iter: 0; batch classifier loss: 0.105225; batch adversarial loss: 0.464961\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076212; batch adversarial loss: 0.419646\n",
      "epoch 69; iter: 0; batch classifier loss: 0.029447; batch adversarial loss: 0.535180\n",
      "epoch 70; iter: 0; batch classifier loss: 0.099801; batch adversarial loss: 0.458803\n",
      "epoch 71; iter: 0; batch classifier loss: 0.093799; batch adversarial loss: 0.468075\n",
      "epoch 72; iter: 0; batch classifier loss: 0.107234; batch adversarial loss: 0.461406\n",
      "epoch 73; iter: 0; batch classifier loss: 0.056144; batch adversarial loss: 0.512138\n",
      "epoch 74; iter: 0; batch classifier loss: 0.105471; batch adversarial loss: 0.496794\n",
      "epoch 75; iter: 0; batch classifier loss: 0.039443; batch adversarial loss: 0.458440\n",
      "epoch 76; iter: 0; batch classifier loss: 0.080209; batch adversarial loss: 0.490962\n",
      "epoch 77; iter: 0; batch classifier loss: 0.153972; batch adversarial loss: 0.416021\n",
      "epoch 78; iter: 0; batch classifier loss: 0.102713; batch adversarial loss: 0.521363\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070832; batch adversarial loss: 0.534892\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090468; batch adversarial loss: 0.575102\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064525; batch adversarial loss: 0.481264\n",
      "epoch 82; iter: 0; batch classifier loss: 0.077839; batch adversarial loss: 0.420379\n",
      "epoch 83; iter: 0; batch classifier loss: 0.067048; batch adversarial loss: 0.377044\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067243; batch adversarial loss: 0.422426\n",
      "epoch 85; iter: 0; batch classifier loss: 0.041518; batch adversarial loss: 0.432022\n",
      "epoch 86; iter: 0; batch classifier loss: 0.077738; batch adversarial loss: 0.506856\n",
      "epoch 87; iter: 0; batch classifier loss: 0.096350; batch adversarial loss: 0.407371\n",
      "epoch 88; iter: 0; batch classifier loss: 0.084975; batch adversarial loss: 0.438748\n",
      "epoch 89; iter: 0; batch classifier loss: 0.077517; batch adversarial loss: 0.392340\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062880; batch adversarial loss: 0.465651\n",
      "epoch 91; iter: 0; batch classifier loss: 0.109659; batch adversarial loss: 0.444788\n",
      "epoch 92; iter: 0; batch classifier loss: 0.098606; batch adversarial loss: 0.418419\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051136; batch adversarial loss: 0.487927\n",
      "epoch 94; iter: 0; batch classifier loss: 0.097710; batch adversarial loss: 0.390392\n",
      "epoch 95; iter: 0; batch classifier loss: 0.097074; batch adversarial loss: 0.438052\n",
      "epoch 96; iter: 0; batch classifier loss: 0.033104; batch adversarial loss: 0.459641\n",
      "epoch 97; iter: 0; batch classifier loss: 0.090163; batch adversarial loss: 0.499539\n",
      "epoch 98; iter: 0; batch classifier loss: 0.077681; batch adversarial loss: 0.506780\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041971; batch adversarial loss: 0.400572\n",
      "epoch 100; iter: 0; batch classifier loss: 0.092259; batch adversarial loss: 0.398917\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054067; batch adversarial loss: 0.481246\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056117; batch adversarial loss: 0.429739\n",
      "epoch 103; iter: 0; batch classifier loss: 0.096341; batch adversarial loss: 0.458720\n",
      "epoch 104; iter: 0; batch classifier loss: 0.052656; batch adversarial loss: 0.511935\n",
      "epoch 105; iter: 0; batch classifier loss: 0.063800; batch adversarial loss: 0.432590\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043607; batch adversarial loss: 0.561649\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055146; batch adversarial loss: 0.518412\n",
      "epoch 108; iter: 0; batch classifier loss: 0.112531; batch adversarial loss: 0.412748\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049037; batch adversarial loss: 0.467314\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046380; batch adversarial loss: 0.484315\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062965; batch adversarial loss: 0.504617\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025869; batch adversarial loss: 0.461326\n",
      "epoch 113; iter: 0; batch classifier loss: 0.018519; batch adversarial loss: 0.416346\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061334; batch adversarial loss: 0.458576\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063763; batch adversarial loss: 0.420213\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055180; batch adversarial loss: 0.357997\n",
      "epoch 117; iter: 0; batch classifier loss: 0.087917; batch adversarial loss: 0.459693\n",
      "epoch 118; iter: 0; batch classifier loss: 0.085862; batch adversarial loss: 0.490792\n",
      "epoch 119; iter: 0; batch classifier loss: 0.076754; batch adversarial loss: 0.395975\n",
      "epoch 120; iter: 0; batch classifier loss: 0.061395; batch adversarial loss: 0.430435\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039214; batch adversarial loss: 0.422682\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041120; batch adversarial loss: 0.382677\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041681; batch adversarial loss: 0.438646\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026990; batch adversarial loss: 0.560392\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033436; batch adversarial loss: 0.381257\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028127; batch adversarial loss: 0.474044\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051841; batch adversarial loss: 0.531727\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032375; batch adversarial loss: 0.490777\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024150; batch adversarial loss: 0.478684\n",
      "epoch 130; iter: 0; batch classifier loss: 0.083681; batch adversarial loss: 0.450075\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048849; batch adversarial loss: 0.415627\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043117; batch adversarial loss: 0.480417\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042250; batch adversarial loss: 0.522129\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053960; batch adversarial loss: 0.498348\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011886; batch adversarial loss: 0.597859\n",
      "epoch 136; iter: 0; batch classifier loss: 0.050926; batch adversarial loss: 0.362126\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040067; batch adversarial loss: 0.464991\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022541; batch adversarial loss: 0.448637\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020146; batch adversarial loss: 0.509967\n",
      "epoch 140; iter: 0; batch classifier loss: 0.042551; batch adversarial loss: 0.399875\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016069; batch adversarial loss: 0.427348\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027015; batch adversarial loss: 0.483907\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015388; batch adversarial loss: 0.497651\n",
      "epoch 144; iter: 0; batch classifier loss: 0.044619; batch adversarial loss: 0.504848\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025111; batch adversarial loss: 0.455095\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025941; batch adversarial loss: 0.428441\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036496; batch adversarial loss: 0.428338\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046449; batch adversarial loss: 0.468192\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029998; batch adversarial loss: 0.387812\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033028; batch adversarial loss: 0.457825\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026426; batch adversarial loss: 0.434288\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037767; batch adversarial loss: 0.477700\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018085; batch adversarial loss: 0.402163\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011377; batch adversarial loss: 0.421366\n",
      "epoch 155; iter: 0; batch classifier loss: 0.064599; batch adversarial loss: 0.543202\n",
      "epoch 156; iter: 0; batch classifier loss: 0.056759; batch adversarial loss: 0.380520\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042335; batch adversarial loss: 0.466390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.029039; batch adversarial loss: 0.406444\n",
      "epoch 159; iter: 0; batch classifier loss: 0.086348; batch adversarial loss: 0.384977\n",
      "epoch 160; iter: 0; batch classifier loss: 0.059150; batch adversarial loss: 0.416566\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027541; batch adversarial loss: 0.447355\n",
      "epoch 162; iter: 0; batch classifier loss: 0.049399; batch adversarial loss: 0.364124\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035566; batch adversarial loss: 0.430428\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021376; batch adversarial loss: 0.390785\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029812; batch adversarial loss: 0.556033\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024863; batch adversarial loss: 0.454710\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039570; batch adversarial loss: 0.455547\n",
      "epoch 168; iter: 0; batch classifier loss: 0.064546; batch adversarial loss: 0.374461\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021208; batch adversarial loss: 0.372225\n",
      "epoch 170; iter: 0; batch classifier loss: 0.041823; batch adversarial loss: 0.439041\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021728; batch adversarial loss: 0.490393\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030652; batch adversarial loss: 0.464665\n",
      "epoch 173; iter: 0; batch classifier loss: 0.045374; batch adversarial loss: 0.458085\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030877; batch adversarial loss: 0.464421\n",
      "epoch 175; iter: 0; batch classifier loss: 0.066107; batch adversarial loss: 0.453191\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020934; batch adversarial loss: 0.428607\n",
      "epoch 177; iter: 0; batch classifier loss: 0.005677; batch adversarial loss: 0.442197\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022132; batch adversarial loss: 0.410950\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028671; batch adversarial loss: 0.463698\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021183; batch adversarial loss: 0.428709\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030475; batch adversarial loss: 0.477070\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020697; batch adversarial loss: 0.535045\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024570; batch adversarial loss: 0.405462\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019306; batch adversarial loss: 0.345181\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010245; batch adversarial loss: 0.390483\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022915; batch adversarial loss: 0.413060\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017429; batch adversarial loss: 0.424884\n",
      "epoch 188; iter: 0; batch classifier loss: 0.077507; batch adversarial loss: 0.346845\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021283; batch adversarial loss: 0.385365\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023684; batch adversarial loss: 0.495990\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018670; batch adversarial loss: 0.465571\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033448; batch adversarial loss: 0.431691\n",
      "epoch 193; iter: 0; batch classifier loss: 0.056503; batch adversarial loss: 0.441901\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016792; batch adversarial loss: 0.430530\n",
      "epoch 195; iter: 0; batch classifier loss: 0.046022; batch adversarial loss: 0.386804\n",
      "epoch 196; iter: 0; batch classifier loss: 0.035294; batch adversarial loss: 0.454686\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007667; batch adversarial loss: 0.438417\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020572; batch adversarial loss: 0.440727\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023991; batch adversarial loss: 0.429059\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695645; batch adversarial loss: 0.682592\n",
      "epoch 1; iter: 0; batch classifier loss: 0.456372; batch adversarial loss: 0.648317\n",
      "epoch 2; iter: 0; batch classifier loss: 0.323826; batch adversarial loss: 0.621997\n",
      "epoch 3; iter: 0; batch classifier loss: 0.385625; batch adversarial loss: 0.582539\n",
      "epoch 4; iter: 0; batch classifier loss: 0.324835; batch adversarial loss: 0.580989\n",
      "epoch 5; iter: 0; batch classifier loss: 0.294588; batch adversarial loss: 0.556141\n",
      "epoch 6; iter: 0; batch classifier loss: 0.228810; batch adversarial loss: 0.529747\n",
      "epoch 7; iter: 0; batch classifier loss: 0.265363; batch adversarial loss: 0.522573\n",
      "epoch 8; iter: 0; batch classifier loss: 0.231848; batch adversarial loss: 0.503377\n",
      "epoch 9; iter: 0; batch classifier loss: 0.198060; batch adversarial loss: 0.502433\n",
      "epoch 10; iter: 0; batch classifier loss: 0.202841; batch adversarial loss: 0.518351\n",
      "epoch 11; iter: 0; batch classifier loss: 0.252665; batch adversarial loss: 0.458021\n",
      "epoch 12; iter: 0; batch classifier loss: 0.200815; batch adversarial loss: 0.514878\n",
      "epoch 13; iter: 0; batch classifier loss: 0.218234; batch adversarial loss: 0.552281\n",
      "epoch 14; iter: 0; batch classifier loss: 0.266965; batch adversarial loss: 0.470333\n",
      "epoch 15; iter: 0; batch classifier loss: 0.167841; batch adversarial loss: 0.550866\n",
      "epoch 16; iter: 0; batch classifier loss: 0.158483; batch adversarial loss: 0.456942\n",
      "epoch 17; iter: 0; batch classifier loss: 0.196569; batch adversarial loss: 0.549075\n",
      "epoch 18; iter: 0; batch classifier loss: 0.173847; batch adversarial loss: 0.538787\n",
      "epoch 19; iter: 0; batch classifier loss: 0.187717; batch adversarial loss: 0.509922\n",
      "epoch 20; iter: 0; batch classifier loss: 0.145974; batch adversarial loss: 0.552470\n",
      "epoch 21; iter: 0; batch classifier loss: 0.201487; batch adversarial loss: 0.526459\n",
      "epoch 22; iter: 0; batch classifier loss: 0.183775; batch adversarial loss: 0.475119\n",
      "epoch 23; iter: 0; batch classifier loss: 0.232389; batch adversarial loss: 0.553141\n",
      "epoch 24; iter: 0; batch classifier loss: 0.170395; batch adversarial loss: 0.471427\n",
      "epoch 25; iter: 0; batch classifier loss: 0.260229; batch adversarial loss: 0.565093\n",
      "epoch 26; iter: 0; batch classifier loss: 0.227826; batch adversarial loss: 0.493710\n",
      "epoch 27; iter: 0; batch classifier loss: 0.355886; batch adversarial loss: 0.468791\n",
      "epoch 28; iter: 0; batch classifier loss: 0.344039; batch adversarial loss: 0.521965\n",
      "epoch 29; iter: 0; batch classifier loss: 0.313033; batch adversarial loss: 0.444246\n",
      "epoch 30; iter: 0; batch classifier loss: 0.238802; batch adversarial loss: 0.507193\n",
      "epoch 31; iter: 0; batch classifier loss: 0.166676; batch adversarial loss: 0.479633\n",
      "epoch 32; iter: 0; batch classifier loss: 0.125336; batch adversarial loss: 0.460988\n",
      "epoch 33; iter: 0; batch classifier loss: 0.102610; batch adversarial loss: 0.395715\n",
      "epoch 34; iter: 0; batch classifier loss: 0.107234; batch adversarial loss: 0.559539\n",
      "epoch 35; iter: 0; batch classifier loss: 0.111340; batch adversarial loss: 0.472097\n",
      "epoch 36; iter: 0; batch classifier loss: 0.095306; batch adversarial loss: 0.498378\n",
      "epoch 37; iter: 0; batch classifier loss: 0.075456; batch adversarial loss: 0.493307\n",
      "epoch 38; iter: 0; batch classifier loss: 0.104056; batch adversarial loss: 0.360251\n",
      "epoch 39; iter: 0; batch classifier loss: 0.115186; batch adversarial loss: 0.591686\n",
      "epoch 40; iter: 0; batch classifier loss: 0.127906; batch adversarial loss: 0.553547\n",
      "epoch 41; iter: 0; batch classifier loss: 0.080276; batch adversarial loss: 0.463585\n",
      "epoch 42; iter: 0; batch classifier loss: 0.096249; batch adversarial loss: 0.432668\n",
      "epoch 43; iter: 0; batch classifier loss: 0.111777; batch adversarial loss: 0.460497\n",
      "epoch 44; iter: 0; batch classifier loss: 0.121500; batch adversarial loss: 0.470546\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103194; batch adversarial loss: 0.498401\n",
      "epoch 46; iter: 0; batch classifier loss: 0.107569; batch adversarial loss: 0.521465\n",
      "epoch 47; iter: 0; batch classifier loss: 0.074982; batch adversarial loss: 0.420367\n",
      "epoch 48; iter: 0; batch classifier loss: 0.078833; batch adversarial loss: 0.486077\n",
      "epoch 49; iter: 0; batch classifier loss: 0.060585; batch adversarial loss: 0.406560\n",
      "epoch 50; iter: 0; batch classifier loss: 0.085290; batch adversarial loss: 0.407629\n",
      "epoch 51; iter: 0; batch classifier loss: 0.169303; batch adversarial loss: 0.445178\n",
      "epoch 52; iter: 0; batch classifier loss: 0.144217; batch adversarial loss: 0.472895\n",
      "epoch 53; iter: 0; batch classifier loss: 0.110679; batch adversarial loss: 0.466245\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095506; batch adversarial loss: 0.488857\n",
      "epoch 55; iter: 0; batch classifier loss: 0.129997; batch adversarial loss: 0.465702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.078814; batch adversarial loss: 0.428387\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072609; batch adversarial loss: 0.363761\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090487; batch adversarial loss: 0.580660\n",
      "epoch 59; iter: 0; batch classifier loss: 0.076994; batch adversarial loss: 0.428032\n",
      "epoch 60; iter: 0; batch classifier loss: 0.100977; batch adversarial loss: 0.424659\n",
      "epoch 61; iter: 0; batch classifier loss: 0.125199; batch adversarial loss: 0.426266\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090390; batch adversarial loss: 0.502998\n",
      "epoch 63; iter: 0; batch classifier loss: 0.106059; batch adversarial loss: 0.483147\n",
      "epoch 64; iter: 0; batch classifier loss: 0.134788; batch adversarial loss: 0.501894\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082146; batch adversarial loss: 0.399517\n",
      "epoch 66; iter: 0; batch classifier loss: 0.141361; batch adversarial loss: 0.463526\n",
      "epoch 67; iter: 0; batch classifier loss: 0.063663; batch adversarial loss: 0.476838\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076596; batch adversarial loss: 0.424659\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072064; batch adversarial loss: 0.482622\n",
      "epoch 70; iter: 0; batch classifier loss: 0.098776; batch adversarial loss: 0.441257\n",
      "epoch 71; iter: 0; batch classifier loss: 0.060878; batch adversarial loss: 0.502596\n",
      "epoch 72; iter: 0; batch classifier loss: 0.104300; batch adversarial loss: 0.563650\n",
      "epoch 73; iter: 0; batch classifier loss: 0.133877; batch adversarial loss: 0.412979\n",
      "epoch 74; iter: 0; batch classifier loss: 0.080053; batch adversarial loss: 0.475144\n",
      "epoch 75; iter: 0; batch classifier loss: 0.101117; batch adversarial loss: 0.494731\n",
      "epoch 76; iter: 0; batch classifier loss: 0.079546; batch adversarial loss: 0.479846\n",
      "epoch 77; iter: 0; batch classifier loss: 0.141528; batch adversarial loss: 0.485344\n",
      "epoch 78; iter: 0; batch classifier loss: 0.095297; batch adversarial loss: 0.400497\n",
      "epoch 79; iter: 0; batch classifier loss: 0.091410; batch adversarial loss: 0.440421\n",
      "epoch 80; iter: 0; batch classifier loss: 0.079245; batch adversarial loss: 0.430285\n",
      "epoch 81; iter: 0; batch classifier loss: 0.093883; batch adversarial loss: 0.455702\n",
      "epoch 82; iter: 0; batch classifier loss: 0.142530; batch adversarial loss: 0.466909\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035621; batch adversarial loss: 0.464785\n",
      "epoch 84; iter: 0; batch classifier loss: 0.093585; batch adversarial loss: 0.455927\n",
      "epoch 85; iter: 0; batch classifier loss: 0.048047; batch adversarial loss: 0.492880\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053813; batch adversarial loss: 0.442455\n",
      "epoch 87; iter: 0; batch classifier loss: 0.089492; batch adversarial loss: 0.439574\n",
      "epoch 88; iter: 0; batch classifier loss: 0.100213; batch adversarial loss: 0.497291\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058197; batch adversarial loss: 0.523402\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056797; batch adversarial loss: 0.449572\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083156; batch adversarial loss: 0.402536\n",
      "epoch 92; iter: 0; batch classifier loss: 0.073614; batch adversarial loss: 0.416071\n",
      "epoch 93; iter: 0; batch classifier loss: 0.074153; batch adversarial loss: 0.442190\n",
      "epoch 94; iter: 0; batch classifier loss: 0.104666; batch adversarial loss: 0.518367\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079765; batch adversarial loss: 0.533694\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082860; batch adversarial loss: 0.506299\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055812; batch adversarial loss: 0.469732\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054219; batch adversarial loss: 0.442962\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071606; batch adversarial loss: 0.432668\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062617; batch adversarial loss: 0.458854\n",
      "epoch 101; iter: 0; batch classifier loss: 0.087963; batch adversarial loss: 0.446069\n",
      "epoch 102; iter: 0; batch classifier loss: 0.073542; batch adversarial loss: 0.620309\n",
      "epoch 103; iter: 0; batch classifier loss: 0.080182; batch adversarial loss: 0.507956\n",
      "epoch 104; iter: 0; batch classifier loss: 0.076354; batch adversarial loss: 0.377162\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057939; batch adversarial loss: 0.406528\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031658; batch adversarial loss: 0.558894\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052488; batch adversarial loss: 0.450839\n",
      "epoch 108; iter: 0; batch classifier loss: 0.088531; batch adversarial loss: 0.396773\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029961; batch adversarial loss: 0.475668\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057635; batch adversarial loss: 0.445668\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048950; batch adversarial loss: 0.500665\n",
      "epoch 112; iter: 0; batch classifier loss: 0.050089; batch adversarial loss: 0.421557\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055980; batch adversarial loss: 0.479733\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043447; batch adversarial loss: 0.416419\n",
      "epoch 115; iter: 0; batch classifier loss: 0.068308; batch adversarial loss: 0.433753\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029707; batch adversarial loss: 0.397067\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051687; batch adversarial loss: 0.440694\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046948; batch adversarial loss: 0.511370\n",
      "epoch 119; iter: 0; batch classifier loss: 0.088831; batch adversarial loss: 0.460086\n",
      "epoch 120; iter: 0; batch classifier loss: 0.063865; batch adversarial loss: 0.351063\n",
      "epoch 121; iter: 0; batch classifier loss: 0.017975; batch adversarial loss: 0.441754\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043577; batch adversarial loss: 0.525622\n",
      "epoch 123; iter: 0; batch classifier loss: 0.065343; batch adversarial loss: 0.470895\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054830; batch adversarial loss: 0.460193\n",
      "epoch 125; iter: 0; batch classifier loss: 0.069479; batch adversarial loss: 0.467696\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025939; batch adversarial loss: 0.426931\n",
      "epoch 127; iter: 0; batch classifier loss: 0.069457; batch adversarial loss: 0.428752\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056399; batch adversarial loss: 0.500538\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036145; batch adversarial loss: 0.428260\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050633; batch adversarial loss: 0.424123\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046729; batch adversarial loss: 0.469178\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043996; batch adversarial loss: 0.517310\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037812; batch adversarial loss: 0.424952\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049916; batch adversarial loss: 0.460455\n",
      "epoch 135; iter: 0; batch classifier loss: 0.053429; batch adversarial loss: 0.505018\n",
      "epoch 136; iter: 0; batch classifier loss: 0.046886; batch adversarial loss: 0.497155\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029637; batch adversarial loss: 0.518858\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036760; batch adversarial loss: 0.437417\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040803; batch adversarial loss: 0.494477\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017169; batch adversarial loss: 0.459093\n",
      "epoch 141; iter: 0; batch classifier loss: 0.073627; batch adversarial loss: 0.411963\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032427; batch adversarial loss: 0.453840\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042394; batch adversarial loss: 0.453675\n",
      "epoch 144; iter: 0; batch classifier loss: 0.056213; batch adversarial loss: 0.427789\n",
      "epoch 145; iter: 0; batch classifier loss: 0.069893; batch adversarial loss: 0.472037\n",
      "epoch 146; iter: 0; batch classifier loss: 0.011987; batch adversarial loss: 0.453172\n",
      "epoch 147; iter: 0; batch classifier loss: 0.058840; batch adversarial loss: 0.453096\n",
      "epoch 148; iter: 0; batch classifier loss: 0.058201; batch adversarial loss: 0.476057\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018256; batch adversarial loss: 0.512834\n",
      "epoch 150; iter: 0; batch classifier loss: 0.068641; batch adversarial loss: 0.428603\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011762; batch adversarial loss: 0.460351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.035196; batch adversarial loss: 0.529396\n",
      "epoch 153; iter: 0; batch classifier loss: 0.037303; batch adversarial loss: 0.451654\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029347; batch adversarial loss: 0.389555\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040936; batch adversarial loss: 0.434989\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038330; batch adversarial loss: 0.407135\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032282; batch adversarial loss: 0.452499\n",
      "epoch 158; iter: 0; batch classifier loss: 0.039276; batch adversarial loss: 0.442057\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028923; batch adversarial loss: 0.471310\n",
      "epoch 160; iter: 0; batch classifier loss: 0.038436; batch adversarial loss: 0.455840\n",
      "epoch 161; iter: 0; batch classifier loss: 0.060615; batch adversarial loss: 0.461185\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030316; batch adversarial loss: 0.423657\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030658; batch adversarial loss: 0.434836\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037803; batch adversarial loss: 0.514135\n",
      "epoch 165; iter: 0; batch classifier loss: 0.048431; batch adversarial loss: 0.469993\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029088; batch adversarial loss: 0.416643\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042758; batch adversarial loss: 0.442822\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029857; batch adversarial loss: 0.388909\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037880; batch adversarial loss: 0.400998\n",
      "epoch 170; iter: 0; batch classifier loss: 0.092927; batch adversarial loss: 0.508129\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038355; batch adversarial loss: 0.432401\n",
      "epoch 172; iter: 0; batch classifier loss: 0.042401; batch adversarial loss: 0.411744\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019793; batch adversarial loss: 0.432913\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032468; batch adversarial loss: 0.430232\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033751; batch adversarial loss: 0.457624\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035142; batch adversarial loss: 0.422957\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025388; batch adversarial loss: 0.446054\n",
      "epoch 178; iter: 0; batch classifier loss: 0.042143; batch adversarial loss: 0.453777\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032058; batch adversarial loss: 0.474785\n",
      "epoch 180; iter: 0; batch classifier loss: 0.044548; batch adversarial loss: 0.415999\n",
      "epoch 181; iter: 0; batch classifier loss: 0.057711; batch adversarial loss: 0.476076\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022058; batch adversarial loss: 0.495824\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020843; batch adversarial loss: 0.472460\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025901; batch adversarial loss: 0.428787\n",
      "epoch 185; iter: 0; batch classifier loss: 0.057884; batch adversarial loss: 0.488524\n",
      "epoch 186; iter: 0; batch classifier loss: 0.048172; batch adversarial loss: 0.471541\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025067; batch adversarial loss: 0.394443\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040602; batch adversarial loss: 0.351635\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027722; batch adversarial loss: 0.465686\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037395; batch adversarial loss: 0.458330\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024704; batch adversarial loss: 0.406487\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010303; batch adversarial loss: 0.558735\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018801; batch adversarial loss: 0.478339\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035265; batch adversarial loss: 0.486354\n",
      "epoch 195; iter: 0; batch classifier loss: 0.040212; batch adversarial loss: 0.490047\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011342; batch adversarial loss: 0.537064\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028117; batch adversarial loss: 0.505998\n",
      "epoch 198; iter: 0; batch classifier loss: 0.060352; batch adversarial loss: 0.456546\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032416; batch adversarial loss: 0.392000\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704749; batch adversarial loss: 0.493701\n",
      "epoch 1; iter: 0; batch classifier loss: 0.452167; batch adversarial loss: 0.607517\n",
      "epoch 2; iter: 0; batch classifier loss: 0.491353; batch adversarial loss: 0.654670\n",
      "epoch 3; iter: 0; batch classifier loss: 0.337718; batch adversarial loss: 0.558083\n",
      "epoch 4; iter: 0; batch classifier loss: 0.360018; batch adversarial loss: 0.566307\n",
      "epoch 5; iter: 0; batch classifier loss: 0.336028; batch adversarial loss: 0.605359\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315902; batch adversarial loss: 0.588861\n",
      "epoch 7; iter: 0; batch classifier loss: 0.258043; batch adversarial loss: 0.545868\n",
      "epoch 8; iter: 0; batch classifier loss: 0.453636; batch adversarial loss: 0.616383\n",
      "epoch 9; iter: 0; batch classifier loss: 0.316016; batch adversarial loss: 0.462181\n",
      "epoch 10; iter: 0; batch classifier loss: 0.353281; batch adversarial loss: 0.492811\n",
      "epoch 11; iter: 0; batch classifier loss: 0.341447; batch adversarial loss: 0.491790\n",
      "epoch 12; iter: 0; batch classifier loss: 0.433381; batch adversarial loss: 0.604915\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501055; batch adversarial loss: 0.632358\n",
      "epoch 14; iter: 0; batch classifier loss: 0.591010; batch adversarial loss: 0.565094\n",
      "epoch 15; iter: 0; batch classifier loss: 0.666681; batch adversarial loss: 0.558100\n",
      "epoch 16; iter: 0; batch classifier loss: 0.554009; batch adversarial loss: 0.557704\n",
      "epoch 17; iter: 0; batch classifier loss: 0.448540; batch adversarial loss: 0.477363\n",
      "epoch 18; iter: 0; batch classifier loss: 0.240266; batch adversarial loss: 0.544855\n",
      "epoch 19; iter: 0; batch classifier loss: 0.212077; batch adversarial loss: 0.516596\n",
      "epoch 20; iter: 0; batch classifier loss: 0.280001; batch adversarial loss: 0.471648\n",
      "epoch 21; iter: 0; batch classifier loss: 0.196601; batch adversarial loss: 0.422111\n",
      "epoch 22; iter: 0; batch classifier loss: 0.158180; batch adversarial loss: 0.448565\n",
      "epoch 23; iter: 0; batch classifier loss: 0.241051; batch adversarial loss: 0.468010\n",
      "epoch 24; iter: 0; batch classifier loss: 0.117079; batch adversarial loss: 0.528759\n",
      "epoch 25; iter: 0; batch classifier loss: 0.199501; batch adversarial loss: 0.420724\n",
      "epoch 26; iter: 0; batch classifier loss: 0.166633; batch adversarial loss: 0.379801\n",
      "epoch 27; iter: 0; batch classifier loss: 0.195102; batch adversarial loss: 0.529153\n",
      "epoch 28; iter: 0; batch classifier loss: 0.103397; batch adversarial loss: 0.522273\n",
      "epoch 29; iter: 0; batch classifier loss: 0.176521; batch adversarial loss: 0.435480\n",
      "epoch 30; iter: 0; batch classifier loss: 0.119183; batch adversarial loss: 0.495962\n",
      "epoch 31; iter: 0; batch classifier loss: 0.129989; batch adversarial loss: 0.533286\n",
      "epoch 32; iter: 0; batch classifier loss: 0.169736; batch adversarial loss: 0.474094\n",
      "epoch 33; iter: 0; batch classifier loss: 0.174072; batch adversarial loss: 0.476413\n",
      "epoch 34; iter: 0; batch classifier loss: 0.105501; batch adversarial loss: 0.483036\n",
      "epoch 35; iter: 0; batch classifier loss: 0.164701; batch adversarial loss: 0.511060\n",
      "epoch 36; iter: 0; batch classifier loss: 0.127227; batch adversarial loss: 0.428973\n",
      "epoch 37; iter: 0; batch classifier loss: 0.157411; batch adversarial loss: 0.453578\n",
      "epoch 38; iter: 0; batch classifier loss: 0.132205; batch adversarial loss: 0.370931\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126544; batch adversarial loss: 0.658938\n",
      "epoch 40; iter: 0; batch classifier loss: 0.090952; batch adversarial loss: 0.454916\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123429; batch adversarial loss: 0.442397\n",
      "epoch 42; iter: 0; batch classifier loss: 0.155751; batch adversarial loss: 0.499071\n",
      "epoch 43; iter: 0; batch classifier loss: 0.108377; batch adversarial loss: 0.462039\n",
      "epoch 44; iter: 0; batch classifier loss: 0.146726; batch adversarial loss: 0.468213\n",
      "epoch 45; iter: 0; batch classifier loss: 0.083024; batch adversarial loss: 0.377900\n",
      "epoch 46; iter: 0; batch classifier loss: 0.154943; batch adversarial loss: 0.410422\n",
      "epoch 47; iter: 0; batch classifier loss: 0.130748; batch adversarial loss: 0.365315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.138009; batch adversarial loss: 0.403039\n",
      "epoch 49; iter: 0; batch classifier loss: 0.109105; batch adversarial loss: 0.399331\n",
      "epoch 50; iter: 0; batch classifier loss: 0.105310; batch adversarial loss: 0.519942\n",
      "epoch 51; iter: 0; batch classifier loss: 0.168535; batch adversarial loss: 0.482907\n",
      "epoch 52; iter: 0; batch classifier loss: 0.129142; batch adversarial loss: 0.545905\n",
      "epoch 53; iter: 0; batch classifier loss: 0.116160; batch adversarial loss: 0.405967\n",
      "epoch 54; iter: 0; batch classifier loss: 0.125087; batch adversarial loss: 0.584377\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122685; batch adversarial loss: 0.462396\n",
      "epoch 56; iter: 0; batch classifier loss: 0.150666; batch adversarial loss: 0.555922\n",
      "epoch 57; iter: 0; batch classifier loss: 0.130893; batch adversarial loss: 0.399877\n",
      "epoch 58; iter: 0; batch classifier loss: 0.132498; batch adversarial loss: 0.401221\n",
      "epoch 59; iter: 0; batch classifier loss: 0.167805; batch adversarial loss: 0.529561\n",
      "epoch 60; iter: 0; batch classifier loss: 0.164370; batch adversarial loss: 0.445237\n",
      "epoch 61; iter: 0; batch classifier loss: 0.173895; batch adversarial loss: 0.444989\n",
      "epoch 62; iter: 0; batch classifier loss: 0.190153; batch adversarial loss: 0.532974\n",
      "epoch 63; iter: 0; batch classifier loss: 0.204419; batch adversarial loss: 0.500759\n",
      "epoch 64; iter: 0; batch classifier loss: 0.152075; batch adversarial loss: 0.413521\n",
      "epoch 65; iter: 0; batch classifier loss: 0.151578; batch adversarial loss: 0.427997\n",
      "epoch 66; iter: 0; batch classifier loss: 0.137657; batch adversarial loss: 0.396667\n",
      "epoch 67; iter: 0; batch classifier loss: 0.256528; batch adversarial loss: 0.489603\n",
      "epoch 68; iter: 0; batch classifier loss: 0.176856; batch adversarial loss: 0.590249\n",
      "epoch 69; iter: 0; batch classifier loss: 0.200293; batch adversarial loss: 0.420310\n",
      "epoch 70; iter: 0; batch classifier loss: 0.324331; batch adversarial loss: 0.356216\n",
      "epoch 71; iter: 0; batch classifier loss: 0.203862; batch adversarial loss: 0.374587\n",
      "epoch 72; iter: 0; batch classifier loss: 0.121140; batch adversarial loss: 0.518231\n",
      "epoch 73; iter: 0; batch classifier loss: 0.177077; batch adversarial loss: 0.468524\n",
      "epoch 74; iter: 0; batch classifier loss: 0.124156; batch adversarial loss: 0.517380\n",
      "epoch 75; iter: 0; batch classifier loss: 0.150893; batch adversarial loss: 0.484581\n",
      "epoch 76; iter: 0; batch classifier loss: 0.205729; batch adversarial loss: 0.520348\n",
      "epoch 77; iter: 0; batch classifier loss: 0.192538; batch adversarial loss: 0.503778\n",
      "epoch 78; iter: 0; batch classifier loss: 0.244208; batch adversarial loss: 0.492248\n",
      "epoch 79; iter: 0; batch classifier loss: 0.196671; batch adversarial loss: 0.435962\n",
      "epoch 80; iter: 0; batch classifier loss: 0.212404; batch adversarial loss: 0.466433\n",
      "epoch 81; iter: 0; batch classifier loss: 0.199613; batch adversarial loss: 0.492449\n",
      "epoch 82; iter: 0; batch classifier loss: 0.224507; batch adversarial loss: 0.426145\n",
      "epoch 83; iter: 0; batch classifier loss: 0.242675; batch adversarial loss: 0.413002\n",
      "epoch 84; iter: 0; batch classifier loss: 0.159794; batch adversarial loss: 0.457601\n",
      "epoch 85; iter: 0; batch classifier loss: 0.186529; batch adversarial loss: 0.426403\n",
      "epoch 86; iter: 0; batch classifier loss: 0.180716; batch adversarial loss: 0.479543\n",
      "epoch 87; iter: 0; batch classifier loss: 0.246052; batch adversarial loss: 0.502647\n",
      "epoch 88; iter: 0; batch classifier loss: 0.288153; batch adversarial loss: 0.480963\n",
      "epoch 89; iter: 0; batch classifier loss: 0.298823; batch adversarial loss: 0.396126\n",
      "epoch 90; iter: 0; batch classifier loss: 0.272872; batch adversarial loss: 0.391035\n",
      "epoch 91; iter: 0; batch classifier loss: 0.217771; batch adversarial loss: 0.590574\n",
      "epoch 92; iter: 0; batch classifier loss: 0.229810; batch adversarial loss: 0.497142\n",
      "epoch 93; iter: 0; batch classifier loss: 0.190481; batch adversarial loss: 0.472871\n",
      "epoch 94; iter: 0; batch classifier loss: 0.193110; batch adversarial loss: 0.530473\n",
      "epoch 95; iter: 0; batch classifier loss: 0.287805; batch adversarial loss: 0.482719\n",
      "epoch 96; iter: 0; batch classifier loss: 0.297499; batch adversarial loss: 0.410391\n",
      "epoch 97; iter: 0; batch classifier loss: 0.204544; batch adversarial loss: 0.507025\n",
      "epoch 98; iter: 0; batch classifier loss: 0.218594; batch adversarial loss: 0.506727\n",
      "epoch 99; iter: 0; batch classifier loss: 0.298668; batch adversarial loss: 0.423445\n",
      "epoch 100; iter: 0; batch classifier loss: 0.146252; batch adversarial loss: 0.518515\n",
      "epoch 101; iter: 0; batch classifier loss: 0.226485; batch adversarial loss: 0.506820\n",
      "epoch 102; iter: 0; batch classifier loss: 0.119479; batch adversarial loss: 0.457849\n",
      "epoch 103; iter: 0; batch classifier loss: 0.083364; batch adversarial loss: 0.442960\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065706; batch adversarial loss: 0.503988\n",
      "epoch 105; iter: 0; batch classifier loss: 0.070954; batch adversarial loss: 0.435482\n",
      "epoch 106; iter: 0; batch classifier loss: 0.079571; batch adversarial loss: 0.391372\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046316; batch adversarial loss: 0.475911\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028748; batch adversarial loss: 0.496087\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059475; batch adversarial loss: 0.456802\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059967; batch adversarial loss: 0.381682\n",
      "epoch 111; iter: 0; batch classifier loss: 0.067165; batch adversarial loss: 0.440557\n",
      "epoch 112; iter: 0; batch classifier loss: 0.050351; batch adversarial loss: 0.442483\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063149; batch adversarial loss: 0.427428\n",
      "epoch 114; iter: 0; batch classifier loss: 0.077064; batch adversarial loss: 0.446445\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039431; batch adversarial loss: 0.404011\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033336; batch adversarial loss: 0.432021\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036891; batch adversarial loss: 0.478996\n",
      "epoch 118; iter: 0; batch classifier loss: 0.086548; batch adversarial loss: 0.510346\n",
      "epoch 119; iter: 0; batch classifier loss: 0.060568; batch adversarial loss: 0.397251\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034127; batch adversarial loss: 0.441114\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036991; batch adversarial loss: 0.520027\n",
      "epoch 122; iter: 0; batch classifier loss: 0.024175; batch adversarial loss: 0.455761\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044956; batch adversarial loss: 0.491898\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036409; batch adversarial loss: 0.515313\n",
      "epoch 125; iter: 0; batch classifier loss: 0.071064; batch adversarial loss: 0.487964\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026588; batch adversarial loss: 0.419731\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053843; batch adversarial loss: 0.430200\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038235; batch adversarial loss: 0.470703\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046008; batch adversarial loss: 0.489111\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040275; batch adversarial loss: 0.421027\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022486; batch adversarial loss: 0.426321\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043037; batch adversarial loss: 0.525512\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018208; batch adversarial loss: 0.488201\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032298; batch adversarial loss: 0.410548\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024881; batch adversarial loss: 0.450643\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036914; batch adversarial loss: 0.529204\n",
      "epoch 137; iter: 0; batch classifier loss: 0.064569; batch adversarial loss: 0.449107\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039964; batch adversarial loss: 0.533129\n",
      "epoch 139; iter: 0; batch classifier loss: 0.027005; batch adversarial loss: 0.451416\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021478; batch adversarial loss: 0.442628\n",
      "epoch 141; iter: 0; batch classifier loss: 0.073923; batch adversarial loss: 0.380363\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034088; batch adversarial loss: 0.508399\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039924; batch adversarial loss: 0.381360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.028079; batch adversarial loss: 0.441890\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038734; batch adversarial loss: 0.411103\n",
      "epoch 146; iter: 0; batch classifier loss: 0.009175; batch adversarial loss: 0.480357\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021717; batch adversarial loss: 0.473888\n",
      "epoch 148; iter: 0; batch classifier loss: 0.070885; batch adversarial loss: 0.449102\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031455; batch adversarial loss: 0.400887\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030983; batch adversarial loss: 0.479698\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025397; batch adversarial loss: 0.410518\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035018; batch adversarial loss: 0.428533\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038533; batch adversarial loss: 0.445937\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033059; batch adversarial loss: 0.590131\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036900; batch adversarial loss: 0.479344\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043779; batch adversarial loss: 0.434424\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041522; batch adversarial loss: 0.479776\n",
      "epoch 158; iter: 0; batch classifier loss: 0.007260; batch adversarial loss: 0.561528\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035534; batch adversarial loss: 0.536383\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036916; batch adversarial loss: 0.405086\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040784; batch adversarial loss: 0.432142\n",
      "epoch 162; iter: 0; batch classifier loss: 0.048516; batch adversarial loss: 0.532074\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032534; batch adversarial loss: 0.429608\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014867; batch adversarial loss: 0.418028\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040781; batch adversarial loss: 0.557541\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023739; batch adversarial loss: 0.371449\n",
      "epoch 167; iter: 0; batch classifier loss: 0.072235; batch adversarial loss: 0.491801\n",
      "epoch 168; iter: 0; batch classifier loss: 0.070138; batch adversarial loss: 0.463389\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037961; batch adversarial loss: 0.457023\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020273; batch adversarial loss: 0.447546\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012475; batch adversarial loss: 0.449966\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024627; batch adversarial loss: 0.331960\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032328; batch adversarial loss: 0.542144\n",
      "epoch 174; iter: 0; batch classifier loss: 0.044208; batch adversarial loss: 0.546538\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026741; batch adversarial loss: 0.508130\n",
      "epoch 176; iter: 0; batch classifier loss: 0.043160; batch adversarial loss: 0.466996\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016892; batch adversarial loss: 0.439594\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013276; batch adversarial loss: 0.332664\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019046; batch adversarial loss: 0.479046\n",
      "epoch 180; iter: 0; batch classifier loss: 0.046263; batch adversarial loss: 0.464375\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008938; batch adversarial loss: 0.532936\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018140; batch adversarial loss: 0.457996\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019957; batch adversarial loss: 0.436996\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024319; batch adversarial loss: 0.491441\n",
      "epoch 185; iter: 0; batch classifier loss: 0.052222; batch adversarial loss: 0.442703\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022583; batch adversarial loss: 0.500634\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024395; batch adversarial loss: 0.411964\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018773; batch adversarial loss: 0.511249\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006156; batch adversarial loss: 0.429926\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022265; batch adversarial loss: 0.378053\n",
      "epoch 191; iter: 0; batch classifier loss: 0.036288; batch adversarial loss: 0.411571\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012704; batch adversarial loss: 0.495414\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030297; batch adversarial loss: 0.453860\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034807; batch adversarial loss: 0.399089\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009995; batch adversarial loss: 0.481192\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018709; batch adversarial loss: 0.533223\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007275; batch adversarial loss: 0.451920\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013292; batch adversarial loss: 0.490906\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012258; batch adversarial loss: 0.407532\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681365; batch adversarial loss: 0.814852\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608138; batch adversarial loss: 0.806767\n",
      "epoch 2; iter: 0; batch classifier loss: 0.727430; batch adversarial loss: 0.803576\n",
      "epoch 3; iter: 0; batch classifier loss: 0.732010; batch adversarial loss: 0.719371\n",
      "epoch 4; iter: 0; batch classifier loss: 0.564328; batch adversarial loss: 0.626916\n",
      "epoch 5; iter: 0; batch classifier loss: 0.466739; batch adversarial loss: 0.563201\n",
      "epoch 6; iter: 0; batch classifier loss: 0.373353; batch adversarial loss: 0.547030\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338952; batch adversarial loss: 0.552538\n",
      "epoch 8; iter: 0; batch classifier loss: 0.231779; batch adversarial loss: 0.549465\n",
      "epoch 9; iter: 0; batch classifier loss: 0.274950; batch adversarial loss: 0.530966\n",
      "epoch 10; iter: 0; batch classifier loss: 0.264456; batch adversarial loss: 0.492982\n",
      "epoch 11; iter: 0; batch classifier loss: 0.254648; batch adversarial loss: 0.594892\n",
      "epoch 12; iter: 0; batch classifier loss: 0.241986; batch adversarial loss: 0.530805\n",
      "epoch 13; iter: 0; batch classifier loss: 0.245492; batch adversarial loss: 0.444343\n",
      "epoch 14; iter: 0; batch classifier loss: 0.228638; batch adversarial loss: 0.485756\n",
      "epoch 15; iter: 0; batch classifier loss: 0.201734; batch adversarial loss: 0.464555\n",
      "epoch 16; iter: 0; batch classifier loss: 0.220743; batch adversarial loss: 0.629799\n",
      "epoch 17; iter: 0; batch classifier loss: 0.258162; batch adversarial loss: 0.435448\n",
      "epoch 18; iter: 0; batch classifier loss: 0.159281; batch adversarial loss: 0.517969\n",
      "epoch 19; iter: 0; batch classifier loss: 0.240524; batch adversarial loss: 0.398299\n",
      "epoch 20; iter: 0; batch classifier loss: 0.253242; batch adversarial loss: 0.401806\n",
      "epoch 21; iter: 0; batch classifier loss: 0.250817; batch adversarial loss: 0.481081\n",
      "epoch 22; iter: 0; batch classifier loss: 0.145671; batch adversarial loss: 0.459453\n",
      "epoch 23; iter: 0; batch classifier loss: 0.216482; batch adversarial loss: 0.433209\n",
      "epoch 24; iter: 0; batch classifier loss: 0.173820; batch adversarial loss: 0.552027\n",
      "epoch 25; iter: 0; batch classifier loss: 0.148720; batch adversarial loss: 0.501037\n",
      "epoch 26; iter: 0; batch classifier loss: 0.137976; batch adversarial loss: 0.472627\n",
      "epoch 27; iter: 0; batch classifier loss: 0.131088; batch adversarial loss: 0.481667\n",
      "epoch 28; iter: 0; batch classifier loss: 0.129740; batch adversarial loss: 0.549027\n",
      "epoch 29; iter: 0; batch classifier loss: 0.124997; batch adversarial loss: 0.522186\n",
      "epoch 30; iter: 0; batch classifier loss: 0.126019; batch adversarial loss: 0.437507\n",
      "epoch 31; iter: 0; batch classifier loss: 0.132196; batch adversarial loss: 0.433370\n",
      "epoch 32; iter: 0; batch classifier loss: 0.137561; batch adversarial loss: 0.512166\n",
      "epoch 33; iter: 0; batch classifier loss: 0.123455; batch adversarial loss: 0.537131\n",
      "epoch 34; iter: 0; batch classifier loss: 0.091945; batch adversarial loss: 0.540119\n",
      "epoch 35; iter: 0; batch classifier loss: 0.146239; batch adversarial loss: 0.428302\n",
      "epoch 36; iter: 0; batch classifier loss: 0.115759; batch adversarial loss: 0.438110\n",
      "epoch 37; iter: 0; batch classifier loss: 0.143669; batch adversarial loss: 0.401035\n",
      "epoch 38; iter: 0; batch classifier loss: 0.088652; batch adversarial loss: 0.478945\n",
      "epoch 39; iter: 0; batch classifier loss: 0.123034; batch adversarial loss: 0.399108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.084484; batch adversarial loss: 0.556726\n",
      "epoch 41; iter: 0; batch classifier loss: 0.081773; batch adversarial loss: 0.436418\n",
      "epoch 42; iter: 0; batch classifier loss: 0.081824; batch adversarial loss: 0.488699\n",
      "epoch 43; iter: 0; batch classifier loss: 0.123255; batch adversarial loss: 0.511090\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136532; batch adversarial loss: 0.372380\n",
      "epoch 45; iter: 0; batch classifier loss: 0.159198; batch adversarial loss: 0.317664\n",
      "epoch 46; iter: 0; batch classifier loss: 0.072625; batch adversarial loss: 0.394003\n",
      "epoch 47; iter: 0; batch classifier loss: 0.077017; batch adversarial loss: 0.466393\n",
      "epoch 48; iter: 0; batch classifier loss: 0.068194; batch adversarial loss: 0.494308\n",
      "epoch 49; iter: 0; batch classifier loss: 0.110079; batch adversarial loss: 0.483720\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087377; batch adversarial loss: 0.419909\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121668; batch adversarial loss: 0.398369\n",
      "epoch 52; iter: 0; batch classifier loss: 0.131610; batch adversarial loss: 0.424596\n",
      "epoch 53; iter: 0; batch classifier loss: 0.097795; batch adversarial loss: 0.501965\n",
      "epoch 54; iter: 0; batch classifier loss: 0.159978; batch adversarial loss: 0.379066\n",
      "epoch 55; iter: 0; batch classifier loss: 0.062827; batch adversarial loss: 0.470777\n",
      "epoch 56; iter: 0; batch classifier loss: 0.110581; batch adversarial loss: 0.526475\n",
      "epoch 57; iter: 0; batch classifier loss: 0.104593; batch adversarial loss: 0.532774\n",
      "epoch 58; iter: 0; batch classifier loss: 0.064859; batch adversarial loss: 0.497360\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081766; batch adversarial loss: 0.407146\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076247; batch adversarial loss: 0.425972\n",
      "epoch 61; iter: 0; batch classifier loss: 0.065618; batch adversarial loss: 0.527547\n",
      "epoch 62; iter: 0; batch classifier loss: 0.053410; batch adversarial loss: 0.428446\n",
      "epoch 63; iter: 0; batch classifier loss: 0.045215; batch adversarial loss: 0.477647\n",
      "epoch 64; iter: 0; batch classifier loss: 0.051160; batch adversarial loss: 0.388469\n",
      "epoch 65; iter: 0; batch classifier loss: 0.064932; batch adversarial loss: 0.535028\n",
      "epoch 66; iter: 0; batch classifier loss: 0.064311; batch adversarial loss: 0.358043\n",
      "epoch 67; iter: 0; batch classifier loss: 0.053007; batch adversarial loss: 0.503018\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081326; batch adversarial loss: 0.451608\n",
      "epoch 69; iter: 0; batch classifier loss: 0.052830; batch adversarial loss: 0.513156\n",
      "epoch 70; iter: 0; batch classifier loss: 0.032865; batch adversarial loss: 0.447979\n",
      "epoch 71; iter: 0; batch classifier loss: 0.108823; batch adversarial loss: 0.417136\n",
      "epoch 72; iter: 0; batch classifier loss: 0.069473; batch adversarial loss: 0.515087\n",
      "epoch 73; iter: 0; batch classifier loss: 0.029625; batch adversarial loss: 0.497741\n",
      "epoch 74; iter: 0; batch classifier loss: 0.106989; batch adversarial loss: 0.426021\n",
      "epoch 75; iter: 0; batch classifier loss: 0.072098; batch adversarial loss: 0.506398\n",
      "epoch 76; iter: 0; batch classifier loss: 0.066983; batch adversarial loss: 0.380379\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064783; batch adversarial loss: 0.556173\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064387; batch adversarial loss: 0.489370\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076822; batch adversarial loss: 0.386245\n",
      "epoch 80; iter: 0; batch classifier loss: 0.057747; batch adversarial loss: 0.427429\n",
      "epoch 81; iter: 0; batch classifier loss: 0.086539; batch adversarial loss: 0.397588\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053096; batch adversarial loss: 0.444819\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035704; batch adversarial loss: 0.495606\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052232; batch adversarial loss: 0.372428\n",
      "epoch 85; iter: 0; batch classifier loss: 0.060451; batch adversarial loss: 0.507512\n",
      "epoch 86; iter: 0; batch classifier loss: 0.039872; batch adversarial loss: 0.369574\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042934; batch adversarial loss: 0.520478\n",
      "epoch 88; iter: 0; batch classifier loss: 0.027310; batch adversarial loss: 0.452499\n",
      "epoch 89; iter: 0; batch classifier loss: 0.033923; batch adversarial loss: 0.439478\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066624; batch adversarial loss: 0.409370\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063693; batch adversarial loss: 0.512914\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063939; batch adversarial loss: 0.445395\n",
      "epoch 93; iter: 0; batch classifier loss: 0.068336; batch adversarial loss: 0.458186\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079575; batch adversarial loss: 0.521006\n",
      "epoch 95; iter: 0; batch classifier loss: 0.061945; batch adversarial loss: 0.492295\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047378; batch adversarial loss: 0.444803\n",
      "epoch 97; iter: 0; batch classifier loss: 0.032976; batch adversarial loss: 0.517438\n",
      "epoch 98; iter: 0; batch classifier loss: 0.014467; batch adversarial loss: 0.397380\n",
      "epoch 99; iter: 0; batch classifier loss: 0.015450; batch adversarial loss: 0.572442\n",
      "epoch 100; iter: 0; batch classifier loss: 0.019204; batch adversarial loss: 0.356874\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042553; batch adversarial loss: 0.444745\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031966; batch adversarial loss: 0.453430\n",
      "epoch 103; iter: 0; batch classifier loss: 0.022121; batch adversarial loss: 0.516425\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031553; batch adversarial loss: 0.421215\n",
      "epoch 105; iter: 0; batch classifier loss: 0.012505; batch adversarial loss: 0.462799\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058497; batch adversarial loss: 0.509601\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040023; batch adversarial loss: 0.442987\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051499; batch adversarial loss: 0.440142\n",
      "epoch 109; iter: 0; batch classifier loss: 0.022343; batch adversarial loss: 0.421423\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025150; batch adversarial loss: 0.455906\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069983; batch adversarial loss: 0.395077\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055427; batch adversarial loss: 0.442633\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038986; batch adversarial loss: 0.405852\n",
      "epoch 114; iter: 0; batch classifier loss: 0.067906; batch adversarial loss: 0.435747\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040344; batch adversarial loss: 0.488763\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045110; batch adversarial loss: 0.471571\n",
      "epoch 117; iter: 0; batch classifier loss: 0.022225; batch adversarial loss: 0.382060\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046114; batch adversarial loss: 0.459980\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025126; batch adversarial loss: 0.415970\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028030; batch adversarial loss: 0.423457\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051112; batch adversarial loss: 0.364340\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032280; batch adversarial loss: 0.463674\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055283; batch adversarial loss: 0.511669\n",
      "epoch 124; iter: 0; batch classifier loss: 0.014015; batch adversarial loss: 0.414711\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039880; batch adversarial loss: 0.557269\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038387; batch adversarial loss: 0.366556\n",
      "epoch 127; iter: 0; batch classifier loss: 0.005919; batch adversarial loss: 0.428670\n",
      "epoch 128; iter: 0; batch classifier loss: 0.020109; batch adversarial loss: 0.358630\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017968; batch adversarial loss: 0.514187\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019007; batch adversarial loss: 0.437671\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019221; batch adversarial loss: 0.445583\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022851; batch adversarial loss: 0.485598\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025364; batch adversarial loss: 0.481035\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019595; batch adversarial loss: 0.462482\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014766; batch adversarial loss: 0.436337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.027804; batch adversarial loss: 0.364206\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052479; batch adversarial loss: 0.424845\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022918; batch adversarial loss: 0.460726\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040852; batch adversarial loss: 0.394348\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033318; batch adversarial loss: 0.528179\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020862; batch adversarial loss: 0.555017\n",
      "epoch 142; iter: 0; batch classifier loss: 0.009162; batch adversarial loss: 0.421986\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015954; batch adversarial loss: 0.509885\n",
      "epoch 144; iter: 0; batch classifier loss: 0.009083; batch adversarial loss: 0.430760\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017789; batch adversarial loss: 0.413735\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010269; batch adversarial loss: 0.341821\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035636; batch adversarial loss: 0.388963\n",
      "epoch 148; iter: 0; batch classifier loss: 0.011834; batch adversarial loss: 0.527025\n",
      "epoch 149; iter: 0; batch classifier loss: 0.010616; batch adversarial loss: 0.522107\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024819; batch adversarial loss: 0.421667\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021300; batch adversarial loss: 0.448382\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010629; batch adversarial loss: 0.450974\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012814; batch adversarial loss: 0.468831\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014586; batch adversarial loss: 0.485394\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026367; batch adversarial loss: 0.426071\n",
      "epoch 156; iter: 0; batch classifier loss: 0.004548; batch adversarial loss: 0.512519\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025466; batch adversarial loss: 0.524509\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027406; batch adversarial loss: 0.438015\n",
      "epoch 159; iter: 0; batch classifier loss: 0.092488; batch adversarial loss: 0.407781\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013910; batch adversarial loss: 0.408961\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013671; batch adversarial loss: 0.430937\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031881; batch adversarial loss: 0.365402\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010702; batch adversarial loss: 0.391270\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020000; batch adversarial loss: 0.479322\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021302; batch adversarial loss: 0.352531\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028873; batch adversarial loss: 0.423302\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009956; batch adversarial loss: 0.443981\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019221; batch adversarial loss: 0.502270\n",
      "epoch 169; iter: 0; batch classifier loss: 0.002972; batch adversarial loss: 0.482296\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026140; batch adversarial loss: 0.400146\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027589; batch adversarial loss: 0.495531\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012906; batch adversarial loss: 0.368395\n",
      "epoch 173; iter: 0; batch classifier loss: 0.039529; batch adversarial loss: 0.447516\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016470; batch adversarial loss: 0.504222\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032659; batch adversarial loss: 0.462866\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030986; batch adversarial loss: 0.449447\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033115; batch adversarial loss: 0.475985\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020157; batch adversarial loss: 0.580728\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025359; batch adversarial loss: 0.506049\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018169; batch adversarial loss: 0.437379\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017792; batch adversarial loss: 0.500313\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014445; batch adversarial loss: 0.487162\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008143; batch adversarial loss: 0.511542\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030894; batch adversarial loss: 0.455038\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007087; batch adversarial loss: 0.372617\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008300; batch adversarial loss: 0.450138\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012287; batch adversarial loss: 0.468350\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027534; batch adversarial loss: 0.336113\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006841; batch adversarial loss: 0.442533\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006624; batch adversarial loss: 0.433162\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016104; batch adversarial loss: 0.477536\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015074; batch adversarial loss: 0.512380\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020272; batch adversarial loss: 0.402297\n",
      "epoch 194; iter: 0; batch classifier loss: 0.003547; batch adversarial loss: 0.405432\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009482; batch adversarial loss: 0.382137\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020263; batch adversarial loss: 0.451589\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019992; batch adversarial loss: 0.502725\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006400; batch adversarial loss: 0.631945\n",
      "epoch 199; iter: 0; batch classifier loss: 0.003815; batch adversarial loss: 0.450652\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677594; batch adversarial loss: 0.604129\n",
      "epoch 1; iter: 0; batch classifier loss: 0.348513; batch adversarial loss: 0.621001\n",
      "epoch 2; iter: 0; batch classifier loss: 0.293953; batch adversarial loss: 0.603501\n",
      "epoch 3; iter: 0; batch classifier loss: 0.351938; batch adversarial loss: 0.547658\n",
      "epoch 4; iter: 0; batch classifier loss: 0.244580; batch adversarial loss: 0.537087\n",
      "epoch 5; iter: 0; batch classifier loss: 0.377170; batch adversarial loss: 0.564796\n",
      "epoch 6; iter: 0; batch classifier loss: 0.337715; batch adversarial loss: 0.546066\n",
      "epoch 7; iter: 0; batch classifier loss: 0.273589; batch adversarial loss: 0.492236\n",
      "epoch 8; iter: 0; batch classifier loss: 0.224253; batch adversarial loss: 0.562450\n",
      "epoch 9; iter: 0; batch classifier loss: 0.305378; batch adversarial loss: 0.581616\n",
      "epoch 10; iter: 0; batch classifier loss: 0.235049; batch adversarial loss: 0.507867\n",
      "epoch 11; iter: 0; batch classifier loss: 0.267720; batch adversarial loss: 0.520915\n",
      "epoch 12; iter: 0; batch classifier loss: 0.272146; batch adversarial loss: 0.569351\n",
      "epoch 13; iter: 0; batch classifier loss: 0.228851; batch adversarial loss: 0.504793\n",
      "epoch 14; iter: 0; batch classifier loss: 0.366665; batch adversarial loss: 0.476886\n",
      "epoch 15; iter: 0; batch classifier loss: 0.356636; batch adversarial loss: 0.565669\n",
      "epoch 16; iter: 0; batch classifier loss: 0.357736; batch adversarial loss: 0.572610\n",
      "epoch 17; iter: 0; batch classifier loss: 0.393637; batch adversarial loss: 0.508198\n",
      "epoch 18; iter: 0; batch classifier loss: 0.430380; batch adversarial loss: 0.461393\n",
      "epoch 19; iter: 0; batch classifier loss: 0.356823; batch adversarial loss: 0.455756\n",
      "epoch 20; iter: 0; batch classifier loss: 0.302396; batch adversarial loss: 0.522515\n",
      "epoch 21; iter: 0; batch classifier loss: 0.273590; batch adversarial loss: 0.474966\n",
      "epoch 22; iter: 0; batch classifier loss: 0.170341; batch adversarial loss: 0.523990\n",
      "epoch 23; iter: 0; batch classifier loss: 0.157941; batch adversarial loss: 0.477954\n",
      "epoch 24; iter: 0; batch classifier loss: 0.159351; batch adversarial loss: 0.546355\n",
      "epoch 25; iter: 0; batch classifier loss: 0.155016; batch adversarial loss: 0.442519\n",
      "epoch 26; iter: 0; batch classifier loss: 0.131149; batch adversarial loss: 0.511419\n",
      "epoch 27; iter: 0; batch classifier loss: 0.155938; batch adversarial loss: 0.452020\n",
      "epoch 28; iter: 0; batch classifier loss: 0.114065; batch adversarial loss: 0.388293\n",
      "epoch 29; iter: 0; batch classifier loss: 0.182508; batch adversarial loss: 0.447971\n",
      "epoch 30; iter: 0; batch classifier loss: 0.129240; batch adversarial loss: 0.423384\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156000; batch adversarial loss: 0.524874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.085279; batch adversarial loss: 0.451440\n",
      "epoch 33; iter: 0; batch classifier loss: 0.079032; batch adversarial loss: 0.487512\n",
      "epoch 34; iter: 0; batch classifier loss: 0.132226; batch adversarial loss: 0.405649\n",
      "epoch 35; iter: 0; batch classifier loss: 0.101318; batch adversarial loss: 0.471085\n",
      "epoch 36; iter: 0; batch classifier loss: 0.116211; batch adversarial loss: 0.501079\n",
      "epoch 37; iter: 0; batch classifier loss: 0.131916; batch adversarial loss: 0.455022\n",
      "epoch 38; iter: 0; batch classifier loss: 0.125293; batch adversarial loss: 0.452110\n",
      "epoch 39; iter: 0; batch classifier loss: 0.120570; batch adversarial loss: 0.421775\n",
      "epoch 40; iter: 0; batch classifier loss: 0.111780; batch adversarial loss: 0.461848\n",
      "epoch 41; iter: 0; batch classifier loss: 0.096472; batch adversarial loss: 0.510390\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088523; batch adversarial loss: 0.522796\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110316; batch adversarial loss: 0.443508\n",
      "epoch 44; iter: 0; batch classifier loss: 0.115818; batch adversarial loss: 0.431546\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117839; batch adversarial loss: 0.441133\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126279; batch adversarial loss: 0.468442\n",
      "epoch 47; iter: 0; batch classifier loss: 0.090704; batch adversarial loss: 0.468780\n",
      "epoch 48; iter: 0; batch classifier loss: 0.098114; batch adversarial loss: 0.392886\n",
      "epoch 49; iter: 0; batch classifier loss: 0.120935; batch adversarial loss: 0.423788\n",
      "epoch 50; iter: 0; batch classifier loss: 0.171883; batch adversarial loss: 0.450296\n",
      "epoch 51; iter: 0; batch classifier loss: 0.082315; batch adversarial loss: 0.494137\n",
      "epoch 52; iter: 0; batch classifier loss: 0.086216; batch adversarial loss: 0.527832\n",
      "epoch 53; iter: 0; batch classifier loss: 0.102847; batch adversarial loss: 0.444928\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096482; batch adversarial loss: 0.593212\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096814; batch adversarial loss: 0.524973\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065062; batch adversarial loss: 0.530242\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086385; batch adversarial loss: 0.472993\n",
      "epoch 58; iter: 0; batch classifier loss: 0.112435; batch adversarial loss: 0.443607\n",
      "epoch 59; iter: 0; batch classifier loss: 0.113413; batch adversarial loss: 0.469411\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097860; batch adversarial loss: 0.542504\n",
      "epoch 61; iter: 0; batch classifier loss: 0.073260; batch adversarial loss: 0.443880\n",
      "epoch 62; iter: 0; batch classifier loss: 0.122632; batch adversarial loss: 0.415626\n",
      "epoch 63; iter: 0; batch classifier loss: 0.061515; batch adversarial loss: 0.476971\n",
      "epoch 64; iter: 0; batch classifier loss: 0.085713; batch adversarial loss: 0.464265\n",
      "epoch 65; iter: 0; batch classifier loss: 0.093430; batch adversarial loss: 0.401212\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086818; batch adversarial loss: 0.383532\n",
      "epoch 67; iter: 0; batch classifier loss: 0.050451; batch adversarial loss: 0.390727\n",
      "epoch 68; iter: 0; batch classifier loss: 0.084072; batch adversarial loss: 0.471077\n",
      "epoch 69; iter: 0; batch classifier loss: 0.146458; batch adversarial loss: 0.406624\n",
      "epoch 70; iter: 0; batch classifier loss: 0.100501; batch adversarial loss: 0.551457\n",
      "epoch 71; iter: 0; batch classifier loss: 0.125887; batch adversarial loss: 0.569297\n",
      "epoch 72; iter: 0; batch classifier loss: 0.119510; batch adversarial loss: 0.458185\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077779; batch adversarial loss: 0.608473\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053750; batch adversarial loss: 0.406148\n",
      "epoch 75; iter: 0; batch classifier loss: 0.051684; batch adversarial loss: 0.437720\n",
      "epoch 76; iter: 0; batch classifier loss: 0.078667; batch adversarial loss: 0.422986\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062336; batch adversarial loss: 0.406107\n",
      "epoch 78; iter: 0; batch classifier loss: 0.078829; batch adversarial loss: 0.353279\n",
      "epoch 79; iter: 0; batch classifier loss: 0.089104; batch adversarial loss: 0.390686\n",
      "epoch 80; iter: 0; batch classifier loss: 0.111157; batch adversarial loss: 0.471349\n",
      "epoch 81; iter: 0; batch classifier loss: 0.102675; batch adversarial loss: 0.449016\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090685; batch adversarial loss: 0.471532\n",
      "epoch 83; iter: 0; batch classifier loss: 0.077997; batch adversarial loss: 0.388894\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045110; batch adversarial loss: 0.446221\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061414; batch adversarial loss: 0.531232\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069594; batch adversarial loss: 0.476797\n",
      "epoch 87; iter: 0; batch classifier loss: 0.058557; batch adversarial loss: 0.425101\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070247; batch adversarial loss: 0.401070\n",
      "epoch 89; iter: 0; batch classifier loss: 0.121354; batch adversarial loss: 0.464477\n",
      "epoch 90; iter: 0; batch classifier loss: 0.095590; batch adversarial loss: 0.429233\n",
      "epoch 91; iter: 0; batch classifier loss: 0.093033; batch adversarial loss: 0.445230\n",
      "epoch 92; iter: 0; batch classifier loss: 0.084540; batch adversarial loss: 0.496445\n",
      "epoch 93; iter: 0; batch classifier loss: 0.119214; batch adversarial loss: 0.392687\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048229; batch adversarial loss: 0.436876\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048619; batch adversarial loss: 0.528908\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063672; batch adversarial loss: 0.386871\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062448; batch adversarial loss: 0.443499\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062013; batch adversarial loss: 0.425319\n",
      "epoch 99; iter: 0; batch classifier loss: 0.083881; batch adversarial loss: 0.465657\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066908; batch adversarial loss: 0.445593\n",
      "epoch 101; iter: 0; batch classifier loss: 0.073605; batch adversarial loss: 0.434363\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071508; batch adversarial loss: 0.429136\n",
      "epoch 103; iter: 0; batch classifier loss: 0.074062; batch adversarial loss: 0.474252\n",
      "epoch 104; iter: 0; batch classifier loss: 0.082782; batch adversarial loss: 0.428191\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076752; batch adversarial loss: 0.457786\n",
      "epoch 106; iter: 0; batch classifier loss: 0.090889; batch adversarial loss: 0.549127\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056841; batch adversarial loss: 0.432536\n",
      "epoch 108; iter: 0; batch classifier loss: 0.063037; batch adversarial loss: 0.546360\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058966; batch adversarial loss: 0.440642\n",
      "epoch 110; iter: 0; batch classifier loss: 0.078981; batch adversarial loss: 0.450913\n",
      "epoch 111; iter: 0; batch classifier loss: 0.088602; batch adversarial loss: 0.453594\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059648; batch adversarial loss: 0.406197\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054102; batch adversarial loss: 0.570740\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041959; batch adversarial loss: 0.440272\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051836; batch adversarial loss: 0.370854\n",
      "epoch 116; iter: 0; batch classifier loss: 0.049599; batch adversarial loss: 0.461286\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044689; batch adversarial loss: 0.395095\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041040; batch adversarial loss: 0.461305\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056041; batch adversarial loss: 0.449627\n",
      "epoch 120; iter: 0; batch classifier loss: 0.072003; batch adversarial loss: 0.377358\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039591; batch adversarial loss: 0.476053\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052804; batch adversarial loss: 0.420054\n",
      "epoch 123; iter: 0; batch classifier loss: 0.082017; batch adversarial loss: 0.486202\n",
      "epoch 124; iter: 0; batch classifier loss: 0.063790; batch adversarial loss: 0.446069\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030709; batch adversarial loss: 0.428931\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028668; batch adversarial loss: 0.441373\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048224; batch adversarial loss: 0.432003\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063397; batch adversarial loss: 0.413247\n",
      "epoch 129; iter: 0; batch classifier loss: 0.073974; batch adversarial loss: 0.313132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.027816; batch adversarial loss: 0.415056\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026610; batch adversarial loss: 0.457602\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050434; batch adversarial loss: 0.409058\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030514; batch adversarial loss: 0.412831\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036234; batch adversarial loss: 0.417695\n",
      "epoch 135; iter: 0; batch classifier loss: 0.048911; batch adversarial loss: 0.434324\n",
      "epoch 136; iter: 0; batch classifier loss: 0.048152; batch adversarial loss: 0.381887\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037516; batch adversarial loss: 0.482198\n",
      "epoch 138; iter: 0; batch classifier loss: 0.068103; batch adversarial loss: 0.355198\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034615; batch adversarial loss: 0.466388\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026269; batch adversarial loss: 0.475312\n",
      "epoch 141; iter: 0; batch classifier loss: 0.062252; batch adversarial loss: 0.464275\n",
      "epoch 142; iter: 0; batch classifier loss: 0.054309; batch adversarial loss: 0.504038\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015658; batch adversarial loss: 0.505937\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039409; batch adversarial loss: 0.278473\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025897; batch adversarial loss: 0.495126\n",
      "epoch 146; iter: 0; batch classifier loss: 0.074349; batch adversarial loss: 0.331235\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040311; batch adversarial loss: 0.475190\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040582; batch adversarial loss: 0.411257\n",
      "epoch 149; iter: 0; batch classifier loss: 0.060950; batch adversarial loss: 0.510114\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030027; batch adversarial loss: 0.471148\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028212; batch adversarial loss: 0.396322\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039602; batch adversarial loss: 0.546760\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042412; batch adversarial loss: 0.492782\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032913; batch adversarial loss: 0.476538\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038786; batch adversarial loss: 0.502437\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040361; batch adversarial loss: 0.513130\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032323; batch adversarial loss: 0.464300\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028914; batch adversarial loss: 0.553172\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026494; batch adversarial loss: 0.543683\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037098; batch adversarial loss: 0.461480\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027610; batch adversarial loss: 0.489217\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023119; batch adversarial loss: 0.446527\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019775; batch adversarial loss: 0.524916\n",
      "epoch 164; iter: 0; batch classifier loss: 0.044518; batch adversarial loss: 0.405966\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022884; batch adversarial loss: 0.502128\n",
      "epoch 166; iter: 0; batch classifier loss: 0.039282; batch adversarial loss: 0.542355\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029492; batch adversarial loss: 0.375702\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023402; batch adversarial loss: 0.444774\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023620; batch adversarial loss: 0.495998\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013582; batch adversarial loss: 0.438052\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012794; batch adversarial loss: 0.575117\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028907; batch adversarial loss: 0.565015\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031758; batch adversarial loss: 0.495172\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032916; batch adversarial loss: 0.500548\n",
      "epoch 175; iter: 0; batch classifier loss: 0.054559; batch adversarial loss: 0.473582\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045592; batch adversarial loss: 0.411975\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025778; batch adversarial loss: 0.421649\n",
      "epoch 178; iter: 0; batch classifier loss: 0.045881; batch adversarial loss: 0.431833\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017830; batch adversarial loss: 0.458222\n",
      "epoch 180; iter: 0; batch classifier loss: 0.044132; batch adversarial loss: 0.478162\n",
      "epoch 181; iter: 0; batch classifier loss: 0.044011; batch adversarial loss: 0.425679\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020059; batch adversarial loss: 0.562540\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016286; batch adversarial loss: 0.487059\n",
      "epoch 184; iter: 0; batch classifier loss: 0.047675; batch adversarial loss: 0.409729\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037578; batch adversarial loss: 0.482478\n",
      "epoch 186; iter: 0; batch classifier loss: 0.077232; batch adversarial loss: 0.463287\n",
      "epoch 187; iter: 0; batch classifier loss: 0.062062; batch adversarial loss: 0.346712\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024948; batch adversarial loss: 0.503688\n",
      "epoch 189; iter: 0; batch classifier loss: 0.049527; batch adversarial loss: 0.362258\n",
      "epoch 190; iter: 0; batch classifier loss: 0.038806; batch adversarial loss: 0.416517\n",
      "epoch 191; iter: 0; batch classifier loss: 0.041980; batch adversarial loss: 0.487101\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008962; batch adversarial loss: 0.547939\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025846; batch adversarial loss: 0.453150\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015345; batch adversarial loss: 0.515952\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023975; batch adversarial loss: 0.432065\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028356; batch adversarial loss: 0.486613\n",
      "epoch 197; iter: 0; batch classifier loss: 0.054672; batch adversarial loss: 0.421909\n",
      "epoch 198; iter: 0; batch classifier loss: 0.065858; batch adversarial loss: 0.444566\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030537; batch adversarial loss: 0.422035\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700113; batch adversarial loss: 0.834810\n",
      "epoch 1; iter: 0; batch classifier loss: 0.502937; batch adversarial loss: 0.769677\n",
      "epoch 2; iter: 0; batch classifier loss: 0.325158; batch adversarial loss: 0.751292\n",
      "epoch 3; iter: 0; batch classifier loss: 0.351101; batch adversarial loss: 0.726984\n",
      "epoch 4; iter: 0; batch classifier loss: 0.331419; batch adversarial loss: 0.711049\n",
      "epoch 5; iter: 0; batch classifier loss: 0.321719; batch adversarial loss: 0.660682\n",
      "epoch 6; iter: 0; batch classifier loss: 0.280651; batch adversarial loss: 0.640413\n",
      "epoch 7; iter: 0; batch classifier loss: 0.315498; batch adversarial loss: 0.606066\n",
      "epoch 8; iter: 0; batch classifier loss: 0.338326; batch adversarial loss: 0.556673\n",
      "epoch 9; iter: 0; batch classifier loss: 0.299855; batch adversarial loss: 0.557551\n",
      "epoch 10; iter: 0; batch classifier loss: 0.333761; batch adversarial loss: 0.522765\n",
      "epoch 11; iter: 0; batch classifier loss: 0.268426; batch adversarial loss: 0.502734\n",
      "epoch 12; iter: 0; batch classifier loss: 0.300015; batch adversarial loss: 0.439925\n",
      "epoch 13; iter: 0; batch classifier loss: 0.283218; batch adversarial loss: 0.488759\n",
      "epoch 14; iter: 0; batch classifier loss: 0.212908; batch adversarial loss: 0.478671\n",
      "epoch 15; iter: 0; batch classifier loss: 0.192605; batch adversarial loss: 0.445799\n",
      "epoch 16; iter: 0; batch classifier loss: 0.210231; batch adversarial loss: 0.479392\n",
      "epoch 17; iter: 0; batch classifier loss: 0.203021; batch adversarial loss: 0.407395\n",
      "epoch 18; iter: 0; batch classifier loss: 0.206822; batch adversarial loss: 0.433395\n",
      "epoch 19; iter: 0; batch classifier loss: 0.198007; batch adversarial loss: 0.504558\n",
      "epoch 20; iter: 0; batch classifier loss: 0.188734; batch adversarial loss: 0.414614\n",
      "epoch 21; iter: 0; batch classifier loss: 0.210138; batch adversarial loss: 0.409742\n",
      "epoch 22; iter: 0; batch classifier loss: 0.158787; batch adversarial loss: 0.452897\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168246; batch adversarial loss: 0.420636\n",
      "epoch 24; iter: 0; batch classifier loss: 0.173007; batch adversarial loss: 0.393005\n",
      "epoch 25; iter: 0; batch classifier loss: 0.182310; batch adversarial loss: 0.359413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.144802; batch adversarial loss: 0.408798\n",
      "epoch 27; iter: 0; batch classifier loss: 0.206114; batch adversarial loss: 0.416519\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173602; batch adversarial loss: 0.406949\n",
      "epoch 29; iter: 0; batch classifier loss: 0.203410; batch adversarial loss: 0.496123\n",
      "epoch 30; iter: 0; batch classifier loss: 0.145748; batch adversarial loss: 0.413023\n",
      "epoch 31; iter: 0; batch classifier loss: 0.211409; batch adversarial loss: 0.398359\n",
      "epoch 32; iter: 0; batch classifier loss: 0.225819; batch adversarial loss: 0.393732\n",
      "epoch 33; iter: 0; batch classifier loss: 0.128559; batch adversarial loss: 0.441371\n",
      "epoch 34; iter: 0; batch classifier loss: 0.104548; batch adversarial loss: 0.519195\n",
      "epoch 35; iter: 0; batch classifier loss: 0.144559; batch adversarial loss: 0.396681\n",
      "epoch 36; iter: 0; batch classifier loss: 0.152482; batch adversarial loss: 0.412053\n",
      "epoch 37; iter: 0; batch classifier loss: 0.118161; batch adversarial loss: 0.362333\n",
      "epoch 38; iter: 0; batch classifier loss: 0.130458; batch adversarial loss: 0.476497\n",
      "epoch 39; iter: 0; batch classifier loss: 0.143123; batch adversarial loss: 0.422736\n",
      "epoch 40; iter: 0; batch classifier loss: 0.114081; batch adversarial loss: 0.410989\n",
      "epoch 41; iter: 0; batch classifier loss: 0.108928; batch adversarial loss: 0.484835\n",
      "epoch 42; iter: 0; batch classifier loss: 0.080641; batch adversarial loss: 0.402427\n",
      "epoch 43; iter: 0; batch classifier loss: 0.132674; batch adversarial loss: 0.373720\n",
      "epoch 44; iter: 0; batch classifier loss: 0.130959; batch adversarial loss: 0.391622\n",
      "epoch 45; iter: 0; batch classifier loss: 0.084311; batch adversarial loss: 0.481467\n",
      "epoch 46; iter: 0; batch classifier loss: 0.141903; batch adversarial loss: 0.385630\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096546; batch adversarial loss: 0.528858\n",
      "epoch 48; iter: 0; batch classifier loss: 0.111816; batch adversarial loss: 0.378477\n",
      "epoch 49; iter: 0; batch classifier loss: 0.131811; batch adversarial loss: 0.362981\n",
      "epoch 50; iter: 0; batch classifier loss: 0.106375; batch adversarial loss: 0.383160\n",
      "epoch 51; iter: 0; batch classifier loss: 0.125695; batch adversarial loss: 0.426535\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111006; batch adversarial loss: 0.404925\n",
      "epoch 53; iter: 0; batch classifier loss: 0.114737; batch adversarial loss: 0.407681\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074956; batch adversarial loss: 0.431919\n",
      "epoch 55; iter: 0; batch classifier loss: 0.090468; batch adversarial loss: 0.385766\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102043; batch adversarial loss: 0.435508\n",
      "epoch 57; iter: 0; batch classifier loss: 0.074073; batch adversarial loss: 0.399886\n",
      "epoch 58; iter: 0; batch classifier loss: 0.120074; batch adversarial loss: 0.477181\n",
      "epoch 59; iter: 0; batch classifier loss: 0.115467; batch adversarial loss: 0.346433\n",
      "epoch 60; iter: 0; batch classifier loss: 0.120522; batch adversarial loss: 0.426722\n",
      "epoch 61; iter: 0; batch classifier loss: 0.137515; batch adversarial loss: 0.387545\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092043; batch adversarial loss: 0.439551\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093474; batch adversarial loss: 0.506269\n",
      "epoch 64; iter: 0; batch classifier loss: 0.104823; batch adversarial loss: 0.410302\n",
      "epoch 65; iter: 0; batch classifier loss: 0.064562; batch adversarial loss: 0.440735\n",
      "epoch 66; iter: 0; batch classifier loss: 0.056565; batch adversarial loss: 0.413119\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069564; batch adversarial loss: 0.429992\n",
      "epoch 68; iter: 0; batch classifier loss: 0.065433; batch adversarial loss: 0.301948\n",
      "epoch 69; iter: 0; batch classifier loss: 0.098245; batch adversarial loss: 0.449145\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067227; batch adversarial loss: 0.483194\n",
      "epoch 71; iter: 0; batch classifier loss: 0.046788; batch adversarial loss: 0.464186\n",
      "epoch 72; iter: 0; batch classifier loss: 0.081581; batch adversarial loss: 0.401450\n",
      "epoch 73; iter: 0; batch classifier loss: 0.070586; batch adversarial loss: 0.445642\n",
      "epoch 74; iter: 0; batch classifier loss: 0.113251; batch adversarial loss: 0.471611\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063115; batch adversarial loss: 0.490730\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069504; batch adversarial loss: 0.495779\n",
      "epoch 77; iter: 0; batch classifier loss: 0.082641; batch adversarial loss: 0.411312\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079293; batch adversarial loss: 0.430823\n",
      "epoch 79; iter: 0; batch classifier loss: 0.077320; batch adversarial loss: 0.383309\n",
      "epoch 80; iter: 0; batch classifier loss: 0.065118; batch adversarial loss: 0.431908\n",
      "epoch 81; iter: 0; batch classifier loss: 0.097251; batch adversarial loss: 0.398850\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059484; batch adversarial loss: 0.406387\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079006; batch adversarial loss: 0.398397\n",
      "epoch 84; iter: 0; batch classifier loss: 0.031419; batch adversarial loss: 0.540231\n",
      "epoch 85; iter: 0; batch classifier loss: 0.053579; batch adversarial loss: 0.460255\n",
      "epoch 86; iter: 0; batch classifier loss: 0.045431; batch adversarial loss: 0.440004\n",
      "epoch 87; iter: 0; batch classifier loss: 0.030523; batch adversarial loss: 0.436685\n",
      "epoch 88; iter: 0; batch classifier loss: 0.082623; batch adversarial loss: 0.448810\n",
      "epoch 89; iter: 0; batch classifier loss: 0.022868; batch adversarial loss: 0.407427\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052194; batch adversarial loss: 0.392497\n",
      "epoch 91; iter: 0; batch classifier loss: 0.040760; batch adversarial loss: 0.389536\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058121; batch adversarial loss: 0.482605\n",
      "epoch 93; iter: 0; batch classifier loss: 0.025340; batch adversarial loss: 0.436712\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056492; batch adversarial loss: 0.538098\n",
      "epoch 95; iter: 0; batch classifier loss: 0.019807; batch adversarial loss: 0.405220\n",
      "epoch 96; iter: 0; batch classifier loss: 0.023526; batch adversarial loss: 0.426678\n",
      "epoch 97; iter: 0; batch classifier loss: 0.018819; batch adversarial loss: 0.448314\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050955; batch adversarial loss: 0.489941\n",
      "epoch 99; iter: 0; batch classifier loss: 0.022431; batch adversarial loss: 0.487755\n",
      "epoch 100; iter: 0; batch classifier loss: 0.029785; batch adversarial loss: 0.538689\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042517; batch adversarial loss: 0.541173\n",
      "epoch 102; iter: 0; batch classifier loss: 0.065251; batch adversarial loss: 0.462624\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033182; batch adversarial loss: 0.515076\n",
      "epoch 104; iter: 0; batch classifier loss: 0.102661; batch adversarial loss: 0.630872\n",
      "epoch 105; iter: 0; batch classifier loss: 0.103944; batch adversarial loss: 0.606085\n",
      "epoch 106; iter: 0; batch classifier loss: 0.108206; batch adversarial loss: 0.517902\n",
      "epoch 107; iter: 0; batch classifier loss: 0.101260; batch adversarial loss: 0.596824\n",
      "epoch 108; iter: 0; batch classifier loss: 0.133764; batch adversarial loss: 0.657658\n",
      "epoch 109; iter: 0; batch classifier loss: 0.078612; batch adversarial loss: 0.654002\n",
      "epoch 110; iter: 0; batch classifier loss: 0.134619; batch adversarial loss: 0.647230\n",
      "epoch 111; iter: 0; batch classifier loss: 0.151861; batch adversarial loss: 0.630472\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056332; batch adversarial loss: 0.401337\n",
      "epoch 113; iter: 0; batch classifier loss: 0.184119; batch adversarial loss: 0.652644\n",
      "epoch 114; iter: 0; batch classifier loss: 0.176946; batch adversarial loss: 0.750845\n",
      "epoch 115; iter: 0; batch classifier loss: 0.180077; batch adversarial loss: 0.631878\n",
      "epoch 116; iter: 0; batch classifier loss: 0.158377; batch adversarial loss: 0.569892\n",
      "epoch 117; iter: 0; batch classifier loss: 0.158616; batch adversarial loss: 0.633234\n",
      "epoch 118; iter: 0; batch classifier loss: 0.125877; batch adversarial loss: 0.552642\n",
      "epoch 119; iter: 0; batch classifier loss: 0.145178; batch adversarial loss: 0.635346\n",
      "epoch 120; iter: 0; batch classifier loss: 0.157943; batch adversarial loss: 0.527252\n",
      "epoch 121; iter: 0; batch classifier loss: 0.080938; batch adversarial loss: 0.420841\n",
      "epoch 122; iter: 0; batch classifier loss: 0.161047; batch adversarial loss: 0.608138\n",
      "epoch 123; iter: 0; batch classifier loss: 0.266475; batch adversarial loss: 0.584464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.150503; batch adversarial loss: 0.511664\n",
      "epoch 125; iter: 0; batch classifier loss: 0.200189; batch adversarial loss: 0.631652\n",
      "epoch 126; iter: 0; batch classifier loss: 0.193328; batch adversarial loss: 0.529168\n",
      "epoch 127; iter: 0; batch classifier loss: 0.137690; batch adversarial loss: 0.522708\n",
      "epoch 128; iter: 0; batch classifier loss: 0.156080; batch adversarial loss: 0.513766\n",
      "epoch 129; iter: 0; batch classifier loss: 0.235157; batch adversarial loss: 0.711048\n",
      "epoch 130; iter: 0; batch classifier loss: 0.178492; batch adversarial loss: 0.566673\n",
      "epoch 131; iter: 0; batch classifier loss: 0.147785; batch adversarial loss: 0.516922\n",
      "epoch 132; iter: 0; batch classifier loss: 0.098786; batch adversarial loss: 0.437859\n",
      "epoch 133; iter: 0; batch classifier loss: 0.144306; batch adversarial loss: 0.545958\n",
      "epoch 134; iter: 0; batch classifier loss: 0.171614; batch adversarial loss: 0.531372\n",
      "epoch 135; iter: 0; batch classifier loss: 0.115002; batch adversarial loss: 0.445060\n",
      "epoch 136; iter: 0; batch classifier loss: 0.112712; batch adversarial loss: 0.500160\n",
      "epoch 137; iter: 0; batch classifier loss: 0.136335; batch adversarial loss: 0.482104\n",
      "epoch 138; iter: 0; batch classifier loss: 0.123443; batch adversarial loss: 0.520556\n",
      "epoch 139; iter: 0; batch classifier loss: 0.087684; batch adversarial loss: 0.488880\n",
      "epoch 140; iter: 0; batch classifier loss: 0.061390; batch adversarial loss: 0.388864\n",
      "epoch 141; iter: 0; batch classifier loss: 0.126476; batch adversarial loss: 0.483062\n",
      "epoch 142; iter: 0; batch classifier loss: 0.075752; batch adversarial loss: 0.505185\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034851; batch adversarial loss: 0.528890\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049299; batch adversarial loss: 0.482993\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025155; batch adversarial loss: 0.408099\n",
      "epoch 146; iter: 0; batch classifier loss: 0.043090; batch adversarial loss: 0.431784\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032737; batch adversarial loss: 0.417621\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021776; batch adversarial loss: 0.467650\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033550; batch adversarial loss: 0.452490\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031056; batch adversarial loss: 0.464961\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026586; batch adversarial loss: 0.454725\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027401; batch adversarial loss: 0.384071\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021943; batch adversarial loss: 0.455685\n",
      "epoch 154; iter: 0; batch classifier loss: 0.056336; batch adversarial loss: 0.321510\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033916; batch adversarial loss: 0.478060\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019815; batch adversarial loss: 0.452048\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036565; batch adversarial loss: 0.431949\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024268; batch adversarial loss: 0.499577\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019360; batch adversarial loss: 0.403571\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032999; batch adversarial loss: 0.458269\n",
      "epoch 161; iter: 0; batch classifier loss: 0.059674; batch adversarial loss: 0.453981\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025181; batch adversarial loss: 0.550149\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029460; batch adversarial loss: 0.579135\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017408; batch adversarial loss: 0.427203\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029545; batch adversarial loss: 0.504718\n",
      "epoch 166; iter: 0; batch classifier loss: 0.063082; batch adversarial loss: 0.446059\n",
      "epoch 167; iter: 0; batch classifier loss: 0.069621; batch adversarial loss: 0.598940\n",
      "epoch 168; iter: 0; batch classifier loss: 0.069773; batch adversarial loss: 0.458286\n",
      "epoch 169; iter: 0; batch classifier loss: 0.064577; batch adversarial loss: 0.570226\n",
      "epoch 170; iter: 0; batch classifier loss: 0.077227; batch adversarial loss: 0.433660\n",
      "epoch 171; iter: 0; batch classifier loss: 0.050291; batch adversarial loss: 0.401085\n",
      "epoch 172; iter: 0; batch classifier loss: 0.043973; batch adversarial loss: 0.521938\n",
      "epoch 173; iter: 0; batch classifier loss: 0.054508; batch adversarial loss: 0.473541\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025997; batch adversarial loss: 0.382231\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029349; batch adversarial loss: 0.471946\n",
      "epoch 176; iter: 0; batch classifier loss: 0.071009; batch adversarial loss: 0.421590\n",
      "epoch 177; iter: 0; batch classifier loss: 0.045239; batch adversarial loss: 0.350228\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035028; batch adversarial loss: 0.504879\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044069; batch adversarial loss: 0.454137\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031206; batch adversarial loss: 0.393021\n",
      "epoch 181; iter: 0; batch classifier loss: 0.047935; batch adversarial loss: 0.412751\n",
      "epoch 182; iter: 0; batch classifier loss: 0.047996; batch adversarial loss: 0.504104\n",
      "epoch 183; iter: 0; batch classifier loss: 0.070820; batch adversarial loss: 0.432085\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028968; batch adversarial loss: 0.456566\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042289; batch adversarial loss: 0.435176\n",
      "epoch 186; iter: 0; batch classifier loss: 0.048453; batch adversarial loss: 0.453914\n",
      "epoch 187; iter: 0; batch classifier loss: 0.044303; batch adversarial loss: 0.385322\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040215; batch adversarial loss: 0.517142\n",
      "epoch 189; iter: 0; batch classifier loss: 0.038060; batch adversarial loss: 0.407144\n",
      "epoch 190; iter: 0; batch classifier loss: 0.056276; batch adversarial loss: 0.418338\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031707; batch adversarial loss: 0.438755\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026258; batch adversarial loss: 0.557843\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035367; batch adversarial loss: 0.457208\n",
      "epoch 194; iter: 0; batch classifier loss: 0.086970; batch adversarial loss: 0.469915\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028692; batch adversarial loss: 0.485686\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025695; batch adversarial loss: 0.412874\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034501; batch adversarial loss: 0.441933\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009461; batch adversarial loss: 0.517118\n",
      "epoch 199; iter: 0; batch classifier loss: 0.059458; batch adversarial loss: 0.367881\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702784; batch adversarial loss: 0.662891\n",
      "epoch 1; iter: 0; batch classifier loss: 0.502967; batch adversarial loss: 0.651826\n",
      "epoch 2; iter: 0; batch classifier loss: 0.455242; batch adversarial loss: 0.645972\n",
      "epoch 3; iter: 0; batch classifier loss: 0.411254; batch adversarial loss: 0.599004\n",
      "epoch 4; iter: 0; batch classifier loss: 0.386727; batch adversarial loss: 0.586986\n",
      "epoch 5; iter: 0; batch classifier loss: 0.407846; batch adversarial loss: 0.588202\n",
      "epoch 6; iter: 0; batch classifier loss: 0.432770; batch adversarial loss: 0.575932\n",
      "epoch 7; iter: 0; batch classifier loss: 0.393775; batch adversarial loss: 0.534622\n",
      "epoch 8; iter: 0; batch classifier loss: 0.434409; batch adversarial loss: 0.534294\n",
      "epoch 9; iter: 0; batch classifier loss: 0.409402; batch adversarial loss: 0.531793\n",
      "epoch 10; iter: 0; batch classifier loss: 0.364056; batch adversarial loss: 0.521839\n",
      "epoch 11; iter: 0; batch classifier loss: 0.434939; batch adversarial loss: 0.493399\n",
      "epoch 12; iter: 0; batch classifier loss: 0.357952; batch adversarial loss: 0.576769\n",
      "epoch 13; iter: 0; batch classifier loss: 0.399629; batch adversarial loss: 0.488066\n",
      "epoch 14; iter: 0; batch classifier loss: 0.292229; batch adversarial loss: 0.512747\n",
      "epoch 15; iter: 0; batch classifier loss: 0.314991; batch adversarial loss: 0.467149\n",
      "epoch 16; iter: 0; batch classifier loss: 0.382598; batch adversarial loss: 0.480601\n",
      "epoch 17; iter: 0; batch classifier loss: 0.334830; batch adversarial loss: 0.552885\n",
      "epoch 18; iter: 0; batch classifier loss: 0.287335; batch adversarial loss: 0.555878\n",
      "epoch 19; iter: 0; batch classifier loss: 0.318321; batch adversarial loss: 0.571374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.303438; batch adversarial loss: 0.508922\n",
      "epoch 21; iter: 0; batch classifier loss: 0.272456; batch adversarial loss: 0.503871\n",
      "epoch 22; iter: 0; batch classifier loss: 0.301697; batch adversarial loss: 0.452415\n",
      "epoch 23; iter: 0; batch classifier loss: 0.329262; batch adversarial loss: 0.418821\n",
      "epoch 24; iter: 0; batch classifier loss: 0.284196; batch adversarial loss: 0.488432\n",
      "epoch 25; iter: 0; batch classifier loss: 0.366062; batch adversarial loss: 0.444753\n",
      "epoch 26; iter: 0; batch classifier loss: 0.298962; batch adversarial loss: 0.475906\n",
      "epoch 27; iter: 0; batch classifier loss: 0.268997; batch adversarial loss: 0.447422\n",
      "epoch 28; iter: 0; batch classifier loss: 0.255261; batch adversarial loss: 0.430537\n",
      "epoch 29; iter: 0; batch classifier loss: 0.268448; batch adversarial loss: 0.523762\n",
      "epoch 30; iter: 0; batch classifier loss: 0.201315; batch adversarial loss: 0.536080\n",
      "epoch 31; iter: 0; batch classifier loss: 0.251876; batch adversarial loss: 0.472984\n",
      "epoch 32; iter: 0; batch classifier loss: 0.282735; batch adversarial loss: 0.418607\n",
      "epoch 33; iter: 0; batch classifier loss: 0.264392; batch adversarial loss: 0.431276\n",
      "epoch 34; iter: 0; batch classifier loss: 0.213306; batch adversarial loss: 0.489393\n",
      "epoch 35; iter: 0; batch classifier loss: 0.251608; batch adversarial loss: 0.570314\n",
      "epoch 36; iter: 0; batch classifier loss: 0.277663; batch adversarial loss: 0.429905\n",
      "epoch 37; iter: 0; batch classifier loss: 0.194471; batch adversarial loss: 0.521813\n",
      "epoch 38; iter: 0; batch classifier loss: 0.277186; batch adversarial loss: 0.424995\n",
      "epoch 39; iter: 0; batch classifier loss: 0.200448; batch adversarial loss: 0.486316\n",
      "epoch 40; iter: 0; batch classifier loss: 0.239428; batch adversarial loss: 0.428271\n",
      "epoch 41; iter: 0; batch classifier loss: 0.215901; batch adversarial loss: 0.494077\n",
      "epoch 42; iter: 0; batch classifier loss: 0.235477; batch adversarial loss: 0.524340\n",
      "epoch 43; iter: 0; batch classifier loss: 0.254409; batch adversarial loss: 0.481793\n",
      "epoch 44; iter: 0; batch classifier loss: 0.196614; batch adversarial loss: 0.436726\n",
      "epoch 45; iter: 0; batch classifier loss: 0.252420; batch adversarial loss: 0.505516\n",
      "epoch 46; iter: 0; batch classifier loss: 0.206527; batch adversarial loss: 0.460612\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119785; batch adversarial loss: 0.423037\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100431; batch adversarial loss: 0.447829\n",
      "epoch 49; iter: 0; batch classifier loss: 0.081251; batch adversarial loss: 0.507358\n",
      "epoch 50; iter: 0; batch classifier loss: 0.101484; batch adversarial loss: 0.422722\n",
      "epoch 51; iter: 0; batch classifier loss: 0.168806; batch adversarial loss: 0.531760\n",
      "epoch 52; iter: 0; batch classifier loss: 0.141786; batch adversarial loss: 0.503741\n",
      "epoch 53; iter: 0; batch classifier loss: 0.134058; batch adversarial loss: 0.399852\n",
      "epoch 54; iter: 0; batch classifier loss: 0.155085; batch adversarial loss: 0.468323\n",
      "epoch 55; iter: 0; batch classifier loss: 0.158828; batch adversarial loss: 0.436190\n",
      "epoch 56; iter: 0; batch classifier loss: 0.162476; batch adversarial loss: 0.507587\n",
      "epoch 57; iter: 0; batch classifier loss: 0.259209; batch adversarial loss: 0.302363\n",
      "epoch 58; iter: 0; batch classifier loss: 0.237547; batch adversarial loss: 0.400477\n",
      "epoch 59; iter: 0; batch classifier loss: 0.159734; batch adversarial loss: 0.471923\n",
      "epoch 60; iter: 0; batch classifier loss: 0.209037; batch adversarial loss: 0.423948\n",
      "epoch 61; iter: 0; batch classifier loss: 0.203899; batch adversarial loss: 0.446406\n",
      "epoch 62; iter: 0; batch classifier loss: 0.145841; batch adversarial loss: 0.566199\n",
      "epoch 63; iter: 0; batch classifier loss: 0.247876; batch adversarial loss: 0.435222\n",
      "epoch 64; iter: 0; batch classifier loss: 0.206046; batch adversarial loss: 0.459015\n",
      "epoch 65; iter: 0; batch classifier loss: 0.098249; batch adversarial loss: 0.470013\n",
      "epoch 66; iter: 0; batch classifier loss: 0.133388; batch adversarial loss: 0.446858\n",
      "epoch 67; iter: 0; batch classifier loss: 0.169581; batch adversarial loss: 0.435699\n",
      "epoch 68; iter: 0; batch classifier loss: 0.161747; batch adversarial loss: 0.444327\n",
      "epoch 69; iter: 0; batch classifier loss: 0.211515; batch adversarial loss: 0.437016\n",
      "epoch 70; iter: 0; batch classifier loss: 0.155788; batch adversarial loss: 0.482129\n",
      "epoch 71; iter: 0; batch classifier loss: 0.228044; batch adversarial loss: 0.459696\n",
      "epoch 72; iter: 0; batch classifier loss: 0.189057; batch adversarial loss: 0.410803\n",
      "epoch 73; iter: 0; batch classifier loss: 0.229632; batch adversarial loss: 0.482887\n",
      "epoch 74; iter: 0; batch classifier loss: 0.220259; batch adversarial loss: 0.458928\n",
      "epoch 75; iter: 0; batch classifier loss: 0.130609; batch adversarial loss: 0.387470\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083071; batch adversarial loss: 0.471762\n",
      "epoch 77; iter: 0; batch classifier loss: 0.176751; batch adversarial loss: 0.384839\n",
      "epoch 78; iter: 0; batch classifier loss: 0.202453; batch adversarial loss: 0.482227\n",
      "epoch 79; iter: 0; batch classifier loss: 0.183751; batch adversarial loss: 0.458949\n",
      "epoch 80; iter: 0; batch classifier loss: 0.205641; batch adversarial loss: 0.518310\n",
      "epoch 81; iter: 0; batch classifier loss: 0.164633; batch adversarial loss: 0.411182\n",
      "epoch 82; iter: 0; batch classifier loss: 0.233441; batch adversarial loss: 0.386487\n",
      "epoch 83; iter: 0; batch classifier loss: 0.188323; batch adversarial loss: 0.470968\n",
      "epoch 84; iter: 0; batch classifier loss: 0.189611; batch adversarial loss: 0.446878\n",
      "epoch 85; iter: 0; batch classifier loss: 0.183969; batch adversarial loss: 0.555607\n",
      "epoch 86; iter: 0; batch classifier loss: 0.101849; batch adversarial loss: 0.446834\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049999; batch adversarial loss: 0.530851\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076825; batch adversarial loss: 0.439677\n",
      "epoch 89; iter: 0; batch classifier loss: 0.039017; batch adversarial loss: 0.437862\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064593; batch adversarial loss: 0.419620\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074064; batch adversarial loss: 0.370193\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069538; batch adversarial loss: 0.457647\n",
      "epoch 93; iter: 0; batch classifier loss: 0.040892; batch adversarial loss: 0.533083\n",
      "epoch 94; iter: 0; batch classifier loss: 0.040353; batch adversarial loss: 0.609227\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063849; batch adversarial loss: 0.410633\n",
      "epoch 96; iter: 0; batch classifier loss: 0.071096; batch adversarial loss: 0.492084\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081945; batch adversarial loss: 0.421112\n",
      "epoch 98; iter: 0; batch classifier loss: 0.033596; batch adversarial loss: 0.429618\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044157; batch adversarial loss: 0.439519\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038128; batch adversarial loss: 0.470423\n",
      "epoch 101; iter: 0; batch classifier loss: 0.104083; batch adversarial loss: 0.566246\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066525; batch adversarial loss: 0.462006\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058680; batch adversarial loss: 0.422216\n",
      "epoch 104; iter: 0; batch classifier loss: 0.072847; batch adversarial loss: 0.500985\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058948; batch adversarial loss: 0.465047\n",
      "epoch 106; iter: 0; batch classifier loss: 0.032090; batch adversarial loss: 0.364433\n",
      "epoch 107; iter: 0; batch classifier loss: 0.092770; batch adversarial loss: 0.378748\n",
      "epoch 108; iter: 0; batch classifier loss: 0.047391; batch adversarial loss: 0.531993\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046975; batch adversarial loss: 0.395033\n",
      "epoch 110; iter: 0; batch classifier loss: 0.032130; batch adversarial loss: 0.593915\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036146; batch adversarial loss: 0.494623\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025676; batch adversarial loss: 0.482920\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025548; batch adversarial loss: 0.464258\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034893; batch adversarial loss: 0.450228\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032447; batch adversarial loss: 0.387460\n",
      "epoch 116; iter: 0; batch classifier loss: 0.022794; batch adversarial loss: 0.420841\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032049; batch adversarial loss: 0.467264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.042883; batch adversarial loss: 0.408092\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030744; batch adversarial loss: 0.510799\n",
      "epoch 120; iter: 0; batch classifier loss: 0.061547; batch adversarial loss: 0.362003\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027018; batch adversarial loss: 0.421510\n",
      "epoch 122; iter: 0; batch classifier loss: 0.072028; batch adversarial loss: 0.376201\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051063; batch adversarial loss: 0.411342\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030401; batch adversarial loss: 0.474902\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038296; batch adversarial loss: 0.417273\n",
      "epoch 126; iter: 0; batch classifier loss: 0.016887; batch adversarial loss: 0.471524\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025872; batch adversarial loss: 0.451883\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028364; batch adversarial loss: 0.529273\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043577; batch adversarial loss: 0.470750\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028984; batch adversarial loss: 0.526640\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019992; batch adversarial loss: 0.458391\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019049; batch adversarial loss: 0.486400\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035487; batch adversarial loss: 0.474784\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026747; batch adversarial loss: 0.406762\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032061; batch adversarial loss: 0.580818\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036066; batch adversarial loss: 0.393148\n",
      "epoch 137; iter: 0; batch classifier loss: 0.021521; batch adversarial loss: 0.497629\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031198; batch adversarial loss: 0.490700\n",
      "epoch 139; iter: 0; batch classifier loss: 0.008464; batch adversarial loss: 0.353447\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036203; batch adversarial loss: 0.477995\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038342; batch adversarial loss: 0.540696\n",
      "epoch 142; iter: 0; batch classifier loss: 0.012476; batch adversarial loss: 0.549393\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018772; batch adversarial loss: 0.414348\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016313; batch adversarial loss: 0.493812\n",
      "epoch 145; iter: 0; batch classifier loss: 0.060002; batch adversarial loss: 0.555120\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037598; batch adversarial loss: 0.428456\n",
      "epoch 147; iter: 0; batch classifier loss: 0.005627; batch adversarial loss: 0.562529\n",
      "epoch 148; iter: 0; batch classifier loss: 0.009739; batch adversarial loss: 0.524805\n",
      "epoch 149; iter: 0; batch classifier loss: 0.004365; batch adversarial loss: 0.468513\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018638; batch adversarial loss: 0.452848\n",
      "epoch 151; iter: 0; batch classifier loss: 0.010518; batch adversarial loss: 0.398698\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018313; batch adversarial loss: 0.469546\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014475; batch adversarial loss: 0.479184\n",
      "epoch 154; iter: 0; batch classifier loss: 0.007210; batch adversarial loss: 0.466157\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014122; batch adversarial loss: 0.432671\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011531; batch adversarial loss: 0.431639\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013859; batch adversarial loss: 0.530027\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019700; batch adversarial loss: 0.482877\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014325; batch adversarial loss: 0.392057\n",
      "epoch 160; iter: 0; batch classifier loss: 0.006277; batch adversarial loss: 0.387678\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015361; batch adversarial loss: 0.405757\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034068; batch adversarial loss: 0.462028\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032551; batch adversarial loss: 0.403270\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011240; batch adversarial loss: 0.424893\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016609; batch adversarial loss: 0.375895\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017804; batch adversarial loss: 0.481270\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012988; batch adversarial loss: 0.520697\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014540; batch adversarial loss: 0.508768\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037558; batch adversarial loss: 0.423315\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033568; batch adversarial loss: 0.431143\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017409; batch adversarial loss: 0.547474\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023363; batch adversarial loss: 0.466572\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008907; batch adversarial loss: 0.400611\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011527; batch adversarial loss: 0.455931\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038717; batch adversarial loss: 0.449889\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025314; batch adversarial loss: 0.376600\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027976; batch adversarial loss: 0.430099\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010427; batch adversarial loss: 0.425728\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015462; batch adversarial loss: 0.433394\n",
      "epoch 180; iter: 0; batch classifier loss: 0.005439; batch adversarial loss: 0.428976\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006606; batch adversarial loss: 0.460075\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031697; batch adversarial loss: 0.518626\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011864; batch adversarial loss: 0.479298\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028127; batch adversarial loss: 0.418592\n",
      "epoch 185; iter: 0; batch classifier loss: 0.039825; batch adversarial loss: 0.411830\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016338; batch adversarial loss: 0.542001\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018817; batch adversarial loss: 0.502090\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024411; batch adversarial loss: 0.409006\n",
      "epoch 189; iter: 0; batch classifier loss: 0.032280; batch adversarial loss: 0.459648\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012146; batch adversarial loss: 0.479921\n",
      "epoch 191; iter: 0; batch classifier loss: 0.042288; batch adversarial loss: 0.433381\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007840; batch adversarial loss: 0.419367\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025769; batch adversarial loss: 0.502635\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012609; batch adversarial loss: 0.425728\n",
      "epoch 195; iter: 0; batch classifier loss: 0.003730; batch adversarial loss: 0.471580\n",
      "epoch 196; iter: 0; batch classifier loss: 0.036292; batch adversarial loss: 0.444215\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011320; batch adversarial loss: 0.356222\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008794; batch adversarial loss: 0.513753\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024716; batch adversarial loss: 0.420701\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703256; batch adversarial loss: 0.655268\n",
      "epoch 1; iter: 0; batch classifier loss: 0.406705; batch adversarial loss: 0.687664\n",
      "epoch 2; iter: 0; batch classifier loss: 0.331242; batch adversarial loss: 0.634899\n",
      "epoch 3; iter: 0; batch classifier loss: 0.387477; batch adversarial loss: 0.590152\n",
      "epoch 4; iter: 0; batch classifier loss: 0.302087; batch adversarial loss: 0.586765\n",
      "epoch 5; iter: 0; batch classifier loss: 0.335361; batch adversarial loss: 0.544386\n",
      "epoch 6; iter: 0; batch classifier loss: 0.272997; batch adversarial loss: 0.509185\n",
      "epoch 7; iter: 0; batch classifier loss: 0.328198; batch adversarial loss: 0.529179\n",
      "epoch 8; iter: 0; batch classifier loss: 0.214193; batch adversarial loss: 0.523843\n",
      "epoch 9; iter: 0; batch classifier loss: 0.220265; batch adversarial loss: 0.500551\n",
      "epoch 10; iter: 0; batch classifier loss: 0.273412; batch adversarial loss: 0.509608\n",
      "epoch 11; iter: 0; batch classifier loss: 0.230910; batch adversarial loss: 0.488810\n",
      "epoch 12; iter: 0; batch classifier loss: 0.193463; batch adversarial loss: 0.443742\n",
      "epoch 13; iter: 0; batch classifier loss: 0.192558; batch adversarial loss: 0.432428\n",
      "epoch 14; iter: 0; batch classifier loss: 0.166708; batch adversarial loss: 0.503438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.119376; batch adversarial loss: 0.448175\n",
      "epoch 16; iter: 0; batch classifier loss: 0.192189; batch adversarial loss: 0.465211\n",
      "epoch 17; iter: 0; batch classifier loss: 0.253536; batch adversarial loss: 0.563915\n",
      "epoch 18; iter: 0; batch classifier loss: 0.169700; batch adversarial loss: 0.543315\n",
      "epoch 19; iter: 0; batch classifier loss: 0.136356; batch adversarial loss: 0.485914\n",
      "epoch 20; iter: 0; batch classifier loss: 0.154441; batch adversarial loss: 0.430853\n",
      "epoch 21; iter: 0; batch classifier loss: 0.105380; batch adversarial loss: 0.426370\n",
      "epoch 22; iter: 0; batch classifier loss: 0.123893; batch adversarial loss: 0.491054\n",
      "epoch 23; iter: 0; batch classifier loss: 0.232096; batch adversarial loss: 0.534569\n",
      "epoch 24; iter: 0; batch classifier loss: 0.137850; batch adversarial loss: 0.532446\n",
      "epoch 25; iter: 0; batch classifier loss: 0.185278; batch adversarial loss: 0.573020\n",
      "epoch 26; iter: 0; batch classifier loss: 0.173918; batch adversarial loss: 0.488370\n",
      "epoch 27; iter: 0; batch classifier loss: 0.144446; batch adversarial loss: 0.479349\n",
      "epoch 28; iter: 0; batch classifier loss: 0.206322; batch adversarial loss: 0.466180\n",
      "epoch 29; iter: 0; batch classifier loss: 0.215520; batch adversarial loss: 0.541916\n",
      "epoch 30; iter: 0; batch classifier loss: 0.157165; batch adversarial loss: 0.480133\n",
      "epoch 31; iter: 0; batch classifier loss: 0.192625; batch adversarial loss: 0.430396\n",
      "epoch 32; iter: 0; batch classifier loss: 0.199673; batch adversarial loss: 0.505793\n",
      "epoch 33; iter: 0; batch classifier loss: 0.217709; batch adversarial loss: 0.522429\n",
      "epoch 34; iter: 0; batch classifier loss: 0.238499; batch adversarial loss: 0.440823\n",
      "epoch 35; iter: 0; batch classifier loss: 0.203540; batch adversarial loss: 0.414885\n",
      "epoch 36; iter: 0; batch classifier loss: 0.349522; batch adversarial loss: 0.461571\n",
      "epoch 37; iter: 0; batch classifier loss: 0.164319; batch adversarial loss: 0.423865\n",
      "epoch 38; iter: 0; batch classifier loss: 0.109474; batch adversarial loss: 0.482373\n",
      "epoch 39; iter: 0; batch classifier loss: 0.084072; batch adversarial loss: 0.522741\n",
      "epoch 40; iter: 0; batch classifier loss: 0.063824; batch adversarial loss: 0.419479\n",
      "epoch 41; iter: 0; batch classifier loss: 0.069919; batch adversarial loss: 0.444186\n",
      "epoch 42; iter: 0; batch classifier loss: 0.096617; batch adversarial loss: 0.452540\n",
      "epoch 43; iter: 0; batch classifier loss: 0.080261; batch adversarial loss: 0.444344\n",
      "epoch 44; iter: 0; batch classifier loss: 0.071153; batch adversarial loss: 0.417129\n",
      "epoch 45; iter: 0; batch classifier loss: 0.077432; batch adversarial loss: 0.469243\n",
      "epoch 46; iter: 0; batch classifier loss: 0.040497; batch adversarial loss: 0.499709\n",
      "epoch 47; iter: 0; batch classifier loss: 0.070422; batch adversarial loss: 0.493657\n",
      "epoch 48; iter: 0; batch classifier loss: 0.117339; batch adversarial loss: 0.466606\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107705; batch adversarial loss: 0.372937\n",
      "epoch 50; iter: 0; batch classifier loss: 0.084079; batch adversarial loss: 0.480243\n",
      "epoch 51; iter: 0; batch classifier loss: 0.062031; batch adversarial loss: 0.361228\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099427; batch adversarial loss: 0.449730\n",
      "epoch 53; iter: 0; batch classifier loss: 0.075897; batch adversarial loss: 0.358754\n",
      "epoch 54; iter: 0; batch classifier loss: 0.106294; batch adversarial loss: 0.405672\n",
      "epoch 55; iter: 0; batch classifier loss: 0.092784; batch adversarial loss: 0.501501\n",
      "epoch 56; iter: 0; batch classifier loss: 0.054451; batch adversarial loss: 0.499829\n",
      "epoch 57; iter: 0; batch classifier loss: 0.049275; batch adversarial loss: 0.411461\n",
      "epoch 58; iter: 0; batch classifier loss: 0.105457; batch adversarial loss: 0.427041\n",
      "epoch 59; iter: 0; batch classifier loss: 0.068808; batch adversarial loss: 0.471886\n",
      "epoch 60; iter: 0; batch classifier loss: 0.116869; batch adversarial loss: 0.481439\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080532; batch adversarial loss: 0.472022\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084304; batch adversarial loss: 0.460199\n",
      "epoch 63; iter: 0; batch classifier loss: 0.081944; batch adversarial loss: 0.429526\n",
      "epoch 64; iter: 0; batch classifier loss: 0.066095; batch adversarial loss: 0.507711\n",
      "epoch 65; iter: 0; batch classifier loss: 0.090194; batch adversarial loss: 0.447430\n",
      "epoch 66; iter: 0; batch classifier loss: 0.065866; batch adversarial loss: 0.529393\n",
      "epoch 67; iter: 0; batch classifier loss: 0.111300; batch adversarial loss: 0.466469\n",
      "epoch 68; iter: 0; batch classifier loss: 0.087204; batch adversarial loss: 0.473123\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065260; batch adversarial loss: 0.517608\n",
      "epoch 70; iter: 0; batch classifier loss: 0.062284; batch adversarial loss: 0.311997\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071205; batch adversarial loss: 0.496453\n",
      "epoch 72; iter: 0; batch classifier loss: 0.094582; batch adversarial loss: 0.346489\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075135; batch adversarial loss: 0.442682\n",
      "epoch 74; iter: 0; batch classifier loss: 0.070030; batch adversarial loss: 0.468537\n",
      "epoch 75; iter: 0; batch classifier loss: 0.166829; batch adversarial loss: 0.443274\n",
      "epoch 76; iter: 0; batch classifier loss: 0.086477; batch adversarial loss: 0.433765\n",
      "epoch 77; iter: 0; batch classifier loss: 0.111997; batch adversarial loss: 0.504093\n",
      "epoch 78; iter: 0; batch classifier loss: 0.051169; batch adversarial loss: 0.532363\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061487; batch adversarial loss: 0.489400\n",
      "epoch 80; iter: 0; batch classifier loss: 0.147169; batch adversarial loss: 0.501052\n",
      "epoch 81; iter: 0; batch classifier loss: 0.161085; batch adversarial loss: 0.405373\n",
      "epoch 82; iter: 0; batch classifier loss: 0.055246; batch adversarial loss: 0.462665\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070398; batch adversarial loss: 0.501614\n",
      "epoch 84; iter: 0; batch classifier loss: 0.112845; batch adversarial loss: 0.441110\n",
      "epoch 85; iter: 0; batch classifier loss: 0.081535; batch adversarial loss: 0.369000\n",
      "epoch 86; iter: 0; batch classifier loss: 0.107261; batch adversarial loss: 0.461474\n",
      "epoch 87; iter: 0; batch classifier loss: 0.029641; batch adversarial loss: 0.455214\n",
      "epoch 88; iter: 0; batch classifier loss: 0.072037; batch adversarial loss: 0.479555\n",
      "epoch 89; iter: 0; batch classifier loss: 0.108915; batch adversarial loss: 0.483137\n",
      "epoch 90; iter: 0; batch classifier loss: 0.044259; batch adversarial loss: 0.430946\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083986; batch adversarial loss: 0.427556\n",
      "epoch 92; iter: 0; batch classifier loss: 0.087272; batch adversarial loss: 0.417309\n",
      "epoch 93; iter: 0; batch classifier loss: 0.060275; batch adversarial loss: 0.522204\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072235; batch adversarial loss: 0.422949\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038996; batch adversarial loss: 0.441887\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045594; batch adversarial loss: 0.415336\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073264; batch adversarial loss: 0.438636\n",
      "epoch 98; iter: 0; batch classifier loss: 0.104784; batch adversarial loss: 0.439824\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057953; batch adversarial loss: 0.326617\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066818; batch adversarial loss: 0.482041\n",
      "epoch 101; iter: 0; batch classifier loss: 0.035003; batch adversarial loss: 0.559512\n",
      "epoch 102; iter: 0; batch classifier loss: 0.065459; batch adversarial loss: 0.493956\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053624; batch adversarial loss: 0.427832\n",
      "epoch 104; iter: 0; batch classifier loss: 0.076438; batch adversarial loss: 0.440619\n",
      "epoch 105; iter: 0; batch classifier loss: 0.082683; batch adversarial loss: 0.508714\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063315; batch adversarial loss: 0.526226\n",
      "epoch 107; iter: 0; batch classifier loss: 0.064376; batch adversarial loss: 0.496090\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060732; batch adversarial loss: 0.469460\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038930; batch adversarial loss: 0.473649\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049823; batch adversarial loss: 0.437841\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057646; batch adversarial loss: 0.373671\n",
      "epoch 112; iter: 0; batch classifier loss: 0.097285; batch adversarial loss: 0.526385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.041861; batch adversarial loss: 0.592062\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044312; batch adversarial loss: 0.535343\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042140; batch adversarial loss: 0.443164\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057969; batch adversarial loss: 0.517458\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051492; batch adversarial loss: 0.437185\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063335; batch adversarial loss: 0.479420\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049376; batch adversarial loss: 0.462269\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046203; batch adversarial loss: 0.506503\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051084; batch adversarial loss: 0.390284\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039276; batch adversarial loss: 0.434444\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031984; batch adversarial loss: 0.407632\n",
      "epoch 124; iter: 0; batch classifier loss: 0.045467; batch adversarial loss: 0.517914\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068375; batch adversarial loss: 0.484183\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033127; batch adversarial loss: 0.411559\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039394; batch adversarial loss: 0.418074\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041420; batch adversarial loss: 0.357234\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042991; batch adversarial loss: 0.524586\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032300; batch adversarial loss: 0.437545\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040496; batch adversarial loss: 0.499676\n",
      "epoch 132; iter: 0; batch classifier loss: 0.056431; batch adversarial loss: 0.382924\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019350; batch adversarial loss: 0.398395\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032249; batch adversarial loss: 0.469887\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028945; batch adversarial loss: 0.435355\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025974; batch adversarial loss: 0.486072\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038235; batch adversarial loss: 0.454271\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017438; batch adversarial loss: 0.438493\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034922; batch adversarial loss: 0.435160\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013082; batch adversarial loss: 0.513146\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022805; batch adversarial loss: 0.330779\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032514; batch adversarial loss: 0.578163\n",
      "epoch 143; iter: 0; batch classifier loss: 0.017664; batch adversarial loss: 0.526065\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033063; batch adversarial loss: 0.486970\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031792; batch adversarial loss: 0.430648\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025260; batch adversarial loss: 0.358472\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024100; batch adversarial loss: 0.423908\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031418; batch adversarial loss: 0.495123\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019739; batch adversarial loss: 0.405616\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020726; batch adversarial loss: 0.455203\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015015; batch adversarial loss: 0.441873\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037998; batch adversarial loss: 0.475662\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029366; batch adversarial loss: 0.509061\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029395; batch adversarial loss: 0.475630\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025761; batch adversarial loss: 0.545015\n",
      "epoch 156; iter: 0; batch classifier loss: 0.049456; batch adversarial loss: 0.546220\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015838; batch adversarial loss: 0.458741\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042044; batch adversarial loss: 0.543111\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049527; batch adversarial loss: 0.428248\n",
      "epoch 160; iter: 0; batch classifier loss: 0.053521; batch adversarial loss: 0.447134\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026758; batch adversarial loss: 0.426189\n",
      "epoch 162; iter: 0; batch classifier loss: 0.008705; batch adversarial loss: 0.475510\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013606; batch adversarial loss: 0.519491\n",
      "epoch 164; iter: 0; batch classifier loss: 0.048081; batch adversarial loss: 0.487792\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019400; batch adversarial loss: 0.544495\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029509; batch adversarial loss: 0.449367\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031236; batch adversarial loss: 0.397503\n",
      "epoch 168; iter: 0; batch classifier loss: 0.004306; batch adversarial loss: 0.408722\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026199; batch adversarial loss: 0.457226\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030951; batch adversarial loss: 0.471765\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022622; batch adversarial loss: 0.396545\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017304; batch adversarial loss: 0.441984\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018101; batch adversarial loss: 0.428572\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031964; batch adversarial loss: 0.494653\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022777; batch adversarial loss: 0.468839\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037016; batch adversarial loss: 0.394468\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010402; batch adversarial loss: 0.415227\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016489; batch adversarial loss: 0.446961\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008912; batch adversarial loss: 0.431832\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020305; batch adversarial loss: 0.511931\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018125; batch adversarial loss: 0.434239\n",
      "epoch 182; iter: 0; batch classifier loss: 0.004484; batch adversarial loss: 0.427903\n",
      "epoch 183; iter: 0; batch classifier loss: 0.043377; batch adversarial loss: 0.400336\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012839; batch adversarial loss: 0.445931\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023362; batch adversarial loss: 0.393392\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016179; batch adversarial loss: 0.399294\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011302; batch adversarial loss: 0.445436\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016111; batch adversarial loss: 0.446942\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023651; batch adversarial loss: 0.495719\n",
      "epoch 190; iter: 0; batch classifier loss: 0.070806; batch adversarial loss: 0.512812\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016013; batch adversarial loss: 0.459363\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015355; batch adversarial loss: 0.409765\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011736; batch adversarial loss: 0.422221\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014760; batch adversarial loss: 0.461795\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009714; batch adversarial loss: 0.348536\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020892; batch adversarial loss: 0.407127\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014828; batch adversarial loss: 0.480827\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019817; batch adversarial loss: 0.543851\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012758; batch adversarial loss: 0.401564\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704207; batch adversarial loss: 0.732437\n",
      "epoch 1; iter: 0; batch classifier loss: 0.424772; batch adversarial loss: 0.704617\n",
      "epoch 2; iter: 0; batch classifier loss: 0.352839; batch adversarial loss: 0.666365\n",
      "epoch 3; iter: 0; batch classifier loss: 0.319178; batch adversarial loss: 0.631731\n",
      "epoch 4; iter: 0; batch classifier loss: 0.247153; batch adversarial loss: 0.614500\n",
      "epoch 5; iter: 0; batch classifier loss: 0.309607; batch adversarial loss: 0.598028\n",
      "epoch 6; iter: 0; batch classifier loss: 0.290785; batch adversarial loss: 0.557099\n",
      "epoch 7; iter: 0; batch classifier loss: 0.304228; batch adversarial loss: 0.552253\n",
      "epoch 8; iter: 0; batch classifier loss: 0.342345; batch adversarial loss: 0.536679\n",
      "epoch 9; iter: 0; batch classifier loss: 0.270793; batch adversarial loss: 0.505435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.296642; batch adversarial loss: 0.508305\n",
      "epoch 11; iter: 0; batch classifier loss: 0.284941; batch adversarial loss: 0.517652\n",
      "epoch 12; iter: 0; batch classifier loss: 0.210695; batch adversarial loss: 0.536578\n",
      "epoch 13; iter: 0; batch classifier loss: 0.273289; batch adversarial loss: 0.503594\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478978; batch adversarial loss: 0.526626\n",
      "epoch 15; iter: 0; batch classifier loss: 0.354125; batch adversarial loss: 0.545877\n",
      "epoch 16; iter: 0; batch classifier loss: 0.296902; batch adversarial loss: 0.506575\n",
      "epoch 17; iter: 0; batch classifier loss: 0.320268; batch adversarial loss: 0.506903\n",
      "epoch 18; iter: 0; batch classifier loss: 0.282644; batch adversarial loss: 0.449037\n",
      "epoch 19; iter: 0; batch classifier loss: 0.188662; batch adversarial loss: 0.502194\n",
      "epoch 20; iter: 0; batch classifier loss: 0.217856; batch adversarial loss: 0.508461\n",
      "epoch 21; iter: 0; batch classifier loss: 0.220665; batch adversarial loss: 0.410099\n",
      "epoch 22; iter: 0; batch classifier loss: 0.162566; batch adversarial loss: 0.504768\n",
      "epoch 23; iter: 0; batch classifier loss: 0.289218; batch adversarial loss: 0.376637\n",
      "epoch 24; iter: 0; batch classifier loss: 0.200933; batch adversarial loss: 0.447785\n",
      "epoch 25; iter: 0; batch classifier loss: 0.203662; batch adversarial loss: 0.453798\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176961; batch adversarial loss: 0.476446\n",
      "epoch 27; iter: 0; batch classifier loss: 0.211564; batch adversarial loss: 0.419155\n",
      "epoch 28; iter: 0; batch classifier loss: 0.155011; batch adversarial loss: 0.487740\n",
      "epoch 29; iter: 0; batch classifier loss: 0.141229; batch adversarial loss: 0.445079\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153196; batch adversarial loss: 0.405057\n",
      "epoch 31; iter: 0; batch classifier loss: 0.200752; batch adversarial loss: 0.409066\n",
      "epoch 32; iter: 0; batch classifier loss: 0.182563; batch adversarial loss: 0.423472\n",
      "epoch 33; iter: 0; batch classifier loss: 0.155989; batch adversarial loss: 0.547255\n",
      "epoch 34; iter: 0; batch classifier loss: 0.126511; batch adversarial loss: 0.401948\n",
      "epoch 35; iter: 0; batch classifier loss: 0.200862; batch adversarial loss: 0.438344\n",
      "epoch 36; iter: 0; batch classifier loss: 0.167939; batch adversarial loss: 0.445784\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110223; batch adversarial loss: 0.437108\n",
      "epoch 38; iter: 0; batch classifier loss: 0.108626; batch adversarial loss: 0.609157\n",
      "epoch 39; iter: 0; batch classifier loss: 0.150688; batch adversarial loss: 0.543659\n",
      "epoch 40; iter: 0; batch classifier loss: 0.146861; batch adversarial loss: 0.566379\n",
      "epoch 41; iter: 0; batch classifier loss: 0.158051; batch adversarial loss: 0.510032\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117918; batch adversarial loss: 0.444890\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117068; batch adversarial loss: 0.550947\n",
      "epoch 44; iter: 0; batch classifier loss: 0.116443; batch adversarial loss: 0.418027\n",
      "epoch 45; iter: 0; batch classifier loss: 0.171726; batch adversarial loss: 0.467767\n",
      "epoch 46; iter: 0; batch classifier loss: 0.092732; batch adversarial loss: 0.528510\n",
      "epoch 47; iter: 0; batch classifier loss: 0.132245; batch adversarial loss: 0.457681\n",
      "epoch 48; iter: 0; batch classifier loss: 0.110862; batch adversarial loss: 0.491986\n",
      "epoch 49; iter: 0; batch classifier loss: 0.140280; batch adversarial loss: 0.347635\n",
      "epoch 50; iter: 0; batch classifier loss: 0.137308; batch adversarial loss: 0.501775\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083487; batch adversarial loss: 0.468643\n",
      "epoch 52; iter: 0; batch classifier loss: 0.118183; batch adversarial loss: 0.435533\n",
      "epoch 53; iter: 0; batch classifier loss: 0.097909; batch adversarial loss: 0.426250\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110915; batch adversarial loss: 0.424539\n",
      "epoch 55; iter: 0; batch classifier loss: 0.111101; batch adversarial loss: 0.459710\n",
      "epoch 56; iter: 0; batch classifier loss: 0.115537; batch adversarial loss: 0.485292\n",
      "epoch 57; iter: 0; batch classifier loss: 0.103587; batch adversarial loss: 0.485501\n",
      "epoch 58; iter: 0; batch classifier loss: 0.124880; batch adversarial loss: 0.482807\n",
      "epoch 59; iter: 0; batch classifier loss: 0.085742; batch adversarial loss: 0.500577\n",
      "epoch 60; iter: 0; batch classifier loss: 0.100774; batch adversarial loss: 0.432372\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071425; batch adversarial loss: 0.501526\n",
      "epoch 62; iter: 0; batch classifier loss: 0.071243; batch adversarial loss: 0.452101\n",
      "epoch 63; iter: 0; batch classifier loss: 0.105331; batch adversarial loss: 0.477949\n",
      "epoch 64; iter: 0; batch classifier loss: 0.071926; batch adversarial loss: 0.499429\n",
      "epoch 65; iter: 0; batch classifier loss: 0.100872; batch adversarial loss: 0.405589\n",
      "epoch 66; iter: 0; batch classifier loss: 0.146520; batch adversarial loss: 0.478136\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079333; batch adversarial loss: 0.423548\n",
      "epoch 68; iter: 0; batch classifier loss: 0.077240; batch adversarial loss: 0.457267\n",
      "epoch 69; iter: 0; batch classifier loss: 0.105086; batch adversarial loss: 0.453975\n",
      "epoch 70; iter: 0; batch classifier loss: 0.091763; batch adversarial loss: 0.470420\n",
      "epoch 71; iter: 0; batch classifier loss: 0.091635; batch adversarial loss: 0.420102\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077316; batch adversarial loss: 0.490810\n",
      "epoch 73; iter: 0; batch classifier loss: 0.064134; batch adversarial loss: 0.489821\n",
      "epoch 74; iter: 0; batch classifier loss: 0.125529; batch adversarial loss: 0.416552\n",
      "epoch 75; iter: 0; batch classifier loss: 0.060810; batch adversarial loss: 0.437536\n",
      "epoch 76; iter: 0; batch classifier loss: 0.059599; batch adversarial loss: 0.538181\n",
      "epoch 77; iter: 0; batch classifier loss: 0.105318; batch adversarial loss: 0.464784\n",
      "epoch 78; iter: 0; batch classifier loss: 0.083845; batch adversarial loss: 0.443528\n",
      "epoch 79; iter: 0; batch classifier loss: 0.113405; batch adversarial loss: 0.472592\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054902; batch adversarial loss: 0.455879\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075142; batch adversarial loss: 0.504752\n",
      "epoch 82; iter: 0; batch classifier loss: 0.099689; batch adversarial loss: 0.420828\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081008; batch adversarial loss: 0.448164\n",
      "epoch 84; iter: 0; batch classifier loss: 0.028546; batch adversarial loss: 0.428131\n",
      "epoch 85; iter: 0; batch classifier loss: 0.037263; batch adversarial loss: 0.426280\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070364; batch adversarial loss: 0.463571\n",
      "epoch 87; iter: 0; batch classifier loss: 0.052520; batch adversarial loss: 0.408134\n",
      "epoch 88; iter: 0; batch classifier loss: 0.053250; batch adversarial loss: 0.432769\n",
      "epoch 89; iter: 0; batch classifier loss: 0.045986; batch adversarial loss: 0.365745\n",
      "epoch 90; iter: 0; batch classifier loss: 0.043907; batch adversarial loss: 0.447194\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075307; batch adversarial loss: 0.422127\n",
      "epoch 92; iter: 0; batch classifier loss: 0.029615; batch adversarial loss: 0.461514\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044257; batch adversarial loss: 0.487491\n",
      "epoch 94; iter: 0; batch classifier loss: 0.021517; batch adversarial loss: 0.456783\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047400; batch adversarial loss: 0.418353\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064358; batch adversarial loss: 0.499079\n",
      "epoch 97; iter: 0; batch classifier loss: 0.022028; batch adversarial loss: 0.468744\n",
      "epoch 98; iter: 0; batch classifier loss: 0.057532; batch adversarial loss: 0.514245\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037090; batch adversarial loss: 0.394710\n",
      "epoch 100; iter: 0; batch classifier loss: 0.027313; batch adversarial loss: 0.497464\n",
      "epoch 101; iter: 0; batch classifier loss: 0.035052; batch adversarial loss: 0.514312\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051608; batch adversarial loss: 0.475013\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050586; batch adversarial loss: 0.413432\n",
      "epoch 104; iter: 0; batch classifier loss: 0.040188; batch adversarial loss: 0.507033\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046934; batch adversarial loss: 0.480548\n",
      "epoch 106; iter: 0; batch classifier loss: 0.027459; batch adversarial loss: 0.505199\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048231; batch adversarial loss: 0.490134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.043988; batch adversarial loss: 0.437382\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046634; batch adversarial loss: 0.425073\n",
      "epoch 110; iter: 0; batch classifier loss: 0.034236; batch adversarial loss: 0.578858\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062193; batch adversarial loss: 0.438003\n",
      "epoch 112; iter: 0; batch classifier loss: 0.048291; batch adversarial loss: 0.495137\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042821; batch adversarial loss: 0.369445\n",
      "epoch 114; iter: 0; batch classifier loss: 0.020162; batch adversarial loss: 0.360662\n",
      "epoch 115; iter: 0; batch classifier loss: 0.079999; batch adversarial loss: 0.412992\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029354; batch adversarial loss: 0.422681\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042014; batch adversarial loss: 0.444673\n",
      "epoch 118; iter: 0; batch classifier loss: 0.016913; batch adversarial loss: 0.461870\n",
      "epoch 119; iter: 0; batch classifier loss: 0.069430; batch adversarial loss: 0.488459\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030382; batch adversarial loss: 0.524170\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058100; batch adversarial loss: 0.353401\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045745; batch adversarial loss: 0.483005\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014030; batch adversarial loss: 0.350122\n",
      "epoch 124; iter: 0; batch classifier loss: 0.047011; batch adversarial loss: 0.482961\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048061; batch adversarial loss: 0.441151\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030099; batch adversarial loss: 0.474794\n",
      "epoch 127; iter: 0; batch classifier loss: 0.013991; batch adversarial loss: 0.426767\n",
      "epoch 128; iter: 0; batch classifier loss: 0.046282; batch adversarial loss: 0.435318\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059646; batch adversarial loss: 0.474223\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038009; batch adversarial loss: 0.503720\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021410; batch adversarial loss: 0.471341\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025206; batch adversarial loss: 0.489044\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043091; batch adversarial loss: 0.472073\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025742; batch adversarial loss: 0.474278\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037650; batch adversarial loss: 0.386121\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019318; batch adversarial loss: 0.457094\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018578; batch adversarial loss: 0.503297\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024526; batch adversarial loss: 0.504700\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031726; batch adversarial loss: 0.496105\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021933; batch adversarial loss: 0.619733\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018386; batch adversarial loss: 0.558081\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023845; batch adversarial loss: 0.539396\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026360; batch adversarial loss: 0.431947\n",
      "epoch 144; iter: 0; batch classifier loss: 0.050675; batch adversarial loss: 0.397867\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019448; batch adversarial loss: 0.470031\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034296; batch adversarial loss: 0.342350\n",
      "epoch 147; iter: 0; batch classifier loss: 0.047956; batch adversarial loss: 0.473798\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030902; batch adversarial loss: 0.451511\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019281; batch adversarial loss: 0.526537\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031014; batch adversarial loss: 0.464967\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024790; batch adversarial loss: 0.529791\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033097; batch adversarial loss: 0.432626\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021336; batch adversarial loss: 0.404193\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046347; batch adversarial loss: 0.510128\n",
      "epoch 155; iter: 0; batch classifier loss: 0.008953; batch adversarial loss: 0.347589\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040839; batch adversarial loss: 0.448242\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016236; batch adversarial loss: 0.495730\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020341; batch adversarial loss: 0.522702\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020368; batch adversarial loss: 0.410479\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016540; batch adversarial loss: 0.474068\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027374; batch adversarial loss: 0.452037\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009763; batch adversarial loss: 0.259765\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007148; batch adversarial loss: 0.409139\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036291; batch adversarial loss: 0.485352\n",
      "epoch 165; iter: 0; batch classifier loss: 0.051009; batch adversarial loss: 0.412426\n",
      "epoch 166; iter: 0; batch classifier loss: 0.006258; batch adversarial loss: 0.538222\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014387; batch adversarial loss: 0.532767\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029392; batch adversarial loss: 0.510751\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032388; batch adversarial loss: 0.482058\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013138; batch adversarial loss: 0.391358\n",
      "epoch 171; iter: 0; batch classifier loss: 0.034251; batch adversarial loss: 0.529280\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009708; batch adversarial loss: 0.442425\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017347; batch adversarial loss: 0.495224\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007847; batch adversarial loss: 0.465097\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017260; batch adversarial loss: 0.409380\n",
      "epoch 176; iter: 0; batch classifier loss: 0.003727; batch adversarial loss: 0.516510\n",
      "epoch 177; iter: 0; batch classifier loss: 0.003232; batch adversarial loss: 0.454433\n",
      "epoch 178; iter: 0; batch classifier loss: 0.041107; batch adversarial loss: 0.501898\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026521; batch adversarial loss: 0.379003\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017264; batch adversarial loss: 0.465381\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010492; batch adversarial loss: 0.464766\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029177; batch adversarial loss: 0.512892\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029610; batch adversarial loss: 0.528115\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029963; batch adversarial loss: 0.517357\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019584; batch adversarial loss: 0.336305\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008296; batch adversarial loss: 0.374210\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011521; batch adversarial loss: 0.437508\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009149; batch adversarial loss: 0.465578\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013100; batch adversarial loss: 0.402829\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011634; batch adversarial loss: 0.530139\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021362; batch adversarial loss: 0.430985\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018552; batch adversarial loss: 0.451320\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014021; batch adversarial loss: 0.417332\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010064; batch adversarial loss: 0.522368\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011671; batch adversarial loss: 0.400081\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020848; batch adversarial loss: 0.457278\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013470; batch adversarial loss: 0.373144\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020982; batch adversarial loss: 0.481693\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015202; batch adversarial loss: 0.485454\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703852; batch adversarial loss: 0.615536\n",
      "epoch 1; iter: 0; batch classifier loss: 0.372361; batch adversarial loss: 0.614398\n",
      "epoch 2; iter: 0; batch classifier loss: 0.400441; batch adversarial loss: 0.613700\n",
      "epoch 3; iter: 0; batch classifier loss: 0.318137; batch adversarial loss: 0.571468\n",
      "epoch 4; iter: 0; batch classifier loss: 0.427318; batch adversarial loss: 0.597997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.443491; batch adversarial loss: 0.575952\n",
      "epoch 6; iter: 0; batch classifier loss: 0.381805; batch adversarial loss: 0.593773\n",
      "epoch 7; iter: 0; batch classifier loss: 0.474929; batch adversarial loss: 0.591818\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520797; batch adversarial loss: 0.553976\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578074; batch adversarial loss: 0.573756\n",
      "epoch 10; iter: 0; batch classifier loss: 0.611210; batch adversarial loss: 0.527026\n",
      "epoch 11; iter: 0; batch classifier loss: 0.351830; batch adversarial loss: 0.528257\n",
      "epoch 12; iter: 0; batch classifier loss: 0.290067; batch adversarial loss: 0.480681\n",
      "epoch 13; iter: 0; batch classifier loss: 0.269484; batch adversarial loss: 0.504719\n",
      "epoch 14; iter: 0; batch classifier loss: 0.309220; batch adversarial loss: 0.497626\n",
      "epoch 15; iter: 0; batch classifier loss: 0.314557; batch adversarial loss: 0.469220\n",
      "epoch 16; iter: 0; batch classifier loss: 0.324256; batch adversarial loss: 0.451867\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269684; batch adversarial loss: 0.521181\n",
      "epoch 18; iter: 0; batch classifier loss: 0.227834; batch adversarial loss: 0.526411\n",
      "epoch 19; iter: 0; batch classifier loss: 0.299546; batch adversarial loss: 0.472803\n",
      "epoch 20; iter: 0; batch classifier loss: 0.273617; batch adversarial loss: 0.422201\n",
      "epoch 21; iter: 0; batch classifier loss: 0.199794; batch adversarial loss: 0.518547\n",
      "epoch 22; iter: 0; batch classifier loss: 0.197805; batch adversarial loss: 0.494316\n",
      "epoch 23; iter: 0; batch classifier loss: 0.204004; batch adversarial loss: 0.495552\n",
      "epoch 24; iter: 0; batch classifier loss: 0.184812; batch adversarial loss: 0.488522\n",
      "epoch 25; iter: 0; batch classifier loss: 0.212686; batch adversarial loss: 0.446580\n",
      "epoch 26; iter: 0; batch classifier loss: 0.177961; batch adversarial loss: 0.450132\n",
      "epoch 27; iter: 0; batch classifier loss: 0.148663; batch adversarial loss: 0.428968\n",
      "epoch 28; iter: 0; batch classifier loss: 0.245122; batch adversarial loss: 0.437630\n",
      "epoch 29; iter: 0; batch classifier loss: 0.163608; batch adversarial loss: 0.544624\n",
      "epoch 30; iter: 0; batch classifier loss: 0.187401; batch adversarial loss: 0.487170\n",
      "epoch 31; iter: 0; batch classifier loss: 0.169433; batch adversarial loss: 0.477618\n",
      "epoch 32; iter: 0; batch classifier loss: 0.172702; batch adversarial loss: 0.490120\n",
      "epoch 33; iter: 0; batch classifier loss: 0.167204; batch adversarial loss: 0.491532\n",
      "epoch 34; iter: 0; batch classifier loss: 0.165756; batch adversarial loss: 0.538939\n",
      "epoch 35; iter: 0; batch classifier loss: 0.173235; batch adversarial loss: 0.463464\n",
      "epoch 36; iter: 0; batch classifier loss: 0.199932; batch adversarial loss: 0.398006\n",
      "epoch 37; iter: 0; batch classifier loss: 0.164595; batch adversarial loss: 0.471642\n",
      "epoch 38; iter: 0; batch classifier loss: 0.189777; batch adversarial loss: 0.548984\n",
      "epoch 39; iter: 0; batch classifier loss: 0.189617; batch adversarial loss: 0.479988\n",
      "epoch 40; iter: 0; batch classifier loss: 0.106622; batch adversarial loss: 0.550702\n",
      "epoch 41; iter: 0; batch classifier loss: 0.131060; batch adversarial loss: 0.404902\n",
      "epoch 42; iter: 0; batch classifier loss: 0.201127; batch adversarial loss: 0.436935\n",
      "epoch 43; iter: 0; batch classifier loss: 0.160663; batch adversarial loss: 0.517544\n",
      "epoch 44; iter: 0; batch classifier loss: 0.148173; batch adversarial loss: 0.598674\n",
      "epoch 45; iter: 0; batch classifier loss: 0.112619; batch adversarial loss: 0.392957\n",
      "epoch 46; iter: 0; batch classifier loss: 0.200280; batch adversarial loss: 0.385381\n",
      "epoch 47; iter: 0; batch classifier loss: 0.188460; batch adversarial loss: 0.440232\n",
      "epoch 48; iter: 0; batch classifier loss: 0.200281; batch adversarial loss: 0.496570\n",
      "epoch 49; iter: 0; batch classifier loss: 0.223720; batch adversarial loss: 0.451024\n",
      "epoch 50; iter: 0; batch classifier loss: 0.151056; batch adversarial loss: 0.518071\n",
      "epoch 51; iter: 0; batch classifier loss: 0.174888; batch adversarial loss: 0.434912\n",
      "epoch 52; iter: 0; batch classifier loss: 0.149775; batch adversarial loss: 0.474390\n",
      "epoch 53; iter: 0; batch classifier loss: 0.178530; batch adversarial loss: 0.483330\n",
      "epoch 54; iter: 0; batch classifier loss: 0.113747; batch adversarial loss: 0.420413\n",
      "epoch 55; iter: 0; batch classifier loss: 0.144596; batch adversarial loss: 0.430757\n",
      "epoch 56; iter: 0; batch classifier loss: 0.154260; batch adversarial loss: 0.467981\n",
      "epoch 57; iter: 0; batch classifier loss: 0.144872; batch adversarial loss: 0.515149\n",
      "epoch 58; iter: 0; batch classifier loss: 0.156253; batch adversarial loss: 0.429736\n",
      "epoch 59; iter: 0; batch classifier loss: 0.187222; batch adversarial loss: 0.430698\n",
      "epoch 60; iter: 0; batch classifier loss: 0.161771; batch adversarial loss: 0.465374\n",
      "epoch 61; iter: 0; batch classifier loss: 0.201603; batch adversarial loss: 0.401545\n",
      "epoch 62; iter: 0; batch classifier loss: 0.159193; batch adversarial loss: 0.443546\n",
      "epoch 63; iter: 0; batch classifier loss: 0.191346; batch adversarial loss: 0.456435\n",
      "epoch 64; iter: 0; batch classifier loss: 0.214206; batch adversarial loss: 0.462985\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087469; batch adversarial loss: 0.534599\n",
      "epoch 66; iter: 0; batch classifier loss: 0.156776; batch adversarial loss: 0.469516\n",
      "epoch 67; iter: 0; batch classifier loss: 0.173652; batch adversarial loss: 0.552594\n",
      "epoch 68; iter: 0; batch classifier loss: 0.201151; batch adversarial loss: 0.455917\n",
      "epoch 69; iter: 0; batch classifier loss: 0.188039; batch adversarial loss: 0.437392\n",
      "epoch 70; iter: 0; batch classifier loss: 0.169596; batch adversarial loss: 0.460822\n",
      "epoch 71; iter: 0; batch classifier loss: 0.256422; batch adversarial loss: 0.460867\n",
      "epoch 72; iter: 0; batch classifier loss: 0.232026; batch adversarial loss: 0.470103\n",
      "epoch 73; iter: 0; batch classifier loss: 0.161389; batch adversarial loss: 0.391250\n",
      "epoch 74; iter: 0; batch classifier loss: 0.205241; batch adversarial loss: 0.455118\n",
      "epoch 75; iter: 0; batch classifier loss: 0.184878; batch adversarial loss: 0.543276\n",
      "epoch 76; iter: 0; batch classifier loss: 0.112720; batch adversarial loss: 0.475046\n",
      "epoch 77; iter: 0; batch classifier loss: 0.214193; batch adversarial loss: 0.462098\n",
      "epoch 78; iter: 0; batch classifier loss: 0.254787; batch adversarial loss: 0.491471\n",
      "epoch 79; iter: 0; batch classifier loss: 0.205750; batch adversarial loss: 0.524236\n",
      "epoch 80; iter: 0; batch classifier loss: 0.244724; batch adversarial loss: 0.472440\n",
      "epoch 81; iter: 0; batch classifier loss: 0.203206; batch adversarial loss: 0.470284\n",
      "epoch 82; iter: 0; batch classifier loss: 0.172200; batch adversarial loss: 0.455365\n",
      "epoch 83; iter: 0; batch classifier loss: 0.206428; batch adversarial loss: 0.508110\n",
      "epoch 84; iter: 0; batch classifier loss: 0.222611; batch adversarial loss: 0.493906\n",
      "epoch 85; iter: 0; batch classifier loss: 0.148671; batch adversarial loss: 0.579939\n",
      "epoch 86; iter: 0; batch classifier loss: 0.269664; batch adversarial loss: 0.446639\n",
      "epoch 87; iter: 0; batch classifier loss: 0.195130; batch adversarial loss: 0.517012\n",
      "epoch 88; iter: 0; batch classifier loss: 0.224588; batch adversarial loss: 0.452786\n",
      "epoch 89; iter: 0; batch classifier loss: 0.227363; batch adversarial loss: 0.506796\n",
      "epoch 90; iter: 0; batch classifier loss: 0.215783; batch adversarial loss: 0.540819\n",
      "epoch 91; iter: 0; batch classifier loss: 0.213036; batch adversarial loss: 0.539284\n",
      "epoch 92; iter: 0; batch classifier loss: 0.138554; batch adversarial loss: 0.451099\n",
      "epoch 93; iter: 0; batch classifier loss: 0.195782; batch adversarial loss: 0.517994\n",
      "epoch 94; iter: 0; batch classifier loss: 0.230259; batch adversarial loss: 0.492975\n",
      "epoch 95; iter: 0; batch classifier loss: 0.220271; batch adversarial loss: 0.483335\n",
      "epoch 96; iter: 0; batch classifier loss: 0.252840; batch adversarial loss: 0.470565\n",
      "epoch 97; iter: 0; batch classifier loss: 0.155315; batch adversarial loss: 0.493050\n",
      "epoch 98; iter: 0; batch classifier loss: 0.199918; batch adversarial loss: 0.461194\n",
      "epoch 99; iter: 0; batch classifier loss: 0.248744; batch adversarial loss: 0.538457\n",
      "epoch 100; iter: 0; batch classifier loss: 0.187458; batch adversarial loss: 0.528733\n",
      "epoch 101; iter: 0; batch classifier loss: 0.204153; batch adversarial loss: 0.401494\n",
      "epoch 102; iter: 0; batch classifier loss: 0.258252; batch adversarial loss: 0.412954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103; iter: 0; batch classifier loss: 0.305203; batch adversarial loss: 0.483085\n",
      "epoch 104; iter: 0; batch classifier loss: 0.217539; batch adversarial loss: 0.563636\n",
      "epoch 105; iter: 0; batch classifier loss: 0.199609; batch adversarial loss: 0.424987\n",
      "epoch 106; iter: 0; batch classifier loss: 0.174000; batch adversarial loss: 0.574429\n",
      "epoch 107; iter: 0; batch classifier loss: 0.173068; batch adversarial loss: 0.470701\n",
      "epoch 108; iter: 0; batch classifier loss: 0.213543; batch adversarial loss: 0.517380\n",
      "epoch 109; iter: 0; batch classifier loss: 0.260854; batch adversarial loss: 0.494577\n",
      "epoch 110; iter: 0; batch classifier loss: 0.185929; batch adversarial loss: 0.446932\n",
      "epoch 111; iter: 0; batch classifier loss: 0.225697; batch adversarial loss: 0.471521\n",
      "epoch 112; iter: 0; batch classifier loss: 0.199613; batch adversarial loss: 0.471352\n",
      "epoch 113; iter: 0; batch classifier loss: 0.142516; batch adversarial loss: 0.471922\n",
      "epoch 114; iter: 0; batch classifier loss: 0.213897; batch adversarial loss: 0.447765\n",
      "epoch 115; iter: 0; batch classifier loss: 0.249076; batch adversarial loss: 0.437418\n",
      "epoch 116; iter: 0; batch classifier loss: 0.252263; batch adversarial loss: 0.401552\n",
      "epoch 117; iter: 0; batch classifier loss: 0.243180; batch adversarial loss: 0.392344\n",
      "epoch 118; iter: 0; batch classifier loss: 0.295932; batch adversarial loss: 0.459707\n",
      "epoch 119; iter: 0; batch classifier loss: 0.189113; batch adversarial loss: 0.516162\n",
      "epoch 120; iter: 0; batch classifier loss: 0.213759; batch adversarial loss: 0.447610\n",
      "epoch 121; iter: 0; batch classifier loss: 0.265123; batch adversarial loss: 0.540148\n",
      "epoch 122; iter: 0; batch classifier loss: 0.165996; batch adversarial loss: 0.493950\n",
      "epoch 123; iter: 0; batch classifier loss: 0.224842; batch adversarial loss: 0.355481\n",
      "epoch 124; iter: 0; batch classifier loss: 0.247331; batch adversarial loss: 0.504290\n",
      "epoch 125; iter: 0; batch classifier loss: 0.215583; batch adversarial loss: 0.516982\n",
      "epoch 126; iter: 0; batch classifier loss: 0.205110; batch adversarial loss: 0.402572\n",
      "epoch 127; iter: 0; batch classifier loss: 0.211920; batch adversarial loss: 0.540424\n",
      "epoch 128; iter: 0; batch classifier loss: 0.196099; batch adversarial loss: 0.482105\n",
      "epoch 129; iter: 0; batch classifier loss: 0.182251; batch adversarial loss: 0.563046\n",
      "epoch 130; iter: 0; batch classifier loss: 0.203850; batch adversarial loss: 0.539313\n",
      "epoch 131; iter: 0; batch classifier loss: 0.213530; batch adversarial loss: 0.505317\n",
      "epoch 132; iter: 0; batch classifier loss: 0.175131; batch adversarial loss: 0.505416\n",
      "epoch 133; iter: 0; batch classifier loss: 0.113674; batch adversarial loss: 0.435739\n",
      "epoch 134; iter: 0; batch classifier loss: 0.169098; batch adversarial loss: 0.425084\n",
      "epoch 135; iter: 0; batch classifier loss: 0.232705; batch adversarial loss: 0.436672\n",
      "epoch 136; iter: 0; batch classifier loss: 0.192485; batch adversarial loss: 0.482055\n",
      "epoch 137; iter: 0; batch classifier loss: 0.259244; batch adversarial loss: 0.435173\n",
      "epoch 138; iter: 0; batch classifier loss: 0.185127; batch adversarial loss: 0.552624\n",
      "epoch 139; iter: 0; batch classifier loss: 0.225097; batch adversarial loss: 0.529536\n",
      "epoch 140; iter: 0; batch classifier loss: 0.285716; batch adversarial loss: 0.448260\n",
      "epoch 141; iter: 0; batch classifier loss: 0.169314; batch adversarial loss: 0.574354\n",
      "epoch 142; iter: 0; batch classifier loss: 0.144211; batch adversarial loss: 0.608644\n",
      "epoch 143; iter: 0; batch classifier loss: 0.203536; batch adversarial loss: 0.505787\n",
      "epoch 144; iter: 0; batch classifier loss: 0.193296; batch adversarial loss: 0.540432\n",
      "epoch 145; iter: 0; batch classifier loss: 0.264069; batch adversarial loss: 0.540548\n",
      "epoch 146; iter: 0; batch classifier loss: 0.268064; batch adversarial loss: 0.447677\n",
      "epoch 147; iter: 0; batch classifier loss: 0.199596; batch adversarial loss: 0.436484\n",
      "epoch 148; iter: 0; batch classifier loss: 0.152500; batch adversarial loss: 0.586287\n",
      "epoch 149; iter: 0; batch classifier loss: 0.173372; batch adversarial loss: 0.482634\n",
      "epoch 150; iter: 0; batch classifier loss: 0.184348; batch adversarial loss: 0.390027\n",
      "epoch 151; iter: 0; batch classifier loss: 0.243153; batch adversarial loss: 0.436387\n",
      "epoch 152; iter: 0; batch classifier loss: 0.233028; batch adversarial loss: 0.448281\n",
      "epoch 153; iter: 0; batch classifier loss: 0.229399; batch adversarial loss: 0.459927\n",
      "epoch 154; iter: 0; batch classifier loss: 0.229870; batch adversarial loss: 0.390698\n",
      "epoch 155; iter: 0; batch classifier loss: 0.198920; batch adversarial loss: 0.483582\n",
      "epoch 156; iter: 0; batch classifier loss: 0.271867; batch adversarial loss: 0.436262\n",
      "epoch 157; iter: 0; batch classifier loss: 0.150371; batch adversarial loss: 0.482218\n",
      "epoch 158; iter: 0; batch classifier loss: 0.206410; batch adversarial loss: 0.482030\n",
      "epoch 159; iter: 0; batch classifier loss: 0.175905; batch adversarial loss: 0.505430\n",
      "epoch 160; iter: 0; batch classifier loss: 0.231761; batch adversarial loss: 0.505318\n",
      "epoch 161; iter: 0; batch classifier loss: 0.197186; batch adversarial loss: 0.436580\n",
      "epoch 162; iter: 0; batch classifier loss: 0.252759; batch adversarial loss: 0.505547\n",
      "epoch 163; iter: 0; batch classifier loss: 0.099800; batch adversarial loss: 0.528090\n",
      "epoch 164; iter: 0; batch classifier loss: 0.132058; batch adversarial loss: 0.552631\n",
      "epoch 165; iter: 0; batch classifier loss: 0.110083; batch adversarial loss: 0.435691\n",
      "epoch 166; iter: 0; batch classifier loss: 0.157809; batch adversarial loss: 0.455244\n",
      "epoch 167; iter: 0; batch classifier loss: 0.192689; batch adversarial loss: 0.542073\n",
      "epoch 168; iter: 0; batch classifier loss: 0.133271; batch adversarial loss: 0.565517\n",
      "epoch 169; iter: 0; batch classifier loss: 0.186157; batch adversarial loss: 0.576024\n",
      "epoch 170; iter: 0; batch classifier loss: 0.202108; batch adversarial loss: 0.459033\n",
      "epoch 171; iter: 0; batch classifier loss: 0.131195; batch adversarial loss: 0.526490\n",
      "epoch 172; iter: 0; batch classifier loss: 0.082080; batch adversarial loss: 0.491688\n",
      "epoch 173; iter: 0; batch classifier loss: 0.093282; batch adversarial loss: 0.525880\n",
      "epoch 174; iter: 0; batch classifier loss: 0.082659; batch adversarial loss: 0.462499\n",
      "epoch 175; iter: 0; batch classifier loss: 0.075915; batch adversarial loss: 0.601917\n",
      "epoch 176; iter: 0; batch classifier loss: 0.066049; batch adversarial loss: 0.475462\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021187; batch adversarial loss: 0.508434\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040810; batch adversarial loss: 0.450824\n",
      "epoch 179; iter: 0; batch classifier loss: 0.050236; batch adversarial loss: 0.518466\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030969; batch adversarial loss: 0.471715\n",
      "epoch 181; iter: 0; batch classifier loss: 0.044508; batch adversarial loss: 0.512303\n",
      "epoch 182; iter: 0; batch classifier loss: 0.074804; batch adversarial loss: 0.365214\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031069; batch adversarial loss: 0.504040\n",
      "epoch 184; iter: 0; batch classifier loss: 0.058429; batch adversarial loss: 0.369326\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020112; batch adversarial loss: 0.493388\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024112; batch adversarial loss: 0.505590\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036541; batch adversarial loss: 0.465944\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016517; batch adversarial loss: 0.521244\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016641; batch adversarial loss: 0.562309\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028552; batch adversarial loss: 0.491803\n",
      "epoch 191; iter: 0; batch classifier loss: 0.042397; batch adversarial loss: 0.491786\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016357; batch adversarial loss: 0.583388\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029553; batch adversarial loss: 0.470347\n",
      "epoch 194; iter: 0; batch classifier loss: 0.040512; batch adversarial loss: 0.545931\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016548; batch adversarial loss: 0.372337\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024739; batch adversarial loss: 0.433354\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025533; batch adversarial loss: 0.429391\n",
      "epoch 198; iter: 0; batch classifier loss: 0.040158; batch adversarial loss: 0.555784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199; iter: 0; batch classifier loss: 0.011808; batch adversarial loss: 0.449286\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706086; batch adversarial loss: 0.573141\n",
      "epoch 1; iter: 0; batch classifier loss: 0.395140; batch adversarial loss: 0.583318\n",
      "epoch 2; iter: 0; batch classifier loss: 0.384541; batch adversarial loss: 0.611241\n",
      "epoch 3; iter: 0; batch classifier loss: 0.390269; batch adversarial loss: 0.586948\n",
      "epoch 4; iter: 0; batch classifier loss: 0.381184; batch adversarial loss: 0.601333\n",
      "epoch 5; iter: 0; batch classifier loss: 0.365063; batch adversarial loss: 0.572804\n",
      "epoch 6; iter: 0; batch classifier loss: 0.285974; batch adversarial loss: 0.588505\n",
      "epoch 7; iter: 0; batch classifier loss: 0.386287; batch adversarial loss: 0.572657\n",
      "epoch 8; iter: 0; batch classifier loss: 0.340808; batch adversarial loss: 0.577014\n",
      "epoch 9; iter: 0; batch classifier loss: 0.257172; batch adversarial loss: 0.551601\n",
      "epoch 10; iter: 0; batch classifier loss: 0.386560; batch adversarial loss: 0.517570\n",
      "epoch 11; iter: 0; batch classifier loss: 0.314275; batch adversarial loss: 0.527233\n",
      "epoch 12; iter: 0; batch classifier loss: 0.314633; batch adversarial loss: 0.611097\n",
      "epoch 13; iter: 0; batch classifier loss: 0.455389; batch adversarial loss: 0.583435\n",
      "epoch 14; iter: 0; batch classifier loss: 0.580626; batch adversarial loss: 0.638786\n",
      "epoch 15; iter: 0; batch classifier loss: 0.499831; batch adversarial loss: 0.496717\n",
      "epoch 16; iter: 0; batch classifier loss: 0.450076; batch adversarial loss: 0.478718\n",
      "epoch 17; iter: 0; batch classifier loss: 0.343191; batch adversarial loss: 0.485887\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251529; batch adversarial loss: 0.476992\n",
      "epoch 19; iter: 0; batch classifier loss: 0.215190; batch adversarial loss: 0.498356\n",
      "epoch 20; iter: 0; batch classifier loss: 0.194022; batch adversarial loss: 0.484433\n",
      "epoch 21; iter: 0; batch classifier loss: 0.166439; batch adversarial loss: 0.457060\n",
      "epoch 22; iter: 0; batch classifier loss: 0.178967; batch adversarial loss: 0.497566\n",
      "epoch 23; iter: 0; batch classifier loss: 0.175159; batch adversarial loss: 0.495874\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192673; batch adversarial loss: 0.431796\n",
      "epoch 25; iter: 0; batch classifier loss: 0.171314; batch adversarial loss: 0.492667\n",
      "epoch 26; iter: 0; batch classifier loss: 0.132266; batch adversarial loss: 0.447117\n",
      "epoch 27; iter: 0; batch classifier loss: 0.172879; batch adversarial loss: 0.503942\n",
      "epoch 28; iter: 0; batch classifier loss: 0.148634; batch adversarial loss: 0.493229\n",
      "epoch 29; iter: 0; batch classifier loss: 0.131625; batch adversarial loss: 0.443497\n",
      "epoch 30; iter: 0; batch classifier loss: 0.164693; batch adversarial loss: 0.489162\n",
      "epoch 31; iter: 0; batch classifier loss: 0.146767; batch adversarial loss: 0.402783\n",
      "epoch 32; iter: 0; batch classifier loss: 0.120590; batch adversarial loss: 0.491605\n",
      "epoch 33; iter: 0; batch classifier loss: 0.113789; batch adversarial loss: 0.444212\n",
      "epoch 34; iter: 0; batch classifier loss: 0.108519; batch adversarial loss: 0.461867\n",
      "epoch 35; iter: 0; batch classifier loss: 0.132737; batch adversarial loss: 0.432040\n",
      "epoch 36; iter: 0; batch classifier loss: 0.126684; batch adversarial loss: 0.455786\n",
      "epoch 37; iter: 0; batch classifier loss: 0.089442; batch adversarial loss: 0.481945\n",
      "epoch 38; iter: 0; batch classifier loss: 0.119851; batch adversarial loss: 0.522537\n",
      "epoch 39; iter: 0; batch classifier loss: 0.150473; batch adversarial loss: 0.496200\n",
      "epoch 40; iter: 0; batch classifier loss: 0.111879; batch adversarial loss: 0.496488\n",
      "epoch 41; iter: 0; batch classifier loss: 0.097053; batch adversarial loss: 0.478890\n",
      "epoch 42; iter: 0; batch classifier loss: 0.167332; batch adversarial loss: 0.414575\n",
      "epoch 43; iter: 0; batch classifier loss: 0.072814; batch adversarial loss: 0.425697\n",
      "epoch 44; iter: 0; batch classifier loss: 0.088130; batch adversarial loss: 0.544189\n",
      "epoch 45; iter: 0; batch classifier loss: 0.157189; batch adversarial loss: 0.404598\n",
      "epoch 46; iter: 0; batch classifier loss: 0.128034; batch adversarial loss: 0.409233\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100329; batch adversarial loss: 0.504233\n",
      "epoch 48; iter: 0; batch classifier loss: 0.119999; batch adversarial loss: 0.413051\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113825; batch adversarial loss: 0.602088\n",
      "epoch 50; iter: 0; batch classifier loss: 0.072145; batch adversarial loss: 0.482617\n",
      "epoch 51; iter: 0; batch classifier loss: 0.116076; batch adversarial loss: 0.471301\n",
      "epoch 52; iter: 0; batch classifier loss: 0.081195; batch adversarial loss: 0.536656\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098859; batch adversarial loss: 0.356351\n",
      "epoch 54; iter: 0; batch classifier loss: 0.138362; batch adversarial loss: 0.381630\n",
      "epoch 55; iter: 0; batch classifier loss: 0.139517; batch adversarial loss: 0.500726\n",
      "epoch 56; iter: 0; batch classifier loss: 0.163648; batch adversarial loss: 0.449494\n",
      "epoch 57; iter: 0; batch classifier loss: 0.109855; batch adversarial loss: 0.403954\n",
      "epoch 58; iter: 0; batch classifier loss: 0.074703; batch adversarial loss: 0.484505\n",
      "epoch 59; iter: 0; batch classifier loss: 0.071669; batch adversarial loss: 0.494462\n",
      "epoch 60; iter: 0; batch classifier loss: 0.138238; batch adversarial loss: 0.410972\n",
      "epoch 61; iter: 0; batch classifier loss: 0.083807; batch adversarial loss: 0.564093\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084319; batch adversarial loss: 0.430902\n",
      "epoch 63; iter: 0; batch classifier loss: 0.090385; batch adversarial loss: 0.497551\n",
      "epoch 64; iter: 0; batch classifier loss: 0.051425; batch adversarial loss: 0.451205\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110781; batch adversarial loss: 0.531765\n",
      "epoch 66; iter: 0; batch classifier loss: 0.099669; batch adversarial loss: 0.540523\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095967; batch adversarial loss: 0.444587\n",
      "epoch 68; iter: 0; batch classifier loss: 0.055966; batch adversarial loss: 0.435151\n",
      "epoch 69; iter: 0; batch classifier loss: 0.104212; batch adversarial loss: 0.476434\n",
      "epoch 70; iter: 0; batch classifier loss: 0.073006; batch adversarial loss: 0.449032\n",
      "epoch 71; iter: 0; batch classifier loss: 0.074303; batch adversarial loss: 0.443585\n",
      "epoch 72; iter: 0; batch classifier loss: 0.096954; batch adversarial loss: 0.464706\n",
      "epoch 73; iter: 0; batch classifier loss: 0.120912; batch adversarial loss: 0.445391\n",
      "epoch 74; iter: 0; batch classifier loss: 0.107849; batch adversarial loss: 0.492835\n",
      "epoch 75; iter: 0; batch classifier loss: 0.087337; batch adversarial loss: 0.444915\n",
      "epoch 76; iter: 0; batch classifier loss: 0.086006; batch adversarial loss: 0.457034\n",
      "epoch 77; iter: 0; batch classifier loss: 0.144200; batch adversarial loss: 0.383388\n",
      "epoch 78; iter: 0; batch classifier loss: 0.118474; batch adversarial loss: 0.481951\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067167; batch adversarial loss: 0.553458\n",
      "epoch 80; iter: 0; batch classifier loss: 0.108712; batch adversarial loss: 0.382422\n",
      "epoch 81; iter: 0; batch classifier loss: 0.091156; batch adversarial loss: 0.549076\n",
      "epoch 82; iter: 0; batch classifier loss: 0.070005; batch adversarial loss: 0.438350\n",
      "epoch 83; iter: 0; batch classifier loss: 0.116901; batch adversarial loss: 0.458112\n",
      "epoch 84; iter: 0; batch classifier loss: 0.123017; batch adversarial loss: 0.433158\n",
      "epoch 85; iter: 0; batch classifier loss: 0.049440; batch adversarial loss: 0.335986\n",
      "epoch 86; iter: 0; batch classifier loss: 0.108361; batch adversarial loss: 0.542214\n",
      "epoch 87; iter: 0; batch classifier loss: 0.078008; batch adversarial loss: 0.432612\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076357; batch adversarial loss: 0.507065\n",
      "epoch 89; iter: 0; batch classifier loss: 0.099589; batch adversarial loss: 0.422766\n",
      "epoch 90; iter: 0; batch classifier loss: 0.106846; batch adversarial loss: 0.431074\n",
      "epoch 91; iter: 0; batch classifier loss: 0.069993; batch adversarial loss: 0.393215\n",
      "epoch 92; iter: 0; batch classifier loss: 0.126454; batch adversarial loss: 0.372247\n",
      "epoch 93; iter: 0; batch classifier loss: 0.098313; batch adversarial loss: 0.417599\n",
      "epoch 94; iter: 0; batch classifier loss: 0.090371; batch adversarial loss: 0.440375\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060236; batch adversarial loss: 0.459540\n",
      "epoch 96; iter: 0; batch classifier loss: 0.105966; batch adversarial loss: 0.507247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97; iter: 0; batch classifier loss: 0.045944; batch adversarial loss: 0.442224\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067022; batch adversarial loss: 0.490455\n",
      "epoch 99; iter: 0; batch classifier loss: 0.096181; batch adversarial loss: 0.487036\n",
      "epoch 100; iter: 0; batch classifier loss: 0.073615; batch adversarial loss: 0.509937\n",
      "epoch 101; iter: 0; batch classifier loss: 0.076702; batch adversarial loss: 0.423795\n",
      "epoch 102; iter: 0; batch classifier loss: 0.082006; batch adversarial loss: 0.450819\n",
      "epoch 103; iter: 0; batch classifier loss: 0.079327; batch adversarial loss: 0.509307\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045145; batch adversarial loss: 0.500669\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061898; batch adversarial loss: 0.444009\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063661; batch adversarial loss: 0.405011\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056095; batch adversarial loss: 0.516968\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059253; batch adversarial loss: 0.515265\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067328; batch adversarial loss: 0.479653\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053343; batch adversarial loss: 0.469136\n",
      "epoch 111; iter: 0; batch classifier loss: 0.071865; batch adversarial loss: 0.495171\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042764; batch adversarial loss: 0.442024\n",
      "epoch 113; iter: 0; batch classifier loss: 0.081430; batch adversarial loss: 0.379359\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051395; batch adversarial loss: 0.430799\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046676; batch adversarial loss: 0.449054\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036438; batch adversarial loss: 0.507899\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060425; batch adversarial loss: 0.488276\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040395; batch adversarial loss: 0.531019\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041012; batch adversarial loss: 0.438525\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048266; batch adversarial loss: 0.493520\n",
      "epoch 121; iter: 0; batch classifier loss: 0.074316; batch adversarial loss: 0.383040\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041378; batch adversarial loss: 0.412105\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051865; batch adversarial loss: 0.482260\n",
      "epoch 124; iter: 0; batch classifier loss: 0.064313; batch adversarial loss: 0.441804\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032447; batch adversarial loss: 0.368697\n",
      "epoch 126; iter: 0; batch classifier loss: 0.071530; batch adversarial loss: 0.401572\n",
      "epoch 127; iter: 0; batch classifier loss: 0.059789; batch adversarial loss: 0.358840\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037798; batch adversarial loss: 0.420084\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022621; batch adversarial loss: 0.444649\n",
      "epoch 130; iter: 0; batch classifier loss: 0.013766; batch adversarial loss: 0.437684\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033372; batch adversarial loss: 0.408223\n",
      "epoch 132; iter: 0; batch classifier loss: 0.082382; batch adversarial loss: 0.476518\n",
      "epoch 133; iter: 0; batch classifier loss: 0.064498; batch adversarial loss: 0.395687\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026941; batch adversarial loss: 0.506439\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016940; batch adversarial loss: 0.554656\n",
      "epoch 136; iter: 0; batch classifier loss: 0.077225; batch adversarial loss: 0.480747\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036564; batch adversarial loss: 0.528397\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020032; batch adversarial loss: 0.469205\n",
      "epoch 139; iter: 0; batch classifier loss: 0.066217; batch adversarial loss: 0.412429\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030820; batch adversarial loss: 0.468348\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022257; batch adversarial loss: 0.468051\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048819; batch adversarial loss: 0.425449\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025150; batch adversarial loss: 0.474642\n",
      "epoch 144; iter: 0; batch classifier loss: 0.059483; batch adversarial loss: 0.494073\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020549; batch adversarial loss: 0.536972\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015511; batch adversarial loss: 0.411497\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038834; batch adversarial loss: 0.477063\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045462; batch adversarial loss: 0.469926\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033381; batch adversarial loss: 0.490569\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038617; batch adversarial loss: 0.360765\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030726; batch adversarial loss: 0.400350\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042915; batch adversarial loss: 0.466153\n",
      "epoch 153; iter: 0; batch classifier loss: 0.045285; batch adversarial loss: 0.459379\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017516; batch adversarial loss: 0.398611\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052487; batch adversarial loss: 0.464173\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034372; batch adversarial loss: 0.509890\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039447; batch adversarial loss: 0.432298\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023843; batch adversarial loss: 0.445114\n",
      "epoch 159; iter: 0; batch classifier loss: 0.057809; batch adversarial loss: 0.399199\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018440; batch adversarial loss: 0.428629\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023772; batch adversarial loss: 0.378380\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024160; batch adversarial loss: 0.509769\n",
      "epoch 163; iter: 0; batch classifier loss: 0.061738; batch adversarial loss: 0.425818\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032504; batch adversarial loss: 0.492472\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015853; batch adversarial loss: 0.527126\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027658; batch adversarial loss: 0.436052\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033299; batch adversarial loss: 0.525912\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020468; batch adversarial loss: 0.484845\n",
      "epoch 169; iter: 0; batch classifier loss: 0.058272; batch adversarial loss: 0.481637\n",
      "epoch 170; iter: 0; batch classifier loss: 0.074306; batch adversarial loss: 0.480725\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024726; batch adversarial loss: 0.459472\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023799; batch adversarial loss: 0.428707\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017182; batch adversarial loss: 0.466929\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016526; batch adversarial loss: 0.475541\n",
      "epoch 175; iter: 0; batch classifier loss: 0.046789; batch adversarial loss: 0.440831\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016739; batch adversarial loss: 0.616669\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011816; batch adversarial loss: 0.429462\n",
      "epoch 178; iter: 0; batch classifier loss: 0.058194; batch adversarial loss: 0.465015\n",
      "epoch 179; iter: 0; batch classifier loss: 0.049293; batch adversarial loss: 0.492635\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021954; batch adversarial loss: 0.471997\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011593; batch adversarial loss: 0.482508\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021904; batch adversarial loss: 0.428010\n",
      "epoch 183; iter: 0; batch classifier loss: 0.065473; batch adversarial loss: 0.473949\n",
      "epoch 184; iter: 0; batch classifier loss: 0.062798; batch adversarial loss: 0.441097\n",
      "epoch 185; iter: 0; batch classifier loss: 0.004077; batch adversarial loss: 0.506469\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031160; batch adversarial loss: 0.515951\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008994; batch adversarial loss: 0.562691\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020795; batch adversarial loss: 0.499847\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033158; batch adversarial loss: 0.463609\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024670; batch adversarial loss: 0.470617\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034838; batch adversarial loss: 0.409250\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033557; batch adversarial loss: 0.421891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 193; iter: 0; batch classifier loss: 0.027367; batch adversarial loss: 0.493351\n",
      "epoch 194; iter: 0; batch classifier loss: 0.037884; batch adversarial loss: 0.512407\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008108; batch adversarial loss: 0.390746\n",
      "epoch 196; iter: 0; batch classifier loss: 0.036215; batch adversarial loss: 0.458856\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008949; batch adversarial loss: 0.479313\n",
      "epoch 198; iter: 0; batch classifier loss: 0.049901; batch adversarial loss: 0.466073\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022598; batch adversarial loss: 0.470982\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678639; batch adversarial loss: 0.782100\n",
      "epoch 1; iter: 0; batch classifier loss: 0.546558; batch adversarial loss: 0.695686\n",
      "epoch 2; iter: 0; batch classifier loss: 0.708272; batch adversarial loss: 0.723617\n",
      "epoch 3; iter: 0; batch classifier loss: 0.631786; batch adversarial loss: 0.702259\n",
      "epoch 4; iter: 0; batch classifier loss: 0.489050; batch adversarial loss: 0.567230\n",
      "epoch 5; iter: 0; batch classifier loss: 0.351512; batch adversarial loss: 0.552730\n",
      "epoch 6; iter: 0; batch classifier loss: 0.291741; batch adversarial loss: 0.540715\n",
      "epoch 7; iter: 0; batch classifier loss: 0.354488; batch adversarial loss: 0.525487\n",
      "epoch 8; iter: 0; batch classifier loss: 0.288644; batch adversarial loss: 0.609057\n",
      "epoch 9; iter: 0; batch classifier loss: 0.231021; batch adversarial loss: 0.486633\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269616; batch adversarial loss: 0.613248\n",
      "epoch 11; iter: 0; batch classifier loss: 0.273365; batch adversarial loss: 0.501476\n",
      "epoch 12; iter: 0; batch classifier loss: 0.296103; batch adversarial loss: 0.471842\n",
      "epoch 13; iter: 0; batch classifier loss: 0.252062; batch adversarial loss: 0.481135\n",
      "epoch 14; iter: 0; batch classifier loss: 0.202418; batch adversarial loss: 0.574185\n",
      "epoch 15; iter: 0; batch classifier loss: 0.229481; batch adversarial loss: 0.491016\n",
      "epoch 16; iter: 0; batch classifier loss: 0.162728; batch adversarial loss: 0.506686\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241425; batch adversarial loss: 0.535950\n",
      "epoch 18; iter: 0; batch classifier loss: 0.256054; batch adversarial loss: 0.447211\n",
      "epoch 19; iter: 0; batch classifier loss: 0.202259; batch adversarial loss: 0.483316\n",
      "epoch 20; iter: 0; batch classifier loss: 0.201345; batch adversarial loss: 0.449386\n",
      "epoch 21; iter: 0; batch classifier loss: 0.162334; batch adversarial loss: 0.495582\n",
      "epoch 22; iter: 0; batch classifier loss: 0.180865; batch adversarial loss: 0.465740\n",
      "epoch 23; iter: 0; batch classifier loss: 0.177233; batch adversarial loss: 0.469322\n",
      "epoch 24; iter: 0; batch classifier loss: 0.137617; batch adversarial loss: 0.448201\n",
      "epoch 25; iter: 0; batch classifier loss: 0.130140; batch adversarial loss: 0.470834\n",
      "epoch 26; iter: 0; batch classifier loss: 0.136431; batch adversarial loss: 0.398443\n",
      "epoch 27; iter: 0; batch classifier loss: 0.135038; batch adversarial loss: 0.486917\n",
      "epoch 28; iter: 0; batch classifier loss: 0.183988; batch adversarial loss: 0.425385\n",
      "epoch 29; iter: 0; batch classifier loss: 0.185622; batch adversarial loss: 0.506227\n",
      "epoch 30; iter: 0; batch classifier loss: 0.130622; batch adversarial loss: 0.515314\n",
      "epoch 31; iter: 0; batch classifier loss: 0.182755; batch adversarial loss: 0.567029\n",
      "epoch 32; iter: 0; batch classifier loss: 0.143426; batch adversarial loss: 0.429353\n",
      "epoch 33; iter: 0; batch classifier loss: 0.155697; batch adversarial loss: 0.442405\n",
      "epoch 34; iter: 0; batch classifier loss: 0.070798; batch adversarial loss: 0.554522\n",
      "epoch 35; iter: 0; batch classifier loss: 0.128469; batch adversarial loss: 0.452587\n",
      "epoch 36; iter: 0; batch classifier loss: 0.119690; batch adversarial loss: 0.457270\n",
      "epoch 37; iter: 0; batch classifier loss: 0.099628; batch adversarial loss: 0.540995\n",
      "epoch 38; iter: 0; batch classifier loss: 0.076504; batch adversarial loss: 0.467267\n",
      "epoch 39; iter: 0; batch classifier loss: 0.173536; batch adversarial loss: 0.504338\n",
      "epoch 40; iter: 0; batch classifier loss: 0.081252; batch adversarial loss: 0.429729\n",
      "epoch 41; iter: 0; batch classifier loss: 0.140704; batch adversarial loss: 0.483863\n",
      "epoch 42; iter: 0; batch classifier loss: 0.115822; batch adversarial loss: 0.417521\n",
      "epoch 43; iter: 0; batch classifier loss: 0.105533; batch adversarial loss: 0.430217\n",
      "epoch 44; iter: 0; batch classifier loss: 0.122480; batch adversarial loss: 0.467334\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089892; batch adversarial loss: 0.504628\n",
      "epoch 46; iter: 0; batch classifier loss: 0.055332; batch adversarial loss: 0.553067\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119613; batch adversarial loss: 0.408280\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081600; batch adversarial loss: 0.450032\n",
      "epoch 49; iter: 0; batch classifier loss: 0.069732; batch adversarial loss: 0.550964\n",
      "epoch 50; iter: 0; batch classifier loss: 0.110892; batch adversarial loss: 0.400572\n",
      "epoch 51; iter: 0; batch classifier loss: 0.067943; batch adversarial loss: 0.427757\n",
      "epoch 52; iter: 0; batch classifier loss: 0.047220; batch adversarial loss: 0.538303\n",
      "epoch 53; iter: 0; batch classifier loss: 0.087699; batch adversarial loss: 0.545632\n",
      "epoch 54; iter: 0; batch classifier loss: 0.123527; batch adversarial loss: 0.445991\n",
      "epoch 55; iter: 0; batch classifier loss: 0.102173; batch adversarial loss: 0.462167\n",
      "epoch 56; iter: 0; batch classifier loss: 0.069470; batch adversarial loss: 0.379224\n",
      "epoch 57; iter: 0; batch classifier loss: 0.078210; batch adversarial loss: 0.462977\n",
      "epoch 58; iter: 0; batch classifier loss: 0.086170; batch adversarial loss: 0.444182\n",
      "epoch 59; iter: 0; batch classifier loss: 0.107101; batch adversarial loss: 0.569821\n",
      "epoch 60; iter: 0; batch classifier loss: 0.069091; batch adversarial loss: 0.483406\n",
      "epoch 61; iter: 0; batch classifier loss: 0.064119; batch adversarial loss: 0.458762\n",
      "epoch 62; iter: 0; batch classifier loss: 0.102621; batch adversarial loss: 0.484832\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095924; batch adversarial loss: 0.423527\n",
      "epoch 64; iter: 0; batch classifier loss: 0.043252; batch adversarial loss: 0.522910\n",
      "epoch 65; iter: 0; batch classifier loss: 0.105499; batch adversarial loss: 0.513544\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060658; batch adversarial loss: 0.510988\n",
      "epoch 67; iter: 0; batch classifier loss: 0.111075; batch adversarial loss: 0.413313\n",
      "epoch 68; iter: 0; batch classifier loss: 0.073741; batch adversarial loss: 0.495002\n",
      "epoch 69; iter: 0; batch classifier loss: 0.077785; batch adversarial loss: 0.480112\n",
      "epoch 70; iter: 0; batch classifier loss: 0.155652; batch adversarial loss: 0.506236\n",
      "epoch 71; iter: 0; batch classifier loss: 0.050865; batch adversarial loss: 0.428448\n",
      "epoch 72; iter: 0; batch classifier loss: 0.065334; batch adversarial loss: 0.447216\n",
      "epoch 73; iter: 0; batch classifier loss: 0.042608; batch adversarial loss: 0.442135\n",
      "epoch 74; iter: 0; batch classifier loss: 0.045336; batch adversarial loss: 0.425255\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061862; batch adversarial loss: 0.522929\n",
      "epoch 76; iter: 0; batch classifier loss: 0.084233; batch adversarial loss: 0.473866\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063667; batch adversarial loss: 0.434226\n",
      "epoch 78; iter: 0; batch classifier loss: 0.088337; batch adversarial loss: 0.433626\n",
      "epoch 79; iter: 0; batch classifier loss: 0.055603; batch adversarial loss: 0.475228\n",
      "epoch 80; iter: 0; batch classifier loss: 0.065293; batch adversarial loss: 0.410088\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069525; batch adversarial loss: 0.532410\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063432; batch adversarial loss: 0.442644\n",
      "epoch 83; iter: 0; batch classifier loss: 0.088771; batch adversarial loss: 0.389370\n",
      "epoch 84; iter: 0; batch classifier loss: 0.072871; batch adversarial loss: 0.447177\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059394; batch adversarial loss: 0.449684\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054895; batch adversarial loss: 0.538726\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048163; batch adversarial loss: 0.427738\n",
      "epoch 88; iter: 0; batch classifier loss: 0.061232; batch adversarial loss: 0.463655\n",
      "epoch 89; iter: 0; batch classifier loss: 0.064973; batch adversarial loss: 0.489293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.079366; batch adversarial loss: 0.555703\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067327; batch adversarial loss: 0.358255\n",
      "epoch 92; iter: 0; batch classifier loss: 0.092143; batch adversarial loss: 0.484928\n",
      "epoch 93; iter: 0; batch classifier loss: 0.035088; batch adversarial loss: 0.446016\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043544; batch adversarial loss: 0.545514\n",
      "epoch 95; iter: 0; batch classifier loss: 0.040569; batch adversarial loss: 0.501359\n",
      "epoch 96; iter: 0; batch classifier loss: 0.042478; batch adversarial loss: 0.463968\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039767; batch adversarial loss: 0.463054\n",
      "epoch 98; iter: 0; batch classifier loss: 0.026234; batch adversarial loss: 0.440003\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043288; batch adversarial loss: 0.480456\n",
      "epoch 100; iter: 0; batch classifier loss: 0.097881; batch adversarial loss: 0.346308\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054522; batch adversarial loss: 0.453284\n",
      "epoch 102; iter: 0; batch classifier loss: 0.023817; batch adversarial loss: 0.346048\n",
      "epoch 103; iter: 0; batch classifier loss: 0.079521; batch adversarial loss: 0.481317\n",
      "epoch 104; iter: 0; batch classifier loss: 0.074762; batch adversarial loss: 0.350305\n",
      "epoch 105; iter: 0; batch classifier loss: 0.090638; batch adversarial loss: 0.468640\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046169; batch adversarial loss: 0.473487\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045263; batch adversarial loss: 0.556156\n",
      "epoch 108; iter: 0; batch classifier loss: 0.021849; batch adversarial loss: 0.443543\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032641; batch adversarial loss: 0.488606\n",
      "epoch 110; iter: 0; batch classifier loss: 0.081461; batch adversarial loss: 0.423059\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058256; batch adversarial loss: 0.444714\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030402; batch adversarial loss: 0.471635\n",
      "epoch 113; iter: 0; batch classifier loss: 0.026831; batch adversarial loss: 0.455482\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049213; batch adversarial loss: 0.424980\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027748; batch adversarial loss: 0.482754\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044000; batch adversarial loss: 0.472925\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056300; batch adversarial loss: 0.403124\n",
      "epoch 118; iter: 0; batch classifier loss: 0.034897; batch adversarial loss: 0.485132\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031222; batch adversarial loss: 0.420766\n",
      "epoch 120; iter: 0; batch classifier loss: 0.010474; batch adversarial loss: 0.475656\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039522; batch adversarial loss: 0.490313\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042391; batch adversarial loss: 0.378090\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064584; batch adversarial loss: 0.492167\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041251; batch adversarial loss: 0.450774\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043536; batch adversarial loss: 0.450644\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050241; batch adversarial loss: 0.474595\n",
      "epoch 127; iter: 0; batch classifier loss: 0.018313; batch adversarial loss: 0.579162\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032792; batch adversarial loss: 0.433989\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017582; batch adversarial loss: 0.474396\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021383; batch adversarial loss: 0.406130\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033798; batch adversarial loss: 0.476739\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058218; batch adversarial loss: 0.308027\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025247; batch adversarial loss: 0.410425\n",
      "epoch 134; iter: 0; batch classifier loss: 0.083790; batch adversarial loss: 0.477985\n",
      "epoch 135; iter: 0; batch classifier loss: 0.053358; batch adversarial loss: 0.444377\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020120; batch adversarial loss: 0.380025\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028545; batch adversarial loss: 0.597225\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045634; batch adversarial loss: 0.593825\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038709; batch adversarial loss: 0.552644\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023758; batch adversarial loss: 0.437568\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030638; batch adversarial loss: 0.489646\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022138; batch adversarial loss: 0.528162\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031430; batch adversarial loss: 0.448584\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013511; batch adversarial loss: 0.413367\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022792; batch adversarial loss: 0.460126\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048620; batch adversarial loss: 0.480348\n",
      "epoch 147; iter: 0; batch classifier loss: 0.003854; batch adversarial loss: 0.421359\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019912; batch adversarial loss: 0.471201\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022682; batch adversarial loss: 0.443674\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011934; batch adversarial loss: 0.482679\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020872; batch adversarial loss: 0.474348\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018827; batch adversarial loss: 0.493339\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022239; batch adversarial loss: 0.383998\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036293; batch adversarial loss: 0.364588\n",
      "epoch 155; iter: 0; batch classifier loss: 0.062373; batch adversarial loss: 0.400577\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032350; batch adversarial loss: 0.432480\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028401; batch adversarial loss: 0.501175\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018894; batch adversarial loss: 0.501273\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012970; batch adversarial loss: 0.479212\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029848; batch adversarial loss: 0.432171\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028280; batch adversarial loss: 0.441784\n",
      "epoch 162; iter: 0; batch classifier loss: 0.008455; batch adversarial loss: 0.491968\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016799; batch adversarial loss: 0.415935\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021205; batch adversarial loss: 0.357557\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025577; batch adversarial loss: 0.356891\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021412; batch adversarial loss: 0.474545\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020762; batch adversarial loss: 0.391918\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038696; batch adversarial loss: 0.454447\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028561; batch adversarial loss: 0.413855\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014963; batch adversarial loss: 0.370659\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015485; batch adversarial loss: 0.394756\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024569; batch adversarial loss: 0.437492\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020808; batch adversarial loss: 0.448786\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039112; batch adversarial loss: 0.491790\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020343; batch adversarial loss: 0.482417\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019907; batch adversarial loss: 0.413535\n",
      "epoch 177; iter: 0; batch classifier loss: 0.005651; batch adversarial loss: 0.443263\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035973; batch adversarial loss: 0.508308\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027884; batch adversarial loss: 0.421632\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007091; batch adversarial loss: 0.527983\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019884; batch adversarial loss: 0.430660\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037672; batch adversarial loss: 0.465001\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006881; batch adversarial loss: 0.555777\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025246; batch adversarial loss: 0.446302\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010274; batch adversarial loss: 0.391717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.015430; batch adversarial loss: 0.339131\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016098; batch adversarial loss: 0.405180\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013451; batch adversarial loss: 0.412498\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008469; batch adversarial loss: 0.450572\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022473; batch adversarial loss: 0.440136\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008784; batch adversarial loss: 0.486073\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036213; batch adversarial loss: 0.458046\n",
      "epoch 193; iter: 0; batch classifier loss: 0.058939; batch adversarial loss: 0.433543\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010680; batch adversarial loss: 0.527688\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023556; batch adversarial loss: 0.472405\n",
      "epoch 196; iter: 0; batch classifier loss: 0.039088; batch adversarial loss: 0.481650\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007568; batch adversarial loss: 0.390228\n",
      "epoch 198; iter: 0; batch classifier loss: 0.035328; batch adversarial loss: 0.475554\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023103; batch adversarial loss: 0.495209\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671765; batch adversarial loss: 0.897666\n",
      "epoch 1; iter: 0; batch classifier loss: 0.789828; batch adversarial loss: 1.152341\n",
      "epoch 2; iter: 0; batch classifier loss: 0.949242; batch adversarial loss: 1.118583\n",
      "epoch 3; iter: 0; batch classifier loss: 0.995660; batch adversarial loss: 1.002319\n",
      "epoch 4; iter: 0; batch classifier loss: 0.974556; batch adversarial loss: 0.911404\n",
      "epoch 5; iter: 0; batch classifier loss: 0.909906; batch adversarial loss: 0.827570\n",
      "epoch 6; iter: 0; batch classifier loss: 0.938521; batch adversarial loss: 0.787126\n",
      "epoch 7; iter: 0; batch classifier loss: 0.960086; batch adversarial loss: 0.747265\n",
      "epoch 8; iter: 0; batch classifier loss: 0.795206; batch adversarial loss: 0.681952\n",
      "epoch 9; iter: 0; batch classifier loss: 0.659959; batch adversarial loss: 0.668395\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550172; batch adversarial loss: 0.561328\n",
      "epoch 11; iter: 0; batch classifier loss: 0.419900; batch adversarial loss: 0.553174\n",
      "epoch 12; iter: 0; batch classifier loss: 0.352319; batch adversarial loss: 0.501012\n",
      "epoch 13; iter: 0; batch classifier loss: 0.292162; batch adversarial loss: 0.520102\n",
      "epoch 14; iter: 0; batch classifier loss: 0.290158; batch adversarial loss: 0.475030\n",
      "epoch 15; iter: 0; batch classifier loss: 0.237669; batch adversarial loss: 0.520843\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311830; batch adversarial loss: 0.464051\n",
      "epoch 17; iter: 0; batch classifier loss: 0.290393; batch adversarial loss: 0.515242\n",
      "epoch 18; iter: 0; batch classifier loss: 0.216581; batch adversarial loss: 0.520706\n",
      "epoch 19; iter: 0; batch classifier loss: 0.222787; batch adversarial loss: 0.561301\n",
      "epoch 20; iter: 0; batch classifier loss: 0.192290; batch adversarial loss: 0.507015\n",
      "epoch 21; iter: 0; batch classifier loss: 0.233379; batch adversarial loss: 0.517400\n",
      "epoch 22; iter: 0; batch classifier loss: 0.153349; batch adversarial loss: 0.475782\n",
      "epoch 23; iter: 0; batch classifier loss: 0.153656; batch adversarial loss: 0.473787\n",
      "epoch 24; iter: 0; batch classifier loss: 0.202669; batch adversarial loss: 0.374060\n",
      "epoch 25; iter: 0; batch classifier loss: 0.176396; batch adversarial loss: 0.451463\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182061; batch adversarial loss: 0.472105\n",
      "epoch 27; iter: 0; batch classifier loss: 0.175365; batch adversarial loss: 0.412007\n",
      "epoch 28; iter: 0; batch classifier loss: 0.178861; batch adversarial loss: 0.420876\n",
      "epoch 29; iter: 0; batch classifier loss: 0.234973; batch adversarial loss: 0.497931\n",
      "epoch 30; iter: 0; batch classifier loss: 0.215436; batch adversarial loss: 0.474857\n",
      "epoch 31; iter: 0; batch classifier loss: 0.155816; batch adversarial loss: 0.408412\n",
      "epoch 32; iter: 0; batch classifier loss: 0.199662; batch adversarial loss: 0.372328\n",
      "epoch 33; iter: 0; batch classifier loss: 0.197067; batch adversarial loss: 0.492151\n",
      "epoch 34; iter: 0; batch classifier loss: 0.173220; batch adversarial loss: 0.383915\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160748; batch adversarial loss: 0.543986\n",
      "epoch 36; iter: 0; batch classifier loss: 0.191705; batch adversarial loss: 0.424996\n",
      "epoch 37; iter: 0; batch classifier loss: 0.168087; batch adversarial loss: 0.416161\n",
      "epoch 38; iter: 0; batch classifier loss: 0.171865; batch adversarial loss: 0.447710\n",
      "epoch 39; iter: 0; batch classifier loss: 0.195149; batch adversarial loss: 0.403997\n",
      "epoch 40; iter: 0; batch classifier loss: 0.139814; batch adversarial loss: 0.447791\n",
      "epoch 41; iter: 0; batch classifier loss: 0.122866; batch adversarial loss: 0.539937\n",
      "epoch 42; iter: 0; batch classifier loss: 0.133640; batch adversarial loss: 0.515836\n",
      "epoch 43; iter: 0; batch classifier loss: 0.180909; batch adversarial loss: 0.468031\n",
      "epoch 44; iter: 0; batch classifier loss: 0.140263; batch adversarial loss: 0.482818\n",
      "epoch 45; iter: 0; batch classifier loss: 0.187545; batch adversarial loss: 0.407443\n",
      "epoch 46; iter: 0; batch classifier loss: 0.193256; batch adversarial loss: 0.457852\n",
      "epoch 47; iter: 0; batch classifier loss: 0.170478; batch adversarial loss: 0.481815\n",
      "epoch 48; iter: 0; batch classifier loss: 0.174839; batch adversarial loss: 0.436981\n",
      "epoch 49; iter: 0; batch classifier loss: 0.225516; batch adversarial loss: 0.450339\n",
      "epoch 50; iter: 0; batch classifier loss: 0.176181; batch adversarial loss: 0.524514\n",
      "epoch 51; iter: 0; batch classifier loss: 0.162526; batch adversarial loss: 0.429852\n",
      "epoch 52; iter: 0; batch classifier loss: 0.168749; batch adversarial loss: 0.427408\n",
      "epoch 53; iter: 0; batch classifier loss: 0.111658; batch adversarial loss: 0.493395\n",
      "epoch 54; iter: 0; batch classifier loss: 0.131603; batch adversarial loss: 0.433638\n",
      "epoch 55; iter: 0; batch classifier loss: 0.143691; batch adversarial loss: 0.435432\n",
      "epoch 56; iter: 0; batch classifier loss: 0.112017; batch adversarial loss: 0.581948\n",
      "epoch 57; iter: 0; batch classifier loss: 0.114699; batch adversarial loss: 0.548739\n",
      "epoch 58; iter: 0; batch classifier loss: 0.170299; batch adversarial loss: 0.554679\n",
      "epoch 59; iter: 0; batch classifier loss: 0.162093; batch adversarial loss: 0.398649\n",
      "epoch 60; iter: 0; batch classifier loss: 0.114011; batch adversarial loss: 0.394026\n",
      "epoch 61; iter: 0; batch classifier loss: 0.199954; batch adversarial loss: 0.527353\n",
      "epoch 62; iter: 0; batch classifier loss: 0.130012; batch adversarial loss: 0.505629\n",
      "epoch 63; iter: 0; batch classifier loss: 0.112337; batch adversarial loss: 0.458821\n",
      "epoch 64; iter: 0; batch classifier loss: 0.174325; batch adversarial loss: 0.442616\n",
      "epoch 65; iter: 0; batch classifier loss: 0.160345; batch adversarial loss: 0.483818\n",
      "epoch 66; iter: 0; batch classifier loss: 0.133725; batch adversarial loss: 0.485391\n",
      "epoch 67; iter: 0; batch classifier loss: 0.093805; batch adversarial loss: 0.558588\n",
      "epoch 68; iter: 0; batch classifier loss: 0.148544; batch adversarial loss: 0.526793\n",
      "epoch 69; iter: 0; batch classifier loss: 0.088185; batch adversarial loss: 0.426689\n",
      "epoch 70; iter: 0; batch classifier loss: 0.173040; batch adversarial loss: 0.434795\n",
      "epoch 71; iter: 0; batch classifier loss: 0.109241; batch adversarial loss: 0.398283\n",
      "epoch 72; iter: 0; batch classifier loss: 0.232029; batch adversarial loss: 0.358687\n",
      "epoch 73; iter: 0; batch classifier loss: 0.154846; batch adversarial loss: 0.443841\n",
      "epoch 74; iter: 0; batch classifier loss: 0.148365; batch adversarial loss: 0.459011\n",
      "epoch 75; iter: 0; batch classifier loss: 0.112393; batch adversarial loss: 0.382188\n",
      "epoch 76; iter: 0; batch classifier loss: 0.150668; batch adversarial loss: 0.414215\n",
      "epoch 77; iter: 0; batch classifier loss: 0.158036; batch adversarial loss: 0.373294\n",
      "epoch 78; iter: 0; batch classifier loss: 0.096664; batch adversarial loss: 0.448200\n",
      "epoch 79; iter: 0; batch classifier loss: 0.089706; batch adversarial loss: 0.536640\n",
      "epoch 80; iter: 0; batch classifier loss: 0.213511; batch adversarial loss: 0.420571\n",
      "epoch 81; iter: 0; batch classifier loss: 0.164971; batch adversarial loss: 0.450993\n",
      "epoch 82; iter: 0; batch classifier loss: 0.193528; batch adversarial loss: 0.414632\n",
      "epoch 83; iter: 0; batch classifier loss: 0.101787; batch adversarial loss: 0.425398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.135631; batch adversarial loss: 0.587487\n",
      "epoch 85; iter: 0; batch classifier loss: 0.140615; batch adversarial loss: 0.397424\n",
      "epoch 86; iter: 0; batch classifier loss: 0.136344; batch adversarial loss: 0.449348\n",
      "epoch 87; iter: 0; batch classifier loss: 0.167365; batch adversarial loss: 0.341819\n",
      "epoch 88; iter: 0; batch classifier loss: 0.188283; batch adversarial loss: 0.384613\n",
      "epoch 89; iter: 0; batch classifier loss: 0.153458; batch adversarial loss: 0.591381\n",
      "epoch 90; iter: 0; batch classifier loss: 0.129064; batch adversarial loss: 0.370172\n",
      "epoch 91; iter: 0; batch classifier loss: 0.115737; batch adversarial loss: 0.410977\n",
      "epoch 92; iter: 0; batch classifier loss: 0.140168; batch adversarial loss: 0.501956\n",
      "epoch 93; iter: 0; batch classifier loss: 0.127768; batch adversarial loss: 0.491130\n",
      "epoch 94; iter: 0; batch classifier loss: 0.149522; batch adversarial loss: 0.460817\n",
      "epoch 95; iter: 0; batch classifier loss: 0.109610; batch adversarial loss: 0.428656\n",
      "epoch 96; iter: 0; batch classifier loss: 0.156672; batch adversarial loss: 0.527689\n",
      "epoch 97; iter: 0; batch classifier loss: 0.101627; batch adversarial loss: 0.586075\n",
      "epoch 98; iter: 0; batch classifier loss: 0.089784; batch adversarial loss: 0.511151\n",
      "epoch 99; iter: 0; batch classifier loss: 0.151674; batch adversarial loss: 0.402060\n",
      "epoch 100; iter: 0; batch classifier loss: 0.079709; batch adversarial loss: 0.415773\n",
      "epoch 101; iter: 0; batch classifier loss: 0.124211; batch adversarial loss: 0.522267\n",
      "epoch 102; iter: 0; batch classifier loss: 0.121629; batch adversarial loss: 0.424960\n",
      "epoch 103; iter: 0; batch classifier loss: 0.139737; batch adversarial loss: 0.454839\n",
      "epoch 104; iter: 0; batch classifier loss: 0.167214; batch adversarial loss: 0.511019\n",
      "epoch 105; iter: 0; batch classifier loss: 0.127351; batch adversarial loss: 0.449122\n",
      "epoch 106; iter: 0; batch classifier loss: 0.156229; batch adversarial loss: 0.383484\n",
      "epoch 107; iter: 0; batch classifier loss: 0.179814; batch adversarial loss: 0.475642\n",
      "epoch 108; iter: 0; batch classifier loss: 0.223005; batch adversarial loss: 0.473117\n",
      "epoch 109; iter: 0; batch classifier loss: 0.150867; batch adversarial loss: 0.558938\n",
      "epoch 110; iter: 0; batch classifier loss: 0.174012; batch adversarial loss: 0.459989\n",
      "epoch 111; iter: 0; batch classifier loss: 0.219522; batch adversarial loss: 0.456773\n",
      "epoch 112; iter: 0; batch classifier loss: 0.149986; batch adversarial loss: 0.516300\n",
      "epoch 113; iter: 0; batch classifier loss: 0.163864; batch adversarial loss: 0.465455\n",
      "epoch 114; iter: 0; batch classifier loss: 0.259144; batch adversarial loss: 0.430032\n",
      "epoch 115; iter: 0; batch classifier loss: 0.204455; batch adversarial loss: 0.491955\n",
      "epoch 116; iter: 0; batch classifier loss: 0.267787; batch adversarial loss: 0.396810\n",
      "epoch 117; iter: 0; batch classifier loss: 0.239864; batch adversarial loss: 0.496987\n",
      "epoch 118; iter: 0; batch classifier loss: 0.279087; batch adversarial loss: 0.391097\n",
      "epoch 119; iter: 0; batch classifier loss: 0.244618; batch adversarial loss: 0.510508\n",
      "epoch 120; iter: 0; batch classifier loss: 0.186791; batch adversarial loss: 0.465354\n",
      "epoch 121; iter: 0; batch classifier loss: 0.195114; batch adversarial loss: 0.554028\n",
      "epoch 122; iter: 0; batch classifier loss: 0.228394; batch adversarial loss: 0.510983\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354427; batch adversarial loss: 0.409851\n",
      "epoch 124; iter: 0; batch classifier loss: 0.315948; batch adversarial loss: 0.541755\n",
      "epoch 125; iter: 0; batch classifier loss: 0.287121; batch adversarial loss: 0.435632\n",
      "epoch 126; iter: 0; batch classifier loss: 0.300950; batch adversarial loss: 0.412175\n",
      "epoch 127; iter: 0; batch classifier loss: 0.300081; batch adversarial loss: 0.446768\n",
      "epoch 128; iter: 0; batch classifier loss: 0.282946; batch adversarial loss: 0.435979\n",
      "epoch 129; iter: 0; batch classifier loss: 0.140366; batch adversarial loss: 0.411265\n",
      "epoch 130; iter: 0; batch classifier loss: 0.165650; batch adversarial loss: 0.459906\n",
      "epoch 131; iter: 0; batch classifier loss: 0.219496; batch adversarial loss: 0.435526\n",
      "epoch 132; iter: 0; batch classifier loss: 0.248390; batch adversarial loss: 0.482821\n",
      "epoch 133; iter: 0; batch classifier loss: 0.183193; batch adversarial loss: 0.482735\n",
      "epoch 134; iter: 0; batch classifier loss: 0.207437; batch adversarial loss: 0.458740\n",
      "epoch 135; iter: 0; batch classifier loss: 0.272142; batch adversarial loss: 0.410178\n",
      "epoch 136; iter: 0; batch classifier loss: 0.226468; batch adversarial loss: 0.434321\n",
      "epoch 137; iter: 0; batch classifier loss: 0.120729; batch adversarial loss: 0.496418\n",
      "epoch 138; iter: 0; batch classifier loss: 0.236533; batch adversarial loss: 0.531023\n",
      "epoch 139; iter: 0; batch classifier loss: 0.211304; batch adversarial loss: 0.445391\n",
      "epoch 140; iter: 0; batch classifier loss: 0.282517; batch adversarial loss: 0.434965\n",
      "epoch 141; iter: 0; batch classifier loss: 0.228514; batch adversarial loss: 0.507125\n",
      "epoch 142; iter: 0; batch classifier loss: 0.215423; batch adversarial loss: 0.495856\n",
      "epoch 143; iter: 0; batch classifier loss: 0.281357; batch adversarial loss: 0.508110\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354538; batch adversarial loss: 0.374565\n",
      "epoch 145; iter: 0; batch classifier loss: 0.267180; batch adversarial loss: 0.542949\n",
      "epoch 146; iter: 0; batch classifier loss: 0.171185; batch adversarial loss: 0.458859\n",
      "epoch 147; iter: 0; batch classifier loss: 0.108276; batch adversarial loss: 0.481303\n",
      "epoch 148; iter: 0; batch classifier loss: 0.072119; batch adversarial loss: 0.506525\n",
      "epoch 149; iter: 0; batch classifier loss: 0.106778; batch adversarial loss: 0.496861\n",
      "epoch 150; iter: 0; batch classifier loss: 0.196901; batch adversarial loss: 0.472055\n",
      "epoch 151; iter: 0; batch classifier loss: 0.276674; batch adversarial loss: 0.503112\n",
      "epoch 152; iter: 0; batch classifier loss: 0.254945; batch adversarial loss: 0.506391\n",
      "epoch 153; iter: 0; batch classifier loss: 0.280022; batch adversarial loss: 0.518508\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350451; batch adversarial loss: 0.493750\n",
      "epoch 155; iter: 0; batch classifier loss: 0.245320; batch adversarial loss: 0.410836\n",
      "epoch 156; iter: 0; batch classifier loss: 0.284163; batch adversarial loss: 0.568733\n",
      "epoch 157; iter: 0; batch classifier loss: 0.247132; batch adversarial loss: 0.409676\n",
      "epoch 158; iter: 0; batch classifier loss: 0.223698; batch adversarial loss: 0.459883\n",
      "epoch 159; iter: 0; batch classifier loss: 0.289316; batch adversarial loss: 0.482510\n",
      "epoch 160; iter: 0; batch classifier loss: 0.226304; batch adversarial loss: 0.495950\n",
      "epoch 161; iter: 0; batch classifier loss: 0.261223; batch adversarial loss: 0.482652\n",
      "epoch 162; iter: 0; batch classifier loss: 0.288155; batch adversarial loss: 0.458935\n",
      "epoch 163; iter: 0; batch classifier loss: 0.142940; batch adversarial loss: 0.590883\n",
      "epoch 164; iter: 0; batch classifier loss: 0.129324; batch adversarial loss: 0.555026\n",
      "epoch 165; iter: 0; batch classifier loss: 0.078059; batch adversarial loss: 0.433232\n",
      "epoch 166; iter: 0; batch classifier loss: 0.092214; batch adversarial loss: 0.493219\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042004; batch adversarial loss: 0.501824\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045681; batch adversarial loss: 0.431987\n",
      "epoch 169; iter: 0; batch classifier loss: 0.056151; batch adversarial loss: 0.355801\n",
      "epoch 170; iter: 0; batch classifier loss: 0.054812; batch adversarial loss: 0.398971\n",
      "epoch 171; iter: 0; batch classifier loss: 0.042204; batch adversarial loss: 0.437553\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033818; batch adversarial loss: 0.519159\n",
      "epoch 173; iter: 0; batch classifier loss: 0.084917; batch adversarial loss: 0.375509\n",
      "epoch 174; iter: 0; batch classifier loss: 0.072093; batch adversarial loss: 0.466206\n",
      "epoch 175; iter: 0; batch classifier loss: 0.110714; batch adversarial loss: 0.428686\n",
      "epoch 176; iter: 0; batch classifier loss: 0.060802; batch adversarial loss: 0.361850\n",
      "epoch 177; iter: 0; batch classifier loss: 0.041094; batch adversarial loss: 0.446177\n",
      "epoch 178; iter: 0; batch classifier loss: 0.048813; batch adversarial loss: 0.405578\n",
      "epoch 179; iter: 0; batch classifier loss: 0.084411; batch adversarial loss: 0.396381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.044183; batch adversarial loss: 0.442734\n",
      "epoch 181; iter: 0; batch classifier loss: 0.057652; batch adversarial loss: 0.350640\n",
      "epoch 182; iter: 0; batch classifier loss: 0.055671; batch adversarial loss: 0.411133\n",
      "epoch 183; iter: 0; batch classifier loss: 0.051380; batch adversarial loss: 0.466035\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027264; batch adversarial loss: 0.422124\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024509; batch adversarial loss: 0.446486\n",
      "epoch 186; iter: 0; batch classifier loss: 0.038231; batch adversarial loss: 0.390627\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027217; batch adversarial loss: 0.576199\n",
      "epoch 188; iter: 0; batch classifier loss: 0.046292; batch adversarial loss: 0.384648\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031905; batch adversarial loss: 0.390945\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034681; batch adversarial loss: 0.476507\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027141; batch adversarial loss: 0.456935\n",
      "epoch 192; iter: 0; batch classifier loss: 0.042251; batch adversarial loss: 0.423333\n",
      "epoch 193; iter: 0; batch classifier loss: 0.043735; batch adversarial loss: 0.403956\n",
      "epoch 194; iter: 0; batch classifier loss: 0.070578; batch adversarial loss: 0.385471\n",
      "epoch 195; iter: 0; batch classifier loss: 0.042024; batch adversarial loss: 0.400884\n",
      "epoch 196; iter: 0; batch classifier loss: 0.046760; batch adversarial loss: 0.411504\n",
      "epoch 197; iter: 0; batch classifier loss: 0.044336; batch adversarial loss: 0.427053\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037416; batch adversarial loss: 0.343322\n",
      "epoch 199; iter: 0; batch classifier loss: 0.076762; batch adversarial loss: 0.412602\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714978; batch adversarial loss: 0.906230\n",
      "epoch 1; iter: 0; batch classifier loss: 0.430481; batch adversarial loss: 0.916195\n",
      "epoch 2; iter: 0; batch classifier loss: 0.476650; batch adversarial loss: 0.905025\n",
      "epoch 3; iter: 0; batch classifier loss: 0.531620; batch adversarial loss: 0.822307\n",
      "epoch 4; iter: 0; batch classifier loss: 0.542835; batch adversarial loss: 0.778265\n",
      "epoch 5; iter: 0; batch classifier loss: 0.464984; batch adversarial loss: 0.691797\n",
      "epoch 6; iter: 0; batch classifier loss: 0.291598; batch adversarial loss: 0.655563\n",
      "epoch 7; iter: 0; batch classifier loss: 0.318519; batch adversarial loss: 0.604463\n",
      "epoch 8; iter: 0; batch classifier loss: 0.314908; batch adversarial loss: 0.597514\n",
      "epoch 9; iter: 0; batch classifier loss: 0.313262; batch adversarial loss: 0.546857\n",
      "epoch 10; iter: 0; batch classifier loss: 0.347394; batch adversarial loss: 0.557552\n",
      "epoch 11; iter: 0; batch classifier loss: 0.264669; batch adversarial loss: 0.528467\n",
      "epoch 12; iter: 0; batch classifier loss: 0.177982; batch adversarial loss: 0.539019\n",
      "epoch 13; iter: 0; batch classifier loss: 0.263632; batch adversarial loss: 0.505231\n",
      "epoch 14; iter: 0; batch classifier loss: 0.249430; batch adversarial loss: 0.484359\n",
      "epoch 15; iter: 0; batch classifier loss: 0.243419; batch adversarial loss: 0.497793\n",
      "epoch 16; iter: 0; batch classifier loss: 0.326406; batch adversarial loss: 0.535899\n",
      "epoch 17; iter: 0; batch classifier loss: 0.257140; batch adversarial loss: 0.496207\n",
      "epoch 18; iter: 0; batch classifier loss: 0.178370; batch adversarial loss: 0.485691\n",
      "epoch 19; iter: 0; batch classifier loss: 0.214169; batch adversarial loss: 0.434572\n",
      "epoch 20; iter: 0; batch classifier loss: 0.174784; batch adversarial loss: 0.474932\n",
      "epoch 21; iter: 0; batch classifier loss: 0.136272; batch adversarial loss: 0.481580\n",
      "epoch 22; iter: 0; batch classifier loss: 0.151613; batch adversarial loss: 0.423623\n",
      "epoch 23; iter: 0; batch classifier loss: 0.143253; batch adversarial loss: 0.441308\n",
      "epoch 24; iter: 0; batch classifier loss: 0.187084; batch adversarial loss: 0.458412\n",
      "epoch 25; iter: 0; batch classifier loss: 0.152206; batch adversarial loss: 0.412921\n",
      "epoch 26; iter: 0; batch classifier loss: 0.145955; batch adversarial loss: 0.395051\n",
      "epoch 27; iter: 0; batch classifier loss: 0.163221; batch adversarial loss: 0.439907\n",
      "epoch 28; iter: 0; batch classifier loss: 0.186937; batch adversarial loss: 0.464392\n",
      "epoch 29; iter: 0; batch classifier loss: 0.119357; batch adversarial loss: 0.421779\n",
      "epoch 30; iter: 0; batch classifier loss: 0.122889; batch adversarial loss: 0.490437\n",
      "epoch 31; iter: 0; batch classifier loss: 0.122997; batch adversarial loss: 0.449085\n",
      "epoch 32; iter: 0; batch classifier loss: 0.150184; batch adversarial loss: 0.471507\n",
      "epoch 33; iter: 0; batch classifier loss: 0.064845; batch adversarial loss: 0.457855\n",
      "epoch 34; iter: 0; batch classifier loss: 0.081433; batch adversarial loss: 0.427745\n",
      "epoch 35; iter: 0; batch classifier loss: 0.121493; batch adversarial loss: 0.402383\n",
      "epoch 36; iter: 0; batch classifier loss: 0.101446; batch adversarial loss: 0.505644\n",
      "epoch 37; iter: 0; batch classifier loss: 0.103996; batch adversarial loss: 0.447685\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117393; batch adversarial loss: 0.500442\n",
      "epoch 39; iter: 0; batch classifier loss: 0.115895; batch adversarial loss: 0.385847\n",
      "epoch 40; iter: 0; batch classifier loss: 0.082837; batch adversarial loss: 0.442666\n",
      "epoch 41; iter: 0; batch classifier loss: 0.083065; batch adversarial loss: 0.449048\n",
      "epoch 42; iter: 0; batch classifier loss: 0.111790; batch adversarial loss: 0.422256\n",
      "epoch 43; iter: 0; batch classifier loss: 0.079891; batch adversarial loss: 0.367863\n",
      "epoch 44; iter: 0; batch classifier loss: 0.093493; batch adversarial loss: 0.445888\n",
      "epoch 45; iter: 0; batch classifier loss: 0.046647; batch adversarial loss: 0.442691\n",
      "epoch 46; iter: 0; batch classifier loss: 0.084274; batch adversarial loss: 0.456707\n",
      "epoch 47; iter: 0; batch classifier loss: 0.118073; batch adversarial loss: 0.428689\n",
      "epoch 48; iter: 0; batch classifier loss: 0.097206; batch adversarial loss: 0.349750\n",
      "epoch 49; iter: 0; batch classifier loss: 0.153829; batch adversarial loss: 0.518408\n",
      "epoch 50; iter: 0; batch classifier loss: 0.049487; batch adversarial loss: 0.370620\n",
      "epoch 51; iter: 0; batch classifier loss: 0.103042; batch adversarial loss: 0.423568\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112363; batch adversarial loss: 0.480551\n",
      "epoch 53; iter: 0; batch classifier loss: 0.064137; batch adversarial loss: 0.462277\n",
      "epoch 54; iter: 0; batch classifier loss: 0.060339; batch adversarial loss: 0.392569\n",
      "epoch 55; iter: 0; batch classifier loss: 0.109084; batch adversarial loss: 0.473629\n",
      "epoch 56; iter: 0; batch classifier loss: 0.059734; batch adversarial loss: 0.375437\n",
      "epoch 57; iter: 0; batch classifier loss: 0.096172; batch adversarial loss: 0.477386\n",
      "epoch 58; iter: 0; batch classifier loss: 0.094344; batch adversarial loss: 0.494436\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067307; batch adversarial loss: 0.493999\n",
      "epoch 60; iter: 0; batch classifier loss: 0.099708; batch adversarial loss: 0.404258\n",
      "epoch 61; iter: 0; batch classifier loss: 0.077609; batch adversarial loss: 0.395673\n",
      "epoch 62; iter: 0; batch classifier loss: 0.060054; batch adversarial loss: 0.483195\n",
      "epoch 63; iter: 0; batch classifier loss: 0.100341; batch adversarial loss: 0.471223\n",
      "epoch 64; iter: 0; batch classifier loss: 0.140493; batch adversarial loss: 0.451402\n",
      "epoch 65; iter: 0; batch classifier loss: 0.109536; batch adversarial loss: 0.469732\n",
      "epoch 66; iter: 0; batch classifier loss: 0.087705; batch adversarial loss: 0.395276\n",
      "epoch 67; iter: 0; batch classifier loss: 0.045229; batch adversarial loss: 0.395659\n",
      "epoch 68; iter: 0; batch classifier loss: 0.068675; batch adversarial loss: 0.404139\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094651; batch adversarial loss: 0.408452\n",
      "epoch 70; iter: 0; batch classifier loss: 0.098397; batch adversarial loss: 0.524707\n",
      "epoch 71; iter: 0; batch classifier loss: 0.113781; batch adversarial loss: 0.362175\n",
      "epoch 72; iter: 0; batch classifier loss: 0.095838; batch adversarial loss: 0.397537\n",
      "epoch 73; iter: 0; batch classifier loss: 0.112941; batch adversarial loss: 0.505691\n",
      "epoch 74; iter: 0; batch classifier loss: 0.072066; batch adversarial loss: 0.489304\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067014; batch adversarial loss: 0.491826\n",
      "epoch 76; iter: 0; batch classifier loss: 0.046197; batch adversarial loss: 0.426413\n",
      "epoch 77; iter: 0; batch classifier loss: 0.058316; batch adversarial loss: 0.458098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.102342; batch adversarial loss: 0.448702\n",
      "epoch 79; iter: 0; batch classifier loss: 0.039733; batch adversarial loss: 0.406307\n",
      "epoch 80; iter: 0; batch classifier loss: 0.087745; batch adversarial loss: 0.450930\n",
      "epoch 81; iter: 0; batch classifier loss: 0.090862; batch adversarial loss: 0.531450\n",
      "epoch 82; iter: 0; batch classifier loss: 0.093848; batch adversarial loss: 0.408609\n",
      "epoch 83; iter: 0; batch classifier loss: 0.094190; batch adversarial loss: 0.504229\n",
      "epoch 84; iter: 0; batch classifier loss: 0.050065; batch adversarial loss: 0.365964\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068354; batch adversarial loss: 0.382988\n",
      "epoch 86; iter: 0; batch classifier loss: 0.075965; batch adversarial loss: 0.441893\n",
      "epoch 87; iter: 0; batch classifier loss: 0.045132; batch adversarial loss: 0.414213\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059888; batch adversarial loss: 0.417872\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059834; batch adversarial loss: 0.491079\n",
      "epoch 90; iter: 0; batch classifier loss: 0.086795; batch adversarial loss: 0.477410\n",
      "epoch 91; iter: 0; batch classifier loss: 0.041237; batch adversarial loss: 0.498235\n",
      "epoch 92; iter: 0; batch classifier loss: 0.081689; batch adversarial loss: 0.411736\n",
      "epoch 93; iter: 0; batch classifier loss: 0.060882; batch adversarial loss: 0.393623\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058619; batch adversarial loss: 0.439779\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054441; batch adversarial loss: 0.462134\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068391; batch adversarial loss: 0.487914\n",
      "epoch 97; iter: 0; batch classifier loss: 0.092999; batch adversarial loss: 0.406146\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055624; batch adversarial loss: 0.375750\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063767; batch adversarial loss: 0.513424\n",
      "epoch 100; iter: 0; batch classifier loss: 0.069195; batch adversarial loss: 0.396734\n",
      "epoch 101; iter: 0; batch classifier loss: 0.038260; batch adversarial loss: 0.520567\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052824; batch adversarial loss: 0.408936\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062091; batch adversarial loss: 0.526377\n",
      "epoch 104; iter: 0; batch classifier loss: 0.090950; batch adversarial loss: 0.455313\n",
      "epoch 105; iter: 0; batch classifier loss: 0.065509; batch adversarial loss: 0.416229\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044667; batch adversarial loss: 0.400203\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052253; batch adversarial loss: 0.468418\n",
      "epoch 108; iter: 0; batch classifier loss: 0.062682; batch adversarial loss: 0.410066\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048830; batch adversarial loss: 0.466832\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044671; batch adversarial loss: 0.512183\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059631; batch adversarial loss: 0.418105\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051854; batch adversarial loss: 0.542060\n",
      "epoch 113; iter: 0; batch classifier loss: 0.068170; batch adversarial loss: 0.526400\n",
      "epoch 114; iter: 0; batch classifier loss: 0.086811; batch adversarial loss: 0.495786\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062824; batch adversarial loss: 0.468909\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028252; batch adversarial loss: 0.414945\n",
      "epoch 117; iter: 0; batch classifier loss: 0.058546; batch adversarial loss: 0.363188\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052494; batch adversarial loss: 0.383804\n",
      "epoch 119; iter: 0; batch classifier loss: 0.085754; batch adversarial loss: 0.343860\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053234; batch adversarial loss: 0.462695\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060713; batch adversarial loss: 0.486375\n",
      "epoch 122; iter: 0; batch classifier loss: 0.058427; batch adversarial loss: 0.486152\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032315; batch adversarial loss: 0.334012\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055031; batch adversarial loss: 0.534378\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057956; batch adversarial loss: 0.408779\n",
      "epoch 126; iter: 0; batch classifier loss: 0.070573; batch adversarial loss: 0.355415\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050295; batch adversarial loss: 0.448592\n",
      "epoch 128; iter: 0; batch classifier loss: 0.072326; batch adversarial loss: 0.476302\n",
      "epoch 129; iter: 0; batch classifier loss: 0.068882; batch adversarial loss: 0.385523\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045841; batch adversarial loss: 0.369306\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039757; batch adversarial loss: 0.392508\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034975; batch adversarial loss: 0.376612\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039346; batch adversarial loss: 0.398449\n",
      "epoch 134; iter: 0; batch classifier loss: 0.054730; batch adversarial loss: 0.443090\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050529; batch adversarial loss: 0.390334\n",
      "epoch 136; iter: 0; batch classifier loss: 0.071116; batch adversarial loss: 0.394324\n",
      "epoch 137; iter: 0; batch classifier loss: 0.053857; batch adversarial loss: 0.443021\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037113; batch adversarial loss: 0.408703\n",
      "epoch 139; iter: 0; batch classifier loss: 0.078418; batch adversarial loss: 0.484590\n",
      "epoch 140; iter: 0; batch classifier loss: 0.075785; batch adversarial loss: 0.561463\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048426; batch adversarial loss: 0.422026\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045430; batch adversarial loss: 0.395288\n",
      "epoch 143; iter: 0; batch classifier loss: 0.076340; batch adversarial loss: 0.429128\n",
      "epoch 144; iter: 0; batch classifier loss: 0.044337; batch adversarial loss: 0.421957\n",
      "epoch 145; iter: 0; batch classifier loss: 0.071089; batch adversarial loss: 0.465382\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045168; batch adversarial loss: 0.440293\n",
      "epoch 147; iter: 0; batch classifier loss: 0.101452; batch adversarial loss: 0.412151\n",
      "epoch 148; iter: 0; batch classifier loss: 0.095132; batch adversarial loss: 0.512794\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034321; batch adversarial loss: 0.409678\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036583; batch adversarial loss: 0.385356\n",
      "epoch 151; iter: 0; batch classifier loss: 0.049564; batch adversarial loss: 0.433559\n",
      "epoch 152; iter: 0; batch classifier loss: 0.073675; batch adversarial loss: 0.493333\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034658; batch adversarial loss: 0.385829\n",
      "epoch 154; iter: 0; batch classifier loss: 0.055873; batch adversarial loss: 0.499803\n",
      "epoch 155; iter: 0; batch classifier loss: 0.059545; batch adversarial loss: 0.347947\n",
      "epoch 156; iter: 0; batch classifier loss: 0.048707; batch adversarial loss: 0.440275\n",
      "epoch 157; iter: 0; batch classifier loss: 0.082363; batch adversarial loss: 0.413444\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034901; batch adversarial loss: 0.409672\n",
      "epoch 159; iter: 0; batch classifier loss: 0.054061; batch adversarial loss: 0.394479\n",
      "epoch 160; iter: 0; batch classifier loss: 0.062913; batch adversarial loss: 0.455310\n",
      "epoch 161; iter: 0; batch classifier loss: 0.056558; batch adversarial loss: 0.443892\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033921; batch adversarial loss: 0.403265\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039117; batch adversarial loss: 0.399476\n",
      "epoch 164; iter: 0; batch classifier loss: 0.063119; batch adversarial loss: 0.372927\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032210; batch adversarial loss: 0.359703\n",
      "epoch 166; iter: 0; batch classifier loss: 0.042850; batch adversarial loss: 0.470442\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034348; batch adversarial loss: 0.457918\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040594; batch adversarial loss: 0.385659\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035515; batch adversarial loss: 0.364995\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033363; batch adversarial loss: 0.445945\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036332; batch adversarial loss: 0.463103\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018650; batch adversarial loss: 0.501819\n",
      "epoch 173; iter: 0; batch classifier loss: 0.058668; batch adversarial loss: 0.413461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.043297; batch adversarial loss: 0.431777\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027277; batch adversarial loss: 0.394440\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035076; batch adversarial loss: 0.506537\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031712; batch adversarial loss: 0.382423\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037135; batch adversarial loss: 0.370302\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038522; batch adversarial loss: 0.403628\n",
      "epoch 180; iter: 0; batch classifier loss: 0.043012; batch adversarial loss: 0.469411\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026666; batch adversarial loss: 0.489477\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029705; batch adversarial loss: 0.340457\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030775; batch adversarial loss: 0.477886\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023518; batch adversarial loss: 0.546888\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026031; batch adversarial loss: 0.434680\n",
      "epoch 186; iter: 0; batch classifier loss: 0.038234; batch adversarial loss: 0.451693\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024666; batch adversarial loss: 0.435262\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035620; batch adversarial loss: 0.486182\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026508; batch adversarial loss: 0.480157\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027255; batch adversarial loss: 0.530217\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015547; batch adversarial loss: 0.506046\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009124; batch adversarial loss: 0.409390\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023102; batch adversarial loss: 0.609304\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010619; batch adversarial loss: 0.486995\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030303; batch adversarial loss: 0.495156\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023372; batch adversarial loss: 0.502322\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032469; batch adversarial loss: 0.462581\n",
      "epoch 198; iter: 0; batch classifier loss: 0.034707; batch adversarial loss: 0.494610\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016997; batch adversarial loss: 0.383745\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712575; batch adversarial loss: 0.703986\n",
      "epoch 1; iter: 0; batch classifier loss: 0.460986; batch adversarial loss: 0.686174\n",
      "epoch 2; iter: 0; batch classifier loss: 0.445557; batch adversarial loss: 0.639102\n",
      "epoch 3; iter: 0; batch classifier loss: 0.329106; batch adversarial loss: 0.601928\n",
      "epoch 4; iter: 0; batch classifier loss: 0.264886; batch adversarial loss: 0.581063\n",
      "epoch 5; iter: 0; batch classifier loss: 0.281278; batch adversarial loss: 0.555006\n",
      "epoch 6; iter: 0; batch classifier loss: 0.278380; batch adversarial loss: 0.505986\n",
      "epoch 7; iter: 0; batch classifier loss: 0.333725; batch adversarial loss: 0.502931\n",
      "epoch 8; iter: 0; batch classifier loss: 0.304679; batch adversarial loss: 0.496044\n",
      "epoch 9; iter: 0; batch classifier loss: 0.278258; batch adversarial loss: 0.481193\n",
      "epoch 10; iter: 0; batch classifier loss: 0.232112; batch adversarial loss: 0.526587\n",
      "epoch 11; iter: 0; batch classifier loss: 0.214825; batch adversarial loss: 0.428849\n",
      "epoch 12; iter: 0; batch classifier loss: 0.189129; batch adversarial loss: 0.432211\n",
      "epoch 13; iter: 0; batch classifier loss: 0.207831; batch adversarial loss: 0.464950\n",
      "epoch 14; iter: 0; batch classifier loss: 0.192817; batch adversarial loss: 0.466152\n",
      "epoch 15; iter: 0; batch classifier loss: 0.159481; batch adversarial loss: 0.482937\n",
      "epoch 16; iter: 0; batch classifier loss: 0.159642; batch adversarial loss: 0.516831\n",
      "epoch 17; iter: 0; batch classifier loss: 0.129639; batch adversarial loss: 0.520573\n",
      "epoch 18; iter: 0; batch classifier loss: 0.165278; batch adversarial loss: 0.429612\n",
      "epoch 19; iter: 0; batch classifier loss: 0.157852; batch adversarial loss: 0.475960\n",
      "epoch 20; iter: 0; batch classifier loss: 0.174260; batch adversarial loss: 0.486948\n",
      "epoch 21; iter: 0; batch classifier loss: 0.173423; batch adversarial loss: 0.518759\n",
      "epoch 22; iter: 0; batch classifier loss: 0.173062; batch adversarial loss: 0.501888\n",
      "epoch 23; iter: 0; batch classifier loss: 0.158616; batch adversarial loss: 0.493238\n",
      "epoch 24; iter: 0; batch classifier loss: 0.179544; batch adversarial loss: 0.601585\n",
      "epoch 25; iter: 0; batch classifier loss: 0.175134; batch adversarial loss: 0.514833\n",
      "epoch 26; iter: 0; batch classifier loss: 0.145265; batch adversarial loss: 0.457381\n",
      "epoch 27; iter: 0; batch classifier loss: 0.205873; batch adversarial loss: 0.479176\n",
      "epoch 28; iter: 0; batch classifier loss: 0.270290; batch adversarial loss: 0.505097\n",
      "epoch 29; iter: 0; batch classifier loss: 0.245107; batch adversarial loss: 0.505221\n",
      "epoch 30; iter: 0; batch classifier loss: 0.343903; batch adversarial loss: 0.548669\n",
      "epoch 31; iter: 0; batch classifier loss: 0.197491; batch adversarial loss: 0.440656\n",
      "epoch 32; iter: 0; batch classifier loss: 0.150653; batch adversarial loss: 0.463910\n",
      "epoch 33; iter: 0; batch classifier loss: 0.148479; batch adversarial loss: 0.462961\n",
      "epoch 34; iter: 0; batch classifier loss: 0.114690; batch adversarial loss: 0.440463\n",
      "epoch 35; iter: 0; batch classifier loss: 0.113160; batch adversarial loss: 0.437989\n",
      "epoch 36; iter: 0; batch classifier loss: 0.099566; batch adversarial loss: 0.540693\n",
      "epoch 37; iter: 0; batch classifier loss: 0.090677; batch adversarial loss: 0.474688\n",
      "epoch 38; iter: 0; batch classifier loss: 0.084569; batch adversarial loss: 0.438493\n",
      "epoch 39; iter: 0; batch classifier loss: 0.102395; batch adversarial loss: 0.458833\n",
      "epoch 40; iter: 0; batch classifier loss: 0.087408; batch adversarial loss: 0.421878\n",
      "epoch 41; iter: 0; batch classifier loss: 0.104336; batch adversarial loss: 0.365056\n",
      "epoch 42; iter: 0; batch classifier loss: 0.150216; batch adversarial loss: 0.479617\n",
      "epoch 43; iter: 0; batch classifier loss: 0.082703; batch adversarial loss: 0.379534\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101118; batch adversarial loss: 0.456054\n",
      "epoch 45; iter: 0; batch classifier loss: 0.076551; batch adversarial loss: 0.472957\n",
      "epoch 46; iter: 0; batch classifier loss: 0.049311; batch adversarial loss: 0.439317\n",
      "epoch 47; iter: 0; batch classifier loss: 0.072779; batch adversarial loss: 0.532194\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081873; batch adversarial loss: 0.462235\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074433; batch adversarial loss: 0.437810\n",
      "epoch 50; iter: 0; batch classifier loss: 0.068764; batch adversarial loss: 0.494498\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073977; batch adversarial loss: 0.412613\n",
      "epoch 52; iter: 0; batch classifier loss: 0.061665; batch adversarial loss: 0.468245\n",
      "epoch 53; iter: 0; batch classifier loss: 0.068286; batch adversarial loss: 0.531956\n",
      "epoch 54; iter: 0; batch classifier loss: 0.050253; batch adversarial loss: 0.470619\n",
      "epoch 55; iter: 0; batch classifier loss: 0.052368; batch adversarial loss: 0.458776\n",
      "epoch 56; iter: 0; batch classifier loss: 0.069965; batch adversarial loss: 0.507818\n",
      "epoch 57; iter: 0; batch classifier loss: 0.083633; batch adversarial loss: 0.566235\n",
      "epoch 58; iter: 0; batch classifier loss: 0.056680; batch adversarial loss: 0.425962\n",
      "epoch 59; iter: 0; batch classifier loss: 0.040580; batch adversarial loss: 0.458410\n",
      "epoch 60; iter: 0; batch classifier loss: 0.059117; batch adversarial loss: 0.444411\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103018; batch adversarial loss: 0.466594\n",
      "epoch 62; iter: 0; batch classifier loss: 0.031980; batch adversarial loss: 0.541567\n",
      "epoch 63; iter: 0; batch classifier loss: 0.115395; batch adversarial loss: 0.376313\n",
      "epoch 64; iter: 0; batch classifier loss: 0.066326; batch adversarial loss: 0.527897\n",
      "epoch 65; iter: 0; batch classifier loss: 0.021380; batch adversarial loss: 0.494425\n",
      "epoch 66; iter: 0; batch classifier loss: 0.041802; batch adversarial loss: 0.460107\n",
      "epoch 67; iter: 0; batch classifier loss: 0.072228; batch adversarial loss: 0.482989\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060086; batch adversarial loss: 0.438879\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064516; batch adversarial loss: 0.466466\n",
      "epoch 70; iter: 0; batch classifier loss: 0.064731; batch adversarial loss: 0.446503\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058517; batch adversarial loss: 0.486622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.051127; batch adversarial loss: 0.485633\n",
      "epoch 73; iter: 0; batch classifier loss: 0.060131; batch adversarial loss: 0.507269\n",
      "epoch 74; iter: 0; batch classifier loss: 0.078965; batch adversarial loss: 0.452240\n",
      "epoch 75; iter: 0; batch classifier loss: 0.053855; batch adversarial loss: 0.532113\n",
      "epoch 76; iter: 0; batch classifier loss: 0.043964; batch adversarial loss: 0.536656\n",
      "epoch 77; iter: 0; batch classifier loss: 0.071677; batch adversarial loss: 0.464254\n",
      "epoch 78; iter: 0; batch classifier loss: 0.068989; batch adversarial loss: 0.489013\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064487; batch adversarial loss: 0.489522\n",
      "epoch 80; iter: 0; batch classifier loss: 0.069395; batch adversarial loss: 0.416505\n",
      "epoch 81; iter: 0; batch classifier loss: 0.048341; batch adversarial loss: 0.402870\n",
      "epoch 82; iter: 0; batch classifier loss: 0.054909; batch adversarial loss: 0.481827\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064606; batch adversarial loss: 0.529542\n",
      "epoch 84; iter: 0; batch classifier loss: 0.077785; batch adversarial loss: 0.465980\n",
      "epoch 85; iter: 0; batch classifier loss: 0.093979; batch adversarial loss: 0.426215\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046057; batch adversarial loss: 0.465113\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047854; batch adversarial loss: 0.455106\n",
      "epoch 88; iter: 0; batch classifier loss: 0.035364; batch adversarial loss: 0.493753\n",
      "epoch 89; iter: 0; batch classifier loss: 0.041450; batch adversarial loss: 0.472412\n",
      "epoch 90; iter: 0; batch classifier loss: 0.085724; batch adversarial loss: 0.505201\n",
      "epoch 91; iter: 0; batch classifier loss: 0.071190; batch adversarial loss: 0.388532\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077490; batch adversarial loss: 0.449870\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062075; batch adversarial loss: 0.406722\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038388; batch adversarial loss: 0.482744\n",
      "epoch 95; iter: 0; batch classifier loss: 0.043929; batch adversarial loss: 0.444551\n",
      "epoch 96; iter: 0; batch classifier loss: 0.050472; batch adversarial loss: 0.489338\n",
      "epoch 97; iter: 0; batch classifier loss: 0.019490; batch adversarial loss: 0.460519\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045103; batch adversarial loss: 0.474452\n",
      "epoch 99; iter: 0; batch classifier loss: 0.048677; batch adversarial loss: 0.479830\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044617; batch adversarial loss: 0.424341\n",
      "epoch 101; iter: 0; batch classifier loss: 0.030905; batch adversarial loss: 0.453976\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029890; batch adversarial loss: 0.546294\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035870; batch adversarial loss: 0.432820\n",
      "epoch 104; iter: 0; batch classifier loss: 0.073578; batch adversarial loss: 0.447971\n",
      "epoch 105; iter: 0; batch classifier loss: 0.020564; batch adversarial loss: 0.414539\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044646; batch adversarial loss: 0.470450\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024112; batch adversarial loss: 0.613005\n",
      "epoch 108; iter: 0; batch classifier loss: 0.029299; batch adversarial loss: 0.464468\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036075; batch adversarial loss: 0.465237\n",
      "epoch 110; iter: 0; batch classifier loss: 0.017357; batch adversarial loss: 0.418177\n",
      "epoch 111; iter: 0; batch classifier loss: 0.027429; batch adversarial loss: 0.418440\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055029; batch adversarial loss: 0.462835\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039157; batch adversarial loss: 0.500069\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032602; batch adversarial loss: 0.443329\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065125; batch adversarial loss: 0.432882\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046367; batch adversarial loss: 0.460503\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034831; batch adversarial loss: 0.418634\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049338; batch adversarial loss: 0.440282\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023622; batch adversarial loss: 0.463466\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048655; batch adversarial loss: 0.482814\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044462; batch adversarial loss: 0.476211\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039615; batch adversarial loss: 0.408160\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047321; batch adversarial loss: 0.459935\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025058; batch adversarial loss: 0.432407\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027507; batch adversarial loss: 0.519631\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050064; batch adversarial loss: 0.483813\n",
      "epoch 127; iter: 0; batch classifier loss: 0.017115; batch adversarial loss: 0.475511\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027644; batch adversarial loss: 0.424484\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027077; batch adversarial loss: 0.426299\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034921; batch adversarial loss: 0.432616\n",
      "epoch 131; iter: 0; batch classifier loss: 0.008334; batch adversarial loss: 0.519520\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016339; batch adversarial loss: 0.459996\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033253; batch adversarial loss: 0.468067\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029747; batch adversarial loss: 0.404810\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030608; batch adversarial loss: 0.428314\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032050; batch adversarial loss: 0.523509\n",
      "epoch 137; iter: 0; batch classifier loss: 0.010027; batch adversarial loss: 0.472428\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021128; batch adversarial loss: 0.407630\n",
      "epoch 139; iter: 0; batch classifier loss: 0.012342; batch adversarial loss: 0.490602\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023116; batch adversarial loss: 0.449578\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021123; batch adversarial loss: 0.545783\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020551; batch adversarial loss: 0.483763\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013850; batch adversarial loss: 0.500509\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052164; batch adversarial loss: 0.425191\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012297; batch adversarial loss: 0.450017\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010552; batch adversarial loss: 0.532217\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019342; batch adversarial loss: 0.484553\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030179; batch adversarial loss: 0.446880\n",
      "epoch 149; iter: 0; batch classifier loss: 0.049071; batch adversarial loss: 0.453502\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036923; batch adversarial loss: 0.495800\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026923; batch adversarial loss: 0.337854\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023912; batch adversarial loss: 0.433827\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038932; batch adversarial loss: 0.551211\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012787; batch adversarial loss: 0.455666\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021990; batch adversarial loss: 0.450884\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019147; batch adversarial loss: 0.548511\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031626; batch adversarial loss: 0.375511\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017752; batch adversarial loss: 0.420783\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025207; batch adversarial loss: 0.519529\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035499; batch adversarial loss: 0.360860\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014859; batch adversarial loss: 0.448339\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032651; batch adversarial loss: 0.394150\n",
      "epoch 163; iter: 0; batch classifier loss: 0.057403; batch adversarial loss: 0.473676\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012399; batch adversarial loss: 0.449891\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028050; batch adversarial loss: 0.418058\n",
      "epoch 166; iter: 0; batch classifier loss: 0.055668; batch adversarial loss: 0.333799\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025512; batch adversarial loss: 0.441985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.042139; batch adversarial loss: 0.424581\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037253; batch adversarial loss: 0.369089\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011925; batch adversarial loss: 0.427828\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018083; batch adversarial loss: 0.446988\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009518; batch adversarial loss: 0.431964\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015136; batch adversarial loss: 0.535431\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011398; batch adversarial loss: 0.420165\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013110; batch adversarial loss: 0.385090\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012108; batch adversarial loss: 0.459401\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018519; batch adversarial loss: 0.536182\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032568; batch adversarial loss: 0.478317\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006243; batch adversarial loss: 0.429557\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009705; batch adversarial loss: 0.436406\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027954; batch adversarial loss: 0.493940\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007155; batch adversarial loss: 0.421551\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027786; batch adversarial loss: 0.418073\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003034; batch adversarial loss: 0.448537\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008926; batch adversarial loss: 0.502098\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009147; batch adversarial loss: 0.416951\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013867; batch adversarial loss: 0.456117\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017681; batch adversarial loss: 0.422426\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007778; batch adversarial loss: 0.471465\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015908; batch adversarial loss: 0.470900\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019095; batch adversarial loss: 0.490392\n",
      "epoch 192; iter: 0; batch classifier loss: 0.003026; batch adversarial loss: 0.498149\n",
      "epoch 193; iter: 0; batch classifier loss: 0.001482; batch adversarial loss: 0.505564\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024034; batch adversarial loss: 0.414459\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009677; batch adversarial loss: 0.499906\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014350; batch adversarial loss: 0.432147\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005981; batch adversarial loss: 0.507332\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009340; batch adversarial loss: 0.409121\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024887; batch adversarial loss: 0.462972\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686862; batch adversarial loss: 0.518860\n",
      "epoch 1; iter: 0; batch classifier loss: 0.390367; batch adversarial loss: 0.632804\n",
      "epoch 2; iter: 0; batch classifier loss: 0.399858; batch adversarial loss: 0.669978\n",
      "epoch 3; iter: 0; batch classifier loss: 0.372367; batch adversarial loss: 0.583273\n",
      "epoch 4; iter: 0; batch classifier loss: 0.366147; batch adversarial loss: 0.600231\n",
      "epoch 5; iter: 0; batch classifier loss: 0.347967; batch adversarial loss: 0.645489\n",
      "epoch 6; iter: 0; batch classifier loss: 0.430313; batch adversarial loss: 0.544553\n",
      "epoch 7; iter: 0; batch classifier loss: 0.332181; batch adversarial loss: 0.616097\n",
      "epoch 8; iter: 0; batch classifier loss: 0.339102; batch adversarial loss: 0.581836\n",
      "epoch 9; iter: 0; batch classifier loss: 0.432421; batch adversarial loss: 0.558599\n",
      "epoch 10; iter: 0; batch classifier loss: 0.474861; batch adversarial loss: 0.496486\n",
      "epoch 11; iter: 0; batch classifier loss: 0.485301; batch adversarial loss: 0.474130\n",
      "epoch 12; iter: 0; batch classifier loss: 0.353011; batch adversarial loss: 0.485345\n",
      "epoch 13; iter: 0; batch classifier loss: 0.286814; batch adversarial loss: 0.475571\n",
      "epoch 14; iter: 0; batch classifier loss: 0.302928; batch adversarial loss: 0.442427\n",
      "epoch 15; iter: 0; batch classifier loss: 0.227637; batch adversarial loss: 0.532897\n",
      "epoch 16; iter: 0; batch classifier loss: 0.271552; batch adversarial loss: 0.492178\n",
      "epoch 17; iter: 0; batch classifier loss: 0.182971; batch adversarial loss: 0.438392\n",
      "epoch 18; iter: 0; batch classifier loss: 0.205587; batch adversarial loss: 0.504286\n",
      "epoch 19; iter: 0; batch classifier loss: 0.294688; batch adversarial loss: 0.414434\n",
      "epoch 20; iter: 0; batch classifier loss: 0.161065; batch adversarial loss: 0.402119\n",
      "epoch 21; iter: 0; batch classifier loss: 0.138622; batch adversarial loss: 0.445759\n",
      "epoch 22; iter: 0; batch classifier loss: 0.129244; batch adversarial loss: 0.492917\n",
      "epoch 23; iter: 0; batch classifier loss: 0.153540; batch adversarial loss: 0.523522\n",
      "epoch 24; iter: 0; batch classifier loss: 0.217781; batch adversarial loss: 0.456479\n",
      "epoch 25; iter: 0; batch classifier loss: 0.168692; batch adversarial loss: 0.431827\n",
      "epoch 26; iter: 0; batch classifier loss: 0.179720; batch adversarial loss: 0.559703\n",
      "epoch 27; iter: 0; batch classifier loss: 0.144904; batch adversarial loss: 0.361191\n",
      "epoch 28; iter: 0; batch classifier loss: 0.194968; batch adversarial loss: 0.525358\n",
      "epoch 29; iter: 0; batch classifier loss: 0.155584; batch adversarial loss: 0.473230\n",
      "epoch 30; iter: 0; batch classifier loss: 0.118768; batch adversarial loss: 0.508659\n",
      "epoch 31; iter: 0; batch classifier loss: 0.140528; batch adversarial loss: 0.496873\n",
      "epoch 32; iter: 0; batch classifier loss: 0.125338; batch adversarial loss: 0.438684\n",
      "epoch 33; iter: 0; batch classifier loss: 0.146553; batch adversarial loss: 0.516001\n",
      "epoch 34; iter: 0; batch classifier loss: 0.124215; batch adversarial loss: 0.517719\n",
      "epoch 35; iter: 0; batch classifier loss: 0.124640; batch adversarial loss: 0.452324\n",
      "epoch 36; iter: 0; batch classifier loss: 0.157599; batch adversarial loss: 0.427468\n",
      "epoch 37; iter: 0; batch classifier loss: 0.156835; batch adversarial loss: 0.518053\n",
      "epoch 38; iter: 0; batch classifier loss: 0.118368; batch adversarial loss: 0.473523\n",
      "epoch 39; iter: 0; batch classifier loss: 0.111308; batch adversarial loss: 0.513105\n",
      "epoch 40; iter: 0; batch classifier loss: 0.101049; batch adversarial loss: 0.477189\n",
      "epoch 41; iter: 0; batch classifier loss: 0.082034; batch adversarial loss: 0.419545\n",
      "epoch 42; iter: 0; batch classifier loss: 0.092927; batch adversarial loss: 0.522697\n",
      "epoch 43; iter: 0; batch classifier loss: 0.105603; batch adversarial loss: 0.453470\n",
      "epoch 44; iter: 0; batch classifier loss: 0.104835; batch adversarial loss: 0.448054\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086485; batch adversarial loss: 0.482130\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127837; batch adversarial loss: 0.483693\n",
      "epoch 47; iter: 0; batch classifier loss: 0.083626; batch adversarial loss: 0.371559\n",
      "epoch 48; iter: 0; batch classifier loss: 0.113377; batch adversarial loss: 0.512621\n",
      "epoch 49; iter: 0; batch classifier loss: 0.081022; batch adversarial loss: 0.570866\n",
      "epoch 50; iter: 0; batch classifier loss: 0.113430; batch adversarial loss: 0.423249\n",
      "epoch 51; iter: 0; batch classifier loss: 0.075224; batch adversarial loss: 0.534069\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089146; batch adversarial loss: 0.499252\n",
      "epoch 53; iter: 0; batch classifier loss: 0.157051; batch adversarial loss: 0.418595\n",
      "epoch 54; iter: 0; batch classifier loss: 0.084182; batch adversarial loss: 0.438631\n",
      "epoch 55; iter: 0; batch classifier loss: 0.204969; batch adversarial loss: 0.468722\n",
      "epoch 56; iter: 0; batch classifier loss: 0.110541; batch adversarial loss: 0.434598\n",
      "epoch 57; iter: 0; batch classifier loss: 0.080436; batch adversarial loss: 0.524191\n",
      "epoch 58; iter: 0; batch classifier loss: 0.092024; batch adversarial loss: 0.471683\n",
      "epoch 59; iter: 0; batch classifier loss: 0.140467; batch adversarial loss: 0.392696\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122603; batch adversarial loss: 0.479528\n",
      "epoch 61; iter: 0; batch classifier loss: 0.119555; batch adversarial loss: 0.443069\n",
      "epoch 62; iter: 0; batch classifier loss: 0.176063; batch adversarial loss: 0.491855\n",
      "epoch 63; iter: 0; batch classifier loss: 0.072751; batch adversarial loss: 0.467304\n",
      "epoch 64; iter: 0; batch classifier loss: 0.101645; batch adversarial loss: 0.507391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.122856; batch adversarial loss: 0.388814\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085442; batch adversarial loss: 0.461857\n",
      "epoch 67; iter: 0; batch classifier loss: 0.085531; batch adversarial loss: 0.402973\n",
      "epoch 68; iter: 0; batch classifier loss: 0.083357; batch adversarial loss: 0.350936\n",
      "epoch 69; iter: 0; batch classifier loss: 0.116079; batch adversarial loss: 0.455935\n",
      "epoch 70; iter: 0; batch classifier loss: 0.052053; batch adversarial loss: 0.536165\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079250; batch adversarial loss: 0.547134\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082260; batch adversarial loss: 0.506752\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083702; batch adversarial loss: 0.496231\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089525; batch adversarial loss: 0.422583\n",
      "epoch 75; iter: 0; batch classifier loss: 0.119994; batch adversarial loss: 0.621877\n",
      "epoch 76; iter: 0; batch classifier loss: 0.079916; batch adversarial loss: 0.546660\n",
      "epoch 77; iter: 0; batch classifier loss: 0.131335; batch adversarial loss: 0.487950\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073753; batch adversarial loss: 0.523544\n",
      "epoch 79; iter: 0; batch classifier loss: 0.096343; batch adversarial loss: 0.445878\n",
      "epoch 80; iter: 0; batch classifier loss: 0.047390; batch adversarial loss: 0.483919\n",
      "epoch 81; iter: 0; batch classifier loss: 0.043441; batch adversarial loss: 0.603073\n",
      "epoch 82; iter: 0; batch classifier loss: 0.085674; batch adversarial loss: 0.494603\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035806; batch adversarial loss: 0.519640\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067212; batch adversarial loss: 0.421777\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046156; batch adversarial loss: 0.473454\n",
      "epoch 86; iter: 0; batch classifier loss: 0.078158; batch adversarial loss: 0.403282\n",
      "epoch 87; iter: 0; batch classifier loss: 0.083531; batch adversarial loss: 0.411501\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063403; batch adversarial loss: 0.374717\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054166; batch adversarial loss: 0.486389\n",
      "epoch 90; iter: 0; batch classifier loss: 0.049181; batch adversarial loss: 0.486591\n",
      "epoch 91; iter: 0; batch classifier loss: 0.070739; batch adversarial loss: 0.361454\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052171; batch adversarial loss: 0.484278\n",
      "epoch 93; iter: 0; batch classifier loss: 0.096923; batch adversarial loss: 0.487294\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051433; batch adversarial loss: 0.526857\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079232; batch adversarial loss: 0.418525\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055491; batch adversarial loss: 0.398664\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051798; batch adversarial loss: 0.493931\n",
      "epoch 98; iter: 0; batch classifier loss: 0.037622; batch adversarial loss: 0.421205\n",
      "epoch 99; iter: 0; batch classifier loss: 0.104059; batch adversarial loss: 0.434734\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047360; batch adversarial loss: 0.514449\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068908; batch adversarial loss: 0.405943\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058525; batch adversarial loss: 0.509389\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049269; batch adversarial loss: 0.461620\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066309; batch adversarial loss: 0.472149\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062291; batch adversarial loss: 0.498525\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046738; batch adversarial loss: 0.421330\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039120; batch adversarial loss: 0.407558\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043750; batch adversarial loss: 0.456619\n",
      "epoch 109; iter: 0; batch classifier loss: 0.086564; batch adversarial loss: 0.421119\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030927; batch adversarial loss: 0.457630\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041063; batch adversarial loss: 0.470169\n",
      "epoch 112; iter: 0; batch classifier loss: 0.022305; batch adversarial loss: 0.446517\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042388; batch adversarial loss: 0.470214\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032153; batch adversarial loss: 0.441467\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042197; batch adversarial loss: 0.460998\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046366; batch adversarial loss: 0.530090\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048831; batch adversarial loss: 0.460865\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049297; batch adversarial loss: 0.452062\n",
      "epoch 119; iter: 0; batch classifier loss: 0.052328; batch adversarial loss: 0.361655\n",
      "epoch 120; iter: 0; batch classifier loss: 0.052138; batch adversarial loss: 0.463942\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032954; batch adversarial loss: 0.415995\n",
      "epoch 122; iter: 0; batch classifier loss: 0.021907; batch adversarial loss: 0.418864\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037430; batch adversarial loss: 0.376438\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026883; batch adversarial loss: 0.554085\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039531; batch adversarial loss: 0.496304\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019247; batch adversarial loss: 0.532388\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048255; batch adversarial loss: 0.467722\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022966; batch adversarial loss: 0.467248\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048623; batch adversarial loss: 0.365016\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044560; batch adversarial loss: 0.510944\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028779; batch adversarial loss: 0.433218\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031441; batch adversarial loss: 0.428734\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029951; batch adversarial loss: 0.496767\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019595; batch adversarial loss: 0.406119\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044232; batch adversarial loss: 0.495197\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037898; batch adversarial loss: 0.440144\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041471; batch adversarial loss: 0.484803\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032132; batch adversarial loss: 0.429248\n",
      "epoch 139; iter: 0; batch classifier loss: 0.093276; batch adversarial loss: 0.424577\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026059; batch adversarial loss: 0.409967\n",
      "epoch 141; iter: 0; batch classifier loss: 0.054020; batch adversarial loss: 0.467429\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014256; batch adversarial loss: 0.434119\n",
      "epoch 143; iter: 0; batch classifier loss: 0.055743; batch adversarial loss: 0.323792\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014728; batch adversarial loss: 0.422305\n",
      "epoch 145; iter: 0; batch classifier loss: 0.057422; batch adversarial loss: 0.431646\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026697; batch adversarial loss: 0.456935\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028313; batch adversarial loss: 0.393010\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020793; batch adversarial loss: 0.435310\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024004; batch adversarial loss: 0.447166\n",
      "epoch 150; iter: 0; batch classifier loss: 0.046400; batch adversarial loss: 0.444677\n",
      "epoch 151; iter: 0; batch classifier loss: 0.069490; batch adversarial loss: 0.410650\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033707; batch adversarial loss: 0.469972\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015561; batch adversarial loss: 0.432544\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030551; batch adversarial loss: 0.527172\n",
      "epoch 155; iter: 0; batch classifier loss: 0.051679; batch adversarial loss: 0.506695\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025254; batch adversarial loss: 0.378695\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032426; batch adversarial loss: 0.437437\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012417; batch adversarial loss: 0.414037\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031497; batch adversarial loss: 0.477449\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028765; batch adversarial loss: 0.443284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.040159; batch adversarial loss: 0.426687\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015525; batch adversarial loss: 0.527679\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021733; batch adversarial loss: 0.400123\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032990; batch adversarial loss: 0.525906\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011121; batch adversarial loss: 0.461427\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019747; batch adversarial loss: 0.354636\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011001; batch adversarial loss: 0.440554\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031983; batch adversarial loss: 0.517031\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009411; batch adversarial loss: 0.509157\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024722; batch adversarial loss: 0.541974\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024234; batch adversarial loss: 0.489225\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030546; batch adversarial loss: 0.383283\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038578; batch adversarial loss: 0.503579\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021528; batch adversarial loss: 0.495851\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026171; batch adversarial loss: 0.366048\n",
      "epoch 176; iter: 0; batch classifier loss: 0.039275; batch adversarial loss: 0.428537\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015482; batch adversarial loss: 0.506422\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038154; batch adversarial loss: 0.447205\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009075; batch adversarial loss: 0.435450\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013732; batch adversarial loss: 0.501103\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006002; batch adversarial loss: 0.436335\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033928; batch adversarial loss: 0.515211\n",
      "epoch 183; iter: 0; batch classifier loss: 0.050298; batch adversarial loss: 0.467562\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014192; batch adversarial loss: 0.494181\n",
      "epoch 185; iter: 0; batch classifier loss: 0.049889; batch adversarial loss: 0.432685\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028310; batch adversarial loss: 0.399311\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010859; batch adversarial loss: 0.421565\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024686; batch adversarial loss: 0.488018\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024741; batch adversarial loss: 0.484016\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030567; batch adversarial loss: 0.497725\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011967; batch adversarial loss: 0.576546\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028700; batch adversarial loss: 0.443607\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031747; batch adversarial loss: 0.534975\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034974; batch adversarial loss: 0.500569\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006933; batch adversarial loss: 0.405685\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021280; batch adversarial loss: 0.388390\n",
      "epoch 197; iter: 0; batch classifier loss: 0.030870; batch adversarial loss: 0.560079\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017233; batch adversarial loss: 0.445946\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028043; batch adversarial loss: 0.471803\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679643; batch adversarial loss: 0.577863\n",
      "epoch 1; iter: 0; batch classifier loss: 0.395269; batch adversarial loss: 0.616125\n",
      "epoch 2; iter: 0; batch classifier loss: 0.368082; batch adversarial loss: 0.585826\n",
      "epoch 3; iter: 0; batch classifier loss: 0.359745; batch adversarial loss: 0.544333\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335095; batch adversarial loss: 0.616248\n",
      "epoch 5; iter: 0; batch classifier loss: 0.356819; batch adversarial loss: 0.521499\n",
      "epoch 6; iter: 0; batch classifier loss: 0.473289; batch adversarial loss: 0.596336\n",
      "epoch 7; iter: 0; batch classifier loss: 0.345433; batch adversarial loss: 0.490036\n",
      "epoch 8; iter: 0; batch classifier loss: 0.308897; batch adversarial loss: 0.531601\n",
      "epoch 9; iter: 0; batch classifier loss: 0.298847; batch adversarial loss: 0.522588\n",
      "epoch 10; iter: 0; batch classifier loss: 0.349434; batch adversarial loss: 0.545108\n",
      "epoch 11; iter: 0; batch classifier loss: 0.320959; batch adversarial loss: 0.556540\n",
      "epoch 12; iter: 0; batch classifier loss: 0.369865; batch adversarial loss: 0.533291\n",
      "epoch 13; iter: 0; batch classifier loss: 0.352947; batch adversarial loss: 0.565163\n",
      "epoch 14; iter: 0; batch classifier loss: 0.610895; batch adversarial loss: 0.519129\n",
      "epoch 15; iter: 0; batch classifier loss: 0.559470; batch adversarial loss: 0.476640\n",
      "epoch 16; iter: 0; batch classifier loss: 0.321490; batch adversarial loss: 0.543845\n",
      "epoch 17; iter: 0; batch classifier loss: 0.270933; batch adversarial loss: 0.481476\n",
      "epoch 18; iter: 0; batch classifier loss: 0.153879; batch adversarial loss: 0.491134\n",
      "epoch 19; iter: 0; batch classifier loss: 0.231260; batch adversarial loss: 0.488894\n",
      "epoch 20; iter: 0; batch classifier loss: 0.196262; batch adversarial loss: 0.514261\n",
      "epoch 21; iter: 0; batch classifier loss: 0.192842; batch adversarial loss: 0.491871\n",
      "epoch 22; iter: 0; batch classifier loss: 0.175148; batch adversarial loss: 0.483332\n",
      "epoch 23; iter: 0; batch classifier loss: 0.153946; batch adversarial loss: 0.536395\n",
      "epoch 24; iter: 0; batch classifier loss: 0.184557; batch adversarial loss: 0.455584\n",
      "epoch 25; iter: 0; batch classifier loss: 0.155118; batch adversarial loss: 0.533532\n",
      "epoch 26; iter: 0; batch classifier loss: 0.141393; batch adversarial loss: 0.514103\n",
      "epoch 27; iter: 0; batch classifier loss: 0.134391; batch adversarial loss: 0.457585\n",
      "epoch 28; iter: 0; batch classifier loss: 0.154610; batch adversarial loss: 0.539667\n",
      "epoch 29; iter: 0; batch classifier loss: 0.140793; batch adversarial loss: 0.507557\n",
      "epoch 30; iter: 0; batch classifier loss: 0.157607; batch adversarial loss: 0.455861\n",
      "epoch 31; iter: 0; batch classifier loss: 0.107743; batch adversarial loss: 0.439098\n",
      "epoch 32; iter: 0; batch classifier loss: 0.102972; batch adversarial loss: 0.476921\n",
      "epoch 33; iter: 0; batch classifier loss: 0.102631; batch adversarial loss: 0.402348\n",
      "epoch 34; iter: 0; batch classifier loss: 0.086835; batch adversarial loss: 0.404519\n",
      "epoch 35; iter: 0; batch classifier loss: 0.106368; batch adversarial loss: 0.597374\n",
      "epoch 36; iter: 0; batch classifier loss: 0.133632; batch adversarial loss: 0.468808\n",
      "epoch 37; iter: 0; batch classifier loss: 0.119173; batch adversarial loss: 0.530408\n",
      "epoch 38; iter: 0; batch classifier loss: 0.180554; batch adversarial loss: 0.484854\n",
      "epoch 39; iter: 0; batch classifier loss: 0.073649; batch adversarial loss: 0.456670\n",
      "epoch 40; iter: 0; batch classifier loss: 0.092717; batch adversarial loss: 0.485819\n",
      "epoch 41; iter: 0; batch classifier loss: 0.065771; batch adversarial loss: 0.503028\n",
      "epoch 42; iter: 0; batch classifier loss: 0.115818; batch adversarial loss: 0.527596\n",
      "epoch 43; iter: 0; batch classifier loss: 0.077802; batch adversarial loss: 0.537248\n",
      "epoch 44; iter: 0; batch classifier loss: 0.088329; batch adversarial loss: 0.425756\n",
      "epoch 45; iter: 0; batch classifier loss: 0.071292; batch adversarial loss: 0.541857\n",
      "epoch 46; iter: 0; batch classifier loss: 0.079357; batch adversarial loss: 0.469972\n",
      "epoch 47; iter: 0; batch classifier loss: 0.062295; batch adversarial loss: 0.424236\n",
      "epoch 48; iter: 0; batch classifier loss: 0.128054; batch adversarial loss: 0.440445\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098736; batch adversarial loss: 0.441339\n",
      "epoch 50; iter: 0; batch classifier loss: 0.164204; batch adversarial loss: 0.523389\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073652; batch adversarial loss: 0.412247\n",
      "epoch 52; iter: 0; batch classifier loss: 0.109217; batch adversarial loss: 0.515272\n",
      "epoch 53; iter: 0; batch classifier loss: 0.112212; batch adversarial loss: 0.432718\n",
      "epoch 54; iter: 0; batch classifier loss: 0.098534; batch adversarial loss: 0.557067\n",
      "epoch 55; iter: 0; batch classifier loss: 0.101712; batch adversarial loss: 0.399481\n",
      "epoch 56; iter: 0; batch classifier loss: 0.069643; batch adversarial loss: 0.374647\n",
      "epoch 57; iter: 0; batch classifier loss: 0.091585; batch adversarial loss: 0.599881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.056742; batch adversarial loss: 0.445033\n",
      "epoch 59; iter: 0; batch classifier loss: 0.093859; batch adversarial loss: 0.476353\n",
      "epoch 60; iter: 0; batch classifier loss: 0.083559; batch adversarial loss: 0.556838\n",
      "epoch 61; iter: 0; batch classifier loss: 0.050853; batch adversarial loss: 0.486113\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085039; batch adversarial loss: 0.466318\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070694; batch adversarial loss: 0.509912\n",
      "epoch 64; iter: 0; batch classifier loss: 0.137059; batch adversarial loss: 0.452413\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075921; batch adversarial loss: 0.438521\n",
      "epoch 66; iter: 0; batch classifier loss: 0.093267; batch adversarial loss: 0.375667\n",
      "epoch 67; iter: 0; batch classifier loss: 0.117083; batch adversarial loss: 0.420401\n",
      "epoch 68; iter: 0; batch classifier loss: 0.055121; batch adversarial loss: 0.446176\n",
      "epoch 69; iter: 0; batch classifier loss: 0.074165; batch adversarial loss: 0.548854\n",
      "epoch 70; iter: 0; batch classifier loss: 0.074110; batch adversarial loss: 0.427551\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078771; batch adversarial loss: 0.456177\n",
      "epoch 72; iter: 0; batch classifier loss: 0.089041; batch adversarial loss: 0.446084\n",
      "epoch 73; iter: 0; batch classifier loss: 0.099480; batch adversarial loss: 0.463881\n",
      "epoch 74; iter: 0; batch classifier loss: 0.047892; batch adversarial loss: 0.372015\n",
      "epoch 75; iter: 0; batch classifier loss: 0.078173; batch adversarial loss: 0.463107\n",
      "epoch 76; iter: 0; batch classifier loss: 0.028829; batch adversarial loss: 0.454019\n",
      "epoch 77; iter: 0; batch classifier loss: 0.061295; batch adversarial loss: 0.403022\n",
      "epoch 78; iter: 0; batch classifier loss: 0.106935; batch adversarial loss: 0.439693\n",
      "epoch 79; iter: 0; batch classifier loss: 0.087119; batch adversarial loss: 0.449198\n",
      "epoch 80; iter: 0; batch classifier loss: 0.041686; batch adversarial loss: 0.481060\n",
      "epoch 81; iter: 0; batch classifier loss: 0.053897; batch adversarial loss: 0.505963\n",
      "epoch 82; iter: 0; batch classifier loss: 0.144564; batch adversarial loss: 0.477863\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086452; batch adversarial loss: 0.456077\n",
      "epoch 84; iter: 0; batch classifier loss: 0.064565; batch adversarial loss: 0.529342\n",
      "epoch 85; iter: 0; batch classifier loss: 0.098927; batch adversarial loss: 0.438613\n",
      "epoch 86; iter: 0; batch classifier loss: 0.109345; batch adversarial loss: 0.567971\n",
      "epoch 87; iter: 0; batch classifier loss: 0.051338; batch adversarial loss: 0.524441\n",
      "epoch 88; iter: 0; batch classifier loss: 0.127685; batch adversarial loss: 0.484560\n",
      "epoch 89; iter: 0; batch classifier loss: 0.045735; batch adversarial loss: 0.445219\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068472; batch adversarial loss: 0.511926\n",
      "epoch 91; iter: 0; batch classifier loss: 0.097661; batch adversarial loss: 0.556903\n",
      "epoch 92; iter: 0; batch classifier loss: 0.092576; batch adversarial loss: 0.442797\n",
      "epoch 93; iter: 0; batch classifier loss: 0.066016; batch adversarial loss: 0.439869\n",
      "epoch 94; iter: 0; batch classifier loss: 0.098707; batch adversarial loss: 0.437564\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063749; batch adversarial loss: 0.455163\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057972; batch adversarial loss: 0.501477\n",
      "epoch 97; iter: 0; batch classifier loss: 0.080644; batch adversarial loss: 0.474449\n",
      "epoch 98; iter: 0; batch classifier loss: 0.096041; batch adversarial loss: 0.518122\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039705; batch adversarial loss: 0.398699\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067901; batch adversarial loss: 0.510360\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040654; batch adversarial loss: 0.465044\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051536; batch adversarial loss: 0.465207\n",
      "epoch 103; iter: 0; batch classifier loss: 0.024497; batch adversarial loss: 0.395563\n",
      "epoch 104; iter: 0; batch classifier loss: 0.088618; batch adversarial loss: 0.432426\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059344; batch adversarial loss: 0.531738\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047654; batch adversarial loss: 0.409248\n",
      "epoch 107; iter: 0; batch classifier loss: 0.030077; batch adversarial loss: 0.500268\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039633; batch adversarial loss: 0.464595\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049697; batch adversarial loss: 0.541292\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052743; batch adversarial loss: 0.494324\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055468; batch adversarial loss: 0.492149\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027664; batch adversarial loss: 0.420347\n",
      "epoch 113; iter: 0; batch classifier loss: 0.079409; batch adversarial loss: 0.451879\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051967; batch adversarial loss: 0.386710\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043433; batch adversarial loss: 0.506747\n",
      "epoch 116; iter: 0; batch classifier loss: 0.064091; batch adversarial loss: 0.523804\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046109; batch adversarial loss: 0.550737\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054227; batch adversarial loss: 0.535062\n",
      "epoch 119; iter: 0; batch classifier loss: 0.100738; batch adversarial loss: 0.472416\n",
      "epoch 120; iter: 0; batch classifier loss: 0.092202; batch adversarial loss: 0.449931\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032828; batch adversarial loss: 0.388616\n",
      "epoch 122; iter: 0; batch classifier loss: 0.024904; batch adversarial loss: 0.449742\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032377; batch adversarial loss: 0.341187\n",
      "epoch 124; iter: 0; batch classifier loss: 0.070480; batch adversarial loss: 0.449437\n",
      "epoch 125; iter: 0; batch classifier loss: 0.069583; batch adversarial loss: 0.477223\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032740; batch adversarial loss: 0.408372\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037871; batch adversarial loss: 0.423752\n",
      "epoch 128; iter: 0; batch classifier loss: 0.057162; batch adversarial loss: 0.512343\n",
      "epoch 129; iter: 0; batch classifier loss: 0.068147; batch adversarial loss: 0.387230\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046173; batch adversarial loss: 0.485274\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041405; batch adversarial loss: 0.506292\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051400; batch adversarial loss: 0.445506\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021013; batch adversarial loss: 0.321003\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034665; batch adversarial loss: 0.401975\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034183; batch adversarial loss: 0.472708\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042964; batch adversarial loss: 0.471464\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015998; batch adversarial loss: 0.396850\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036296; batch adversarial loss: 0.404333\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039327; batch adversarial loss: 0.403184\n",
      "epoch 140; iter: 0; batch classifier loss: 0.068867; batch adversarial loss: 0.374749\n",
      "epoch 141; iter: 0; batch classifier loss: 0.047248; batch adversarial loss: 0.486664\n",
      "epoch 142; iter: 0; batch classifier loss: 0.046786; batch adversarial loss: 0.434987\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036012; batch adversarial loss: 0.481155\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032289; batch adversarial loss: 0.373457\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013463; batch adversarial loss: 0.372342\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030887; batch adversarial loss: 0.499258\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010154; batch adversarial loss: 0.435903\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015061; batch adversarial loss: 0.473730\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031778; batch adversarial loss: 0.493599\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013720; batch adversarial loss: 0.578672\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034606; batch adversarial loss: 0.478658\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030319; batch adversarial loss: 0.492361\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014115; batch adversarial loss: 0.451133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.053443; batch adversarial loss: 0.421802\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019856; batch adversarial loss: 0.426668\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029254; batch adversarial loss: 0.503768\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024563; batch adversarial loss: 0.418669\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014845; batch adversarial loss: 0.514823\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025570; batch adversarial loss: 0.503871\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031939; batch adversarial loss: 0.472840\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020112; batch adversarial loss: 0.419855\n",
      "epoch 162; iter: 0; batch classifier loss: 0.048895; batch adversarial loss: 0.489578\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037462; batch adversarial loss: 0.412952\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030909; batch adversarial loss: 0.526368\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017591; batch adversarial loss: 0.521503\n",
      "epoch 166; iter: 0; batch classifier loss: 0.039669; batch adversarial loss: 0.524725\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026208; batch adversarial loss: 0.489165\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021167; batch adversarial loss: 0.460937\n",
      "epoch 169; iter: 0; batch classifier loss: 0.063878; batch adversarial loss: 0.518953\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026386; batch adversarial loss: 0.456456\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020188; batch adversarial loss: 0.555634\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018384; batch adversarial loss: 0.495760\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038340; batch adversarial loss: 0.474610\n",
      "epoch 174; iter: 0; batch classifier loss: 0.069786; batch adversarial loss: 0.454799\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039200; batch adversarial loss: 0.430901\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012052; batch adversarial loss: 0.410597\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033827; batch adversarial loss: 0.409721\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006186; batch adversarial loss: 0.464569\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021068; batch adversarial loss: 0.469588\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014013; batch adversarial loss: 0.465345\n",
      "epoch 181; iter: 0; batch classifier loss: 0.071025; batch adversarial loss: 0.429877\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037776; batch adversarial loss: 0.452126\n",
      "epoch 183; iter: 0; batch classifier loss: 0.050142; batch adversarial loss: 0.502609\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008626; batch adversarial loss: 0.509781\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019061; batch adversarial loss: 0.451101\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015069; batch adversarial loss: 0.507072\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023999; batch adversarial loss: 0.445214\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020980; batch adversarial loss: 0.440320\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020834; batch adversarial loss: 0.522545\n",
      "epoch 190; iter: 0; batch classifier loss: 0.040248; batch adversarial loss: 0.508060\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015483; batch adversarial loss: 0.462460\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032416; batch adversarial loss: 0.406392\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032836; batch adversarial loss: 0.425189\n",
      "epoch 194; iter: 0; batch classifier loss: 0.039432; batch adversarial loss: 0.383127\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013166; batch adversarial loss: 0.425591\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013917; batch adversarial loss: 0.430675\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024048; batch adversarial loss: 0.470942\n",
      "epoch 198; iter: 0; batch classifier loss: 0.039620; batch adversarial loss: 0.500454\n",
      "epoch 199; iter: 0; batch classifier loss: 0.039289; batch adversarial loss: 0.521641\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718901; batch adversarial loss: 0.598011\n",
      "epoch 1; iter: 0; batch classifier loss: 0.555501; batch adversarial loss: 0.580051\n",
      "epoch 2; iter: 0; batch classifier loss: 0.394911; batch adversarial loss: 0.612325\n",
      "epoch 3; iter: 0; batch classifier loss: 0.339070; batch adversarial loss: 0.569755\n",
      "epoch 4; iter: 0; batch classifier loss: 0.435718; batch adversarial loss: 0.598153\n",
      "epoch 5; iter: 0; batch classifier loss: 0.405909; batch adversarial loss: 0.593159\n",
      "epoch 6; iter: 0; batch classifier loss: 0.393748; batch adversarial loss: 0.565737\n",
      "epoch 7; iter: 0; batch classifier loss: 0.354335; batch adversarial loss: 0.608006\n",
      "epoch 8; iter: 0; batch classifier loss: 0.371107; batch adversarial loss: 0.570074\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502992; batch adversarial loss: 0.557429\n",
      "epoch 10; iter: 0; batch classifier loss: 0.339176; batch adversarial loss: 0.539683\n",
      "epoch 11; iter: 0; batch classifier loss: 0.348077; batch adversarial loss: 0.582605\n",
      "epoch 12; iter: 0; batch classifier loss: 0.310106; batch adversarial loss: 0.520611\n",
      "epoch 13; iter: 0; batch classifier loss: 0.356980; batch adversarial loss: 0.458431\n",
      "epoch 14; iter: 0; batch classifier loss: 0.288795; batch adversarial loss: 0.530571\n",
      "epoch 15; iter: 0; batch classifier loss: 0.214497; batch adversarial loss: 0.455890\n",
      "epoch 16; iter: 0; batch classifier loss: 0.258615; batch adversarial loss: 0.536817\n",
      "epoch 17; iter: 0; batch classifier loss: 0.168475; batch adversarial loss: 0.546523\n",
      "epoch 18; iter: 0; batch classifier loss: 0.187058; batch adversarial loss: 0.468519\n",
      "epoch 19; iter: 0; batch classifier loss: 0.164285; batch adversarial loss: 0.490764\n",
      "epoch 20; iter: 0; batch classifier loss: 0.258712; batch adversarial loss: 0.489487\n",
      "epoch 21; iter: 0; batch classifier loss: 0.222269; batch adversarial loss: 0.562697\n",
      "epoch 22; iter: 0; batch classifier loss: 0.214306; batch adversarial loss: 0.422017\n",
      "epoch 23; iter: 0; batch classifier loss: 0.148418; batch adversarial loss: 0.475627\n",
      "epoch 24; iter: 0; batch classifier loss: 0.179613; batch adversarial loss: 0.481184\n",
      "epoch 25; iter: 0; batch classifier loss: 0.205750; batch adversarial loss: 0.474512\n",
      "epoch 26; iter: 0; batch classifier loss: 0.135717; batch adversarial loss: 0.507397\n",
      "epoch 27; iter: 0; batch classifier loss: 0.203241; batch adversarial loss: 0.428311\n",
      "epoch 28; iter: 0; batch classifier loss: 0.140212; batch adversarial loss: 0.574958\n",
      "epoch 29; iter: 0; batch classifier loss: 0.107654; batch adversarial loss: 0.478664\n",
      "epoch 30; iter: 0; batch classifier loss: 0.141719; batch adversarial loss: 0.431977\n",
      "epoch 31; iter: 0; batch classifier loss: 0.078581; batch adversarial loss: 0.537012\n",
      "epoch 32; iter: 0; batch classifier loss: 0.141260; batch adversarial loss: 0.543568\n",
      "epoch 33; iter: 0; batch classifier loss: 0.134743; batch adversarial loss: 0.503604\n",
      "epoch 34; iter: 0; batch classifier loss: 0.119849; batch adversarial loss: 0.488658\n",
      "epoch 35; iter: 0; batch classifier loss: 0.117106; batch adversarial loss: 0.437008\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150346; batch adversarial loss: 0.484713\n",
      "epoch 37; iter: 0; batch classifier loss: 0.182745; batch adversarial loss: 0.505092\n",
      "epoch 38; iter: 0; batch classifier loss: 0.129749; batch adversarial loss: 0.364006\n",
      "epoch 39; iter: 0; batch classifier loss: 0.170686; batch adversarial loss: 0.517970\n",
      "epoch 40; iter: 0; batch classifier loss: 0.147177; batch adversarial loss: 0.390750\n",
      "epoch 41; iter: 0; batch classifier loss: 0.124518; batch adversarial loss: 0.477007\n",
      "epoch 42; iter: 0; batch classifier loss: 0.189827; batch adversarial loss: 0.444651\n",
      "epoch 43; iter: 0; batch classifier loss: 0.136089; batch adversarial loss: 0.434015\n",
      "epoch 44; iter: 0; batch classifier loss: 0.129361; batch adversarial loss: 0.529350\n",
      "epoch 45; iter: 0; batch classifier loss: 0.164097; batch adversarial loss: 0.464157\n",
      "epoch 46; iter: 0; batch classifier loss: 0.098976; batch adversarial loss: 0.466739\n",
      "epoch 47; iter: 0; batch classifier loss: 0.120024; batch adversarial loss: 0.475721\n",
      "epoch 48; iter: 0; batch classifier loss: 0.136799; batch adversarial loss: 0.563559\n",
      "epoch 49; iter: 0; batch classifier loss: 0.134156; batch adversarial loss: 0.434612\n",
      "epoch 50; iter: 0; batch classifier loss: 0.163089; batch adversarial loss: 0.447468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.130927; batch adversarial loss: 0.444211\n",
      "epoch 52; iter: 0; batch classifier loss: 0.193170; batch adversarial loss: 0.456737\n",
      "epoch 53; iter: 0; batch classifier loss: 0.123230; batch adversarial loss: 0.566234\n",
      "epoch 54; iter: 0; batch classifier loss: 0.124151; batch adversarial loss: 0.520564\n",
      "epoch 55; iter: 0; batch classifier loss: 0.180840; batch adversarial loss: 0.398349\n",
      "epoch 56; iter: 0; batch classifier loss: 0.160500; batch adversarial loss: 0.446265\n",
      "epoch 57; iter: 0; batch classifier loss: 0.117775; batch adversarial loss: 0.466044\n",
      "epoch 58; iter: 0; batch classifier loss: 0.162805; batch adversarial loss: 0.470253\n",
      "epoch 59; iter: 0; batch classifier loss: 0.154108; batch adversarial loss: 0.417477\n",
      "epoch 60; iter: 0; batch classifier loss: 0.183728; batch adversarial loss: 0.448845\n",
      "epoch 61; iter: 0; batch classifier loss: 0.169498; batch adversarial loss: 0.438501\n",
      "epoch 62; iter: 0; batch classifier loss: 0.143464; batch adversarial loss: 0.471421\n",
      "epoch 63; iter: 0; batch classifier loss: 0.151899; batch adversarial loss: 0.438331\n",
      "epoch 64; iter: 0; batch classifier loss: 0.187637; batch adversarial loss: 0.478311\n",
      "epoch 65; iter: 0; batch classifier loss: 0.170725; batch adversarial loss: 0.607394\n",
      "epoch 66; iter: 0; batch classifier loss: 0.158602; batch adversarial loss: 0.510591\n",
      "epoch 67; iter: 0; batch classifier loss: 0.144471; batch adversarial loss: 0.469163\n",
      "epoch 68; iter: 0; batch classifier loss: 0.139146; batch adversarial loss: 0.410909\n",
      "epoch 69; iter: 0; batch classifier loss: 0.181727; batch adversarial loss: 0.544917\n",
      "epoch 70; iter: 0; batch classifier loss: 0.118379; batch adversarial loss: 0.487427\n",
      "epoch 71; iter: 0; batch classifier loss: 0.182703; batch adversarial loss: 0.411475\n",
      "epoch 72; iter: 0; batch classifier loss: 0.248888; batch adversarial loss: 0.517961\n",
      "epoch 73; iter: 0; batch classifier loss: 0.193596; batch adversarial loss: 0.504479\n",
      "epoch 74; iter: 0; batch classifier loss: 0.122347; batch adversarial loss: 0.459822\n",
      "epoch 75; iter: 0; batch classifier loss: 0.111974; batch adversarial loss: 0.529507\n",
      "epoch 76; iter: 0; batch classifier loss: 0.161559; batch adversarial loss: 0.516960\n",
      "epoch 77; iter: 0; batch classifier loss: 0.238879; batch adversarial loss: 0.399599\n",
      "epoch 78; iter: 0; batch classifier loss: 0.151950; batch adversarial loss: 0.447801\n",
      "epoch 79; iter: 0; batch classifier loss: 0.192056; batch adversarial loss: 0.435233\n",
      "epoch 80; iter: 0; batch classifier loss: 0.197429; batch adversarial loss: 0.563838\n",
      "epoch 81; iter: 0; batch classifier loss: 0.251616; batch adversarial loss: 0.378788\n",
      "epoch 82; iter: 0; batch classifier loss: 0.195117; batch adversarial loss: 0.494457\n",
      "epoch 83; iter: 0; batch classifier loss: 0.233827; batch adversarial loss: 0.516987\n",
      "epoch 84; iter: 0; batch classifier loss: 0.241310; batch adversarial loss: 0.485058\n",
      "epoch 85; iter: 0; batch classifier loss: 0.157491; batch adversarial loss: 0.529040\n",
      "epoch 86; iter: 0; batch classifier loss: 0.226549; batch adversarial loss: 0.529141\n",
      "epoch 87; iter: 0; batch classifier loss: 0.225372; batch adversarial loss: 0.470184\n",
      "epoch 88; iter: 0; batch classifier loss: 0.215344; batch adversarial loss: 0.482503\n",
      "epoch 89; iter: 0; batch classifier loss: 0.260501; batch adversarial loss: 0.470942\n",
      "epoch 90; iter: 0; batch classifier loss: 0.289770; batch adversarial loss: 0.517951\n",
      "epoch 91; iter: 0; batch classifier loss: 0.211660; batch adversarial loss: 0.447464\n",
      "epoch 92; iter: 0; batch classifier loss: 0.149825; batch adversarial loss: 0.506367\n",
      "epoch 93; iter: 0; batch classifier loss: 0.148316; batch adversarial loss: 0.447330\n",
      "epoch 94; iter: 0; batch classifier loss: 0.118361; batch adversarial loss: 0.483805\n",
      "epoch 95; iter: 0; batch classifier loss: 0.233561; batch adversarial loss: 0.530404\n",
      "epoch 96; iter: 0; batch classifier loss: 0.184609; batch adversarial loss: 0.460219\n",
      "epoch 97; iter: 0; batch classifier loss: 0.221870; batch adversarial loss: 0.471474\n",
      "epoch 98; iter: 0; batch classifier loss: 0.230901; batch adversarial loss: 0.424291\n",
      "epoch 99; iter: 0; batch classifier loss: 0.222042; batch adversarial loss: 0.494947\n",
      "epoch 100; iter: 0; batch classifier loss: 0.239306; batch adversarial loss: 0.482735\n",
      "epoch 101; iter: 0; batch classifier loss: 0.177020; batch adversarial loss: 0.494363\n",
      "epoch 102; iter: 0; batch classifier loss: 0.140749; batch adversarial loss: 0.481801\n",
      "epoch 103; iter: 0; batch classifier loss: 0.139002; batch adversarial loss: 0.445427\n",
      "epoch 104; iter: 0; batch classifier loss: 0.220838; batch adversarial loss: 0.315145\n",
      "epoch 105; iter: 0; batch classifier loss: 0.166773; batch adversarial loss: 0.520099\n",
      "epoch 106; iter: 0; batch classifier loss: 0.250954; batch adversarial loss: 0.423659\n",
      "epoch 107; iter: 0; batch classifier loss: 0.227529; batch adversarial loss: 0.517683\n",
      "epoch 108; iter: 0; batch classifier loss: 0.184647; batch adversarial loss: 0.506477\n",
      "epoch 109; iter: 0; batch classifier loss: 0.146565; batch adversarial loss: 0.518026\n",
      "epoch 110; iter: 0; batch classifier loss: 0.207141; batch adversarial loss: 0.505724\n",
      "epoch 111; iter: 0; batch classifier loss: 0.161499; batch adversarial loss: 0.530998\n",
      "epoch 112; iter: 0; batch classifier loss: 0.150294; batch adversarial loss: 0.482841\n",
      "epoch 113; iter: 0; batch classifier loss: 0.155057; batch adversarial loss: 0.506120\n",
      "epoch 114; iter: 0; batch classifier loss: 0.236857; batch adversarial loss: 0.412241\n",
      "epoch 115; iter: 0; batch classifier loss: 0.154342; batch adversarial loss: 0.518398\n",
      "epoch 116; iter: 0; batch classifier loss: 0.151125; batch adversarial loss: 0.519677\n",
      "epoch 117; iter: 0; batch classifier loss: 0.160111; batch adversarial loss: 0.494612\n",
      "epoch 118; iter: 0; batch classifier loss: 0.227846; batch adversarial loss: 0.506255\n",
      "epoch 119; iter: 0; batch classifier loss: 0.135962; batch adversarial loss: 0.459277\n",
      "epoch 120; iter: 0; batch classifier loss: 0.168505; batch adversarial loss: 0.447097\n",
      "epoch 121; iter: 0; batch classifier loss: 0.192775; batch adversarial loss: 0.423318\n",
      "epoch 122; iter: 0; batch classifier loss: 0.128373; batch adversarial loss: 0.435173\n",
      "epoch 123; iter: 0; batch classifier loss: 0.194281; batch adversarial loss: 0.435270\n",
      "epoch 124; iter: 0; batch classifier loss: 0.126249; batch adversarial loss: 0.565946\n",
      "epoch 125; iter: 0; batch classifier loss: 0.198115; batch adversarial loss: 0.423958\n",
      "epoch 126; iter: 0; batch classifier loss: 0.199590; batch adversarial loss: 0.459655\n",
      "epoch 127; iter: 0; batch classifier loss: 0.124097; batch adversarial loss: 0.494689\n",
      "epoch 128; iter: 0; batch classifier loss: 0.168437; batch adversarial loss: 0.376572\n",
      "epoch 129; iter: 0; batch classifier loss: 0.188328; batch adversarial loss: 0.470926\n",
      "epoch 130; iter: 0; batch classifier loss: 0.088371; batch adversarial loss: 0.529465\n",
      "epoch 131; iter: 0; batch classifier loss: 0.081236; batch adversarial loss: 0.399065\n",
      "epoch 132; iter: 0; batch classifier loss: 0.061781; batch adversarial loss: 0.541312\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044850; batch adversarial loss: 0.505976\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049545; batch adversarial loss: 0.529184\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044718; batch adversarial loss: 0.512977\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026725; batch adversarial loss: 0.534051\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029555; batch adversarial loss: 0.494860\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030821; batch adversarial loss: 0.403743\n",
      "epoch 139; iter: 0; batch classifier loss: 0.072642; batch adversarial loss: 0.438656\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029951; batch adversarial loss: 0.454105\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042075; batch adversarial loss: 0.428469\n",
      "epoch 142; iter: 0; batch classifier loss: 0.082914; batch adversarial loss: 0.492968\n",
      "epoch 143; iter: 0; batch classifier loss: 0.079133; batch adversarial loss: 0.465672\n",
      "epoch 144; iter: 0; batch classifier loss: 0.053128; batch adversarial loss: 0.466930\n",
      "epoch 145; iter: 0; batch classifier loss: 0.052489; batch adversarial loss: 0.411325\n",
      "epoch 146; iter: 0; batch classifier loss: 0.064301; batch adversarial loss: 0.399741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.071461; batch adversarial loss: 0.501141\n",
      "epoch 148; iter: 0; batch classifier loss: 0.084355; batch adversarial loss: 0.381779\n",
      "epoch 149; iter: 0; batch classifier loss: 0.062657; batch adversarial loss: 0.432666\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038937; batch adversarial loss: 0.564944\n",
      "epoch 151; iter: 0; batch classifier loss: 0.047243; batch adversarial loss: 0.498765\n",
      "epoch 152; iter: 0; batch classifier loss: 0.050304; batch adversarial loss: 0.384426\n",
      "epoch 153; iter: 0; batch classifier loss: 0.047499; batch adversarial loss: 0.535055\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035362; batch adversarial loss: 0.591834\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042612; batch adversarial loss: 0.474936\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034964; batch adversarial loss: 0.394716\n",
      "epoch 157; iter: 0; batch classifier loss: 0.048738; batch adversarial loss: 0.460416\n",
      "epoch 158; iter: 0; batch classifier loss: 0.049222; batch adversarial loss: 0.476201\n",
      "epoch 159; iter: 0; batch classifier loss: 0.041587; batch adversarial loss: 0.387681\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019102; batch adversarial loss: 0.548545\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013061; batch adversarial loss: 0.462600\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031122; batch adversarial loss: 0.449404\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042390; batch adversarial loss: 0.520188\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023035; batch adversarial loss: 0.470529\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032434; batch adversarial loss: 0.503211\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030667; batch adversarial loss: 0.433460\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023972; batch adversarial loss: 0.433834\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021892; batch adversarial loss: 0.500041\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021369; batch adversarial loss: 0.460702\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016097; batch adversarial loss: 0.453257\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022672; batch adversarial loss: 0.385642\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033368; batch adversarial loss: 0.394719\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023079; batch adversarial loss: 0.452401\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022956; batch adversarial loss: 0.460721\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010556; batch adversarial loss: 0.461980\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033476; batch adversarial loss: 0.436152\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036407; batch adversarial loss: 0.524891\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014163; batch adversarial loss: 0.452555\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012543; batch adversarial loss: 0.478488\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028586; batch adversarial loss: 0.437784\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010007; batch adversarial loss: 0.503706\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020828; batch adversarial loss: 0.441733\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007807; batch adversarial loss: 0.362201\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020352; batch adversarial loss: 0.382596\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019677; batch adversarial loss: 0.448290\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022007; batch adversarial loss: 0.454734\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042990; batch adversarial loss: 0.466673\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020251; batch adversarial loss: 0.337781\n",
      "epoch 189; iter: 0; batch classifier loss: 0.047498; batch adversarial loss: 0.448707\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021310; batch adversarial loss: 0.450723\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023028; batch adversarial loss: 0.381693\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023748; batch adversarial loss: 0.397126\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014196; batch adversarial loss: 0.437735\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008166; batch adversarial loss: 0.581642\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010854; batch adversarial loss: 0.457088\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015604; batch adversarial loss: 0.429045\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013774; batch adversarial loss: 0.421290\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031242; batch adversarial loss: 0.525660\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020208; batch adversarial loss: 0.406098\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707030; batch adversarial loss: 0.595794\n",
      "epoch 1; iter: 0; batch classifier loss: 0.617546; batch adversarial loss: 0.589774\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396745; batch adversarial loss: 0.648544\n",
      "epoch 3; iter: 0; batch classifier loss: 0.381594; batch adversarial loss: 0.599174\n",
      "epoch 4; iter: 0; batch classifier loss: 0.382723; batch adversarial loss: 0.562571\n",
      "epoch 5; iter: 0; batch classifier loss: 0.454122; batch adversarial loss: 0.559725\n",
      "epoch 6; iter: 0; batch classifier loss: 0.495259; batch adversarial loss: 0.558365\n",
      "epoch 7; iter: 0; batch classifier loss: 0.438596; batch adversarial loss: 0.561186\n",
      "epoch 8; iter: 0; batch classifier loss: 0.467001; batch adversarial loss: 0.568222\n",
      "epoch 9; iter: 0; batch classifier loss: 0.372539; batch adversarial loss: 0.551107\n",
      "epoch 10; iter: 0; batch classifier loss: 0.335592; batch adversarial loss: 0.560940\n",
      "epoch 11; iter: 0; batch classifier loss: 0.298990; batch adversarial loss: 0.476166\n",
      "epoch 12; iter: 0; batch classifier loss: 0.315037; batch adversarial loss: 0.512667\n",
      "epoch 13; iter: 0; batch classifier loss: 0.299392; batch adversarial loss: 0.528425\n",
      "epoch 14; iter: 0; batch classifier loss: 0.256698; batch adversarial loss: 0.449768\n",
      "epoch 15; iter: 0; batch classifier loss: 0.321972; batch adversarial loss: 0.516892\n",
      "epoch 16; iter: 0; batch classifier loss: 0.341923; batch adversarial loss: 0.434429\n",
      "epoch 17; iter: 0; batch classifier loss: 0.250930; batch adversarial loss: 0.473847\n",
      "epoch 18; iter: 0; batch classifier loss: 0.268771; batch adversarial loss: 0.469046\n",
      "epoch 19; iter: 0; batch classifier loss: 0.255273; batch adversarial loss: 0.486735\n",
      "epoch 20; iter: 0; batch classifier loss: 0.307855; batch adversarial loss: 0.421878\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234747; batch adversarial loss: 0.408928\n",
      "epoch 22; iter: 0; batch classifier loss: 0.203242; batch adversarial loss: 0.471572\n",
      "epoch 23; iter: 0; batch classifier loss: 0.202854; batch adversarial loss: 0.421040\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199261; batch adversarial loss: 0.513387\n",
      "epoch 25; iter: 0; batch classifier loss: 0.212348; batch adversarial loss: 0.402308\n",
      "epoch 26; iter: 0; batch classifier loss: 0.249086; batch adversarial loss: 0.405269\n",
      "epoch 27; iter: 0; batch classifier loss: 0.191239; batch adversarial loss: 0.439660\n",
      "epoch 28; iter: 0; batch classifier loss: 0.139466; batch adversarial loss: 0.481278\n",
      "epoch 29; iter: 0; batch classifier loss: 0.152692; batch adversarial loss: 0.494088\n",
      "epoch 30; iter: 0; batch classifier loss: 0.160258; batch adversarial loss: 0.401067\n",
      "epoch 31; iter: 0; batch classifier loss: 0.227389; batch adversarial loss: 0.407018\n",
      "epoch 32; iter: 0; batch classifier loss: 0.200227; batch adversarial loss: 0.472236\n",
      "epoch 33; iter: 0; batch classifier loss: 0.194181; batch adversarial loss: 0.398489\n",
      "epoch 34; iter: 0; batch classifier loss: 0.166806; batch adversarial loss: 0.432643\n",
      "epoch 35; iter: 0; batch classifier loss: 0.178160; batch adversarial loss: 0.440392\n",
      "epoch 36; iter: 0; batch classifier loss: 0.130288; batch adversarial loss: 0.476525\n",
      "epoch 37; iter: 0; batch classifier loss: 0.157393; batch adversarial loss: 0.500275\n",
      "epoch 38; iter: 0; batch classifier loss: 0.174873; batch adversarial loss: 0.464157\n",
      "epoch 39; iter: 0; batch classifier loss: 0.284703; batch adversarial loss: 0.418390\n",
      "epoch 40; iter: 0; batch classifier loss: 0.193064; batch adversarial loss: 0.481419\n",
      "epoch 41; iter: 0; batch classifier loss: 0.135989; batch adversarial loss: 0.579540\n",
      "epoch 42; iter: 0; batch classifier loss: 0.194073; batch adversarial loss: 0.445346\n",
      "epoch 43; iter: 0; batch classifier loss: 0.177391; batch adversarial loss: 0.465744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.162211; batch adversarial loss: 0.474033\n",
      "epoch 45; iter: 0; batch classifier loss: 0.214585; batch adversarial loss: 0.493388\n",
      "epoch 46; iter: 0; batch classifier loss: 0.185272; batch adversarial loss: 0.509990\n",
      "epoch 47; iter: 0; batch classifier loss: 0.235634; batch adversarial loss: 0.503105\n",
      "epoch 48; iter: 0; batch classifier loss: 0.238506; batch adversarial loss: 0.415468\n",
      "epoch 49; iter: 0; batch classifier loss: 0.128352; batch adversarial loss: 0.480190\n",
      "epoch 50; iter: 0; batch classifier loss: 0.216716; batch adversarial loss: 0.492032\n",
      "epoch 51; iter: 0; batch classifier loss: 0.188255; batch adversarial loss: 0.501005\n",
      "epoch 52; iter: 0; batch classifier loss: 0.234324; batch adversarial loss: 0.426482\n",
      "epoch 53; iter: 0; batch classifier loss: 0.138910; batch adversarial loss: 0.425484\n",
      "epoch 54; iter: 0; batch classifier loss: 0.152790; batch adversarial loss: 0.446906\n",
      "epoch 55; iter: 0; batch classifier loss: 0.205859; batch adversarial loss: 0.543999\n",
      "epoch 56; iter: 0; batch classifier loss: 0.180061; batch adversarial loss: 0.563780\n",
      "epoch 57; iter: 0; batch classifier loss: 0.228280; batch adversarial loss: 0.435869\n",
      "epoch 58; iter: 0; batch classifier loss: 0.241087; batch adversarial loss: 0.437775\n",
      "epoch 59; iter: 0; batch classifier loss: 0.242244; batch adversarial loss: 0.460311\n",
      "epoch 60; iter: 0; batch classifier loss: 0.250058; batch adversarial loss: 0.461777\n",
      "epoch 61; iter: 0; batch classifier loss: 0.228802; batch adversarial loss: 0.566837\n",
      "epoch 62; iter: 0; batch classifier loss: 0.197830; batch adversarial loss: 0.471273\n",
      "epoch 63; iter: 0; batch classifier loss: 0.195843; batch adversarial loss: 0.484422\n",
      "epoch 64; iter: 0; batch classifier loss: 0.231926; batch adversarial loss: 0.507199\n",
      "epoch 65; iter: 0; batch classifier loss: 0.237724; batch adversarial loss: 0.457793\n",
      "epoch 66; iter: 0; batch classifier loss: 0.183942; batch adversarial loss: 0.436469\n",
      "epoch 67; iter: 0; batch classifier loss: 0.202247; batch adversarial loss: 0.482164\n",
      "epoch 68; iter: 0; batch classifier loss: 0.215734; batch adversarial loss: 0.459048\n",
      "epoch 69; iter: 0; batch classifier loss: 0.237220; batch adversarial loss: 0.434916\n",
      "epoch 70; iter: 0; batch classifier loss: 0.117140; batch adversarial loss: 0.483075\n",
      "epoch 71; iter: 0; batch classifier loss: 0.159979; batch adversarial loss: 0.458979\n",
      "epoch 72; iter: 0; batch classifier loss: 0.163170; batch adversarial loss: 0.470641\n",
      "epoch 73; iter: 0; batch classifier loss: 0.317383; batch adversarial loss: 0.482807\n",
      "epoch 74; iter: 0; batch classifier loss: 0.197751; batch adversarial loss: 0.483969\n",
      "epoch 75; iter: 0; batch classifier loss: 0.183666; batch adversarial loss: 0.446639\n",
      "epoch 76; iter: 0; batch classifier loss: 0.204844; batch adversarial loss: 0.507707\n",
      "epoch 77; iter: 0; batch classifier loss: 0.198179; batch adversarial loss: 0.446930\n",
      "epoch 78; iter: 0; batch classifier loss: 0.152248; batch adversarial loss: 0.459130\n",
      "epoch 79; iter: 0; batch classifier loss: 0.194271; batch adversarial loss: 0.557168\n",
      "epoch 80; iter: 0; batch classifier loss: 0.173149; batch adversarial loss: 0.481556\n",
      "epoch 81; iter: 0; batch classifier loss: 0.137029; batch adversarial loss: 0.482672\n",
      "epoch 82; iter: 0; batch classifier loss: 0.212285; batch adversarial loss: 0.494072\n",
      "epoch 83; iter: 0; batch classifier loss: 0.167714; batch adversarial loss: 0.422128\n",
      "epoch 84; iter: 0; batch classifier loss: 0.171617; batch adversarial loss: 0.580021\n",
      "epoch 85; iter: 0; batch classifier loss: 0.202439; batch adversarial loss: 0.410955\n",
      "epoch 86; iter: 0; batch classifier loss: 0.258499; batch adversarial loss: 0.409881\n",
      "epoch 87; iter: 0; batch classifier loss: 0.167789; batch adversarial loss: 0.459003\n",
      "epoch 88; iter: 0; batch classifier loss: 0.128540; batch adversarial loss: 0.470112\n",
      "epoch 89; iter: 0; batch classifier loss: 0.093916; batch adversarial loss: 0.360548\n",
      "epoch 90; iter: 0; batch classifier loss: 0.133769; batch adversarial loss: 0.506980\n",
      "epoch 91; iter: 0; batch classifier loss: 0.164101; batch adversarial loss: 0.420474\n",
      "epoch 92; iter: 0; batch classifier loss: 0.182958; batch adversarial loss: 0.473423\n",
      "epoch 93; iter: 0; batch classifier loss: 0.177054; batch adversarial loss: 0.470119\n",
      "epoch 94; iter: 0; batch classifier loss: 0.221498; batch adversarial loss: 0.520184\n",
      "epoch 95; iter: 0; batch classifier loss: 0.178341; batch adversarial loss: 0.371691\n",
      "epoch 96; iter: 0; batch classifier loss: 0.229784; batch adversarial loss: 0.423704\n",
      "epoch 97; iter: 0; batch classifier loss: 0.221983; batch adversarial loss: 0.446751\n",
      "epoch 98; iter: 0; batch classifier loss: 0.160295; batch adversarial loss: 0.496002\n",
      "epoch 99; iter: 0; batch classifier loss: 0.196397; batch adversarial loss: 0.420656\n",
      "epoch 100; iter: 0; batch classifier loss: 0.236535; batch adversarial loss: 0.400328\n",
      "epoch 101; iter: 0; batch classifier loss: 0.246493; batch adversarial loss: 0.436086\n",
      "epoch 102; iter: 0; batch classifier loss: 0.190597; batch adversarial loss: 0.375341\n",
      "epoch 103; iter: 0; batch classifier loss: 0.196701; batch adversarial loss: 0.424339\n",
      "epoch 104; iter: 0; batch classifier loss: 0.192846; batch adversarial loss: 0.532495\n",
      "epoch 105; iter: 0; batch classifier loss: 0.220681; batch adversarial loss: 0.580119\n",
      "epoch 106; iter: 0; batch classifier loss: 0.214299; batch adversarial loss: 0.470488\n",
      "epoch 107; iter: 0; batch classifier loss: 0.246697; batch adversarial loss: 0.471180\n",
      "epoch 108; iter: 0; batch classifier loss: 0.145097; batch adversarial loss: 0.470480\n",
      "epoch 109; iter: 0; batch classifier loss: 0.202295; batch adversarial loss: 0.505632\n",
      "epoch 110; iter: 0; batch classifier loss: 0.185666; batch adversarial loss: 0.532319\n",
      "epoch 111; iter: 0; batch classifier loss: 0.207626; batch adversarial loss: 0.434491\n",
      "epoch 112; iter: 0; batch classifier loss: 0.197616; batch adversarial loss: 0.483166\n",
      "epoch 113; iter: 0; batch classifier loss: 0.173077; batch adversarial loss: 0.507276\n",
      "epoch 114; iter: 0; batch classifier loss: 0.174597; batch adversarial loss: 0.543878\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043911; batch adversarial loss: 0.493216\n",
      "epoch 116; iter: 0; batch classifier loss: 0.094905; batch adversarial loss: 0.516826\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042959; batch adversarial loss: 0.443089\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063109; batch adversarial loss: 0.523598\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037369; batch adversarial loss: 0.517495\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045542; batch adversarial loss: 0.416837\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032240; batch adversarial loss: 0.449160\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048194; batch adversarial loss: 0.518500\n",
      "epoch 123; iter: 0; batch classifier loss: 0.068797; batch adversarial loss: 0.458497\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042395; batch adversarial loss: 0.399221\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037514; batch adversarial loss: 0.326086\n",
      "epoch 126; iter: 0; batch classifier loss: 0.064587; batch adversarial loss: 0.540537\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033006; batch adversarial loss: 0.411631\n",
      "epoch 128; iter: 0; batch classifier loss: 0.057765; batch adversarial loss: 0.452865\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042839; batch adversarial loss: 0.515020\n",
      "epoch 130; iter: 0; batch classifier loss: 0.070029; batch adversarial loss: 0.459756\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050734; batch adversarial loss: 0.436354\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032623; batch adversarial loss: 0.435312\n",
      "epoch 133; iter: 0; batch classifier loss: 0.091834; batch adversarial loss: 0.416460\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040710; batch adversarial loss: 0.500096\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038002; batch adversarial loss: 0.414490\n",
      "epoch 136; iter: 0; batch classifier loss: 0.072263; batch adversarial loss: 0.536090\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025402; batch adversarial loss: 0.418351\n",
      "epoch 138; iter: 0; batch classifier loss: 0.080573; batch adversarial loss: 0.485794\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050935; batch adversarial loss: 0.468344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.066942; batch adversarial loss: 0.463014\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044289; batch adversarial loss: 0.395189\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041629; batch adversarial loss: 0.402641\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042147; batch adversarial loss: 0.462584\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037811; batch adversarial loss: 0.550975\n",
      "epoch 145; iter: 0; batch classifier loss: 0.068176; batch adversarial loss: 0.440618\n",
      "epoch 146; iter: 0; batch classifier loss: 0.046504; batch adversarial loss: 0.440729\n",
      "epoch 147; iter: 0; batch classifier loss: 0.064594; batch adversarial loss: 0.352595\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045839; batch adversarial loss: 0.359454\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036275; batch adversarial loss: 0.430940\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052138; batch adversarial loss: 0.429801\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031737; batch adversarial loss: 0.424379\n",
      "epoch 152; iter: 0; batch classifier loss: 0.056271; batch adversarial loss: 0.481134\n",
      "epoch 153; iter: 0; batch classifier loss: 0.063247; batch adversarial loss: 0.380711\n",
      "epoch 154; iter: 0; batch classifier loss: 0.072385; batch adversarial loss: 0.401847\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044679; batch adversarial loss: 0.465524\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045831; batch adversarial loss: 0.436992\n",
      "epoch 157; iter: 0; batch classifier loss: 0.050465; batch adversarial loss: 0.458382\n",
      "epoch 158; iter: 0; batch classifier loss: 0.061051; batch adversarial loss: 0.452465\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045481; batch adversarial loss: 0.467223\n",
      "epoch 160; iter: 0; batch classifier loss: 0.064628; batch adversarial loss: 0.399742\n",
      "epoch 161; iter: 0; batch classifier loss: 0.078826; batch adversarial loss: 0.418867\n",
      "epoch 162; iter: 0; batch classifier loss: 0.071101; batch adversarial loss: 0.447859\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036878; batch adversarial loss: 0.480083\n",
      "epoch 164; iter: 0; batch classifier loss: 0.052902; batch adversarial loss: 0.432968\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030150; batch adversarial loss: 0.386667\n",
      "epoch 166; iter: 0; batch classifier loss: 0.061673; batch adversarial loss: 0.438349\n",
      "epoch 167; iter: 0; batch classifier loss: 0.049584; batch adversarial loss: 0.458695\n",
      "epoch 168; iter: 0; batch classifier loss: 0.048903; batch adversarial loss: 0.377414\n",
      "epoch 169; iter: 0; batch classifier loss: 0.053694; batch adversarial loss: 0.513160\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035946; batch adversarial loss: 0.432219\n",
      "epoch 171; iter: 0; batch classifier loss: 0.034847; batch adversarial loss: 0.440642\n",
      "epoch 172; iter: 0; batch classifier loss: 0.048830; batch adversarial loss: 0.434169\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034505; batch adversarial loss: 0.405319\n",
      "epoch 174; iter: 0; batch classifier loss: 0.045533; batch adversarial loss: 0.363947\n",
      "epoch 175; iter: 0; batch classifier loss: 0.063055; batch adversarial loss: 0.549501\n",
      "epoch 176; iter: 0; batch classifier loss: 0.050708; batch adversarial loss: 0.386363\n",
      "epoch 177; iter: 0; batch classifier loss: 0.074312; batch adversarial loss: 0.378253\n",
      "epoch 178; iter: 0; batch classifier loss: 0.069644; batch adversarial loss: 0.402462\n",
      "epoch 179; iter: 0; batch classifier loss: 0.048680; batch adversarial loss: 0.406362\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039182; batch adversarial loss: 0.438067\n",
      "epoch 181; iter: 0; batch classifier loss: 0.053877; batch adversarial loss: 0.394884\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023778; batch adversarial loss: 0.372620\n",
      "epoch 183; iter: 0; batch classifier loss: 0.049040; batch adversarial loss: 0.448036\n",
      "epoch 184; iter: 0; batch classifier loss: 0.058786; batch adversarial loss: 0.503628\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028557; batch adversarial loss: 0.424457\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041894; batch adversarial loss: 0.527487\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030689; batch adversarial loss: 0.497822\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040525; batch adversarial loss: 0.456925\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036058; batch adversarial loss: 0.455826\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031419; batch adversarial loss: 0.434421\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033464; batch adversarial loss: 0.441173\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040724; batch adversarial loss: 0.416144\n",
      "epoch 193; iter: 0; batch classifier loss: 0.087901; batch adversarial loss: 0.461659\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034872; batch adversarial loss: 0.422731\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031843; batch adversarial loss: 0.389808\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032316; batch adversarial loss: 0.459392\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032253; batch adversarial loss: 0.448744\n",
      "epoch 198; iter: 0; batch classifier loss: 0.049035; batch adversarial loss: 0.460370\n",
      "epoch 199; iter: 0; batch classifier loss: 0.039897; batch adversarial loss: 0.399985\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688636; batch adversarial loss: 0.726584\n",
      "epoch 1; iter: 0; batch classifier loss: 0.489856; batch adversarial loss: 0.673001\n",
      "epoch 2; iter: 0; batch classifier loss: 0.420234; batch adversarial loss: 0.642223\n",
      "epoch 3; iter: 0; batch classifier loss: 0.348135; batch adversarial loss: 0.620195\n",
      "epoch 4; iter: 0; batch classifier loss: 0.426338; batch adversarial loss: 0.603835\n",
      "epoch 5; iter: 0; batch classifier loss: 0.349290; batch adversarial loss: 0.580135\n",
      "epoch 6; iter: 0; batch classifier loss: 0.364666; batch adversarial loss: 0.564140\n",
      "epoch 7; iter: 0; batch classifier loss: 0.345607; batch adversarial loss: 0.572659\n",
      "epoch 8; iter: 0; batch classifier loss: 0.338270; batch adversarial loss: 0.509731\n",
      "epoch 9; iter: 0; batch classifier loss: 0.379759; batch adversarial loss: 0.528666\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358684; batch adversarial loss: 0.516540\n",
      "epoch 11; iter: 0; batch classifier loss: 0.346309; batch adversarial loss: 0.553400\n",
      "epoch 12; iter: 0; batch classifier loss: 0.335556; batch adversarial loss: 0.487118\n",
      "epoch 13; iter: 0; batch classifier loss: 0.357397; batch adversarial loss: 0.526660\n",
      "epoch 14; iter: 0; batch classifier loss: 0.255072; batch adversarial loss: 0.586935\n",
      "epoch 15; iter: 0; batch classifier loss: 0.306062; batch adversarial loss: 0.542302\n",
      "epoch 16; iter: 0; batch classifier loss: 0.336365; batch adversarial loss: 0.487448\n",
      "epoch 17; iter: 0; batch classifier loss: 0.267871; batch adversarial loss: 0.563033\n",
      "epoch 18; iter: 0; batch classifier loss: 0.325105; batch adversarial loss: 0.520976\n",
      "epoch 19; iter: 0; batch classifier loss: 0.365153; batch adversarial loss: 0.496254\n",
      "epoch 20; iter: 0; batch classifier loss: 0.375438; batch adversarial loss: 0.433192\n",
      "epoch 21; iter: 0; batch classifier loss: 0.288627; batch adversarial loss: 0.524444\n",
      "epoch 22; iter: 0; batch classifier loss: 0.290816; batch adversarial loss: 0.474108\n",
      "epoch 23; iter: 0; batch classifier loss: 0.273298; batch adversarial loss: 0.509691\n",
      "epoch 24; iter: 0; batch classifier loss: 0.307449; batch adversarial loss: 0.412169\n",
      "epoch 25; iter: 0; batch classifier loss: 0.203755; batch adversarial loss: 0.475330\n",
      "epoch 26; iter: 0; batch classifier loss: 0.203665; batch adversarial loss: 0.568124\n",
      "epoch 27; iter: 0; batch classifier loss: 0.279338; batch adversarial loss: 0.440452\n",
      "epoch 28; iter: 0; batch classifier loss: 0.227425; batch adversarial loss: 0.570054\n",
      "epoch 29; iter: 0; batch classifier loss: 0.270260; batch adversarial loss: 0.431067\n",
      "epoch 30; iter: 0; batch classifier loss: 0.219496; batch adversarial loss: 0.459011\n",
      "epoch 31; iter: 0; batch classifier loss: 0.193016; batch adversarial loss: 0.461892\n",
      "epoch 32; iter: 0; batch classifier loss: 0.208653; batch adversarial loss: 0.458178\n",
      "epoch 33; iter: 0; batch classifier loss: 0.217338; batch adversarial loss: 0.485423\n",
      "epoch 34; iter: 0; batch classifier loss: 0.207337; batch adversarial loss: 0.467730\n",
      "epoch 35; iter: 0; batch classifier loss: 0.237298; batch adversarial loss: 0.499295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.193141; batch adversarial loss: 0.502270\n",
      "epoch 37; iter: 0; batch classifier loss: 0.234782; batch adversarial loss: 0.454957\n",
      "epoch 38; iter: 0; batch classifier loss: 0.207026; batch adversarial loss: 0.440607\n",
      "epoch 39; iter: 0; batch classifier loss: 0.167165; batch adversarial loss: 0.417146\n",
      "epoch 40; iter: 0; batch classifier loss: 0.212930; batch adversarial loss: 0.452377\n",
      "epoch 41; iter: 0; batch classifier loss: 0.276868; batch adversarial loss: 0.425897\n",
      "epoch 42; iter: 0; batch classifier loss: 0.232886; batch adversarial loss: 0.456480\n",
      "epoch 43; iter: 0; batch classifier loss: 0.208110; batch adversarial loss: 0.336646\n",
      "epoch 44; iter: 0; batch classifier loss: 0.233217; batch adversarial loss: 0.555145\n",
      "epoch 45; iter: 0; batch classifier loss: 0.245675; batch adversarial loss: 0.426914\n",
      "epoch 46; iter: 0; batch classifier loss: 0.192495; batch adversarial loss: 0.405734\n",
      "epoch 47; iter: 0; batch classifier loss: 0.181080; batch adversarial loss: 0.455765\n",
      "epoch 48; iter: 0; batch classifier loss: 0.167938; batch adversarial loss: 0.474041\n",
      "epoch 49; iter: 0; batch classifier loss: 0.149869; batch adversarial loss: 0.480467\n",
      "epoch 50; iter: 0; batch classifier loss: 0.186595; batch adversarial loss: 0.444745\n",
      "epoch 51; iter: 0; batch classifier loss: 0.189837; batch adversarial loss: 0.473353\n",
      "epoch 52; iter: 0; batch classifier loss: 0.220685; batch adversarial loss: 0.410665\n",
      "epoch 53; iter: 0; batch classifier loss: 0.171494; batch adversarial loss: 0.381180\n",
      "epoch 54; iter: 0; batch classifier loss: 0.196381; batch adversarial loss: 0.404392\n",
      "epoch 55; iter: 0; batch classifier loss: 0.207617; batch adversarial loss: 0.531283\n",
      "epoch 56; iter: 0; batch classifier loss: 0.229380; batch adversarial loss: 0.412040\n",
      "epoch 57; iter: 0; batch classifier loss: 0.221682; batch adversarial loss: 0.460687\n",
      "epoch 58; iter: 0; batch classifier loss: 0.124250; batch adversarial loss: 0.447634\n",
      "epoch 59; iter: 0; batch classifier loss: 0.186793; batch adversarial loss: 0.508504\n",
      "epoch 60; iter: 0; batch classifier loss: 0.251246; batch adversarial loss: 0.375780\n",
      "epoch 61; iter: 0; batch classifier loss: 0.189500; batch adversarial loss: 0.431701\n",
      "epoch 62; iter: 0; batch classifier loss: 0.268933; batch adversarial loss: 0.496398\n",
      "epoch 63; iter: 0; batch classifier loss: 0.295498; batch adversarial loss: 0.483270\n",
      "epoch 64; iter: 0; batch classifier loss: 0.249767; batch adversarial loss: 0.481645\n",
      "epoch 65; iter: 0; batch classifier loss: 0.205449; batch adversarial loss: 0.457935\n",
      "epoch 66; iter: 0; batch classifier loss: 0.174107; batch adversarial loss: 0.505539\n",
      "epoch 67; iter: 0; batch classifier loss: 0.244460; batch adversarial loss: 0.531020\n",
      "epoch 68; iter: 0; batch classifier loss: 0.221110; batch adversarial loss: 0.447273\n",
      "epoch 69; iter: 0; batch classifier loss: 0.168796; batch adversarial loss: 0.387529\n",
      "epoch 70; iter: 0; batch classifier loss: 0.271587; batch adversarial loss: 0.386917\n",
      "epoch 71; iter: 0; batch classifier loss: 0.215747; batch adversarial loss: 0.435048\n",
      "epoch 72; iter: 0; batch classifier loss: 0.186855; batch adversarial loss: 0.386216\n",
      "epoch 73; iter: 0; batch classifier loss: 0.189508; batch adversarial loss: 0.470028\n",
      "epoch 74; iter: 0; batch classifier loss: 0.179434; batch adversarial loss: 0.448511\n",
      "epoch 75; iter: 0; batch classifier loss: 0.270945; batch adversarial loss: 0.470738\n",
      "epoch 76; iter: 0; batch classifier loss: 0.157828; batch adversarial loss: 0.411275\n",
      "epoch 77; iter: 0; batch classifier loss: 0.181814; batch adversarial loss: 0.456914\n",
      "epoch 78; iter: 0; batch classifier loss: 0.171996; batch adversarial loss: 0.433443\n",
      "epoch 79; iter: 0; batch classifier loss: 0.211586; batch adversarial loss: 0.470693\n",
      "epoch 80; iter: 0; batch classifier loss: 0.216625; batch adversarial loss: 0.457591\n",
      "epoch 81; iter: 0; batch classifier loss: 0.233105; batch adversarial loss: 0.458330\n",
      "epoch 82; iter: 0; batch classifier loss: 0.183374; batch adversarial loss: 0.529662\n",
      "epoch 83; iter: 0; batch classifier loss: 0.224548; batch adversarial loss: 0.496211\n",
      "epoch 84; iter: 0; batch classifier loss: 0.253030; batch adversarial loss: 0.531138\n",
      "epoch 85; iter: 0; batch classifier loss: 0.151894; batch adversarial loss: 0.386299\n",
      "epoch 86; iter: 0; batch classifier loss: 0.251832; batch adversarial loss: 0.483757\n",
      "epoch 87; iter: 0; batch classifier loss: 0.186424; batch adversarial loss: 0.446814\n",
      "epoch 88; iter: 0; batch classifier loss: 0.195900; batch adversarial loss: 0.543532\n",
      "epoch 89; iter: 0; batch classifier loss: 0.288142; batch adversarial loss: 0.362392\n",
      "epoch 90; iter: 0; batch classifier loss: 0.205152; batch adversarial loss: 0.446825\n",
      "epoch 91; iter: 0; batch classifier loss: 0.155630; batch adversarial loss: 0.470739\n",
      "epoch 92; iter: 0; batch classifier loss: 0.212510; batch adversarial loss: 0.531533\n",
      "epoch 93; iter: 0; batch classifier loss: 0.154087; batch adversarial loss: 0.531671\n",
      "epoch 94; iter: 0; batch classifier loss: 0.106569; batch adversarial loss: 0.483307\n",
      "epoch 95; iter: 0; batch classifier loss: 0.153350; batch adversarial loss: 0.396210\n",
      "epoch 96; iter: 0; batch classifier loss: 0.199002; batch adversarial loss: 0.546326\n",
      "epoch 97; iter: 0; batch classifier loss: 0.279435; batch adversarial loss: 0.409599\n",
      "epoch 98; iter: 0; batch classifier loss: 0.175941; batch adversarial loss: 0.434399\n",
      "epoch 99; iter: 0; batch classifier loss: 0.147226; batch adversarial loss: 0.456951\n",
      "epoch 100; iter: 0; batch classifier loss: 0.128172; batch adversarial loss: 0.544740\n",
      "epoch 101; iter: 0; batch classifier loss: 0.120982; batch adversarial loss: 0.456876\n",
      "epoch 102; iter: 0; batch classifier loss: 0.141180; batch adversarial loss: 0.499234\n",
      "epoch 103; iter: 0; batch classifier loss: 0.124088; batch adversarial loss: 0.395191\n",
      "epoch 104; iter: 0; batch classifier loss: 0.106298; batch adversarial loss: 0.586829\n",
      "epoch 105; iter: 0; batch classifier loss: 0.082060; batch adversarial loss: 0.501037\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039771; batch adversarial loss: 0.506990\n",
      "epoch 107; iter: 0; batch classifier loss: 0.083026; batch adversarial loss: 0.501999\n",
      "epoch 108; iter: 0; batch classifier loss: 0.073005; batch adversarial loss: 0.527316\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051402; batch adversarial loss: 0.437982\n",
      "epoch 110; iter: 0; batch classifier loss: 0.056774; batch adversarial loss: 0.484844\n",
      "epoch 111; iter: 0; batch classifier loss: 0.097923; batch adversarial loss: 0.394832\n",
      "epoch 112; iter: 0; batch classifier loss: 0.072030; batch adversarial loss: 0.493194\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027448; batch adversarial loss: 0.494677\n",
      "epoch 114; iter: 0; batch classifier loss: 0.025865; batch adversarial loss: 0.453904\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041752; batch adversarial loss: 0.481127\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050836; batch adversarial loss: 0.362155\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040894; batch adversarial loss: 0.522001\n",
      "epoch 118; iter: 0; batch classifier loss: 0.053465; batch adversarial loss: 0.340057\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036157; batch adversarial loss: 0.552064\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050057; batch adversarial loss: 0.383570\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038828; batch adversarial loss: 0.464211\n",
      "epoch 122; iter: 0; batch classifier loss: 0.060572; batch adversarial loss: 0.359322\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044789; batch adversarial loss: 0.406099\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030499; batch adversarial loss: 0.484635\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044284; batch adversarial loss: 0.422771\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032908; batch adversarial loss: 0.373254\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024856; batch adversarial loss: 0.446678\n",
      "epoch 128; iter: 0; batch classifier loss: 0.048012; batch adversarial loss: 0.575188\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025975; batch adversarial loss: 0.447748\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037908; batch adversarial loss: 0.456319\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024275; batch adversarial loss: 0.420654\n",
      "epoch 132; iter: 0; batch classifier loss: 0.011342; batch adversarial loss: 0.376532\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021857; batch adversarial loss: 0.463778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.043056; batch adversarial loss: 0.529176\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020233; batch adversarial loss: 0.424108\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030690; batch adversarial loss: 0.453020\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022129; batch adversarial loss: 0.340758\n",
      "epoch 138; iter: 0; batch classifier loss: 0.010260; batch adversarial loss: 0.427394\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031581; batch adversarial loss: 0.509607\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037222; batch adversarial loss: 0.424379\n",
      "epoch 141; iter: 0; batch classifier loss: 0.057090; batch adversarial loss: 0.489995\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019630; batch adversarial loss: 0.445291\n",
      "epoch 143; iter: 0; batch classifier loss: 0.056084; batch adversarial loss: 0.454866\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012129; batch adversarial loss: 0.445869\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019433; batch adversarial loss: 0.425473\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028071; batch adversarial loss: 0.442640\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040351; batch adversarial loss: 0.405704\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034287; batch adversarial loss: 0.383719\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026950; batch adversarial loss: 0.532462\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025601; batch adversarial loss: 0.495859\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034200; batch adversarial loss: 0.511668\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028520; batch adversarial loss: 0.500628\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017253; batch adversarial loss: 0.553532\n",
      "epoch 154; iter: 0; batch classifier loss: 0.047775; batch adversarial loss: 0.391147\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031493; batch adversarial loss: 0.390946\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021028; batch adversarial loss: 0.411383\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036126; batch adversarial loss: 0.545721\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032352; batch adversarial loss: 0.390576\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016529; batch adversarial loss: 0.365779\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019435; batch adversarial loss: 0.450942\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017434; batch adversarial loss: 0.507585\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016724; batch adversarial loss: 0.534067\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009532; batch adversarial loss: 0.430500\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022124; batch adversarial loss: 0.476942\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012621; batch adversarial loss: 0.470932\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012498; batch adversarial loss: 0.395644\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016845; batch adversarial loss: 0.523951\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010886; batch adversarial loss: 0.506545\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006250; batch adversarial loss: 0.515968\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025358; batch adversarial loss: 0.449667\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023313; batch adversarial loss: 0.490028\n",
      "epoch 172; iter: 0; batch classifier loss: 0.006228; batch adversarial loss: 0.522201\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034727; batch adversarial loss: 0.400769\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029332; batch adversarial loss: 0.485724\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023198; batch adversarial loss: 0.541390\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027484; batch adversarial loss: 0.507045\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042733; batch adversarial loss: 0.446029\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012185; batch adversarial loss: 0.475678\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011233; batch adversarial loss: 0.515507\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020327; batch adversarial loss: 0.532030\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035172; batch adversarial loss: 0.351656\n",
      "epoch 182; iter: 0; batch classifier loss: 0.041411; batch adversarial loss: 0.473167\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006547; batch adversarial loss: 0.468390\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012162; batch adversarial loss: 0.413516\n",
      "epoch 185; iter: 0; batch classifier loss: 0.004010; batch adversarial loss: 0.413415\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023035; batch adversarial loss: 0.484060\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007549; batch adversarial loss: 0.445493\n",
      "epoch 188; iter: 0; batch classifier loss: 0.004837; batch adversarial loss: 0.380130\n",
      "epoch 189; iter: 0; batch classifier loss: 0.003977; batch adversarial loss: 0.497693\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037580; batch adversarial loss: 0.446253\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015275; batch adversarial loss: 0.494048\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028920; batch adversarial loss: 0.464448\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005190; batch adversarial loss: 0.412606\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022461; batch adversarial loss: 0.543242\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008923; batch adversarial loss: 0.557353\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010378; batch adversarial loss: 0.420477\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004816; batch adversarial loss: 0.516703\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031619; batch adversarial loss: 0.457804\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007778; batch adversarial loss: 0.455595\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677362; batch adversarial loss: 0.823928\n",
      "epoch 1; iter: 0; batch classifier loss: 0.444580; batch adversarial loss: 0.803419\n",
      "epoch 2; iter: 0; batch classifier loss: 0.408523; batch adversarial loss: 0.744396\n",
      "epoch 3; iter: 0; batch classifier loss: 0.376343; batch adversarial loss: 0.705021\n",
      "epoch 4; iter: 0; batch classifier loss: 0.333571; batch adversarial loss: 0.660519\n",
      "epoch 5; iter: 0; batch classifier loss: 0.262938; batch adversarial loss: 0.620128\n",
      "epoch 6; iter: 0; batch classifier loss: 0.289932; batch adversarial loss: 0.593234\n",
      "epoch 7; iter: 0; batch classifier loss: 0.328621; batch adversarial loss: 0.576202\n",
      "epoch 8; iter: 0; batch classifier loss: 0.230350; batch adversarial loss: 0.586187\n",
      "epoch 9; iter: 0; batch classifier loss: 0.293751; batch adversarial loss: 0.576166\n",
      "epoch 10; iter: 0; batch classifier loss: 0.277580; batch adversarial loss: 0.525652\n",
      "epoch 11; iter: 0; batch classifier loss: 0.298227; batch adversarial loss: 0.516261\n",
      "epoch 12; iter: 0; batch classifier loss: 0.217252; batch adversarial loss: 0.494739\n",
      "epoch 13; iter: 0; batch classifier loss: 0.250969; batch adversarial loss: 0.489428\n",
      "epoch 14; iter: 0; batch classifier loss: 0.217598; batch adversarial loss: 0.513582\n",
      "epoch 15; iter: 0; batch classifier loss: 0.163674; batch adversarial loss: 0.513777\n",
      "epoch 16; iter: 0; batch classifier loss: 0.191541; batch adversarial loss: 0.483415\n",
      "epoch 17; iter: 0; batch classifier loss: 0.206137; batch adversarial loss: 0.425388\n",
      "epoch 18; iter: 0; batch classifier loss: 0.122665; batch adversarial loss: 0.457019\n",
      "epoch 19; iter: 0; batch classifier loss: 0.198776; batch adversarial loss: 0.456942\n",
      "epoch 20; iter: 0; batch classifier loss: 0.186530; batch adversarial loss: 0.454819\n",
      "epoch 21; iter: 0; batch classifier loss: 0.194324; batch adversarial loss: 0.429767\n",
      "epoch 22; iter: 0; batch classifier loss: 0.212651; batch adversarial loss: 0.455268\n",
      "epoch 23; iter: 0; batch classifier loss: 0.140651; batch adversarial loss: 0.440492\n",
      "epoch 24; iter: 0; batch classifier loss: 0.095843; batch adversarial loss: 0.412807\n",
      "epoch 25; iter: 0; batch classifier loss: 0.096322; batch adversarial loss: 0.497918\n",
      "epoch 26; iter: 0; batch classifier loss: 0.128607; batch adversarial loss: 0.456847\n",
      "epoch 27; iter: 0; batch classifier loss: 0.125451; batch adversarial loss: 0.443715\n",
      "epoch 28; iter: 0; batch classifier loss: 0.195619; batch adversarial loss: 0.440757\n",
      "epoch 29; iter: 0; batch classifier loss: 0.121455; batch adversarial loss: 0.447537\n",
      "epoch 30; iter: 0; batch classifier loss: 0.119909; batch adversarial loss: 0.417865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31; iter: 0; batch classifier loss: 0.170246; batch adversarial loss: 0.467364\n",
      "epoch 32; iter: 0; batch classifier loss: 0.132297; batch adversarial loss: 0.421681\n",
      "epoch 33; iter: 0; batch classifier loss: 0.092225; batch adversarial loss: 0.496215\n",
      "epoch 34; iter: 0; batch classifier loss: 0.131376; batch adversarial loss: 0.556951\n",
      "epoch 35; iter: 0; batch classifier loss: 0.120501; batch adversarial loss: 0.418247\n",
      "epoch 36; iter: 0; batch classifier loss: 0.099704; batch adversarial loss: 0.481365\n",
      "epoch 37; iter: 0; batch classifier loss: 0.143086; batch adversarial loss: 0.455835\n",
      "epoch 38; iter: 0; batch classifier loss: 0.113326; batch adversarial loss: 0.402438\n",
      "epoch 39; iter: 0; batch classifier loss: 0.088813; batch adversarial loss: 0.369661\n",
      "epoch 40; iter: 0; batch classifier loss: 0.097180; batch adversarial loss: 0.377984\n",
      "epoch 41; iter: 0; batch classifier loss: 0.161911; batch adversarial loss: 0.417431\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116104; batch adversarial loss: 0.434411\n",
      "epoch 43; iter: 0; batch classifier loss: 0.099041; batch adversarial loss: 0.441702\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105526; batch adversarial loss: 0.463614\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124077; batch adversarial loss: 0.405749\n",
      "epoch 46; iter: 0; batch classifier loss: 0.101607; batch adversarial loss: 0.437611\n",
      "epoch 47; iter: 0; batch classifier loss: 0.117787; batch adversarial loss: 0.416576\n",
      "epoch 48; iter: 0; batch classifier loss: 0.148912; batch adversarial loss: 0.476878\n",
      "epoch 49; iter: 0; batch classifier loss: 0.103503; batch adversarial loss: 0.466125\n",
      "epoch 50; iter: 0; batch classifier loss: 0.119735; batch adversarial loss: 0.527376\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083160; batch adversarial loss: 0.451066\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100441; batch adversarial loss: 0.500137\n",
      "epoch 53; iter: 0; batch classifier loss: 0.102962; batch adversarial loss: 0.430124\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114051; batch adversarial loss: 0.465841\n",
      "epoch 55; iter: 0; batch classifier loss: 0.078410; batch adversarial loss: 0.384138\n",
      "epoch 56; iter: 0; batch classifier loss: 0.078421; batch adversarial loss: 0.435191\n",
      "epoch 57; iter: 0; batch classifier loss: 0.110739; batch adversarial loss: 0.374992\n",
      "epoch 58; iter: 0; batch classifier loss: 0.108425; batch adversarial loss: 0.473846\n",
      "epoch 59; iter: 0; batch classifier loss: 0.100148; batch adversarial loss: 0.339388\n",
      "epoch 60; iter: 0; batch classifier loss: 0.064503; batch adversarial loss: 0.419338\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088163; batch adversarial loss: 0.398381\n",
      "epoch 62; iter: 0; batch classifier loss: 0.079092; batch adversarial loss: 0.483712\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085569; batch adversarial loss: 0.343036\n",
      "epoch 64; iter: 0; batch classifier loss: 0.135906; batch adversarial loss: 0.491010\n",
      "epoch 65; iter: 0; batch classifier loss: 0.084201; batch adversarial loss: 0.378812\n",
      "epoch 66; iter: 0; batch classifier loss: 0.067082; batch adversarial loss: 0.544696\n",
      "epoch 67; iter: 0; batch classifier loss: 0.134181; batch adversarial loss: 0.447865\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078458; batch adversarial loss: 0.481614\n",
      "epoch 69; iter: 0; batch classifier loss: 0.069922; batch adversarial loss: 0.440179\n",
      "epoch 70; iter: 0; batch classifier loss: 0.087474; batch adversarial loss: 0.490082\n",
      "epoch 71; iter: 0; batch classifier loss: 0.060120; batch adversarial loss: 0.377112\n",
      "epoch 72; iter: 0; batch classifier loss: 0.088529; batch adversarial loss: 0.456600\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068865; batch adversarial loss: 0.401036\n",
      "epoch 74; iter: 0; batch classifier loss: 0.098137; batch adversarial loss: 0.442171\n",
      "epoch 75; iter: 0; batch classifier loss: 0.110351; batch adversarial loss: 0.394884\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083640; batch adversarial loss: 0.465515\n",
      "epoch 77; iter: 0; batch classifier loss: 0.060637; batch adversarial loss: 0.435614\n",
      "epoch 78; iter: 0; batch classifier loss: 0.052574; batch adversarial loss: 0.536031\n",
      "epoch 79; iter: 0; batch classifier loss: 0.118477; batch adversarial loss: 0.495964\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088816; batch adversarial loss: 0.516017\n",
      "epoch 81; iter: 0; batch classifier loss: 0.061139; batch adversarial loss: 0.447830\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059874; batch adversarial loss: 0.438024\n",
      "epoch 83; iter: 0; batch classifier loss: 0.103624; batch adversarial loss: 0.476966\n",
      "epoch 84; iter: 0; batch classifier loss: 0.087851; batch adversarial loss: 0.425850\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055880; batch adversarial loss: 0.412585\n",
      "epoch 86; iter: 0; batch classifier loss: 0.079009; batch adversarial loss: 0.472504\n",
      "epoch 87; iter: 0; batch classifier loss: 0.060124; batch adversarial loss: 0.372891\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075387; batch adversarial loss: 0.384613\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065077; batch adversarial loss: 0.581101\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062830; batch adversarial loss: 0.446189\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060280; batch adversarial loss: 0.464562\n",
      "epoch 92; iter: 0; batch classifier loss: 0.101235; batch adversarial loss: 0.388029\n",
      "epoch 93; iter: 0; batch classifier loss: 0.110552; batch adversarial loss: 0.463431\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062050; batch adversarial loss: 0.409168\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077225; batch adversarial loss: 0.390333\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062641; batch adversarial loss: 0.455715\n",
      "epoch 97; iter: 0; batch classifier loss: 0.083534; batch adversarial loss: 0.549285\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046675; batch adversarial loss: 0.380897\n",
      "epoch 99; iter: 0; batch classifier loss: 0.086141; batch adversarial loss: 0.473270\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064020; batch adversarial loss: 0.472905\n",
      "epoch 101; iter: 0; batch classifier loss: 0.094625; batch adversarial loss: 0.451546\n",
      "epoch 102; iter: 0; batch classifier loss: 0.074154; batch adversarial loss: 0.402849\n",
      "epoch 103; iter: 0; batch classifier loss: 0.096883; batch adversarial loss: 0.428838\n",
      "epoch 104; iter: 0; batch classifier loss: 0.068542; batch adversarial loss: 0.428983\n",
      "epoch 105; iter: 0; batch classifier loss: 0.070922; batch adversarial loss: 0.462287\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041463; batch adversarial loss: 0.449372\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055078; batch adversarial loss: 0.430567\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060863; batch adversarial loss: 0.483843\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046712; batch adversarial loss: 0.509679\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048319; batch adversarial loss: 0.401389\n",
      "epoch 111; iter: 0; batch classifier loss: 0.070993; batch adversarial loss: 0.449493\n",
      "epoch 112; iter: 0; batch classifier loss: 0.064357; batch adversarial loss: 0.449749\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059178; batch adversarial loss: 0.485607\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043223; batch adversarial loss: 0.415636\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053633; batch adversarial loss: 0.364150\n",
      "epoch 116; iter: 0; batch classifier loss: 0.085579; batch adversarial loss: 0.497817\n",
      "epoch 117; iter: 0; batch classifier loss: 0.058455; batch adversarial loss: 0.453481\n",
      "epoch 118; iter: 0; batch classifier loss: 0.085452; batch adversarial loss: 0.383822\n",
      "epoch 119; iter: 0; batch classifier loss: 0.079056; batch adversarial loss: 0.440612\n",
      "epoch 120; iter: 0; batch classifier loss: 0.056494; batch adversarial loss: 0.540717\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043126; batch adversarial loss: 0.458075\n",
      "epoch 122; iter: 0; batch classifier loss: 0.073427; batch adversarial loss: 0.464163\n",
      "epoch 123; iter: 0; batch classifier loss: 0.058541; batch adversarial loss: 0.470730\n",
      "epoch 124; iter: 0; batch classifier loss: 0.071821; batch adversarial loss: 0.459500\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045235; batch adversarial loss: 0.417839\n",
      "epoch 126; iter: 0; batch classifier loss: 0.076001; batch adversarial loss: 0.402651\n",
      "epoch 127; iter: 0; batch classifier loss: 0.078918; batch adversarial loss: 0.422587\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033205; batch adversarial loss: 0.406692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.050600; batch adversarial loss: 0.398584\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024501; batch adversarial loss: 0.513314\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032213; batch adversarial loss: 0.388990\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036578; batch adversarial loss: 0.457356\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045843; batch adversarial loss: 0.386738\n",
      "epoch 134; iter: 0; batch classifier loss: 0.067077; batch adversarial loss: 0.411895\n",
      "epoch 135; iter: 0; batch classifier loss: 0.067933; batch adversarial loss: 0.488171\n",
      "epoch 136; iter: 0; batch classifier loss: 0.062410; batch adversarial loss: 0.442356\n",
      "epoch 137; iter: 0; batch classifier loss: 0.047708; batch adversarial loss: 0.432700\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038365; batch adversarial loss: 0.445857\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037168; batch adversarial loss: 0.450875\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032591; batch adversarial loss: 0.385527\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035685; batch adversarial loss: 0.416480\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043059; batch adversarial loss: 0.442012\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032264; batch adversarial loss: 0.437801\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029678; batch adversarial loss: 0.445701\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045120; batch adversarial loss: 0.435390\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028344; batch adversarial loss: 0.507167\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035737; batch adversarial loss: 0.545640\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021919; batch adversarial loss: 0.511088\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014677; batch adversarial loss: 0.442091\n",
      "epoch 150; iter: 0; batch classifier loss: 0.055532; batch adversarial loss: 0.493749\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020217; batch adversarial loss: 0.454989\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038724; batch adversarial loss: 0.450138\n",
      "epoch 153; iter: 0; batch classifier loss: 0.037537; batch adversarial loss: 0.498192\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025301; batch adversarial loss: 0.575847\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030364; batch adversarial loss: 0.459045\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022257; batch adversarial loss: 0.428935\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032244; batch adversarial loss: 0.483337\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014973; batch adversarial loss: 0.465752\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015783; batch adversarial loss: 0.526267\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026789; batch adversarial loss: 0.469036\n",
      "epoch 161; iter: 0; batch classifier loss: 0.050901; batch adversarial loss: 0.502313\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029469; batch adversarial loss: 0.390744\n",
      "epoch 163; iter: 0; batch classifier loss: 0.069276; batch adversarial loss: 0.486053\n",
      "epoch 164; iter: 0; batch classifier loss: 0.045929; batch adversarial loss: 0.476790\n",
      "epoch 165; iter: 0; batch classifier loss: 0.059373; batch adversarial loss: 0.650936\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031678; batch adversarial loss: 0.424003\n",
      "epoch 167; iter: 0; batch classifier loss: 0.100084; batch adversarial loss: 0.554230\n",
      "epoch 168; iter: 0; batch classifier loss: 0.085524; batch adversarial loss: 0.681622\n",
      "epoch 169; iter: 0; batch classifier loss: 0.123125; batch adversarial loss: 0.614769\n",
      "epoch 170; iter: 0; batch classifier loss: 0.117620; batch adversarial loss: 0.661446\n",
      "epoch 171; iter: 0; batch classifier loss: 0.181054; batch adversarial loss: 0.665390\n",
      "epoch 172; iter: 0; batch classifier loss: 0.078050; batch adversarial loss: 0.582648\n",
      "epoch 173; iter: 0; batch classifier loss: 0.082582; batch adversarial loss: 0.684049\n",
      "epoch 174; iter: 0; batch classifier loss: 0.102993; batch adversarial loss: 0.710215\n",
      "epoch 175; iter: 0; batch classifier loss: 0.142208; batch adversarial loss: 0.771764\n",
      "epoch 176; iter: 0; batch classifier loss: 0.151619; batch adversarial loss: 0.655369\n",
      "epoch 177; iter: 0; batch classifier loss: 0.088768; batch adversarial loss: 0.624437\n",
      "epoch 178; iter: 0; batch classifier loss: 0.178208; batch adversarial loss: 0.790245\n",
      "epoch 179; iter: 0; batch classifier loss: 0.115819; batch adversarial loss: 0.666980\n",
      "epoch 180; iter: 0; batch classifier loss: 0.201501; batch adversarial loss: 0.686761\n",
      "epoch 181; iter: 0; batch classifier loss: 0.162091; batch adversarial loss: 0.612806\n",
      "epoch 182; iter: 0; batch classifier loss: 0.175824; batch adversarial loss: 0.643318\n",
      "epoch 183; iter: 0; batch classifier loss: 0.156745; batch adversarial loss: 0.652485\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337387; batch adversarial loss: 0.684116\n",
      "epoch 185; iter: 0; batch classifier loss: 0.182178; batch adversarial loss: 0.681430\n",
      "epoch 186; iter: 0; batch classifier loss: 0.133413; batch adversarial loss: 0.522931\n",
      "epoch 187; iter: 0; batch classifier loss: 0.192923; batch adversarial loss: 0.679484\n",
      "epoch 188; iter: 0; batch classifier loss: 0.221965; batch adversarial loss: 0.720614\n",
      "epoch 189; iter: 0; batch classifier loss: 0.149280; batch adversarial loss: 0.638233\n",
      "epoch 190; iter: 0; batch classifier loss: 0.164555; batch adversarial loss: 0.523595\n",
      "epoch 191; iter: 0; batch classifier loss: 0.073378; batch adversarial loss: 0.454817\n",
      "epoch 192; iter: 0; batch classifier loss: 0.153405; batch adversarial loss: 0.558755\n",
      "epoch 193; iter: 0; batch classifier loss: 0.109040; batch adversarial loss: 0.482695\n",
      "epoch 194; iter: 0; batch classifier loss: 0.158566; batch adversarial loss: 0.623902\n",
      "epoch 195; iter: 0; batch classifier loss: 0.152006; batch adversarial loss: 0.534499\n",
      "epoch 196; iter: 0; batch classifier loss: 0.110653; batch adversarial loss: 0.507206\n",
      "epoch 197; iter: 0; batch classifier loss: 0.143957; batch adversarial loss: 0.532329\n",
      "epoch 198; iter: 0; batch classifier loss: 0.141832; batch adversarial loss: 0.523070\n",
      "epoch 199; iter: 0; batch classifier loss: 0.185909; batch adversarial loss: 0.563776\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702178; batch adversarial loss: 1.202349\n",
      "epoch 1; iter: 0; batch classifier loss: 0.775250; batch adversarial loss: 1.446039\n",
      "epoch 2; iter: 0; batch classifier loss: 0.890561; batch adversarial loss: 1.439401\n",
      "epoch 3; iter: 0; batch classifier loss: 1.135936; batch adversarial loss: 1.373790\n",
      "epoch 4; iter: 0; batch classifier loss: 1.220160; batch adversarial loss: 1.261068\n",
      "epoch 5; iter: 0; batch classifier loss: 1.139230; batch adversarial loss: 1.133344\n",
      "epoch 6; iter: 0; batch classifier loss: 1.163578; batch adversarial loss: 1.038994\n",
      "epoch 7; iter: 0; batch classifier loss: 1.052789; batch adversarial loss: 0.948670\n",
      "epoch 8; iter: 0; batch classifier loss: 1.304003; batch adversarial loss: 0.873875\n",
      "epoch 9; iter: 0; batch classifier loss: 1.277990; batch adversarial loss: 0.809395\n",
      "epoch 10; iter: 0; batch classifier loss: 1.000898; batch adversarial loss: 0.757453\n",
      "epoch 11; iter: 0; batch classifier loss: 1.138002; batch adversarial loss: 0.685278\n",
      "epoch 12; iter: 0; batch classifier loss: 1.111592; batch adversarial loss: 0.645872\n",
      "epoch 13; iter: 0; batch classifier loss: 1.179494; batch adversarial loss: 0.604879\n",
      "epoch 14; iter: 0; batch classifier loss: 1.021080; batch adversarial loss: 0.589943\n",
      "epoch 15; iter: 0; batch classifier loss: 1.187521; batch adversarial loss: 0.552516\n",
      "epoch 16; iter: 0; batch classifier loss: 0.840191; batch adversarial loss: 0.507610\n",
      "epoch 17; iter: 0; batch classifier loss: 0.430785; batch adversarial loss: 0.494752\n",
      "epoch 18; iter: 0; batch classifier loss: 0.331701; batch adversarial loss: 0.502147\n",
      "epoch 19; iter: 0; batch classifier loss: 0.307866; batch adversarial loss: 0.490302\n",
      "epoch 20; iter: 0; batch classifier loss: 0.340093; batch adversarial loss: 0.454294\n",
      "epoch 21; iter: 0; batch classifier loss: 0.256591; batch adversarial loss: 0.483142\n",
      "epoch 22; iter: 0; batch classifier loss: 0.272728; batch adversarial loss: 0.449543\n",
      "epoch 23; iter: 0; batch classifier loss: 0.278662; batch adversarial loss: 0.433507\n",
      "epoch 24; iter: 0; batch classifier loss: 0.259432; batch adversarial loss: 0.475555\n",
      "epoch 25; iter: 0; batch classifier loss: 0.271286; batch adversarial loss: 0.494686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.257303; batch adversarial loss: 0.471484\n",
      "epoch 27; iter: 0; batch classifier loss: 0.281059; batch adversarial loss: 0.484329\n",
      "epoch 28; iter: 0; batch classifier loss: 0.270278; batch adversarial loss: 0.441236\n",
      "epoch 29; iter: 0; batch classifier loss: 0.247434; batch adversarial loss: 0.463202\n",
      "epoch 30; iter: 0; batch classifier loss: 0.249803; batch adversarial loss: 0.502079\n",
      "epoch 31; iter: 0; batch classifier loss: 0.272023; batch adversarial loss: 0.436233\n",
      "epoch 32; iter: 0; batch classifier loss: 0.293612; batch adversarial loss: 0.489135\n",
      "epoch 33; iter: 0; batch classifier loss: 0.235759; batch adversarial loss: 0.440072\n",
      "epoch 34; iter: 0; batch classifier loss: 0.242985; batch adversarial loss: 0.451023\n",
      "epoch 35; iter: 0; batch classifier loss: 0.244814; batch adversarial loss: 0.466823\n",
      "epoch 36; iter: 0; batch classifier loss: 0.259440; batch adversarial loss: 0.459858\n",
      "epoch 37; iter: 0; batch classifier loss: 0.262400; batch adversarial loss: 0.514306\n",
      "epoch 38; iter: 0; batch classifier loss: 0.235802; batch adversarial loss: 0.449069\n",
      "epoch 39; iter: 0; batch classifier loss: 0.226934; batch adversarial loss: 0.435746\n",
      "epoch 40; iter: 0; batch classifier loss: 0.159821; batch adversarial loss: 0.514941\n",
      "epoch 41; iter: 0; batch classifier loss: 0.207617; batch adversarial loss: 0.456032\n",
      "epoch 42; iter: 0; batch classifier loss: 0.231719; batch adversarial loss: 0.468168\n",
      "epoch 43; iter: 0; batch classifier loss: 0.237336; batch adversarial loss: 0.468929\n",
      "epoch 44; iter: 0; batch classifier loss: 0.212135; batch adversarial loss: 0.427273\n",
      "epoch 45; iter: 0; batch classifier loss: 0.198475; batch adversarial loss: 0.560283\n",
      "epoch 46; iter: 0; batch classifier loss: 0.211994; batch adversarial loss: 0.436374\n",
      "epoch 47; iter: 0; batch classifier loss: 0.232602; batch adversarial loss: 0.436770\n",
      "epoch 48; iter: 0; batch classifier loss: 0.196126; batch adversarial loss: 0.438406\n",
      "epoch 49; iter: 0; batch classifier loss: 0.218265; batch adversarial loss: 0.455377\n",
      "epoch 50; iter: 0; batch classifier loss: 0.239558; batch adversarial loss: 0.417002\n",
      "epoch 51; iter: 0; batch classifier loss: 0.204441; batch adversarial loss: 0.438632\n",
      "epoch 52; iter: 0; batch classifier loss: 0.211034; batch adversarial loss: 0.483122\n",
      "epoch 53; iter: 0; batch classifier loss: 0.221196; batch adversarial loss: 0.442948\n",
      "epoch 54; iter: 0; batch classifier loss: 0.187062; batch adversarial loss: 0.417485\n",
      "epoch 55; iter: 0; batch classifier loss: 0.198243; batch adversarial loss: 0.465596\n",
      "epoch 56; iter: 0; batch classifier loss: 0.188210; batch adversarial loss: 0.520354\n",
      "epoch 57; iter: 0; batch classifier loss: 0.187141; batch adversarial loss: 0.455663\n",
      "epoch 58; iter: 0; batch classifier loss: 0.207060; batch adversarial loss: 0.504616\n",
      "epoch 59; iter: 0; batch classifier loss: 0.186192; batch adversarial loss: 0.487181\n",
      "epoch 60; iter: 0; batch classifier loss: 0.194717; batch adversarial loss: 0.472988\n",
      "epoch 61; iter: 0; batch classifier loss: 0.182169; batch adversarial loss: 0.397139\n",
      "epoch 62; iter: 0; batch classifier loss: 0.175235; batch adversarial loss: 0.409696\n",
      "epoch 63; iter: 0; batch classifier loss: 0.173280; batch adversarial loss: 0.472214\n",
      "epoch 64; iter: 0; batch classifier loss: 0.165958; batch adversarial loss: 0.401053\n",
      "epoch 65; iter: 0; batch classifier loss: 0.147499; batch adversarial loss: 0.495761\n",
      "epoch 66; iter: 0; batch classifier loss: 0.126940; batch adversarial loss: 0.409579\n",
      "epoch 67; iter: 0; batch classifier loss: 0.148874; batch adversarial loss: 0.475322\n",
      "epoch 68; iter: 0; batch classifier loss: 0.169557; batch adversarial loss: 0.468000\n",
      "epoch 69; iter: 0; batch classifier loss: 0.126331; batch adversarial loss: 0.463932\n",
      "epoch 70; iter: 0; batch classifier loss: 0.241169; batch adversarial loss: 0.431299\n",
      "epoch 71; iter: 0; batch classifier loss: 0.178786; batch adversarial loss: 0.492219\n",
      "epoch 72; iter: 0; batch classifier loss: 0.247015; batch adversarial loss: 0.407849\n",
      "epoch 73; iter: 0; batch classifier loss: 0.233572; batch adversarial loss: 0.461067\n",
      "epoch 74; iter: 0; batch classifier loss: 0.143791; batch adversarial loss: 0.475544\n",
      "epoch 75; iter: 0; batch classifier loss: 0.175894; batch adversarial loss: 0.412669\n",
      "epoch 76; iter: 0; batch classifier loss: 0.165904; batch adversarial loss: 0.482958\n",
      "epoch 77; iter: 0; batch classifier loss: 0.199344; batch adversarial loss: 0.469484\n",
      "epoch 78; iter: 0; batch classifier loss: 0.168956; batch adversarial loss: 0.409874\n",
      "epoch 79; iter: 0; batch classifier loss: 0.192727; batch adversarial loss: 0.447792\n",
      "epoch 80; iter: 0; batch classifier loss: 0.180607; batch adversarial loss: 0.433918\n",
      "epoch 81; iter: 0; batch classifier loss: 0.180854; batch adversarial loss: 0.484107\n",
      "epoch 82; iter: 0; batch classifier loss: 0.206368; batch adversarial loss: 0.458434\n",
      "epoch 83; iter: 0; batch classifier loss: 0.187284; batch adversarial loss: 0.433987\n",
      "epoch 84; iter: 0; batch classifier loss: 0.182273; batch adversarial loss: 0.422381\n",
      "epoch 85; iter: 0; batch classifier loss: 0.150899; batch adversarial loss: 0.496386\n",
      "epoch 86; iter: 0; batch classifier loss: 0.123137; batch adversarial loss: 0.486539\n",
      "epoch 87; iter: 0; batch classifier loss: 0.159173; batch adversarial loss: 0.468591\n",
      "epoch 88; iter: 0; batch classifier loss: 0.191765; batch adversarial loss: 0.447196\n",
      "epoch 89; iter: 0; batch classifier loss: 0.123883; batch adversarial loss: 0.541333\n",
      "epoch 90; iter: 0; batch classifier loss: 0.170295; batch adversarial loss: 0.434925\n",
      "epoch 91; iter: 0; batch classifier loss: 0.175001; batch adversarial loss: 0.510847\n",
      "epoch 92; iter: 0; batch classifier loss: 0.213348; batch adversarial loss: 0.398595\n",
      "epoch 93; iter: 0; batch classifier loss: 0.195144; batch adversarial loss: 0.409929\n",
      "epoch 94; iter: 0; batch classifier loss: 0.199759; batch adversarial loss: 0.445285\n",
      "epoch 95; iter: 0; batch classifier loss: 0.194018; batch adversarial loss: 0.435000\n",
      "epoch 96; iter: 0; batch classifier loss: 0.140236; batch adversarial loss: 0.518812\n",
      "epoch 97; iter: 0; batch classifier loss: 0.162444; batch adversarial loss: 0.448373\n",
      "epoch 98; iter: 0; batch classifier loss: 0.161703; batch adversarial loss: 0.412196\n",
      "epoch 99; iter: 0; batch classifier loss: 0.155998; batch adversarial loss: 0.471819\n",
      "epoch 100; iter: 0; batch classifier loss: 0.165605; batch adversarial loss: 0.482631\n",
      "epoch 101; iter: 0; batch classifier loss: 0.163616; batch adversarial loss: 0.531644\n",
      "epoch 102; iter: 0; batch classifier loss: 0.152141; batch adversarial loss: 0.481843\n",
      "epoch 103; iter: 0; batch classifier loss: 0.192851; batch adversarial loss: 0.410903\n",
      "epoch 104; iter: 0; batch classifier loss: 0.178202; batch adversarial loss: 0.411095\n",
      "epoch 105; iter: 0; batch classifier loss: 0.163842; batch adversarial loss: 0.458286\n",
      "epoch 106; iter: 0; batch classifier loss: 0.219081; batch adversarial loss: 0.530816\n",
      "epoch 107; iter: 0; batch classifier loss: 0.176066; batch adversarial loss: 0.434232\n",
      "epoch 108; iter: 0; batch classifier loss: 0.237652; batch adversarial loss: 0.445610\n",
      "epoch 109; iter: 0; batch classifier loss: 0.200203; batch adversarial loss: 0.362544\n",
      "epoch 110; iter: 0; batch classifier loss: 0.225854; batch adversarial loss: 0.446935\n",
      "epoch 111; iter: 0; batch classifier loss: 0.226566; batch adversarial loss: 0.505123\n",
      "epoch 112; iter: 0; batch classifier loss: 0.161710; batch adversarial loss: 0.434848\n",
      "epoch 113; iter: 0; batch classifier loss: 0.171481; batch adversarial loss: 0.385810\n",
      "epoch 114; iter: 0; batch classifier loss: 0.142428; batch adversarial loss: 0.556514\n",
      "epoch 115; iter: 0; batch classifier loss: 0.189041; batch adversarial loss: 0.495231\n",
      "epoch 116; iter: 0; batch classifier loss: 0.157746; batch adversarial loss: 0.386588\n",
      "epoch 117; iter: 0; batch classifier loss: 0.208914; batch adversarial loss: 0.421310\n",
      "epoch 118; iter: 0; batch classifier loss: 0.163124; batch adversarial loss: 0.411658\n",
      "epoch 119; iter: 0; batch classifier loss: 0.254999; batch adversarial loss: 0.495901\n",
      "epoch 120; iter: 0; batch classifier loss: 0.191536; batch adversarial loss: 0.409836\n",
      "epoch 121; iter: 0; batch classifier loss: 0.138105; batch adversarial loss: 0.448005\n",
      "epoch 122; iter: 0; batch classifier loss: 0.186451; batch adversarial loss: 0.435065\n",
      "epoch 123; iter: 0; batch classifier loss: 0.210214; batch adversarial loss: 0.446699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.230762; batch adversarial loss: 0.325352\n",
      "epoch 125; iter: 0; batch classifier loss: 0.112376; batch adversarial loss: 0.555804\n",
      "epoch 126; iter: 0; batch classifier loss: 0.177962; batch adversarial loss: 0.446213\n",
      "epoch 127; iter: 0; batch classifier loss: 0.130446; batch adversarial loss: 0.470408\n",
      "epoch 128; iter: 0; batch classifier loss: 0.150273; batch adversarial loss: 0.434732\n",
      "epoch 129; iter: 0; batch classifier loss: 0.234833; batch adversarial loss: 0.423250\n",
      "epoch 130; iter: 0; batch classifier loss: 0.224942; batch adversarial loss: 0.398542\n",
      "epoch 131; iter: 0; batch classifier loss: 0.215883; batch adversarial loss: 0.386476\n",
      "epoch 132; iter: 0; batch classifier loss: 0.118983; batch adversarial loss: 0.543833\n",
      "epoch 133; iter: 0; batch classifier loss: 0.154307; batch adversarial loss: 0.458593\n",
      "epoch 134; iter: 0; batch classifier loss: 0.117870; batch adversarial loss: 0.445979\n",
      "epoch 135; iter: 0; batch classifier loss: 0.194170; batch adversarial loss: 0.446760\n",
      "epoch 136; iter: 0; batch classifier loss: 0.148575; batch adversarial loss: 0.459275\n",
      "epoch 137; iter: 0; batch classifier loss: 0.196181; batch adversarial loss: 0.481177\n",
      "epoch 138; iter: 0; batch classifier loss: 0.179498; batch adversarial loss: 0.506272\n",
      "epoch 139; iter: 0; batch classifier loss: 0.193332; batch adversarial loss: 0.567337\n",
      "epoch 140; iter: 0; batch classifier loss: 0.172795; batch adversarial loss: 0.469736\n",
      "epoch 141; iter: 0; batch classifier loss: 0.184464; batch adversarial loss: 0.410411\n",
      "epoch 142; iter: 0; batch classifier loss: 0.139434; batch adversarial loss: 0.411317\n",
      "epoch 143; iter: 0; batch classifier loss: 0.109071; batch adversarial loss: 0.471810\n",
      "epoch 144; iter: 0; batch classifier loss: 0.170241; batch adversarial loss: 0.508236\n",
      "epoch 145; iter: 0; batch classifier loss: 0.152450; batch adversarial loss: 0.411122\n",
      "epoch 146; iter: 0; batch classifier loss: 0.144736; batch adversarial loss: 0.495388\n",
      "epoch 147; iter: 0; batch classifier loss: 0.123412; batch adversarial loss: 0.458780\n",
      "epoch 148; iter: 0; batch classifier loss: 0.164326; batch adversarial loss: 0.434301\n",
      "epoch 149; iter: 0; batch classifier loss: 0.156740; batch adversarial loss: 0.530098\n",
      "epoch 150; iter: 0; batch classifier loss: 0.108943; batch adversarial loss: 0.457955\n",
      "epoch 151; iter: 0; batch classifier loss: 0.138632; batch adversarial loss: 0.444821\n",
      "epoch 152; iter: 0; batch classifier loss: 0.148701; batch adversarial loss: 0.361328\n",
      "epoch 153; iter: 0; batch classifier loss: 0.178008; batch adversarial loss: 0.410989\n",
      "epoch 154; iter: 0; batch classifier loss: 0.165236; batch adversarial loss: 0.507553\n",
      "epoch 155; iter: 0; batch classifier loss: 0.142726; batch adversarial loss: 0.494757\n",
      "epoch 156; iter: 0; batch classifier loss: 0.195366; batch adversarial loss: 0.456054\n",
      "epoch 157; iter: 0; batch classifier loss: 0.149894; batch adversarial loss: 0.472706\n",
      "epoch 158; iter: 0; batch classifier loss: 0.114641; batch adversarial loss: 0.434460\n",
      "epoch 159; iter: 0; batch classifier loss: 0.177008; batch adversarial loss: 0.362965\n",
      "epoch 160; iter: 0; batch classifier loss: 0.124904; batch adversarial loss: 0.447809\n",
      "epoch 161; iter: 0; batch classifier loss: 0.227753; batch adversarial loss: 0.361202\n",
      "epoch 162; iter: 0; batch classifier loss: 0.121590; batch adversarial loss: 0.443686\n",
      "epoch 163; iter: 0; batch classifier loss: 0.149072; batch adversarial loss: 0.432820\n",
      "epoch 164; iter: 0; batch classifier loss: 0.095251; batch adversarial loss: 0.479276\n",
      "epoch 165; iter: 0; batch classifier loss: 0.154143; batch adversarial loss: 0.349908\n",
      "epoch 166; iter: 0; batch classifier loss: 0.076895; batch adversarial loss: 0.526103\n",
      "epoch 167; iter: 0; batch classifier loss: 0.120413; batch adversarial loss: 0.459211\n",
      "epoch 168; iter: 0; batch classifier loss: 0.096531; batch adversarial loss: 0.390483\n",
      "epoch 169; iter: 0; batch classifier loss: 0.075452; batch adversarial loss: 0.434507\n",
      "epoch 170; iter: 0; batch classifier loss: 0.072950; batch adversarial loss: 0.546218\n",
      "epoch 171; iter: 0; batch classifier loss: 0.054668; batch adversarial loss: 0.470815\n",
      "epoch 172; iter: 0; batch classifier loss: 0.045868; batch adversarial loss: 0.470819\n",
      "epoch 173; iter: 0; batch classifier loss: 0.043390; batch adversarial loss: 0.482793\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037302; batch adversarial loss: 0.500799\n",
      "epoch 175; iter: 0; batch classifier loss: 0.044246; batch adversarial loss: 0.370972\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032871; batch adversarial loss: 0.458620\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020617; batch adversarial loss: 0.441326\n",
      "epoch 178; iter: 0; batch classifier loss: 0.044035; batch adversarial loss: 0.403051\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012976; batch adversarial loss: 0.421825\n",
      "epoch 180; iter: 0; batch classifier loss: 0.033813; batch adversarial loss: 0.437486\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029497; batch adversarial loss: 0.516644\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017393; batch adversarial loss: 0.417053\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023439; batch adversarial loss: 0.494400\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026847; batch adversarial loss: 0.518460\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032166; batch adversarial loss: 0.499197\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025461; batch adversarial loss: 0.379638\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022346; batch adversarial loss: 0.442123\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018826; batch adversarial loss: 0.456863\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011633; batch adversarial loss: 0.354645\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008219; batch adversarial loss: 0.440979\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019245; batch adversarial loss: 0.461751\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015415; batch adversarial loss: 0.466147\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007881; batch adversarial loss: 0.514842\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012344; batch adversarial loss: 0.406874\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012444; batch adversarial loss: 0.481854\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018797; batch adversarial loss: 0.512952\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014020; batch adversarial loss: 0.450507\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022850; batch adversarial loss: 0.447902\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005390; batch adversarial loss: 0.419475\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686801; batch adversarial loss: 0.782111\n",
      "epoch 1; iter: 0; batch classifier loss: 0.563077; batch adversarial loss: 0.710931\n",
      "epoch 2; iter: 0; batch classifier loss: 0.512154; batch adversarial loss: 0.658277\n",
      "epoch 3; iter: 0; batch classifier loss: 0.434206; batch adversarial loss: 0.603387\n",
      "epoch 4; iter: 0; batch classifier loss: 0.379738; batch adversarial loss: 0.581176\n",
      "epoch 5; iter: 0; batch classifier loss: 0.338510; batch adversarial loss: 0.574325\n",
      "epoch 6; iter: 0; batch classifier loss: 0.268067; batch adversarial loss: 0.559718\n",
      "epoch 7; iter: 0; batch classifier loss: 0.348100; batch adversarial loss: 0.567728\n",
      "epoch 8; iter: 0; batch classifier loss: 0.249959; batch adversarial loss: 0.491575\n",
      "epoch 9; iter: 0; batch classifier loss: 0.251472; batch adversarial loss: 0.518009\n",
      "epoch 10; iter: 0; batch classifier loss: 0.300429; batch adversarial loss: 0.512388\n",
      "epoch 11; iter: 0; batch classifier loss: 0.362595; batch adversarial loss: 0.531005\n",
      "epoch 12; iter: 0; batch classifier loss: 0.241935; batch adversarial loss: 0.485136\n",
      "epoch 13; iter: 0; batch classifier loss: 0.241459; batch adversarial loss: 0.504517\n",
      "epoch 14; iter: 0; batch classifier loss: 0.241762; batch adversarial loss: 0.500792\n",
      "epoch 15; iter: 0; batch classifier loss: 0.249518; batch adversarial loss: 0.533427\n",
      "epoch 16; iter: 0; batch classifier loss: 0.203085; batch adversarial loss: 0.519968\n",
      "epoch 17; iter: 0; batch classifier loss: 0.273673; batch adversarial loss: 0.459699\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251975; batch adversarial loss: 0.438646\n",
      "epoch 19; iter: 0; batch classifier loss: 0.196166; batch adversarial loss: 0.457800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.169000; batch adversarial loss: 0.477348\n",
      "epoch 21; iter: 0; batch classifier loss: 0.170033; batch adversarial loss: 0.431885\n",
      "epoch 22; iter: 0; batch classifier loss: 0.149953; batch adversarial loss: 0.424862\n",
      "epoch 23; iter: 0; batch classifier loss: 0.179738; batch adversarial loss: 0.519189\n",
      "epoch 24; iter: 0; batch classifier loss: 0.170102; batch adversarial loss: 0.478585\n",
      "epoch 25; iter: 0; batch classifier loss: 0.228430; batch adversarial loss: 0.510182\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223828; batch adversarial loss: 0.500922\n",
      "epoch 27; iter: 0; batch classifier loss: 0.153213; batch adversarial loss: 0.443014\n",
      "epoch 28; iter: 0; batch classifier loss: 0.154910; batch adversarial loss: 0.448539\n",
      "epoch 29; iter: 0; batch classifier loss: 0.093929; batch adversarial loss: 0.466853\n",
      "epoch 30; iter: 0; batch classifier loss: 0.119717; batch adversarial loss: 0.379580\n",
      "epoch 31; iter: 0; batch classifier loss: 0.165412; batch adversarial loss: 0.457118\n",
      "epoch 32; iter: 0; batch classifier loss: 0.141302; batch adversarial loss: 0.443398\n",
      "epoch 33; iter: 0; batch classifier loss: 0.106017; batch adversarial loss: 0.425902\n",
      "epoch 34; iter: 0; batch classifier loss: 0.177341; batch adversarial loss: 0.461807\n",
      "epoch 35; iter: 0; batch classifier loss: 0.104425; batch adversarial loss: 0.423789\n",
      "epoch 36; iter: 0; batch classifier loss: 0.164333; batch adversarial loss: 0.450937\n",
      "epoch 37; iter: 0; batch classifier loss: 0.101351; batch adversarial loss: 0.524513\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126145; batch adversarial loss: 0.436278\n",
      "epoch 39; iter: 0; batch classifier loss: 0.096189; batch adversarial loss: 0.524165\n",
      "epoch 40; iter: 0; batch classifier loss: 0.142866; batch adversarial loss: 0.453788\n",
      "epoch 41; iter: 0; batch classifier loss: 0.136259; batch adversarial loss: 0.492510\n",
      "epoch 42; iter: 0; batch classifier loss: 0.112884; batch adversarial loss: 0.496967\n",
      "epoch 43; iter: 0; batch classifier loss: 0.107977; batch adversarial loss: 0.445250\n",
      "epoch 44; iter: 0; batch classifier loss: 0.144710; batch adversarial loss: 0.441132\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104838; batch adversarial loss: 0.425552\n",
      "epoch 46; iter: 0; batch classifier loss: 0.100130; batch adversarial loss: 0.547285\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106744; batch adversarial loss: 0.483050\n",
      "epoch 48; iter: 0; batch classifier loss: 0.113859; batch adversarial loss: 0.510831\n",
      "epoch 49; iter: 0; batch classifier loss: 0.111691; batch adversarial loss: 0.440814\n",
      "epoch 50; iter: 0; batch classifier loss: 0.101417; batch adversarial loss: 0.395943\n",
      "epoch 51; iter: 0; batch classifier loss: 0.099361; batch adversarial loss: 0.450559\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101397; batch adversarial loss: 0.572647\n",
      "epoch 53; iter: 0; batch classifier loss: 0.077374; batch adversarial loss: 0.517483\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108101; batch adversarial loss: 0.522827\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122526; batch adversarial loss: 0.454835\n",
      "epoch 56; iter: 0; batch classifier loss: 0.097550; batch adversarial loss: 0.511011\n",
      "epoch 57; iter: 0; batch classifier loss: 0.075141; batch adversarial loss: 0.458240\n",
      "epoch 58; iter: 0; batch classifier loss: 0.135795; batch adversarial loss: 0.404218\n",
      "epoch 59; iter: 0; batch classifier loss: 0.114653; batch adversarial loss: 0.490826\n",
      "epoch 60; iter: 0; batch classifier loss: 0.064549; batch adversarial loss: 0.485037\n",
      "epoch 61; iter: 0; batch classifier loss: 0.092677; batch adversarial loss: 0.461910\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081847; batch adversarial loss: 0.496166\n",
      "epoch 63; iter: 0; batch classifier loss: 0.090339; batch adversarial loss: 0.399171\n",
      "epoch 64; iter: 0; batch classifier loss: 0.093427; batch adversarial loss: 0.442941\n",
      "epoch 65; iter: 0; batch classifier loss: 0.127560; batch adversarial loss: 0.454323\n",
      "epoch 66; iter: 0; batch classifier loss: 0.051671; batch adversarial loss: 0.537030\n",
      "epoch 67; iter: 0; batch classifier loss: 0.113388; batch adversarial loss: 0.582249\n",
      "epoch 68; iter: 0; batch classifier loss: 0.091771; batch adversarial loss: 0.466542\n",
      "epoch 69; iter: 0; batch classifier loss: 0.096805; batch adversarial loss: 0.432504\n",
      "epoch 70; iter: 0; batch classifier loss: 0.131387; batch adversarial loss: 0.437385\n",
      "epoch 71; iter: 0; batch classifier loss: 0.043622; batch adversarial loss: 0.614115\n",
      "epoch 72; iter: 0; batch classifier loss: 0.057255; batch adversarial loss: 0.473653\n",
      "epoch 73; iter: 0; batch classifier loss: 0.059237; batch adversarial loss: 0.416988\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079384; batch adversarial loss: 0.613690\n",
      "epoch 75; iter: 0; batch classifier loss: 0.058561; batch adversarial loss: 0.411424\n",
      "epoch 76; iter: 0; batch classifier loss: 0.107074; batch adversarial loss: 0.541404\n",
      "epoch 77; iter: 0; batch classifier loss: 0.060991; batch adversarial loss: 0.434507\n",
      "epoch 78; iter: 0; batch classifier loss: 0.065770; batch adversarial loss: 0.418358\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044034; batch adversarial loss: 0.585715\n",
      "epoch 80; iter: 0; batch classifier loss: 0.064984; batch adversarial loss: 0.453940\n",
      "epoch 81; iter: 0; batch classifier loss: 0.039992; batch adversarial loss: 0.483557\n",
      "epoch 82; iter: 0; batch classifier loss: 0.044906; batch adversarial loss: 0.417593\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071076; batch adversarial loss: 0.455792\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052769; batch adversarial loss: 0.439558\n",
      "epoch 85; iter: 0; batch classifier loss: 0.053603; batch adversarial loss: 0.385485\n",
      "epoch 86; iter: 0; batch classifier loss: 0.027790; batch adversarial loss: 0.409572\n",
      "epoch 87; iter: 0; batch classifier loss: 0.088097; batch adversarial loss: 0.420781\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073414; batch adversarial loss: 0.393949\n",
      "epoch 89; iter: 0; batch classifier loss: 0.070313; batch adversarial loss: 0.429885\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057501; batch adversarial loss: 0.427283\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057036; batch adversarial loss: 0.501311\n",
      "epoch 92; iter: 0; batch classifier loss: 0.022245; batch adversarial loss: 0.459307\n",
      "epoch 93; iter: 0; batch classifier loss: 0.047986; batch adversarial loss: 0.443222\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046039; batch adversarial loss: 0.444359\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047232; batch adversarial loss: 0.533093\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041084; batch adversarial loss: 0.499440\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064695; batch adversarial loss: 0.407335\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035685; batch adversarial loss: 0.380590\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043141; batch adversarial loss: 0.535043\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044614; batch adversarial loss: 0.456367\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040371; batch adversarial loss: 0.467601\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044121; batch adversarial loss: 0.489759\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047173; batch adversarial loss: 0.434142\n",
      "epoch 104; iter: 0; batch classifier loss: 0.029945; batch adversarial loss: 0.434277\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045439; batch adversarial loss: 0.472609\n",
      "epoch 106; iter: 0; batch classifier loss: 0.029948; batch adversarial loss: 0.421429\n",
      "epoch 107; iter: 0; batch classifier loss: 0.095221; batch adversarial loss: 0.401111\n",
      "epoch 108; iter: 0; batch classifier loss: 0.032857; batch adversarial loss: 0.453103\n",
      "epoch 109; iter: 0; batch classifier loss: 0.018909; batch adversarial loss: 0.452017\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035105; batch adversarial loss: 0.535130\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037072; batch adversarial loss: 0.475948\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054339; batch adversarial loss: 0.500461\n",
      "epoch 113; iter: 0; batch classifier loss: 0.024148; batch adversarial loss: 0.505965\n",
      "epoch 114; iter: 0; batch classifier loss: 0.023497; batch adversarial loss: 0.484163\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034619; batch adversarial loss: 0.306887\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039285; batch adversarial loss: 0.451968\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026770; batch adversarial loss: 0.461633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.041804; batch adversarial loss: 0.412218\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034245; batch adversarial loss: 0.511349\n",
      "epoch 120; iter: 0; batch classifier loss: 0.020352; batch adversarial loss: 0.449889\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037398; batch adversarial loss: 0.419438\n",
      "epoch 122; iter: 0; batch classifier loss: 0.027939; batch adversarial loss: 0.455331\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030745; batch adversarial loss: 0.567057\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021389; batch adversarial loss: 0.431759\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022238; batch adversarial loss: 0.581346\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032052; batch adversarial loss: 0.447054\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022763; batch adversarial loss: 0.445411\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023124; batch adversarial loss: 0.437697\n",
      "epoch 129; iter: 0; batch classifier loss: 0.044154; batch adversarial loss: 0.406556\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059571; batch adversarial loss: 0.476842\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022810; batch adversarial loss: 0.467824\n",
      "epoch 132; iter: 0; batch classifier loss: 0.070910; batch adversarial loss: 0.470137\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019244; batch adversarial loss: 0.465663\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032343; batch adversarial loss: 0.476107\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019794; batch adversarial loss: 0.516598\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028087; batch adversarial loss: 0.456395\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035327; batch adversarial loss: 0.487059\n",
      "epoch 138; iter: 0; batch classifier loss: 0.042670; batch adversarial loss: 0.427062\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033290; batch adversarial loss: 0.418443\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035931; batch adversarial loss: 0.493421\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020732; batch adversarial loss: 0.524303\n",
      "epoch 142; iter: 0; batch classifier loss: 0.015831; batch adversarial loss: 0.556707\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033029; batch adversarial loss: 0.570703\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018915; batch adversarial loss: 0.475549\n",
      "epoch 145; iter: 0; batch classifier loss: 0.052230; batch adversarial loss: 0.423817\n",
      "epoch 146; iter: 0; batch classifier loss: 0.012113; batch adversarial loss: 0.393258\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014646; batch adversarial loss: 0.427396\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032848; batch adversarial loss: 0.474839\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027547; batch adversarial loss: 0.446610\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027771; batch adversarial loss: 0.439832\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042738; batch adversarial loss: 0.518345\n",
      "epoch 152; iter: 0; batch classifier loss: 0.012789; batch adversarial loss: 0.464043\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012912; batch adversarial loss: 0.477426\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023178; batch adversarial loss: 0.434176\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020027; batch adversarial loss: 0.485841\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023344; batch adversarial loss: 0.403784\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012573; batch adversarial loss: 0.439821\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030373; batch adversarial loss: 0.570397\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011224; batch adversarial loss: 0.415279\n",
      "epoch 160; iter: 0; batch classifier loss: 0.039044; batch adversarial loss: 0.396795\n",
      "epoch 161; iter: 0; batch classifier loss: 0.045485; batch adversarial loss: 0.482137\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024501; batch adversarial loss: 0.444706\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017267; batch adversarial loss: 0.466225\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022188; batch adversarial loss: 0.444500\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029081; batch adversarial loss: 0.473465\n",
      "epoch 166; iter: 0; batch classifier loss: 0.043922; batch adversarial loss: 0.357027\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009086; batch adversarial loss: 0.420116\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010552; batch adversarial loss: 0.539339\n",
      "epoch 169; iter: 0; batch classifier loss: 0.057355; batch adversarial loss: 0.462385\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030833; batch adversarial loss: 0.478616\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010009; batch adversarial loss: 0.468212\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018766; batch adversarial loss: 0.433135\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038111; batch adversarial loss: 0.372275\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020763; batch adversarial loss: 0.533381\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038505; batch adversarial loss: 0.489065\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017950; batch adversarial loss: 0.599690\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016447; batch adversarial loss: 0.507444\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017993; batch adversarial loss: 0.453563\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022995; batch adversarial loss: 0.590721\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015786; batch adversarial loss: 0.529354\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021217; batch adversarial loss: 0.464721\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020999; batch adversarial loss: 0.448498\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012157; batch adversarial loss: 0.348849\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007575; batch adversarial loss: 0.474113\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009627; batch adversarial loss: 0.524997\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026925; batch adversarial loss: 0.409169\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018773; batch adversarial loss: 0.503272\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006689; batch adversarial loss: 0.403825\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015156; batch adversarial loss: 0.488991\n",
      "epoch 190; iter: 0; batch classifier loss: 0.045761; batch adversarial loss: 0.377478\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022256; batch adversarial loss: 0.453145\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007009; batch adversarial loss: 0.434597\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016075; batch adversarial loss: 0.470736\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008599; batch adversarial loss: 0.434386\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014389; batch adversarial loss: 0.395213\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032752; batch adversarial loss: 0.409109\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021884; batch adversarial loss: 0.570520\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006753; batch adversarial loss: 0.387882\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035659; batch adversarial loss: 0.400167\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704572; batch adversarial loss: 0.732042\n",
      "epoch 1; iter: 0; batch classifier loss: 0.479740; batch adversarial loss: 0.669506\n",
      "epoch 2; iter: 0; batch classifier loss: 0.431753; batch adversarial loss: 0.598831\n",
      "epoch 3; iter: 0; batch classifier loss: 0.390508; batch adversarial loss: 0.605996\n",
      "epoch 4; iter: 0; batch classifier loss: 0.372709; batch adversarial loss: 0.581143\n",
      "epoch 5; iter: 0; batch classifier loss: 0.322711; batch adversarial loss: 0.561561\n",
      "epoch 6; iter: 0; batch classifier loss: 0.281669; batch adversarial loss: 0.554167\n",
      "epoch 7; iter: 0; batch classifier loss: 0.315344; batch adversarial loss: 0.562145\n",
      "epoch 8; iter: 0; batch classifier loss: 0.308926; batch adversarial loss: 0.557784\n",
      "epoch 9; iter: 0; batch classifier loss: 0.371647; batch adversarial loss: 0.463423\n",
      "epoch 10; iter: 0; batch classifier loss: 0.245702; batch adversarial loss: 0.515593\n",
      "epoch 11; iter: 0; batch classifier loss: 0.307043; batch adversarial loss: 0.519704\n",
      "epoch 12; iter: 0; batch classifier loss: 0.165757; batch adversarial loss: 0.610510\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232716; batch adversarial loss: 0.485406\n",
      "epoch 14; iter: 0; batch classifier loss: 0.261785; batch adversarial loss: 0.514676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.200033; batch adversarial loss: 0.508611\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222452; batch adversarial loss: 0.558335\n",
      "epoch 17; iter: 0; batch classifier loss: 0.232647; batch adversarial loss: 0.499955\n",
      "epoch 18; iter: 0; batch classifier loss: 0.221664; batch adversarial loss: 0.486945\n",
      "epoch 19; iter: 0; batch classifier loss: 0.143455; batch adversarial loss: 0.486104\n",
      "epoch 20; iter: 0; batch classifier loss: 0.165063; batch adversarial loss: 0.476724\n",
      "epoch 21; iter: 0; batch classifier loss: 0.227656; batch adversarial loss: 0.515233\n",
      "epoch 22; iter: 0; batch classifier loss: 0.179441; batch adversarial loss: 0.430836\n",
      "epoch 23; iter: 0; batch classifier loss: 0.112320; batch adversarial loss: 0.483631\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194126; batch adversarial loss: 0.434289\n",
      "epoch 25; iter: 0; batch classifier loss: 0.167945; batch adversarial loss: 0.503232\n",
      "epoch 26; iter: 0; batch classifier loss: 0.117448; batch adversarial loss: 0.471406\n",
      "epoch 27; iter: 0; batch classifier loss: 0.223329; batch adversarial loss: 0.391369\n",
      "epoch 28; iter: 0; batch classifier loss: 0.126316; batch adversarial loss: 0.484914\n",
      "epoch 29; iter: 0; batch classifier loss: 0.115761; batch adversarial loss: 0.459256\n",
      "epoch 30; iter: 0; batch classifier loss: 0.180858; batch adversarial loss: 0.412648\n",
      "epoch 31; iter: 0; batch classifier loss: 0.158924; batch adversarial loss: 0.494273\n",
      "epoch 32; iter: 0; batch classifier loss: 0.102658; batch adversarial loss: 0.563299\n",
      "epoch 33; iter: 0; batch classifier loss: 0.106782; batch adversarial loss: 0.465447\n",
      "epoch 34; iter: 0; batch classifier loss: 0.090677; batch adversarial loss: 0.476227\n",
      "epoch 35; iter: 0; batch classifier loss: 0.163617; batch adversarial loss: 0.505206\n",
      "epoch 36; iter: 0; batch classifier loss: 0.088885; batch adversarial loss: 0.476023\n",
      "epoch 37; iter: 0; batch classifier loss: 0.127372; batch adversarial loss: 0.446776\n",
      "epoch 38; iter: 0; batch classifier loss: 0.101611; batch adversarial loss: 0.516843\n",
      "epoch 39; iter: 0; batch classifier loss: 0.112694; batch adversarial loss: 0.485538\n",
      "epoch 40; iter: 0; batch classifier loss: 0.110473; batch adversarial loss: 0.404114\n",
      "epoch 41; iter: 0; batch classifier loss: 0.053239; batch adversarial loss: 0.541716\n",
      "epoch 42; iter: 0; batch classifier loss: 0.070894; batch adversarial loss: 0.453201\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089015; batch adversarial loss: 0.441852\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112010; batch adversarial loss: 0.477407\n",
      "epoch 45; iter: 0; batch classifier loss: 0.156082; batch adversarial loss: 0.402872\n",
      "epoch 46; iter: 0; batch classifier loss: 0.132256; batch adversarial loss: 0.417492\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114382; batch adversarial loss: 0.457677\n",
      "epoch 48; iter: 0; batch classifier loss: 0.073328; batch adversarial loss: 0.399031\n",
      "epoch 49; iter: 0; batch classifier loss: 0.165699; batch adversarial loss: 0.470153\n",
      "epoch 50; iter: 0; batch classifier loss: 0.105438; batch adversarial loss: 0.428733\n",
      "epoch 51; iter: 0; batch classifier loss: 0.076916; batch adversarial loss: 0.445821\n",
      "epoch 52; iter: 0; batch classifier loss: 0.036086; batch adversarial loss: 0.596294\n",
      "epoch 53; iter: 0; batch classifier loss: 0.130365; batch adversarial loss: 0.415068\n",
      "epoch 54; iter: 0; batch classifier loss: 0.090674; batch adversarial loss: 0.478450\n",
      "epoch 55; iter: 0; batch classifier loss: 0.178377; batch adversarial loss: 0.431914\n",
      "epoch 56; iter: 0; batch classifier loss: 0.078512; batch adversarial loss: 0.451894\n",
      "epoch 57; iter: 0; batch classifier loss: 0.047589; batch adversarial loss: 0.379507\n",
      "epoch 58; iter: 0; batch classifier loss: 0.082094; batch adversarial loss: 0.495754\n",
      "epoch 59; iter: 0; batch classifier loss: 0.094881; batch adversarial loss: 0.499453\n",
      "epoch 60; iter: 0; batch classifier loss: 0.044509; batch adversarial loss: 0.531698\n",
      "epoch 61; iter: 0; batch classifier loss: 0.032681; batch adversarial loss: 0.548223\n",
      "epoch 62; iter: 0; batch classifier loss: 0.123735; batch adversarial loss: 0.495360\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093287; batch adversarial loss: 0.476597\n",
      "epoch 64; iter: 0; batch classifier loss: 0.051413; batch adversarial loss: 0.446845\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079926; batch adversarial loss: 0.476011\n",
      "epoch 66; iter: 0; batch classifier loss: 0.074041; batch adversarial loss: 0.483202\n",
      "epoch 67; iter: 0; batch classifier loss: 0.084135; batch adversarial loss: 0.399220\n",
      "epoch 68; iter: 0; batch classifier loss: 0.041072; batch adversarial loss: 0.454675\n",
      "epoch 69; iter: 0; batch classifier loss: 0.048356; batch adversarial loss: 0.488801\n",
      "epoch 70; iter: 0; batch classifier loss: 0.051368; batch adversarial loss: 0.460568\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064525; batch adversarial loss: 0.426223\n",
      "epoch 72; iter: 0; batch classifier loss: 0.032638; batch adversarial loss: 0.504050\n",
      "epoch 73; iter: 0; batch classifier loss: 0.078673; batch adversarial loss: 0.422551\n",
      "epoch 74; iter: 0; batch classifier loss: 0.064281; batch adversarial loss: 0.523092\n",
      "epoch 75; iter: 0; batch classifier loss: 0.084738; batch adversarial loss: 0.336174\n",
      "epoch 76; iter: 0; batch classifier loss: 0.038525; batch adversarial loss: 0.409933\n",
      "epoch 77; iter: 0; batch classifier loss: 0.068840; batch adversarial loss: 0.425680\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059747; batch adversarial loss: 0.453863\n",
      "epoch 79; iter: 0; batch classifier loss: 0.073313; batch adversarial loss: 0.490985\n",
      "epoch 80; iter: 0; batch classifier loss: 0.032963; batch adversarial loss: 0.389866\n",
      "epoch 81; iter: 0; batch classifier loss: 0.087607; batch adversarial loss: 0.490130\n",
      "epoch 82; iter: 0; batch classifier loss: 0.037729; batch adversarial loss: 0.454755\n",
      "epoch 83; iter: 0; batch classifier loss: 0.077366; batch adversarial loss: 0.419443\n",
      "epoch 84; iter: 0; batch classifier loss: 0.091427; batch adversarial loss: 0.411256\n",
      "epoch 85; iter: 0; batch classifier loss: 0.082325; batch adversarial loss: 0.466220\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046384; batch adversarial loss: 0.495145\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053228; batch adversarial loss: 0.470286\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050316; batch adversarial loss: 0.346928\n",
      "epoch 89; iter: 0; batch classifier loss: 0.025019; batch adversarial loss: 0.530993\n",
      "epoch 90; iter: 0; batch classifier loss: 0.044297; batch adversarial loss: 0.378378\n",
      "epoch 91; iter: 0; batch classifier loss: 0.037451; batch adversarial loss: 0.492751\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065841; batch adversarial loss: 0.489178\n",
      "epoch 93; iter: 0; batch classifier loss: 0.033168; batch adversarial loss: 0.473049\n",
      "epoch 94; iter: 0; batch classifier loss: 0.073450; batch adversarial loss: 0.450870\n",
      "epoch 95; iter: 0; batch classifier loss: 0.018912; batch adversarial loss: 0.409747\n",
      "epoch 96; iter: 0; batch classifier loss: 0.031680; batch adversarial loss: 0.499016\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050057; batch adversarial loss: 0.405429\n",
      "epoch 98; iter: 0; batch classifier loss: 0.030428; batch adversarial loss: 0.430821\n",
      "epoch 99; iter: 0; batch classifier loss: 0.048965; batch adversarial loss: 0.375771\n",
      "epoch 100; iter: 0; batch classifier loss: 0.035324; batch adversarial loss: 0.432643\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039926; batch adversarial loss: 0.511018\n",
      "epoch 102; iter: 0; batch classifier loss: 0.086162; batch adversarial loss: 0.429486\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056250; batch adversarial loss: 0.521320\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034488; batch adversarial loss: 0.408579\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046273; batch adversarial loss: 0.421562\n",
      "epoch 106; iter: 0; batch classifier loss: 0.026714; batch adversarial loss: 0.527610\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052340; batch adversarial loss: 0.567344\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048408; batch adversarial loss: 0.482948\n",
      "epoch 109; iter: 0; batch classifier loss: 0.028283; batch adversarial loss: 0.450972\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043225; batch adversarial loss: 0.413356\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062833; batch adversarial loss: 0.476674\n",
      "epoch 112; iter: 0; batch classifier loss: 0.087826; batch adversarial loss: 0.477187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.048408; batch adversarial loss: 0.414214\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028675; batch adversarial loss: 0.431738\n",
      "epoch 115; iter: 0; batch classifier loss: 0.023306; batch adversarial loss: 0.461228\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028577; batch adversarial loss: 0.426742\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028174; batch adversarial loss: 0.446638\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036832; batch adversarial loss: 0.546993\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026116; batch adversarial loss: 0.428870\n",
      "epoch 120; iter: 0; batch classifier loss: 0.020809; batch adversarial loss: 0.539368\n",
      "epoch 121; iter: 0; batch classifier loss: 0.017205; batch adversarial loss: 0.487833\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039269; batch adversarial loss: 0.441571\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045969; batch adversarial loss: 0.347497\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038552; batch adversarial loss: 0.402243\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025183; batch adversarial loss: 0.537853\n",
      "epoch 126; iter: 0; batch classifier loss: 0.015279; batch adversarial loss: 0.408893\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019699; batch adversarial loss: 0.490020\n",
      "epoch 128; iter: 0; batch classifier loss: 0.078787; batch adversarial loss: 0.489233\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024468; batch adversarial loss: 0.504918\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017480; batch adversarial loss: 0.497220\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051071; batch adversarial loss: 0.351387\n",
      "epoch 132; iter: 0; batch classifier loss: 0.065460; batch adversarial loss: 0.428993\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021974; batch adversarial loss: 0.444513\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019705; batch adversarial loss: 0.401030\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025306; batch adversarial loss: 0.446930\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025784; batch adversarial loss: 0.441921\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015943; batch adversarial loss: 0.431347\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028595; batch adversarial loss: 0.422783\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046070; batch adversarial loss: 0.470743\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013369; batch adversarial loss: 0.479814\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046320; batch adversarial loss: 0.418501\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028678; batch adversarial loss: 0.381158\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027976; batch adversarial loss: 0.495642\n",
      "epoch 144; iter: 0; batch classifier loss: 0.010662; batch adversarial loss: 0.558660\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021204; batch adversarial loss: 0.451939\n",
      "epoch 146; iter: 0; batch classifier loss: 0.070521; batch adversarial loss: 0.399583\n",
      "epoch 147; iter: 0; batch classifier loss: 0.012369; batch adversarial loss: 0.501999\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036954; batch adversarial loss: 0.456677\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040582; batch adversarial loss: 0.482266\n",
      "epoch 150; iter: 0; batch classifier loss: 0.065218; batch adversarial loss: 0.462629\n",
      "epoch 151; iter: 0; batch classifier loss: 0.007707; batch adversarial loss: 0.513734\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014007; batch adversarial loss: 0.538403\n",
      "epoch 153; iter: 0; batch classifier loss: 0.059327; batch adversarial loss: 0.422332\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022482; batch adversarial loss: 0.475268\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014042; batch adversarial loss: 0.505514\n",
      "epoch 156; iter: 0; batch classifier loss: 0.059787; batch adversarial loss: 0.458979\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029816; batch adversarial loss: 0.416354\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030521; batch adversarial loss: 0.358709\n",
      "epoch 159; iter: 0; batch classifier loss: 0.050508; batch adversarial loss: 0.539422\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021593; batch adversarial loss: 0.371313\n",
      "epoch 161; iter: 0; batch classifier loss: 0.061507; batch adversarial loss: 0.429536\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018368; batch adversarial loss: 0.484633\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036914; batch adversarial loss: 0.474919\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022316; batch adversarial loss: 0.433451\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026737; batch adversarial loss: 0.374561\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023968; batch adversarial loss: 0.461835\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017297; batch adversarial loss: 0.456612\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035221; batch adversarial loss: 0.445954\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016562; batch adversarial loss: 0.547340\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013679; batch adversarial loss: 0.543875\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009784; batch adversarial loss: 0.416555\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019606; batch adversarial loss: 0.496947\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014628; batch adversarial loss: 0.492198\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022621; batch adversarial loss: 0.497688\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025680; batch adversarial loss: 0.514226\n",
      "epoch 176; iter: 0; batch classifier loss: 0.036848; batch adversarial loss: 0.414298\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017216; batch adversarial loss: 0.402303\n",
      "epoch 178; iter: 0; batch classifier loss: 0.043785; batch adversarial loss: 0.416499\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029885; batch adversarial loss: 0.382913\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041351; batch adversarial loss: 0.435386\n",
      "epoch 181; iter: 0; batch classifier loss: 0.054312; batch adversarial loss: 0.464105\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014983; batch adversarial loss: 0.495237\n",
      "epoch 183; iter: 0; batch classifier loss: 0.043781; batch adversarial loss: 0.435952\n",
      "epoch 184; iter: 0; batch classifier loss: 0.048739; batch adversarial loss: 0.449697\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026595; batch adversarial loss: 0.422840\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011425; batch adversarial loss: 0.424198\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011380; batch adversarial loss: 0.495436\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012028; batch adversarial loss: 0.458946\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014656; batch adversarial loss: 0.456526\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021594; batch adversarial loss: 0.428528\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011528; batch adversarial loss: 0.373830\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021502; batch adversarial loss: 0.415058\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016033; batch adversarial loss: 0.342530\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015207; batch adversarial loss: 0.388549\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028947; batch adversarial loss: 0.519427\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027473; batch adversarial loss: 0.457539\n",
      "epoch 197; iter: 0; batch classifier loss: 0.037682; batch adversarial loss: 0.546761\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018094; batch adversarial loss: 0.501427\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012627; batch adversarial loss: 0.467222\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681361; batch adversarial loss: 0.609230\n",
      "epoch 1; iter: 0; batch classifier loss: 0.479924; batch adversarial loss: 0.631786\n",
      "epoch 2; iter: 0; batch classifier loss: 0.409320; batch adversarial loss: 0.567659\n",
      "epoch 3; iter: 0; batch classifier loss: 0.458626; batch adversarial loss: 0.579890\n",
      "epoch 4; iter: 0; batch classifier loss: 0.448841; batch adversarial loss: 0.565763\n",
      "epoch 5; iter: 0; batch classifier loss: 0.466535; batch adversarial loss: 0.586574\n",
      "epoch 6; iter: 0; batch classifier loss: 0.497859; batch adversarial loss: 0.537609\n",
      "epoch 7; iter: 0; batch classifier loss: 0.462412; batch adversarial loss: 0.577427\n",
      "epoch 8; iter: 0; batch classifier loss: 0.336586; batch adversarial loss: 0.520182\n",
      "epoch 9; iter: 0; batch classifier loss: 0.345680; batch adversarial loss: 0.457080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.327553; batch adversarial loss: 0.533265\n",
      "epoch 11; iter: 0; batch classifier loss: 0.360200; batch adversarial loss: 0.492442\n",
      "epoch 12; iter: 0; batch classifier loss: 0.244673; batch adversarial loss: 0.551864\n",
      "epoch 13; iter: 0; batch classifier loss: 0.259695; batch adversarial loss: 0.474183\n",
      "epoch 14; iter: 0; batch classifier loss: 0.264748; batch adversarial loss: 0.447585\n",
      "epoch 15; iter: 0; batch classifier loss: 0.257004; batch adversarial loss: 0.486300\n",
      "epoch 16; iter: 0; batch classifier loss: 0.146873; batch adversarial loss: 0.508704\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221343; batch adversarial loss: 0.449307\n",
      "epoch 18; iter: 0; batch classifier loss: 0.193714; batch adversarial loss: 0.491867\n",
      "epoch 19; iter: 0; batch classifier loss: 0.242150; batch adversarial loss: 0.423348\n",
      "epoch 20; iter: 0; batch classifier loss: 0.213798; batch adversarial loss: 0.478904\n",
      "epoch 21; iter: 0; batch classifier loss: 0.210929; batch adversarial loss: 0.510503\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206404; batch adversarial loss: 0.451145\n",
      "epoch 23; iter: 0; batch classifier loss: 0.187646; batch adversarial loss: 0.489548\n",
      "epoch 24; iter: 0; batch classifier loss: 0.212972; batch adversarial loss: 0.421871\n",
      "epoch 25; iter: 0; batch classifier loss: 0.211387; batch adversarial loss: 0.553504\n",
      "epoch 26; iter: 0; batch classifier loss: 0.175891; batch adversarial loss: 0.439889\n",
      "epoch 27; iter: 0; batch classifier loss: 0.153076; batch adversarial loss: 0.494986\n",
      "epoch 28; iter: 0; batch classifier loss: 0.131448; batch adversarial loss: 0.472941\n",
      "epoch 29; iter: 0; batch classifier loss: 0.154821; batch adversarial loss: 0.488796\n",
      "epoch 30; iter: 0; batch classifier loss: 0.162484; batch adversarial loss: 0.478847\n",
      "epoch 31; iter: 0; batch classifier loss: 0.173847; batch adversarial loss: 0.438532\n",
      "epoch 32; iter: 0; batch classifier loss: 0.123838; batch adversarial loss: 0.453573\n",
      "epoch 33; iter: 0; batch classifier loss: 0.172445; batch adversarial loss: 0.428378\n",
      "epoch 34; iter: 0; batch classifier loss: 0.137487; batch adversarial loss: 0.427329\n",
      "epoch 35; iter: 0; batch classifier loss: 0.151154; batch adversarial loss: 0.493799\n",
      "epoch 36; iter: 0; batch classifier loss: 0.198592; batch adversarial loss: 0.518332\n",
      "epoch 37; iter: 0; batch classifier loss: 0.188883; batch adversarial loss: 0.458464\n",
      "epoch 38; iter: 0; batch classifier loss: 0.110903; batch adversarial loss: 0.520571\n",
      "epoch 39; iter: 0; batch classifier loss: 0.160253; batch adversarial loss: 0.599556\n",
      "epoch 40; iter: 0; batch classifier loss: 0.151146; batch adversarial loss: 0.480866\n",
      "epoch 41; iter: 0; batch classifier loss: 0.218615; batch adversarial loss: 0.477681\n",
      "epoch 42; iter: 0; batch classifier loss: 0.168282; batch adversarial loss: 0.532917\n",
      "epoch 43; iter: 0; batch classifier loss: 0.141382; batch adversarial loss: 0.426461\n",
      "epoch 44; iter: 0; batch classifier loss: 0.163550; batch adversarial loss: 0.529662\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108917; batch adversarial loss: 0.376100\n",
      "epoch 46; iter: 0; batch classifier loss: 0.168578; batch adversarial loss: 0.535837\n",
      "epoch 47; iter: 0; batch classifier loss: 0.197042; batch adversarial loss: 0.345651\n",
      "epoch 48; iter: 0; batch classifier loss: 0.129110; batch adversarial loss: 0.516371\n",
      "epoch 49; iter: 0; batch classifier loss: 0.170321; batch adversarial loss: 0.477329\n",
      "epoch 50; iter: 0; batch classifier loss: 0.176250; batch adversarial loss: 0.544134\n",
      "epoch 51; iter: 0; batch classifier loss: 0.165935; batch adversarial loss: 0.459627\n",
      "epoch 52; iter: 0; batch classifier loss: 0.117629; batch adversarial loss: 0.437750\n",
      "epoch 53; iter: 0; batch classifier loss: 0.111759; batch adversarial loss: 0.401526\n",
      "epoch 54; iter: 0; batch classifier loss: 0.159733; batch adversarial loss: 0.494931\n",
      "epoch 55; iter: 0; batch classifier loss: 0.173037; batch adversarial loss: 0.426630\n",
      "epoch 56; iter: 0; batch classifier loss: 0.170441; batch adversarial loss: 0.467108\n",
      "epoch 57; iter: 0; batch classifier loss: 0.177055; batch adversarial loss: 0.495369\n",
      "epoch 58; iter: 0; batch classifier loss: 0.253126; batch adversarial loss: 0.436125\n",
      "epoch 59; iter: 0; batch classifier loss: 0.151510; batch adversarial loss: 0.554662\n",
      "epoch 60; iter: 0; batch classifier loss: 0.173930; batch adversarial loss: 0.446789\n",
      "epoch 61; iter: 0; batch classifier loss: 0.164923; batch adversarial loss: 0.421426\n",
      "epoch 62; iter: 0; batch classifier loss: 0.098890; batch adversarial loss: 0.485702\n",
      "epoch 63; iter: 0; batch classifier loss: 0.196493; batch adversarial loss: 0.413069\n",
      "epoch 64; iter: 0; batch classifier loss: 0.167524; batch adversarial loss: 0.505902\n",
      "epoch 65; iter: 0; batch classifier loss: 0.194427; batch adversarial loss: 0.468991\n",
      "epoch 66; iter: 0; batch classifier loss: 0.191057; batch adversarial loss: 0.423376\n",
      "epoch 67; iter: 0; batch classifier loss: 0.175619; batch adversarial loss: 0.506313\n",
      "epoch 68; iter: 0; batch classifier loss: 0.157217; batch adversarial loss: 0.531441\n",
      "epoch 69; iter: 0; batch classifier loss: 0.166178; batch adversarial loss: 0.423194\n",
      "epoch 70; iter: 0; batch classifier loss: 0.116868; batch adversarial loss: 0.566745\n",
      "epoch 71; iter: 0; batch classifier loss: 0.174810; batch adversarial loss: 0.495763\n",
      "epoch 72; iter: 0; batch classifier loss: 0.183621; batch adversarial loss: 0.339036\n",
      "epoch 73; iter: 0; batch classifier loss: 0.165917; batch adversarial loss: 0.435186\n",
      "epoch 74; iter: 0; batch classifier loss: 0.134756; batch adversarial loss: 0.446557\n",
      "epoch 75; iter: 0; batch classifier loss: 0.244677; batch adversarial loss: 0.445469\n",
      "epoch 76; iter: 0; batch classifier loss: 0.153709; batch adversarial loss: 0.446855\n",
      "epoch 77; iter: 0; batch classifier loss: 0.170312; batch adversarial loss: 0.482418\n",
      "epoch 78; iter: 0; batch classifier loss: 0.244947; batch adversarial loss: 0.435020\n",
      "epoch 79; iter: 0; batch classifier loss: 0.143895; batch adversarial loss: 0.470621\n",
      "epoch 80; iter: 0; batch classifier loss: 0.147139; batch adversarial loss: 0.434786\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096082; batch adversarial loss: 0.459769\n",
      "epoch 82; iter: 0; batch classifier loss: 0.136395; batch adversarial loss: 0.582731\n",
      "epoch 83; iter: 0; batch classifier loss: 0.170731; batch adversarial loss: 0.517817\n",
      "epoch 84; iter: 0; batch classifier loss: 0.158809; batch adversarial loss: 0.494700\n",
      "epoch 85; iter: 0; batch classifier loss: 0.161208; batch adversarial loss: 0.470901\n",
      "epoch 86; iter: 0; batch classifier loss: 0.190016; batch adversarial loss: 0.472309\n",
      "epoch 87; iter: 0; batch classifier loss: 0.138033; batch adversarial loss: 0.420815\n",
      "epoch 88; iter: 0; batch classifier loss: 0.164108; batch adversarial loss: 0.473551\n",
      "epoch 89; iter: 0; batch classifier loss: 0.189734; batch adversarial loss: 0.457780\n",
      "epoch 90; iter: 0; batch classifier loss: 0.165601; batch adversarial loss: 0.409875\n",
      "epoch 91; iter: 0; batch classifier loss: 0.160970; batch adversarial loss: 0.519015\n",
      "epoch 92; iter: 0; batch classifier loss: 0.226775; batch adversarial loss: 0.470876\n",
      "epoch 93; iter: 0; batch classifier loss: 0.157714; batch adversarial loss: 0.507053\n",
      "epoch 94; iter: 0; batch classifier loss: 0.129086; batch adversarial loss: 0.530984\n",
      "epoch 95; iter: 0; batch classifier loss: 0.152553; batch adversarial loss: 0.374679\n",
      "epoch 96; iter: 0; batch classifier loss: 0.157580; batch adversarial loss: 0.459799\n",
      "epoch 97; iter: 0; batch classifier loss: 0.136025; batch adversarial loss: 0.421821\n",
      "epoch 98; iter: 0; batch classifier loss: 0.187912; batch adversarial loss: 0.434947\n",
      "epoch 99; iter: 0; batch classifier loss: 0.117295; batch adversarial loss: 0.458448\n",
      "epoch 100; iter: 0; batch classifier loss: 0.151844; batch adversarial loss: 0.385518\n",
      "epoch 101; iter: 0; batch classifier loss: 0.162966; batch adversarial loss: 0.506615\n",
      "epoch 102; iter: 0; batch classifier loss: 0.113759; batch adversarial loss: 0.496273\n",
      "epoch 103; iter: 0; batch classifier loss: 0.142161; batch adversarial loss: 0.458224\n",
      "epoch 104; iter: 0; batch classifier loss: 0.151319; batch adversarial loss: 0.495585\n",
      "epoch 105; iter: 0; batch classifier loss: 0.218969; batch adversarial loss: 0.519381\n",
      "epoch 106; iter: 0; batch classifier loss: 0.161965; batch adversarial loss: 0.461045\n",
      "epoch 107; iter: 0; batch classifier loss: 0.153355; batch adversarial loss: 0.422389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.173655; batch adversarial loss: 0.483576\n",
      "epoch 109; iter: 0; batch classifier loss: 0.141589; batch adversarial loss: 0.592614\n",
      "epoch 110; iter: 0; batch classifier loss: 0.141596; batch adversarial loss: 0.522698\n",
      "epoch 111; iter: 0; batch classifier loss: 0.175681; batch adversarial loss: 0.544072\n",
      "epoch 112; iter: 0; batch classifier loss: 0.151678; batch adversarial loss: 0.482944\n",
      "epoch 113; iter: 0; batch classifier loss: 0.124753; batch adversarial loss: 0.434775\n",
      "epoch 114; iter: 0; batch classifier loss: 0.126169; batch adversarial loss: 0.423425\n",
      "epoch 115; iter: 0; batch classifier loss: 0.129066; batch adversarial loss: 0.505462\n",
      "epoch 116; iter: 0; batch classifier loss: 0.122112; batch adversarial loss: 0.432883\n",
      "epoch 117; iter: 0; batch classifier loss: 0.127575; batch adversarial loss: 0.471864\n",
      "epoch 118; iter: 0; batch classifier loss: 0.142741; batch adversarial loss: 0.529580\n",
      "epoch 119; iter: 0; batch classifier loss: 0.119983; batch adversarial loss: 0.492937\n",
      "epoch 120; iter: 0; batch classifier loss: 0.148154; batch adversarial loss: 0.469060\n",
      "epoch 121; iter: 0; batch classifier loss: 0.122915; batch adversarial loss: 0.420782\n",
      "epoch 122; iter: 0; batch classifier loss: 0.106273; batch adversarial loss: 0.472609\n",
      "epoch 123; iter: 0; batch classifier loss: 0.105549; batch adversarial loss: 0.446521\n",
      "epoch 124; iter: 0; batch classifier loss: 0.101867; batch adversarial loss: 0.393292\n",
      "epoch 125; iter: 0; batch classifier loss: 0.122227; batch adversarial loss: 0.432868\n",
      "epoch 126; iter: 0; batch classifier loss: 0.086719; batch adversarial loss: 0.432422\n",
      "epoch 127; iter: 0; batch classifier loss: 0.089818; batch adversarial loss: 0.408092\n",
      "epoch 128; iter: 0; batch classifier loss: 0.077295; batch adversarial loss: 0.431599\n",
      "epoch 129; iter: 0; batch classifier loss: 0.055816; batch adversarial loss: 0.456783\n",
      "epoch 130; iter: 0; batch classifier loss: 0.077264; batch adversarial loss: 0.494650\n",
      "epoch 131; iter: 0; batch classifier loss: 0.054871; batch adversarial loss: 0.507455\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053209; batch adversarial loss: 0.429207\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037037; batch adversarial loss: 0.450232\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027166; batch adversarial loss: 0.497894\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046982; batch adversarial loss: 0.461056\n",
      "epoch 136; iter: 0; batch classifier loss: 0.061497; batch adversarial loss: 0.486026\n",
      "epoch 137; iter: 0; batch classifier loss: 0.071709; batch adversarial loss: 0.423259\n",
      "epoch 138; iter: 0; batch classifier loss: 0.080052; batch adversarial loss: 0.497405\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035342; batch adversarial loss: 0.530579\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013494; batch adversarial loss: 0.546622\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038979; batch adversarial loss: 0.472200\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040642; batch adversarial loss: 0.480213\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032621; batch adversarial loss: 0.495778\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020138; batch adversarial loss: 0.467054\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025766; batch adversarial loss: 0.386607\n",
      "epoch 146; iter: 0; batch classifier loss: 0.049372; batch adversarial loss: 0.351838\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035411; batch adversarial loss: 0.480099\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029358; batch adversarial loss: 0.432479\n",
      "epoch 149; iter: 0; batch classifier loss: 0.051867; batch adversarial loss: 0.436849\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031326; batch adversarial loss: 0.496483\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024953; batch adversarial loss: 0.605944\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041483; batch adversarial loss: 0.494638\n",
      "epoch 153; iter: 0; batch classifier loss: 0.007902; batch adversarial loss: 0.445210\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021633; batch adversarial loss: 0.404155\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027079; batch adversarial loss: 0.470913\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025390; batch adversarial loss: 0.398021\n",
      "epoch 157; iter: 0; batch classifier loss: 0.077977; batch adversarial loss: 0.377512\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014256; batch adversarial loss: 0.539308\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017808; batch adversarial loss: 0.406222\n",
      "epoch 160; iter: 0; batch classifier loss: 0.040522; batch adversarial loss: 0.349838\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015832; batch adversarial loss: 0.390041\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018451; batch adversarial loss: 0.498108\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018386; batch adversarial loss: 0.483911\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024926; batch adversarial loss: 0.435950\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023010; batch adversarial loss: 0.359293\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019404; batch adversarial loss: 0.443889\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023212; batch adversarial loss: 0.429451\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013465; batch adversarial loss: 0.516031\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021234; batch adversarial loss: 0.622719\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008945; batch adversarial loss: 0.526564\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021080; batch adversarial loss: 0.575533\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036053; batch adversarial loss: 0.422331\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009157; batch adversarial loss: 0.476059\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016212; batch adversarial loss: 0.510861\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027609; batch adversarial loss: 0.432623\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012911; batch adversarial loss: 0.393340\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022408; batch adversarial loss: 0.478218\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010583; batch adversarial loss: 0.476767\n",
      "epoch 179; iter: 0; batch classifier loss: 0.042687; batch adversarial loss: 0.442571\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021879; batch adversarial loss: 0.416731\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012691; batch adversarial loss: 0.444822\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018804; batch adversarial loss: 0.420234\n",
      "epoch 183; iter: 0; batch classifier loss: 0.035106; batch adversarial loss: 0.479676\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004099; batch adversarial loss: 0.568838\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022081; batch adversarial loss: 0.508916\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017546; batch adversarial loss: 0.367572\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025667; batch adversarial loss: 0.431127\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027844; batch adversarial loss: 0.414420\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016692; batch adversarial loss: 0.468789\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035129; batch adversarial loss: 0.572364\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018317; batch adversarial loss: 0.413048\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029367; batch adversarial loss: 0.408040\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012709; batch adversarial loss: 0.437819\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012877; batch adversarial loss: 0.427913\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024173; batch adversarial loss: 0.526411\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019424; batch adversarial loss: 0.434120\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007481; batch adversarial loss: 0.584252\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012851; batch adversarial loss: 0.463291\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027352; batch adversarial loss: 0.451216\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703093; batch adversarial loss: 0.648263\n",
      "epoch 1; iter: 0; batch classifier loss: 0.463980; batch adversarial loss: 0.634813\n",
      "epoch 2; iter: 0; batch classifier loss: 0.425393; batch adversarial loss: 0.623647\n",
      "epoch 3; iter: 0; batch classifier loss: 0.403585; batch adversarial loss: 0.602652\n",
      "epoch 4; iter: 0; batch classifier loss: 0.290186; batch adversarial loss: 0.555943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.231732; batch adversarial loss: 0.588163\n",
      "epoch 6; iter: 0; batch classifier loss: 0.262087; batch adversarial loss: 0.541774\n",
      "epoch 7; iter: 0; batch classifier loss: 0.326422; batch adversarial loss: 0.511717\n",
      "epoch 8; iter: 0; batch classifier loss: 0.249835; batch adversarial loss: 0.528755\n",
      "epoch 9; iter: 0; batch classifier loss: 0.285775; batch adversarial loss: 0.480912\n",
      "epoch 10; iter: 0; batch classifier loss: 0.222596; batch adversarial loss: 0.531983\n",
      "epoch 11; iter: 0; batch classifier loss: 0.243826; batch adversarial loss: 0.489781\n",
      "epoch 12; iter: 0; batch classifier loss: 0.210478; batch adversarial loss: 0.468565\n",
      "epoch 13; iter: 0; batch classifier loss: 0.215055; batch adversarial loss: 0.471013\n",
      "epoch 14; iter: 0; batch classifier loss: 0.248384; batch adversarial loss: 0.480316\n",
      "epoch 15; iter: 0; batch classifier loss: 0.252219; batch adversarial loss: 0.481910\n",
      "epoch 16; iter: 0; batch classifier loss: 0.153162; batch adversarial loss: 0.460149\n",
      "epoch 17; iter: 0; batch classifier loss: 0.158374; batch adversarial loss: 0.489939\n",
      "epoch 18; iter: 0; batch classifier loss: 0.180862; batch adversarial loss: 0.561558\n",
      "epoch 19; iter: 0; batch classifier loss: 0.196185; batch adversarial loss: 0.518851\n",
      "epoch 20; iter: 0; batch classifier loss: 0.181678; batch adversarial loss: 0.580954\n",
      "epoch 21; iter: 0; batch classifier loss: 0.215016; batch adversarial loss: 0.526485\n",
      "epoch 22; iter: 0; batch classifier loss: 0.191067; batch adversarial loss: 0.491334\n",
      "epoch 23; iter: 0; batch classifier loss: 0.215349; batch adversarial loss: 0.591206\n",
      "epoch 24; iter: 0; batch classifier loss: 0.164882; batch adversarial loss: 0.452385\n",
      "epoch 25; iter: 0; batch classifier loss: 0.192079; batch adversarial loss: 0.516269\n",
      "epoch 26; iter: 0; batch classifier loss: 0.166356; batch adversarial loss: 0.507919\n",
      "epoch 27; iter: 0; batch classifier loss: 0.222288; batch adversarial loss: 0.489236\n",
      "epoch 28; iter: 0; batch classifier loss: 0.181786; batch adversarial loss: 0.489064\n",
      "epoch 29; iter: 0; batch classifier loss: 0.311096; batch adversarial loss: 0.546527\n",
      "epoch 30; iter: 0; batch classifier loss: 0.212049; batch adversarial loss: 0.524119\n",
      "epoch 31; iter: 0; batch classifier loss: 0.227165; batch adversarial loss: 0.521931\n",
      "epoch 32; iter: 0; batch classifier loss: 0.237651; batch adversarial loss: 0.497927\n",
      "epoch 33; iter: 0; batch classifier loss: 0.196882; batch adversarial loss: 0.455306\n",
      "epoch 34; iter: 0; batch classifier loss: 0.143454; batch adversarial loss: 0.542712\n",
      "epoch 35; iter: 0; batch classifier loss: 0.112073; batch adversarial loss: 0.556489\n",
      "epoch 36; iter: 0; batch classifier loss: 0.117844; batch adversarial loss: 0.452435\n",
      "epoch 37; iter: 0; batch classifier loss: 0.070408; batch adversarial loss: 0.484827\n",
      "epoch 38; iter: 0; batch classifier loss: 0.120860; batch adversarial loss: 0.538673\n",
      "epoch 39; iter: 0; batch classifier loss: 0.134130; batch adversarial loss: 0.450846\n",
      "epoch 40; iter: 0; batch classifier loss: 0.092330; batch adversarial loss: 0.469961\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123058; batch adversarial loss: 0.421041\n",
      "epoch 42; iter: 0; batch classifier loss: 0.099581; batch adversarial loss: 0.532590\n",
      "epoch 43; iter: 0; batch classifier loss: 0.053697; batch adversarial loss: 0.429216\n",
      "epoch 44; iter: 0; batch classifier loss: 0.081311; batch adversarial loss: 0.459440\n",
      "epoch 45; iter: 0; batch classifier loss: 0.092513; batch adversarial loss: 0.518998\n",
      "epoch 46; iter: 0; batch classifier loss: 0.069064; batch adversarial loss: 0.404105\n",
      "epoch 47; iter: 0; batch classifier loss: 0.094693; batch adversarial loss: 0.523348\n",
      "epoch 48; iter: 0; batch classifier loss: 0.067863; batch adversarial loss: 0.493978\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094018; batch adversarial loss: 0.531105\n",
      "epoch 50; iter: 0; batch classifier loss: 0.046418; batch adversarial loss: 0.503700\n",
      "epoch 51; iter: 0; batch classifier loss: 0.054456; batch adversarial loss: 0.451707\n",
      "epoch 52; iter: 0; batch classifier loss: 0.060649; batch adversarial loss: 0.534718\n",
      "epoch 53; iter: 0; batch classifier loss: 0.108931; batch adversarial loss: 0.401282\n",
      "epoch 54; iter: 0; batch classifier loss: 0.101238; batch adversarial loss: 0.442645\n",
      "epoch 55; iter: 0; batch classifier loss: 0.070023; batch adversarial loss: 0.508581\n",
      "epoch 56; iter: 0; batch classifier loss: 0.088592; batch adversarial loss: 0.463209\n",
      "epoch 57; iter: 0; batch classifier loss: 0.059029; batch adversarial loss: 0.487945\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077941; batch adversarial loss: 0.488125\n",
      "epoch 59; iter: 0; batch classifier loss: 0.075684; batch adversarial loss: 0.397378\n",
      "epoch 60; iter: 0; batch classifier loss: 0.067942; batch adversarial loss: 0.464969\n",
      "epoch 61; iter: 0; batch classifier loss: 0.070236; batch adversarial loss: 0.452822\n",
      "epoch 62; iter: 0; batch classifier loss: 0.070043; batch adversarial loss: 0.492688\n",
      "epoch 63; iter: 0; batch classifier loss: 0.047769; batch adversarial loss: 0.545464\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073191; batch adversarial loss: 0.505038\n",
      "epoch 65; iter: 0; batch classifier loss: 0.136090; batch adversarial loss: 0.427607\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062649; batch adversarial loss: 0.487863\n",
      "epoch 67; iter: 0; batch classifier loss: 0.057410; batch adversarial loss: 0.535932\n",
      "epoch 68; iter: 0; batch classifier loss: 0.085629; batch adversarial loss: 0.471739\n",
      "epoch 69; iter: 0; batch classifier loss: 0.070116; batch adversarial loss: 0.461023\n",
      "epoch 70; iter: 0; batch classifier loss: 0.064937; batch adversarial loss: 0.513185\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058929; batch adversarial loss: 0.479239\n",
      "epoch 72; iter: 0; batch classifier loss: 0.111308; batch adversarial loss: 0.507410\n",
      "epoch 73; iter: 0; batch classifier loss: 0.071167; batch adversarial loss: 0.500950\n",
      "epoch 74; iter: 0; batch classifier loss: 0.059774; batch adversarial loss: 0.467419\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073632; batch adversarial loss: 0.428532\n",
      "epoch 76; iter: 0; batch classifier loss: 0.046429; batch adversarial loss: 0.506841\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063838; batch adversarial loss: 0.444277\n",
      "epoch 78; iter: 0; batch classifier loss: 0.070545; batch adversarial loss: 0.500116\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053429; batch adversarial loss: 0.466442\n",
      "epoch 80; iter: 0; batch classifier loss: 0.104197; batch adversarial loss: 0.445983\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083846; batch adversarial loss: 0.459949\n",
      "epoch 82; iter: 0; batch classifier loss: 0.093870; batch adversarial loss: 0.397866\n",
      "epoch 83; iter: 0; batch classifier loss: 0.082646; batch adversarial loss: 0.542821\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067982; batch adversarial loss: 0.480117\n",
      "epoch 85; iter: 0; batch classifier loss: 0.045932; batch adversarial loss: 0.449591\n",
      "epoch 86; iter: 0; batch classifier loss: 0.032734; batch adversarial loss: 0.411879\n",
      "epoch 87; iter: 0; batch classifier loss: 0.098870; batch adversarial loss: 0.478281\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062312; batch adversarial loss: 0.522617\n",
      "epoch 89; iter: 0; batch classifier loss: 0.084905; batch adversarial loss: 0.496977\n",
      "epoch 90; iter: 0; batch classifier loss: 0.080088; batch adversarial loss: 0.432858\n",
      "epoch 91; iter: 0; batch classifier loss: 0.076034; batch adversarial loss: 0.415805\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070491; batch adversarial loss: 0.414930\n",
      "epoch 93; iter: 0; batch classifier loss: 0.030261; batch adversarial loss: 0.512438\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075480; batch adversarial loss: 0.411909\n",
      "epoch 95; iter: 0; batch classifier loss: 0.055817; batch adversarial loss: 0.413017\n",
      "epoch 96; iter: 0; batch classifier loss: 0.030954; batch adversarial loss: 0.462356\n",
      "epoch 97; iter: 0; batch classifier loss: 0.036714; batch adversarial loss: 0.558435\n",
      "epoch 98; iter: 0; batch classifier loss: 0.034472; batch adversarial loss: 0.520689\n",
      "epoch 99; iter: 0; batch classifier loss: 0.035067; batch adversarial loss: 0.486443\n",
      "epoch 100; iter: 0; batch classifier loss: 0.040861; batch adversarial loss: 0.479261\n",
      "epoch 101; iter: 0; batch classifier loss: 0.038115; batch adversarial loss: 0.492725\n",
      "epoch 102; iter: 0; batch classifier loss: 0.039175; batch adversarial loss: 0.482942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103; iter: 0; batch classifier loss: 0.028590; batch adversarial loss: 0.459071\n",
      "epoch 104; iter: 0; batch classifier loss: 0.067059; batch adversarial loss: 0.439821\n",
      "epoch 105; iter: 0; batch classifier loss: 0.070210; batch adversarial loss: 0.424658\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036866; batch adversarial loss: 0.490419\n",
      "epoch 107; iter: 0; batch classifier loss: 0.096186; batch adversarial loss: 0.452172\n",
      "epoch 108; iter: 0; batch classifier loss: 0.016130; batch adversarial loss: 0.553069\n",
      "epoch 109; iter: 0; batch classifier loss: 0.113099; batch adversarial loss: 0.475426\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025230; batch adversarial loss: 0.601547\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047140; batch adversarial loss: 0.508389\n",
      "epoch 112; iter: 0; batch classifier loss: 0.076883; batch adversarial loss: 0.484838\n",
      "epoch 113; iter: 0; batch classifier loss: 0.111481; batch adversarial loss: 0.487066\n",
      "epoch 114; iter: 0; batch classifier loss: 0.080214; batch adversarial loss: 0.480600\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037671; batch adversarial loss: 0.425354\n",
      "epoch 116; iter: 0; batch classifier loss: 0.064155; batch adversarial loss: 0.467712\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036259; batch adversarial loss: 0.543401\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060255; batch adversarial loss: 0.414524\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053215; batch adversarial loss: 0.459071\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053347; batch adversarial loss: 0.482414\n",
      "epoch 121; iter: 0; batch classifier loss: 0.067320; batch adversarial loss: 0.447216\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034062; batch adversarial loss: 0.420099\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019801; batch adversarial loss: 0.454050\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067464; batch adversarial loss: 0.410383\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026196; batch adversarial loss: 0.495846\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026841; batch adversarial loss: 0.446287\n",
      "epoch 127; iter: 0; batch classifier loss: 0.083170; batch adversarial loss: 0.456194\n",
      "epoch 128; iter: 0; batch classifier loss: 0.070331; batch adversarial loss: 0.395322\n",
      "epoch 129; iter: 0; batch classifier loss: 0.044647; batch adversarial loss: 0.473447\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040882; batch adversarial loss: 0.452723\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035077; batch adversarial loss: 0.497358\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029937; batch adversarial loss: 0.470329\n",
      "epoch 133; iter: 0; batch classifier loss: 0.062319; batch adversarial loss: 0.496169\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018329; batch adversarial loss: 0.400455\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040456; batch adversarial loss: 0.472352\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028365; batch adversarial loss: 0.563405\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039945; batch adversarial loss: 0.451202\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045671; batch adversarial loss: 0.449746\n",
      "epoch 139; iter: 0; batch classifier loss: 0.051972; batch adversarial loss: 0.510957\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021640; batch adversarial loss: 0.457672\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023397; batch adversarial loss: 0.436480\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040433; batch adversarial loss: 0.470970\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024611; batch adversarial loss: 0.538933\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029925; batch adversarial loss: 0.394263\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033626; batch adversarial loss: 0.394586\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030386; batch adversarial loss: 0.520891\n",
      "epoch 147; iter: 0; batch classifier loss: 0.055749; batch adversarial loss: 0.491052\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014243; batch adversarial loss: 0.479492\n",
      "epoch 149; iter: 0; batch classifier loss: 0.047871; batch adversarial loss: 0.501515\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031437; batch adversarial loss: 0.594388\n",
      "epoch 151; iter: 0; batch classifier loss: 0.050901; batch adversarial loss: 0.442512\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028051; batch adversarial loss: 0.519383\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023309; batch adversarial loss: 0.411796\n",
      "epoch 154; iter: 0; batch classifier loss: 0.060603; batch adversarial loss: 0.532197\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032653; batch adversarial loss: 0.448418\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037581; batch adversarial loss: 0.490301\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040811; batch adversarial loss: 0.510421\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038721; batch adversarial loss: 0.414311\n",
      "epoch 159; iter: 0; batch classifier loss: 0.047361; batch adversarial loss: 0.486702\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016114; batch adversarial loss: 0.533510\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032823; batch adversarial loss: 0.456309\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032521; batch adversarial loss: 0.425090\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023582; batch adversarial loss: 0.553560\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026166; batch adversarial loss: 0.451527\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029767; batch adversarial loss: 0.504995\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036737; batch adversarial loss: 0.486921\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035019; batch adversarial loss: 0.541246\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038767; batch adversarial loss: 0.367290\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016594; batch adversarial loss: 0.460637\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014670; batch adversarial loss: 0.496380\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019622; batch adversarial loss: 0.390026\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030004; batch adversarial loss: 0.445256\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025845; batch adversarial loss: 0.535471\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019248; batch adversarial loss: 0.439172\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018126; batch adversarial loss: 0.432806\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015791; batch adversarial loss: 0.555536\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015929; batch adversarial loss: 0.391732\n",
      "epoch 178; iter: 0; batch classifier loss: 0.045591; batch adversarial loss: 0.533246\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023947; batch adversarial loss: 0.552333\n",
      "epoch 180; iter: 0; batch classifier loss: 0.036491; batch adversarial loss: 0.429895\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029591; batch adversarial loss: 0.538179\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013803; batch adversarial loss: 0.426134\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009181; batch adversarial loss: 0.520418\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030273; batch adversarial loss: 0.489565\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016284; batch adversarial loss: 0.452421\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025577; batch adversarial loss: 0.521882\n",
      "epoch 187; iter: 0; batch classifier loss: 0.041765; batch adversarial loss: 0.571088\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041243; batch adversarial loss: 0.552092\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026524; batch adversarial loss: 0.544718\n",
      "epoch 190; iter: 0; batch classifier loss: 0.050781; batch adversarial loss: 0.440197\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018192; batch adversarial loss: 0.438544\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026865; batch adversarial loss: 0.403337\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017211; batch adversarial loss: 0.360780\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033346; batch adversarial loss: 0.494638\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017752; batch adversarial loss: 0.469707\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021876; batch adversarial loss: 0.385818\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011488; batch adversarial loss: 0.488174\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015799; batch adversarial loss: 0.603371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199; iter: 0; batch classifier loss: 0.010942; batch adversarial loss: 0.401439\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674436; batch adversarial loss: 0.841223\n",
      "epoch 1; iter: 0; batch classifier loss: 0.425745; batch adversarial loss: 0.855192\n",
      "epoch 2; iter: 0; batch classifier loss: 0.490626; batch adversarial loss: 0.787175\n",
      "epoch 3; iter: 0; batch classifier loss: 0.456292; batch adversarial loss: 0.745126\n",
      "epoch 4; iter: 0; batch classifier loss: 0.434762; batch adversarial loss: 0.704917\n",
      "epoch 5; iter: 0; batch classifier loss: 0.497502; batch adversarial loss: 0.637597\n",
      "epoch 6; iter: 0; batch classifier loss: 0.375597; batch adversarial loss: 0.585134\n",
      "epoch 7; iter: 0; batch classifier loss: 0.343448; batch adversarial loss: 0.585259\n",
      "epoch 8; iter: 0; batch classifier loss: 0.251814; batch adversarial loss: 0.555691\n",
      "epoch 9; iter: 0; batch classifier loss: 0.306126; batch adversarial loss: 0.558194\n",
      "epoch 10; iter: 0; batch classifier loss: 0.244766; batch adversarial loss: 0.573866\n",
      "epoch 11; iter: 0; batch classifier loss: 0.287559; batch adversarial loss: 0.501401\n",
      "epoch 12; iter: 0; batch classifier loss: 0.166626; batch adversarial loss: 0.499850\n",
      "epoch 13; iter: 0; batch classifier loss: 0.245265; batch adversarial loss: 0.502748\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236209; batch adversarial loss: 0.466632\n",
      "epoch 15; iter: 0; batch classifier loss: 0.233777; batch adversarial loss: 0.522786\n",
      "epoch 16; iter: 0; batch classifier loss: 0.194464; batch adversarial loss: 0.514932\n",
      "epoch 17; iter: 0; batch classifier loss: 0.159427; batch adversarial loss: 0.392713\n",
      "epoch 18; iter: 0; batch classifier loss: 0.223940; batch adversarial loss: 0.513552\n",
      "epoch 19; iter: 0; batch classifier loss: 0.182300; batch adversarial loss: 0.439157\n",
      "epoch 20; iter: 0; batch classifier loss: 0.124373; batch adversarial loss: 0.423227\n",
      "epoch 21; iter: 0; batch classifier loss: 0.146529; batch adversarial loss: 0.480232\n",
      "epoch 22; iter: 0; batch classifier loss: 0.159479; batch adversarial loss: 0.435868\n",
      "epoch 23; iter: 0; batch classifier loss: 0.163133; batch adversarial loss: 0.453956\n",
      "epoch 24; iter: 0; batch classifier loss: 0.168354; batch adversarial loss: 0.430455\n",
      "epoch 25; iter: 0; batch classifier loss: 0.104881; batch adversarial loss: 0.494920\n",
      "epoch 26; iter: 0; batch classifier loss: 0.112442; batch adversarial loss: 0.403713\n",
      "epoch 27; iter: 0; batch classifier loss: 0.141670; batch adversarial loss: 0.545516\n",
      "epoch 28; iter: 0; batch classifier loss: 0.126316; batch adversarial loss: 0.434928\n",
      "epoch 29; iter: 0; batch classifier loss: 0.168826; batch adversarial loss: 0.420869\n",
      "epoch 30; iter: 0; batch classifier loss: 0.110777; batch adversarial loss: 0.486746\n",
      "epoch 31; iter: 0; batch classifier loss: 0.127962; batch adversarial loss: 0.479342\n",
      "epoch 32; iter: 0; batch classifier loss: 0.121476; batch adversarial loss: 0.477059\n",
      "epoch 33; iter: 0; batch classifier loss: 0.113157; batch adversarial loss: 0.432693\n",
      "epoch 34; iter: 0; batch classifier loss: 0.097560; batch adversarial loss: 0.489648\n",
      "epoch 35; iter: 0; batch classifier loss: 0.107521; batch adversarial loss: 0.424977\n",
      "epoch 36; iter: 0; batch classifier loss: 0.120100; batch adversarial loss: 0.428205\n",
      "epoch 37; iter: 0; batch classifier loss: 0.105759; batch adversarial loss: 0.510341\n",
      "epoch 38; iter: 0; batch classifier loss: 0.085757; batch adversarial loss: 0.398025\n",
      "epoch 39; iter: 0; batch classifier loss: 0.118192; batch adversarial loss: 0.396157\n",
      "epoch 40; iter: 0; batch classifier loss: 0.092044; batch adversarial loss: 0.507999\n",
      "epoch 41; iter: 0; batch classifier loss: 0.140417; batch adversarial loss: 0.403291\n",
      "epoch 42; iter: 0; batch classifier loss: 0.081855; batch adversarial loss: 0.452381\n",
      "epoch 43; iter: 0; batch classifier loss: 0.085472; batch adversarial loss: 0.529836\n",
      "epoch 44; iter: 0; batch classifier loss: 0.078651; batch adversarial loss: 0.530017\n",
      "epoch 45; iter: 0; batch classifier loss: 0.075897; batch adversarial loss: 0.447201\n",
      "epoch 46; iter: 0; batch classifier loss: 0.115627; batch adversarial loss: 0.464159\n",
      "epoch 47; iter: 0; batch classifier loss: 0.130335; batch adversarial loss: 0.457033\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082635; batch adversarial loss: 0.523313\n",
      "epoch 49; iter: 0; batch classifier loss: 0.078869; batch adversarial loss: 0.415589\n",
      "epoch 50; iter: 0; batch classifier loss: 0.081558; batch adversarial loss: 0.471770\n",
      "epoch 51; iter: 0; batch classifier loss: 0.135522; batch adversarial loss: 0.530251\n",
      "epoch 52; iter: 0; batch classifier loss: 0.134015; batch adversarial loss: 0.366865\n",
      "epoch 53; iter: 0; batch classifier loss: 0.109918; batch adversarial loss: 0.457269\n",
      "epoch 54; iter: 0; batch classifier loss: 0.092880; batch adversarial loss: 0.407147\n",
      "epoch 55; iter: 0; batch classifier loss: 0.100773; batch adversarial loss: 0.386746\n",
      "epoch 56; iter: 0; batch classifier loss: 0.074842; batch adversarial loss: 0.389400\n",
      "epoch 57; iter: 0; batch classifier loss: 0.092650; batch adversarial loss: 0.429540\n",
      "epoch 58; iter: 0; batch classifier loss: 0.112101; batch adversarial loss: 0.367967\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102126; batch adversarial loss: 0.491635\n",
      "epoch 60; iter: 0; batch classifier loss: 0.073569; batch adversarial loss: 0.417728\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088359; batch adversarial loss: 0.450274\n",
      "epoch 62; iter: 0; batch classifier loss: 0.076735; batch adversarial loss: 0.433907\n",
      "epoch 63; iter: 0; batch classifier loss: 0.098720; batch adversarial loss: 0.568847\n",
      "epoch 64; iter: 0; batch classifier loss: 0.111808; batch adversarial loss: 0.439630\n",
      "epoch 65; iter: 0; batch classifier loss: 0.038270; batch adversarial loss: 0.438173\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096062; batch adversarial loss: 0.521960\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100734; batch adversarial loss: 0.457958\n",
      "epoch 68; iter: 0; batch classifier loss: 0.057469; batch adversarial loss: 0.385545\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087095; batch adversarial loss: 0.471824\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090884; batch adversarial loss: 0.430223\n",
      "epoch 71; iter: 0; batch classifier loss: 0.105523; batch adversarial loss: 0.444401\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054209; batch adversarial loss: 0.472248\n",
      "epoch 73; iter: 0; batch classifier loss: 0.042436; batch adversarial loss: 0.408445\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082154; batch adversarial loss: 0.394809\n",
      "epoch 75; iter: 0; batch classifier loss: 0.066701; batch adversarial loss: 0.423357\n",
      "epoch 76; iter: 0; batch classifier loss: 0.052421; batch adversarial loss: 0.430066\n",
      "epoch 77; iter: 0; batch classifier loss: 0.089359; batch adversarial loss: 0.388269\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054903; batch adversarial loss: 0.408466\n",
      "epoch 79; iter: 0; batch classifier loss: 0.126527; batch adversarial loss: 0.483789\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084496; batch adversarial loss: 0.389923\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071257; batch adversarial loss: 0.466126\n",
      "epoch 82; iter: 0; batch classifier loss: 0.068711; batch adversarial loss: 0.436919\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074212; batch adversarial loss: 0.478989\n",
      "epoch 84; iter: 0; batch classifier loss: 0.099696; batch adversarial loss: 0.451736\n",
      "epoch 85; iter: 0; batch classifier loss: 0.119857; batch adversarial loss: 0.441291\n",
      "epoch 86; iter: 0; batch classifier loss: 0.113878; batch adversarial loss: 0.432483\n",
      "epoch 87; iter: 0; batch classifier loss: 0.051302; batch adversarial loss: 0.480822\n",
      "epoch 88; iter: 0; batch classifier loss: 0.113029; batch adversarial loss: 0.386762\n",
      "epoch 89; iter: 0; batch classifier loss: 0.139846; batch adversarial loss: 0.466747\n",
      "epoch 90; iter: 0; batch classifier loss: 0.078517; batch adversarial loss: 0.346935\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074777; batch adversarial loss: 0.522251\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082381; batch adversarial loss: 0.419496\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069669; batch adversarial loss: 0.437772\n",
      "epoch 94; iter: 0; batch classifier loss: 0.087719; batch adversarial loss: 0.474421\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052886; batch adversarial loss: 0.486025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.070986; batch adversarial loss: 0.420025\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057166; batch adversarial loss: 0.400372\n",
      "epoch 98; iter: 0; batch classifier loss: 0.126697; batch adversarial loss: 0.454926\n",
      "epoch 99; iter: 0; batch classifier loss: 0.028926; batch adversarial loss: 0.524617\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053013; batch adversarial loss: 0.335713\n",
      "epoch 101; iter: 0; batch classifier loss: 0.069967; batch adversarial loss: 0.408610\n",
      "epoch 102; iter: 0; batch classifier loss: 0.084082; batch adversarial loss: 0.393413\n",
      "epoch 103; iter: 0; batch classifier loss: 0.103300; batch adversarial loss: 0.506756\n",
      "epoch 104; iter: 0; batch classifier loss: 0.078526; batch adversarial loss: 0.416498\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049041; batch adversarial loss: 0.453692\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052690; batch adversarial loss: 0.492497\n",
      "epoch 107; iter: 0; batch classifier loss: 0.067542; batch adversarial loss: 0.465178\n",
      "epoch 108; iter: 0; batch classifier loss: 0.050124; batch adversarial loss: 0.462384\n",
      "epoch 109; iter: 0; batch classifier loss: 0.091755; batch adversarial loss: 0.439481\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052683; batch adversarial loss: 0.388605\n",
      "epoch 111; iter: 0; batch classifier loss: 0.073942; batch adversarial loss: 0.432199\n",
      "epoch 112; iter: 0; batch classifier loss: 0.091903; batch adversarial loss: 0.435187\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058917; batch adversarial loss: 0.516013\n",
      "epoch 114; iter: 0; batch classifier loss: 0.073703; batch adversarial loss: 0.429471\n",
      "epoch 115; iter: 0; batch classifier loss: 0.082723; batch adversarial loss: 0.423832\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062808; batch adversarial loss: 0.416387\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039894; batch adversarial loss: 0.433885\n",
      "epoch 118; iter: 0; batch classifier loss: 0.086769; batch adversarial loss: 0.404990\n",
      "epoch 119; iter: 0; batch classifier loss: 0.068039; batch adversarial loss: 0.415558\n",
      "epoch 120; iter: 0; batch classifier loss: 0.088304; batch adversarial loss: 0.410592\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053876; batch adversarial loss: 0.380771\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045932; batch adversarial loss: 0.390989\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050003; batch adversarial loss: 0.492279\n",
      "epoch 124; iter: 0; batch classifier loss: 0.066115; batch adversarial loss: 0.472764\n",
      "epoch 125; iter: 0; batch classifier loss: 0.088919; batch adversarial loss: 0.493471\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051770; batch adversarial loss: 0.477774\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045905; batch adversarial loss: 0.438975\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063293; batch adversarial loss: 0.461189\n",
      "epoch 129; iter: 0; batch classifier loss: 0.052167; batch adversarial loss: 0.492150\n",
      "epoch 130; iter: 0; batch classifier loss: 0.060616; batch adversarial loss: 0.426625\n",
      "epoch 131; iter: 0; batch classifier loss: 0.066445; batch adversarial loss: 0.397633\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050481; batch adversarial loss: 0.473174\n",
      "epoch 133; iter: 0; batch classifier loss: 0.075340; batch adversarial loss: 0.393539\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069445; batch adversarial loss: 0.396435\n",
      "epoch 135; iter: 0; batch classifier loss: 0.099905; batch adversarial loss: 0.396775\n",
      "epoch 136; iter: 0; batch classifier loss: 0.095093; batch adversarial loss: 0.409283\n",
      "epoch 137; iter: 0; batch classifier loss: 0.056920; batch adversarial loss: 0.444642\n",
      "epoch 138; iter: 0; batch classifier loss: 0.068827; batch adversarial loss: 0.504156\n",
      "epoch 139; iter: 0; batch classifier loss: 0.087624; batch adversarial loss: 0.416618\n",
      "epoch 140; iter: 0; batch classifier loss: 0.070111; batch adversarial loss: 0.370270\n",
      "epoch 141; iter: 0; batch classifier loss: 0.058430; batch adversarial loss: 0.387379\n",
      "epoch 142; iter: 0; batch classifier loss: 0.100042; batch adversarial loss: 0.421852\n",
      "epoch 143; iter: 0; batch classifier loss: 0.108561; batch adversarial loss: 0.528111\n",
      "epoch 144; iter: 0; batch classifier loss: 0.097984; batch adversarial loss: 0.485689\n",
      "epoch 145; iter: 0; batch classifier loss: 0.060150; batch adversarial loss: 0.405526\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030803; batch adversarial loss: 0.465400\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046755; batch adversarial loss: 0.436214\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031088; batch adversarial loss: 0.375413\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031221; batch adversarial loss: 0.435761\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030288; batch adversarial loss: 0.419907\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031623; batch adversarial loss: 0.470710\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038282; batch adversarial loss: 0.537542\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035026; batch adversarial loss: 0.494968\n",
      "epoch 154; iter: 0; batch classifier loss: 0.050525; batch adversarial loss: 0.405369\n",
      "epoch 155; iter: 0; batch classifier loss: 0.074832; batch adversarial loss: 0.375410\n",
      "epoch 156; iter: 0; batch classifier loss: 0.062054; batch adversarial loss: 0.559746\n",
      "epoch 157; iter: 0; batch classifier loss: 0.045972; batch adversarial loss: 0.480867\n",
      "epoch 158; iter: 0; batch classifier loss: 0.056430; batch adversarial loss: 0.407449\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049477; batch adversarial loss: 0.438719\n",
      "epoch 160; iter: 0; batch classifier loss: 0.051516; batch adversarial loss: 0.452690\n",
      "epoch 161; iter: 0; batch classifier loss: 0.053532; batch adversarial loss: 0.415263\n",
      "epoch 162; iter: 0; batch classifier loss: 0.078117; batch adversarial loss: 0.429650\n",
      "epoch 163; iter: 0; batch classifier loss: 0.060834; batch adversarial loss: 0.510007\n",
      "epoch 164; iter: 0; batch classifier loss: 0.045964; batch adversarial loss: 0.377693\n",
      "epoch 165; iter: 0; batch classifier loss: 0.050920; batch adversarial loss: 0.449332\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032260; batch adversarial loss: 0.466136\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034964; batch adversarial loss: 0.494778\n",
      "epoch 168; iter: 0; batch classifier loss: 0.053156; batch adversarial loss: 0.456111\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038947; batch adversarial loss: 0.346147\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030987; batch adversarial loss: 0.467598\n",
      "epoch 171; iter: 0; batch classifier loss: 0.072009; batch adversarial loss: 0.464927\n",
      "epoch 172; iter: 0; batch classifier loss: 0.086929; batch adversarial loss: 0.445809\n",
      "epoch 173; iter: 0; batch classifier loss: 0.052659; batch adversarial loss: 0.424650\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038792; batch adversarial loss: 0.423734\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018026; batch adversarial loss: 0.391709\n",
      "epoch 176; iter: 0; batch classifier loss: 0.042957; batch adversarial loss: 0.360976\n",
      "epoch 177; iter: 0; batch classifier loss: 0.052704; batch adversarial loss: 0.448171\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038301; batch adversarial loss: 0.407567\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035438; batch adversarial loss: 0.488677\n",
      "epoch 180; iter: 0; batch classifier loss: 0.036310; batch adversarial loss: 0.434838\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018076; batch adversarial loss: 0.329155\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037265; batch adversarial loss: 0.414903\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029761; batch adversarial loss: 0.467591\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030416; batch adversarial loss: 0.435253\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018505; batch adversarial loss: 0.453252\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031038; batch adversarial loss: 0.373888\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013846; batch adversarial loss: 0.477974\n",
      "epoch 188; iter: 0; batch classifier loss: 0.058456; batch adversarial loss: 0.425731\n",
      "epoch 189; iter: 0; batch classifier loss: 0.058734; batch adversarial loss: 0.398187\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024724; batch adversarial loss: 0.490511\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037916; batch adversarial loss: 0.365559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.042004; batch adversarial loss: 0.539680\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012299; batch adversarial loss: 0.505649\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024372; batch adversarial loss: 0.433950\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014256; batch adversarial loss: 0.565123\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033058; batch adversarial loss: 0.408266\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020462; batch adversarial loss: 0.353624\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021148; batch adversarial loss: 0.416049\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019525; batch adversarial loss: 0.505870\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695498; batch adversarial loss: 0.538097\n",
      "epoch 1; iter: 0; batch classifier loss: 0.353458; batch adversarial loss: 0.606531\n",
      "epoch 2; iter: 0; batch classifier loss: 0.388443; batch adversarial loss: 0.593078\n",
      "epoch 3; iter: 0; batch classifier loss: 0.330806; batch adversarial loss: 0.593090\n",
      "epoch 4; iter: 0; batch classifier loss: 0.308009; batch adversarial loss: 0.593748\n",
      "epoch 5; iter: 0; batch classifier loss: 0.333935; batch adversarial loss: 0.568569\n",
      "epoch 6; iter: 0; batch classifier loss: 0.384020; batch adversarial loss: 0.570978\n",
      "epoch 7; iter: 0; batch classifier loss: 0.311965; batch adversarial loss: 0.612792\n",
      "epoch 8; iter: 0; batch classifier loss: 0.349864; batch adversarial loss: 0.539940\n",
      "epoch 9; iter: 0; batch classifier loss: 0.293783; batch adversarial loss: 0.537995\n",
      "epoch 10; iter: 0; batch classifier loss: 0.282972; batch adversarial loss: 0.488890\n",
      "epoch 11; iter: 0; batch classifier loss: 0.321929; batch adversarial loss: 0.443945\n",
      "epoch 12; iter: 0; batch classifier loss: 0.230316; batch adversarial loss: 0.560389\n",
      "epoch 13; iter: 0; batch classifier loss: 0.251615; batch adversarial loss: 0.571411\n",
      "epoch 14; iter: 0; batch classifier loss: 0.270785; batch adversarial loss: 0.463514\n",
      "epoch 15; iter: 0; batch classifier loss: 0.179397; batch adversarial loss: 0.541399\n",
      "epoch 16; iter: 0; batch classifier loss: 0.263691; batch adversarial loss: 0.521259\n",
      "epoch 17; iter: 0; batch classifier loss: 0.168416; batch adversarial loss: 0.543541\n",
      "epoch 18; iter: 0; batch classifier loss: 0.192630; batch adversarial loss: 0.442867\n",
      "epoch 19; iter: 0; batch classifier loss: 0.169007; batch adversarial loss: 0.564635\n",
      "epoch 20; iter: 0; batch classifier loss: 0.187997; batch adversarial loss: 0.506085\n",
      "epoch 21; iter: 0; batch classifier loss: 0.137742; batch adversarial loss: 0.519524\n",
      "epoch 22; iter: 0; batch classifier loss: 0.138499; batch adversarial loss: 0.467520\n",
      "epoch 23; iter: 0; batch classifier loss: 0.188153; batch adversarial loss: 0.406350\n",
      "epoch 24; iter: 0; batch classifier loss: 0.164374; batch adversarial loss: 0.582000\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132617; batch adversarial loss: 0.506482\n",
      "epoch 26; iter: 0; batch classifier loss: 0.095566; batch adversarial loss: 0.404064\n",
      "epoch 27; iter: 0; batch classifier loss: 0.123256; batch adversarial loss: 0.509913\n",
      "epoch 28; iter: 0; batch classifier loss: 0.110076; batch adversarial loss: 0.534036\n",
      "epoch 29; iter: 0; batch classifier loss: 0.147064; batch adversarial loss: 0.489240\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167242; batch adversarial loss: 0.432095\n",
      "epoch 31; iter: 0; batch classifier loss: 0.101081; batch adversarial loss: 0.473271\n",
      "epoch 32; iter: 0; batch classifier loss: 0.120382; batch adversarial loss: 0.512390\n",
      "epoch 33; iter: 0; batch classifier loss: 0.129035; batch adversarial loss: 0.428255\n",
      "epoch 34; iter: 0; batch classifier loss: 0.145335; batch adversarial loss: 0.457335\n",
      "epoch 35; iter: 0; batch classifier loss: 0.152432; batch adversarial loss: 0.445122\n",
      "epoch 36; iter: 0; batch classifier loss: 0.146113; batch adversarial loss: 0.522696\n",
      "epoch 37; iter: 0; batch classifier loss: 0.120270; batch adversarial loss: 0.468951\n",
      "epoch 38; iter: 0; batch classifier loss: 0.103825; batch adversarial loss: 0.558962\n",
      "epoch 39; iter: 0; batch classifier loss: 0.096040; batch adversarial loss: 0.546998\n",
      "epoch 40; iter: 0; batch classifier loss: 0.088374; batch adversarial loss: 0.514903\n",
      "epoch 41; iter: 0; batch classifier loss: 0.088448; batch adversarial loss: 0.443884\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106057; batch adversarial loss: 0.466236\n",
      "epoch 43; iter: 0; batch classifier loss: 0.139483; batch adversarial loss: 0.420450\n",
      "epoch 44; iter: 0; batch classifier loss: 0.130104; batch adversarial loss: 0.474184\n",
      "epoch 45; iter: 0; batch classifier loss: 0.074073; batch adversarial loss: 0.474331\n",
      "epoch 46; iter: 0; batch classifier loss: 0.082039; batch adversarial loss: 0.502393\n",
      "epoch 47; iter: 0; batch classifier loss: 0.109895; batch adversarial loss: 0.541461\n",
      "epoch 48; iter: 0; batch classifier loss: 0.102531; batch adversarial loss: 0.397392\n",
      "epoch 49; iter: 0; batch classifier loss: 0.149558; batch adversarial loss: 0.450403\n",
      "epoch 50; iter: 0; batch classifier loss: 0.101199; batch adversarial loss: 0.500152\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081203; batch adversarial loss: 0.543186\n",
      "epoch 52; iter: 0; batch classifier loss: 0.084261; batch adversarial loss: 0.396197\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076872; batch adversarial loss: 0.413374\n",
      "epoch 54; iter: 0; batch classifier loss: 0.083801; batch adversarial loss: 0.446635\n",
      "epoch 55; iter: 0; batch classifier loss: 0.110310; batch adversarial loss: 0.541710\n",
      "epoch 56; iter: 0; batch classifier loss: 0.111727; batch adversarial loss: 0.455494\n",
      "epoch 57; iter: 0; batch classifier loss: 0.109811; batch adversarial loss: 0.477911\n",
      "epoch 58; iter: 0; batch classifier loss: 0.099309; batch adversarial loss: 0.539656\n",
      "epoch 59; iter: 0; batch classifier loss: 0.096195; batch adversarial loss: 0.504865\n",
      "epoch 60; iter: 0; batch classifier loss: 0.099833; batch adversarial loss: 0.473305\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090958; batch adversarial loss: 0.548555\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094180; batch adversarial loss: 0.462949\n",
      "epoch 63; iter: 0; batch classifier loss: 0.131778; batch adversarial loss: 0.464892\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106245; batch adversarial loss: 0.449537\n",
      "epoch 65; iter: 0; batch classifier loss: 0.080522; batch adversarial loss: 0.503529\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091062; batch adversarial loss: 0.408199\n",
      "epoch 67; iter: 0; batch classifier loss: 0.081351; batch adversarial loss: 0.586732\n",
      "epoch 68; iter: 0; batch classifier loss: 0.114496; batch adversarial loss: 0.434921\n",
      "epoch 69; iter: 0; batch classifier loss: 0.101095; batch adversarial loss: 0.483583\n",
      "epoch 70; iter: 0; batch classifier loss: 0.154431; batch adversarial loss: 0.465116\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092077; batch adversarial loss: 0.454681\n",
      "epoch 72; iter: 0; batch classifier loss: 0.049526; batch adversarial loss: 0.559391\n",
      "epoch 73; iter: 0; batch classifier loss: 0.118855; batch adversarial loss: 0.487902\n",
      "epoch 74; iter: 0; batch classifier loss: 0.088523; batch adversarial loss: 0.580244\n",
      "epoch 75; iter: 0; batch classifier loss: 0.095878; batch adversarial loss: 0.522291\n",
      "epoch 76; iter: 0; batch classifier loss: 0.103865; batch adversarial loss: 0.428292\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055642; batch adversarial loss: 0.544352\n",
      "epoch 78; iter: 0; batch classifier loss: 0.117730; batch adversarial loss: 0.478488\n",
      "epoch 79; iter: 0; batch classifier loss: 0.090378; batch adversarial loss: 0.561719\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068471; batch adversarial loss: 0.470687\n",
      "epoch 81; iter: 0; batch classifier loss: 0.118048; batch adversarial loss: 0.463189\n",
      "epoch 82; iter: 0; batch classifier loss: 0.099237; batch adversarial loss: 0.470849\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056213; batch adversarial loss: 0.379056\n",
      "epoch 84; iter: 0; batch classifier loss: 0.109637; batch adversarial loss: 0.538009\n",
      "epoch 85; iter: 0; batch classifier loss: 0.086564; batch adversarial loss: 0.422547\n",
      "epoch 86; iter: 0; batch classifier loss: 0.099726; batch adversarial loss: 0.480048\n",
      "epoch 87; iter: 0; batch classifier loss: 0.069571; batch adversarial loss: 0.383468\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055254; batch adversarial loss: 0.429384\n",
      "epoch 89; iter: 0; batch classifier loss: 0.076284; batch adversarial loss: 0.422849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.059604; batch adversarial loss: 0.405760\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056038; batch adversarial loss: 0.500561\n",
      "epoch 92; iter: 0; batch classifier loss: 0.098417; batch adversarial loss: 0.454107\n",
      "epoch 93; iter: 0; batch classifier loss: 0.059095; batch adversarial loss: 0.452590\n",
      "epoch 94; iter: 0; batch classifier loss: 0.067222; batch adversarial loss: 0.436599\n",
      "epoch 95; iter: 0; batch classifier loss: 0.059898; batch adversarial loss: 0.415610\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047459; batch adversarial loss: 0.448524\n",
      "epoch 97; iter: 0; batch classifier loss: 0.078573; batch adversarial loss: 0.418989\n",
      "epoch 98; iter: 0; batch classifier loss: 0.088362; batch adversarial loss: 0.397236\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044721; batch adversarial loss: 0.375031\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065368; batch adversarial loss: 0.518463\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042648; batch adversarial loss: 0.506459\n",
      "epoch 102; iter: 0; batch classifier loss: 0.035616; batch adversarial loss: 0.527222\n",
      "epoch 103; iter: 0; batch classifier loss: 0.022192; batch adversarial loss: 0.495215\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083721; batch adversarial loss: 0.462582\n",
      "epoch 105; iter: 0; batch classifier loss: 0.085029; batch adversarial loss: 0.345532\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033811; batch adversarial loss: 0.423626\n",
      "epoch 107; iter: 0; batch classifier loss: 0.022938; batch adversarial loss: 0.421525\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049483; batch adversarial loss: 0.505969\n",
      "epoch 109; iter: 0; batch classifier loss: 0.017250; batch adversarial loss: 0.462822\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025614; batch adversarial loss: 0.455534\n",
      "epoch 111; iter: 0; batch classifier loss: 0.074788; batch adversarial loss: 0.551621\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052845; batch adversarial loss: 0.403910\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035386; batch adversarial loss: 0.505660\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035997; batch adversarial loss: 0.490783\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051174; batch adversarial loss: 0.454995\n",
      "epoch 116; iter: 0; batch classifier loss: 0.031734; batch adversarial loss: 0.460155\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029095; batch adversarial loss: 0.449529\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031842; batch adversarial loss: 0.572962\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025207; batch adversarial loss: 0.442061\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048771; batch adversarial loss: 0.493441\n",
      "epoch 121; iter: 0; batch classifier loss: 0.061717; batch adversarial loss: 0.529318\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039137; batch adversarial loss: 0.569790\n",
      "epoch 123; iter: 0; batch classifier loss: 0.056909; batch adversarial loss: 0.475082\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025166; batch adversarial loss: 0.351396\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037872; batch adversarial loss: 0.429522\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045005; batch adversarial loss: 0.485238\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039559; batch adversarial loss: 0.439208\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058781; batch adversarial loss: 0.403397\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032948; batch adversarial loss: 0.395683\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040039; batch adversarial loss: 0.476496\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045867; batch adversarial loss: 0.568269\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025340; batch adversarial loss: 0.366124\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035969; batch adversarial loss: 0.445365\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043586; batch adversarial loss: 0.353135\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034603; batch adversarial loss: 0.400897\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027839; batch adversarial loss: 0.429939\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028865; batch adversarial loss: 0.454874\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033126; batch adversarial loss: 0.452790\n",
      "epoch 139; iter: 0; batch classifier loss: 0.048662; batch adversarial loss: 0.480666\n",
      "epoch 140; iter: 0; batch classifier loss: 0.073253; batch adversarial loss: 0.566963\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030009; batch adversarial loss: 0.398200\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022848; batch adversarial loss: 0.434818\n",
      "epoch 143; iter: 0; batch classifier loss: 0.082911; batch adversarial loss: 0.454144\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018154; batch adversarial loss: 0.416865\n",
      "epoch 145; iter: 0; batch classifier loss: 0.060957; batch adversarial loss: 0.380743\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020079; batch adversarial loss: 0.458656\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030389; batch adversarial loss: 0.428254\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032141; batch adversarial loss: 0.490672\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037742; batch adversarial loss: 0.493552\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028783; batch adversarial loss: 0.480870\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015697; batch adversarial loss: 0.456356\n",
      "epoch 152; iter: 0; batch classifier loss: 0.012529; batch adversarial loss: 0.572677\n",
      "epoch 153; iter: 0; batch classifier loss: 0.067506; batch adversarial loss: 0.467367\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023642; batch adversarial loss: 0.508307\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033756; batch adversarial loss: 0.500841\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043889; batch adversarial loss: 0.461726\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011336; batch adversarial loss: 0.478317\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016727; batch adversarial loss: 0.406957\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031803; batch adversarial loss: 0.525554\n",
      "epoch 160; iter: 0; batch classifier loss: 0.049757; batch adversarial loss: 0.476157\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015851; batch adversarial loss: 0.424006\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038276; batch adversarial loss: 0.486875\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032730; batch adversarial loss: 0.504693\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029283; batch adversarial loss: 0.452727\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024895; batch adversarial loss: 0.472797\n",
      "epoch 166; iter: 0; batch classifier loss: 0.042160; batch adversarial loss: 0.538750\n",
      "epoch 167; iter: 0; batch classifier loss: 0.057243; batch adversarial loss: 0.516747\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014958; batch adversarial loss: 0.387362\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036963; batch adversarial loss: 0.537753\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016023; batch adversarial loss: 0.531309\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017611; batch adversarial loss: 0.459995\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031653; batch adversarial loss: 0.424492\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025319; batch adversarial loss: 0.488212\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021231; batch adversarial loss: 0.505976\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014855; batch adversarial loss: 0.471214\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028732; batch adversarial loss: 0.501722\n",
      "epoch 177; iter: 0; batch classifier loss: 0.004271; batch adversarial loss: 0.492379\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023480; batch adversarial loss: 0.458235\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020906; batch adversarial loss: 0.502722\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015473; batch adversarial loss: 0.443930\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009858; batch adversarial loss: 0.464398\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012905; batch adversarial loss: 0.517771\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008570; batch adversarial loss: 0.375515\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021874; batch adversarial loss: 0.497843\n",
      "epoch 185; iter: 0; batch classifier loss: 0.034938; batch adversarial loss: 0.415854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.015189; batch adversarial loss: 0.488694\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032678; batch adversarial loss: 0.453629\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024568; batch adversarial loss: 0.449684\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017837; batch adversarial loss: 0.392650\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006773; batch adversarial loss: 0.421907\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017254; batch adversarial loss: 0.456445\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014655; batch adversarial loss: 0.530321\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019879; batch adversarial loss: 0.489309\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012869; batch adversarial loss: 0.455512\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026397; batch adversarial loss: 0.445256\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024802; batch adversarial loss: 0.493153\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014161; batch adversarial loss: 0.489646\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003347; batch adversarial loss: 0.533690\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006137; batch adversarial loss: 0.390600\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705851; batch adversarial loss: 0.550643\n",
      "epoch 1; iter: 0; batch classifier loss: 0.467709; batch adversarial loss: 0.596397\n",
      "epoch 2; iter: 0; batch classifier loss: 0.388437; batch adversarial loss: 0.578538\n",
      "epoch 3; iter: 0; batch classifier loss: 0.313692; batch adversarial loss: 0.558815\n",
      "epoch 4; iter: 0; batch classifier loss: 0.320936; batch adversarial loss: 0.511963\n",
      "epoch 5; iter: 0; batch classifier loss: 0.332278; batch adversarial loss: 0.512826\n",
      "epoch 6; iter: 0; batch classifier loss: 0.313651; batch adversarial loss: 0.583017\n",
      "epoch 7; iter: 0; batch classifier loss: 0.310763; batch adversarial loss: 0.537385\n",
      "epoch 8; iter: 0; batch classifier loss: 0.262469; batch adversarial loss: 0.554061\n",
      "epoch 9; iter: 0; batch classifier loss: 0.298403; batch adversarial loss: 0.477144\n",
      "epoch 10; iter: 0; batch classifier loss: 0.333581; batch adversarial loss: 0.477302\n",
      "epoch 11; iter: 0; batch classifier loss: 0.235414; batch adversarial loss: 0.582484\n",
      "epoch 12; iter: 0; batch classifier loss: 0.310201; batch adversarial loss: 0.548124\n",
      "epoch 13; iter: 0; batch classifier loss: 0.271206; batch adversarial loss: 0.548107\n",
      "epoch 14; iter: 0; batch classifier loss: 0.316736; batch adversarial loss: 0.516948\n",
      "epoch 15; iter: 0; batch classifier loss: 0.274448; batch adversarial loss: 0.519842\n",
      "epoch 16; iter: 0; batch classifier loss: 0.296797; batch adversarial loss: 0.509534\n",
      "epoch 17; iter: 0; batch classifier loss: 0.284493; batch adversarial loss: 0.573199\n",
      "epoch 18; iter: 0; batch classifier loss: 0.263232; batch adversarial loss: 0.514104\n",
      "epoch 19; iter: 0; batch classifier loss: 0.383068; batch adversarial loss: 0.519480\n",
      "epoch 20; iter: 0; batch classifier loss: 0.449806; batch adversarial loss: 0.562039\n",
      "epoch 21; iter: 0; batch classifier loss: 0.453754; batch adversarial loss: 0.473943\n",
      "epoch 22; iter: 0; batch classifier loss: 0.285455; batch adversarial loss: 0.466934\n",
      "epoch 23; iter: 0; batch classifier loss: 0.170016; batch adversarial loss: 0.423951\n",
      "epoch 24; iter: 0; batch classifier loss: 0.131271; batch adversarial loss: 0.397541\n",
      "epoch 25; iter: 0; batch classifier loss: 0.182225; batch adversarial loss: 0.464744\n",
      "epoch 26; iter: 0; batch classifier loss: 0.121709; batch adversarial loss: 0.422459\n",
      "epoch 27; iter: 0; batch classifier loss: 0.105503; batch adversarial loss: 0.497469\n",
      "epoch 28; iter: 0; batch classifier loss: 0.148750; batch adversarial loss: 0.539171\n",
      "epoch 29; iter: 0; batch classifier loss: 0.130088; batch adversarial loss: 0.365934\n",
      "epoch 30; iter: 0; batch classifier loss: 0.139351; batch adversarial loss: 0.519088\n",
      "epoch 31; iter: 0; batch classifier loss: 0.101792; batch adversarial loss: 0.444212\n",
      "epoch 32; iter: 0; batch classifier loss: 0.110290; batch adversarial loss: 0.581528\n",
      "epoch 33; iter: 0; batch classifier loss: 0.082618; batch adversarial loss: 0.549886\n",
      "epoch 34; iter: 0; batch classifier loss: 0.113115; batch adversarial loss: 0.399232\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129384; batch adversarial loss: 0.469600\n",
      "epoch 36; iter: 0; batch classifier loss: 0.117495; batch adversarial loss: 0.491859\n",
      "epoch 37; iter: 0; batch classifier loss: 0.141678; batch adversarial loss: 0.386901\n",
      "epoch 38; iter: 0; batch classifier loss: 0.097800; batch adversarial loss: 0.447345\n",
      "epoch 39; iter: 0; batch classifier loss: 0.118017; batch adversarial loss: 0.388303\n",
      "epoch 40; iter: 0; batch classifier loss: 0.104813; batch adversarial loss: 0.458374\n",
      "epoch 41; iter: 0; batch classifier loss: 0.099496; batch adversarial loss: 0.365983\n",
      "epoch 42; iter: 0; batch classifier loss: 0.119885; batch adversarial loss: 0.467609\n",
      "epoch 43; iter: 0; batch classifier loss: 0.123575; batch adversarial loss: 0.376236\n",
      "epoch 44; iter: 0; batch classifier loss: 0.108325; batch adversarial loss: 0.532499\n",
      "epoch 45; iter: 0; batch classifier loss: 0.063782; batch adversarial loss: 0.442523\n",
      "epoch 46; iter: 0; batch classifier loss: 0.092922; batch adversarial loss: 0.460067\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114646; batch adversarial loss: 0.411531\n",
      "epoch 48; iter: 0; batch classifier loss: 0.088431; batch adversarial loss: 0.443270\n",
      "epoch 49; iter: 0; batch classifier loss: 0.102749; batch adversarial loss: 0.472021\n",
      "epoch 50; iter: 0; batch classifier loss: 0.078599; batch adversarial loss: 0.397707\n",
      "epoch 51; iter: 0; batch classifier loss: 0.096328; batch adversarial loss: 0.532015\n",
      "epoch 52; iter: 0; batch classifier loss: 0.066545; batch adversarial loss: 0.358817\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096158; batch adversarial loss: 0.475338\n",
      "epoch 54; iter: 0; batch classifier loss: 0.065917; batch adversarial loss: 0.398843\n",
      "epoch 55; iter: 0; batch classifier loss: 0.051162; batch adversarial loss: 0.468543\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099657; batch adversarial loss: 0.393394\n",
      "epoch 57; iter: 0; batch classifier loss: 0.109017; batch adversarial loss: 0.511582\n",
      "epoch 58; iter: 0; batch classifier loss: 0.108365; batch adversarial loss: 0.416148\n",
      "epoch 59; iter: 0; batch classifier loss: 0.153295; batch adversarial loss: 0.498126\n",
      "epoch 60; iter: 0; batch classifier loss: 0.080895; batch adversarial loss: 0.388551\n",
      "epoch 61; iter: 0; batch classifier loss: 0.064488; batch adversarial loss: 0.496937\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089153; batch adversarial loss: 0.401614\n",
      "epoch 63; iter: 0; batch classifier loss: 0.116047; batch adversarial loss: 0.483858\n",
      "epoch 64; iter: 0; batch classifier loss: 0.088372; batch adversarial loss: 0.439089\n",
      "epoch 65; iter: 0; batch classifier loss: 0.073429; batch adversarial loss: 0.383423\n",
      "epoch 66; iter: 0; batch classifier loss: 0.090166; batch adversarial loss: 0.468117\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100791; batch adversarial loss: 0.470125\n",
      "epoch 68; iter: 0; batch classifier loss: 0.101906; batch adversarial loss: 0.513225\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065253; batch adversarial loss: 0.447773\n",
      "epoch 70; iter: 0; batch classifier loss: 0.047117; batch adversarial loss: 0.464819\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073659; batch adversarial loss: 0.419024\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077965; batch adversarial loss: 0.548975\n",
      "epoch 73; iter: 0; batch classifier loss: 0.105651; batch adversarial loss: 0.473138\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081985; batch adversarial loss: 0.469357\n",
      "epoch 75; iter: 0; batch classifier loss: 0.055562; batch adversarial loss: 0.487395\n",
      "epoch 76; iter: 0; batch classifier loss: 0.094846; batch adversarial loss: 0.504321\n",
      "epoch 77; iter: 0; batch classifier loss: 0.071047; batch adversarial loss: 0.425803\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072408; batch adversarial loss: 0.434394\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060623; batch adversarial loss: 0.440732\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090265; batch adversarial loss: 0.469099\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068640; batch adversarial loss: 0.501332\n",
      "epoch 82; iter: 0; batch classifier loss: 0.048152; batch adversarial loss: 0.450158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.063953; batch adversarial loss: 0.441669\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055323; batch adversarial loss: 0.460075\n",
      "epoch 85; iter: 0; batch classifier loss: 0.063885; batch adversarial loss: 0.461790\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061069; batch adversarial loss: 0.464277\n",
      "epoch 87; iter: 0; batch classifier loss: 0.117677; batch adversarial loss: 0.477028\n",
      "epoch 88; iter: 0; batch classifier loss: 0.162500; batch adversarial loss: 0.458806\n",
      "epoch 89; iter: 0; batch classifier loss: 0.120841; batch adversarial loss: 0.331858\n",
      "epoch 90; iter: 0; batch classifier loss: 0.106043; batch adversarial loss: 0.432818\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057109; batch adversarial loss: 0.463473\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069154; batch adversarial loss: 0.497076\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054349; batch adversarial loss: 0.432434\n",
      "epoch 94; iter: 0; batch classifier loss: 0.102197; batch adversarial loss: 0.497955\n",
      "epoch 95; iter: 0; batch classifier loss: 0.091414; batch adversarial loss: 0.452362\n",
      "epoch 96; iter: 0; batch classifier loss: 0.075314; batch adversarial loss: 0.438556\n",
      "epoch 97; iter: 0; batch classifier loss: 0.070610; batch adversarial loss: 0.490114\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050962; batch adversarial loss: 0.405968\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064769; batch adversarial loss: 0.418260\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046551; batch adversarial loss: 0.587007\n",
      "epoch 101; iter: 0; batch classifier loss: 0.020368; batch adversarial loss: 0.531226\n",
      "epoch 102; iter: 0; batch classifier loss: 0.087221; batch adversarial loss: 0.395743\n",
      "epoch 103; iter: 0; batch classifier loss: 0.068319; batch adversarial loss: 0.404016\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071558; batch adversarial loss: 0.465414\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060077; batch adversarial loss: 0.502751\n",
      "epoch 106; iter: 0; batch classifier loss: 0.077776; batch adversarial loss: 0.355454\n",
      "epoch 107; iter: 0; batch classifier loss: 0.094348; batch adversarial loss: 0.443810\n",
      "epoch 108; iter: 0; batch classifier loss: 0.092744; batch adversarial loss: 0.370372\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059799; batch adversarial loss: 0.511544\n",
      "epoch 110; iter: 0; batch classifier loss: 0.021699; batch adversarial loss: 0.412405\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030277; batch adversarial loss: 0.493181\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054771; batch adversarial loss: 0.449194\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052018; batch adversarial loss: 0.455500\n",
      "epoch 114; iter: 0; batch classifier loss: 0.067979; batch adversarial loss: 0.386946\n",
      "epoch 115; iter: 0; batch classifier loss: 0.064360; batch adversarial loss: 0.413564\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024213; batch adversarial loss: 0.406015\n",
      "epoch 117; iter: 0; batch classifier loss: 0.079484; batch adversarial loss: 0.481647\n",
      "epoch 118; iter: 0; batch classifier loss: 0.086424; batch adversarial loss: 0.534205\n",
      "epoch 119; iter: 0; batch classifier loss: 0.080651; batch adversarial loss: 0.413148\n",
      "epoch 120; iter: 0; batch classifier loss: 0.128264; batch adversarial loss: 0.424049\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052670; batch adversarial loss: 0.468319\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039612; batch adversarial loss: 0.504438\n",
      "epoch 123; iter: 0; batch classifier loss: 0.058714; batch adversarial loss: 0.442983\n",
      "epoch 124; iter: 0; batch classifier loss: 0.075296; batch adversarial loss: 0.444364\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035120; batch adversarial loss: 0.448732\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040302; batch adversarial loss: 0.471382\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047912; batch adversarial loss: 0.432065\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023328; batch adversarial loss: 0.436992\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027414; batch adversarial loss: 0.381464\n",
      "epoch 130; iter: 0; batch classifier loss: 0.062725; batch adversarial loss: 0.447486\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050184; batch adversarial loss: 0.449441\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032677; batch adversarial loss: 0.410578\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031145; batch adversarial loss: 0.519956\n",
      "epoch 134; iter: 0; batch classifier loss: 0.047452; batch adversarial loss: 0.439246\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032210; batch adversarial loss: 0.491218\n",
      "epoch 136; iter: 0; batch classifier loss: 0.046973; batch adversarial loss: 0.475455\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040843; batch adversarial loss: 0.458063\n",
      "epoch 138; iter: 0; batch classifier loss: 0.043453; batch adversarial loss: 0.456176\n",
      "epoch 139; iter: 0; batch classifier loss: 0.065038; batch adversarial loss: 0.371844\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035542; batch adversarial loss: 0.508115\n",
      "epoch 141; iter: 0; batch classifier loss: 0.055459; batch adversarial loss: 0.490930\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031015; batch adversarial loss: 0.549926\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042071; batch adversarial loss: 0.476916\n",
      "epoch 144; iter: 0; batch classifier loss: 0.058065; batch adversarial loss: 0.385144\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038984; batch adversarial loss: 0.405297\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040920; batch adversarial loss: 0.441341\n",
      "epoch 147; iter: 0; batch classifier loss: 0.057399; batch adversarial loss: 0.470084\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020515; batch adversarial loss: 0.427096\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025713; batch adversarial loss: 0.454638\n",
      "epoch 150; iter: 0; batch classifier loss: 0.051960; batch adversarial loss: 0.457464\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016062; batch adversarial loss: 0.439725\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025085; batch adversarial loss: 0.469461\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029803; batch adversarial loss: 0.458271\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028758; batch adversarial loss: 0.370391\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021837; batch adversarial loss: 0.484983\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041434; batch adversarial loss: 0.457336\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025507; batch adversarial loss: 0.436415\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034092; batch adversarial loss: 0.461258\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027348; batch adversarial loss: 0.497347\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017184; batch adversarial loss: 0.497606\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032997; batch adversarial loss: 0.504644\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032499; batch adversarial loss: 0.478509\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028128; batch adversarial loss: 0.509124\n",
      "epoch 164; iter: 0; batch classifier loss: 0.056389; batch adversarial loss: 0.391391\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024099; batch adversarial loss: 0.454603\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038118; batch adversarial loss: 0.475577\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013225; batch adversarial loss: 0.492815\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015024; batch adversarial loss: 0.517881\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020713; batch adversarial loss: 0.469142\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024083; batch adversarial loss: 0.450808\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032891; batch adversarial loss: 0.508817\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023880; batch adversarial loss: 0.482408\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023897; batch adversarial loss: 0.460451\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020580; batch adversarial loss: 0.555114\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015179; batch adversarial loss: 0.411190\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019562; batch adversarial loss: 0.398327\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018882; batch adversarial loss: 0.384388\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024543; batch adversarial loss: 0.423503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.044284; batch adversarial loss: 0.490345\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016403; batch adversarial loss: 0.454073\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015818; batch adversarial loss: 0.481675\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038071; batch adversarial loss: 0.430471\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013075; batch adversarial loss: 0.499496\n",
      "epoch 184; iter: 0; batch classifier loss: 0.054847; batch adversarial loss: 0.394510\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021089; batch adversarial loss: 0.442502\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029279; batch adversarial loss: 0.409292\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020545; batch adversarial loss: 0.411890\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008419; batch adversarial loss: 0.456558\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007174; batch adversarial loss: 0.423773\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015135; batch adversarial loss: 0.430120\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024625; batch adversarial loss: 0.401422\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024480; batch adversarial loss: 0.444509\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015599; batch adversarial loss: 0.534940\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023328; batch adversarial loss: 0.449419\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020216; batch adversarial loss: 0.452080\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026122; batch adversarial loss: 0.490160\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039245; batch adversarial loss: 0.494204\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014219; batch adversarial loss: 0.453590\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004906; batch adversarial loss: 0.563456\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712126; batch adversarial loss: 0.820817\n",
      "epoch 1; iter: 0; batch classifier loss: 0.738329; batch adversarial loss: 0.897905\n",
      "epoch 2; iter: 0; batch classifier loss: 0.890246; batch adversarial loss: 0.912406\n",
      "epoch 3; iter: 0; batch classifier loss: 0.707851; batch adversarial loss: 0.709689\n",
      "epoch 4; iter: 0; batch classifier loss: 0.675942; batch adversarial loss: 0.687877\n",
      "epoch 5; iter: 0; batch classifier loss: 0.665658; batch adversarial loss: 0.645146\n",
      "epoch 6; iter: 0; batch classifier loss: 0.525951; batch adversarial loss: 0.617996\n",
      "epoch 7; iter: 0; batch classifier loss: 0.366668; batch adversarial loss: 0.524220\n",
      "epoch 8; iter: 0; batch classifier loss: 0.402346; batch adversarial loss: 0.526235\n",
      "epoch 9; iter: 0; batch classifier loss: 0.258968; batch adversarial loss: 0.546935\n",
      "epoch 10; iter: 0; batch classifier loss: 0.271695; batch adversarial loss: 0.596077\n",
      "epoch 11; iter: 0; batch classifier loss: 0.225830; batch adversarial loss: 0.456922\n",
      "epoch 12; iter: 0; batch classifier loss: 0.178901; batch adversarial loss: 0.526846\n",
      "epoch 13; iter: 0; batch classifier loss: 0.235831; batch adversarial loss: 0.572709\n",
      "epoch 14; iter: 0; batch classifier loss: 0.277520; batch adversarial loss: 0.470133\n",
      "epoch 15; iter: 0; batch classifier loss: 0.230000; batch adversarial loss: 0.529177\n",
      "epoch 16; iter: 0; batch classifier loss: 0.221451; batch adversarial loss: 0.513475\n",
      "epoch 17; iter: 0; batch classifier loss: 0.200659; batch adversarial loss: 0.470121\n",
      "epoch 18; iter: 0; batch classifier loss: 0.250273; batch adversarial loss: 0.480539\n",
      "epoch 19; iter: 0; batch classifier loss: 0.164276; batch adversarial loss: 0.504846\n",
      "epoch 20; iter: 0; batch classifier loss: 0.171243; batch adversarial loss: 0.502915\n",
      "epoch 21; iter: 0; batch classifier loss: 0.169107; batch adversarial loss: 0.443193\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224011; batch adversarial loss: 0.452582\n",
      "epoch 23; iter: 0; batch classifier loss: 0.172791; batch adversarial loss: 0.522629\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192447; batch adversarial loss: 0.473670\n",
      "epoch 25; iter: 0; batch classifier loss: 0.159655; batch adversarial loss: 0.512679\n",
      "epoch 26; iter: 0; batch classifier loss: 0.117784; batch adversarial loss: 0.492157\n",
      "epoch 27; iter: 0; batch classifier loss: 0.138269; batch adversarial loss: 0.423046\n",
      "epoch 28; iter: 0; batch classifier loss: 0.160059; batch adversarial loss: 0.471736\n",
      "epoch 29; iter: 0; batch classifier loss: 0.165121; batch adversarial loss: 0.505569\n",
      "epoch 30; iter: 0; batch classifier loss: 0.115094; batch adversarial loss: 0.430185\n",
      "epoch 31; iter: 0; batch classifier loss: 0.155763; batch adversarial loss: 0.426446\n",
      "epoch 32; iter: 0; batch classifier loss: 0.132757; batch adversarial loss: 0.447885\n",
      "epoch 33; iter: 0; batch classifier loss: 0.131814; batch adversarial loss: 0.497294\n",
      "epoch 34; iter: 0; batch classifier loss: 0.129757; batch adversarial loss: 0.496861\n",
      "epoch 35; iter: 0; batch classifier loss: 0.169931; batch adversarial loss: 0.471287\n",
      "epoch 36; iter: 0; batch classifier loss: 0.144612; batch adversarial loss: 0.491741\n",
      "epoch 37; iter: 0; batch classifier loss: 0.063942; batch adversarial loss: 0.427565\n",
      "epoch 38; iter: 0; batch classifier loss: 0.169218; batch adversarial loss: 0.430555\n",
      "epoch 39; iter: 0; batch classifier loss: 0.139805; batch adversarial loss: 0.489860\n",
      "epoch 40; iter: 0; batch classifier loss: 0.112310; batch adversarial loss: 0.393232\n",
      "epoch 41; iter: 0; batch classifier loss: 0.121933; batch adversarial loss: 0.378188\n",
      "epoch 42; iter: 0; batch classifier loss: 0.129953; batch adversarial loss: 0.404260\n",
      "epoch 43; iter: 0; batch classifier loss: 0.092632; batch adversarial loss: 0.418068\n",
      "epoch 44; iter: 0; batch classifier loss: 0.130965; batch adversarial loss: 0.417141\n",
      "epoch 45; iter: 0; batch classifier loss: 0.120449; batch adversarial loss: 0.410313\n",
      "epoch 46; iter: 0; batch classifier loss: 0.098175; batch adversarial loss: 0.570071\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114774; batch adversarial loss: 0.451923\n",
      "epoch 48; iter: 0; batch classifier loss: 0.078881; batch adversarial loss: 0.471574\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099298; batch adversarial loss: 0.530869\n",
      "epoch 50; iter: 0; batch classifier loss: 0.101533; batch adversarial loss: 0.439838\n",
      "epoch 51; iter: 0; batch classifier loss: 0.089974; batch adversarial loss: 0.469674\n",
      "epoch 52; iter: 0; batch classifier loss: 0.119473; batch adversarial loss: 0.393824\n",
      "epoch 53; iter: 0; batch classifier loss: 0.106463; batch adversarial loss: 0.423045\n",
      "epoch 54; iter: 0; batch classifier loss: 0.129923; batch adversarial loss: 0.425227\n",
      "epoch 55; iter: 0; batch classifier loss: 0.129115; batch adversarial loss: 0.367906\n",
      "epoch 56; iter: 0; batch classifier loss: 0.114287; batch adversarial loss: 0.470910\n",
      "epoch 57; iter: 0; batch classifier loss: 0.088566; batch adversarial loss: 0.448334\n",
      "epoch 58; iter: 0; batch classifier loss: 0.152839; batch adversarial loss: 0.401945\n",
      "epoch 59; iter: 0; batch classifier loss: 0.135367; batch adversarial loss: 0.433826\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122493; batch adversarial loss: 0.529174\n",
      "epoch 61; iter: 0; batch classifier loss: 0.125803; batch adversarial loss: 0.402515\n",
      "epoch 62; iter: 0; batch classifier loss: 0.075636; batch adversarial loss: 0.403359\n",
      "epoch 63; iter: 0; batch classifier loss: 0.105177; batch adversarial loss: 0.479538\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106692; batch adversarial loss: 0.410768\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118985; batch adversarial loss: 0.515257\n",
      "epoch 66; iter: 0; batch classifier loss: 0.146206; batch adversarial loss: 0.478105\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101680; batch adversarial loss: 0.372577\n",
      "epoch 68; iter: 0; batch classifier loss: 0.042305; batch adversarial loss: 0.455791\n",
      "epoch 69; iter: 0; batch classifier loss: 0.120297; batch adversarial loss: 0.526264\n",
      "epoch 70; iter: 0; batch classifier loss: 0.075032; batch adversarial loss: 0.528138\n",
      "epoch 71; iter: 0; batch classifier loss: 0.114924; batch adversarial loss: 0.489745\n",
      "epoch 72; iter: 0; batch classifier loss: 0.070050; batch adversarial loss: 0.510948\n",
      "epoch 73; iter: 0; batch classifier loss: 0.104671; batch adversarial loss: 0.416674\n",
      "epoch 74; iter: 0; batch classifier loss: 0.116852; batch adversarial loss: 0.590524\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069023; batch adversarial loss: 0.452544\n",
      "epoch 76; iter: 0; batch classifier loss: 0.106775; batch adversarial loss: 0.402748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.127965; batch adversarial loss: 0.550472\n",
      "epoch 78; iter: 0; batch classifier loss: 0.103532; batch adversarial loss: 0.527649\n",
      "epoch 79; iter: 0; batch classifier loss: 0.046705; batch adversarial loss: 0.540904\n",
      "epoch 80; iter: 0; batch classifier loss: 0.087983; batch adversarial loss: 0.438361\n",
      "epoch 81; iter: 0; batch classifier loss: 0.103666; batch adversarial loss: 0.540814\n",
      "epoch 82; iter: 0; batch classifier loss: 0.084146; batch adversarial loss: 0.412489\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078008; batch adversarial loss: 0.413312\n",
      "epoch 84; iter: 0; batch classifier loss: 0.102608; batch adversarial loss: 0.507921\n",
      "epoch 85; iter: 0; batch classifier loss: 0.060848; batch adversarial loss: 0.588612\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061401; batch adversarial loss: 0.508335\n",
      "epoch 87; iter: 0; batch classifier loss: 0.083012; batch adversarial loss: 0.481015\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040826; batch adversarial loss: 0.490339\n",
      "epoch 89; iter: 0; batch classifier loss: 0.139795; batch adversarial loss: 0.434939\n",
      "epoch 90; iter: 0; batch classifier loss: 0.135088; batch adversarial loss: 0.515844\n",
      "epoch 91; iter: 0; batch classifier loss: 0.121872; batch adversarial loss: 0.468576\n",
      "epoch 92; iter: 0; batch classifier loss: 0.067862; batch adversarial loss: 0.374259\n",
      "epoch 93; iter: 0; batch classifier loss: 0.088715; batch adversarial loss: 0.398837\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083229; batch adversarial loss: 0.524963\n",
      "epoch 95; iter: 0; batch classifier loss: 0.127048; batch adversarial loss: 0.503372\n",
      "epoch 96; iter: 0; batch classifier loss: 0.078770; batch adversarial loss: 0.345141\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048753; batch adversarial loss: 0.372455\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058223; batch adversarial loss: 0.447695\n",
      "epoch 99; iter: 0; batch classifier loss: 0.099670; batch adversarial loss: 0.417417\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065619; batch adversarial loss: 0.405110\n",
      "epoch 101; iter: 0; batch classifier loss: 0.090665; batch adversarial loss: 0.424533\n",
      "epoch 102; iter: 0; batch classifier loss: 0.087955; batch adversarial loss: 0.487146\n",
      "epoch 103; iter: 0; batch classifier loss: 0.109843; batch adversarial loss: 0.432720\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063414; batch adversarial loss: 0.447827\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060858; batch adversarial loss: 0.455229\n",
      "epoch 106; iter: 0; batch classifier loss: 0.126544; batch adversarial loss: 0.462123\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072536; batch adversarial loss: 0.463192\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056768; batch adversarial loss: 0.443909\n",
      "epoch 109; iter: 0; batch classifier loss: 0.091373; batch adversarial loss: 0.414843\n",
      "epoch 110; iter: 0; batch classifier loss: 0.094758; batch adversarial loss: 0.407081\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043662; batch adversarial loss: 0.436749\n",
      "epoch 112; iter: 0; batch classifier loss: 0.097149; batch adversarial loss: 0.438980\n",
      "epoch 113; iter: 0; batch classifier loss: 0.097058; batch adversarial loss: 0.464723\n",
      "epoch 114; iter: 0; batch classifier loss: 0.066741; batch adversarial loss: 0.356451\n",
      "epoch 115; iter: 0; batch classifier loss: 0.073831; batch adversarial loss: 0.396821\n",
      "epoch 116; iter: 0; batch classifier loss: 0.125281; batch adversarial loss: 0.446548\n",
      "epoch 117; iter: 0; batch classifier loss: 0.066625; batch adversarial loss: 0.488211\n",
      "epoch 118; iter: 0; batch classifier loss: 0.090392; batch adversarial loss: 0.437226\n",
      "epoch 119; iter: 0; batch classifier loss: 0.064104; batch adversarial loss: 0.381610\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053344; batch adversarial loss: 0.453657\n",
      "epoch 121; iter: 0; batch classifier loss: 0.134666; batch adversarial loss: 0.548153\n",
      "epoch 122; iter: 0; batch classifier loss: 0.094601; batch adversarial loss: 0.389347\n",
      "epoch 123; iter: 0; batch classifier loss: 0.093741; batch adversarial loss: 0.442887\n",
      "epoch 124; iter: 0; batch classifier loss: 0.113749; batch adversarial loss: 0.408637\n",
      "epoch 125; iter: 0; batch classifier loss: 0.122484; batch adversarial loss: 0.421363\n",
      "epoch 126; iter: 0; batch classifier loss: 0.112220; batch adversarial loss: 0.528651\n",
      "epoch 127; iter: 0; batch classifier loss: 0.096175; batch adversarial loss: 0.451203\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063541; batch adversarial loss: 0.504253\n",
      "epoch 129; iter: 0; batch classifier loss: 0.133726; batch adversarial loss: 0.577316\n",
      "epoch 130; iter: 0; batch classifier loss: 0.188160; batch adversarial loss: 0.363906\n",
      "epoch 131; iter: 0; batch classifier loss: 0.149609; batch adversarial loss: 0.442224\n",
      "epoch 132; iter: 0; batch classifier loss: 0.157705; batch adversarial loss: 0.516882\n",
      "epoch 133; iter: 0; batch classifier loss: 0.155685; batch adversarial loss: 0.531865\n",
      "epoch 134; iter: 0; batch classifier loss: 0.201127; batch adversarial loss: 0.449960\n",
      "epoch 135; iter: 0; batch classifier loss: 0.195591; batch adversarial loss: 0.397927\n",
      "epoch 136; iter: 0; batch classifier loss: 0.194718; batch adversarial loss: 0.479833\n",
      "epoch 137; iter: 0; batch classifier loss: 0.162634; batch adversarial loss: 0.465960\n",
      "epoch 138; iter: 0; batch classifier loss: 0.190432; batch adversarial loss: 0.389066\n",
      "epoch 139; iter: 0; batch classifier loss: 0.189369; batch adversarial loss: 0.484304\n",
      "epoch 140; iter: 0; batch classifier loss: 0.195280; batch adversarial loss: 0.510153\n",
      "epoch 141; iter: 0; batch classifier loss: 0.279604; batch adversarial loss: 0.463715\n",
      "epoch 142; iter: 0; batch classifier loss: 0.253998; batch adversarial loss: 0.473350\n",
      "epoch 143; iter: 0; batch classifier loss: 0.249202; batch adversarial loss: 0.428018\n",
      "epoch 144; iter: 0; batch classifier loss: 0.238932; batch adversarial loss: 0.377343\n",
      "epoch 145; iter: 0; batch classifier loss: 0.183532; batch adversarial loss: 0.435991\n",
      "epoch 146; iter: 0; batch classifier loss: 0.189519; batch adversarial loss: 0.447774\n",
      "epoch 147; iter: 0; batch classifier loss: 0.217357; batch adversarial loss: 0.567236\n",
      "epoch 148; iter: 0; batch classifier loss: 0.274764; batch adversarial loss: 0.481758\n",
      "epoch 149; iter: 0; batch classifier loss: 0.269533; batch adversarial loss: 0.447159\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043788; batch adversarial loss: 0.542398\n",
      "epoch 151; iter: 0; batch classifier loss: 0.061038; batch adversarial loss: 0.482497\n",
      "epoch 152; iter: 0; batch classifier loss: 0.115155; batch adversarial loss: 0.431073\n",
      "epoch 153; iter: 0; batch classifier loss: 0.219709; batch adversarial loss: 0.458203\n",
      "epoch 154; iter: 0; batch classifier loss: 0.237490; batch adversarial loss: 0.483068\n",
      "epoch 155; iter: 0; batch classifier loss: 0.225625; batch adversarial loss: 0.433459\n",
      "epoch 156; iter: 0; batch classifier loss: 0.277475; batch adversarial loss: 0.375629\n",
      "epoch 157; iter: 0; batch classifier loss: 0.241979; batch adversarial loss: 0.446143\n",
      "epoch 158; iter: 0; batch classifier loss: 0.224892; batch adversarial loss: 0.471162\n",
      "epoch 159; iter: 0; batch classifier loss: 0.199061; batch adversarial loss: 0.507100\n",
      "epoch 160; iter: 0; batch classifier loss: 0.232474; batch adversarial loss: 0.543017\n",
      "epoch 161; iter: 0; batch classifier loss: 0.203138; batch adversarial loss: 0.495116\n",
      "epoch 162; iter: 0; batch classifier loss: 0.102447; batch adversarial loss: 0.422234\n",
      "epoch 163; iter: 0; batch classifier loss: 0.189996; batch adversarial loss: 0.362498\n",
      "epoch 164; iter: 0; batch classifier loss: 0.204746; batch adversarial loss: 0.507487\n",
      "epoch 165; iter: 0; batch classifier loss: 0.148449; batch adversarial loss: 0.459658\n",
      "epoch 166; iter: 0; batch classifier loss: 0.181624; batch adversarial loss: 0.495614\n",
      "epoch 167; iter: 0; batch classifier loss: 0.244248; batch adversarial loss: 0.458847\n",
      "epoch 168; iter: 0; batch classifier loss: 0.242431; batch adversarial loss: 0.506846\n",
      "epoch 169; iter: 0; batch classifier loss: 0.091494; batch adversarial loss: 0.554944\n",
      "epoch 170; iter: 0; batch classifier loss: 0.059450; batch adversarial loss: 0.529056\n",
      "epoch 171; iter: 0; batch classifier loss: 0.044334; batch adversarial loss: 0.392909\n",
      "epoch 172; iter: 0; batch classifier loss: 0.053308; batch adversarial loss: 0.376082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.040342; batch adversarial loss: 0.515319\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031849; batch adversarial loss: 0.523966\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037421; batch adversarial loss: 0.512796\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037088; batch adversarial loss: 0.470830\n",
      "epoch 177; iter: 0; batch classifier loss: 0.050134; batch adversarial loss: 0.438451\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017857; batch adversarial loss: 0.565010\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025738; batch adversarial loss: 0.443155\n",
      "epoch 180; iter: 0; batch classifier loss: 0.061184; batch adversarial loss: 0.423069\n",
      "epoch 181; iter: 0; batch classifier loss: 0.045360; batch adversarial loss: 0.439244\n",
      "epoch 182; iter: 0; batch classifier loss: 0.043632; batch adversarial loss: 0.423150\n",
      "epoch 183; iter: 0; batch classifier loss: 0.068965; batch adversarial loss: 0.369993\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032168; batch adversarial loss: 0.487692\n",
      "epoch 185; iter: 0; batch classifier loss: 0.048364; batch adversarial loss: 0.484169\n",
      "epoch 186; iter: 0; batch classifier loss: 0.038296; batch adversarial loss: 0.439525\n",
      "epoch 187; iter: 0; batch classifier loss: 0.048905; batch adversarial loss: 0.420565\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040247; batch adversarial loss: 0.560037\n",
      "epoch 189; iter: 0; batch classifier loss: 0.044030; batch adversarial loss: 0.426969\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029672; batch adversarial loss: 0.446577\n",
      "epoch 191; iter: 0; batch classifier loss: 0.044689; batch adversarial loss: 0.430260\n",
      "epoch 192; iter: 0; batch classifier loss: 0.048180; batch adversarial loss: 0.460297\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031204; batch adversarial loss: 0.452857\n",
      "epoch 194; iter: 0; batch classifier loss: 0.090788; batch adversarial loss: 0.412008\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026276; batch adversarial loss: 0.515539\n",
      "epoch 196; iter: 0; batch classifier loss: 0.089147; batch adversarial loss: 0.522476\n",
      "epoch 197; iter: 0; batch classifier loss: 0.047337; batch adversarial loss: 0.444739\n",
      "epoch 198; iter: 0; batch classifier loss: 0.075583; batch adversarial loss: 0.468008\n",
      "epoch 199; iter: 0; batch classifier loss: 0.036521; batch adversarial loss: 0.364645\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688229; batch adversarial loss: 0.811421\n",
      "epoch 1; iter: 0; batch classifier loss: 0.626566; batch adversarial loss: 0.807643\n",
      "epoch 2; iter: 0; batch classifier loss: 0.728012; batch adversarial loss: 0.806311\n",
      "epoch 3; iter: 0; batch classifier loss: 0.747074; batch adversarial loss: 0.727387\n",
      "epoch 4; iter: 0; batch classifier loss: 0.664174; batch adversarial loss: 0.661592\n",
      "epoch 5; iter: 0; batch classifier loss: 0.570050; batch adversarial loss: 0.589397\n",
      "epoch 6; iter: 0; batch classifier loss: 0.457181; batch adversarial loss: 0.562186\n",
      "epoch 7; iter: 0; batch classifier loss: 0.336676; batch adversarial loss: 0.558939\n",
      "epoch 8; iter: 0; batch classifier loss: 0.305331; batch adversarial loss: 0.512345\n",
      "epoch 9; iter: 0; batch classifier loss: 0.357490; batch adversarial loss: 0.507830\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269757; batch adversarial loss: 0.500284\n",
      "epoch 11; iter: 0; batch classifier loss: 0.300258; batch adversarial loss: 0.538776\n",
      "epoch 12; iter: 0; batch classifier loss: 0.365893; batch adversarial loss: 0.534494\n",
      "epoch 13; iter: 0; batch classifier loss: 0.242338; batch adversarial loss: 0.475678\n",
      "epoch 14; iter: 0; batch classifier loss: 0.195375; batch adversarial loss: 0.468833\n",
      "epoch 15; iter: 0; batch classifier loss: 0.223873; batch adversarial loss: 0.437723\n",
      "epoch 16; iter: 0; batch classifier loss: 0.263443; batch adversarial loss: 0.486091\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192528; batch adversarial loss: 0.385610\n",
      "epoch 18; iter: 0; batch classifier loss: 0.186374; batch adversarial loss: 0.466254\n",
      "epoch 19; iter: 0; batch classifier loss: 0.155892; batch adversarial loss: 0.447079\n",
      "epoch 20; iter: 0; batch classifier loss: 0.185503; batch adversarial loss: 0.520991\n",
      "epoch 21; iter: 0; batch classifier loss: 0.153608; batch adversarial loss: 0.494466\n",
      "epoch 22; iter: 0; batch classifier loss: 0.149135; batch adversarial loss: 0.481295\n",
      "epoch 23; iter: 0; batch classifier loss: 0.141126; batch adversarial loss: 0.497662\n",
      "epoch 24; iter: 0; batch classifier loss: 0.210940; batch adversarial loss: 0.442623\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132935; batch adversarial loss: 0.495037\n",
      "epoch 26; iter: 0; batch classifier loss: 0.169657; batch adversarial loss: 0.508097\n",
      "epoch 27; iter: 0; batch classifier loss: 0.158607; batch adversarial loss: 0.467080\n",
      "epoch 28; iter: 0; batch classifier loss: 0.144081; batch adversarial loss: 0.445771\n",
      "epoch 29; iter: 0; batch classifier loss: 0.132539; batch adversarial loss: 0.498381\n",
      "epoch 30; iter: 0; batch classifier loss: 0.134515; batch adversarial loss: 0.433866\n",
      "epoch 31; iter: 0; batch classifier loss: 0.159271; batch adversarial loss: 0.521221\n",
      "epoch 32; iter: 0; batch classifier loss: 0.148566; batch adversarial loss: 0.467339\n",
      "epoch 33; iter: 0; batch classifier loss: 0.119055; batch adversarial loss: 0.508568\n",
      "epoch 34; iter: 0; batch classifier loss: 0.107362; batch adversarial loss: 0.486487\n",
      "epoch 35; iter: 0; batch classifier loss: 0.091342; batch adversarial loss: 0.525097\n",
      "epoch 36; iter: 0; batch classifier loss: 0.143842; batch adversarial loss: 0.559915\n",
      "epoch 37; iter: 0; batch classifier loss: 0.072676; batch adversarial loss: 0.414817\n",
      "epoch 38; iter: 0; batch classifier loss: 0.097403; batch adversarial loss: 0.472466\n",
      "epoch 39; iter: 0; batch classifier loss: 0.097514; batch adversarial loss: 0.507346\n",
      "epoch 40; iter: 0; batch classifier loss: 0.094209; batch adversarial loss: 0.485632\n",
      "epoch 41; iter: 0; batch classifier loss: 0.068833; batch adversarial loss: 0.474627\n",
      "epoch 42; iter: 0; batch classifier loss: 0.102719; batch adversarial loss: 0.404930\n",
      "epoch 43; iter: 0; batch classifier loss: 0.088832; batch adversarial loss: 0.458822\n",
      "epoch 44; iter: 0; batch classifier loss: 0.120323; batch adversarial loss: 0.471018\n",
      "epoch 45; iter: 0; batch classifier loss: 0.060961; batch adversarial loss: 0.499682\n",
      "epoch 46; iter: 0; batch classifier loss: 0.092193; batch adversarial loss: 0.465901\n",
      "epoch 47; iter: 0; batch classifier loss: 0.087821; batch adversarial loss: 0.458866\n",
      "epoch 48; iter: 0; batch classifier loss: 0.079778; batch adversarial loss: 0.459694\n",
      "epoch 49; iter: 0; batch classifier loss: 0.105982; batch adversarial loss: 0.404014\n",
      "epoch 50; iter: 0; batch classifier loss: 0.071153; batch adversarial loss: 0.391360\n",
      "epoch 51; iter: 0; batch classifier loss: 0.089283; batch adversarial loss: 0.461811\n",
      "epoch 52; iter: 0; batch classifier loss: 0.067154; batch adversarial loss: 0.482462\n",
      "epoch 53; iter: 0; batch classifier loss: 0.135610; batch adversarial loss: 0.439896\n",
      "epoch 54; iter: 0; batch classifier loss: 0.098278; batch adversarial loss: 0.371849\n",
      "epoch 55; iter: 0; batch classifier loss: 0.080067; batch adversarial loss: 0.396271\n",
      "epoch 56; iter: 0; batch classifier loss: 0.047558; batch adversarial loss: 0.501232\n",
      "epoch 57; iter: 0; batch classifier loss: 0.062203; batch adversarial loss: 0.555638\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072776; batch adversarial loss: 0.483033\n",
      "epoch 59; iter: 0; batch classifier loss: 0.111307; batch adversarial loss: 0.401612\n",
      "epoch 60; iter: 0; batch classifier loss: 0.088073; batch adversarial loss: 0.401301\n",
      "epoch 61; iter: 0; batch classifier loss: 0.055979; batch adversarial loss: 0.417701\n",
      "epoch 62; iter: 0; batch classifier loss: 0.074980; batch adversarial loss: 0.495745\n",
      "epoch 63; iter: 0; batch classifier loss: 0.064733; batch adversarial loss: 0.457794\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070275; batch adversarial loss: 0.473075\n",
      "epoch 65; iter: 0; batch classifier loss: 0.107414; batch adversarial loss: 0.369060\n",
      "epoch 66; iter: 0; batch classifier loss: 0.074937; batch adversarial loss: 0.450320\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082202; batch adversarial loss: 0.536148\n",
      "epoch 68; iter: 0; batch classifier loss: 0.059742; batch adversarial loss: 0.504626\n",
      "epoch 69; iter: 0; batch classifier loss: 0.069982; batch adversarial loss: 0.406306\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078901; batch adversarial loss: 0.364376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.065134; batch adversarial loss: 0.372005\n",
      "epoch 72; iter: 0; batch classifier loss: 0.069886; batch adversarial loss: 0.443677\n",
      "epoch 73; iter: 0; batch classifier loss: 0.028497; batch adversarial loss: 0.451500\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082510; batch adversarial loss: 0.510598\n",
      "epoch 75; iter: 0; batch classifier loss: 0.080708; batch adversarial loss: 0.424935\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064238; batch adversarial loss: 0.509907\n",
      "epoch 77; iter: 0; batch classifier loss: 0.051150; batch adversarial loss: 0.445237\n",
      "epoch 78; iter: 0; batch classifier loss: 0.065376; batch adversarial loss: 0.427748\n",
      "epoch 79; iter: 0; batch classifier loss: 0.041546; batch adversarial loss: 0.549437\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061999; batch adversarial loss: 0.470587\n",
      "epoch 81; iter: 0; batch classifier loss: 0.034968; batch adversarial loss: 0.426555\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060996; batch adversarial loss: 0.402370\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083727; batch adversarial loss: 0.455878\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062948; batch adversarial loss: 0.461315\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067801; batch adversarial loss: 0.565580\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058758; batch adversarial loss: 0.430769\n",
      "epoch 87; iter: 0; batch classifier loss: 0.029715; batch adversarial loss: 0.492176\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063641; batch adversarial loss: 0.457244\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057466; batch adversarial loss: 0.463543\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065189; batch adversarial loss: 0.467379\n",
      "epoch 91; iter: 0; batch classifier loss: 0.093827; batch adversarial loss: 0.445993\n",
      "epoch 92; iter: 0; batch classifier loss: 0.034550; batch adversarial loss: 0.425262\n",
      "epoch 93; iter: 0; batch classifier loss: 0.040820; batch adversarial loss: 0.447079\n",
      "epoch 94; iter: 0; batch classifier loss: 0.026093; batch adversarial loss: 0.413652\n",
      "epoch 95; iter: 0; batch classifier loss: 0.044787; batch adversarial loss: 0.480949\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055112; batch adversarial loss: 0.458635\n",
      "epoch 97; iter: 0; batch classifier loss: 0.028747; batch adversarial loss: 0.459271\n",
      "epoch 98; iter: 0; batch classifier loss: 0.028506; batch adversarial loss: 0.479571\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039020; batch adversarial loss: 0.433897\n",
      "epoch 100; iter: 0; batch classifier loss: 0.029623; batch adversarial loss: 0.537114\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042757; batch adversarial loss: 0.397678\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058405; batch adversarial loss: 0.514677\n",
      "epoch 103; iter: 0; batch classifier loss: 0.071739; batch adversarial loss: 0.526859\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034301; batch adversarial loss: 0.487081\n",
      "epoch 105; iter: 0; batch classifier loss: 0.026394; batch adversarial loss: 0.484302\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045641; batch adversarial loss: 0.427480\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040221; batch adversarial loss: 0.434909\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042504; batch adversarial loss: 0.427832\n",
      "epoch 109; iter: 0; batch classifier loss: 0.023467; batch adversarial loss: 0.430182\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058545; batch adversarial loss: 0.382744\n",
      "epoch 111; iter: 0; batch classifier loss: 0.070281; batch adversarial loss: 0.473276\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044293; batch adversarial loss: 0.490532\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027500; batch adversarial loss: 0.460112\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041997; batch adversarial loss: 0.424401\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038659; batch adversarial loss: 0.417962\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032593; batch adversarial loss: 0.434676\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030949; batch adversarial loss: 0.497438\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052347; batch adversarial loss: 0.426857\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050838; batch adversarial loss: 0.486481\n",
      "epoch 120; iter: 0; batch classifier loss: 0.017477; batch adversarial loss: 0.488866\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040828; batch adversarial loss: 0.490250\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028174; batch adversarial loss: 0.472932\n",
      "epoch 123; iter: 0; batch classifier loss: 0.018151; batch adversarial loss: 0.456402\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027289; batch adversarial loss: 0.453842\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033496; batch adversarial loss: 0.362159\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028259; batch adversarial loss: 0.459656\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046872; batch adversarial loss: 0.465039\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028205; batch adversarial loss: 0.385128\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019302; batch adversarial loss: 0.433447\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042690; batch adversarial loss: 0.442604\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027525; batch adversarial loss: 0.434732\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022361; batch adversarial loss: 0.466651\n",
      "epoch 133; iter: 0; batch classifier loss: 0.063812; batch adversarial loss: 0.519618\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030382; batch adversarial loss: 0.501831\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018030; batch adversarial loss: 0.518082\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023558; batch adversarial loss: 0.492860\n",
      "epoch 137; iter: 0; batch classifier loss: 0.014625; batch adversarial loss: 0.386102\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035582; batch adversarial loss: 0.494990\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014299; batch adversarial loss: 0.444061\n",
      "epoch 140; iter: 0; batch classifier loss: 0.014231; batch adversarial loss: 0.457670\n",
      "epoch 141; iter: 0; batch classifier loss: 0.051903; batch adversarial loss: 0.447415\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023803; batch adversarial loss: 0.485355\n",
      "epoch 143; iter: 0; batch classifier loss: 0.070930; batch adversarial loss: 0.461300\n",
      "epoch 144; iter: 0; batch classifier loss: 0.058136; batch adversarial loss: 0.530991\n",
      "epoch 145; iter: 0; batch classifier loss: 0.075597; batch adversarial loss: 0.599031\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024935; batch adversarial loss: 0.418119\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013013; batch adversarial loss: 0.429959\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034334; batch adversarial loss: 0.488669\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026131; batch adversarial loss: 0.494498\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012817; batch adversarial loss: 0.438485\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017074; batch adversarial loss: 0.452021\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021838; batch adversarial loss: 0.582206\n",
      "epoch 153; iter: 0; batch classifier loss: 0.043306; batch adversarial loss: 0.481613\n",
      "epoch 154; iter: 0; batch classifier loss: 0.059605; batch adversarial loss: 0.537026\n",
      "epoch 155; iter: 0; batch classifier loss: 0.108459; batch adversarial loss: 0.493766\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011743; batch adversarial loss: 0.422336\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023456; batch adversarial loss: 0.504896\n",
      "epoch 158; iter: 0; batch classifier loss: 0.041944; batch adversarial loss: 0.417353\n",
      "epoch 159; iter: 0; batch classifier loss: 0.041905; batch adversarial loss: 0.518375\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026278; batch adversarial loss: 0.461764\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018636; batch adversarial loss: 0.501188\n",
      "epoch 162; iter: 0; batch classifier loss: 0.008578; batch adversarial loss: 0.472985\n",
      "epoch 163; iter: 0; batch classifier loss: 0.046028; batch adversarial loss: 0.369737\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033796; batch adversarial loss: 0.529325\n",
      "epoch 165; iter: 0; batch classifier loss: 0.059268; batch adversarial loss: 0.440264\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031228; batch adversarial loss: 0.497446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.063675; batch adversarial loss: 0.393076\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010430; batch adversarial loss: 0.377494\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038272; batch adversarial loss: 0.415355\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027226; batch adversarial loss: 0.539062\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014703; batch adversarial loss: 0.419666\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026351; batch adversarial loss: 0.514564\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018599; batch adversarial loss: 0.486593\n",
      "epoch 174; iter: 0; batch classifier loss: 0.005676; batch adversarial loss: 0.476487\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024872; batch adversarial loss: 0.374840\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032487; batch adversarial loss: 0.415943\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032365; batch adversarial loss: 0.505735\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015156; batch adversarial loss: 0.575762\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020078; batch adversarial loss: 0.528244\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013551; batch adversarial loss: 0.504398\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018963; batch adversarial loss: 0.499666\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022410; batch adversarial loss: 0.498591\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026393; batch adversarial loss: 0.441527\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024018; batch adversarial loss: 0.431732\n",
      "epoch 185; iter: 0; batch classifier loss: 0.048049; batch adversarial loss: 0.478393\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027896; batch adversarial loss: 0.390122\n",
      "epoch 187; iter: 0; batch classifier loss: 0.049954; batch adversarial loss: 0.428823\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028030; batch adversarial loss: 0.378366\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007905; batch adversarial loss: 0.475259\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010969; batch adversarial loss: 0.460454\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017610; batch adversarial loss: 0.525443\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020145; batch adversarial loss: 0.475500\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013639; batch adversarial loss: 0.450225\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013919; batch adversarial loss: 0.465907\n",
      "epoch 195; iter: 0; batch classifier loss: 0.033309; batch adversarial loss: 0.517755\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010993; batch adversarial loss: 0.403091\n",
      "epoch 197; iter: 0; batch classifier loss: 0.058025; batch adversarial loss: 0.501461\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017680; batch adversarial loss: 0.486652\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022264; batch adversarial loss: 0.347689\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677794; batch adversarial loss: 0.797456\n",
      "epoch 1; iter: 0; batch classifier loss: 0.506638; batch adversarial loss: 0.716999\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586022; batch adversarial loss: 0.676391\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614896; batch adversarial loss: 0.637445\n",
      "epoch 4; iter: 0; batch classifier loss: 0.381788; batch adversarial loss: 0.580683\n",
      "epoch 5; iter: 0; batch classifier loss: 0.356443; batch adversarial loss: 0.601360\n",
      "epoch 6; iter: 0; batch classifier loss: 0.401620; batch adversarial loss: 0.541641\n",
      "epoch 7; iter: 0; batch classifier loss: 0.411142; batch adversarial loss: 0.539971\n",
      "epoch 8; iter: 0; batch classifier loss: 0.271507; batch adversarial loss: 0.533480\n",
      "epoch 9; iter: 0; batch classifier loss: 0.365578; batch adversarial loss: 0.526915\n",
      "epoch 10; iter: 0; batch classifier loss: 0.244355; batch adversarial loss: 0.542069\n",
      "epoch 11; iter: 0; batch classifier loss: 0.284844; batch adversarial loss: 0.483537\n",
      "epoch 12; iter: 0; batch classifier loss: 0.325994; batch adversarial loss: 0.517732\n",
      "epoch 13; iter: 0; batch classifier loss: 0.266202; batch adversarial loss: 0.471621\n",
      "epoch 14; iter: 0; batch classifier loss: 0.219036; batch adversarial loss: 0.527310\n",
      "epoch 15; iter: 0; batch classifier loss: 0.260584; batch adversarial loss: 0.528770\n",
      "epoch 16; iter: 0; batch classifier loss: 0.186498; batch adversarial loss: 0.474132\n",
      "epoch 17; iter: 0; batch classifier loss: 0.182628; batch adversarial loss: 0.513413\n",
      "epoch 18; iter: 0; batch classifier loss: 0.171835; batch adversarial loss: 0.455749\n",
      "epoch 19; iter: 0; batch classifier loss: 0.179402; batch adversarial loss: 0.505241\n",
      "epoch 20; iter: 0; batch classifier loss: 0.157909; batch adversarial loss: 0.504859\n",
      "epoch 21; iter: 0; batch classifier loss: 0.129019; batch adversarial loss: 0.466836\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206271; batch adversarial loss: 0.437206\n",
      "epoch 23; iter: 0; batch classifier loss: 0.124488; batch adversarial loss: 0.434349\n",
      "epoch 24; iter: 0; batch classifier loss: 0.228941; batch adversarial loss: 0.484472\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132737; batch adversarial loss: 0.404914\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181541; batch adversarial loss: 0.487552\n",
      "epoch 27; iter: 0; batch classifier loss: 0.149748; batch adversarial loss: 0.518352\n",
      "epoch 28; iter: 0; batch classifier loss: 0.142732; batch adversarial loss: 0.432426\n",
      "epoch 29; iter: 0; batch classifier loss: 0.141946; batch adversarial loss: 0.525628\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205199; batch adversarial loss: 0.380429\n",
      "epoch 31; iter: 0; batch classifier loss: 0.175001; batch adversarial loss: 0.502690\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165552; batch adversarial loss: 0.452373\n",
      "epoch 33; iter: 0; batch classifier loss: 0.122656; batch adversarial loss: 0.427506\n",
      "epoch 34; iter: 0; batch classifier loss: 0.175416; batch adversarial loss: 0.486907\n",
      "epoch 35; iter: 0; batch classifier loss: 0.121530; batch adversarial loss: 0.519131\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109389; batch adversarial loss: 0.397086\n",
      "epoch 37; iter: 0; batch classifier loss: 0.123207; batch adversarial loss: 0.467526\n",
      "epoch 38; iter: 0; batch classifier loss: 0.146934; batch adversarial loss: 0.432615\n",
      "epoch 39; iter: 0; batch classifier loss: 0.124022; batch adversarial loss: 0.416585\n",
      "epoch 40; iter: 0; batch classifier loss: 0.052465; batch adversarial loss: 0.478119\n",
      "epoch 41; iter: 0; batch classifier loss: 0.102656; batch adversarial loss: 0.438681\n",
      "epoch 42; iter: 0; batch classifier loss: 0.155093; batch adversarial loss: 0.598253\n",
      "epoch 43; iter: 0; batch classifier loss: 0.132602; batch adversarial loss: 0.459851\n",
      "epoch 44; iter: 0; batch classifier loss: 0.077807; batch adversarial loss: 0.425259\n",
      "epoch 45; iter: 0; batch classifier loss: 0.139143; batch adversarial loss: 0.397036\n",
      "epoch 46; iter: 0; batch classifier loss: 0.100051; batch adversarial loss: 0.422834\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113128; batch adversarial loss: 0.513740\n",
      "epoch 48; iter: 0; batch classifier loss: 0.177313; batch adversarial loss: 0.410171\n",
      "epoch 49; iter: 0; batch classifier loss: 0.096470; batch adversarial loss: 0.519847\n",
      "epoch 50; iter: 0; batch classifier loss: 0.083293; batch adversarial loss: 0.433479\n",
      "epoch 51; iter: 0; batch classifier loss: 0.066870; batch adversarial loss: 0.479346\n",
      "epoch 52; iter: 0; batch classifier loss: 0.137888; batch adversarial loss: 0.481160\n",
      "epoch 53; iter: 0; batch classifier loss: 0.070742; batch adversarial loss: 0.521431\n",
      "epoch 54; iter: 0; batch classifier loss: 0.045695; batch adversarial loss: 0.500707\n",
      "epoch 55; iter: 0; batch classifier loss: 0.107034; batch adversarial loss: 0.419554\n",
      "epoch 56; iter: 0; batch classifier loss: 0.093123; batch adversarial loss: 0.494570\n",
      "epoch 57; iter: 0; batch classifier loss: 0.058683; batch adversarial loss: 0.408351\n",
      "epoch 58; iter: 0; batch classifier loss: 0.087730; batch adversarial loss: 0.507959\n",
      "epoch 59; iter: 0; batch classifier loss: 0.096318; batch adversarial loss: 0.463971\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072181; batch adversarial loss: 0.493708\n",
      "epoch 61; iter: 0; batch classifier loss: 0.054606; batch adversarial loss: 0.513846\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085142; batch adversarial loss: 0.502998\n",
      "epoch 63; iter: 0; batch classifier loss: 0.061392; batch adversarial loss: 0.438279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.123037; batch adversarial loss: 0.351808\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079637; batch adversarial loss: 0.483741\n",
      "epoch 66; iter: 0; batch classifier loss: 0.080814; batch adversarial loss: 0.508114\n",
      "epoch 67; iter: 0; batch classifier loss: 0.083427; batch adversarial loss: 0.457051\n",
      "epoch 68; iter: 0; batch classifier loss: 0.069408; batch adversarial loss: 0.460143\n",
      "epoch 69; iter: 0; batch classifier loss: 0.047199; batch adversarial loss: 0.408692\n",
      "epoch 70; iter: 0; batch classifier loss: 0.069145; batch adversarial loss: 0.445880\n",
      "epoch 71; iter: 0; batch classifier loss: 0.070467; batch adversarial loss: 0.473240\n",
      "epoch 72; iter: 0; batch classifier loss: 0.094569; batch adversarial loss: 0.418106\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083757; batch adversarial loss: 0.380534\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063612; batch adversarial loss: 0.501115\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096173; batch adversarial loss: 0.454374\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083680; batch adversarial loss: 0.413035\n",
      "epoch 77; iter: 0; batch classifier loss: 0.052580; batch adversarial loss: 0.393496\n",
      "epoch 78; iter: 0; batch classifier loss: 0.043409; batch adversarial loss: 0.444328\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068878; batch adversarial loss: 0.391457\n",
      "epoch 80; iter: 0; batch classifier loss: 0.042620; batch adversarial loss: 0.459877\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073376; batch adversarial loss: 0.348283\n",
      "epoch 82; iter: 0; batch classifier loss: 0.051754; batch adversarial loss: 0.423954\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054351; batch adversarial loss: 0.374406\n",
      "epoch 84; iter: 0; batch classifier loss: 0.029109; batch adversarial loss: 0.500736\n",
      "epoch 85; iter: 0; batch classifier loss: 0.040559; batch adversarial loss: 0.400941\n",
      "epoch 86; iter: 0; batch classifier loss: 0.101282; batch adversarial loss: 0.387779\n",
      "epoch 87; iter: 0; batch classifier loss: 0.036619; batch adversarial loss: 0.410640\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050329; batch adversarial loss: 0.421797\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050494; batch adversarial loss: 0.409216\n",
      "epoch 90; iter: 0; batch classifier loss: 0.034005; batch adversarial loss: 0.449809\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048716; batch adversarial loss: 0.429121\n",
      "epoch 92; iter: 0; batch classifier loss: 0.042610; batch adversarial loss: 0.503151\n",
      "epoch 93; iter: 0; batch classifier loss: 0.059121; batch adversarial loss: 0.532619\n",
      "epoch 94; iter: 0; batch classifier loss: 0.030865; batch adversarial loss: 0.500559\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063229; batch adversarial loss: 0.495557\n",
      "epoch 96; iter: 0; batch classifier loss: 0.060947; batch adversarial loss: 0.397781\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039218; batch adversarial loss: 0.497977\n",
      "epoch 98; iter: 0; batch classifier loss: 0.069110; batch adversarial loss: 0.508553\n",
      "epoch 99; iter: 0; batch classifier loss: 0.024663; batch adversarial loss: 0.542673\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053450; batch adversarial loss: 0.429568\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056422; batch adversarial loss: 0.461530\n",
      "epoch 102; iter: 0; batch classifier loss: 0.026567; batch adversarial loss: 0.418031\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056950; batch adversarial loss: 0.477276\n",
      "epoch 104; iter: 0; batch classifier loss: 0.049174; batch adversarial loss: 0.526451\n",
      "epoch 105; iter: 0; batch classifier loss: 0.028004; batch adversarial loss: 0.512512\n",
      "epoch 106; iter: 0; batch classifier loss: 0.074118; batch adversarial loss: 0.407209\n",
      "epoch 107; iter: 0; batch classifier loss: 0.018057; batch adversarial loss: 0.538461\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030913; batch adversarial loss: 0.404163\n",
      "epoch 109; iter: 0; batch classifier loss: 0.034108; batch adversarial loss: 0.510628\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041289; batch adversarial loss: 0.537325\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048263; batch adversarial loss: 0.460778\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034994; batch adversarial loss: 0.338338\n",
      "epoch 113; iter: 0; batch classifier loss: 0.024083; batch adversarial loss: 0.547422\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036044; batch adversarial loss: 0.485393\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035653; batch adversarial loss: 0.566651\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026653; batch adversarial loss: 0.510244\n",
      "epoch 117; iter: 0; batch classifier loss: 0.059785; batch adversarial loss: 0.453794\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031574; batch adversarial loss: 0.505015\n",
      "epoch 119; iter: 0; batch classifier loss: 0.019501; batch adversarial loss: 0.511886\n",
      "epoch 120; iter: 0; batch classifier loss: 0.065359; batch adversarial loss: 0.387769\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021793; batch adversarial loss: 0.469488\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015456; batch adversarial loss: 0.512676\n",
      "epoch 123; iter: 0; batch classifier loss: 0.061127; batch adversarial loss: 0.461923\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031583; batch adversarial loss: 0.427374\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045273; batch adversarial loss: 0.528267\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039035; batch adversarial loss: 0.522957\n",
      "epoch 127; iter: 0; batch classifier loss: 0.015820; batch adversarial loss: 0.484430\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017612; batch adversarial loss: 0.409872\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020775; batch adversarial loss: 0.416427\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025465; batch adversarial loss: 0.413190\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032359; batch adversarial loss: 0.454770\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047774; batch adversarial loss: 0.540960\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023038; batch adversarial loss: 0.444840\n",
      "epoch 134; iter: 0; batch classifier loss: 0.010275; batch adversarial loss: 0.453772\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050305; batch adversarial loss: 0.464839\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016417; batch adversarial loss: 0.480506\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032489; batch adversarial loss: 0.531177\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017356; batch adversarial loss: 0.565630\n",
      "epoch 139; iter: 0; batch classifier loss: 0.012909; batch adversarial loss: 0.434017\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024040; batch adversarial loss: 0.437196\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016840; batch adversarial loss: 0.540585\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023051; batch adversarial loss: 0.428959\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018397; batch adversarial loss: 0.498428\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021747; batch adversarial loss: 0.429464\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014293; batch adversarial loss: 0.475688\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027988; batch adversarial loss: 0.329953\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022040; batch adversarial loss: 0.405845\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024292; batch adversarial loss: 0.499157\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031750; batch adversarial loss: 0.409803\n",
      "epoch 150; iter: 0; batch classifier loss: 0.009588; batch adversarial loss: 0.500585\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036107; batch adversarial loss: 0.466759\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036392; batch adversarial loss: 0.522476\n",
      "epoch 153; iter: 0; batch classifier loss: 0.009131; batch adversarial loss: 0.472577\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032064; batch adversarial loss: 0.412137\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031515; batch adversarial loss: 0.571720\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044391; batch adversarial loss: 0.422272\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024831; batch adversarial loss: 0.387637\n",
      "epoch 158; iter: 0; batch classifier loss: 0.043422; batch adversarial loss: 0.406548\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021283; batch adversarial loss: 0.544052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.025748; batch adversarial loss: 0.418550\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018767; batch adversarial loss: 0.454959\n",
      "epoch 162; iter: 0; batch classifier loss: 0.006363; batch adversarial loss: 0.433012\n",
      "epoch 163; iter: 0; batch classifier loss: 0.031437; batch adversarial loss: 0.395117\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022622; batch adversarial loss: 0.422954\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026080; batch adversarial loss: 0.417549\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017486; batch adversarial loss: 0.509268\n",
      "epoch 167; iter: 0; batch classifier loss: 0.038221; batch adversarial loss: 0.465698\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029287; batch adversarial loss: 0.376592\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023427; batch adversarial loss: 0.335548\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019102; batch adversarial loss: 0.474788\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016357; batch adversarial loss: 0.483270\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013231; batch adversarial loss: 0.361591\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007693; batch adversarial loss: 0.469970\n",
      "epoch 174; iter: 0; batch classifier loss: 0.034472; batch adversarial loss: 0.565434\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035247; batch adversarial loss: 0.526975\n",
      "epoch 176; iter: 0; batch classifier loss: 0.060606; batch adversarial loss: 0.511572\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010411; batch adversarial loss: 0.386980\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026821; batch adversarial loss: 0.389568\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021720; batch adversarial loss: 0.414110\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032971; batch adversarial loss: 0.431979\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025306; batch adversarial loss: 0.536326\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029577; batch adversarial loss: 0.459343\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025432; batch adversarial loss: 0.433807\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014477; batch adversarial loss: 0.433866\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011802; batch adversarial loss: 0.459355\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018302; batch adversarial loss: 0.489075\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006713; batch adversarial loss: 0.465819\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013705; batch adversarial loss: 0.396335\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022900; batch adversarial loss: 0.580096\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010963; batch adversarial loss: 0.471756\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018152; batch adversarial loss: 0.537133\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030806; batch adversarial loss: 0.423450\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032300; batch adversarial loss: 0.508499\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024106; batch adversarial loss: 0.417520\n",
      "epoch 195; iter: 0; batch classifier loss: 0.047129; batch adversarial loss: 0.446737\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009120; batch adversarial loss: 0.489692\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019036; batch adversarial loss: 0.449608\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003739; batch adversarial loss: 0.411846\n",
      "epoch 199; iter: 0; batch classifier loss: 0.003031; batch adversarial loss: 0.396487\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669366; batch adversarial loss: 0.626455\n",
      "epoch 1; iter: 0; batch classifier loss: 0.536521; batch adversarial loss: 0.625142\n",
      "epoch 2; iter: 0; batch classifier loss: 0.413346; batch adversarial loss: 0.636855\n",
      "epoch 3; iter: 0; batch classifier loss: 0.405789; batch adversarial loss: 0.611387\n",
      "epoch 4; iter: 0; batch classifier loss: 0.429316; batch adversarial loss: 0.613181\n",
      "epoch 5; iter: 0; batch classifier loss: 0.385379; batch adversarial loss: 0.620774\n",
      "epoch 6; iter: 0; batch classifier loss: 0.482293; batch adversarial loss: 0.548717\n",
      "epoch 7; iter: 0; batch classifier loss: 0.406357; batch adversarial loss: 0.569739\n",
      "epoch 8; iter: 0; batch classifier loss: 0.351618; batch adversarial loss: 0.560328\n",
      "epoch 9; iter: 0; batch classifier loss: 0.340801; batch adversarial loss: 0.541607\n",
      "epoch 10; iter: 0; batch classifier loss: 0.383260; batch adversarial loss: 0.537244\n",
      "epoch 11; iter: 0; batch classifier loss: 0.377760; batch adversarial loss: 0.462655\n",
      "epoch 12; iter: 0; batch classifier loss: 0.328408; batch adversarial loss: 0.470636\n",
      "epoch 13; iter: 0; batch classifier loss: 0.346049; batch adversarial loss: 0.477013\n",
      "epoch 14; iter: 0; batch classifier loss: 0.286858; batch adversarial loss: 0.436837\n",
      "epoch 15; iter: 0; batch classifier loss: 0.262108; batch adversarial loss: 0.442297\n",
      "epoch 16; iter: 0; batch classifier loss: 0.271432; batch adversarial loss: 0.458929\n",
      "epoch 17; iter: 0; batch classifier loss: 0.279220; batch adversarial loss: 0.508689\n",
      "epoch 18; iter: 0; batch classifier loss: 0.268466; batch adversarial loss: 0.488782\n",
      "epoch 19; iter: 0; batch classifier loss: 0.246936; batch adversarial loss: 0.457564\n",
      "epoch 20; iter: 0; batch classifier loss: 0.256634; batch adversarial loss: 0.506001\n",
      "epoch 21; iter: 0; batch classifier loss: 0.168920; batch adversarial loss: 0.525263\n",
      "epoch 22; iter: 0; batch classifier loss: 0.195880; batch adversarial loss: 0.427381\n",
      "epoch 23; iter: 0; batch classifier loss: 0.270323; batch adversarial loss: 0.412009\n",
      "epoch 24; iter: 0; batch classifier loss: 0.176746; batch adversarial loss: 0.513366\n",
      "epoch 25; iter: 0; batch classifier loss: 0.210168; batch adversarial loss: 0.523044\n",
      "epoch 26; iter: 0; batch classifier loss: 0.295417; batch adversarial loss: 0.493598\n",
      "epoch 27; iter: 0; batch classifier loss: 0.209805; batch adversarial loss: 0.443953\n",
      "epoch 28; iter: 0; batch classifier loss: 0.269760; batch adversarial loss: 0.415769\n",
      "epoch 29; iter: 0; batch classifier loss: 0.211231; batch adversarial loss: 0.416827\n",
      "epoch 30; iter: 0; batch classifier loss: 0.305297; batch adversarial loss: 0.418897\n",
      "epoch 31; iter: 0; batch classifier loss: 0.190466; batch adversarial loss: 0.450664\n",
      "epoch 32; iter: 0; batch classifier loss: 0.168625; batch adversarial loss: 0.446198\n",
      "epoch 33; iter: 0; batch classifier loss: 0.283961; batch adversarial loss: 0.461888\n",
      "epoch 34; iter: 0; batch classifier loss: 0.284180; batch adversarial loss: 0.463791\n",
      "epoch 35; iter: 0; batch classifier loss: 0.225464; batch adversarial loss: 0.434429\n",
      "epoch 36; iter: 0; batch classifier loss: 0.203385; batch adversarial loss: 0.462513\n",
      "epoch 37; iter: 0; batch classifier loss: 0.168415; batch adversarial loss: 0.519066\n",
      "epoch 38; iter: 0; batch classifier loss: 0.159499; batch adversarial loss: 0.534084\n",
      "epoch 39; iter: 0; batch classifier loss: 0.246305; batch adversarial loss: 0.425824\n",
      "epoch 40; iter: 0; batch classifier loss: 0.219785; batch adversarial loss: 0.480130\n",
      "epoch 41; iter: 0; batch classifier loss: 0.269441; batch adversarial loss: 0.424403\n",
      "epoch 42; iter: 0; batch classifier loss: 0.197078; batch adversarial loss: 0.417889\n",
      "epoch 43; iter: 0; batch classifier loss: 0.237876; batch adversarial loss: 0.389346\n",
      "epoch 44; iter: 0; batch classifier loss: 0.206003; batch adversarial loss: 0.536785\n",
      "epoch 45; iter: 0; batch classifier loss: 0.266352; batch adversarial loss: 0.446370\n",
      "epoch 46; iter: 0; batch classifier loss: 0.193578; batch adversarial loss: 0.460976\n",
      "epoch 47; iter: 0; batch classifier loss: 0.188425; batch adversarial loss: 0.528969\n",
      "epoch 48; iter: 0; batch classifier loss: 0.192996; batch adversarial loss: 0.574626\n",
      "epoch 49; iter: 0; batch classifier loss: 0.182398; batch adversarial loss: 0.447700\n",
      "epoch 50; iter: 0; batch classifier loss: 0.159412; batch adversarial loss: 0.435490\n",
      "epoch 51; iter: 0; batch classifier loss: 0.181490; batch adversarial loss: 0.411835\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103466; batch adversarial loss: 0.494551\n",
      "epoch 53; iter: 0; batch classifier loss: 0.102427; batch adversarial loss: 0.385669\n",
      "epoch 54; iter: 0; batch classifier loss: 0.113205; batch adversarial loss: 0.458204\n",
      "epoch 55; iter: 0; batch classifier loss: 0.069633; batch adversarial loss: 0.393932\n",
      "epoch 56; iter: 0; batch classifier loss: 0.063868; batch adversarial loss: 0.455026\n",
      "epoch 57; iter: 0; batch classifier loss: 0.148367; batch adversarial loss: 0.362858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.168292; batch adversarial loss: 0.393317\n",
      "epoch 59; iter: 0; batch classifier loss: 0.128570; batch adversarial loss: 0.480504\n",
      "epoch 60; iter: 0; batch classifier loss: 0.099128; batch adversarial loss: 0.531269\n",
      "epoch 61; iter: 0; batch classifier loss: 0.085498; batch adversarial loss: 0.466258\n",
      "epoch 62; iter: 0; batch classifier loss: 0.123358; batch adversarial loss: 0.604185\n",
      "epoch 63; iter: 0; batch classifier loss: 0.135887; batch adversarial loss: 0.433800\n",
      "epoch 64; iter: 0; batch classifier loss: 0.137699; batch adversarial loss: 0.382080\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118652; batch adversarial loss: 0.471209\n",
      "epoch 66; iter: 0; batch classifier loss: 0.124394; batch adversarial loss: 0.405431\n",
      "epoch 67; iter: 0; batch classifier loss: 0.138697; batch adversarial loss: 0.475186\n",
      "epoch 68; iter: 0; batch classifier loss: 0.138360; batch adversarial loss: 0.545412\n",
      "epoch 69; iter: 0; batch classifier loss: 0.156028; batch adversarial loss: 0.352359\n",
      "epoch 70; iter: 0; batch classifier loss: 0.158913; batch adversarial loss: 0.450383\n",
      "epoch 71; iter: 0; batch classifier loss: 0.106403; batch adversarial loss: 0.526344\n",
      "epoch 72; iter: 0; batch classifier loss: 0.155109; batch adversarial loss: 0.407976\n",
      "epoch 73; iter: 0; batch classifier loss: 0.135433; batch adversarial loss: 0.428188\n",
      "epoch 74; iter: 0; batch classifier loss: 0.123360; batch adversarial loss: 0.471927\n",
      "epoch 75; iter: 0; batch classifier loss: 0.084288; batch adversarial loss: 0.588439\n",
      "epoch 76; iter: 0; batch classifier loss: 0.155335; batch adversarial loss: 0.460210\n",
      "epoch 77; iter: 0; batch classifier loss: 0.161937; batch adversarial loss: 0.452960\n",
      "epoch 78; iter: 0; batch classifier loss: 0.098720; batch adversarial loss: 0.495688\n",
      "epoch 79; iter: 0; batch classifier loss: 0.090103; batch adversarial loss: 0.480877\n",
      "epoch 80; iter: 0; batch classifier loss: 0.098291; batch adversarial loss: 0.396099\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096996; batch adversarial loss: 0.407231\n",
      "epoch 82; iter: 0; batch classifier loss: 0.134671; batch adversarial loss: 0.504305\n",
      "epoch 83; iter: 0; batch classifier loss: 0.125067; batch adversarial loss: 0.520327\n",
      "epoch 84; iter: 0; batch classifier loss: 0.124901; batch adversarial loss: 0.476858\n",
      "epoch 85; iter: 0; batch classifier loss: 0.123392; batch adversarial loss: 0.425076\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084183; batch adversarial loss: 0.426902\n",
      "epoch 87; iter: 0; batch classifier loss: 0.128884; batch adversarial loss: 0.499164\n",
      "epoch 88; iter: 0; batch classifier loss: 0.066069; batch adversarial loss: 0.434920\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057330; batch adversarial loss: 0.452177\n",
      "epoch 90; iter: 0; batch classifier loss: 0.107639; batch adversarial loss: 0.567636\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083021; batch adversarial loss: 0.484868\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082217; batch adversarial loss: 0.470262\n",
      "epoch 93; iter: 0; batch classifier loss: 0.101104; batch adversarial loss: 0.464654\n",
      "epoch 94; iter: 0; batch classifier loss: 0.131951; batch adversarial loss: 0.388008\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071738; batch adversarial loss: 0.443055\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066459; batch adversarial loss: 0.392158\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069957; batch adversarial loss: 0.352747\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074674; batch adversarial loss: 0.389550\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042390; batch adversarial loss: 0.418250\n",
      "epoch 100; iter: 0; batch classifier loss: 0.086335; batch adversarial loss: 0.468778\n",
      "epoch 101; iter: 0; batch classifier loss: 0.081924; batch adversarial loss: 0.417081\n",
      "epoch 102; iter: 0; batch classifier loss: 0.083394; batch adversarial loss: 0.494417\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062589; batch adversarial loss: 0.483634\n",
      "epoch 104; iter: 0; batch classifier loss: 0.064890; batch adversarial loss: 0.478852\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059094; batch adversarial loss: 0.463930\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043861; batch adversarial loss: 0.438869\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062276; batch adversarial loss: 0.405910\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039242; batch adversarial loss: 0.493376\n",
      "epoch 109; iter: 0; batch classifier loss: 0.019059; batch adversarial loss: 0.556052\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036704; batch adversarial loss: 0.438226\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041481; batch adversarial loss: 0.432873\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053153; batch adversarial loss: 0.483924\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048500; batch adversarial loss: 0.414067\n",
      "epoch 114; iter: 0; batch classifier loss: 0.038523; batch adversarial loss: 0.499749\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042808; batch adversarial loss: 0.526935\n",
      "epoch 116; iter: 0; batch classifier loss: 0.019321; batch adversarial loss: 0.377092\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025543; batch adversarial loss: 0.487481\n",
      "epoch 118; iter: 0; batch classifier loss: 0.020147; batch adversarial loss: 0.356717\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026582; batch adversarial loss: 0.415397\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055592; batch adversarial loss: 0.511890\n",
      "epoch 121; iter: 0; batch classifier loss: 0.009474; batch adversarial loss: 0.406288\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041347; batch adversarial loss: 0.473510\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049446; batch adversarial loss: 0.392568\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042219; batch adversarial loss: 0.367934\n",
      "epoch 125; iter: 0; batch classifier loss: 0.055794; batch adversarial loss: 0.427826\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030464; batch adversarial loss: 0.374949\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023274; batch adversarial loss: 0.438119\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033003; batch adversarial loss: 0.462058\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040391; batch adversarial loss: 0.408588\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051430; batch adversarial loss: 0.498314\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043538; batch adversarial loss: 0.408236\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042605; batch adversarial loss: 0.515284\n",
      "epoch 133; iter: 0; batch classifier loss: 0.048333; batch adversarial loss: 0.427789\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036529; batch adversarial loss: 0.493492\n",
      "epoch 135; iter: 0; batch classifier loss: 0.077729; batch adversarial loss: 0.502258\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018813; batch adversarial loss: 0.481077\n",
      "epoch 137; iter: 0; batch classifier loss: 0.021849; batch adversarial loss: 0.545548\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036610; batch adversarial loss: 0.453389\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020426; batch adversarial loss: 0.374949\n",
      "epoch 140; iter: 0; batch classifier loss: 0.011408; batch adversarial loss: 0.452263\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023658; batch adversarial loss: 0.466617\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033252; batch adversarial loss: 0.597133\n",
      "epoch 143; iter: 0; batch classifier loss: 0.059781; batch adversarial loss: 0.431778\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013711; batch adversarial loss: 0.516223\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016042; batch adversarial loss: 0.527165\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029424; batch adversarial loss: 0.408514\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041556; batch adversarial loss: 0.474223\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032506; batch adversarial loss: 0.457305\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012009; batch adversarial loss: 0.392222\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036194; batch adversarial loss: 0.406830\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016477; batch adversarial loss: 0.543331\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016935; batch adversarial loss: 0.415922\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027884; batch adversarial loss: 0.574565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.023429; batch adversarial loss: 0.506251\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040526; batch adversarial loss: 0.508059\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036915; batch adversarial loss: 0.493943\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030521; batch adversarial loss: 0.497631\n",
      "epoch 158; iter: 0; batch classifier loss: 0.031216; batch adversarial loss: 0.438359\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014289; batch adversarial loss: 0.447338\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019774; batch adversarial loss: 0.378020\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016960; batch adversarial loss: 0.436941\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024668; batch adversarial loss: 0.459057\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010518; batch adversarial loss: 0.424026\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019228; batch adversarial loss: 0.497784\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024794; batch adversarial loss: 0.415529\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029883; batch adversarial loss: 0.472202\n",
      "epoch 167; iter: 0; batch classifier loss: 0.061716; batch adversarial loss: 0.444012\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029563; batch adversarial loss: 0.460829\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012026; batch adversarial loss: 0.417815\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031112; batch adversarial loss: 0.422154\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014210; batch adversarial loss: 0.396896\n",
      "epoch 172; iter: 0; batch classifier loss: 0.082329; batch adversarial loss: 0.421897\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022800; batch adversarial loss: 0.468436\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019637; batch adversarial loss: 0.498451\n",
      "epoch 175; iter: 0; batch classifier loss: 0.049392; batch adversarial loss: 0.485267\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010151; batch adversarial loss: 0.443734\n",
      "epoch 177; iter: 0; batch classifier loss: 0.005110; batch adversarial loss: 0.391160\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012696; batch adversarial loss: 0.393838\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023520; batch adversarial loss: 0.520713\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010144; batch adversarial loss: 0.424447\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015837; batch adversarial loss: 0.415477\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027100; batch adversarial loss: 0.538601\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017639; batch adversarial loss: 0.381546\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011724; batch adversarial loss: 0.419982\n",
      "epoch 185; iter: 0; batch classifier loss: 0.001785; batch adversarial loss: 0.474081\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029724; batch adversarial loss: 0.357343\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024229; batch adversarial loss: 0.429484\n",
      "epoch 188; iter: 0; batch classifier loss: 0.049108; batch adversarial loss: 0.401663\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018662; batch adversarial loss: 0.460484\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004677; batch adversarial loss: 0.393742\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015796; batch adversarial loss: 0.328749\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012052; batch adversarial loss: 0.458770\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009886; batch adversarial loss: 0.517689\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019044; batch adversarial loss: 0.490921\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012573; batch adversarial loss: 0.498810\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017713; batch adversarial loss: 0.402681\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008369; batch adversarial loss: 0.422746\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021579; batch adversarial loss: 0.426842\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016733; batch adversarial loss: 0.444892\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716716; batch adversarial loss: 0.651226\n",
      "epoch 1; iter: 0; batch classifier loss: 0.447432; batch adversarial loss: 0.635221\n",
      "epoch 2; iter: 0; batch classifier loss: 0.398581; batch adversarial loss: 0.622878\n",
      "epoch 3; iter: 0; batch classifier loss: 0.425897; batch adversarial loss: 0.631994\n",
      "epoch 4; iter: 0; batch classifier loss: 0.457003; batch adversarial loss: 0.592388\n",
      "epoch 5; iter: 0; batch classifier loss: 0.422818; batch adversarial loss: 0.555628\n",
      "epoch 6; iter: 0; batch classifier loss: 0.508880; batch adversarial loss: 0.614426\n",
      "epoch 7; iter: 0; batch classifier loss: 0.488834; batch adversarial loss: 0.605845\n",
      "epoch 8; iter: 0; batch classifier loss: 0.471541; batch adversarial loss: 0.568746\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528446; batch adversarial loss: 0.539620\n",
      "epoch 10; iter: 0; batch classifier loss: 0.457676; batch adversarial loss: 0.494756\n",
      "epoch 11; iter: 0; batch classifier loss: 0.426890; batch adversarial loss: 0.540760\n",
      "epoch 12; iter: 0; batch classifier loss: 0.354052; batch adversarial loss: 0.493444\n",
      "epoch 13; iter: 0; batch classifier loss: 0.471230; batch adversarial loss: 0.512635\n",
      "epoch 14; iter: 0; batch classifier loss: 0.395803; batch adversarial loss: 0.500195\n",
      "epoch 15; iter: 0; batch classifier loss: 0.322094; batch adversarial loss: 0.529246\n",
      "epoch 16; iter: 0; batch classifier loss: 0.419292; batch adversarial loss: 0.451423\n",
      "epoch 17; iter: 0; batch classifier loss: 0.470399; batch adversarial loss: 0.446355\n",
      "epoch 18; iter: 0; batch classifier loss: 0.329535; batch adversarial loss: 0.501164\n",
      "epoch 19; iter: 0; batch classifier loss: 0.348009; batch adversarial loss: 0.438497\n",
      "epoch 20; iter: 0; batch classifier loss: 0.357857; batch adversarial loss: 0.486407\n",
      "epoch 21; iter: 0; batch classifier loss: 0.328245; batch adversarial loss: 0.464773\n",
      "epoch 22; iter: 0; batch classifier loss: 0.334126; batch adversarial loss: 0.467902\n",
      "epoch 23; iter: 0; batch classifier loss: 0.325347; batch adversarial loss: 0.445208\n",
      "epoch 24; iter: 0; batch classifier loss: 0.303936; batch adversarial loss: 0.507361\n",
      "epoch 25; iter: 0; batch classifier loss: 0.323071; batch adversarial loss: 0.478253\n",
      "epoch 26; iter: 0; batch classifier loss: 0.243820; batch adversarial loss: 0.454380\n",
      "epoch 27; iter: 0; batch classifier loss: 0.310276; batch adversarial loss: 0.454994\n",
      "epoch 28; iter: 0; batch classifier loss: 0.248781; batch adversarial loss: 0.462681\n",
      "epoch 29; iter: 0; batch classifier loss: 0.303306; batch adversarial loss: 0.461020\n",
      "epoch 30; iter: 0; batch classifier loss: 0.256608; batch adversarial loss: 0.480845\n",
      "epoch 31; iter: 0; batch classifier loss: 0.266521; batch adversarial loss: 0.454468\n",
      "epoch 32; iter: 0; batch classifier loss: 0.265095; batch adversarial loss: 0.483939\n",
      "epoch 33; iter: 0; batch classifier loss: 0.249442; batch adversarial loss: 0.481733\n",
      "epoch 34; iter: 0; batch classifier loss: 0.262060; batch adversarial loss: 0.474644\n",
      "epoch 35; iter: 0; batch classifier loss: 0.354416; batch adversarial loss: 0.389857\n",
      "epoch 36; iter: 0; batch classifier loss: 0.267158; batch adversarial loss: 0.446150\n",
      "epoch 37; iter: 0; batch classifier loss: 0.280938; batch adversarial loss: 0.497388\n",
      "epoch 38; iter: 0; batch classifier loss: 0.278207; batch adversarial loss: 0.354549\n",
      "epoch 39; iter: 0; batch classifier loss: 0.257941; batch adversarial loss: 0.393664\n",
      "epoch 40; iter: 0; batch classifier loss: 0.244412; batch adversarial loss: 0.536983\n",
      "epoch 41; iter: 0; batch classifier loss: 0.327843; batch adversarial loss: 0.424558\n",
      "epoch 42; iter: 0; batch classifier loss: 0.216467; batch adversarial loss: 0.447781\n",
      "epoch 43; iter: 0; batch classifier loss: 0.256751; batch adversarial loss: 0.506920\n",
      "epoch 44; iter: 0; batch classifier loss: 0.208891; batch adversarial loss: 0.532429\n",
      "epoch 45; iter: 0; batch classifier loss: 0.284855; batch adversarial loss: 0.471879\n",
      "epoch 46; iter: 0; batch classifier loss: 0.196404; batch adversarial loss: 0.543960\n",
      "epoch 47; iter: 0; batch classifier loss: 0.278598; batch adversarial loss: 0.530770\n",
      "epoch 48; iter: 0; batch classifier loss: 0.224383; batch adversarial loss: 0.543391\n",
      "epoch 49; iter: 0; batch classifier loss: 0.148997; batch adversarial loss: 0.555037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.111844; batch adversarial loss: 0.470761\n",
      "epoch 51; iter: 0; batch classifier loss: 0.112133; batch adversarial loss: 0.505551\n",
      "epoch 52; iter: 0; batch classifier loss: 0.060076; batch adversarial loss: 0.460761\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088545; batch adversarial loss: 0.409480\n",
      "epoch 54; iter: 0; batch classifier loss: 0.065197; batch adversarial loss: 0.466231\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086134; batch adversarial loss: 0.417460\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065891; batch adversarial loss: 0.412427\n",
      "epoch 57; iter: 0; batch classifier loss: 0.101007; batch adversarial loss: 0.482507\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072957; batch adversarial loss: 0.543688\n",
      "epoch 59; iter: 0; batch classifier loss: 0.064405; batch adversarial loss: 0.399924\n",
      "epoch 60; iter: 0; batch classifier loss: 0.148043; batch adversarial loss: 0.453736\n",
      "epoch 61; iter: 0; batch classifier loss: 0.199237; batch adversarial loss: 0.502878\n",
      "epoch 62; iter: 0; batch classifier loss: 0.193985; batch adversarial loss: 0.452497\n",
      "epoch 63; iter: 0; batch classifier loss: 0.274191; batch adversarial loss: 0.345323\n",
      "epoch 64; iter: 0; batch classifier loss: 0.118827; batch adversarial loss: 0.443617\n",
      "epoch 65; iter: 0; batch classifier loss: 0.174046; batch adversarial loss: 0.468110\n",
      "epoch 66; iter: 0; batch classifier loss: 0.196661; batch adversarial loss: 0.418058\n",
      "epoch 67; iter: 0; batch classifier loss: 0.164209; batch adversarial loss: 0.446109\n",
      "epoch 68; iter: 0; batch classifier loss: 0.083191; batch adversarial loss: 0.393781\n",
      "epoch 69; iter: 0; batch classifier loss: 0.130838; batch adversarial loss: 0.483719\n",
      "epoch 70; iter: 0; batch classifier loss: 0.167522; batch adversarial loss: 0.488691\n",
      "epoch 71; iter: 0; batch classifier loss: 0.161175; batch adversarial loss: 0.367714\n",
      "epoch 72; iter: 0; batch classifier loss: 0.160150; batch adversarial loss: 0.519522\n",
      "epoch 73; iter: 0; batch classifier loss: 0.149534; batch adversarial loss: 0.358597\n",
      "epoch 74; iter: 0; batch classifier loss: 0.194113; batch adversarial loss: 0.435760\n",
      "epoch 75; iter: 0; batch classifier loss: 0.204278; batch adversarial loss: 0.362230\n",
      "epoch 76; iter: 0; batch classifier loss: 0.201806; batch adversarial loss: 0.504730\n",
      "epoch 77; iter: 0; batch classifier loss: 0.153405; batch adversarial loss: 0.440874\n",
      "epoch 78; iter: 0; batch classifier loss: 0.105261; batch adversarial loss: 0.425457\n",
      "epoch 79; iter: 0; batch classifier loss: 0.112635; batch adversarial loss: 0.473621\n",
      "epoch 80; iter: 0; batch classifier loss: 0.135940; batch adversarial loss: 0.491100\n",
      "epoch 81; iter: 0; batch classifier loss: 0.077526; batch adversarial loss: 0.562805\n",
      "epoch 82; iter: 0; batch classifier loss: 0.085869; batch adversarial loss: 0.495921\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085463; batch adversarial loss: 0.503852\n",
      "epoch 84; iter: 0; batch classifier loss: 0.093979; batch adversarial loss: 0.428658\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084051; batch adversarial loss: 0.438944\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067437; batch adversarial loss: 0.436684\n",
      "epoch 87; iter: 0; batch classifier loss: 0.085675; batch adversarial loss: 0.501429\n",
      "epoch 88; iter: 0; batch classifier loss: 0.093883; batch adversarial loss: 0.469801\n",
      "epoch 89; iter: 0; batch classifier loss: 0.085719; batch adversarial loss: 0.458773\n",
      "epoch 90; iter: 0; batch classifier loss: 0.076368; batch adversarial loss: 0.509460\n",
      "epoch 91; iter: 0; batch classifier loss: 0.069136; batch adversarial loss: 0.498621\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077903; batch adversarial loss: 0.510194\n",
      "epoch 93; iter: 0; batch classifier loss: 0.075474; batch adversarial loss: 0.409989\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049778; batch adversarial loss: 0.378634\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066374; batch adversarial loss: 0.525978\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068756; batch adversarial loss: 0.445540\n",
      "epoch 97; iter: 0; batch classifier loss: 0.087384; batch adversarial loss: 0.444803\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042543; batch adversarial loss: 0.447713\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052253; batch adversarial loss: 0.402747\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075505; batch adversarial loss: 0.344893\n",
      "epoch 101; iter: 0; batch classifier loss: 0.065797; batch adversarial loss: 0.427493\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054743; batch adversarial loss: 0.458192\n",
      "epoch 103; iter: 0; batch classifier loss: 0.068819; batch adversarial loss: 0.525477\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050597; batch adversarial loss: 0.393590\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051225; batch adversarial loss: 0.444363\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039383; batch adversarial loss: 0.356577\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033436; batch adversarial loss: 0.448579\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043177; batch adversarial loss: 0.389789\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054823; batch adversarial loss: 0.423801\n",
      "epoch 110; iter: 0; batch classifier loss: 0.073773; batch adversarial loss: 0.425550\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033349; batch adversarial loss: 0.392325\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047376; batch adversarial loss: 0.385893\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027803; batch adversarial loss: 0.423902\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054844; batch adversarial loss: 0.493572\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051345; batch adversarial loss: 0.392529\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037430; batch adversarial loss: 0.515515\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035513; batch adversarial loss: 0.505695\n",
      "epoch 118; iter: 0; batch classifier loss: 0.019247; batch adversarial loss: 0.465495\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042340; batch adversarial loss: 0.364363\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041569; batch adversarial loss: 0.291453\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049971; batch adversarial loss: 0.443380\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039069; batch adversarial loss: 0.375410\n",
      "epoch 123; iter: 0; batch classifier loss: 0.022189; batch adversarial loss: 0.473134\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048844; batch adversarial loss: 0.449433\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020883; batch adversarial loss: 0.437464\n",
      "epoch 126; iter: 0; batch classifier loss: 0.010384; batch adversarial loss: 0.448867\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019525; batch adversarial loss: 0.526490\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017366; batch adversarial loss: 0.443817\n",
      "epoch 129; iter: 0; batch classifier loss: 0.011303; batch adversarial loss: 0.419750\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031345; batch adversarial loss: 0.425410\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026053; batch adversarial loss: 0.396049\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028909; batch adversarial loss: 0.472371\n",
      "epoch 133; iter: 0; batch classifier loss: 0.048625; batch adversarial loss: 0.469077\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021735; batch adversarial loss: 0.440452\n",
      "epoch 135; iter: 0; batch classifier loss: 0.015176; batch adversarial loss: 0.483258\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017759; batch adversarial loss: 0.485479\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037226; batch adversarial loss: 0.437121\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017177; batch adversarial loss: 0.497818\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013054; batch adversarial loss: 0.448561\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020795; batch adversarial loss: 0.452259\n",
      "epoch 141; iter: 0; batch classifier loss: 0.009266; batch adversarial loss: 0.396247\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036416; batch adversarial loss: 0.539165\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014968; batch adversarial loss: 0.335046\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021606; batch adversarial loss: 0.449066\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023130; batch adversarial loss: 0.408178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.028653; batch adversarial loss: 0.396077\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023304; batch adversarial loss: 0.411242\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020196; batch adversarial loss: 0.398140\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016839; batch adversarial loss: 0.404807\n",
      "epoch 150; iter: 0; batch classifier loss: 0.058560; batch adversarial loss: 0.532109\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038933; batch adversarial loss: 0.455376\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026443; batch adversarial loss: 0.383618\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030406; batch adversarial loss: 0.423279\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017683; batch adversarial loss: 0.520137\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018559; batch adversarial loss: 0.438500\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023697; batch adversarial loss: 0.473216\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020279; batch adversarial loss: 0.321795\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009595; batch adversarial loss: 0.436601\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014393; batch adversarial loss: 0.518541\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026087; batch adversarial loss: 0.419792\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009208; batch adversarial loss: 0.452935\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017534; batch adversarial loss: 0.422823\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025614; batch adversarial loss: 0.412855\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009845; batch adversarial loss: 0.384184\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009029; batch adversarial loss: 0.439180\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015687; batch adversarial loss: 0.428280\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011543; batch adversarial loss: 0.402362\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008571; batch adversarial loss: 0.424154\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008823; batch adversarial loss: 0.378754\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014956; batch adversarial loss: 0.391135\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017757; batch adversarial loss: 0.359464\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013858; batch adversarial loss: 0.438469\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015701; batch adversarial loss: 0.336097\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015321; batch adversarial loss: 0.441318\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014901; batch adversarial loss: 0.549850\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008681; batch adversarial loss: 0.376462\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018087; batch adversarial loss: 0.548762\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034839; batch adversarial loss: 0.378473\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007216; batch adversarial loss: 0.419138\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012260; batch adversarial loss: 0.390450\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013402; batch adversarial loss: 0.554841\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018573; batch adversarial loss: 0.504954\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023030; batch adversarial loss: 0.446215\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013648; batch adversarial loss: 0.443561\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014667; batch adversarial loss: 0.479181\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010265; batch adversarial loss: 0.406780\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023719; batch adversarial loss: 0.485691\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040308; batch adversarial loss: 0.462673\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019297; batch adversarial loss: 0.398052\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005493; batch adversarial loss: 0.530895\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010731; batch adversarial loss: 0.502699\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026386; batch adversarial loss: 0.423221\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017723; batch adversarial loss: 0.430400\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019919; batch adversarial loss: 0.510015\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021033; batch adversarial loss: 0.570807\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021976; batch adversarial loss: 0.466062\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013593; batch adversarial loss: 0.423587\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003712; batch adversarial loss: 0.471691\n",
      "epoch 199; iter: 0; batch classifier loss: 0.075054; batch adversarial loss: 0.492431\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698915; batch adversarial loss: 0.660889\n",
      "epoch 1; iter: 0; batch classifier loss: 0.379063; batch adversarial loss: 0.640641\n",
      "epoch 2; iter: 0; batch classifier loss: 0.387546; batch adversarial loss: 0.592249\n",
      "epoch 3; iter: 0; batch classifier loss: 0.384551; batch adversarial loss: 0.571783\n",
      "epoch 4; iter: 0; batch classifier loss: 0.310351; batch adversarial loss: 0.559479\n",
      "epoch 5; iter: 0; batch classifier loss: 0.296741; batch adversarial loss: 0.555767\n",
      "epoch 6; iter: 0; batch classifier loss: 0.305370; batch adversarial loss: 0.569863\n",
      "epoch 7; iter: 0; batch classifier loss: 0.217933; batch adversarial loss: 0.514488\n",
      "epoch 8; iter: 0; batch classifier loss: 0.255465; batch adversarial loss: 0.511868\n",
      "epoch 9; iter: 0; batch classifier loss: 0.252599; batch adversarial loss: 0.484117\n",
      "epoch 10; iter: 0; batch classifier loss: 0.241930; batch adversarial loss: 0.508325\n",
      "epoch 11; iter: 0; batch classifier loss: 0.238896; batch adversarial loss: 0.524820\n",
      "epoch 12; iter: 0; batch classifier loss: 0.266083; batch adversarial loss: 0.469246\n",
      "epoch 13; iter: 0; batch classifier loss: 0.124699; batch adversarial loss: 0.481944\n",
      "epoch 14; iter: 0; batch classifier loss: 0.209593; batch adversarial loss: 0.478414\n",
      "epoch 15; iter: 0; batch classifier loss: 0.217795; batch adversarial loss: 0.500919\n",
      "epoch 16; iter: 0; batch classifier loss: 0.221065; batch adversarial loss: 0.449511\n",
      "epoch 17; iter: 0; batch classifier loss: 0.169568; batch adversarial loss: 0.426458\n",
      "epoch 18; iter: 0; batch classifier loss: 0.239156; batch adversarial loss: 0.605603\n",
      "epoch 19; iter: 0; batch classifier loss: 0.182710; batch adversarial loss: 0.422707\n",
      "epoch 20; iter: 0; batch classifier loss: 0.185766; batch adversarial loss: 0.556404\n",
      "epoch 21; iter: 0; batch classifier loss: 0.261798; batch adversarial loss: 0.499352\n",
      "epoch 22; iter: 0; batch classifier loss: 0.269510; batch adversarial loss: 0.523012\n",
      "epoch 23; iter: 0; batch classifier loss: 0.401456; batch adversarial loss: 0.604460\n",
      "epoch 24; iter: 0; batch classifier loss: 0.359802; batch adversarial loss: 0.442357\n",
      "epoch 25; iter: 0; batch classifier loss: 0.375544; batch adversarial loss: 0.522164\n",
      "epoch 26; iter: 0; batch classifier loss: 0.265486; batch adversarial loss: 0.461250\n",
      "epoch 27; iter: 0; batch classifier loss: 0.159736; batch adversarial loss: 0.518040\n",
      "epoch 28; iter: 0; batch classifier loss: 0.159003; batch adversarial loss: 0.480314\n",
      "epoch 29; iter: 0; batch classifier loss: 0.102241; batch adversarial loss: 0.473258\n",
      "epoch 30; iter: 0; batch classifier loss: 0.120759; batch adversarial loss: 0.501246\n",
      "epoch 31; iter: 0; batch classifier loss: 0.101069; batch adversarial loss: 0.496434\n",
      "epoch 32; iter: 0; batch classifier loss: 0.143602; batch adversarial loss: 0.471761\n",
      "epoch 33; iter: 0; batch classifier loss: 0.184740; batch adversarial loss: 0.459320\n",
      "epoch 34; iter: 0; batch classifier loss: 0.119646; batch adversarial loss: 0.327037\n",
      "epoch 35; iter: 0; batch classifier loss: 0.119298; batch adversarial loss: 0.433442\n",
      "epoch 36; iter: 0; batch classifier loss: 0.130861; batch adversarial loss: 0.412462\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110633; batch adversarial loss: 0.369735\n",
      "epoch 38; iter: 0; batch classifier loss: 0.155398; batch adversarial loss: 0.466037\n",
      "epoch 39; iter: 0; batch classifier loss: 0.098379; batch adversarial loss: 0.564428\n",
      "epoch 40; iter: 0; batch classifier loss: 0.092178; batch adversarial loss: 0.459681\n",
      "epoch 41; iter: 0; batch classifier loss: 0.113172; batch adversarial loss: 0.500484\n",
      "epoch 42; iter: 0; batch classifier loss: 0.080147; batch adversarial loss: 0.424417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43; iter: 0; batch classifier loss: 0.116870; batch adversarial loss: 0.398921\n",
      "epoch 44; iter: 0; batch classifier loss: 0.079078; batch adversarial loss: 0.530765\n",
      "epoch 45; iter: 0; batch classifier loss: 0.079833; batch adversarial loss: 0.452097\n",
      "epoch 46; iter: 0; batch classifier loss: 0.143397; batch adversarial loss: 0.424388\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112412; batch adversarial loss: 0.464031\n",
      "epoch 48; iter: 0; batch classifier loss: 0.108743; batch adversarial loss: 0.381996\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114522; batch adversarial loss: 0.398944\n",
      "epoch 50; iter: 0; batch classifier loss: 0.066907; batch adversarial loss: 0.441661\n",
      "epoch 51; iter: 0; batch classifier loss: 0.087714; batch adversarial loss: 0.426001\n",
      "epoch 52; iter: 0; batch classifier loss: 0.083205; batch adversarial loss: 0.378858\n",
      "epoch 53; iter: 0; batch classifier loss: 0.071827; batch adversarial loss: 0.417382\n",
      "epoch 54; iter: 0; batch classifier loss: 0.151445; batch adversarial loss: 0.483179\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122580; batch adversarial loss: 0.424619\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102319; batch adversarial loss: 0.403189\n",
      "epoch 57; iter: 0; batch classifier loss: 0.102007; batch adversarial loss: 0.466102\n",
      "epoch 58; iter: 0; batch classifier loss: 0.079439; batch adversarial loss: 0.425048\n",
      "epoch 59; iter: 0; batch classifier loss: 0.092554; batch adversarial loss: 0.450913\n",
      "epoch 60; iter: 0; batch classifier loss: 0.074257; batch adversarial loss: 0.419622\n",
      "epoch 61; iter: 0; batch classifier loss: 0.120018; batch adversarial loss: 0.380473\n",
      "epoch 62; iter: 0; batch classifier loss: 0.070474; batch adversarial loss: 0.490594\n",
      "epoch 63; iter: 0; batch classifier loss: 0.058299; batch adversarial loss: 0.400307\n",
      "epoch 64; iter: 0; batch classifier loss: 0.067141; batch adversarial loss: 0.442105\n",
      "epoch 65; iter: 0; batch classifier loss: 0.132695; batch adversarial loss: 0.452496\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084383; batch adversarial loss: 0.429144\n",
      "epoch 67; iter: 0; batch classifier loss: 0.104833; batch adversarial loss: 0.535219\n",
      "epoch 68; iter: 0; batch classifier loss: 0.063919; batch adversarial loss: 0.441169\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076930; batch adversarial loss: 0.444004\n",
      "epoch 70; iter: 0; batch classifier loss: 0.068758; batch adversarial loss: 0.390275\n",
      "epoch 71; iter: 0; batch classifier loss: 0.046659; batch adversarial loss: 0.430721\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080881; batch adversarial loss: 0.375405\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075589; batch adversarial loss: 0.358961\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063682; batch adversarial loss: 0.467297\n",
      "epoch 75; iter: 0; batch classifier loss: 0.104415; batch adversarial loss: 0.428072\n",
      "epoch 76; iter: 0; batch classifier loss: 0.120831; batch adversarial loss: 0.393345\n",
      "epoch 77; iter: 0; batch classifier loss: 0.108185; batch adversarial loss: 0.480490\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075467; batch adversarial loss: 0.536643\n",
      "epoch 79; iter: 0; batch classifier loss: 0.059169; batch adversarial loss: 0.480631\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083614; batch adversarial loss: 0.431225\n",
      "epoch 81; iter: 0; batch classifier loss: 0.126262; batch adversarial loss: 0.447138\n",
      "epoch 82; iter: 0; batch classifier loss: 0.107184; batch adversarial loss: 0.435186\n",
      "epoch 83; iter: 0; batch classifier loss: 0.103314; batch adversarial loss: 0.432264\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055266; batch adversarial loss: 0.570285\n",
      "epoch 85; iter: 0; batch classifier loss: 0.092321; batch adversarial loss: 0.455355\n",
      "epoch 86; iter: 0; batch classifier loss: 0.075587; batch adversarial loss: 0.519223\n",
      "epoch 87; iter: 0; batch classifier loss: 0.063127; batch adversarial loss: 0.478776\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069745; batch adversarial loss: 0.461270\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081316; batch adversarial loss: 0.506255\n",
      "epoch 90; iter: 0; batch classifier loss: 0.076003; batch adversarial loss: 0.457477\n",
      "epoch 91; iter: 0; batch classifier loss: 0.094835; batch adversarial loss: 0.462422\n",
      "epoch 92; iter: 0; batch classifier loss: 0.101929; batch adversarial loss: 0.510347\n",
      "epoch 93; iter: 0; batch classifier loss: 0.042684; batch adversarial loss: 0.436690\n",
      "epoch 94; iter: 0; batch classifier loss: 0.054282; batch adversarial loss: 0.489033\n",
      "epoch 95; iter: 0; batch classifier loss: 0.098733; batch adversarial loss: 0.525240\n",
      "epoch 96; iter: 0; batch classifier loss: 0.069758; batch adversarial loss: 0.446936\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043928; batch adversarial loss: 0.453404\n",
      "epoch 98; iter: 0; batch classifier loss: 0.097067; batch adversarial loss: 0.403870\n",
      "epoch 99; iter: 0; batch classifier loss: 0.051858; batch adversarial loss: 0.453342\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056500; batch adversarial loss: 0.462302\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044859; batch adversarial loss: 0.475315\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031492; batch adversarial loss: 0.418871\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040418; batch adversarial loss: 0.540696\n",
      "epoch 104; iter: 0; batch classifier loss: 0.052248; batch adversarial loss: 0.483980\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030737; batch adversarial loss: 0.550301\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030305; batch adversarial loss: 0.483181\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037244; batch adversarial loss: 0.300854\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043522; batch adversarial loss: 0.562795\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064917; batch adversarial loss: 0.519694\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042105; batch adversarial loss: 0.465505\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043528; batch adversarial loss: 0.392085\n",
      "epoch 112; iter: 0; batch classifier loss: 0.065746; batch adversarial loss: 0.536730\n",
      "epoch 113; iter: 0; batch classifier loss: 0.026794; batch adversarial loss: 0.429853\n",
      "epoch 114; iter: 0; batch classifier loss: 0.074612; batch adversarial loss: 0.461552\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054774; batch adversarial loss: 0.478826\n",
      "epoch 116; iter: 0; batch classifier loss: 0.073274; batch adversarial loss: 0.453034\n",
      "epoch 117; iter: 0; batch classifier loss: 0.077722; batch adversarial loss: 0.464252\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057146; batch adversarial loss: 0.425687\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065108; batch adversarial loss: 0.536766\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035772; batch adversarial loss: 0.433753\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032619; batch adversarial loss: 0.409550\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046934; batch adversarial loss: 0.531403\n",
      "epoch 123; iter: 0; batch classifier loss: 0.063525; batch adversarial loss: 0.469415\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041071; batch adversarial loss: 0.467566\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061170; batch adversarial loss: 0.356218\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027219; batch adversarial loss: 0.453204\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034135; batch adversarial loss: 0.415306\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039213; batch adversarial loss: 0.432586\n",
      "epoch 129; iter: 0; batch classifier loss: 0.014149; batch adversarial loss: 0.345853\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021388; batch adversarial loss: 0.398200\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043776; batch adversarial loss: 0.446670\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047686; batch adversarial loss: 0.454943\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045467; batch adversarial loss: 0.512865\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036229; batch adversarial loss: 0.449106\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023242; batch adversarial loss: 0.465466\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021538; batch adversarial loss: 0.463942\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025153; batch adversarial loss: 0.429304\n",
      "epoch 138; iter: 0; batch classifier loss: 0.009811; batch adversarial loss: 0.504225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 139; iter: 0; batch classifier loss: 0.027078; batch adversarial loss: 0.424701\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044879; batch adversarial loss: 0.486386\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044227; batch adversarial loss: 0.457272\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036746; batch adversarial loss: 0.508350\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022895; batch adversarial loss: 0.464017\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012302; batch adversarial loss: 0.425052\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046914; batch adversarial loss: 0.435879\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045163; batch adversarial loss: 0.540983\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020651; batch adversarial loss: 0.461070\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021309; batch adversarial loss: 0.375515\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031239; batch adversarial loss: 0.442570\n",
      "epoch 150; iter: 0; batch classifier loss: 0.059096; batch adversarial loss: 0.385346\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033945; batch adversarial loss: 0.450585\n",
      "epoch 152; iter: 0; batch classifier loss: 0.049509; batch adversarial loss: 0.483396\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010510; batch adversarial loss: 0.594318\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038509; batch adversarial loss: 0.390482\n",
      "epoch 155; iter: 0; batch classifier loss: 0.004704; batch adversarial loss: 0.461154\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023733; batch adversarial loss: 0.396256\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041413; batch adversarial loss: 0.476485\n",
      "epoch 158; iter: 0; batch classifier loss: 0.005997; batch adversarial loss: 0.395797\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037442; batch adversarial loss: 0.455362\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023082; batch adversarial loss: 0.387391\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043339; batch adversarial loss: 0.524854\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026948; batch adversarial loss: 0.542280\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014342; batch adversarial loss: 0.398137\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015394; batch adversarial loss: 0.389990\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016142; batch adversarial loss: 0.428472\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010836; batch adversarial loss: 0.529901\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012531; batch adversarial loss: 0.488908\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022147; batch adversarial loss: 0.514391\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014726; batch adversarial loss: 0.446654\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008966; batch adversarial loss: 0.451901\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018750; batch adversarial loss: 0.491401\n",
      "epoch 172; iter: 0; batch classifier loss: 0.041927; batch adversarial loss: 0.460469\n",
      "epoch 173; iter: 0; batch classifier loss: 0.049515; batch adversarial loss: 0.452214\n",
      "epoch 174; iter: 0; batch classifier loss: 0.059117; batch adversarial loss: 0.507494\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030473; batch adversarial loss: 0.481668\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011645; batch adversarial loss: 0.476902\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011940; batch adversarial loss: 0.465248\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026588; batch adversarial loss: 0.548407\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018786; batch adversarial loss: 0.380822\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013965; batch adversarial loss: 0.492341\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023726; batch adversarial loss: 0.419389\n",
      "epoch 182; iter: 0; batch classifier loss: 0.040697; batch adversarial loss: 0.439930\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017956; batch adversarial loss: 0.459052\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003405; batch adversarial loss: 0.456941\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008837; batch adversarial loss: 0.354492\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015481; batch adversarial loss: 0.409619\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022225; batch adversarial loss: 0.476180\n",
      "epoch 188; iter: 0; batch classifier loss: 0.052519; batch adversarial loss: 0.392192\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012907; batch adversarial loss: 0.403666\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022366; batch adversarial loss: 0.441397\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011891; batch adversarial loss: 0.493350\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009898; batch adversarial loss: 0.429192\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017486; batch adversarial loss: 0.403093\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023978; batch adversarial loss: 0.460170\n",
      "epoch 195; iter: 0; batch classifier loss: 0.039969; batch adversarial loss: 0.459027\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014517; batch adversarial loss: 0.549500\n",
      "epoch 197; iter: 0; batch classifier loss: 0.043392; batch adversarial loss: 0.339516\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007451; batch adversarial loss: 0.436504\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015092; batch adversarial loss: 0.523316\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687771; batch adversarial loss: 0.677309\n",
      "epoch 1; iter: 0; batch classifier loss: 0.546624; batch adversarial loss: 0.656191\n",
      "epoch 2; iter: 0; batch classifier loss: 0.495085; batch adversarial loss: 0.636792\n",
      "epoch 3; iter: 0; batch classifier loss: 0.481526; batch adversarial loss: 0.613822\n",
      "epoch 4; iter: 0; batch classifier loss: 0.398064; batch adversarial loss: 0.622117\n",
      "epoch 5; iter: 0; batch classifier loss: 0.518328; batch adversarial loss: 0.594915\n",
      "epoch 6; iter: 0; batch classifier loss: 0.436764; batch adversarial loss: 0.557622\n",
      "epoch 7; iter: 0; batch classifier loss: 0.298525; batch adversarial loss: 0.612634\n",
      "epoch 8; iter: 0; batch classifier loss: 0.467086; batch adversarial loss: 0.511793\n",
      "epoch 9; iter: 0; batch classifier loss: 0.448333; batch adversarial loss: 0.510981\n",
      "epoch 10; iter: 0; batch classifier loss: 0.368591; batch adversarial loss: 0.534301\n",
      "epoch 11; iter: 0; batch classifier loss: 0.367954; batch adversarial loss: 0.484842\n",
      "epoch 12; iter: 0; batch classifier loss: 0.353199; batch adversarial loss: 0.499294\n",
      "epoch 13; iter: 0; batch classifier loss: 0.290481; batch adversarial loss: 0.536335\n",
      "epoch 14; iter: 0; batch classifier loss: 0.286961; batch adversarial loss: 0.488469\n",
      "epoch 15; iter: 0; batch classifier loss: 0.311158; batch adversarial loss: 0.441404\n",
      "epoch 16; iter: 0; batch classifier loss: 0.263044; batch adversarial loss: 0.488041\n",
      "epoch 17; iter: 0; batch classifier loss: 0.309731; batch adversarial loss: 0.484100\n",
      "epoch 18; iter: 0; batch classifier loss: 0.208910; batch adversarial loss: 0.466413\n",
      "epoch 19; iter: 0; batch classifier loss: 0.208637; batch adversarial loss: 0.499283\n",
      "epoch 20; iter: 0; batch classifier loss: 0.236497; batch adversarial loss: 0.438293\n",
      "epoch 21; iter: 0; batch classifier loss: 0.191830; batch adversarial loss: 0.466545\n",
      "epoch 22; iter: 0; batch classifier loss: 0.165460; batch adversarial loss: 0.553297\n",
      "epoch 23; iter: 0; batch classifier loss: 0.202920; batch adversarial loss: 0.418527\n",
      "epoch 24; iter: 0; batch classifier loss: 0.187096; batch adversarial loss: 0.465006\n",
      "epoch 25; iter: 0; batch classifier loss: 0.184281; batch adversarial loss: 0.501037\n",
      "epoch 26; iter: 0; batch classifier loss: 0.144343; batch adversarial loss: 0.513094\n",
      "epoch 27; iter: 0; batch classifier loss: 0.194675; batch adversarial loss: 0.393140\n",
      "epoch 28; iter: 0; batch classifier loss: 0.161204; batch adversarial loss: 0.450280\n",
      "epoch 29; iter: 0; batch classifier loss: 0.181698; batch adversarial loss: 0.511205\n",
      "epoch 30; iter: 0; batch classifier loss: 0.218274; batch adversarial loss: 0.449741\n",
      "epoch 31; iter: 0; batch classifier loss: 0.100941; batch adversarial loss: 0.461013\n",
      "epoch 32; iter: 0; batch classifier loss: 0.138444; batch adversarial loss: 0.449118\n",
      "epoch 33; iter: 0; batch classifier loss: 0.145484; batch adversarial loss: 0.381468\n",
      "epoch 34; iter: 0; batch classifier loss: 0.163466; batch adversarial loss: 0.477967\n",
      "epoch 35; iter: 0; batch classifier loss: 0.132478; batch adversarial loss: 0.421855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.166381; batch adversarial loss: 0.423747\n",
      "epoch 37; iter: 0; batch classifier loss: 0.182323; batch adversarial loss: 0.484154\n",
      "epoch 38; iter: 0; batch classifier loss: 0.096112; batch adversarial loss: 0.460645\n",
      "epoch 39; iter: 0; batch classifier loss: 0.143627; batch adversarial loss: 0.418029\n",
      "epoch 40; iter: 0; batch classifier loss: 0.102968; batch adversarial loss: 0.543819\n",
      "epoch 41; iter: 0; batch classifier loss: 0.140391; batch adversarial loss: 0.517598\n",
      "epoch 42; iter: 0; batch classifier loss: 0.084559; batch adversarial loss: 0.512513\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117002; batch adversarial loss: 0.459981\n",
      "epoch 44; iter: 0; batch classifier loss: 0.076779; batch adversarial loss: 0.554720\n",
      "epoch 45; iter: 0; batch classifier loss: 0.142177; batch adversarial loss: 0.412303\n",
      "epoch 46; iter: 0; batch classifier loss: 0.096550; batch adversarial loss: 0.503240\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095787; batch adversarial loss: 0.446952\n",
      "epoch 48; iter: 0; batch classifier loss: 0.183369; batch adversarial loss: 0.401749\n",
      "epoch 49; iter: 0; batch classifier loss: 0.091061; batch adversarial loss: 0.410480\n",
      "epoch 50; iter: 0; batch classifier loss: 0.167227; batch adversarial loss: 0.440469\n",
      "epoch 51; iter: 0; batch classifier loss: 0.130780; batch adversarial loss: 0.404039\n",
      "epoch 52; iter: 0; batch classifier loss: 0.108518; batch adversarial loss: 0.452750\n",
      "epoch 53; iter: 0; batch classifier loss: 0.134522; batch adversarial loss: 0.475513\n",
      "epoch 54; iter: 0; batch classifier loss: 0.054395; batch adversarial loss: 0.480229\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089719; batch adversarial loss: 0.511334\n",
      "epoch 56; iter: 0; batch classifier loss: 0.109294; batch adversarial loss: 0.426106\n",
      "epoch 57; iter: 0; batch classifier loss: 0.103251; batch adversarial loss: 0.451701\n",
      "epoch 58; iter: 0; batch classifier loss: 0.088928; batch adversarial loss: 0.431388\n",
      "epoch 59; iter: 0; batch classifier loss: 0.086340; batch adversarial loss: 0.398466\n",
      "epoch 60; iter: 0; batch classifier loss: 0.044998; batch adversarial loss: 0.453124\n",
      "epoch 61; iter: 0; batch classifier loss: 0.105916; batch adversarial loss: 0.486218\n",
      "epoch 62; iter: 0; batch classifier loss: 0.058511; batch adversarial loss: 0.478261\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076918; batch adversarial loss: 0.428501\n",
      "epoch 64; iter: 0; batch classifier loss: 0.091530; batch adversarial loss: 0.459081\n",
      "epoch 65; iter: 0; batch classifier loss: 0.138750; batch adversarial loss: 0.344593\n",
      "epoch 66; iter: 0; batch classifier loss: 0.074643; batch adversarial loss: 0.543534\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082022; batch adversarial loss: 0.499531\n",
      "epoch 68; iter: 0; batch classifier loss: 0.043710; batch adversarial loss: 0.425870\n",
      "epoch 69; iter: 0; batch classifier loss: 0.063988; batch adversarial loss: 0.568408\n",
      "epoch 70; iter: 0; batch classifier loss: 0.106547; batch adversarial loss: 0.493108\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058580; batch adversarial loss: 0.362314\n",
      "epoch 72; iter: 0; batch classifier loss: 0.035814; batch adversarial loss: 0.348004\n",
      "epoch 73; iter: 0; batch classifier loss: 0.052288; batch adversarial loss: 0.379943\n",
      "epoch 74; iter: 0; batch classifier loss: 0.064360; batch adversarial loss: 0.420493\n",
      "epoch 75; iter: 0; batch classifier loss: 0.044053; batch adversarial loss: 0.441245\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081514; batch adversarial loss: 0.470822\n",
      "epoch 77; iter: 0; batch classifier loss: 0.073475; batch adversarial loss: 0.460230\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066925; batch adversarial loss: 0.378606\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044188; batch adversarial loss: 0.418258\n",
      "epoch 80; iter: 0; batch classifier loss: 0.081532; batch adversarial loss: 0.430549\n",
      "epoch 81; iter: 0; batch classifier loss: 0.105777; batch adversarial loss: 0.438633\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062767; batch adversarial loss: 0.399540\n",
      "epoch 83; iter: 0; batch classifier loss: 0.057723; batch adversarial loss: 0.537002\n",
      "epoch 84; iter: 0; batch classifier loss: 0.049256; batch adversarial loss: 0.542575\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068213; batch adversarial loss: 0.458079\n",
      "epoch 86; iter: 0; batch classifier loss: 0.066495; batch adversarial loss: 0.509600\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042497; batch adversarial loss: 0.386181\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070886; batch adversarial loss: 0.442937\n",
      "epoch 89; iter: 0; batch classifier loss: 0.035806; batch adversarial loss: 0.433207\n",
      "epoch 90; iter: 0; batch classifier loss: 0.098568; batch adversarial loss: 0.559996\n",
      "epoch 91; iter: 0; batch classifier loss: 0.071668; batch adversarial loss: 0.440724\n",
      "epoch 92; iter: 0; batch classifier loss: 0.076289; batch adversarial loss: 0.413230\n",
      "epoch 93; iter: 0; batch classifier loss: 0.032159; batch adversarial loss: 0.501014\n",
      "epoch 94; iter: 0; batch classifier loss: 0.040483; batch adversarial loss: 0.433668\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053134; batch adversarial loss: 0.425319\n",
      "epoch 96; iter: 0; batch classifier loss: 0.071342; batch adversarial loss: 0.514594\n",
      "epoch 97; iter: 0; batch classifier loss: 0.027499; batch adversarial loss: 0.437720\n",
      "epoch 98; iter: 0; batch classifier loss: 0.088736; batch adversarial loss: 0.543592\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047261; batch adversarial loss: 0.455292\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054972; batch adversarial loss: 0.437159\n",
      "epoch 101; iter: 0; batch classifier loss: 0.028495; batch adversarial loss: 0.389795\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054072; batch adversarial loss: 0.481206\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043812; batch adversarial loss: 0.469984\n",
      "epoch 104; iter: 0; batch classifier loss: 0.030482; batch adversarial loss: 0.505804\n",
      "epoch 105; iter: 0; batch classifier loss: 0.016436; batch adversarial loss: 0.415503\n",
      "epoch 106; iter: 0; batch classifier loss: 0.048227; batch adversarial loss: 0.464599\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059036; batch adversarial loss: 0.491663\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037369; batch adversarial loss: 0.490938\n",
      "epoch 109; iter: 0; batch classifier loss: 0.078440; batch adversarial loss: 0.416660\n",
      "epoch 110; iter: 0; batch classifier loss: 0.014852; batch adversarial loss: 0.419849\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040191; batch adversarial loss: 0.426057\n",
      "epoch 112; iter: 0; batch classifier loss: 0.011242; batch adversarial loss: 0.543606\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035326; batch adversarial loss: 0.416105\n",
      "epoch 114; iter: 0; batch classifier loss: 0.004924; batch adversarial loss: 0.536116\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022662; batch adversarial loss: 0.438368\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042255; batch adversarial loss: 0.431571\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046608; batch adversarial loss: 0.499991\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030327; batch adversarial loss: 0.460007\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059690; batch adversarial loss: 0.483422\n",
      "epoch 120; iter: 0; batch classifier loss: 0.060440; batch adversarial loss: 0.431707\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038532; batch adversarial loss: 0.424085\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036636; batch adversarial loss: 0.482350\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032504; batch adversarial loss: 0.466656\n",
      "epoch 124; iter: 0; batch classifier loss: 0.096165; batch adversarial loss: 0.430322\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033366; batch adversarial loss: 0.391396\n",
      "epoch 126; iter: 0; batch classifier loss: 0.018450; batch adversarial loss: 0.518169\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037542; batch adversarial loss: 0.475628\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032928; batch adversarial loss: 0.512736\n",
      "epoch 129; iter: 0; batch classifier loss: 0.072550; batch adversarial loss: 0.478942\n",
      "epoch 130; iter: 0; batch classifier loss: 0.013585; batch adversarial loss: 0.510194\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026429; batch adversarial loss: 0.320479\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021589; batch adversarial loss: 0.477999\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014120; batch adversarial loss: 0.453993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.042879; batch adversarial loss: 0.498961\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036334; batch adversarial loss: 0.352742\n",
      "epoch 136; iter: 0; batch classifier loss: 0.012112; batch adversarial loss: 0.414019\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035733; batch adversarial loss: 0.491587\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038929; batch adversarial loss: 0.461598\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023277; batch adversarial loss: 0.557226\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029233; batch adversarial loss: 0.510520\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030467; batch adversarial loss: 0.470446\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024257; batch adversarial loss: 0.456049\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026998; batch adversarial loss: 0.517020\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036109; batch adversarial loss: 0.349879\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034063; batch adversarial loss: 0.475194\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024696; batch adversarial loss: 0.515774\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016205; batch adversarial loss: 0.413907\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018520; batch adversarial loss: 0.520649\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015001; batch adversarial loss: 0.455936\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038423; batch adversarial loss: 0.415022\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022602; batch adversarial loss: 0.428377\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017225; batch adversarial loss: 0.407567\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039556; batch adversarial loss: 0.459529\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023251; batch adversarial loss: 0.578324\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017028; batch adversarial loss: 0.426416\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026763; batch adversarial loss: 0.450258\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009193; batch adversarial loss: 0.588268\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020282; batch adversarial loss: 0.474960\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036490; batch adversarial loss: 0.462030\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027581; batch adversarial loss: 0.419247\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025226; batch adversarial loss: 0.482424\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014665; batch adversarial loss: 0.450190\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021991; batch adversarial loss: 0.443670\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023645; batch adversarial loss: 0.401046\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011281; batch adversarial loss: 0.463013\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014638; batch adversarial loss: 0.372673\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023198; batch adversarial loss: 0.512888\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014160; batch adversarial loss: 0.465333\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012923; batch adversarial loss: 0.374937\n",
      "epoch 170; iter: 0; batch classifier loss: 0.006647; batch adversarial loss: 0.517319\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011891; batch adversarial loss: 0.494475\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013153; batch adversarial loss: 0.530006\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009099; batch adversarial loss: 0.492696\n",
      "epoch 174; iter: 0; batch classifier loss: 0.044914; batch adversarial loss: 0.438396\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033324; batch adversarial loss: 0.455241\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019030; batch adversarial loss: 0.467815\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006202; batch adversarial loss: 0.410548\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006701; batch adversarial loss: 0.498042\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016820; batch adversarial loss: 0.511646\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032701; batch adversarial loss: 0.462568\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021381; batch adversarial loss: 0.405620\n",
      "epoch 182; iter: 0; batch classifier loss: 0.039037; batch adversarial loss: 0.475506\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017633; batch adversarial loss: 0.546774\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011667; batch adversarial loss: 0.436204\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014575; batch adversarial loss: 0.446575\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009373; batch adversarial loss: 0.474759\n",
      "epoch 187; iter: 0; batch classifier loss: 0.003657; batch adversarial loss: 0.397197\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014296; batch adversarial loss: 0.542392\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018712; batch adversarial loss: 0.462801\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011214; batch adversarial loss: 0.413009\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023062; batch adversarial loss: 0.397223\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006632; batch adversarial loss: 0.393915\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013663; batch adversarial loss: 0.496857\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026612; batch adversarial loss: 0.472094\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022149; batch adversarial loss: 0.432079\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017796; batch adversarial loss: 0.405842\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023054; batch adversarial loss: 0.487984\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019882; batch adversarial loss: 0.475247\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018743; batch adversarial loss: 0.411532\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707062; batch adversarial loss: 0.687245\n",
      "epoch 1; iter: 0; batch classifier loss: 0.460433; batch adversarial loss: 0.646930\n",
      "epoch 2; iter: 0; batch classifier loss: 0.429208; batch adversarial loss: 0.584604\n",
      "epoch 3; iter: 0; batch classifier loss: 0.353073; batch adversarial loss: 0.556772\n",
      "epoch 4; iter: 0; batch classifier loss: 0.364577; batch adversarial loss: 0.590624\n",
      "epoch 5; iter: 0; batch classifier loss: 0.405135; batch adversarial loss: 0.588423\n",
      "epoch 6; iter: 0; batch classifier loss: 0.329013; batch adversarial loss: 0.540078\n",
      "epoch 7; iter: 0; batch classifier loss: 0.347395; batch adversarial loss: 0.520899\n",
      "epoch 8; iter: 0; batch classifier loss: 0.255066; batch adversarial loss: 0.606068\n",
      "epoch 9; iter: 0; batch classifier loss: 0.318236; batch adversarial loss: 0.520404\n",
      "epoch 10; iter: 0; batch classifier loss: 0.262646; batch adversarial loss: 0.528767\n",
      "epoch 11; iter: 0; batch classifier loss: 0.279325; batch adversarial loss: 0.454034\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251313; batch adversarial loss: 0.517473\n",
      "epoch 13; iter: 0; batch classifier loss: 0.155630; batch adversarial loss: 0.505228\n",
      "epoch 14; iter: 0; batch classifier loss: 0.248565; batch adversarial loss: 0.525397\n",
      "epoch 15; iter: 0; batch classifier loss: 0.152060; batch adversarial loss: 0.532258\n",
      "epoch 16; iter: 0; batch classifier loss: 0.312228; batch adversarial loss: 0.457128\n",
      "epoch 17; iter: 0; batch classifier loss: 0.211171; batch adversarial loss: 0.519333\n",
      "epoch 18; iter: 0; batch classifier loss: 0.175347; batch adversarial loss: 0.441493\n",
      "epoch 19; iter: 0; batch classifier loss: 0.225369; batch adversarial loss: 0.451446\n",
      "epoch 20; iter: 0; batch classifier loss: 0.211560; batch adversarial loss: 0.491948\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149468; batch adversarial loss: 0.490670\n",
      "epoch 22; iter: 0; batch classifier loss: 0.148141; batch adversarial loss: 0.541049\n",
      "epoch 23; iter: 0; batch classifier loss: 0.148171; batch adversarial loss: 0.464012\n",
      "epoch 24; iter: 0; batch classifier loss: 0.187150; batch adversarial loss: 0.528244\n",
      "epoch 25; iter: 0; batch classifier loss: 0.163513; batch adversarial loss: 0.437222\n",
      "epoch 26; iter: 0; batch classifier loss: 0.127942; batch adversarial loss: 0.500365\n",
      "epoch 27; iter: 0; batch classifier loss: 0.172199; batch adversarial loss: 0.417974\n",
      "epoch 28; iter: 0; batch classifier loss: 0.169201; batch adversarial loss: 0.505181\n",
      "epoch 29; iter: 0; batch classifier loss: 0.121994; batch adversarial loss: 0.413030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.169255; batch adversarial loss: 0.556933\n",
      "epoch 31; iter: 0; batch classifier loss: 0.148201; batch adversarial loss: 0.474457\n",
      "epoch 32; iter: 0; batch classifier loss: 0.110646; batch adversarial loss: 0.433721\n",
      "epoch 33; iter: 0; batch classifier loss: 0.093854; batch adversarial loss: 0.493921\n",
      "epoch 34; iter: 0; batch classifier loss: 0.118629; batch adversarial loss: 0.501583\n",
      "epoch 35; iter: 0; batch classifier loss: 0.107693; batch adversarial loss: 0.429524\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102200; batch adversarial loss: 0.482845\n",
      "epoch 37; iter: 0; batch classifier loss: 0.116994; batch adversarial loss: 0.505790\n",
      "epoch 38; iter: 0; batch classifier loss: 0.128086; batch adversarial loss: 0.478562\n",
      "epoch 39; iter: 0; batch classifier loss: 0.128786; batch adversarial loss: 0.415299\n",
      "epoch 40; iter: 0; batch classifier loss: 0.077451; batch adversarial loss: 0.438598\n",
      "epoch 41; iter: 0; batch classifier loss: 0.185462; batch adversarial loss: 0.442952\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103388; batch adversarial loss: 0.461898\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089409; batch adversarial loss: 0.444628\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118397; batch adversarial loss: 0.400474\n",
      "epoch 45; iter: 0; batch classifier loss: 0.127829; batch adversarial loss: 0.453369\n",
      "epoch 46; iter: 0; batch classifier loss: 0.105535; batch adversarial loss: 0.439612\n",
      "epoch 47; iter: 0; batch classifier loss: 0.120760; batch adversarial loss: 0.494085\n",
      "epoch 48; iter: 0; batch classifier loss: 0.135878; batch adversarial loss: 0.423483\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114200; batch adversarial loss: 0.619412\n",
      "epoch 50; iter: 0; batch classifier loss: 0.144461; batch adversarial loss: 0.447015\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109515; batch adversarial loss: 0.405842\n",
      "epoch 52; iter: 0; batch classifier loss: 0.076535; batch adversarial loss: 0.534951\n",
      "epoch 53; iter: 0; batch classifier loss: 0.125015; batch adversarial loss: 0.466093\n",
      "epoch 54; iter: 0; batch classifier loss: 0.129056; batch adversarial loss: 0.499143\n",
      "epoch 55; iter: 0; batch classifier loss: 0.080742; batch adversarial loss: 0.470488\n",
      "epoch 56; iter: 0; batch classifier loss: 0.140067; batch adversarial loss: 0.408383\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112615; batch adversarial loss: 0.556185\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080619; batch adversarial loss: 0.376943\n",
      "epoch 59; iter: 0; batch classifier loss: 0.055504; batch adversarial loss: 0.502048\n",
      "epoch 60; iter: 0; batch classifier loss: 0.108735; batch adversarial loss: 0.512785\n",
      "epoch 61; iter: 0; batch classifier loss: 0.083675; batch adversarial loss: 0.467376\n",
      "epoch 62; iter: 0; batch classifier loss: 0.073951; batch adversarial loss: 0.498579\n",
      "epoch 63; iter: 0; batch classifier loss: 0.124235; batch adversarial loss: 0.369908\n",
      "epoch 64; iter: 0; batch classifier loss: 0.100969; batch adversarial loss: 0.376771\n",
      "epoch 65; iter: 0; batch classifier loss: 0.076408; batch adversarial loss: 0.395780\n",
      "epoch 66; iter: 0; batch classifier loss: 0.070854; batch adversarial loss: 0.530279\n",
      "epoch 67; iter: 0; batch classifier loss: 0.093125; batch adversarial loss: 0.517979\n",
      "epoch 68; iter: 0; batch classifier loss: 0.089964; batch adversarial loss: 0.476870\n",
      "epoch 69; iter: 0; batch classifier loss: 0.083620; batch adversarial loss: 0.600059\n",
      "epoch 70; iter: 0; batch classifier loss: 0.057875; batch adversarial loss: 0.447286\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079993; batch adversarial loss: 0.450187\n",
      "epoch 72; iter: 0; batch classifier loss: 0.075562; batch adversarial loss: 0.501049\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101895; batch adversarial loss: 0.468197\n",
      "epoch 74; iter: 0; batch classifier loss: 0.060372; batch adversarial loss: 0.363435\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077219; batch adversarial loss: 0.577303\n",
      "epoch 76; iter: 0; batch classifier loss: 0.074008; batch adversarial loss: 0.524274\n",
      "epoch 77; iter: 0; batch classifier loss: 0.107416; batch adversarial loss: 0.391282\n",
      "epoch 78; iter: 0; batch classifier loss: 0.058042; batch adversarial loss: 0.456826\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065815; batch adversarial loss: 0.408899\n",
      "epoch 80; iter: 0; batch classifier loss: 0.053556; batch adversarial loss: 0.440449\n",
      "epoch 81; iter: 0; batch classifier loss: 0.112958; batch adversarial loss: 0.533619\n",
      "epoch 82; iter: 0; batch classifier loss: 0.058559; batch adversarial loss: 0.569348\n",
      "epoch 83; iter: 0; batch classifier loss: 0.034092; batch adversarial loss: 0.519724\n",
      "epoch 84; iter: 0; batch classifier loss: 0.044254; batch adversarial loss: 0.480154\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070721; batch adversarial loss: 0.473318\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069576; batch adversarial loss: 0.424929\n",
      "epoch 87; iter: 0; batch classifier loss: 0.083664; batch adversarial loss: 0.471223\n",
      "epoch 88; iter: 0; batch classifier loss: 0.048865; batch adversarial loss: 0.405030\n",
      "epoch 89; iter: 0; batch classifier loss: 0.055386; batch adversarial loss: 0.481165\n",
      "epoch 90; iter: 0; batch classifier loss: 0.034182; batch adversarial loss: 0.425824\n",
      "epoch 91; iter: 0; batch classifier loss: 0.086587; batch adversarial loss: 0.457148\n",
      "epoch 92; iter: 0; batch classifier loss: 0.059233; batch adversarial loss: 0.445391\n",
      "epoch 93; iter: 0; batch classifier loss: 0.045461; batch adversarial loss: 0.487085\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061992; batch adversarial loss: 0.503217\n",
      "epoch 95; iter: 0; batch classifier loss: 0.032116; batch adversarial loss: 0.515002\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064846; batch adversarial loss: 0.455330\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066912; batch adversarial loss: 0.435398\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050015; batch adversarial loss: 0.483162\n",
      "epoch 99; iter: 0; batch classifier loss: 0.036654; batch adversarial loss: 0.487315\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062780; batch adversarial loss: 0.469747\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075065; batch adversarial loss: 0.410654\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060302; batch adversarial loss: 0.384315\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041345; batch adversarial loss: 0.542662\n",
      "epoch 104; iter: 0; batch classifier loss: 0.028573; batch adversarial loss: 0.478175\n",
      "epoch 105; iter: 0; batch classifier loss: 0.033408; batch adversarial loss: 0.484147\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031544; batch adversarial loss: 0.482980\n",
      "epoch 107; iter: 0; batch classifier loss: 0.017297; batch adversarial loss: 0.432616\n",
      "epoch 108; iter: 0; batch classifier loss: 0.068055; batch adversarial loss: 0.409345\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050784; batch adversarial loss: 0.436439\n",
      "epoch 110; iter: 0; batch classifier loss: 0.055336; batch adversarial loss: 0.317947\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045363; batch adversarial loss: 0.424720\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041495; batch adversarial loss: 0.498133\n",
      "epoch 113; iter: 0; batch classifier loss: 0.026779; batch adversarial loss: 0.426364\n",
      "epoch 114; iter: 0; batch classifier loss: 0.020730; batch adversarial loss: 0.377661\n",
      "epoch 115; iter: 0; batch classifier loss: 0.077164; batch adversarial loss: 0.569457\n",
      "epoch 116; iter: 0; batch classifier loss: 0.031387; batch adversarial loss: 0.482978\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037252; batch adversarial loss: 0.455362\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048522; batch adversarial loss: 0.497714\n",
      "epoch 119; iter: 0; batch classifier loss: 0.019865; batch adversarial loss: 0.521617\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042835; batch adversarial loss: 0.471012\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034530; batch adversarial loss: 0.460624\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029953; batch adversarial loss: 0.355911\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034080; batch adversarial loss: 0.472887\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026337; batch adversarial loss: 0.493977\n",
      "epoch 125; iter: 0; batch classifier loss: 0.016776; batch adversarial loss: 0.490104\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030615; batch adversarial loss: 0.440153\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033355; batch adversarial loss: 0.488323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.059242; batch adversarial loss: 0.462214\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021604; batch adversarial loss: 0.487682\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037065; batch adversarial loss: 0.420635\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022921; batch adversarial loss: 0.462624\n",
      "epoch 132; iter: 0; batch classifier loss: 0.075328; batch adversarial loss: 0.470876\n",
      "epoch 133; iter: 0; batch classifier loss: 0.009976; batch adversarial loss: 0.459945\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050560; batch adversarial loss: 0.469720\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036638; batch adversarial loss: 0.491668\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023927; batch adversarial loss: 0.502754\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043258; batch adversarial loss: 0.496039\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019972; batch adversarial loss: 0.381984\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021803; batch adversarial loss: 0.438433\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017107; batch adversarial loss: 0.459836\n",
      "epoch 141; iter: 0; batch classifier loss: 0.013999; batch adversarial loss: 0.432019\n",
      "epoch 142; iter: 0; batch classifier loss: 0.011003; batch adversarial loss: 0.501477\n",
      "epoch 143; iter: 0; batch classifier loss: 0.067412; batch adversarial loss: 0.419490\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022946; batch adversarial loss: 0.440730\n",
      "epoch 145; iter: 0; batch classifier loss: 0.054768; batch adversarial loss: 0.471600\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016126; batch adversarial loss: 0.473064\n",
      "epoch 147; iter: 0; batch classifier loss: 0.057704; batch adversarial loss: 0.471710\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036308; batch adversarial loss: 0.546194\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024364; batch adversarial loss: 0.412214\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018616; batch adversarial loss: 0.434352\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016168; batch adversarial loss: 0.451961\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028571; batch adversarial loss: 0.534576\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014538; batch adversarial loss: 0.490365\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011233; batch adversarial loss: 0.414352\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038839; batch adversarial loss: 0.456354\n",
      "epoch 156; iter: 0; batch classifier loss: 0.048978; batch adversarial loss: 0.471729\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012829; batch adversarial loss: 0.398248\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023008; batch adversarial loss: 0.447134\n",
      "epoch 159; iter: 0; batch classifier loss: 0.057011; batch adversarial loss: 0.418373\n",
      "epoch 160; iter: 0; batch classifier loss: 0.038898; batch adversarial loss: 0.416025\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023142; batch adversarial loss: 0.349060\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009825; batch adversarial loss: 0.454786\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024148; batch adversarial loss: 0.484392\n",
      "epoch 164; iter: 0; batch classifier loss: 0.048681; batch adversarial loss: 0.501263\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014608; batch adversarial loss: 0.557384\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015207; batch adversarial loss: 0.410588\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033582; batch adversarial loss: 0.449163\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026798; batch adversarial loss: 0.450207\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030241; batch adversarial loss: 0.409553\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013630; batch adversarial loss: 0.442743\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007465; batch adversarial loss: 0.487970\n",
      "epoch 172; iter: 0; batch classifier loss: 0.003748; batch adversarial loss: 0.394573\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010723; batch adversarial loss: 0.489933\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026895; batch adversarial loss: 0.376682\n",
      "epoch 175; iter: 0; batch classifier loss: 0.004157; batch adversarial loss: 0.444148\n",
      "epoch 176; iter: 0; batch classifier loss: 0.042716; batch adversarial loss: 0.498519\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018701; batch adversarial loss: 0.407887\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029955; batch adversarial loss: 0.451327\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009782; batch adversarial loss: 0.470883\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020637; batch adversarial loss: 0.402665\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027874; batch adversarial loss: 0.427355\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021234; batch adversarial loss: 0.394618\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019018; batch adversarial loss: 0.497700\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006459; batch adversarial loss: 0.398212\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014170; batch adversarial loss: 0.422994\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026645; batch adversarial loss: 0.398102\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007761; batch adversarial loss: 0.525318\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017758; batch adversarial loss: 0.529141\n",
      "epoch 189; iter: 0; batch classifier loss: 0.037845; batch adversarial loss: 0.433602\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004681; batch adversarial loss: 0.364497\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013718; batch adversarial loss: 0.449526\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009957; batch adversarial loss: 0.489719\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009654; batch adversarial loss: 0.505071\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027727; batch adversarial loss: 0.466082\n",
      "epoch 195; iter: 0; batch classifier loss: 0.066391; batch adversarial loss: 0.460266\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008934; batch adversarial loss: 0.518194\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017075; batch adversarial loss: 0.433950\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028348; batch adversarial loss: 0.430235\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017712; batch adversarial loss: 0.552472\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713040; batch adversarial loss: 0.628424\n",
      "epoch 1; iter: 0; batch classifier loss: 0.416801; batch adversarial loss: 0.643364\n",
      "epoch 2; iter: 0; batch classifier loss: 0.378350; batch adversarial loss: 0.603682\n",
      "epoch 3; iter: 0; batch classifier loss: 0.398911; batch adversarial loss: 0.591025\n",
      "epoch 4; iter: 0; batch classifier loss: 0.310628; batch adversarial loss: 0.608088\n",
      "epoch 5; iter: 0; batch classifier loss: 0.320305; batch adversarial loss: 0.594408\n",
      "epoch 6; iter: 0; batch classifier loss: 0.370400; batch adversarial loss: 0.570106\n",
      "epoch 7; iter: 0; batch classifier loss: 0.512407; batch adversarial loss: 0.546622\n",
      "epoch 8; iter: 0; batch classifier loss: 0.499583; batch adversarial loss: 0.563659\n",
      "epoch 9; iter: 0; batch classifier loss: 0.700057; batch adversarial loss: 0.619862\n",
      "epoch 10; iter: 0; batch classifier loss: 0.514889; batch adversarial loss: 0.557256\n",
      "epoch 11; iter: 0; batch classifier loss: 0.407071; batch adversarial loss: 0.515652\n",
      "epoch 12; iter: 0; batch classifier loss: 0.328472; batch adversarial loss: 0.539127\n",
      "epoch 13; iter: 0; batch classifier loss: 0.351108; batch adversarial loss: 0.546067\n",
      "epoch 14; iter: 0; batch classifier loss: 0.286551; batch adversarial loss: 0.511280\n",
      "epoch 15; iter: 0; batch classifier loss: 0.229380; batch adversarial loss: 0.540653\n",
      "epoch 16; iter: 0; batch classifier loss: 0.224159; batch adversarial loss: 0.592247\n",
      "epoch 17; iter: 0; batch classifier loss: 0.259467; batch adversarial loss: 0.452944\n",
      "epoch 18; iter: 0; batch classifier loss: 0.298326; batch adversarial loss: 0.451943\n",
      "epoch 19; iter: 0; batch classifier loss: 0.250140; batch adversarial loss: 0.484200\n",
      "epoch 20; iter: 0; batch classifier loss: 0.278120; batch adversarial loss: 0.397067\n",
      "epoch 21; iter: 0; batch classifier loss: 0.226374; batch adversarial loss: 0.388147\n",
      "epoch 22; iter: 0; batch classifier loss: 0.173503; batch adversarial loss: 0.459916\n",
      "epoch 23; iter: 0; batch classifier loss: 0.154000; batch adversarial loss: 0.484278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.213833; batch adversarial loss: 0.377463\n",
      "epoch 25; iter: 0; batch classifier loss: 0.161350; batch adversarial loss: 0.529476\n",
      "epoch 26; iter: 0; batch classifier loss: 0.151339; batch adversarial loss: 0.515336\n",
      "epoch 27; iter: 0; batch classifier loss: 0.140600; batch adversarial loss: 0.521606\n",
      "epoch 28; iter: 0; batch classifier loss: 0.179308; batch adversarial loss: 0.445830\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170254; batch adversarial loss: 0.450607\n",
      "epoch 30; iter: 0; batch classifier loss: 0.142518; batch adversarial loss: 0.431354\n",
      "epoch 31; iter: 0; batch classifier loss: 0.170482; batch adversarial loss: 0.493953\n",
      "epoch 32; iter: 0; batch classifier loss: 0.107105; batch adversarial loss: 0.394083\n",
      "epoch 33; iter: 0; batch classifier loss: 0.141836; batch adversarial loss: 0.380231\n",
      "epoch 34; iter: 0; batch classifier loss: 0.115359; batch adversarial loss: 0.454688\n",
      "epoch 35; iter: 0; batch classifier loss: 0.098374; batch adversarial loss: 0.472840\n",
      "epoch 36; iter: 0; batch classifier loss: 0.166160; batch adversarial loss: 0.404332\n",
      "epoch 37; iter: 0; batch classifier loss: 0.203338; batch adversarial loss: 0.448752\n",
      "epoch 38; iter: 0; batch classifier loss: 0.108625; batch adversarial loss: 0.499949\n",
      "epoch 39; iter: 0; batch classifier loss: 0.170634; batch adversarial loss: 0.510753\n",
      "epoch 40; iter: 0; batch classifier loss: 0.183017; batch adversarial loss: 0.485893\n",
      "epoch 41; iter: 0; batch classifier loss: 0.108576; batch adversarial loss: 0.458765\n",
      "epoch 42; iter: 0; batch classifier loss: 0.120816; batch adversarial loss: 0.481139\n",
      "epoch 43; iter: 0; batch classifier loss: 0.158008; batch adversarial loss: 0.514938\n",
      "epoch 44; iter: 0; batch classifier loss: 0.133255; batch adversarial loss: 0.517571\n",
      "epoch 45; iter: 0; batch classifier loss: 0.088207; batch adversarial loss: 0.535225\n",
      "epoch 46; iter: 0; batch classifier loss: 0.066992; batch adversarial loss: 0.502927\n",
      "epoch 47; iter: 0; batch classifier loss: 0.115568; batch adversarial loss: 0.549921\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125136; batch adversarial loss: 0.404362\n",
      "epoch 49; iter: 0; batch classifier loss: 0.097228; batch adversarial loss: 0.356703\n",
      "epoch 50; iter: 0; batch classifier loss: 0.168710; batch adversarial loss: 0.395942\n",
      "epoch 51; iter: 0; batch classifier loss: 0.157201; batch adversarial loss: 0.423245\n",
      "epoch 52; iter: 0; batch classifier loss: 0.109817; batch adversarial loss: 0.475612\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088991; batch adversarial loss: 0.471097\n",
      "epoch 54; iter: 0; batch classifier loss: 0.092169; batch adversarial loss: 0.426729\n",
      "epoch 55; iter: 0; batch classifier loss: 0.080310; batch adversarial loss: 0.563539\n",
      "epoch 56; iter: 0; batch classifier loss: 0.140828; batch adversarial loss: 0.369919\n",
      "epoch 57; iter: 0; batch classifier loss: 0.121199; batch adversarial loss: 0.390428\n",
      "epoch 58; iter: 0; batch classifier loss: 0.114373; batch adversarial loss: 0.465193\n",
      "epoch 59; iter: 0; batch classifier loss: 0.089634; batch adversarial loss: 0.403091\n",
      "epoch 60; iter: 0; batch classifier loss: 0.134649; batch adversarial loss: 0.462503\n",
      "epoch 61; iter: 0; batch classifier loss: 0.141932; batch adversarial loss: 0.516797\n",
      "epoch 62; iter: 0; batch classifier loss: 0.096969; batch adversarial loss: 0.552907\n",
      "epoch 63; iter: 0; batch classifier loss: 0.141691; batch adversarial loss: 0.536113\n",
      "epoch 64; iter: 0; batch classifier loss: 0.172876; batch adversarial loss: 0.351963\n",
      "epoch 65; iter: 0; batch classifier loss: 0.104197; batch adversarial loss: 0.421094\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088381; batch adversarial loss: 0.522884\n",
      "epoch 67; iter: 0; batch classifier loss: 0.119562; batch adversarial loss: 0.404449\n",
      "epoch 68; iter: 0; batch classifier loss: 0.069043; batch adversarial loss: 0.478517\n",
      "epoch 69; iter: 0; batch classifier loss: 0.157198; batch adversarial loss: 0.470470\n",
      "epoch 70; iter: 0; batch classifier loss: 0.150801; batch adversarial loss: 0.484634\n",
      "epoch 71; iter: 0; batch classifier loss: 0.125547; batch adversarial loss: 0.449482\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062896; batch adversarial loss: 0.467933\n",
      "epoch 73; iter: 0; batch classifier loss: 0.112830; batch adversarial loss: 0.427951\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079562; batch adversarial loss: 0.529460\n",
      "epoch 75; iter: 0; batch classifier loss: 0.102183; batch adversarial loss: 0.502874\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082083; batch adversarial loss: 0.486000\n",
      "epoch 77; iter: 0; batch classifier loss: 0.099211; batch adversarial loss: 0.479288\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080717; batch adversarial loss: 0.480415\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060228; batch adversarial loss: 0.390098\n",
      "epoch 80; iter: 0; batch classifier loss: 0.080362; batch adversarial loss: 0.506245\n",
      "epoch 81; iter: 0; batch classifier loss: 0.070192; batch adversarial loss: 0.373802\n",
      "epoch 82; iter: 0; batch classifier loss: 0.086181; batch adversarial loss: 0.491715\n",
      "epoch 83; iter: 0; batch classifier loss: 0.075599; batch adversarial loss: 0.421875\n",
      "epoch 84; iter: 0; batch classifier loss: 0.058104; batch adversarial loss: 0.469604\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074951; batch adversarial loss: 0.574718\n",
      "epoch 86; iter: 0; batch classifier loss: 0.094334; batch adversarial loss: 0.396941\n",
      "epoch 87; iter: 0; batch classifier loss: 0.094559; batch adversarial loss: 0.543596\n",
      "epoch 88; iter: 0; batch classifier loss: 0.085972; batch adversarial loss: 0.426576\n",
      "epoch 89; iter: 0; batch classifier loss: 0.078356; batch adversarial loss: 0.493148\n",
      "epoch 90; iter: 0; batch classifier loss: 0.095011; batch adversarial loss: 0.489913\n",
      "epoch 91; iter: 0; batch classifier loss: 0.096878; batch adversarial loss: 0.392137\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057890; batch adversarial loss: 0.423173\n",
      "epoch 93; iter: 0; batch classifier loss: 0.093346; batch adversarial loss: 0.545885\n",
      "epoch 94; iter: 0; batch classifier loss: 0.069091; batch adversarial loss: 0.437413\n",
      "epoch 95; iter: 0; batch classifier loss: 0.039690; batch adversarial loss: 0.390496\n",
      "epoch 96; iter: 0; batch classifier loss: 0.071177; batch adversarial loss: 0.414523\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063508; batch adversarial loss: 0.487696\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062682; batch adversarial loss: 0.429908\n",
      "epoch 99; iter: 0; batch classifier loss: 0.076500; batch adversarial loss: 0.403549\n",
      "epoch 100; iter: 0; batch classifier loss: 0.078715; batch adversarial loss: 0.442441\n",
      "epoch 101; iter: 0; batch classifier loss: 0.052459; batch adversarial loss: 0.421308\n",
      "epoch 102; iter: 0; batch classifier loss: 0.080780; batch adversarial loss: 0.475792\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063642; batch adversarial loss: 0.433669\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044104; batch adversarial loss: 0.458526\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042280; batch adversarial loss: 0.456653\n",
      "epoch 106; iter: 0; batch classifier loss: 0.069711; batch adversarial loss: 0.556762\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058701; batch adversarial loss: 0.490392\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039949; batch adversarial loss: 0.395967\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049262; batch adversarial loss: 0.496999\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050890; batch adversarial loss: 0.498116\n",
      "epoch 111; iter: 0; batch classifier loss: 0.016907; batch adversarial loss: 0.438741\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033066; batch adversarial loss: 0.333925\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045357; batch adversarial loss: 0.491501\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046310; batch adversarial loss: 0.387894\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039851; batch adversarial loss: 0.399170\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043110; batch adversarial loss: 0.441234\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045461; batch adversarial loss: 0.485467\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024512; batch adversarial loss: 0.362227\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046802; batch adversarial loss: 0.429927\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062219; batch adversarial loss: 0.544763\n",
      "epoch 121; iter: 0; batch classifier loss: 0.056958; batch adversarial loss: 0.485932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.034879; batch adversarial loss: 0.404587\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040792; batch adversarial loss: 0.515772\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048069; batch adversarial loss: 0.503687\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031837; batch adversarial loss: 0.495613\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019659; batch adversarial loss: 0.452620\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034042; batch adversarial loss: 0.441000\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054106; batch adversarial loss: 0.444840\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027844; batch adversarial loss: 0.453337\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017744; batch adversarial loss: 0.501093\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018969; batch adversarial loss: 0.376796\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034444; batch adversarial loss: 0.382038\n",
      "epoch 133; iter: 0; batch classifier loss: 0.055445; batch adversarial loss: 0.366333\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023754; batch adversarial loss: 0.529570\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012621; batch adversarial loss: 0.498199\n",
      "epoch 136; iter: 0; batch classifier loss: 0.052425; batch adversarial loss: 0.441052\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037499; batch adversarial loss: 0.476163\n",
      "epoch 138; iter: 0; batch classifier loss: 0.055298; batch adversarial loss: 0.442277\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036584; batch adversarial loss: 0.586173\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028173; batch adversarial loss: 0.472356\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031551; batch adversarial loss: 0.465647\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031903; batch adversarial loss: 0.430479\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021601; batch adversarial loss: 0.463086\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017400; batch adversarial loss: 0.410528\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031569; batch adversarial loss: 0.423135\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026574; batch adversarial loss: 0.434593\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014840; batch adversarial loss: 0.508168\n",
      "epoch 148; iter: 0; batch classifier loss: 0.041969; batch adversarial loss: 0.405947\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019245; batch adversarial loss: 0.444306\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035474; batch adversarial loss: 0.484727\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023784; batch adversarial loss: 0.424535\n",
      "epoch 152; iter: 0; batch classifier loss: 0.052535; batch adversarial loss: 0.445660\n",
      "epoch 153; iter: 0; batch classifier loss: 0.009233; batch adversarial loss: 0.440458\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015283; batch adversarial loss: 0.496865\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023794; batch adversarial loss: 0.530613\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032905; batch adversarial loss: 0.520101\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022980; batch adversarial loss: 0.450463\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029317; batch adversarial loss: 0.412804\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010878; batch adversarial loss: 0.441879\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016790; batch adversarial loss: 0.412378\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010745; batch adversarial loss: 0.329132\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029292; batch adversarial loss: 0.510054\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028443; batch adversarial loss: 0.520215\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016319; batch adversarial loss: 0.472015\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024450; batch adversarial loss: 0.389364\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024958; batch adversarial loss: 0.296878\n",
      "epoch 167; iter: 0; batch classifier loss: 0.057884; batch adversarial loss: 0.398921\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008692; batch adversarial loss: 0.524724\n",
      "epoch 169; iter: 0; batch classifier loss: 0.053892; batch adversarial loss: 0.456267\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022503; batch adversarial loss: 0.435327\n",
      "epoch 171; iter: 0; batch classifier loss: 0.060724; batch adversarial loss: 0.465657\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027823; batch adversarial loss: 0.360329\n",
      "epoch 173; iter: 0; batch classifier loss: 0.050714; batch adversarial loss: 0.480082\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021346; batch adversarial loss: 0.440734\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011688; batch adversarial loss: 0.376699\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019741; batch adversarial loss: 0.452989\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013538; batch adversarial loss: 0.503973\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028160; batch adversarial loss: 0.470567\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020212; batch adversarial loss: 0.505542\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017634; batch adversarial loss: 0.443812\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017839; batch adversarial loss: 0.535745\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018831; batch adversarial loss: 0.383144\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013973; batch adversarial loss: 0.480420\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006217; batch adversarial loss: 0.470558\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018347; batch adversarial loss: 0.479019\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012140; batch adversarial loss: 0.422350\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020914; batch adversarial loss: 0.512868\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011830; batch adversarial loss: 0.473998\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021302; batch adversarial loss: 0.511071\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029311; batch adversarial loss: 0.413448\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012279; batch adversarial loss: 0.395139\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037745; batch adversarial loss: 0.395531\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007102; batch adversarial loss: 0.435615\n",
      "epoch 194; iter: 0; batch classifier loss: 0.053815; batch adversarial loss: 0.440059\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006300; batch adversarial loss: 0.440551\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018227; batch adversarial loss: 0.380192\n",
      "epoch 197; iter: 0; batch classifier loss: 0.037516; batch adversarial loss: 0.410008\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010800; batch adversarial loss: 0.459072\n",
      "epoch 199; iter: 0; batch classifier loss: 0.029702; batch adversarial loss: 0.453935\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678718; batch adversarial loss: 0.625215\n",
      "epoch 1; iter: 0; batch classifier loss: 0.400381; batch adversarial loss: 0.617638\n",
      "epoch 2; iter: 0; batch classifier loss: 0.421375; batch adversarial loss: 0.607651\n",
      "epoch 3; iter: 0; batch classifier loss: 0.422179; batch adversarial loss: 0.597013\n",
      "epoch 4; iter: 0; batch classifier loss: 0.407820; batch adversarial loss: 0.588847\n",
      "epoch 5; iter: 0; batch classifier loss: 0.353495; batch adversarial loss: 0.592329\n",
      "epoch 6; iter: 0; batch classifier loss: 0.432690; batch adversarial loss: 0.639887\n",
      "epoch 7; iter: 0; batch classifier loss: 0.501457; batch adversarial loss: 0.599855\n",
      "epoch 8; iter: 0; batch classifier loss: 0.579727; batch adversarial loss: 0.560767\n",
      "epoch 9; iter: 0; batch classifier loss: 0.610393; batch adversarial loss: 0.571627\n",
      "epoch 10; iter: 0; batch classifier loss: 0.375535; batch adversarial loss: 0.560547\n",
      "epoch 11; iter: 0; batch classifier loss: 0.395220; batch adversarial loss: 0.515622\n",
      "epoch 12; iter: 0; batch classifier loss: 0.325899; batch adversarial loss: 0.538909\n",
      "epoch 13; iter: 0; batch classifier loss: 0.269487; batch adversarial loss: 0.530181\n",
      "epoch 14; iter: 0; batch classifier loss: 0.249827; batch adversarial loss: 0.446291\n",
      "epoch 15; iter: 0; batch classifier loss: 0.212989; batch adversarial loss: 0.494945\n",
      "epoch 16; iter: 0; batch classifier loss: 0.341091; batch adversarial loss: 0.489652\n",
      "epoch 17; iter: 0; batch classifier loss: 0.237423; batch adversarial loss: 0.501959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.283313; batch adversarial loss: 0.515641\n",
      "epoch 19; iter: 0; batch classifier loss: 0.217114; batch adversarial loss: 0.415816\n",
      "epoch 20; iter: 0; batch classifier loss: 0.214626; batch adversarial loss: 0.478017\n",
      "epoch 21; iter: 0; batch classifier loss: 0.227334; batch adversarial loss: 0.464229\n",
      "epoch 22; iter: 0; batch classifier loss: 0.219704; batch adversarial loss: 0.471930\n",
      "epoch 23; iter: 0; batch classifier loss: 0.155738; batch adversarial loss: 0.425248\n",
      "epoch 24; iter: 0; batch classifier loss: 0.190860; batch adversarial loss: 0.491067\n",
      "epoch 25; iter: 0; batch classifier loss: 0.153832; batch adversarial loss: 0.433447\n",
      "epoch 26; iter: 0; batch classifier loss: 0.189181; batch adversarial loss: 0.488839\n",
      "epoch 27; iter: 0; batch classifier loss: 0.222831; batch adversarial loss: 0.477154\n",
      "epoch 28; iter: 0; batch classifier loss: 0.172301; batch adversarial loss: 0.425355\n",
      "epoch 29; iter: 0; batch classifier loss: 0.164769; batch adversarial loss: 0.402742\n",
      "epoch 30; iter: 0; batch classifier loss: 0.103595; batch adversarial loss: 0.554791\n",
      "epoch 31; iter: 0; batch classifier loss: 0.122130; batch adversarial loss: 0.451310\n",
      "epoch 32; iter: 0; batch classifier loss: 0.097693; batch adversarial loss: 0.462612\n",
      "epoch 33; iter: 0; batch classifier loss: 0.109604; batch adversarial loss: 0.559930\n",
      "epoch 34; iter: 0; batch classifier loss: 0.192465; batch adversarial loss: 0.475829\n",
      "epoch 35; iter: 0; batch classifier loss: 0.159986; batch adversarial loss: 0.452840\n",
      "epoch 36; iter: 0; batch classifier loss: 0.219855; batch adversarial loss: 0.429324\n",
      "epoch 37; iter: 0; batch classifier loss: 0.074131; batch adversarial loss: 0.433361\n",
      "epoch 38; iter: 0; batch classifier loss: 0.108933; batch adversarial loss: 0.490149\n",
      "epoch 39; iter: 0; batch classifier loss: 0.088514; batch adversarial loss: 0.436151\n",
      "epoch 40; iter: 0; batch classifier loss: 0.129157; batch adversarial loss: 0.368487\n",
      "epoch 41; iter: 0; batch classifier loss: 0.110263; batch adversarial loss: 0.520374\n",
      "epoch 42; iter: 0; batch classifier loss: 0.129618; batch adversarial loss: 0.357944\n",
      "epoch 43; iter: 0; batch classifier loss: 0.073371; batch adversarial loss: 0.362193\n",
      "epoch 44; iter: 0; batch classifier loss: 0.131122; batch adversarial loss: 0.474770\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089367; batch adversarial loss: 0.425179\n",
      "epoch 46; iter: 0; batch classifier loss: 0.114196; batch adversarial loss: 0.514423\n",
      "epoch 47; iter: 0; batch classifier loss: 0.149136; batch adversarial loss: 0.507500\n",
      "epoch 48; iter: 0; batch classifier loss: 0.093174; batch adversarial loss: 0.502066\n",
      "epoch 49; iter: 0; batch classifier loss: 0.126314; batch adversarial loss: 0.483234\n",
      "epoch 50; iter: 0; batch classifier loss: 0.105844; batch adversarial loss: 0.438442\n",
      "epoch 51; iter: 0; batch classifier loss: 0.125830; batch adversarial loss: 0.431481\n",
      "epoch 52; iter: 0; batch classifier loss: 0.084007; batch adversarial loss: 0.470077\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096954; batch adversarial loss: 0.481766\n",
      "epoch 54; iter: 0; batch classifier loss: 0.128130; batch adversarial loss: 0.473172\n",
      "epoch 55; iter: 0; batch classifier loss: 0.069537; batch adversarial loss: 0.347873\n",
      "epoch 56; iter: 0; batch classifier loss: 0.147874; batch adversarial loss: 0.444936\n",
      "epoch 57; iter: 0; batch classifier loss: 0.108157; batch adversarial loss: 0.415630\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080866; batch adversarial loss: 0.465689\n",
      "epoch 59; iter: 0; batch classifier loss: 0.097430; batch adversarial loss: 0.431409\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086127; batch adversarial loss: 0.522676\n",
      "epoch 61; iter: 0; batch classifier loss: 0.069278; batch adversarial loss: 0.516092\n",
      "epoch 62; iter: 0; batch classifier loss: 0.119409; batch adversarial loss: 0.556158\n",
      "epoch 63; iter: 0; batch classifier loss: 0.090814; batch adversarial loss: 0.462080\n",
      "epoch 64; iter: 0; batch classifier loss: 0.097325; batch adversarial loss: 0.432637\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079692; batch adversarial loss: 0.503018\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073429; batch adversarial loss: 0.392348\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073918; batch adversarial loss: 0.458421\n",
      "epoch 68; iter: 0; batch classifier loss: 0.119185; batch adversarial loss: 0.448390\n",
      "epoch 69; iter: 0; batch classifier loss: 0.083071; batch adversarial loss: 0.472867\n",
      "epoch 70; iter: 0; batch classifier loss: 0.086756; batch adversarial loss: 0.475487\n",
      "epoch 71; iter: 0; batch classifier loss: 0.088423; batch adversarial loss: 0.406177\n",
      "epoch 72; iter: 0; batch classifier loss: 0.046435; batch adversarial loss: 0.458926\n",
      "epoch 73; iter: 0; batch classifier loss: 0.057822; batch adversarial loss: 0.500781\n",
      "epoch 74; iter: 0; batch classifier loss: 0.044473; batch adversarial loss: 0.453921\n",
      "epoch 75; iter: 0; batch classifier loss: 0.038259; batch adversarial loss: 0.540700\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064418; batch adversarial loss: 0.446292\n",
      "epoch 77; iter: 0; batch classifier loss: 0.043552; batch adversarial loss: 0.400322\n",
      "epoch 78; iter: 0; batch classifier loss: 0.063971; batch adversarial loss: 0.473576\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068501; batch adversarial loss: 0.561966\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067581; batch adversarial loss: 0.417179\n",
      "epoch 81; iter: 0; batch classifier loss: 0.111920; batch adversarial loss: 0.397347\n",
      "epoch 82; iter: 0; batch classifier loss: 0.057405; batch adversarial loss: 0.376462\n",
      "epoch 83; iter: 0; batch classifier loss: 0.031005; batch adversarial loss: 0.455744\n",
      "epoch 84; iter: 0; batch classifier loss: 0.047318; batch adversarial loss: 0.505731\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067296; batch adversarial loss: 0.458964\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081391; batch adversarial loss: 0.432507\n",
      "epoch 87; iter: 0; batch classifier loss: 0.041089; batch adversarial loss: 0.559228\n",
      "epoch 88; iter: 0; batch classifier loss: 0.104784; batch adversarial loss: 0.362072\n",
      "epoch 89; iter: 0; batch classifier loss: 0.086904; batch adversarial loss: 0.424262\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065493; batch adversarial loss: 0.349799\n",
      "epoch 91; iter: 0; batch classifier loss: 0.049932; batch adversarial loss: 0.399162\n",
      "epoch 92; iter: 0; batch classifier loss: 0.049534; batch adversarial loss: 0.465655\n",
      "epoch 93; iter: 0; batch classifier loss: 0.049373; batch adversarial loss: 0.455366\n",
      "epoch 94; iter: 0; batch classifier loss: 0.064947; batch adversarial loss: 0.489528\n",
      "epoch 95; iter: 0; batch classifier loss: 0.059740; batch adversarial loss: 0.357775\n",
      "epoch 96; iter: 0; batch classifier loss: 0.053376; batch adversarial loss: 0.399603\n",
      "epoch 97; iter: 0; batch classifier loss: 0.028043; batch adversarial loss: 0.462731\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035392; batch adversarial loss: 0.452931\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050442; batch adversarial loss: 0.441084\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062251; batch adversarial loss: 0.483919\n",
      "epoch 101; iter: 0; batch classifier loss: 0.025755; batch adversarial loss: 0.377497\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050010; batch adversarial loss: 0.436176\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064356; batch adversarial loss: 0.471365\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043010; batch adversarial loss: 0.456220\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030932; batch adversarial loss: 0.380728\n",
      "epoch 106; iter: 0; batch classifier loss: 0.056222; batch adversarial loss: 0.386521\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048522; batch adversarial loss: 0.463982\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036162; batch adversarial loss: 0.437354\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027693; batch adversarial loss: 0.588687\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059906; batch adversarial loss: 0.483817\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036079; batch adversarial loss: 0.396925\n",
      "epoch 112; iter: 0; batch classifier loss: 0.029507; batch adversarial loss: 0.518462\n",
      "epoch 113; iter: 0; batch classifier loss: 0.020531; batch adversarial loss: 0.488313\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043770; batch adversarial loss: 0.415246\n",
      "epoch 115; iter: 0; batch classifier loss: 0.064605; batch adversarial loss: 0.431611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.093423; batch adversarial loss: 0.430397\n",
      "epoch 117; iter: 0; batch classifier loss: 0.059163; batch adversarial loss: 0.463910\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040668; batch adversarial loss: 0.459139\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048653; batch adversarial loss: 0.384162\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046087; batch adversarial loss: 0.434136\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037816; batch adversarial loss: 0.533093\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028090; batch adversarial loss: 0.539929\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051725; batch adversarial loss: 0.503713\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020365; batch adversarial loss: 0.495581\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036682; batch adversarial loss: 0.417288\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027746; batch adversarial loss: 0.442494\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044240; batch adversarial loss: 0.416623\n",
      "epoch 128; iter: 0; batch classifier loss: 0.046761; batch adversarial loss: 0.483343\n",
      "epoch 129; iter: 0; batch classifier loss: 0.011839; batch adversarial loss: 0.495159\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044595; batch adversarial loss: 0.318353\n",
      "epoch 131; iter: 0; batch classifier loss: 0.058702; batch adversarial loss: 0.527975\n",
      "epoch 132; iter: 0; batch classifier loss: 0.072628; batch adversarial loss: 0.464979\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043044; batch adversarial loss: 0.384059\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025997; batch adversarial loss: 0.480914\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011618; batch adversarial loss: 0.475378\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028988; batch adversarial loss: 0.464398\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029257; batch adversarial loss: 0.554784\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031409; batch adversarial loss: 0.545159\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037200; batch adversarial loss: 0.492253\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018411; batch adversarial loss: 0.417080\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025045; batch adversarial loss: 0.429534\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036993; batch adversarial loss: 0.435996\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027994; batch adversarial loss: 0.555645\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034500; batch adversarial loss: 0.455374\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018113; batch adversarial loss: 0.411416\n",
      "epoch 146; iter: 0; batch classifier loss: 0.006388; batch adversarial loss: 0.499269\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016052; batch adversarial loss: 0.441986\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026616; batch adversarial loss: 0.505851\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035121; batch adversarial loss: 0.461605\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015254; batch adversarial loss: 0.387737\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035800; batch adversarial loss: 0.528730\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011611; batch adversarial loss: 0.543527\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039649; batch adversarial loss: 0.457463\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012014; batch adversarial loss: 0.506997\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014867; batch adversarial loss: 0.438643\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033686; batch adversarial loss: 0.480210\n",
      "epoch 157; iter: 0; batch classifier loss: 0.048347; batch adversarial loss: 0.429214\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010216; batch adversarial loss: 0.384055\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025099; batch adversarial loss: 0.478509\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035464; batch adversarial loss: 0.465030\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007806; batch adversarial loss: 0.552595\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030848; batch adversarial loss: 0.446324\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021667; batch adversarial loss: 0.556411\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014626; batch adversarial loss: 0.482036\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016344; batch adversarial loss: 0.418171\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017840; batch adversarial loss: 0.522912\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028799; batch adversarial loss: 0.458621\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024245; batch adversarial loss: 0.405627\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029191; batch adversarial loss: 0.473157\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017093; batch adversarial loss: 0.467183\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007613; batch adversarial loss: 0.485048\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008160; batch adversarial loss: 0.499053\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032594; batch adversarial loss: 0.271521\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013230; batch adversarial loss: 0.414299\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019712; batch adversarial loss: 0.378301\n",
      "epoch 176; iter: 0; batch classifier loss: 0.004261; batch adversarial loss: 0.499517\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015778; batch adversarial loss: 0.447914\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010184; batch adversarial loss: 0.355471\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006266; batch adversarial loss: 0.488513\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014979; batch adversarial loss: 0.490226\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013375; batch adversarial loss: 0.483573\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024899; batch adversarial loss: 0.399264\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018001; batch adversarial loss: 0.369621\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012609; batch adversarial loss: 0.400652\n",
      "epoch 185; iter: 0; batch classifier loss: 0.054649; batch adversarial loss: 0.460677\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019516; batch adversarial loss: 0.538083\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014596; batch adversarial loss: 0.488611\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014045; batch adversarial loss: 0.457197\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012956; batch adversarial loss: 0.519897\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022044; batch adversarial loss: 0.484327\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034405; batch adversarial loss: 0.417423\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016490; batch adversarial loss: 0.391618\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008646; batch adversarial loss: 0.496439\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023919; batch adversarial loss: 0.544826\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016640; batch adversarial loss: 0.446228\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008461; batch adversarial loss: 0.508807\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016519; batch adversarial loss: 0.400253\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011839; batch adversarial loss: 0.510954\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012554; batch adversarial loss: 0.482961\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693232; batch adversarial loss: 0.763716\n",
      "epoch 1; iter: 0; batch classifier loss: 0.422745; batch adversarial loss: 0.737104\n",
      "epoch 2; iter: 0; batch classifier loss: 0.387253; batch adversarial loss: 0.691884\n",
      "epoch 3; iter: 0; batch classifier loss: 0.412434; batch adversarial loss: 0.644738\n",
      "epoch 4; iter: 0; batch classifier loss: 0.419055; batch adversarial loss: 0.630092\n",
      "epoch 5; iter: 0; batch classifier loss: 0.330774; batch adversarial loss: 0.624971\n",
      "epoch 6; iter: 0; batch classifier loss: 0.299680; batch adversarial loss: 0.569857\n",
      "epoch 7; iter: 0; batch classifier loss: 0.327882; batch adversarial loss: 0.549253\n",
      "epoch 8; iter: 0; batch classifier loss: 0.336267; batch adversarial loss: 0.527154\n",
      "epoch 9; iter: 0; batch classifier loss: 0.292633; batch adversarial loss: 0.502155\n",
      "epoch 10; iter: 0; batch classifier loss: 0.283011; batch adversarial loss: 0.472949\n",
      "epoch 11; iter: 0; batch classifier loss: 0.218127; batch adversarial loss: 0.484623\n",
      "epoch 12; iter: 0; batch classifier loss: 0.250037; batch adversarial loss: 0.471899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13; iter: 0; batch classifier loss: 0.213591; batch adversarial loss: 0.418023\n",
      "epoch 14; iter: 0; batch classifier loss: 0.177513; batch adversarial loss: 0.444074\n",
      "epoch 15; iter: 0; batch classifier loss: 0.235098; batch adversarial loss: 0.435787\n",
      "epoch 16; iter: 0; batch classifier loss: 0.166071; batch adversarial loss: 0.512870\n",
      "epoch 17; iter: 0; batch classifier loss: 0.168217; batch adversarial loss: 0.435560\n",
      "epoch 18; iter: 0; batch classifier loss: 0.196730; batch adversarial loss: 0.405355\n",
      "epoch 19; iter: 0; batch classifier loss: 0.189981; batch adversarial loss: 0.423013\n",
      "epoch 20; iter: 0; batch classifier loss: 0.244758; batch adversarial loss: 0.477403\n",
      "epoch 21; iter: 0; batch classifier loss: 0.201524; batch adversarial loss: 0.425961\n",
      "epoch 22; iter: 0; batch classifier loss: 0.132408; batch adversarial loss: 0.363981\n",
      "epoch 23; iter: 0; batch classifier loss: 0.153438; batch adversarial loss: 0.450922\n",
      "epoch 24; iter: 0; batch classifier loss: 0.140995; batch adversarial loss: 0.451699\n",
      "epoch 25; iter: 0; batch classifier loss: 0.246393; batch adversarial loss: 0.442584\n",
      "epoch 26; iter: 0; batch classifier loss: 0.167195; batch adversarial loss: 0.367434\n",
      "epoch 27; iter: 0; batch classifier loss: 0.258469; batch adversarial loss: 0.441379\n",
      "epoch 28; iter: 0; batch classifier loss: 0.159274; batch adversarial loss: 0.345919\n",
      "epoch 29; iter: 0; batch classifier loss: 0.175559; batch adversarial loss: 0.478345\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153135; batch adversarial loss: 0.440594\n",
      "epoch 31; iter: 0; batch classifier loss: 0.110297; batch adversarial loss: 0.400307\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140962; batch adversarial loss: 0.368183\n",
      "epoch 33; iter: 0; batch classifier loss: 0.118680; batch adversarial loss: 0.450999\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122541; batch adversarial loss: 0.410016\n",
      "epoch 35; iter: 0; batch classifier loss: 0.199061; batch adversarial loss: 0.379139\n",
      "epoch 36; iter: 0; batch classifier loss: 0.163658; batch adversarial loss: 0.301375\n",
      "epoch 37; iter: 0; batch classifier loss: 0.084154; batch adversarial loss: 0.395146\n",
      "epoch 38; iter: 0; batch classifier loss: 0.153874; batch adversarial loss: 0.447859\n",
      "epoch 39; iter: 0; batch classifier loss: 0.094236; batch adversarial loss: 0.459305\n",
      "epoch 40; iter: 0; batch classifier loss: 0.128825; batch adversarial loss: 0.458676\n",
      "epoch 41; iter: 0; batch classifier loss: 0.103990; batch adversarial loss: 0.422312\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146706; batch adversarial loss: 0.490596\n",
      "epoch 43; iter: 0; batch classifier loss: 0.111401; batch adversarial loss: 0.348292\n",
      "epoch 44; iter: 0; batch classifier loss: 0.171930; batch adversarial loss: 0.381703\n",
      "epoch 45; iter: 0; batch classifier loss: 0.112019; batch adversarial loss: 0.466822\n",
      "epoch 46; iter: 0; batch classifier loss: 0.115332; batch adversarial loss: 0.440731\n",
      "epoch 47; iter: 0; batch classifier loss: 0.110836; batch adversarial loss: 0.390916\n",
      "epoch 48; iter: 0; batch classifier loss: 0.095041; batch adversarial loss: 0.457623\n",
      "epoch 49; iter: 0; batch classifier loss: 0.103092; batch adversarial loss: 0.482639\n",
      "epoch 50; iter: 0; batch classifier loss: 0.114817; batch adversarial loss: 0.453989\n",
      "epoch 51; iter: 0; batch classifier loss: 0.089425; batch adversarial loss: 0.385531\n",
      "epoch 52; iter: 0; batch classifier loss: 0.064874; batch adversarial loss: 0.418973\n",
      "epoch 53; iter: 0; batch classifier loss: 0.085390; batch adversarial loss: 0.447510\n",
      "epoch 54; iter: 0; batch classifier loss: 0.068355; batch adversarial loss: 0.473071\n",
      "epoch 55; iter: 0; batch classifier loss: 0.123180; batch adversarial loss: 0.491381\n",
      "epoch 56; iter: 0; batch classifier loss: 0.073262; batch adversarial loss: 0.444004\n",
      "epoch 57; iter: 0; batch classifier loss: 0.078405; batch adversarial loss: 0.381460\n",
      "epoch 58; iter: 0; batch classifier loss: 0.110468; batch adversarial loss: 0.541859\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090470; batch adversarial loss: 0.538188\n",
      "epoch 60; iter: 0; batch classifier loss: 0.104392; batch adversarial loss: 0.450311\n",
      "epoch 61; iter: 0; batch classifier loss: 0.089161; batch adversarial loss: 0.420830\n",
      "epoch 62; iter: 0; batch classifier loss: 0.105568; batch adversarial loss: 0.427710\n",
      "epoch 63; iter: 0; batch classifier loss: 0.057260; batch adversarial loss: 0.341406\n",
      "epoch 64; iter: 0; batch classifier loss: 0.145815; batch adversarial loss: 0.463928\n",
      "epoch 65; iter: 0; batch classifier loss: 0.095637; batch adversarial loss: 0.388347\n",
      "epoch 66; iter: 0; batch classifier loss: 0.067355; batch adversarial loss: 0.456380\n",
      "epoch 67; iter: 0; batch classifier loss: 0.088170; batch adversarial loss: 0.378524\n",
      "epoch 68; iter: 0; batch classifier loss: 0.112054; batch adversarial loss: 0.439295\n",
      "epoch 69; iter: 0; batch classifier loss: 0.100036; batch adversarial loss: 0.396302\n",
      "epoch 70; iter: 0; batch classifier loss: 0.054413; batch adversarial loss: 0.470689\n",
      "epoch 71; iter: 0; batch classifier loss: 0.072659; batch adversarial loss: 0.422565\n",
      "epoch 72; iter: 0; batch classifier loss: 0.070607; batch adversarial loss: 0.487683\n",
      "epoch 73; iter: 0; batch classifier loss: 0.124585; batch adversarial loss: 0.482089\n",
      "epoch 74; iter: 0; batch classifier loss: 0.051943; batch adversarial loss: 0.423347\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061902; batch adversarial loss: 0.378174\n",
      "epoch 76; iter: 0; batch classifier loss: 0.108427; batch adversarial loss: 0.474565\n",
      "epoch 77; iter: 0; batch classifier loss: 0.093221; batch adversarial loss: 0.428033\n",
      "epoch 78; iter: 0; batch classifier loss: 0.047892; batch adversarial loss: 0.408958\n",
      "epoch 79; iter: 0; batch classifier loss: 0.123492; batch adversarial loss: 0.420361\n",
      "epoch 80; iter: 0; batch classifier loss: 0.097499; batch adversarial loss: 0.434276\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064465; batch adversarial loss: 0.420274\n",
      "epoch 82; iter: 0; batch classifier loss: 0.094558; batch adversarial loss: 0.535678\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062352; batch adversarial loss: 0.356433\n",
      "epoch 84; iter: 0; batch classifier loss: 0.091725; batch adversarial loss: 0.523467\n",
      "epoch 85; iter: 0; batch classifier loss: 0.087929; batch adversarial loss: 0.406473\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068236; batch adversarial loss: 0.405006\n",
      "epoch 87; iter: 0; batch classifier loss: 0.064923; batch adversarial loss: 0.354402\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067530; batch adversarial loss: 0.402315\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054336; batch adversarial loss: 0.385118\n",
      "epoch 90; iter: 0; batch classifier loss: 0.038286; batch adversarial loss: 0.417404\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064650; batch adversarial loss: 0.454806\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063019; batch adversarial loss: 0.318138\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077233; batch adversarial loss: 0.478890\n",
      "epoch 94; iter: 0; batch classifier loss: 0.063232; batch adversarial loss: 0.409386\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077734; batch adversarial loss: 0.449029\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066280; batch adversarial loss: 0.374811\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050932; batch adversarial loss: 0.406584\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061697; batch adversarial loss: 0.446486\n",
      "epoch 99; iter: 0; batch classifier loss: 0.060885; batch adversarial loss: 0.449005\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044660; batch adversarial loss: 0.456272\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083056; batch adversarial loss: 0.461612\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059043; batch adversarial loss: 0.428173\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063476; batch adversarial loss: 0.450390\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045679; batch adversarial loss: 0.429452\n",
      "epoch 105; iter: 0; batch classifier loss: 0.068359; batch adversarial loss: 0.420120\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047186; batch adversarial loss: 0.391114\n",
      "epoch 107; iter: 0; batch classifier loss: 0.087314; batch adversarial loss: 0.389518\n",
      "epoch 108; iter: 0; batch classifier loss: 0.054642; batch adversarial loss: 0.432610\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057638; batch adversarial loss: 0.429571\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052236; batch adversarial loss: 0.456507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.054874; batch adversarial loss: 0.421428\n",
      "epoch 112; iter: 0; batch classifier loss: 0.048607; batch adversarial loss: 0.464163\n",
      "epoch 113; iter: 0; batch classifier loss: 0.103528; batch adversarial loss: 0.456090\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056568; batch adversarial loss: 0.455303\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048817; batch adversarial loss: 0.405014\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034140; batch adversarial loss: 0.409612\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056661; batch adversarial loss: 0.486410\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040587; batch adversarial loss: 0.436914\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057210; batch adversarial loss: 0.340298\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036759; batch adversarial loss: 0.308496\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054018; batch adversarial loss: 0.419953\n",
      "epoch 122; iter: 0; batch classifier loss: 0.060210; batch adversarial loss: 0.432875\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037741; batch adversarial loss: 0.586857\n",
      "epoch 124; iter: 0; batch classifier loss: 0.084323; batch adversarial loss: 0.465504\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036964; batch adversarial loss: 0.397023\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055072; batch adversarial loss: 0.396409\n",
      "epoch 127; iter: 0; batch classifier loss: 0.058381; batch adversarial loss: 0.455701\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027078; batch adversarial loss: 0.457079\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027491; batch adversarial loss: 0.460320\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032631; batch adversarial loss: 0.367660\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045514; batch adversarial loss: 0.482949\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037766; batch adversarial loss: 0.418305\n",
      "epoch 133; iter: 0; batch classifier loss: 0.059843; batch adversarial loss: 0.505233\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029677; batch adversarial loss: 0.550680\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032419; batch adversarial loss: 0.515165\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033712; batch adversarial loss: 0.569064\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024987; batch adversarial loss: 0.406956\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024331; batch adversarial loss: 0.400270\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032517; batch adversarial loss: 0.496767\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034296; batch adversarial loss: 0.371095\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030914; batch adversarial loss: 0.479965\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043678; batch adversarial loss: 0.479306\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027822; batch adversarial loss: 0.443185\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030387; batch adversarial loss: 0.528135\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026196; batch adversarial loss: 0.439476\n",
      "epoch 146; iter: 0; batch classifier loss: 0.055072; batch adversarial loss: 0.497321\n",
      "epoch 147; iter: 0; batch classifier loss: 0.051521; batch adversarial loss: 0.400996\n",
      "epoch 148; iter: 0; batch classifier loss: 0.071994; batch adversarial loss: 0.581571\n",
      "epoch 149; iter: 0; batch classifier loss: 0.083289; batch adversarial loss: 0.548888\n",
      "epoch 150; iter: 0; batch classifier loss: 0.137573; batch adversarial loss: 0.578388\n",
      "epoch 151; iter: 0; batch classifier loss: 0.112763; batch adversarial loss: 0.567096\n",
      "epoch 152; iter: 0; batch classifier loss: 0.103811; batch adversarial loss: 0.587887\n",
      "epoch 153; iter: 0; batch classifier loss: 0.185055; batch adversarial loss: 0.704111\n",
      "epoch 154; iter: 0; batch classifier loss: 0.139086; batch adversarial loss: 0.616203\n",
      "epoch 155; iter: 0; batch classifier loss: 0.130313; batch adversarial loss: 0.652241\n",
      "epoch 156; iter: 0; batch classifier loss: 0.106434; batch adversarial loss: 0.618721\n",
      "epoch 157; iter: 0; batch classifier loss: 0.146834; batch adversarial loss: 0.664379\n",
      "epoch 158; iter: 0; batch classifier loss: 0.193429; batch adversarial loss: 0.754976\n",
      "epoch 159; iter: 0; batch classifier loss: 0.240738; batch adversarial loss: 0.781815\n",
      "epoch 160; iter: 0; batch classifier loss: 0.137460; batch adversarial loss: 0.510913\n",
      "epoch 161; iter: 0; batch classifier loss: 0.193946; batch adversarial loss: 0.693950\n",
      "epoch 162; iter: 0; batch classifier loss: 0.231012; batch adversarial loss: 0.794948\n",
      "epoch 163; iter: 0; batch classifier loss: 0.133261; batch adversarial loss: 0.556845\n",
      "epoch 164; iter: 0; batch classifier loss: 0.232466; batch adversarial loss: 0.683934\n",
      "epoch 165; iter: 0; batch classifier loss: 0.166056; batch adversarial loss: 0.552917\n",
      "epoch 166; iter: 0; batch classifier loss: 0.182363; batch adversarial loss: 0.658855\n",
      "epoch 167; iter: 0; batch classifier loss: 0.108929; batch adversarial loss: 0.579479\n",
      "epoch 168; iter: 0; batch classifier loss: 0.225292; batch adversarial loss: 0.694942\n",
      "epoch 169; iter: 0; batch classifier loss: 0.168007; batch adversarial loss: 0.640638\n",
      "epoch 170; iter: 0; batch classifier loss: 0.147309; batch adversarial loss: 0.618607\n",
      "epoch 171; iter: 0; batch classifier loss: 0.147192; batch adversarial loss: 0.594757\n",
      "epoch 172; iter: 0; batch classifier loss: 0.159369; batch adversarial loss: 0.544007\n",
      "epoch 173; iter: 0; batch classifier loss: 0.169474; batch adversarial loss: 0.709889\n",
      "epoch 174; iter: 0; batch classifier loss: 0.183940; batch adversarial loss: 0.630556\n",
      "epoch 175; iter: 0; batch classifier loss: 0.144891; batch adversarial loss: 0.541331\n",
      "epoch 176; iter: 0; batch classifier loss: 0.224529; batch adversarial loss: 0.674254\n",
      "epoch 177; iter: 0; batch classifier loss: 0.182406; batch adversarial loss: 0.581636\n",
      "epoch 178; iter: 0; batch classifier loss: 0.184879; batch adversarial loss: 0.552008\n",
      "epoch 179; iter: 0; batch classifier loss: 0.105126; batch adversarial loss: 0.505649\n",
      "epoch 180; iter: 0; batch classifier loss: 0.147887; batch adversarial loss: 0.539469\n",
      "epoch 181; iter: 0; batch classifier loss: 0.130463; batch adversarial loss: 0.516571\n",
      "epoch 182; iter: 0; batch classifier loss: 0.060389; batch adversarial loss: 0.424399\n",
      "epoch 183; iter: 0; batch classifier loss: 0.142604; batch adversarial loss: 0.540953\n",
      "epoch 184; iter: 0; batch classifier loss: 0.184067; batch adversarial loss: 0.539721\n",
      "epoch 185; iter: 0; batch classifier loss: 0.213326; batch adversarial loss: 0.608672\n",
      "epoch 186; iter: 0; batch classifier loss: 0.123510; batch adversarial loss: 0.452543\n",
      "epoch 187; iter: 0; batch classifier loss: 0.216662; batch adversarial loss: 0.652154\n",
      "epoch 188; iter: 0; batch classifier loss: 0.158445; batch adversarial loss: 0.551992\n",
      "epoch 189; iter: 0; batch classifier loss: 0.128187; batch adversarial loss: 0.394343\n",
      "epoch 190; iter: 0; batch classifier loss: 0.178868; batch adversarial loss: 0.581874\n",
      "epoch 191; iter: 0; batch classifier loss: 0.154326; batch adversarial loss: 0.510651\n",
      "epoch 192; iter: 0; batch classifier loss: 0.130857; batch adversarial loss: 0.542284\n",
      "epoch 193; iter: 0; batch classifier loss: 0.161719; batch adversarial loss: 0.545049\n",
      "epoch 194; iter: 0; batch classifier loss: 0.150465; batch adversarial loss: 0.474161\n",
      "epoch 195; iter: 0; batch classifier loss: 0.084967; batch adversarial loss: 0.454621\n",
      "epoch 196; iter: 0; batch classifier loss: 0.123691; batch adversarial loss: 0.380405\n",
      "epoch 197; iter: 0; batch classifier loss: 0.129098; batch adversarial loss: 0.391851\n",
      "epoch 198; iter: 0; batch classifier loss: 0.114101; batch adversarial loss: 0.461437\n",
      "epoch 199; iter: 0; batch classifier loss: 0.148772; batch adversarial loss: 0.457969\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684402; batch adversarial loss: 0.702136\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433155; batch adversarial loss: 0.667031\n",
      "epoch 2; iter: 0; batch classifier loss: 0.353318; batch adversarial loss: 0.626811\n",
      "epoch 3; iter: 0; batch classifier loss: 0.364865; batch adversarial loss: 0.603484\n",
      "epoch 4; iter: 0; batch classifier loss: 0.296398; batch adversarial loss: 0.561606\n",
      "epoch 5; iter: 0; batch classifier loss: 0.212087; batch adversarial loss: 0.531607\n",
      "epoch 6; iter: 0; batch classifier loss: 0.305698; batch adversarial loss: 0.538584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7; iter: 0; batch classifier loss: 0.279096; batch adversarial loss: 0.500773\n",
      "epoch 8; iter: 0; batch classifier loss: 0.277841; batch adversarial loss: 0.540735\n",
      "epoch 9; iter: 0; batch classifier loss: 0.261247; batch adversarial loss: 0.525126\n",
      "epoch 10; iter: 0; batch classifier loss: 0.253796; batch adversarial loss: 0.564630\n",
      "epoch 11; iter: 0; batch classifier loss: 0.279680; batch adversarial loss: 0.463360\n",
      "epoch 12; iter: 0; batch classifier loss: 0.261699; batch adversarial loss: 0.528540\n",
      "epoch 13; iter: 0; batch classifier loss: 0.328002; batch adversarial loss: 0.578750\n",
      "epoch 14; iter: 0; batch classifier loss: 0.391962; batch adversarial loss: 0.507846\n",
      "epoch 15; iter: 0; batch classifier loss: 0.562011; batch adversarial loss: 0.510275\n",
      "epoch 16; iter: 0; batch classifier loss: 0.536220; batch adversarial loss: 0.566428\n",
      "epoch 17; iter: 0; batch classifier loss: 0.347286; batch adversarial loss: 0.477092\n",
      "epoch 18; iter: 0; batch classifier loss: 0.238007; batch adversarial loss: 0.526867\n",
      "epoch 19; iter: 0; batch classifier loss: 0.255943; batch adversarial loss: 0.488140\n",
      "epoch 20; iter: 0; batch classifier loss: 0.181126; batch adversarial loss: 0.448752\n",
      "epoch 21; iter: 0; batch classifier loss: 0.240756; batch adversarial loss: 0.470289\n",
      "epoch 22; iter: 0; batch classifier loss: 0.164146; batch adversarial loss: 0.492028\n",
      "epoch 23; iter: 0; batch classifier loss: 0.209703; batch adversarial loss: 0.470703\n",
      "epoch 24; iter: 0; batch classifier loss: 0.193736; batch adversarial loss: 0.410943\n",
      "epoch 25; iter: 0; batch classifier loss: 0.199959; batch adversarial loss: 0.529607\n",
      "epoch 26; iter: 0; batch classifier loss: 0.225905; batch adversarial loss: 0.463615\n",
      "epoch 27; iter: 0; batch classifier loss: 0.210483; batch adversarial loss: 0.474399\n",
      "epoch 28; iter: 0; batch classifier loss: 0.223640; batch adversarial loss: 0.486589\n",
      "epoch 29; iter: 0; batch classifier loss: 0.142197; batch adversarial loss: 0.425465\n",
      "epoch 30; iter: 0; batch classifier loss: 0.107001; batch adversarial loss: 0.489122\n",
      "epoch 31; iter: 0; batch classifier loss: 0.191318; batch adversarial loss: 0.405000\n",
      "epoch 32; iter: 0; batch classifier loss: 0.115852; batch adversarial loss: 0.430725\n",
      "epoch 33; iter: 0; batch classifier loss: 0.140622; batch adversarial loss: 0.496435\n",
      "epoch 34; iter: 0; batch classifier loss: 0.114716; batch adversarial loss: 0.518346\n",
      "epoch 35; iter: 0; batch classifier loss: 0.116878; batch adversarial loss: 0.516379\n",
      "epoch 36; iter: 0; batch classifier loss: 0.106630; batch adversarial loss: 0.464105\n",
      "epoch 37; iter: 0; batch classifier loss: 0.139157; batch adversarial loss: 0.439190\n",
      "epoch 38; iter: 0; batch classifier loss: 0.108452; batch adversarial loss: 0.505297\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126777; batch adversarial loss: 0.403204\n",
      "epoch 40; iter: 0; batch classifier loss: 0.088796; batch adversarial loss: 0.403046\n",
      "epoch 41; iter: 0; batch classifier loss: 0.093146; batch adversarial loss: 0.516785\n",
      "epoch 42; iter: 0; batch classifier loss: 0.163555; batch adversarial loss: 0.357683\n",
      "epoch 43; iter: 0; batch classifier loss: 0.139851; batch adversarial loss: 0.457989\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124380; batch adversarial loss: 0.418644\n",
      "epoch 45; iter: 0; batch classifier loss: 0.126925; batch adversarial loss: 0.500111\n",
      "epoch 46; iter: 0; batch classifier loss: 0.149668; batch adversarial loss: 0.406272\n",
      "epoch 47; iter: 0; batch classifier loss: 0.126313; batch adversarial loss: 0.445993\n",
      "epoch 48; iter: 0; batch classifier loss: 0.117566; batch adversarial loss: 0.508539\n",
      "epoch 49; iter: 0; batch classifier loss: 0.090010; batch adversarial loss: 0.362845\n",
      "epoch 50; iter: 0; batch classifier loss: 0.083286; batch adversarial loss: 0.445935\n",
      "epoch 51; iter: 0; batch classifier loss: 0.095540; batch adversarial loss: 0.387608\n",
      "epoch 52; iter: 0; batch classifier loss: 0.156646; batch adversarial loss: 0.364213\n",
      "epoch 53; iter: 0; batch classifier loss: 0.083646; batch adversarial loss: 0.467804\n",
      "epoch 54; iter: 0; batch classifier loss: 0.094622; batch adversarial loss: 0.434934\n",
      "epoch 55; iter: 0; batch classifier loss: 0.139978; batch adversarial loss: 0.488546\n",
      "epoch 56; iter: 0; batch classifier loss: 0.120416; batch adversarial loss: 0.416531\n",
      "epoch 57; iter: 0; batch classifier loss: 0.172078; batch adversarial loss: 0.420221\n",
      "epoch 58; iter: 0; batch classifier loss: 0.089719; batch adversarial loss: 0.435667\n",
      "epoch 59; iter: 0; batch classifier loss: 0.066484; batch adversarial loss: 0.433671\n",
      "epoch 60; iter: 0; batch classifier loss: 0.077583; batch adversarial loss: 0.464730\n",
      "epoch 61; iter: 0; batch classifier loss: 0.101335; batch adversarial loss: 0.452571\n",
      "epoch 62; iter: 0; batch classifier loss: 0.128006; batch adversarial loss: 0.513831\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092699; batch adversarial loss: 0.458533\n",
      "epoch 64; iter: 0; batch classifier loss: 0.142071; batch adversarial loss: 0.374354\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082277; batch adversarial loss: 0.477190\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075387; batch adversarial loss: 0.503270\n",
      "epoch 67; iter: 0; batch classifier loss: 0.091939; batch adversarial loss: 0.485717\n",
      "epoch 68; iter: 0; batch classifier loss: 0.122195; batch adversarial loss: 0.467017\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071300; batch adversarial loss: 0.489617\n",
      "epoch 70; iter: 0; batch classifier loss: 0.094361; batch adversarial loss: 0.491682\n",
      "epoch 71; iter: 0; batch classifier loss: 0.128152; batch adversarial loss: 0.384839\n",
      "epoch 72; iter: 0; batch classifier loss: 0.131810; batch adversarial loss: 0.570433\n",
      "epoch 73; iter: 0; batch classifier loss: 0.088016; batch adversarial loss: 0.468018\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081921; batch adversarial loss: 0.483213\n",
      "epoch 75; iter: 0; batch classifier loss: 0.070107; batch adversarial loss: 0.381374\n",
      "epoch 76; iter: 0; batch classifier loss: 0.126818; batch adversarial loss: 0.499979\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069447; batch adversarial loss: 0.558182\n",
      "epoch 78; iter: 0; batch classifier loss: 0.083848; batch adversarial loss: 0.541378\n",
      "epoch 79; iter: 0; batch classifier loss: 0.084728; batch adversarial loss: 0.425993\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078139; batch adversarial loss: 0.423205\n",
      "epoch 81; iter: 0; batch classifier loss: 0.094042; batch adversarial loss: 0.354927\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066170; batch adversarial loss: 0.324719\n",
      "epoch 83; iter: 0; batch classifier loss: 0.076474; batch adversarial loss: 0.501626\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085926; batch adversarial loss: 0.465428\n",
      "epoch 85; iter: 0; batch classifier loss: 0.066442; batch adversarial loss: 0.353080\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063792; batch adversarial loss: 0.445097\n",
      "epoch 87; iter: 0; batch classifier loss: 0.078424; batch adversarial loss: 0.457088\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073662; batch adversarial loss: 0.422768\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048966; batch adversarial loss: 0.478218\n",
      "epoch 90; iter: 0; batch classifier loss: 0.116286; batch adversarial loss: 0.387781\n",
      "epoch 91; iter: 0; batch classifier loss: 0.028008; batch adversarial loss: 0.522654\n",
      "epoch 92; iter: 0; batch classifier loss: 0.104452; batch adversarial loss: 0.403587\n",
      "epoch 93; iter: 0; batch classifier loss: 0.082561; batch adversarial loss: 0.585247\n",
      "epoch 94; iter: 0; batch classifier loss: 0.103681; batch adversarial loss: 0.407645\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060770; batch adversarial loss: 0.453330\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064913; batch adversarial loss: 0.504710\n",
      "epoch 97; iter: 0; batch classifier loss: 0.058536; batch adversarial loss: 0.446258\n",
      "epoch 98; iter: 0; batch classifier loss: 0.089230; batch adversarial loss: 0.440009\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044947; batch adversarial loss: 0.481514\n",
      "epoch 100; iter: 0; batch classifier loss: 0.030249; batch adversarial loss: 0.339892\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043029; batch adversarial loss: 0.377334\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071721; batch adversarial loss: 0.344523\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052269; batch adversarial loss: 0.470458\n",
      "epoch 104; iter: 0; batch classifier loss: 0.073369; batch adversarial loss: 0.468627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.077620; batch adversarial loss: 0.455458\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035554; batch adversarial loss: 0.385493\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053161; batch adversarial loss: 0.373681\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030769; batch adversarial loss: 0.367183\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032974; batch adversarial loss: 0.489356\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053937; batch adversarial loss: 0.412228\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036312; batch adversarial loss: 0.471563\n",
      "epoch 112; iter: 0; batch classifier loss: 0.048474; batch adversarial loss: 0.499401\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069312; batch adversarial loss: 0.403902\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048495; batch adversarial loss: 0.529543\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045197; batch adversarial loss: 0.483177\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035046; batch adversarial loss: 0.378859\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067280; batch adversarial loss: 0.408323\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043770; batch adversarial loss: 0.370784\n",
      "epoch 119; iter: 0; batch classifier loss: 0.062050; batch adversarial loss: 0.416804\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050329; batch adversarial loss: 0.435256\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057388; batch adversarial loss: 0.409706\n",
      "epoch 122; iter: 0; batch classifier loss: 0.065419; batch adversarial loss: 0.472714\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038476; batch adversarial loss: 0.425270\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026360; batch adversarial loss: 0.498650\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022184; batch adversarial loss: 0.448568\n",
      "epoch 126; iter: 0; batch classifier loss: 0.059955; batch adversarial loss: 0.484407\n",
      "epoch 127; iter: 0; batch classifier loss: 0.049303; batch adversarial loss: 0.417638\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044451; batch adversarial loss: 0.437872\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017895; batch adversarial loss: 0.551892\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032216; batch adversarial loss: 0.535177\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027655; batch adversarial loss: 0.432662\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057519; batch adversarial loss: 0.369811\n",
      "epoch 133; iter: 0; batch classifier loss: 0.078564; batch adversarial loss: 0.478395\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015379; batch adversarial loss: 0.475352\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027169; batch adversarial loss: 0.459928\n",
      "epoch 136; iter: 0; batch classifier loss: 0.045544; batch adversarial loss: 0.375696\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036399; batch adversarial loss: 0.512671\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023242; batch adversarial loss: 0.508725\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034919; batch adversarial loss: 0.388649\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022682; batch adversarial loss: 0.427393\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030413; batch adversarial loss: 0.427034\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025443; batch adversarial loss: 0.409324\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042482; batch adversarial loss: 0.446592\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041880; batch adversarial loss: 0.454479\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042165; batch adversarial loss: 0.385293\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019266; batch adversarial loss: 0.370163\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032478; batch adversarial loss: 0.409744\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017694; batch adversarial loss: 0.490593\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013504; batch adversarial loss: 0.444922\n",
      "epoch 150; iter: 0; batch classifier loss: 0.009815; batch adversarial loss: 0.472549\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039133; batch adversarial loss: 0.558403\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036377; batch adversarial loss: 0.409821\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023424; batch adversarial loss: 0.490911\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015062; batch adversarial loss: 0.371263\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030880; batch adversarial loss: 0.354057\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040784; batch adversarial loss: 0.443854\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018888; batch adversarial loss: 0.440434\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014643; batch adversarial loss: 0.437307\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021772; batch adversarial loss: 0.482998\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017904; batch adversarial loss: 0.505424\n",
      "epoch 161; iter: 0; batch classifier loss: 0.045885; batch adversarial loss: 0.489153\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014243; batch adversarial loss: 0.550825\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038274; batch adversarial loss: 0.418297\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026527; batch adversarial loss: 0.433556\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009333; batch adversarial loss: 0.460412\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038914; batch adversarial loss: 0.446298\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026532; batch adversarial loss: 0.434059\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038508; batch adversarial loss: 0.491824\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010848; batch adversarial loss: 0.505577\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021738; batch adversarial loss: 0.411834\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016326; batch adversarial loss: 0.454997\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012001; batch adversarial loss: 0.514045\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038434; batch adversarial loss: 0.476639\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010684; batch adversarial loss: 0.418828\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008296; batch adversarial loss: 0.500460\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012530; batch adversarial loss: 0.457511\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022192; batch adversarial loss: 0.431721\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016941; batch adversarial loss: 0.482408\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031331; batch adversarial loss: 0.557313\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015897; batch adversarial loss: 0.462895\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036368; batch adversarial loss: 0.472365\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010869; batch adversarial loss: 0.417498\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026903; batch adversarial loss: 0.452181\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013919; batch adversarial loss: 0.464355\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033400; batch adversarial loss: 0.400451\n",
      "epoch 186; iter: 0; batch classifier loss: 0.038122; batch adversarial loss: 0.400709\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015278; batch adversarial loss: 0.502880\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028663; batch adversarial loss: 0.468628\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027106; batch adversarial loss: 0.423359\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010327; batch adversarial loss: 0.411045\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007352; batch adversarial loss: 0.463490\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017462; batch adversarial loss: 0.366425\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022046; batch adversarial loss: 0.445431\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007020; batch adversarial loss: 0.379203\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016804; batch adversarial loss: 0.389776\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018105; batch adversarial loss: 0.438458\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026614; batch adversarial loss: 0.352323\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017390; batch adversarial loss: 0.472163\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011916; batch adversarial loss: 0.421132\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd461eec",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3683468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de3877ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:37.675129Z",
     "start_time": "2024-01-04T20:53:37.670178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 400,\n",
      " 'experiment_iteration': 'Exp_iter_4',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 400,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5b534568b14897b8686d22a9c79d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 400, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42164aebf0d74a5992f0ca8075639200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a128a0a62f40fb9bd0b88e41d55103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6300cf6db9cc4bcf95389b1f6e9b8108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e75feb8b5c4e00a1fc551544462dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d7042",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a5f9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eed713ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:27.080554Z",
     "start_time": "2024-01-04T20:53:27.072313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 500,\n",
      " 'experiment_iteration': 'Exp_iter_5',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 500,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8257cfd4f743e8887bbc74613694af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 500, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2d40e5f54c4d67bf9f1e66289ae23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63535df3c576469e9e855b70194bc572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15688b8597f74cdaadb60cc93599720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165f4884fae4f29829de3acc475dac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd04a2",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8900384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d82869bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:16.632770Z",
     "start_time": "2024-01-04T20:53:16.629083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 600,\n",
      " 'experiment_iteration': 'Exp_iter_6',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 600,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2670abffe30e4a388a7a09306feb6673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 600, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f28080438649c0aa4a0f71f4b322c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511b20dacfe5420981d3cf173f60fc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a989d937f483784b5138783479302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c5fe28a14a47118da3a7d485a77e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa1117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
