{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e10ece6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf71dbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:55:54.052462Z",
     "start_time": "2024-01-06T10:55:54.038357Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dfb010b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:56:09.679156Z",
     "start_time": "2024-01-06T10:56:09.668186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3052f22b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.457257Z",
     "start_time": "2024-01-06T11:15:26.114625Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43aab573",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.466361Z",
     "start_time": "2024-01-06T11:15:26.457627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aedbd54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.478005Z",
     "start_time": "2024-01-06T11:15:26.467253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/dh3553/projects/fairness-variance\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae75abd",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84c92d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.734704Z",
     "start_time": "2024-01-06T11:15:28.036691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import ACSIncomeDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_inprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45335c72",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f5f5d11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.772286Z",
     "start_time": "2024-01-06T11:15:31.735883Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'ADB_acs_income'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIRNESS_INTERVENTION_NAME = 'ADB'\n",
    "FAIR_INTERVENTION_PARAMS_LST = ['debiased_classifier']\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                     FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, 'folk_GA_2018_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a8b23c",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d46ec4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.813421Z",
     "start_time": "2024-01-06T11:15:31.771935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairness_variance'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a6f00de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.096974Z",
     "start_time": "2024-01-06T11:15:31.811395Z"
    }
   },
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "401d4b4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.138747Z",
     "start_time": "2024-01-06T11:15:32.097343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current session uuid:  bbba3cc4-760b-4e93-bb97-3a2077202cce\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6470e82c",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2e5fcf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:33.528732Z",
     "start_time": "2024-01-06T11:15:33.475702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL</th>\n",
       "      <th>COW</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>RELP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>WKHP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>230</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4110</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4130</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4020</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8300</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SCHL COW MAR  OCCP POBP RELP SEX RAC1P  AGEP  WKHP\n",
       "0   23   7   3   230   36    0   1     1    55  55.0\n",
       "1   16   1   5  4110   13    2   2     1    20  35.0\n",
       "2   16   4   3  4130   51    0   2     1    59  30.0\n",
       "3   18   4   1  4020   13    0   1     2    43  40.0\n",
       "4   14   1   1  8300   20    1   2     2    33  20.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = ACSIncomeDataset(state=['GA'], year=2018, with_nulls=False,\n",
    "                               subsample_size=15_000, subsample_seed=42)\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c53f584",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:34.580537Z",
     "start_time": "2024-01-06T11:15:34.538952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d3860a",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2fa652",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d209fa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:37.135031Z",
     "start_time": "2024-01-06T11:15:37.105079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24349f4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:44.618835Z",
     "start_time": "2024-01-06T11:15:43.745040Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:04:06 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 100,\n",
      " 'experiment_iteration': 'Exp_iter_1',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 100,\n",
      " 'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc38ee9c876469caefd18438ec5bf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:04:06 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=724)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0a941737a8417cb4f7946d88b35431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8c917d6c174359aff6c81106515faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.703511; batch adversarial loss: 0.868435\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433493; batch adversarial loss: 0.870017\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396227; batch adversarial loss: 0.863279\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393296; batch adversarial loss: 0.784595\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335170; batch adversarial loss: 0.729312\n",
      "epoch 5; iter: 0; batch classifier loss: 0.302273; batch adversarial loss: 0.718420\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340553; batch adversarial loss: 0.671042\n",
      "epoch 7; iter: 0; batch classifier loss: 0.317702; batch adversarial loss: 0.662751\n",
      "epoch 8; iter: 0; batch classifier loss: 0.252170; batch adversarial loss: 0.648393\n",
      "epoch 9; iter: 0; batch classifier loss: 0.292380; batch adversarial loss: 0.613334\n",
      "epoch 10; iter: 0; batch classifier loss: 0.278500; batch adversarial loss: 0.582467\n",
      "epoch 11; iter: 0; batch classifier loss: 0.315808; batch adversarial loss: 0.541661\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282857; batch adversarial loss: 0.547508\n",
      "epoch 13; iter: 0; batch classifier loss: 0.245198; batch adversarial loss: 0.570313\n",
      "epoch 14; iter: 0; batch classifier loss: 0.295288; batch adversarial loss: 0.471533\n",
      "epoch 15; iter: 0; batch classifier loss: 0.255773; batch adversarial loss: 0.471669\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227866; batch adversarial loss: 0.459387\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265236; batch adversarial loss: 0.390383\n",
      "epoch 18; iter: 0; batch classifier loss: 0.221451; batch adversarial loss: 0.492176\n",
      "epoch 19; iter: 0; batch classifier loss: 0.235272; batch adversarial loss: 0.424545\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222551; batch adversarial loss: 0.393122\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149757; batch adversarial loss: 0.495092\n",
      "epoch 22; iter: 0; batch classifier loss: 0.181218; batch adversarial loss: 0.386822\n",
      "epoch 23; iter: 0; batch classifier loss: 0.139735; batch adversarial loss: 0.457702\n",
      "epoch 24; iter: 0; batch classifier loss: 0.153798; batch adversarial loss: 0.475582\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132027; batch adversarial loss: 0.444322\n",
      "epoch 26; iter: 0; batch classifier loss: 0.129947; batch adversarial loss: 0.370190\n",
      "epoch 27; iter: 0; batch classifier loss: 0.140482; batch adversarial loss: 0.350910\n",
      "epoch 28; iter: 0; batch classifier loss: 0.166366; batch adversarial loss: 0.481889\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178009; batch adversarial loss: 0.357132\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e78c75",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b0b3deb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EXPERIMENT_SEEDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Configs for an experiment iteration\u001b[39;00m\n\u001b[1;32m      2\u001b[0m exp_iter_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 3\u001b[0m experiment_seed \u001b[38;5;241m=\u001b[39m \u001b[43mEXPERIMENT_SEEDS\u001b[49m[exp_iter_num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m tuned_params_filenames \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      6\u001b[0m tuned_params_df_paths \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_fairness_interventions_exp\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                       FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, tuned_params_filename)\n\u001b[1;32m      8\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m tuned_params_filename \u001b[38;5;129;01min\u001b[39;00m tuned_params_filenames]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EXPERIMENT_SEEDS' is not defined"
     ]
    }
   ],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce03e155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:56.249510Z",
     "start_time": "2024-01-04T20:53:56.233525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 17:15:39 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 200,\n",
      " 'experiment_iteration': 'Exp_iter_2',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 200,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5645c6009d3b48d29619a238bc476502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 17:15:39 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 17:15:39 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([322, 293, 576, 300, 391, 343, 294, 558, 560, 439, 355, 440, 277,\n",
      "            492, 644, 639, 589, 259, 313, 129],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([322, 293, 576, 300, 391, 343, 294, 558, 560, 439, 355, 440, 277,\n",
      "            492, 644, 639, 589, 259, 313, 129],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 200, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c0277603884950a0c35cc9dcc3f539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7137564e8e0d4fcbbbfaaf03d73e170a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa30ab3dbbfe4acb8557a8c1e2d6556b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a36e32d08b44c1b01ae496881c6b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596808eb",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "135f9969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "634f9178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:46.750905Z",
     "start_time": "2024-01-04T20:53:46.744795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 300,\n",
      " 'experiment_iteration': 'Exp_iter_3',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 300,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48b0aa26f024ad1b1089190e134193d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 300, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eddcae8f6fc4651885a3144088ae9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43ba8d965cc436a91f10cc39b3d5e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94495e7bec64c9ebf4c05cdd52e605d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f7167dd20740a68f8f90158ec19560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059176f",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70f5e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c475fa55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:37.675129Z",
     "start_time": "2024-01-04T20:53:37.670178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 400,\n",
      " 'experiment_iteration': 'Exp_iter_4',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 400,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5b534568b14897b8686d22a9c79d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 400, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42164aebf0d74a5992f0ca8075639200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a128a0a62f40fb9bd0b88e41d55103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6300cf6db9cc4bcf95389b1f6e9b8108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e75feb8b5c4e00a1fc551544462dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8251dc",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c82240df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "682d6c79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:27.080554Z",
     "start_time": "2024-01-04T20:53:27.072313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:06:03 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 500,\n",
      " 'experiment_iteration': 'Exp_iter_5',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 500,\n",
      " 'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd54f9c824346bfadc80e9dc2b59071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:06:03 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=730)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 8104,   580,  8954,  6500,  5436,  3490,  1621, 11610,  7067,\n",
      "            10637,   767, 10997,  6202,  4468,  8440, 10810, 11409,  3682,\n",
      "            12856, 14104],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 8104,   580,  8954,  6500,  5436,  3490,  1621, 11610,  7067,\n",
      "            10637,   767, 10997,  6202,  4468,  8440, 10810, 11409,  3682,\n",
      "            12856, 14104],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01f45d3839f42cba106f1902f91d5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57136c5c8024b809be83774c5d6fca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.698604; batch adversarial loss: 0.753836\n",
      "epoch 1; iter: 0; batch classifier loss: 0.449413; batch adversarial loss: 0.656631\n",
      "epoch 2; iter: 0; batch classifier loss: 0.410863; batch adversarial loss: 0.616627\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374883; batch adversarial loss: 0.601123\n",
      "epoch 4; iter: 0; batch classifier loss: 0.339765; batch adversarial loss: 0.615700\n",
      "epoch 5; iter: 0; batch classifier loss: 0.380644; batch adversarial loss: 0.584557\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315304; batch adversarial loss: 0.596260\n",
      "epoch 7; iter: 0; batch classifier loss: 0.295440; batch adversarial loss: 0.564723\n",
      "epoch 8; iter: 0; batch classifier loss: 0.288062; batch adversarial loss: 0.554626\n",
      "epoch 9; iter: 0; batch classifier loss: 0.307547; batch adversarial loss: 0.549957\n",
      "epoch 10; iter: 0; batch classifier loss: 0.341461; batch adversarial loss: 0.546882\n",
      "epoch 11; iter: 0; batch classifier loss: 0.406466; batch adversarial loss: 0.501260\n",
      "epoch 12; iter: 0; batch classifier loss: 0.391525; batch adversarial loss: 0.518319\n",
      "epoch 13; iter: 0; batch classifier loss: 0.304332; batch adversarial loss: 0.498127\n",
      "epoch 14; iter: 0; batch classifier loss: 0.339556; batch adversarial loss: 0.472889\n",
      "epoch 15; iter: 0; batch classifier loss: 0.231014; batch adversarial loss: 0.469979\n",
      "epoch 16; iter: 0; batch classifier loss: 0.341794; batch adversarial loss: 0.477046\n",
      "epoch 17; iter: 0; batch classifier loss: 0.228839; batch adversarial loss: 0.554744\n",
      "epoch 18; iter: 0; batch classifier loss: 0.279737; batch adversarial loss: 0.547117\n",
      "epoch 19; iter: 0; batch classifier loss: 0.214822; batch adversarial loss: 0.530043\n",
      "epoch 20; iter: 0; batch classifier loss: 0.310140; batch adversarial loss: 0.393519\n",
      "epoch 21; iter: 0; batch classifier loss: 0.200886; batch adversarial loss: 0.481037\n",
      "epoch 22; iter: 0; batch classifier loss: 0.254351; batch adversarial loss: 0.420932\n",
      "epoch 23; iter: 0; batch classifier loss: 0.208692; batch adversarial loss: 0.481831\n",
      "epoch 24; iter: 0; batch classifier loss: 0.196106; batch adversarial loss: 0.551192\n",
      "epoch 25; iter: 0; batch classifier loss: 0.158444; batch adversarial loss: 0.485130\n",
      "epoch 26; iter: 0; batch classifier loss: 0.195972; batch adversarial loss: 0.448630\n",
      "epoch 27; iter: 0; batch classifier loss: 0.202371; batch adversarial loss: 0.452494\n",
      "epoch 28; iter: 0; batch classifier loss: 0.233447; batch adversarial loss: 0.429414\n",
      "epoch 29; iter: 0; batch classifier loss: 0.276897; batch adversarial loss: 0.395627\n",
      "epoch 30; iter: 0; batch classifier loss: 0.260255; batch adversarial loss: 0.391917\n",
      "epoch 31; iter: 0; batch classifier loss: 0.154933; batch adversarial loss: 0.511568\n",
      "epoch 32; iter: 0; batch classifier loss: 0.174863; batch adversarial loss: 0.422476\n",
      "epoch 33; iter: 0; batch classifier loss: 0.221060; batch adversarial loss: 0.419881\n",
      "epoch 34; iter: 0; batch classifier loss: 0.200860; batch adversarial loss: 0.441580\n",
      "epoch 35; iter: 0; batch classifier loss: 0.163393; batch adversarial loss: 0.509646\n",
      "epoch 36; iter: 0; batch classifier loss: 0.191206; batch adversarial loss: 0.449537\n",
      "epoch 37; iter: 0; batch classifier loss: 0.237930; batch adversarial loss: 0.448391\n",
      "epoch 38; iter: 0; batch classifier loss: 0.113453; batch adversarial loss: 0.473866\n",
      "epoch 39; iter: 0; batch classifier loss: 0.206127; batch adversarial loss: 0.396179\n",
      "epoch 40; iter: 0; batch classifier loss: 0.199447; batch adversarial loss: 0.526473\n",
      "epoch 41; iter: 0; batch classifier loss: 0.178462; batch adversarial loss: 0.422042\n",
      "epoch 42; iter: 0; batch classifier loss: 0.159205; batch adversarial loss: 0.496531\n",
      "epoch 43; iter: 0; batch classifier loss: 0.118805; batch adversarial loss: 0.421500\n",
      "epoch 44; iter: 0; batch classifier loss: 0.174651; batch adversarial loss: 0.435281\n",
      "epoch 45; iter: 0; batch classifier loss: 0.186624; batch adversarial loss: 0.481756\n",
      "epoch 46; iter: 0; batch classifier loss: 0.278781; batch adversarial loss: 0.466109\n",
      "epoch 47; iter: 0; batch classifier loss: 0.216434; batch adversarial loss: 0.447701\n",
      "epoch 48; iter: 0; batch classifier loss: 0.291653; batch adversarial loss: 0.447570\n",
      "epoch 49; iter: 0; batch classifier loss: 0.135674; batch adversarial loss: 0.446382\n",
      "epoch 50; iter: 0; batch classifier loss: 0.159830; batch adversarial loss: 0.556389\n",
      "epoch 51; iter: 0; batch classifier loss: 0.284834; batch adversarial loss: 0.400166\n",
      "epoch 52; iter: 0; batch classifier loss: 0.198949; batch adversarial loss: 0.446776\n",
      "epoch 53; iter: 0; batch classifier loss: 0.198715; batch adversarial loss: 0.486758\n",
      "epoch 54; iter: 0; batch classifier loss: 0.199566; batch adversarial loss: 0.462451\n",
      "epoch 55; iter: 0; batch classifier loss: 0.198153; batch adversarial loss: 0.450000\n",
      "epoch 56; iter: 0; batch classifier loss: 0.184822; batch adversarial loss: 0.424166\n",
      "epoch 57; iter: 0; batch classifier loss: 0.199831; batch adversarial loss: 0.435703\n",
      "epoch 58; iter: 0; batch classifier loss: 0.239712; batch adversarial loss: 0.458360\n",
      "epoch 59; iter: 0; batch classifier loss: 0.265293; batch adversarial loss: 0.471250\n",
      "epoch 60; iter: 0; batch classifier loss: 0.222180; batch adversarial loss: 0.459309\n",
      "epoch 61; iter: 0; batch classifier loss: 0.219575; batch adversarial loss: 0.483095\n",
      "epoch 62; iter: 0; batch classifier loss: 0.208492; batch adversarial loss: 0.483490\n",
      "epoch 63; iter: 0; batch classifier loss: 0.257120; batch adversarial loss: 0.434965\n",
      "epoch 64; iter: 0; batch classifier loss: 0.088377; batch adversarial loss: 0.542474\n",
      "epoch 65; iter: 0; batch classifier loss: 0.064762; batch adversarial loss: 0.441116\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078713; batch adversarial loss: 0.453350\n",
      "epoch 67; iter: 0; batch classifier loss: 0.058867; batch adversarial loss: 0.450280\n",
      "epoch 68; iter: 0; batch classifier loss: 0.072753; batch adversarial loss: 0.398085\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065427; batch adversarial loss: 0.514435\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065257; batch adversarial loss: 0.499892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073904; batch adversarial loss: 0.453159\n",
      "epoch 72; iter: 0; batch classifier loss: 0.036666; batch adversarial loss: 0.431203\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076299; batch adversarial loss: 0.361556\n",
      "epoch 74; iter: 0; batch classifier loss: 0.048362; batch adversarial loss: 0.531370\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063776; batch adversarial loss: 0.471518\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072863; batch adversarial loss: 0.388513\n",
      "epoch 77; iter: 0; batch classifier loss: 0.033488; batch adversarial loss: 0.450351\n",
      "epoch 78; iter: 0; batch classifier loss: 0.048608; batch adversarial loss: 0.464936\n",
      "epoch 79; iter: 0; batch classifier loss: 0.042274; batch adversarial loss: 0.440044\n",
      "epoch 80; iter: 0; batch classifier loss: 0.081771; batch adversarial loss: 0.432137\n",
      "epoch 81; iter: 0; batch classifier loss: 0.032296; batch adversarial loss: 0.412172\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073875; batch adversarial loss: 0.458053\n",
      "epoch 83; iter: 0; batch classifier loss: 0.073361; batch adversarial loss: 0.494039\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065179; batch adversarial loss: 0.505883\n",
      "epoch 85; iter: 0; batch classifier loss: 0.079717; batch adversarial loss: 0.442225\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063211; batch adversarial loss: 0.456780\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066857; batch adversarial loss: 0.458912\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067384; batch adversarial loss: 0.489418\n",
      "epoch 89; iter: 0; batch classifier loss: 0.087534; batch adversarial loss: 0.350880\n",
      "epoch 90; iter: 0; batch classifier loss: 0.081377; batch adversarial loss: 0.436191\n",
      "epoch 91; iter: 0; batch classifier loss: 0.030003; batch adversarial loss: 0.421605\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063082; batch adversarial loss: 0.434553\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072581; batch adversarial loss: 0.449141\n",
      "epoch 94; iter: 0; batch classifier loss: 0.057060; batch adversarial loss: 0.417148\n",
      "epoch 95; iter: 0; batch classifier loss: 0.061141; batch adversarial loss: 0.507351\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056815; batch adversarial loss: 0.339242\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052216; batch adversarial loss: 0.530849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.067161; batch adversarial loss: 0.468873\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065038; batch adversarial loss: 0.432284\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043065; batch adversarial loss: 0.414576\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063767; batch adversarial loss: 0.402353\n",
      "epoch 102; iter: 0; batch classifier loss: 0.074738; batch adversarial loss: 0.428936\n",
      "epoch 103; iter: 0; batch classifier loss: 0.127608; batch adversarial loss: 0.433222\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071868; batch adversarial loss: 0.504858\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046379; batch adversarial loss: 0.422168\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051026; batch adversarial loss: 0.346650\n",
      "epoch 107; iter: 0; batch classifier loss: 0.078070; batch adversarial loss: 0.428668\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030643; batch adversarial loss: 0.485820\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064698; batch adversarial loss: 0.402569\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057774; batch adversarial loss: 0.528482\n",
      "epoch 111; iter: 0; batch classifier loss: 0.085369; batch adversarial loss: 0.394559\n",
      "epoch 112; iter: 0; batch classifier loss: 0.071526; batch adversarial loss: 0.388803\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039488; batch adversarial loss: 0.487292\n",
      "epoch 114; iter: 0; batch classifier loss: 0.082116; batch adversarial loss: 0.413456\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053679; batch adversarial loss: 0.494149\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040632; batch adversarial loss: 0.404859\n",
      "epoch 117; iter: 0; batch classifier loss: 0.064264; batch adversarial loss: 0.399967\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051400; batch adversarial loss: 0.353829\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050696; batch adversarial loss: 0.429119\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054800; batch adversarial loss: 0.457960\n",
      "epoch 121; iter: 0; batch classifier loss: 0.068047; batch adversarial loss: 0.441542\n",
      "epoch 122; iter: 0; batch classifier loss: 0.056330; batch adversarial loss: 0.377305\n",
      "epoch 123; iter: 0; batch classifier loss: 0.080386; batch adversarial loss: 0.466984\n",
      "epoch 124; iter: 0; batch classifier loss: 0.068208; batch adversarial loss: 0.454433\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048828; batch adversarial loss: 0.314321\n",
      "epoch 126; iter: 0; batch classifier loss: 0.071309; batch adversarial loss: 0.464952\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047721; batch adversarial loss: 0.426913\n",
      "epoch 128; iter: 0; batch classifier loss: 0.057758; batch adversarial loss: 0.418507\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039970; batch adversarial loss: 0.393047\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045608; batch adversarial loss: 0.418573\n",
      "epoch 131; iter: 0; batch classifier loss: 0.080359; batch adversarial loss: 0.375613\n",
      "epoch 132; iter: 0; batch classifier loss: 0.073918; batch adversarial loss: 0.478639\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053741; batch adversarial loss: 0.505495\n",
      "epoch 134; iter: 0; batch classifier loss: 0.061720; batch adversarial loss: 0.407708\n",
      "epoch 135; iter: 0; batch classifier loss: 0.069145; batch adversarial loss: 0.432554\n",
      "epoch 136; iter: 0; batch classifier loss: 0.065592; batch adversarial loss: 0.509606\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048579; batch adversarial loss: 0.395618\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046313; batch adversarial loss: 0.389708\n",
      "epoch 139; iter: 0; batch classifier loss: 0.067108; batch adversarial loss: 0.424548\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051631; batch adversarial loss: 0.465106\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037465; batch adversarial loss: 0.352532\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050973; batch adversarial loss: 0.357868\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041601; batch adversarial loss: 0.469833\n",
      "epoch 144; iter: 0; batch classifier loss: 0.063264; batch adversarial loss: 0.399522\n",
      "epoch 145; iter: 0; batch classifier loss: 0.049921; batch adversarial loss: 0.351169\n",
      "epoch 146; iter: 0; batch classifier loss: 0.047462; batch adversarial loss: 0.356486\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023320; batch adversarial loss: 0.433804\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035031; batch adversarial loss: 0.405457\n",
      "epoch 149; iter: 0; batch classifier loss: 0.057689; batch adversarial loss: 0.388408\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034894; batch adversarial loss: 0.389145\n",
      "epoch 151; iter: 0; batch classifier loss: 0.051493; batch adversarial loss: 0.536957\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042091; batch adversarial loss: 0.493620\n",
      "epoch 153; iter: 0; batch classifier loss: 0.066194; batch adversarial loss: 0.490371\n",
      "epoch 154; iter: 0; batch classifier loss: 0.057908; batch adversarial loss: 0.460212\n",
      "epoch 155; iter: 0; batch classifier loss: 0.043982; batch adversarial loss: 0.415839\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033376; batch adversarial loss: 0.474140\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036697; batch adversarial loss: 0.377339\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028861; batch adversarial loss: 0.361544\n",
      "epoch 159; iter: 0; batch classifier loss: 0.042195; batch adversarial loss: 0.378853\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044149; batch adversarial loss: 0.370707\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038532; batch adversarial loss: 0.477959\n",
      "epoch 162; iter: 0; batch classifier loss: 0.056129; batch adversarial loss: 0.394460\n",
      "epoch 163; iter: 0; batch classifier loss: 0.031319; batch adversarial loss: 0.442582\n",
      "epoch 164; iter: 0; batch classifier loss: 0.049560; batch adversarial loss: 0.427936\n",
      "epoch 165; iter: 0; batch classifier loss: 0.054346; batch adversarial loss: 0.411786\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028301; batch adversarial loss: 0.593335\n",
      "epoch 167; iter: 0; batch classifier loss: 0.058178; batch adversarial loss: 0.386022\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034391; batch adversarial loss: 0.438313\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019426; batch adversarial loss: 0.533823\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038407; batch adversarial loss: 0.437979\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033846; batch adversarial loss: 0.394972\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023940; batch adversarial loss: 0.425710\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012776; batch adversarial loss: 0.408542\n",
      "epoch 174; iter: 0; batch classifier loss: 0.043698; batch adversarial loss: 0.397647\n",
      "epoch 175; iter: 0; batch classifier loss: 0.066957; batch adversarial loss: 0.427263\n",
      "epoch 176; iter: 0; batch classifier loss: 0.036045; batch adversarial loss: 0.583867\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032219; batch adversarial loss: 0.461755\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021390; batch adversarial loss: 0.492720\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044399; batch adversarial loss: 0.478768\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024813; batch adversarial loss: 0.343567\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013264; batch adversarial loss: 0.409979\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031357; batch adversarial loss: 0.450730\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036271; batch adversarial loss: 0.484866\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026273; batch adversarial loss: 0.534065\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035407; batch adversarial loss: 0.420613\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016617; batch adversarial loss: 0.394465\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034038; batch adversarial loss: 0.501262\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029297; batch adversarial loss: 0.452769\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016637; batch adversarial loss: 0.454201\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016336; batch adversarial loss: 0.466062\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016614; batch adversarial loss: 0.474391\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020970; batch adversarial loss: 0.410956\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026706; batch adversarial loss: 0.420042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.023528; batch adversarial loss: 0.417355\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025993; batch adversarial loss: 0.474019\n",
      "epoch 196; iter: 0; batch classifier loss: 0.044816; batch adversarial loss: 0.432139\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045878; batch adversarial loss: 0.508862\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031519; batch adversarial loss: 0.494590\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019269; batch adversarial loss: 0.436155\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666072; batch adversarial loss: 0.671640\n",
      "epoch 1; iter: 0; batch classifier loss: 0.446511; batch adversarial loss: 0.626905\n",
      "epoch 2; iter: 0; batch classifier loss: 0.325232; batch adversarial loss: 0.602477\n",
      "epoch 3; iter: 0; batch classifier loss: 0.316332; batch adversarial loss: 0.584079\n",
      "epoch 4; iter: 0; batch classifier loss: 0.330771; batch adversarial loss: 0.568705\n",
      "epoch 5; iter: 0; batch classifier loss: 0.352312; batch adversarial loss: 0.512841\n",
      "epoch 6; iter: 0; batch classifier loss: 0.285435; batch adversarial loss: 0.518346\n",
      "epoch 7; iter: 0; batch classifier loss: 0.299793; batch adversarial loss: 0.517064\n",
      "epoch 8; iter: 0; batch classifier loss: 0.275778; batch adversarial loss: 0.480753\n",
      "epoch 9; iter: 0; batch classifier loss: 0.266203; batch adversarial loss: 0.511138\n",
      "epoch 10; iter: 0; batch classifier loss: 0.282124; batch adversarial loss: 0.500665\n",
      "epoch 11; iter: 0; batch classifier loss: 0.265599; batch adversarial loss: 0.471401\n",
      "epoch 12; iter: 0; batch classifier loss: 0.214080; batch adversarial loss: 0.491685\n",
      "epoch 13; iter: 0; batch classifier loss: 0.284457; batch adversarial loss: 0.483547\n",
      "epoch 14; iter: 0; batch classifier loss: 0.270840; batch adversarial loss: 0.513785\n",
      "epoch 15; iter: 0; batch classifier loss: 0.257019; batch adversarial loss: 0.522031\n",
      "epoch 16; iter: 0; batch classifier loss: 0.255648; batch adversarial loss: 0.498996\n",
      "epoch 17; iter: 0; batch classifier loss: 0.253240; batch adversarial loss: 0.433866\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197321; batch adversarial loss: 0.488536\n",
      "epoch 19; iter: 0; batch classifier loss: 0.227165; batch adversarial loss: 0.509385\n",
      "epoch 20; iter: 0; batch classifier loss: 0.237073; batch adversarial loss: 0.505349\n",
      "epoch 21; iter: 0; batch classifier loss: 0.310004; batch adversarial loss: 0.510239\n",
      "epoch 22; iter: 0; batch classifier loss: 0.350723; batch adversarial loss: 0.514809\n",
      "epoch 23; iter: 0; batch classifier loss: 0.375954; batch adversarial loss: 0.463900\n",
      "epoch 24; iter: 0; batch classifier loss: 0.387899; batch adversarial loss: 0.510671\n",
      "epoch 25; iter: 0; batch classifier loss: 0.181388; batch adversarial loss: 0.551315\n",
      "epoch 26; iter: 0; batch classifier loss: 0.156967; batch adversarial loss: 0.476641\n",
      "epoch 27; iter: 0; batch classifier loss: 0.096833; batch adversarial loss: 0.539442\n",
      "epoch 28; iter: 0; batch classifier loss: 0.154244; batch adversarial loss: 0.391564\n",
      "epoch 29; iter: 0; batch classifier loss: 0.125737; batch adversarial loss: 0.412861\n",
      "epoch 30; iter: 0; batch classifier loss: 0.071550; batch adversarial loss: 0.355941\n",
      "epoch 31; iter: 0; batch classifier loss: 0.106353; batch adversarial loss: 0.422844\n",
      "epoch 32; iter: 0; batch classifier loss: 0.111098; batch adversarial loss: 0.494581\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143982; batch adversarial loss: 0.422004\n",
      "epoch 34; iter: 0; batch classifier loss: 0.098875; batch adversarial loss: 0.401849\n",
      "epoch 35; iter: 0; batch classifier loss: 0.119143; batch adversarial loss: 0.489816\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128504; batch adversarial loss: 0.461588\n",
      "epoch 37; iter: 0; batch classifier loss: 0.115996; batch adversarial loss: 0.412755\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099098; batch adversarial loss: 0.429337\n",
      "epoch 39; iter: 0; batch classifier loss: 0.127321; batch adversarial loss: 0.446297\n",
      "epoch 40; iter: 0; batch classifier loss: 0.082747; batch adversarial loss: 0.489852\n",
      "epoch 41; iter: 0; batch classifier loss: 0.075972; batch adversarial loss: 0.524860\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117842; batch adversarial loss: 0.432729\n",
      "epoch 43; iter: 0; batch classifier loss: 0.082164; batch adversarial loss: 0.548817\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105358; batch adversarial loss: 0.520269\n",
      "epoch 45; iter: 0; batch classifier loss: 0.106427; batch adversarial loss: 0.413042\n",
      "epoch 46; iter: 0; batch classifier loss: 0.125000; batch adversarial loss: 0.607431\n",
      "epoch 47; iter: 0; batch classifier loss: 0.104282; batch adversarial loss: 0.414431\n",
      "epoch 48; iter: 0; batch classifier loss: 0.102317; batch adversarial loss: 0.461456\n",
      "epoch 49; iter: 0; batch classifier loss: 0.064737; batch adversarial loss: 0.407397\n",
      "epoch 50; iter: 0; batch classifier loss: 0.076021; batch adversarial loss: 0.512812\n",
      "epoch 51; iter: 0; batch classifier loss: 0.087884; batch adversarial loss: 0.548519\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089085; batch adversarial loss: 0.402395\n",
      "epoch 53; iter: 0; batch classifier loss: 0.110319; batch adversarial loss: 0.361568\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122115; batch adversarial loss: 0.430859\n",
      "epoch 55; iter: 0; batch classifier loss: 0.094364; batch adversarial loss: 0.461083\n",
      "epoch 56; iter: 0; batch classifier loss: 0.094023; batch adversarial loss: 0.430407\n",
      "epoch 57; iter: 0; batch classifier loss: 0.118709; batch adversarial loss: 0.439158\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090705; batch adversarial loss: 0.450512\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090749; batch adversarial loss: 0.397622\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095955; batch adversarial loss: 0.511860\n",
      "epoch 61; iter: 0; batch classifier loss: 0.085213; batch adversarial loss: 0.481859\n",
      "epoch 62; iter: 0; batch classifier loss: 0.111786; batch adversarial loss: 0.457153\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099935; batch adversarial loss: 0.481331\n",
      "epoch 64; iter: 0; batch classifier loss: 0.058006; batch adversarial loss: 0.434198\n",
      "epoch 65; iter: 0; batch classifier loss: 0.089516; batch adversarial loss: 0.407752\n",
      "epoch 66; iter: 0; batch classifier loss: 0.101352; batch adversarial loss: 0.516029\n",
      "epoch 67; iter: 0; batch classifier loss: 0.109863; batch adversarial loss: 0.429167\n",
      "epoch 68; iter: 0; batch classifier loss: 0.059695; batch adversarial loss: 0.549320\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081344; batch adversarial loss: 0.413475\n",
      "epoch 70; iter: 0; batch classifier loss: 0.128497; batch adversarial loss: 0.471790\n",
      "epoch 71; iter: 0; batch classifier loss: 0.106047; batch adversarial loss: 0.414593\n",
      "epoch 72; iter: 0; batch classifier loss: 0.086872; batch adversarial loss: 0.407950\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077719; batch adversarial loss: 0.444403\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066351; batch adversarial loss: 0.487155\n",
      "epoch 75; iter: 0; batch classifier loss: 0.144496; batch adversarial loss: 0.473848\n",
      "epoch 76; iter: 0; batch classifier loss: 0.098499; batch adversarial loss: 0.471163\n",
      "epoch 77; iter: 0; batch classifier loss: 0.051544; batch adversarial loss: 0.395782\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071687; batch adversarial loss: 0.442444\n",
      "epoch 79; iter: 0; batch classifier loss: 0.098037; batch adversarial loss: 0.587515\n",
      "epoch 80; iter: 0; batch classifier loss: 0.074981; batch adversarial loss: 0.446182\n",
      "epoch 81; iter: 0; batch classifier loss: 0.117463; batch adversarial loss: 0.530847\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060650; batch adversarial loss: 0.499672\n",
      "epoch 83; iter: 0; batch classifier loss: 0.105139; batch adversarial loss: 0.493311\n",
      "epoch 84; iter: 0; batch classifier loss: 0.111156; batch adversarial loss: 0.486486\n",
      "epoch 85; iter: 0; batch classifier loss: 0.049895; batch adversarial loss: 0.463802\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057003; batch adversarial loss: 0.482895\n",
      "epoch 87; iter: 0; batch classifier loss: 0.064671; batch adversarial loss: 0.497717\n",
      "epoch 88; iter: 0; batch classifier loss: 0.082103; batch adversarial loss: 0.339173\n",
      "epoch 89; iter: 0; batch classifier loss: 0.087723; batch adversarial loss: 0.450148\n",
      "epoch 90; iter: 0; batch classifier loss: 0.040719; batch adversarial loss: 0.378106\n",
      "epoch 91; iter: 0; batch classifier loss: 0.100698; batch adversarial loss: 0.418102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.071960; batch adversarial loss: 0.484555\n",
      "epoch 93; iter: 0; batch classifier loss: 0.088054; batch adversarial loss: 0.460224\n",
      "epoch 94; iter: 0; batch classifier loss: 0.045768; batch adversarial loss: 0.523030\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052284; batch adversarial loss: 0.504828\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055575; batch adversarial loss: 0.469593\n",
      "epoch 97; iter: 0; batch classifier loss: 0.031975; batch adversarial loss: 0.399000\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061524; batch adversarial loss: 0.443434\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064280; batch adversarial loss: 0.521261\n",
      "epoch 100; iter: 0; batch classifier loss: 0.063711; batch adversarial loss: 0.499719\n",
      "epoch 101; iter: 0; batch classifier loss: 0.093049; batch adversarial loss: 0.471540\n",
      "epoch 102; iter: 0; batch classifier loss: 0.077349; batch adversarial loss: 0.444170\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076588; batch adversarial loss: 0.468691\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063472; batch adversarial loss: 0.553635\n",
      "epoch 105; iter: 0; batch classifier loss: 0.079838; batch adversarial loss: 0.512751\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058339; batch adversarial loss: 0.394899\n",
      "epoch 107; iter: 0; batch classifier loss: 0.068897; batch adversarial loss: 0.465119\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040756; batch adversarial loss: 0.487273\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042064; batch adversarial loss: 0.407674\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042341; batch adversarial loss: 0.559831\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054039; batch adversarial loss: 0.488927\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057983; batch adversarial loss: 0.443851\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063493; batch adversarial loss: 0.373355\n",
      "epoch 114; iter: 0; batch classifier loss: 0.067051; batch adversarial loss: 0.447772\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065537; batch adversarial loss: 0.534396\n",
      "epoch 116; iter: 0; batch classifier loss: 0.073258; batch adversarial loss: 0.418280\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055111; batch adversarial loss: 0.497813\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032324; batch adversarial loss: 0.436714\n",
      "epoch 119; iter: 0; batch classifier loss: 0.072024; batch adversarial loss: 0.345254\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040834; batch adversarial loss: 0.462711\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054539; batch adversarial loss: 0.518285\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043068; batch adversarial loss: 0.449515\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032981; batch adversarial loss: 0.421417\n",
      "epoch 124; iter: 0; batch classifier loss: 0.049064; batch adversarial loss: 0.451984\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030526; batch adversarial loss: 0.516114\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039835; batch adversarial loss: 0.406455\n",
      "epoch 127; iter: 0; batch classifier loss: 0.017344; batch adversarial loss: 0.383737\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043709; batch adversarial loss: 0.457216\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020328; batch adversarial loss: 0.440856\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044821; batch adversarial loss: 0.398187\n",
      "epoch 131; iter: 0; batch classifier loss: 0.090748; batch adversarial loss: 0.467872\n",
      "epoch 132; iter: 0; batch classifier loss: 0.077811; batch adversarial loss: 0.368105\n",
      "epoch 133; iter: 0; batch classifier loss: 0.089003; batch adversarial loss: 0.467773\n",
      "epoch 134; iter: 0; batch classifier loss: 0.022716; batch adversarial loss: 0.471521\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031288; batch adversarial loss: 0.471609\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057156; batch adversarial loss: 0.345607\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034909; batch adversarial loss: 0.422062\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020041; batch adversarial loss: 0.481947\n",
      "epoch 139; iter: 0; batch classifier loss: 0.054821; batch adversarial loss: 0.418287\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040758; batch adversarial loss: 0.496956\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052497; batch adversarial loss: 0.369636\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027457; batch adversarial loss: 0.492225\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020547; batch adversarial loss: 0.571656\n",
      "epoch 144; iter: 0; batch classifier loss: 0.043520; batch adversarial loss: 0.342095\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036086; batch adversarial loss: 0.412755\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031593; batch adversarial loss: 0.548648\n",
      "epoch 147; iter: 0; batch classifier loss: 0.051835; batch adversarial loss: 0.503310\n",
      "epoch 148; iter: 0; batch classifier loss: 0.048094; batch adversarial loss: 0.394563\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019049; batch adversarial loss: 0.442736\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034637; batch adversarial loss: 0.414055\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013458; batch adversarial loss: 0.469585\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010326; batch adversarial loss: 0.570356\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035037; batch adversarial loss: 0.490362\n",
      "epoch 154; iter: 0; batch classifier loss: 0.048803; batch adversarial loss: 0.481307\n",
      "epoch 155; iter: 0; batch classifier loss: 0.056905; batch adversarial loss: 0.383610\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023630; batch adversarial loss: 0.425417\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034511; batch adversarial loss: 0.418379\n",
      "epoch 158; iter: 0; batch classifier loss: 0.068826; batch adversarial loss: 0.494473\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040669; batch adversarial loss: 0.499800\n",
      "epoch 160; iter: 0; batch classifier loss: 0.054303; batch adversarial loss: 0.464712\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032652; batch adversarial loss: 0.507297\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029611; batch adversarial loss: 0.459412\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011921; batch adversarial loss: 0.489381\n",
      "epoch 164; iter: 0; batch classifier loss: 0.042709; batch adversarial loss: 0.435268\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016886; batch adversarial loss: 0.467304\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026314; batch adversarial loss: 0.477667\n",
      "epoch 167; iter: 0; batch classifier loss: 0.049524; batch adversarial loss: 0.429839\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023027; batch adversarial loss: 0.409380\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010102; batch adversarial loss: 0.421848\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016754; batch adversarial loss: 0.407135\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024683; batch adversarial loss: 0.432386\n",
      "epoch 172; iter: 0; batch classifier loss: 0.045944; batch adversarial loss: 0.433126\n",
      "epoch 173; iter: 0; batch classifier loss: 0.060184; batch adversarial loss: 0.423084\n",
      "epoch 174; iter: 0; batch classifier loss: 0.034425; batch adversarial loss: 0.417569\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030061; batch adversarial loss: 0.476403\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033822; batch adversarial loss: 0.474108\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010748; batch adversarial loss: 0.426154\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008016; batch adversarial loss: 0.508690\n",
      "epoch 179; iter: 0; batch classifier loss: 0.062907; batch adversarial loss: 0.436189\n",
      "epoch 180; iter: 0; batch classifier loss: 0.042613; batch adversarial loss: 0.439902\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015129; batch adversarial loss: 0.477905\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019495; batch adversarial loss: 0.468687\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005742; batch adversarial loss: 0.553851\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012579; batch adversarial loss: 0.525825\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027930; batch adversarial loss: 0.544728\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007334; batch adversarial loss: 0.454395\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022713; batch adversarial loss: 0.440861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.048701; batch adversarial loss: 0.432477\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035255; batch adversarial loss: 0.385456\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017948; batch adversarial loss: 0.441805\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018602; batch adversarial loss: 0.427381\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040655; batch adversarial loss: 0.467787\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009570; batch adversarial loss: 0.443408\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034204; batch adversarial loss: 0.537508\n",
      "epoch 195; iter: 0; batch classifier loss: 0.054180; batch adversarial loss: 0.446341\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013177; batch adversarial loss: 0.548868\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007209; batch adversarial loss: 0.544653\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019855; batch adversarial loss: 0.492582\n",
      "epoch 199; iter: 0; batch classifier loss: 0.043807; batch adversarial loss: 0.437177\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681137; batch adversarial loss: 0.751495\n",
      "epoch 1; iter: 0; batch classifier loss: 0.560229; batch adversarial loss: 0.700017\n",
      "epoch 2; iter: 0; batch classifier loss: 0.540714; batch adversarial loss: 0.661343\n",
      "epoch 3; iter: 0; batch classifier loss: 0.381062; batch adversarial loss: 0.588731\n",
      "epoch 4; iter: 0; batch classifier loss: 0.418984; batch adversarial loss: 0.561551\n",
      "epoch 5; iter: 0; batch classifier loss: 0.416995; batch adversarial loss: 0.609133\n",
      "epoch 6; iter: 0; batch classifier loss: 0.426404; batch adversarial loss: 0.577852\n",
      "epoch 7; iter: 0; batch classifier loss: 0.351076; batch adversarial loss: 0.549317\n",
      "epoch 8; iter: 0; batch classifier loss: 0.316349; batch adversarial loss: 0.545005\n",
      "epoch 9; iter: 0; batch classifier loss: 0.253042; batch adversarial loss: 0.543945\n",
      "epoch 10; iter: 0; batch classifier loss: 0.244081; batch adversarial loss: 0.499097\n",
      "epoch 11; iter: 0; batch classifier loss: 0.342719; batch adversarial loss: 0.541990\n",
      "epoch 12; iter: 0; batch classifier loss: 0.307125; batch adversarial loss: 0.529439\n",
      "epoch 13; iter: 0; batch classifier loss: 0.244916; batch adversarial loss: 0.519142\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283138; batch adversarial loss: 0.428834\n",
      "epoch 15; iter: 0; batch classifier loss: 0.277247; batch adversarial loss: 0.443271\n",
      "epoch 16; iter: 0; batch classifier loss: 0.289271; batch adversarial loss: 0.484933\n",
      "epoch 17; iter: 0; batch classifier loss: 0.203310; batch adversarial loss: 0.518072\n",
      "epoch 18; iter: 0; batch classifier loss: 0.248127; batch adversarial loss: 0.445396\n",
      "epoch 19; iter: 0; batch classifier loss: 0.247382; batch adversarial loss: 0.516799\n",
      "epoch 20; iter: 0; batch classifier loss: 0.194407; batch adversarial loss: 0.437446\n",
      "epoch 21; iter: 0; batch classifier loss: 0.298158; batch adversarial loss: 0.428000\n",
      "epoch 22; iter: 0; batch classifier loss: 0.230286; batch adversarial loss: 0.527773\n",
      "epoch 23; iter: 0; batch classifier loss: 0.239568; batch adversarial loss: 0.441868\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195932; batch adversarial loss: 0.485391\n",
      "epoch 25; iter: 0; batch classifier loss: 0.196042; batch adversarial loss: 0.497145\n",
      "epoch 26; iter: 0; batch classifier loss: 0.174378; batch adversarial loss: 0.420321\n",
      "epoch 27; iter: 0; batch classifier loss: 0.231123; batch adversarial loss: 0.515170\n",
      "epoch 28; iter: 0; batch classifier loss: 0.212287; batch adversarial loss: 0.425085\n",
      "epoch 29; iter: 0; batch classifier loss: 0.237866; batch adversarial loss: 0.436980\n",
      "epoch 30; iter: 0; batch classifier loss: 0.222829; batch adversarial loss: 0.501663\n",
      "epoch 31; iter: 0; batch classifier loss: 0.246216; batch adversarial loss: 0.505295\n",
      "epoch 32; iter: 0; batch classifier loss: 0.228197; batch adversarial loss: 0.562785\n",
      "epoch 33; iter: 0; batch classifier loss: 0.203644; batch adversarial loss: 0.454173\n",
      "epoch 34; iter: 0; batch classifier loss: 0.194547; batch adversarial loss: 0.408036\n",
      "epoch 35; iter: 0; batch classifier loss: 0.261945; batch adversarial loss: 0.445005\n",
      "epoch 36; iter: 0; batch classifier loss: 0.238174; batch adversarial loss: 0.437673\n",
      "epoch 37; iter: 0; batch classifier loss: 0.273246; batch adversarial loss: 0.415134\n",
      "epoch 38; iter: 0; batch classifier loss: 0.245486; batch adversarial loss: 0.445314\n",
      "epoch 39; iter: 0; batch classifier loss: 0.193662; batch adversarial loss: 0.436749\n",
      "epoch 40; iter: 0; batch classifier loss: 0.264560; batch adversarial loss: 0.478149\n",
      "epoch 41; iter: 0; batch classifier loss: 0.227393; batch adversarial loss: 0.412263\n",
      "epoch 42; iter: 0; batch classifier loss: 0.214540; batch adversarial loss: 0.445356\n",
      "epoch 43; iter: 0; batch classifier loss: 0.229002; batch adversarial loss: 0.435456\n",
      "epoch 44; iter: 0; batch classifier loss: 0.214191; batch adversarial loss: 0.521129\n",
      "epoch 45; iter: 0; batch classifier loss: 0.252989; batch adversarial loss: 0.411586\n",
      "epoch 46; iter: 0; batch classifier loss: 0.230936; batch adversarial loss: 0.481238\n",
      "epoch 47; iter: 0; batch classifier loss: 0.223734; batch adversarial loss: 0.389419\n",
      "epoch 48; iter: 0; batch classifier loss: 0.225296; batch adversarial loss: 0.409111\n",
      "epoch 49; iter: 0; batch classifier loss: 0.267443; batch adversarial loss: 0.337203\n",
      "epoch 50; iter: 0; batch classifier loss: 0.247278; batch adversarial loss: 0.370007\n",
      "epoch 51; iter: 0; batch classifier loss: 0.234968; batch adversarial loss: 0.534060\n",
      "epoch 52; iter: 0; batch classifier loss: 0.197489; batch adversarial loss: 0.448551\n",
      "epoch 53; iter: 0; batch classifier loss: 0.227924; batch adversarial loss: 0.376622\n",
      "epoch 54; iter: 0; batch classifier loss: 0.256555; batch adversarial loss: 0.448007\n",
      "epoch 55; iter: 0; batch classifier loss: 0.214650; batch adversarial loss: 0.460990\n",
      "epoch 56; iter: 0; batch classifier loss: 0.181677; batch adversarial loss: 0.472771\n",
      "epoch 57; iter: 0; batch classifier loss: 0.223335; batch adversarial loss: 0.457157\n",
      "epoch 58; iter: 0; batch classifier loss: 0.237803; batch adversarial loss: 0.435355\n",
      "epoch 59; iter: 0; batch classifier loss: 0.194346; batch adversarial loss: 0.507598\n",
      "epoch 60; iter: 0; batch classifier loss: 0.246399; batch adversarial loss: 0.434405\n",
      "epoch 61; iter: 0; batch classifier loss: 0.239822; batch adversarial loss: 0.471112\n",
      "epoch 62; iter: 0; batch classifier loss: 0.262520; batch adversarial loss: 0.371988\n",
      "epoch 63; iter: 0; batch classifier loss: 0.164249; batch adversarial loss: 0.359966\n",
      "epoch 64; iter: 0; batch classifier loss: 0.091925; batch adversarial loss: 0.459347\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087987; batch adversarial loss: 0.471681\n",
      "epoch 66; iter: 0; batch classifier loss: 0.156969; batch adversarial loss: 0.494762\n",
      "epoch 67; iter: 0; batch classifier loss: 0.189561; batch adversarial loss: 0.395811\n",
      "epoch 68; iter: 0; batch classifier loss: 0.215498; batch adversarial loss: 0.472312\n",
      "epoch 69; iter: 0; batch classifier loss: 0.266662; batch adversarial loss: 0.447315\n",
      "epoch 70; iter: 0; batch classifier loss: 0.142419; batch adversarial loss: 0.520819\n",
      "epoch 71; iter: 0; batch classifier loss: 0.185041; batch adversarial loss: 0.485463\n",
      "epoch 72; iter: 0; batch classifier loss: 0.330081; batch adversarial loss: 0.496891\n",
      "epoch 73; iter: 0; batch classifier loss: 0.248113; batch adversarial loss: 0.446506\n",
      "epoch 74; iter: 0; batch classifier loss: 0.145802; batch adversarial loss: 0.484313\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067818; batch adversarial loss: 0.395871\n",
      "epoch 76; iter: 0; batch classifier loss: 0.087384; batch adversarial loss: 0.507591\n",
      "epoch 77; iter: 0; batch classifier loss: 0.054867; batch adversarial loss: 0.485254\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074078; batch adversarial loss: 0.496335\n",
      "epoch 79; iter: 0; batch classifier loss: 0.087934; batch adversarial loss: 0.555470\n",
      "epoch 80; iter: 0; batch classifier loss: 0.149782; batch adversarial loss: 0.394939\n",
      "epoch 81; iter: 0; batch classifier loss: 0.114887; batch adversarial loss: 0.469625\n",
      "epoch 82; iter: 0; batch classifier loss: 0.099493; batch adversarial loss: 0.458180\n",
      "epoch 83; iter: 0; batch classifier loss: 0.103123; batch adversarial loss: 0.543674\n",
      "epoch 84; iter: 0; batch classifier loss: 0.092459; batch adversarial loss: 0.587632\n",
      "epoch 85; iter: 0; batch classifier loss: 0.123470; batch adversarial loss: 0.467272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.201652; batch adversarial loss: 0.379584\n",
      "epoch 87; iter: 0; batch classifier loss: 0.124976; batch adversarial loss: 0.432431\n",
      "epoch 88; iter: 0; batch classifier loss: 0.107982; batch adversarial loss: 0.504536\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081201; batch adversarial loss: 0.386763\n",
      "epoch 90; iter: 0; batch classifier loss: 0.107768; batch adversarial loss: 0.529253\n",
      "epoch 91; iter: 0; batch classifier loss: 0.107017; batch adversarial loss: 0.391740\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055145; batch adversarial loss: 0.472730\n",
      "epoch 93; iter: 0; batch classifier loss: 0.113988; batch adversarial loss: 0.589718\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075448; batch adversarial loss: 0.428320\n",
      "epoch 95; iter: 0; batch classifier loss: 0.075684; batch adversarial loss: 0.419391\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065855; batch adversarial loss: 0.495327\n",
      "epoch 97; iter: 0; batch classifier loss: 0.082126; batch adversarial loss: 0.533386\n",
      "epoch 98; iter: 0; batch classifier loss: 0.087267; batch adversarial loss: 0.477556\n",
      "epoch 99; iter: 0; batch classifier loss: 0.089699; batch adversarial loss: 0.450967\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065531; batch adversarial loss: 0.478620\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049016; batch adversarial loss: 0.487399\n",
      "epoch 102; iter: 0; batch classifier loss: 0.077513; batch adversarial loss: 0.410018\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060892; batch adversarial loss: 0.407302\n",
      "epoch 104; iter: 0; batch classifier loss: 0.086206; batch adversarial loss: 0.442172\n",
      "epoch 105; iter: 0; batch classifier loss: 0.069986; batch adversarial loss: 0.476755\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063893; batch adversarial loss: 0.412226\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033811; batch adversarial loss: 0.468555\n",
      "epoch 108; iter: 0; batch classifier loss: 0.085408; batch adversarial loss: 0.456420\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066566; batch adversarial loss: 0.385607\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057250; batch adversarial loss: 0.342801\n",
      "epoch 111; iter: 0; batch classifier loss: 0.056922; batch adversarial loss: 0.462440\n",
      "epoch 112; iter: 0; batch classifier loss: 0.085613; batch adversarial loss: 0.473619\n",
      "epoch 113; iter: 0; batch classifier loss: 0.031480; batch adversarial loss: 0.529023\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057237; batch adversarial loss: 0.396763\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062698; batch adversarial loss: 0.500199\n",
      "epoch 116; iter: 0; batch classifier loss: 0.061190; batch adversarial loss: 0.452467\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067350; batch adversarial loss: 0.466451\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041850; batch adversarial loss: 0.528471\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059383; batch adversarial loss: 0.533013\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040022; batch adversarial loss: 0.495835\n",
      "epoch 121; iter: 0; batch classifier loss: 0.022546; batch adversarial loss: 0.437943\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025082; batch adversarial loss: 0.368329\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039582; batch adversarial loss: 0.462471\n",
      "epoch 124; iter: 0; batch classifier loss: 0.060713; batch adversarial loss: 0.446739\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068507; batch adversarial loss: 0.404229\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030998; batch adversarial loss: 0.476869\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048054; batch adversarial loss: 0.457656\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023951; batch adversarial loss: 0.445531\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040662; batch adversarial loss: 0.412705\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041030; batch adversarial loss: 0.509393\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022452; batch adversarial loss: 0.422732\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032618; batch adversarial loss: 0.512419\n",
      "epoch 133; iter: 0; batch classifier loss: 0.017050; batch adversarial loss: 0.385652\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053602; batch adversarial loss: 0.397199\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019658; batch adversarial loss: 0.383944\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023327; batch adversarial loss: 0.412866\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029043; batch adversarial loss: 0.384327\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049030; batch adversarial loss: 0.372674\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018947; batch adversarial loss: 0.495387\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040570; batch adversarial loss: 0.494815\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021387; batch adversarial loss: 0.488932\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026963; batch adversarial loss: 0.468852\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046374; batch adversarial loss: 0.426262\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017730; batch adversarial loss: 0.421175\n",
      "epoch 145; iter: 0; batch classifier loss: 0.009308; batch adversarial loss: 0.485189\n",
      "epoch 146; iter: 0; batch classifier loss: 0.008433; batch adversarial loss: 0.426548\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027410; batch adversarial loss: 0.515898\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026868; batch adversarial loss: 0.457922\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014549; batch adversarial loss: 0.409245\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044706; batch adversarial loss: 0.460456\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016611; batch adversarial loss: 0.462085\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008924; batch adversarial loss: 0.495451\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008296; batch adversarial loss: 0.396000\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016542; batch adversarial loss: 0.373806\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032636; batch adversarial loss: 0.505068\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020498; batch adversarial loss: 0.368894\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027993; batch adversarial loss: 0.455261\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025505; batch adversarial loss: 0.570766\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035810; batch adversarial loss: 0.414011\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029976; batch adversarial loss: 0.421971\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014365; batch adversarial loss: 0.398287\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013592; batch adversarial loss: 0.458883\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014953; batch adversarial loss: 0.402855\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035934; batch adversarial loss: 0.465774\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022746; batch adversarial loss: 0.404152\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038051; batch adversarial loss: 0.334482\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006625; batch adversarial loss: 0.454153\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013157; batch adversarial loss: 0.531747\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010738; batch adversarial loss: 0.377663\n",
      "epoch 170; iter: 0; batch classifier loss: 0.047071; batch adversarial loss: 0.507892\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029101; batch adversarial loss: 0.477683\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019955; batch adversarial loss: 0.491462\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018293; batch adversarial loss: 0.398093\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020966; batch adversarial loss: 0.437312\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026640; batch adversarial loss: 0.457411\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012566; batch adversarial loss: 0.397692\n",
      "epoch 177; iter: 0; batch classifier loss: 0.007507; batch adversarial loss: 0.409373\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012812; batch adversarial loss: 0.439178\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027826; batch adversarial loss: 0.466598\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019344; batch adversarial loss: 0.430089\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020828; batch adversarial loss: 0.470186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.017673; batch adversarial loss: 0.499312\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010884; batch adversarial loss: 0.498749\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019913; batch adversarial loss: 0.413233\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021335; batch adversarial loss: 0.409660\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011822; batch adversarial loss: 0.461360\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011502; batch adversarial loss: 0.377066\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034436; batch adversarial loss: 0.526876\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013040; batch adversarial loss: 0.517138\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008845; batch adversarial loss: 0.380357\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015007; batch adversarial loss: 0.473625\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015344; batch adversarial loss: 0.471022\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022909; batch adversarial loss: 0.415562\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025204; batch adversarial loss: 0.433846\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011932; batch adversarial loss: 0.431147\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020007; batch adversarial loss: 0.481891\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039320; batch adversarial loss: 0.471529\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009582; batch adversarial loss: 0.392445\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021382; batch adversarial loss: 0.474597\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698060; batch adversarial loss: 0.640049\n",
      "epoch 1; iter: 0; batch classifier loss: 0.431348; batch adversarial loss: 0.660314\n",
      "epoch 2; iter: 0; batch classifier loss: 0.404556; batch adversarial loss: 0.616081\n",
      "epoch 3; iter: 0; batch classifier loss: 0.424904; batch adversarial loss: 0.584375\n",
      "epoch 4; iter: 0; batch classifier loss: 0.360370; batch adversarial loss: 0.581381\n",
      "epoch 5; iter: 0; batch classifier loss: 0.285263; batch adversarial loss: 0.548879\n",
      "epoch 6; iter: 0; batch classifier loss: 0.281013; batch adversarial loss: 0.535493\n",
      "epoch 7; iter: 0; batch classifier loss: 0.354078; batch adversarial loss: 0.527031\n",
      "epoch 8; iter: 0; batch classifier loss: 0.241581; batch adversarial loss: 0.503127\n",
      "epoch 9; iter: 0; batch classifier loss: 0.273858; batch adversarial loss: 0.477781\n",
      "epoch 10; iter: 0; batch classifier loss: 0.207629; batch adversarial loss: 0.524574\n",
      "epoch 11; iter: 0; batch classifier loss: 0.169441; batch adversarial loss: 0.458417\n",
      "epoch 12; iter: 0; batch classifier loss: 0.230537; batch adversarial loss: 0.481049\n",
      "epoch 13; iter: 0; batch classifier loss: 0.143037; batch adversarial loss: 0.518431\n",
      "epoch 14; iter: 0; batch classifier loss: 0.203159; batch adversarial loss: 0.463998\n",
      "epoch 15; iter: 0; batch classifier loss: 0.170956; batch adversarial loss: 0.468965\n",
      "epoch 16; iter: 0; batch classifier loss: 0.204863; batch adversarial loss: 0.494159\n",
      "epoch 17; iter: 0; batch classifier loss: 0.182274; batch adversarial loss: 0.487351\n",
      "epoch 18; iter: 0; batch classifier loss: 0.124141; batch adversarial loss: 0.500080\n",
      "epoch 19; iter: 0; batch classifier loss: 0.163014; batch adversarial loss: 0.479342\n",
      "epoch 20; iter: 0; batch classifier loss: 0.161657; batch adversarial loss: 0.419424\n",
      "epoch 21; iter: 0; batch classifier loss: 0.129236; batch adversarial loss: 0.473201\n",
      "epoch 22; iter: 0; batch classifier loss: 0.201139; batch adversarial loss: 0.507670\n",
      "epoch 23; iter: 0; batch classifier loss: 0.152965; batch adversarial loss: 0.543338\n",
      "epoch 24; iter: 0; batch classifier loss: 0.208181; batch adversarial loss: 0.501572\n",
      "epoch 25; iter: 0; batch classifier loss: 0.137991; batch adversarial loss: 0.528449\n",
      "epoch 26; iter: 0; batch classifier loss: 0.209388; batch adversarial loss: 0.448184\n",
      "epoch 27; iter: 0; batch classifier loss: 0.295762; batch adversarial loss: 0.562927\n",
      "epoch 28; iter: 0; batch classifier loss: 0.226954; batch adversarial loss: 0.434703\n",
      "epoch 29; iter: 0; batch classifier loss: 0.161918; batch adversarial loss: 0.540997\n",
      "epoch 30; iter: 0; batch classifier loss: 0.168092; batch adversarial loss: 0.500051\n",
      "epoch 31; iter: 0; batch classifier loss: 0.221901; batch adversarial loss: 0.556247\n",
      "epoch 32; iter: 0; batch classifier loss: 0.151094; batch adversarial loss: 0.422298\n",
      "epoch 33; iter: 0; batch classifier loss: 0.158477; batch adversarial loss: 0.447848\n",
      "epoch 34; iter: 0; batch classifier loss: 0.293317; batch adversarial loss: 0.368639\n",
      "epoch 35; iter: 0; batch classifier loss: 0.260073; batch adversarial loss: 0.474128\n",
      "epoch 36; iter: 0; batch classifier loss: 0.242930; batch adversarial loss: 0.495586\n",
      "epoch 37; iter: 0; batch classifier loss: 0.364379; batch adversarial loss: 0.476925\n",
      "epoch 38; iter: 0; batch classifier loss: 0.180126; batch adversarial loss: 0.434673\n",
      "epoch 39; iter: 0; batch classifier loss: 0.140522; batch adversarial loss: 0.447888\n",
      "epoch 40; iter: 0; batch classifier loss: 0.108270; batch adversarial loss: 0.447391\n",
      "epoch 41; iter: 0; batch classifier loss: 0.064283; batch adversarial loss: 0.556816\n",
      "epoch 42; iter: 0; batch classifier loss: 0.083268; batch adversarial loss: 0.445189\n",
      "epoch 43; iter: 0; batch classifier loss: 0.082631; batch adversarial loss: 0.426882\n",
      "epoch 44; iter: 0; batch classifier loss: 0.106068; batch adversarial loss: 0.413333\n",
      "epoch 45; iter: 0; batch classifier loss: 0.120374; batch adversarial loss: 0.457382\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116318; batch adversarial loss: 0.501066\n",
      "epoch 47; iter: 0; batch classifier loss: 0.116240; batch adversarial loss: 0.407234\n",
      "epoch 48; iter: 0; batch classifier loss: 0.067858; batch adversarial loss: 0.493056\n",
      "epoch 49; iter: 0; batch classifier loss: 0.088444; batch adversarial loss: 0.523964\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074726; batch adversarial loss: 0.442129\n",
      "epoch 51; iter: 0; batch classifier loss: 0.096464; batch adversarial loss: 0.475210\n",
      "epoch 52; iter: 0; batch classifier loss: 0.049474; batch adversarial loss: 0.496732\n",
      "epoch 53; iter: 0; batch classifier loss: 0.097511; batch adversarial loss: 0.415878\n",
      "epoch 54; iter: 0; batch classifier loss: 0.062808; batch adversarial loss: 0.420652\n",
      "epoch 55; iter: 0; batch classifier loss: 0.060336; batch adversarial loss: 0.455296\n",
      "epoch 56; iter: 0; batch classifier loss: 0.053547; batch adversarial loss: 0.492123\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073425; batch adversarial loss: 0.406490\n",
      "epoch 58; iter: 0; batch classifier loss: 0.092212; batch adversarial loss: 0.296452\n",
      "epoch 59; iter: 0; batch classifier loss: 0.098933; batch adversarial loss: 0.499378\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105297; batch adversarial loss: 0.440101\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088287; batch adversarial loss: 0.521538\n",
      "epoch 62; iter: 0; batch classifier loss: 0.053817; batch adversarial loss: 0.429610\n",
      "epoch 63; iter: 0; batch classifier loss: 0.061072; batch adversarial loss: 0.483315\n",
      "epoch 64; iter: 0; batch classifier loss: 0.061032; batch adversarial loss: 0.496850\n",
      "epoch 65; iter: 0; batch classifier loss: 0.098372; batch adversarial loss: 0.410346\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060796; batch adversarial loss: 0.440278\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080410; batch adversarial loss: 0.482538\n",
      "epoch 68; iter: 0; batch classifier loss: 0.048000; batch adversarial loss: 0.503893\n",
      "epoch 69; iter: 0; batch classifier loss: 0.108014; batch adversarial loss: 0.402068\n",
      "epoch 70; iter: 0; batch classifier loss: 0.063529; batch adversarial loss: 0.521838\n",
      "epoch 71; iter: 0; batch classifier loss: 0.085323; batch adversarial loss: 0.431899\n",
      "epoch 72; iter: 0; batch classifier loss: 0.075917; batch adversarial loss: 0.451568\n",
      "epoch 73; iter: 0; batch classifier loss: 0.046683; batch adversarial loss: 0.429601\n",
      "epoch 74; iter: 0; batch classifier loss: 0.111808; batch adversarial loss: 0.397694\n",
      "epoch 75; iter: 0; batch classifier loss: 0.091083; batch adversarial loss: 0.431928\n",
      "epoch 76; iter: 0; batch classifier loss: 0.114364; batch adversarial loss: 0.487584\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084386; batch adversarial loss: 0.491979\n",
      "epoch 78; iter: 0; batch classifier loss: 0.063299; batch adversarial loss: 0.518686\n",
      "epoch 79; iter: 0; batch classifier loss: 0.062693; batch adversarial loss: 0.448371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.054417; batch adversarial loss: 0.441271\n",
      "epoch 81; iter: 0; batch classifier loss: 0.053289; batch adversarial loss: 0.447786\n",
      "epoch 82; iter: 0; batch classifier loss: 0.118287; batch adversarial loss: 0.498213\n",
      "epoch 83; iter: 0; batch classifier loss: 0.041949; batch adversarial loss: 0.427285\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070584; batch adversarial loss: 0.428703\n",
      "epoch 85; iter: 0; batch classifier loss: 0.049598; batch adversarial loss: 0.547753\n",
      "epoch 86; iter: 0; batch classifier loss: 0.036471; batch adversarial loss: 0.491507\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046688; batch adversarial loss: 0.503178\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051024; batch adversarial loss: 0.467883\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054138; batch adversarial loss: 0.453902\n",
      "epoch 90; iter: 0; batch classifier loss: 0.034187; batch adversarial loss: 0.464905\n",
      "epoch 91; iter: 0; batch classifier loss: 0.049588; batch adversarial loss: 0.489891\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052290; batch adversarial loss: 0.489900\n",
      "epoch 93; iter: 0; batch classifier loss: 0.080387; batch adversarial loss: 0.468732\n",
      "epoch 94; iter: 0; batch classifier loss: 0.096263; batch adversarial loss: 0.396715\n",
      "epoch 95; iter: 0; batch classifier loss: 0.074540; batch adversarial loss: 0.359831\n",
      "epoch 96; iter: 0; batch classifier loss: 0.083158; batch adversarial loss: 0.398689\n",
      "epoch 97; iter: 0; batch classifier loss: 0.079811; batch adversarial loss: 0.385210\n",
      "epoch 98; iter: 0; batch classifier loss: 0.089647; batch adversarial loss: 0.404077\n",
      "epoch 99; iter: 0; batch classifier loss: 0.029669; batch adversarial loss: 0.484973\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046900; batch adversarial loss: 0.411438\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063777; batch adversarial loss: 0.494955\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038212; batch adversarial loss: 0.493542\n",
      "epoch 103; iter: 0; batch classifier loss: 0.092132; batch adversarial loss: 0.479009\n",
      "epoch 104; iter: 0; batch classifier loss: 0.077625; batch adversarial loss: 0.477391\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056646; batch adversarial loss: 0.464222\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033672; batch adversarial loss: 0.431696\n",
      "epoch 107; iter: 0; batch classifier loss: 0.026583; batch adversarial loss: 0.467702\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065834; batch adversarial loss: 0.408222\n",
      "epoch 109; iter: 0; batch classifier loss: 0.056036; batch adversarial loss: 0.489922\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047911; batch adversarial loss: 0.411884\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054586; batch adversarial loss: 0.453712\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051487; batch adversarial loss: 0.506335\n",
      "epoch 113; iter: 0; batch classifier loss: 0.064495; batch adversarial loss: 0.485699\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042627; batch adversarial loss: 0.471959\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033758; batch adversarial loss: 0.486569\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046477; batch adversarial loss: 0.444883\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031891; batch adversarial loss: 0.431990\n",
      "epoch 118; iter: 0; batch classifier loss: 0.068526; batch adversarial loss: 0.358905\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056858; batch adversarial loss: 0.372175\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050261; batch adversarial loss: 0.461471\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038077; batch adversarial loss: 0.463591\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050820; batch adversarial loss: 0.439987\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035673; batch adversarial loss: 0.458508\n",
      "epoch 124; iter: 0; batch classifier loss: 0.053727; batch adversarial loss: 0.401997\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042578; batch adversarial loss: 0.450717\n",
      "epoch 126; iter: 0; batch classifier loss: 0.052092; batch adversarial loss: 0.518189\n",
      "epoch 127; iter: 0; batch classifier loss: 0.020483; batch adversarial loss: 0.468486\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023685; batch adversarial loss: 0.527173\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026560; batch adversarial loss: 0.374227\n",
      "epoch 130; iter: 0; batch classifier loss: 0.074683; batch adversarial loss: 0.513807\n",
      "epoch 131; iter: 0; batch classifier loss: 0.061116; batch adversarial loss: 0.332428\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036277; batch adversarial loss: 0.464920\n",
      "epoch 133; iter: 0; batch classifier loss: 0.055092; batch adversarial loss: 0.462467\n",
      "epoch 134; iter: 0; batch classifier loss: 0.060977; batch adversarial loss: 0.359213\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034507; batch adversarial loss: 0.419385\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021524; batch adversarial loss: 0.425697\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022061; batch adversarial loss: 0.439454\n",
      "epoch 138; iter: 0; batch classifier loss: 0.053766; batch adversarial loss: 0.404817\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034258; batch adversarial loss: 0.433536\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053468; batch adversarial loss: 0.480912\n",
      "epoch 141; iter: 0; batch classifier loss: 0.011272; batch adversarial loss: 0.473076\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026438; batch adversarial loss: 0.473647\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031450; batch adversarial loss: 0.347943\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031634; batch adversarial loss: 0.461864\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030892; batch adversarial loss: 0.443444\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031167; batch adversarial loss: 0.444263\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030068; batch adversarial loss: 0.430083\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025367; batch adversarial loss: 0.458175\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036889; batch adversarial loss: 0.377512\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024582; batch adversarial loss: 0.498075\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014818; batch adversarial loss: 0.522332\n",
      "epoch 152; iter: 0; batch classifier loss: 0.009086; batch adversarial loss: 0.469487\n",
      "epoch 153; iter: 0; batch classifier loss: 0.046118; batch adversarial loss: 0.438362\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046321; batch adversarial loss: 0.508249\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016359; batch adversarial loss: 0.578043\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018711; batch adversarial loss: 0.511930\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035089; batch adversarial loss: 0.417430\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036687; batch adversarial loss: 0.480568\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024104; batch adversarial loss: 0.399293\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010690; batch adversarial loss: 0.492032\n",
      "epoch 161; iter: 0; batch classifier loss: 0.052053; batch adversarial loss: 0.494944\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007778; batch adversarial loss: 0.424250\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037279; batch adversarial loss: 0.486355\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017936; batch adversarial loss: 0.413013\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023316; batch adversarial loss: 0.505360\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029452; batch adversarial loss: 0.398720\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012673; batch adversarial loss: 0.457588\n",
      "epoch 168; iter: 0; batch classifier loss: 0.059540; batch adversarial loss: 0.424308\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032373; batch adversarial loss: 0.427222\n",
      "epoch 170; iter: 0; batch classifier loss: 0.042835; batch adversarial loss: 0.469692\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033621; batch adversarial loss: 0.436903\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012978; batch adversarial loss: 0.552568\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022318; batch adversarial loss: 0.457427\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009815; batch adversarial loss: 0.447555\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029264; batch adversarial loss: 0.467976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.029901; batch adversarial loss: 0.524475\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009103; batch adversarial loss: 0.509013\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015539; batch adversarial loss: 0.541095\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018329; batch adversarial loss: 0.405177\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034703; batch adversarial loss: 0.533596\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026616; batch adversarial loss: 0.424623\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023850; batch adversarial loss: 0.541900\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018113; batch adversarial loss: 0.424812\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013721; batch adversarial loss: 0.461969\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033527; batch adversarial loss: 0.495811\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033621; batch adversarial loss: 0.522015\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033491; batch adversarial loss: 0.431885\n",
      "epoch 188; iter: 0; batch classifier loss: 0.071321; batch adversarial loss: 0.503438\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008579; batch adversarial loss: 0.367882\n",
      "epoch 190; iter: 0; batch classifier loss: 0.055822; batch adversarial loss: 0.472155\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024013; batch adversarial loss: 0.413303\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014659; batch adversarial loss: 0.458921\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017446; batch adversarial loss: 0.443116\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018307; batch adversarial loss: 0.384614\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019992; batch adversarial loss: 0.595547\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023247; batch adversarial loss: 0.458774\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033183; batch adversarial loss: 0.455905\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015779; batch adversarial loss: 0.412361\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015111; batch adversarial loss: 0.453012\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678284; batch adversarial loss: 0.973983\n",
      "epoch 1; iter: 0; batch classifier loss: 0.503492; batch adversarial loss: 1.119357\n",
      "epoch 2; iter: 0; batch classifier loss: 0.602018; batch adversarial loss: 1.028295\n",
      "epoch 3; iter: 0; batch classifier loss: 0.619254; batch adversarial loss: 0.987235\n",
      "epoch 4; iter: 0; batch classifier loss: 0.672077; batch adversarial loss: 0.949537\n",
      "epoch 5; iter: 0; batch classifier loss: 0.648835; batch adversarial loss: 0.843151\n",
      "epoch 6; iter: 0; batch classifier loss: 0.490619; batch adversarial loss: 0.788747\n",
      "epoch 7; iter: 0; batch classifier loss: 0.356873; batch adversarial loss: 0.696641\n",
      "epoch 8; iter: 0; batch classifier loss: 0.335087; batch adversarial loss: 0.643751\n",
      "epoch 9; iter: 0; batch classifier loss: 0.238219; batch adversarial loss: 0.626644\n",
      "epoch 10; iter: 0; batch classifier loss: 0.292206; batch adversarial loss: 0.619473\n",
      "epoch 11; iter: 0; batch classifier loss: 0.282521; batch adversarial loss: 0.577049\n",
      "epoch 12; iter: 0; batch classifier loss: 0.259817; batch adversarial loss: 0.530591\n",
      "epoch 13; iter: 0; batch classifier loss: 0.262222; batch adversarial loss: 0.567564\n",
      "epoch 14; iter: 0; batch classifier loss: 0.255049; batch adversarial loss: 0.560581\n",
      "epoch 15; iter: 0; batch classifier loss: 0.331785; batch adversarial loss: 0.475997\n",
      "epoch 16; iter: 0; batch classifier loss: 0.245508; batch adversarial loss: 0.554981\n",
      "epoch 17; iter: 0; batch classifier loss: 0.222210; batch adversarial loss: 0.548551\n",
      "epoch 18; iter: 0; batch classifier loss: 0.259429; batch adversarial loss: 0.477082\n",
      "epoch 19; iter: 0; batch classifier loss: 0.213873; batch adversarial loss: 0.502289\n",
      "epoch 20; iter: 0; batch classifier loss: 0.162794; batch adversarial loss: 0.512170\n",
      "epoch 21; iter: 0; batch classifier loss: 0.188946; batch adversarial loss: 0.472753\n",
      "epoch 22; iter: 0; batch classifier loss: 0.169844; batch adversarial loss: 0.466793\n",
      "epoch 23; iter: 0; batch classifier loss: 0.191588; batch adversarial loss: 0.522878\n",
      "epoch 24; iter: 0; batch classifier loss: 0.145553; batch adversarial loss: 0.460993\n",
      "epoch 25; iter: 0; batch classifier loss: 0.195775; batch adversarial loss: 0.506879\n",
      "epoch 26; iter: 0; batch classifier loss: 0.197323; batch adversarial loss: 0.500668\n",
      "epoch 27; iter: 0; batch classifier loss: 0.201697; batch adversarial loss: 0.439824\n",
      "epoch 28; iter: 0; batch classifier loss: 0.216826; batch adversarial loss: 0.484814\n",
      "epoch 29; iter: 0; batch classifier loss: 0.171124; batch adversarial loss: 0.468145\n",
      "epoch 30; iter: 0; batch classifier loss: 0.272966; batch adversarial loss: 0.376597\n",
      "epoch 31; iter: 0; batch classifier loss: 0.120167; batch adversarial loss: 0.382749\n",
      "epoch 32; iter: 0; batch classifier loss: 0.121159; batch adversarial loss: 0.452608\n",
      "epoch 33; iter: 0; batch classifier loss: 0.099783; batch adversarial loss: 0.514303\n",
      "epoch 34; iter: 0; batch classifier loss: 0.117120; batch adversarial loss: 0.402826\n",
      "epoch 35; iter: 0; batch classifier loss: 0.098714; batch adversarial loss: 0.439788\n",
      "epoch 36; iter: 0; batch classifier loss: 0.090170; batch adversarial loss: 0.496259\n",
      "epoch 37; iter: 0; batch classifier loss: 0.118532; batch adversarial loss: 0.431233\n",
      "epoch 38; iter: 0; batch classifier loss: 0.085891; batch adversarial loss: 0.451466\n",
      "epoch 39; iter: 0; batch classifier loss: 0.108528; batch adversarial loss: 0.451506\n",
      "epoch 40; iter: 0; batch classifier loss: 0.076531; batch adversarial loss: 0.405438\n",
      "epoch 41; iter: 0; batch classifier loss: 0.089611; batch adversarial loss: 0.412761\n",
      "epoch 42; iter: 0; batch classifier loss: 0.148003; batch adversarial loss: 0.392559\n",
      "epoch 43; iter: 0; batch classifier loss: 0.119308; batch adversarial loss: 0.514335\n",
      "epoch 44; iter: 0; batch classifier loss: 0.080807; batch adversarial loss: 0.396781\n",
      "epoch 45; iter: 0; batch classifier loss: 0.092910; batch adversarial loss: 0.438088\n",
      "epoch 46; iter: 0; batch classifier loss: 0.062669; batch adversarial loss: 0.390605\n",
      "epoch 47; iter: 0; batch classifier loss: 0.145511; batch adversarial loss: 0.400860\n",
      "epoch 48; iter: 0; batch classifier loss: 0.171460; batch adversarial loss: 0.404741\n",
      "epoch 49; iter: 0; batch classifier loss: 0.066663; batch adversarial loss: 0.386332\n",
      "epoch 50; iter: 0; batch classifier loss: 0.109713; batch adversarial loss: 0.432450\n",
      "epoch 51; iter: 0; batch classifier loss: 0.075507; batch adversarial loss: 0.496618\n",
      "epoch 52; iter: 0; batch classifier loss: 0.067797; batch adversarial loss: 0.346924\n",
      "epoch 53; iter: 0; batch classifier loss: 0.086710; batch adversarial loss: 0.387040\n",
      "epoch 54; iter: 0; batch classifier loss: 0.051247; batch adversarial loss: 0.394868\n",
      "epoch 55; iter: 0; batch classifier loss: 0.066978; batch adversarial loss: 0.444117\n",
      "epoch 56; iter: 0; batch classifier loss: 0.085054; batch adversarial loss: 0.434944\n",
      "epoch 57; iter: 0; batch classifier loss: 0.131959; batch adversarial loss: 0.413754\n",
      "epoch 58; iter: 0; batch classifier loss: 0.070605; batch adversarial loss: 0.431397\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087406; batch adversarial loss: 0.433785\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079106; batch adversarial loss: 0.394926\n",
      "epoch 61; iter: 0; batch classifier loss: 0.062921; batch adversarial loss: 0.346856\n",
      "epoch 62; iter: 0; batch classifier loss: 0.074524; batch adversarial loss: 0.495979\n",
      "epoch 63; iter: 0; batch classifier loss: 0.110892; batch adversarial loss: 0.446423\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082280; batch adversarial loss: 0.398669\n",
      "epoch 65; iter: 0; batch classifier loss: 0.094941; batch adversarial loss: 0.456556\n",
      "epoch 66; iter: 0; batch classifier loss: 0.052624; batch adversarial loss: 0.438155\n",
      "epoch 67; iter: 0; batch classifier loss: 0.068128; batch adversarial loss: 0.461468\n",
      "epoch 68; iter: 0; batch classifier loss: 0.056893; batch adversarial loss: 0.302348\n",
      "epoch 69; iter: 0; batch classifier loss: 0.037897; batch adversarial loss: 0.373445\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065827; batch adversarial loss: 0.589299\n",
      "epoch 71; iter: 0; batch classifier loss: 0.050926; batch adversarial loss: 0.409599\n",
      "epoch 72; iter: 0; batch classifier loss: 0.081815; batch adversarial loss: 0.442142\n",
      "epoch 73; iter: 0; batch classifier loss: 0.094068; batch adversarial loss: 0.587040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.076781; batch adversarial loss: 0.476518\n",
      "epoch 75; iter: 0; batch classifier loss: 0.029201; batch adversarial loss: 0.418294\n",
      "epoch 76; iter: 0; batch classifier loss: 0.056010; batch adversarial loss: 0.332450\n",
      "epoch 77; iter: 0; batch classifier loss: 0.041939; batch adversarial loss: 0.542684\n",
      "epoch 78; iter: 0; batch classifier loss: 0.053103; batch adversarial loss: 0.498973\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065816; batch adversarial loss: 0.448107\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067653; batch adversarial loss: 0.444586\n",
      "epoch 81; iter: 0; batch classifier loss: 0.047885; batch adversarial loss: 0.454703\n",
      "epoch 82; iter: 0; batch classifier loss: 0.038379; batch adversarial loss: 0.520715\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059099; batch adversarial loss: 0.345660\n",
      "epoch 84; iter: 0; batch classifier loss: 0.018849; batch adversarial loss: 0.507654\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046642; batch adversarial loss: 0.392723\n",
      "epoch 86; iter: 0; batch classifier loss: 0.059216; batch adversarial loss: 0.476613\n",
      "epoch 87; iter: 0; batch classifier loss: 0.036056; batch adversarial loss: 0.354357\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041484; batch adversarial loss: 0.387478\n",
      "epoch 89; iter: 0; batch classifier loss: 0.043937; batch adversarial loss: 0.475486\n",
      "epoch 90; iter: 0; batch classifier loss: 0.090570; batch adversarial loss: 0.595428\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048710; batch adversarial loss: 0.475334\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063515; batch adversarial loss: 0.430001\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055460; batch adversarial loss: 0.475565\n",
      "epoch 94; iter: 0; batch classifier loss: 0.086546; batch adversarial loss: 0.444467\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077911; batch adversarial loss: 0.351653\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070213; batch adversarial loss: 0.457153\n",
      "epoch 97; iter: 0; batch classifier loss: 0.076085; batch adversarial loss: 0.442442\n",
      "epoch 98; iter: 0; batch classifier loss: 0.080148; batch adversarial loss: 0.417295\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042840; batch adversarial loss: 0.462542\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034451; batch adversarial loss: 0.421269\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051147; batch adversarial loss: 0.454988\n",
      "epoch 102; iter: 0; batch classifier loss: 0.028542; batch adversarial loss: 0.441108\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055081; batch adversarial loss: 0.493667\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053401; batch adversarial loss: 0.458816\n",
      "epoch 105; iter: 0; batch classifier loss: 0.125881; batch adversarial loss: 0.603344\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046788; batch adversarial loss: 0.427703\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033280; batch adversarial loss: 0.387874\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056150; batch adversarial loss: 0.387976\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062937; batch adversarial loss: 0.447152\n",
      "epoch 110; iter: 0; batch classifier loss: 0.066365; batch adversarial loss: 0.396250\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062251; batch adversarial loss: 0.479309\n",
      "epoch 112; iter: 0; batch classifier loss: 0.066937; batch adversarial loss: 0.466179\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056014; batch adversarial loss: 0.435877\n",
      "epoch 114; iter: 0; batch classifier loss: 0.070777; batch adversarial loss: 0.356935\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029565; batch adversarial loss: 0.506891\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060018; batch adversarial loss: 0.476369\n",
      "epoch 117; iter: 0; batch classifier loss: 0.022572; batch adversarial loss: 0.334167\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028041; batch adversarial loss: 0.433139\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051949; batch adversarial loss: 0.446310\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031400; batch adversarial loss: 0.469798\n",
      "epoch 121; iter: 0; batch classifier loss: 0.069723; batch adversarial loss: 0.515393\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066330; batch adversarial loss: 0.562582\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053093; batch adversarial loss: 0.478565\n",
      "epoch 124; iter: 0; batch classifier loss: 0.073553; batch adversarial loss: 0.447861\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051314; batch adversarial loss: 0.440234\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033697; batch adversarial loss: 0.437376\n",
      "epoch 127; iter: 0; batch classifier loss: 0.099553; batch adversarial loss: 0.461363\n",
      "epoch 128; iter: 0; batch classifier loss: 0.069515; batch adversarial loss: 0.459197\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046432; batch adversarial loss: 0.489094\n",
      "epoch 130; iter: 0; batch classifier loss: 0.052730; batch adversarial loss: 0.423399\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049691; batch adversarial loss: 0.470211\n",
      "epoch 132; iter: 0; batch classifier loss: 0.059928; batch adversarial loss: 0.531823\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025164; batch adversarial loss: 0.452886\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051019; batch adversarial loss: 0.458911\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040308; batch adversarial loss: 0.418209\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031775; batch adversarial loss: 0.411515\n",
      "epoch 137; iter: 0; batch classifier loss: 0.074758; batch adversarial loss: 0.530504\n",
      "epoch 138; iter: 0; batch classifier loss: 0.072867; batch adversarial loss: 0.349534\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046753; batch adversarial loss: 0.468100\n",
      "epoch 140; iter: 0; batch classifier loss: 0.058110; batch adversarial loss: 0.407659\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040640; batch adversarial loss: 0.449009\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037313; batch adversarial loss: 0.301846\n",
      "epoch 143; iter: 0; batch classifier loss: 0.038695; batch adversarial loss: 0.467035\n",
      "epoch 144; iter: 0; batch classifier loss: 0.062488; batch adversarial loss: 0.420888\n",
      "epoch 145; iter: 0; batch classifier loss: 0.061338; batch adversarial loss: 0.457492\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052232; batch adversarial loss: 0.465910\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028705; batch adversarial loss: 0.393466\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054885; batch adversarial loss: 0.448397\n",
      "epoch 149; iter: 0; batch classifier loss: 0.051521; batch adversarial loss: 0.395059\n",
      "epoch 150; iter: 0; batch classifier loss: 0.073167; batch adversarial loss: 0.310445\n",
      "epoch 151; iter: 0; batch classifier loss: 0.062522; batch adversarial loss: 0.324276\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035840; batch adversarial loss: 0.405161\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031846; batch adversarial loss: 0.355589\n",
      "epoch 154; iter: 0; batch classifier loss: 0.067513; batch adversarial loss: 0.495402\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034469; batch adversarial loss: 0.307885\n",
      "epoch 156; iter: 0; batch classifier loss: 0.048343; batch adversarial loss: 0.544447\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026229; batch adversarial loss: 0.459609\n",
      "epoch 158; iter: 0; batch classifier loss: 0.040758; batch adversarial loss: 0.415900\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033411; batch adversarial loss: 0.492079\n",
      "epoch 160; iter: 0; batch classifier loss: 0.068059; batch adversarial loss: 0.415970\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030602; batch adversarial loss: 0.418554\n",
      "epoch 162; iter: 0; batch classifier loss: 0.061979; batch adversarial loss: 0.488262\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039076; batch adversarial loss: 0.381960\n",
      "epoch 164; iter: 0; batch classifier loss: 0.085383; batch adversarial loss: 0.486202\n",
      "epoch 165; iter: 0; batch classifier loss: 0.086093; batch adversarial loss: 0.536055\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032946; batch adversarial loss: 0.389337\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042918; batch adversarial loss: 0.461328\n",
      "epoch 168; iter: 0; batch classifier loss: 0.078929; batch adversarial loss: 0.565682\n",
      "epoch 169; iter: 0; batch classifier loss: 0.046432; batch adversarial loss: 0.405863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.071256; batch adversarial loss: 0.349688\n",
      "epoch 171; iter: 0; batch classifier loss: 0.068884; batch adversarial loss: 0.365645\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031292; batch adversarial loss: 0.344323\n",
      "epoch 173; iter: 0; batch classifier loss: 0.060939; batch adversarial loss: 0.398767\n",
      "epoch 174; iter: 0; batch classifier loss: 0.068601; batch adversarial loss: 0.488785\n",
      "epoch 175; iter: 0; batch classifier loss: 0.042531; batch adversarial loss: 0.454515\n",
      "epoch 176; iter: 0; batch classifier loss: 0.048305; batch adversarial loss: 0.401847\n",
      "epoch 177; iter: 0; batch classifier loss: 0.059073; batch adversarial loss: 0.383729\n",
      "epoch 178; iter: 0; batch classifier loss: 0.050121; batch adversarial loss: 0.380544\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043005; batch adversarial loss: 0.354649\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049778; batch adversarial loss: 0.349008\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030087; batch adversarial loss: 0.351593\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031934; batch adversarial loss: 0.414316\n",
      "epoch 183; iter: 0; batch classifier loss: 0.037745; batch adversarial loss: 0.521820\n",
      "epoch 184; iter: 0; batch classifier loss: 0.050980; batch adversarial loss: 0.454278\n",
      "epoch 185; iter: 0; batch classifier loss: 0.045714; batch adversarial loss: 0.406880\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041539; batch adversarial loss: 0.372213\n",
      "epoch 187; iter: 0; batch classifier loss: 0.044539; batch adversarial loss: 0.442633\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030167; batch adversarial loss: 0.521958\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035270; batch adversarial loss: 0.498966\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027139; batch adversarial loss: 0.325241\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030733; batch adversarial loss: 0.426090\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040913; batch adversarial loss: 0.430859\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020927; batch adversarial loss: 0.396223\n",
      "epoch 194; iter: 0; batch classifier loss: 0.068446; batch adversarial loss: 0.513057\n",
      "epoch 195; iter: 0; batch classifier loss: 0.049017; batch adversarial loss: 0.399969\n",
      "epoch 196; iter: 0; batch classifier loss: 0.050052; batch adversarial loss: 0.388144\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031221; batch adversarial loss: 0.506531\n",
      "epoch 198; iter: 0; batch classifier loss: 0.040387; batch adversarial loss: 0.350689\n",
      "epoch 199; iter: 0; batch classifier loss: 0.057898; batch adversarial loss: 0.421412\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723391; batch adversarial loss: 0.905608\n",
      "epoch 1; iter: 0; batch classifier loss: 0.487853; batch adversarial loss: 0.870749\n",
      "epoch 2; iter: 0; batch classifier loss: 0.380466; batch adversarial loss: 0.865139\n",
      "epoch 3; iter: 0; batch classifier loss: 0.362339; batch adversarial loss: 0.782768\n",
      "epoch 4; iter: 0; batch classifier loss: 0.271171; batch adversarial loss: 0.747562\n",
      "epoch 5; iter: 0; batch classifier loss: 0.306774; batch adversarial loss: 0.664604\n",
      "epoch 6; iter: 0; batch classifier loss: 0.314448; batch adversarial loss: 0.648195\n",
      "epoch 7; iter: 0; batch classifier loss: 0.365930; batch adversarial loss: 0.598244\n",
      "epoch 8; iter: 0; batch classifier loss: 0.214794; batch adversarial loss: 0.593957\n",
      "epoch 9; iter: 0; batch classifier loss: 0.296124; batch adversarial loss: 0.561679\n",
      "epoch 10; iter: 0; batch classifier loss: 0.276263; batch adversarial loss: 0.575150\n",
      "epoch 11; iter: 0; batch classifier loss: 0.234333; batch adversarial loss: 0.548737\n",
      "epoch 12; iter: 0; batch classifier loss: 0.290809; batch adversarial loss: 0.521861\n",
      "epoch 13; iter: 0; batch classifier loss: 0.222170; batch adversarial loss: 0.512947\n",
      "epoch 14; iter: 0; batch classifier loss: 0.231494; batch adversarial loss: 0.499619\n",
      "epoch 15; iter: 0; batch classifier loss: 0.282653; batch adversarial loss: 0.521707\n",
      "epoch 16; iter: 0; batch classifier loss: 0.306256; batch adversarial loss: 0.493585\n",
      "epoch 17; iter: 0; batch classifier loss: 0.252028; batch adversarial loss: 0.540629\n",
      "epoch 18; iter: 0; batch classifier loss: 0.323748; batch adversarial loss: 0.466023\n",
      "epoch 19; iter: 0; batch classifier loss: 0.271058; batch adversarial loss: 0.461646\n",
      "epoch 20; iter: 0; batch classifier loss: 0.247560; batch adversarial loss: 0.426791\n",
      "epoch 21; iter: 0; batch classifier loss: 0.232075; batch adversarial loss: 0.450632\n",
      "epoch 22; iter: 0; batch classifier loss: 0.225553; batch adversarial loss: 0.400231\n",
      "epoch 23; iter: 0; batch classifier loss: 0.226403; batch adversarial loss: 0.445130\n",
      "epoch 24; iter: 0; batch classifier loss: 0.169110; batch adversarial loss: 0.437757\n",
      "epoch 25; iter: 0; batch classifier loss: 0.160749; batch adversarial loss: 0.353486\n",
      "epoch 26; iter: 0; batch classifier loss: 0.131807; batch adversarial loss: 0.430144\n",
      "epoch 27; iter: 0; batch classifier loss: 0.124734; batch adversarial loss: 0.413433\n",
      "epoch 28; iter: 0; batch classifier loss: 0.196494; batch adversarial loss: 0.367515\n",
      "epoch 29; iter: 0; batch classifier loss: 0.171982; batch adversarial loss: 0.422962\n",
      "epoch 30; iter: 0; batch classifier loss: 0.200828; batch adversarial loss: 0.409249\n",
      "epoch 31; iter: 0; batch classifier loss: 0.147670; batch adversarial loss: 0.395885\n",
      "epoch 32; iter: 0; batch classifier loss: 0.189129; batch adversarial loss: 0.450873\n",
      "epoch 33; iter: 0; batch classifier loss: 0.135309; batch adversarial loss: 0.471301\n",
      "epoch 34; iter: 0; batch classifier loss: 0.194987; batch adversarial loss: 0.401085\n",
      "epoch 35; iter: 0; batch classifier loss: 0.116361; batch adversarial loss: 0.441708\n",
      "epoch 36; iter: 0; batch classifier loss: 0.095457; batch adversarial loss: 0.381084\n",
      "epoch 37; iter: 0; batch classifier loss: 0.143883; batch adversarial loss: 0.419459\n",
      "epoch 38; iter: 0; batch classifier loss: 0.132490; batch adversarial loss: 0.434487\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132373; batch adversarial loss: 0.392753\n",
      "epoch 40; iter: 0; batch classifier loss: 0.174803; batch adversarial loss: 0.357875\n",
      "epoch 41; iter: 0; batch classifier loss: 0.141556; batch adversarial loss: 0.371804\n",
      "epoch 42; iter: 0; batch classifier loss: 0.135432; batch adversarial loss: 0.421877\n",
      "epoch 43; iter: 0; batch classifier loss: 0.145180; batch adversarial loss: 0.430617\n",
      "epoch 44; iter: 0; batch classifier loss: 0.143407; batch adversarial loss: 0.461592\n",
      "epoch 45; iter: 0; batch classifier loss: 0.116285; batch adversarial loss: 0.368779\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102966; batch adversarial loss: 0.453108\n",
      "epoch 47; iter: 0; batch classifier loss: 0.127653; batch adversarial loss: 0.413477\n",
      "epoch 48; iter: 0; batch classifier loss: 0.102787; batch adversarial loss: 0.404764\n",
      "epoch 49; iter: 0; batch classifier loss: 0.092316; batch adversarial loss: 0.392962\n",
      "epoch 50; iter: 0; batch classifier loss: 0.160955; batch adversarial loss: 0.411522\n",
      "epoch 51; iter: 0; batch classifier loss: 0.112483; batch adversarial loss: 0.381728\n",
      "epoch 52; iter: 0; batch classifier loss: 0.213016; batch adversarial loss: 0.523109\n",
      "epoch 53; iter: 0; batch classifier loss: 0.170585; batch adversarial loss: 0.562927\n",
      "epoch 54; iter: 0; batch classifier loss: 0.082546; batch adversarial loss: 0.427191\n",
      "epoch 55; iter: 0; batch classifier loss: 0.090065; batch adversarial loss: 0.419882\n",
      "epoch 56; iter: 0; batch classifier loss: 0.111768; batch adversarial loss: 0.372475\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061602; batch adversarial loss: 0.355122\n",
      "epoch 58; iter: 0; batch classifier loss: 0.063179; batch adversarial loss: 0.320325\n",
      "epoch 59; iter: 0; batch classifier loss: 0.052779; batch adversarial loss: 0.449982\n",
      "epoch 60; iter: 0; batch classifier loss: 0.112562; batch adversarial loss: 0.369866\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087357; batch adversarial loss: 0.503399\n",
      "epoch 62; iter: 0; batch classifier loss: 0.083271; batch adversarial loss: 0.411978\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070364; batch adversarial loss: 0.431950\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072446; batch adversarial loss: 0.504452\n",
      "epoch 65; iter: 0; batch classifier loss: 0.113454; batch adversarial loss: 0.413784\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072714; batch adversarial loss: 0.400892\n",
      "epoch 67; iter: 0; batch classifier loss: 0.068354; batch adversarial loss: 0.427751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.100073; batch adversarial loss: 0.482089\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081867; batch adversarial loss: 0.353335\n",
      "epoch 70; iter: 0; batch classifier loss: 0.112344; batch adversarial loss: 0.539522\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115454; batch adversarial loss: 0.449736\n",
      "epoch 72; iter: 0; batch classifier loss: 0.106708; batch adversarial loss: 0.402489\n",
      "epoch 73; iter: 0; batch classifier loss: 0.089936; batch adversarial loss: 0.399270\n",
      "epoch 74; iter: 0; batch classifier loss: 0.044232; batch adversarial loss: 0.366168\n",
      "epoch 75; iter: 0; batch classifier loss: 0.064615; batch adversarial loss: 0.410655\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063811; batch adversarial loss: 0.431008\n",
      "epoch 77; iter: 0; batch classifier loss: 0.040859; batch adversarial loss: 0.451661\n",
      "epoch 78; iter: 0; batch classifier loss: 0.081415; batch adversarial loss: 0.320424\n",
      "epoch 79; iter: 0; batch classifier loss: 0.039586; batch adversarial loss: 0.363612\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083695; batch adversarial loss: 0.448308\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065646; batch adversarial loss: 0.401219\n",
      "epoch 82; iter: 0; batch classifier loss: 0.092719; batch adversarial loss: 0.402166\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083310; batch adversarial loss: 0.330016\n",
      "epoch 84; iter: 0; batch classifier loss: 0.128557; batch adversarial loss: 0.504055\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067903; batch adversarial loss: 0.508462\n",
      "epoch 86; iter: 0; batch classifier loss: 0.045569; batch adversarial loss: 0.447102\n",
      "epoch 87; iter: 0; batch classifier loss: 0.094880; batch adversarial loss: 0.478534\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073729; batch adversarial loss: 0.329943\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051870; batch adversarial loss: 0.447226\n",
      "epoch 90; iter: 0; batch classifier loss: 0.079770; batch adversarial loss: 0.405619\n",
      "epoch 91; iter: 0; batch classifier loss: 0.100243; batch adversarial loss: 0.475482\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068607; batch adversarial loss: 0.424981\n",
      "epoch 93; iter: 0; batch classifier loss: 0.112609; batch adversarial loss: 0.463352\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062153; batch adversarial loss: 0.540367\n",
      "epoch 95; iter: 0; batch classifier loss: 0.078918; batch adversarial loss: 0.453160\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057351; batch adversarial loss: 0.428713\n",
      "epoch 97; iter: 0; batch classifier loss: 0.083901; batch adversarial loss: 0.515840\n",
      "epoch 98; iter: 0; batch classifier loss: 0.092762; batch adversarial loss: 0.448608\n",
      "epoch 99; iter: 0; batch classifier loss: 0.088556; batch adversarial loss: 0.447488\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061491; batch adversarial loss: 0.354374\n",
      "epoch 101; iter: 0; batch classifier loss: 0.074124; batch adversarial loss: 0.368322\n",
      "epoch 102; iter: 0; batch classifier loss: 0.081265; batch adversarial loss: 0.407304\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036252; batch adversarial loss: 0.422455\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047621; batch adversarial loss: 0.414577\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057703; batch adversarial loss: 0.413652\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062002; batch adversarial loss: 0.443408\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065991; batch adversarial loss: 0.491055\n",
      "epoch 108; iter: 0; batch classifier loss: 0.066510; batch adversarial loss: 0.335475\n",
      "epoch 109; iter: 0; batch classifier loss: 0.071798; batch adversarial loss: 0.448906\n",
      "epoch 110; iter: 0; batch classifier loss: 0.065169; batch adversarial loss: 0.444032\n",
      "epoch 111; iter: 0; batch classifier loss: 0.077176; batch adversarial loss: 0.360924\n",
      "epoch 112; iter: 0; batch classifier loss: 0.064027; batch adversarial loss: 0.390183\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045911; batch adversarial loss: 0.381157\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046835; batch adversarial loss: 0.357822\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046828; batch adversarial loss: 0.472354\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056897; batch adversarial loss: 0.447812\n",
      "epoch 117; iter: 0; batch classifier loss: 0.065012; batch adversarial loss: 0.443006\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048851; batch adversarial loss: 0.414532\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053863; batch adversarial loss: 0.421107\n",
      "epoch 120; iter: 0; batch classifier loss: 0.069346; batch adversarial loss: 0.385085\n",
      "epoch 121; iter: 0; batch classifier loss: 0.061674; batch adversarial loss: 0.391654\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036328; batch adversarial loss: 0.350626\n",
      "epoch 123; iter: 0; batch classifier loss: 0.080256; batch adversarial loss: 0.383294\n",
      "epoch 124; iter: 0; batch classifier loss: 0.071388; batch adversarial loss: 0.365766\n",
      "epoch 125; iter: 0; batch classifier loss: 0.059037; batch adversarial loss: 0.506596\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030779; batch adversarial loss: 0.363441\n",
      "epoch 127; iter: 0; batch classifier loss: 0.064902; batch adversarial loss: 0.447067\n",
      "epoch 128; iter: 0; batch classifier loss: 0.064220; batch adversarial loss: 0.499256\n",
      "epoch 129; iter: 0; batch classifier loss: 0.061080; batch adversarial loss: 0.459336\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051656; batch adversarial loss: 0.413539\n",
      "epoch 131; iter: 0; batch classifier loss: 0.071434; batch adversarial loss: 0.431794\n",
      "epoch 132; iter: 0; batch classifier loss: 0.049173; batch adversarial loss: 0.461509\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060706; batch adversarial loss: 0.556740\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053099; batch adversarial loss: 0.312254\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051467; batch adversarial loss: 0.440447\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056230; batch adversarial loss: 0.381889\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041797; batch adversarial loss: 0.391296\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036173; batch adversarial loss: 0.390878\n",
      "epoch 139; iter: 0; batch classifier loss: 0.067490; batch adversarial loss: 0.387198\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040254; batch adversarial loss: 0.392214\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042718; batch adversarial loss: 0.378772\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027755; batch adversarial loss: 0.527537\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037571; batch adversarial loss: 0.379205\n",
      "epoch 144; iter: 0; batch classifier loss: 0.081289; batch adversarial loss: 0.532169\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041721; batch adversarial loss: 0.463484\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037707; batch adversarial loss: 0.381517\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046466; batch adversarial loss: 0.443355\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042224; batch adversarial loss: 0.488534\n",
      "epoch 149; iter: 0; batch classifier loss: 0.051861; batch adversarial loss: 0.360529\n",
      "epoch 150; iter: 0; batch classifier loss: 0.072418; batch adversarial loss: 0.382147\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031220; batch adversarial loss: 0.395979\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035938; batch adversarial loss: 0.455828\n",
      "epoch 153; iter: 0; batch classifier loss: 0.051780; batch adversarial loss: 0.311984\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039125; batch adversarial loss: 0.337209\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035144; batch adversarial loss: 0.364868\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035960; batch adversarial loss: 0.380906\n",
      "epoch 157; iter: 0; batch classifier loss: 0.058094; batch adversarial loss: 0.416946\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023445; batch adversarial loss: 0.481138\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027002; batch adversarial loss: 0.317488\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027820; batch adversarial loss: 0.383315\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013069; batch adversarial loss: 0.483458\n",
      "epoch 162; iter: 0; batch classifier loss: 0.056505; batch adversarial loss: 0.360122\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029041; batch adversarial loss: 0.424913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.049516; batch adversarial loss: 0.476895\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022021; batch adversarial loss: 0.442732\n",
      "epoch 166; iter: 0; batch classifier loss: 0.041605; batch adversarial loss: 0.463632\n",
      "epoch 167; iter: 0; batch classifier loss: 0.058556; batch adversarial loss: 0.424179\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019029; batch adversarial loss: 0.422846\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040968; batch adversarial loss: 0.429410\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025043; batch adversarial loss: 0.435334\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025725; batch adversarial loss: 0.471511\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022070; batch adversarial loss: 0.527752\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040183; batch adversarial loss: 0.408885\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033142; batch adversarial loss: 0.485563\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033693; batch adversarial loss: 0.414543\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021784; batch adversarial loss: 0.535283\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023560; batch adversarial loss: 0.478107\n",
      "epoch 178; iter: 0; batch classifier loss: 0.057449; batch adversarial loss: 0.468303\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010842; batch adversarial loss: 0.446891\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037143; batch adversarial loss: 0.463814\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026431; batch adversarial loss: 0.386205\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026816; batch adversarial loss: 0.493767\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017573; batch adversarial loss: 0.441856\n",
      "epoch 184; iter: 0; batch classifier loss: 0.084493; batch adversarial loss: 0.438483\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021389; batch adversarial loss: 0.482919\n",
      "epoch 186; iter: 0; batch classifier loss: 0.063080; batch adversarial loss: 0.489111\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027105; batch adversarial loss: 0.494332\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040792; batch adversarial loss: 0.470601\n",
      "epoch 189; iter: 0; batch classifier loss: 0.060411; batch adversarial loss: 0.561888\n",
      "epoch 190; iter: 0; batch classifier loss: 0.086349; batch adversarial loss: 0.586511\n",
      "epoch 191; iter: 0; batch classifier loss: 0.114905; batch adversarial loss: 0.739582\n",
      "epoch 192; iter: 0; batch classifier loss: 0.085690; batch adversarial loss: 0.524057\n",
      "epoch 193; iter: 0; batch classifier loss: 0.084035; batch adversarial loss: 0.642003\n",
      "epoch 194; iter: 0; batch classifier loss: 0.105171; batch adversarial loss: 0.717498\n",
      "epoch 195; iter: 0; batch classifier loss: 0.140465; batch adversarial loss: 0.676999\n",
      "epoch 196; iter: 0; batch classifier loss: 0.107010; batch adversarial loss: 0.656908\n",
      "epoch 197; iter: 0; batch classifier loss: 0.096080; batch adversarial loss: 0.554293\n",
      "epoch 198; iter: 0; batch classifier loss: 0.069672; batch adversarial loss: 0.545743\n",
      "epoch 199; iter: 0; batch classifier loss: 0.091654; batch adversarial loss: 0.524003\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693724; batch adversarial loss: 0.575781\n",
      "epoch 1; iter: 0; batch classifier loss: 0.423146; batch adversarial loss: 0.598626\n",
      "epoch 2; iter: 0; batch classifier loss: 0.410931; batch adversarial loss: 0.574973\n",
      "epoch 3; iter: 0; batch classifier loss: 0.406458; batch adversarial loss: 0.593315\n",
      "epoch 4; iter: 0; batch classifier loss: 0.407745; batch adversarial loss: 0.564092\n",
      "epoch 5; iter: 0; batch classifier loss: 0.423312; batch adversarial loss: 0.598254\n",
      "epoch 6; iter: 0; batch classifier loss: 0.318345; batch adversarial loss: 0.590391\n",
      "epoch 7; iter: 0; batch classifier loss: 0.350815; batch adversarial loss: 0.536486\n",
      "epoch 8; iter: 0; batch classifier loss: 0.451206; batch adversarial loss: 0.572679\n",
      "epoch 9; iter: 0; batch classifier loss: 0.465890; batch adversarial loss: 0.575278\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503923; batch adversarial loss: 0.537059\n",
      "epoch 11; iter: 0; batch classifier loss: 0.718303; batch adversarial loss: 0.524086\n",
      "epoch 12; iter: 0; batch classifier loss: 0.701134; batch adversarial loss: 0.504901\n",
      "epoch 13; iter: 0; batch classifier loss: 0.443957; batch adversarial loss: 0.475282\n",
      "epoch 14; iter: 0; batch classifier loss: 0.382100; batch adversarial loss: 0.523395\n",
      "epoch 15; iter: 0; batch classifier loss: 0.316870; batch adversarial loss: 0.499768\n",
      "epoch 16; iter: 0; batch classifier loss: 0.239004; batch adversarial loss: 0.471301\n",
      "epoch 17; iter: 0; batch classifier loss: 0.220418; batch adversarial loss: 0.488142\n",
      "epoch 18; iter: 0; batch classifier loss: 0.194136; batch adversarial loss: 0.521689\n",
      "epoch 19; iter: 0; batch classifier loss: 0.298292; batch adversarial loss: 0.466934\n",
      "epoch 20; iter: 0; batch classifier loss: 0.277619; batch adversarial loss: 0.441192\n",
      "epoch 21; iter: 0; batch classifier loss: 0.261071; batch adversarial loss: 0.464458\n",
      "epoch 22; iter: 0; batch classifier loss: 0.230524; batch adversarial loss: 0.419150\n",
      "epoch 23; iter: 0; batch classifier loss: 0.186705; batch adversarial loss: 0.492601\n",
      "epoch 24; iter: 0; batch classifier loss: 0.238126; batch adversarial loss: 0.415612\n",
      "epoch 25; iter: 0; batch classifier loss: 0.147669; batch adversarial loss: 0.451048\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194605; batch adversarial loss: 0.433338\n",
      "epoch 27; iter: 0; batch classifier loss: 0.203726; batch adversarial loss: 0.479426\n",
      "epoch 28; iter: 0; batch classifier loss: 0.158397; batch adversarial loss: 0.467502\n",
      "epoch 29; iter: 0; batch classifier loss: 0.223464; batch adversarial loss: 0.344350\n",
      "epoch 30; iter: 0; batch classifier loss: 0.177516; batch adversarial loss: 0.429165\n",
      "epoch 31; iter: 0; batch classifier loss: 0.177583; batch adversarial loss: 0.475076\n",
      "epoch 32; iter: 0; batch classifier loss: 0.183255; batch adversarial loss: 0.430431\n",
      "epoch 33; iter: 0; batch classifier loss: 0.175772; batch adversarial loss: 0.455405\n",
      "epoch 34; iter: 0; batch classifier loss: 0.191730; batch adversarial loss: 0.369679\n",
      "epoch 35; iter: 0; batch classifier loss: 0.192698; batch adversarial loss: 0.492909\n",
      "epoch 36; iter: 0; batch classifier loss: 0.249955; batch adversarial loss: 0.364631\n",
      "epoch 37; iter: 0; batch classifier loss: 0.188457; batch adversarial loss: 0.397451\n",
      "epoch 38; iter: 0; batch classifier loss: 0.183561; batch adversarial loss: 0.462747\n",
      "epoch 39; iter: 0; batch classifier loss: 0.249463; batch adversarial loss: 0.420116\n",
      "epoch 40; iter: 0; batch classifier loss: 0.163819; batch adversarial loss: 0.475789\n",
      "epoch 41; iter: 0; batch classifier loss: 0.218486; batch adversarial loss: 0.440531\n",
      "epoch 42; iter: 0; batch classifier loss: 0.195481; batch adversarial loss: 0.515249\n",
      "epoch 43; iter: 0; batch classifier loss: 0.257878; batch adversarial loss: 0.448477\n",
      "epoch 44; iter: 0; batch classifier loss: 0.167912; batch adversarial loss: 0.388719\n",
      "epoch 45; iter: 0; batch classifier loss: 0.175666; batch adversarial loss: 0.424306\n",
      "epoch 46; iter: 0; batch classifier loss: 0.179824; batch adversarial loss: 0.430345\n",
      "epoch 47; iter: 0; batch classifier loss: 0.282121; batch adversarial loss: 0.440762\n",
      "epoch 48; iter: 0; batch classifier loss: 0.229998; batch adversarial loss: 0.504216\n",
      "epoch 49; iter: 0; batch classifier loss: 0.242747; batch adversarial loss: 0.370974\n",
      "epoch 50; iter: 0; batch classifier loss: 0.196612; batch adversarial loss: 0.490552\n",
      "epoch 51; iter: 0; batch classifier loss: 0.218411; batch adversarial loss: 0.476951\n",
      "epoch 52; iter: 0; batch classifier loss: 0.154016; batch adversarial loss: 0.448502\n",
      "epoch 53; iter: 0; batch classifier loss: 0.161040; batch adversarial loss: 0.471942\n",
      "epoch 54; iter: 0; batch classifier loss: 0.156771; batch adversarial loss: 0.492945\n",
      "epoch 55; iter: 0; batch classifier loss: 0.182222; batch adversarial loss: 0.457978\n",
      "epoch 56; iter: 0; batch classifier loss: 0.250961; batch adversarial loss: 0.523241\n",
      "epoch 57; iter: 0; batch classifier loss: 0.192991; batch adversarial loss: 0.434923\n",
      "epoch 58; iter: 0; batch classifier loss: 0.297831; batch adversarial loss: 0.433668\n",
      "epoch 59; iter: 0; batch classifier loss: 0.240866; batch adversarial loss: 0.396902\n",
      "epoch 60; iter: 0; batch classifier loss: 0.213093; batch adversarial loss: 0.409449\n",
      "epoch 61; iter: 0; batch classifier loss: 0.232705; batch adversarial loss: 0.459044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.232270; batch adversarial loss: 0.496326\n",
      "epoch 63; iter: 0; batch classifier loss: 0.185102; batch adversarial loss: 0.508441\n",
      "epoch 64; iter: 0; batch classifier loss: 0.167486; batch adversarial loss: 0.433472\n",
      "epoch 65; iter: 0; batch classifier loss: 0.225654; batch adversarial loss: 0.472616\n",
      "epoch 66; iter: 0; batch classifier loss: 0.167260; batch adversarial loss: 0.446871\n",
      "epoch 67; iter: 0; batch classifier loss: 0.194635; batch adversarial loss: 0.608406\n",
      "epoch 68; iter: 0; batch classifier loss: 0.195210; batch adversarial loss: 0.533816\n",
      "epoch 69; iter: 0; batch classifier loss: 0.121958; batch adversarial loss: 0.433708\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090352; batch adversarial loss: 0.433944\n",
      "epoch 71; iter: 0; batch classifier loss: 0.219159; batch adversarial loss: 0.407422\n",
      "epoch 72; iter: 0; batch classifier loss: 0.313300; batch adversarial loss: 0.435381\n",
      "epoch 73; iter: 0; batch classifier loss: 0.182727; batch adversarial loss: 0.509360\n",
      "epoch 74; iter: 0; batch classifier loss: 0.196992; batch adversarial loss: 0.434052\n",
      "epoch 75; iter: 0; batch classifier loss: 0.211634; batch adversarial loss: 0.407769\n",
      "epoch 76; iter: 0; batch classifier loss: 0.263538; batch adversarial loss: 0.384236\n",
      "epoch 77; iter: 0; batch classifier loss: 0.181123; batch adversarial loss: 0.408975\n",
      "epoch 78; iter: 0; batch classifier loss: 0.128945; batch adversarial loss: 0.521140\n",
      "epoch 79; iter: 0; batch classifier loss: 0.231117; batch adversarial loss: 0.421493\n",
      "epoch 80; iter: 0; batch classifier loss: 0.082785; batch adversarial loss: 0.558427\n",
      "epoch 81; iter: 0; batch classifier loss: 0.077040; batch adversarial loss: 0.519321\n",
      "epoch 82; iter: 0; batch classifier loss: 0.082808; batch adversarial loss: 0.505808\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061777; batch adversarial loss: 0.469130\n",
      "epoch 84; iter: 0; batch classifier loss: 0.047060; batch adversarial loss: 0.447387\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084915; batch adversarial loss: 0.421513\n",
      "epoch 86; iter: 0; batch classifier loss: 0.060314; batch adversarial loss: 0.384199\n",
      "epoch 87; iter: 0; batch classifier loss: 0.040350; batch adversarial loss: 0.493711\n",
      "epoch 88; iter: 0; batch classifier loss: 0.071834; batch adversarial loss: 0.444775\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059541; batch adversarial loss: 0.428393\n",
      "epoch 90; iter: 0; batch classifier loss: 0.070893; batch adversarial loss: 0.406169\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046841; batch adversarial loss: 0.388326\n",
      "epoch 92; iter: 0; batch classifier loss: 0.089991; batch adversarial loss: 0.334728\n",
      "epoch 93; iter: 0; batch classifier loss: 0.034395; batch adversarial loss: 0.360186\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061822; batch adversarial loss: 0.426271\n",
      "epoch 95; iter: 0; batch classifier loss: 0.040853; batch adversarial loss: 0.468054\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047799; batch adversarial loss: 0.469815\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059350; batch adversarial loss: 0.432888\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062362; batch adversarial loss: 0.344528\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054616; batch adversarial loss: 0.436656\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050926; batch adversarial loss: 0.468889\n",
      "epoch 101; iter: 0; batch classifier loss: 0.038691; batch adversarial loss: 0.451512\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042154; batch adversarial loss: 0.445752\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032890; batch adversarial loss: 0.418013\n",
      "epoch 104; iter: 0; batch classifier loss: 0.088694; batch adversarial loss: 0.471704\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029652; batch adversarial loss: 0.395979\n",
      "epoch 106; iter: 0; batch classifier loss: 0.012797; batch adversarial loss: 0.410831\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028501; batch adversarial loss: 0.433787\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048228; batch adversarial loss: 0.340803\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043648; batch adversarial loss: 0.396640\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040403; batch adversarial loss: 0.424404\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033621; batch adversarial loss: 0.442750\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039341; batch adversarial loss: 0.407580\n",
      "epoch 113; iter: 0; batch classifier loss: 0.061623; batch adversarial loss: 0.434154\n",
      "epoch 114; iter: 0; batch classifier loss: 0.064262; batch adversarial loss: 0.482031\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033128; batch adversarial loss: 0.479625\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035335; batch adversarial loss: 0.437101\n",
      "epoch 117; iter: 0; batch classifier loss: 0.075081; batch adversarial loss: 0.463787\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046384; batch adversarial loss: 0.478357\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037182; batch adversarial loss: 0.431528\n",
      "epoch 120; iter: 0; batch classifier loss: 0.061858; batch adversarial loss: 0.405401\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033674; batch adversarial loss: 0.454652\n",
      "epoch 122; iter: 0; batch classifier loss: 0.021656; batch adversarial loss: 0.493425\n",
      "epoch 123; iter: 0; batch classifier loss: 0.084580; batch adversarial loss: 0.534746\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055427; batch adversarial loss: 0.516125\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029769; batch adversarial loss: 0.360309\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031613; batch adversarial loss: 0.449150\n",
      "epoch 127; iter: 0; batch classifier loss: 0.049406; batch adversarial loss: 0.391331\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037649; batch adversarial loss: 0.453503\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025614; batch adversarial loss: 0.413871\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031876; batch adversarial loss: 0.485758\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047037; batch adversarial loss: 0.420597\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039004; batch adversarial loss: 0.389177\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015460; batch adversarial loss: 0.441752\n",
      "epoch 134; iter: 0; batch classifier loss: 0.017233; batch adversarial loss: 0.451966\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024575; batch adversarial loss: 0.461449\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049915; batch adversarial loss: 0.498642\n",
      "epoch 137; iter: 0; batch classifier loss: 0.019889; batch adversarial loss: 0.434064\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036964; batch adversarial loss: 0.325200\n",
      "epoch 139; iter: 0; batch classifier loss: 0.054511; batch adversarial loss: 0.389224\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028814; batch adversarial loss: 0.442512\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026579; batch adversarial loss: 0.467893\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024857; batch adversarial loss: 0.511941\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031568; batch adversarial loss: 0.421696\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017336; batch adversarial loss: 0.373725\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026131; batch adversarial loss: 0.433262\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029902; batch adversarial loss: 0.399238\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024143; batch adversarial loss: 0.515648\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040317; batch adversarial loss: 0.404932\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037140; batch adversarial loss: 0.415600\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012108; batch adversarial loss: 0.410166\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025304; batch adversarial loss: 0.361141\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018351; batch adversarial loss: 0.497831\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020957; batch adversarial loss: 0.378819\n",
      "epoch 154; iter: 0; batch classifier loss: 0.005871; batch adversarial loss: 0.437495\n",
      "epoch 155; iter: 0; batch classifier loss: 0.039624; batch adversarial loss: 0.423593\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036648; batch adversarial loss: 0.492909\n",
      "epoch 157; iter: 0; batch classifier loss: 0.044995; batch adversarial loss: 0.454657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.025298; batch adversarial loss: 0.440964\n",
      "epoch 159; iter: 0; batch classifier loss: 0.006511; batch adversarial loss: 0.459287\n",
      "epoch 160; iter: 0; batch classifier loss: 0.006642; batch adversarial loss: 0.447531\n",
      "epoch 161; iter: 0; batch classifier loss: 0.005952; batch adversarial loss: 0.422541\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028163; batch adversarial loss: 0.448416\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009125; batch adversarial loss: 0.435162\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029889; batch adversarial loss: 0.448950\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009642; batch adversarial loss: 0.399624\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030938; batch adversarial loss: 0.479489\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024262; batch adversarial loss: 0.380422\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012506; batch adversarial loss: 0.465772\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044783; batch adversarial loss: 0.421337\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018796; batch adversarial loss: 0.414193\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016880; batch adversarial loss: 0.351456\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040334; batch adversarial loss: 0.474318\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012311; batch adversarial loss: 0.447231\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013187; batch adversarial loss: 0.516330\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023067; batch adversarial loss: 0.527130\n",
      "epoch 176; iter: 0; batch classifier loss: 0.004068; batch adversarial loss: 0.434483\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038521; batch adversarial loss: 0.367983\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010129; batch adversarial loss: 0.541458\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011677; batch adversarial loss: 0.347245\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010011; batch adversarial loss: 0.461140\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022052; batch adversarial loss: 0.357384\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030666; batch adversarial loss: 0.503106\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031776; batch adversarial loss: 0.485831\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013699; batch adversarial loss: 0.461554\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010906; batch adversarial loss: 0.347143\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026695; batch adversarial loss: 0.426441\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020622; batch adversarial loss: 0.388752\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023666; batch adversarial loss: 0.438830\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012871; batch adversarial loss: 0.494891\n",
      "epoch 190; iter: 0; batch classifier loss: 0.033549; batch adversarial loss: 0.517504\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020424; batch adversarial loss: 0.453609\n",
      "epoch 192; iter: 0; batch classifier loss: 0.069159; batch adversarial loss: 0.446036\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009296; batch adversarial loss: 0.389909\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018551; batch adversarial loss: 0.465503\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011578; batch adversarial loss: 0.478994\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023897; batch adversarial loss: 0.353706\n",
      "epoch 197; iter: 0; batch classifier loss: 0.042928; batch adversarial loss: 0.489875\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032617; batch adversarial loss: 0.431426\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011326; batch adversarial loss: 0.435477\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708588; batch adversarial loss: 0.994304\n",
      "epoch 1; iter: 0; batch classifier loss: 0.619430; batch adversarial loss: 1.075978\n",
      "epoch 2; iter: 0; batch classifier loss: 0.782140; batch adversarial loss: 1.087461\n",
      "epoch 3; iter: 0; batch classifier loss: 0.840794; batch adversarial loss: 0.997083\n",
      "epoch 4; iter: 0; batch classifier loss: 0.861719; batch adversarial loss: 0.910047\n",
      "epoch 5; iter: 0; batch classifier loss: 0.980805; batch adversarial loss: 0.819815\n",
      "epoch 6; iter: 0; batch classifier loss: 0.874673; batch adversarial loss: 0.749084\n",
      "epoch 7; iter: 0; batch classifier loss: 0.803500; batch adversarial loss: 0.669954\n",
      "epoch 8; iter: 0; batch classifier loss: 0.804745; batch adversarial loss: 0.631275\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554940; batch adversarial loss: 0.582095\n",
      "epoch 10; iter: 0; batch classifier loss: 0.281798; batch adversarial loss: 0.564645\n",
      "epoch 11; iter: 0; batch classifier loss: 0.286948; batch adversarial loss: 0.522131\n",
      "epoch 12; iter: 0; batch classifier loss: 0.247280; batch adversarial loss: 0.518152\n",
      "epoch 13; iter: 0; batch classifier loss: 0.281773; batch adversarial loss: 0.518876\n",
      "epoch 14; iter: 0; batch classifier loss: 0.229402; batch adversarial loss: 0.484056\n",
      "epoch 15; iter: 0; batch classifier loss: 0.235169; batch adversarial loss: 0.525971\n",
      "epoch 16; iter: 0; batch classifier loss: 0.243833; batch adversarial loss: 0.438493\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269625; batch adversarial loss: 0.476667\n",
      "epoch 18; iter: 0; batch classifier loss: 0.226728; batch adversarial loss: 0.491799\n",
      "epoch 19; iter: 0; batch classifier loss: 0.170962; batch adversarial loss: 0.523915\n",
      "epoch 20; iter: 0; batch classifier loss: 0.183851; batch adversarial loss: 0.482191\n",
      "epoch 21; iter: 0; batch classifier loss: 0.162518; batch adversarial loss: 0.414682\n",
      "epoch 22; iter: 0; batch classifier loss: 0.169566; batch adversarial loss: 0.494385\n",
      "epoch 23; iter: 0; batch classifier loss: 0.132031; batch adversarial loss: 0.439943\n",
      "epoch 24; iter: 0; batch classifier loss: 0.095695; batch adversarial loss: 0.511173\n",
      "epoch 25; iter: 0; batch classifier loss: 0.121907; batch adversarial loss: 0.467563\n",
      "epoch 26; iter: 0; batch classifier loss: 0.093623; batch adversarial loss: 0.521440\n",
      "epoch 27; iter: 0; batch classifier loss: 0.139910; batch adversarial loss: 0.469990\n",
      "epoch 28; iter: 0; batch classifier loss: 0.072117; batch adversarial loss: 0.379520\n",
      "epoch 29; iter: 0; batch classifier loss: 0.130886; batch adversarial loss: 0.467653\n",
      "epoch 30; iter: 0; batch classifier loss: 0.091283; batch adversarial loss: 0.399218\n",
      "epoch 31; iter: 0; batch classifier loss: 0.049187; batch adversarial loss: 0.512116\n",
      "epoch 32; iter: 0; batch classifier loss: 0.084363; batch adversarial loss: 0.456376\n",
      "epoch 33; iter: 0; batch classifier loss: 0.064682; batch adversarial loss: 0.460109\n",
      "epoch 34; iter: 0; batch classifier loss: 0.116882; batch adversarial loss: 0.401795\n",
      "epoch 35; iter: 0; batch classifier loss: 0.117177; batch adversarial loss: 0.487257\n",
      "epoch 36; iter: 0; batch classifier loss: 0.089442; batch adversarial loss: 0.453975\n",
      "epoch 37; iter: 0; batch classifier loss: 0.122402; batch adversarial loss: 0.526782\n",
      "epoch 38; iter: 0; batch classifier loss: 0.077997; batch adversarial loss: 0.445285\n",
      "epoch 39; iter: 0; batch classifier loss: 0.066094; batch adversarial loss: 0.420163\n",
      "epoch 40; iter: 0; batch classifier loss: 0.071224; batch adversarial loss: 0.526284\n",
      "epoch 41; iter: 0; batch classifier loss: 0.057697; batch adversarial loss: 0.451705\n",
      "epoch 42; iter: 0; batch classifier loss: 0.043731; batch adversarial loss: 0.369619\n",
      "epoch 43; iter: 0; batch classifier loss: 0.072418; batch adversarial loss: 0.403968\n",
      "epoch 44; iter: 0; batch classifier loss: 0.096219; batch adversarial loss: 0.354292\n",
      "epoch 45; iter: 0; batch classifier loss: 0.081129; batch adversarial loss: 0.384162\n",
      "epoch 46; iter: 0; batch classifier loss: 0.064393; batch adversarial loss: 0.459173\n",
      "epoch 47; iter: 0; batch classifier loss: 0.093164; batch adversarial loss: 0.418442\n",
      "epoch 48; iter: 0; batch classifier loss: 0.116644; batch adversarial loss: 0.423547\n",
      "epoch 49; iter: 0; batch classifier loss: 0.054362; batch adversarial loss: 0.370166\n",
      "epoch 50; iter: 0; batch classifier loss: 0.126662; batch adversarial loss: 0.523096\n",
      "epoch 51; iter: 0; batch classifier loss: 0.112070; batch adversarial loss: 0.420856\n",
      "epoch 52; iter: 0; batch classifier loss: 0.063773; batch adversarial loss: 0.402164\n",
      "epoch 53; iter: 0; batch classifier loss: 0.065016; batch adversarial loss: 0.484010\n",
      "epoch 54; iter: 0; batch classifier loss: 0.051363; batch adversarial loss: 0.465043\n",
      "epoch 55; iter: 0; batch classifier loss: 0.058054; batch adversarial loss: 0.358245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.075226; batch adversarial loss: 0.403857\n",
      "epoch 57; iter: 0; batch classifier loss: 0.063217; batch adversarial loss: 0.414833\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097242; batch adversarial loss: 0.412505\n",
      "epoch 59; iter: 0; batch classifier loss: 0.078859; batch adversarial loss: 0.413365\n",
      "epoch 60; iter: 0; batch classifier loss: 0.092658; batch adversarial loss: 0.461466\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078503; batch adversarial loss: 0.463319\n",
      "epoch 62; iter: 0; batch classifier loss: 0.058528; batch adversarial loss: 0.360536\n",
      "epoch 63; iter: 0; batch classifier loss: 0.039289; batch adversarial loss: 0.433484\n",
      "epoch 64; iter: 0; batch classifier loss: 0.096731; batch adversarial loss: 0.420671\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075028; batch adversarial loss: 0.405801\n",
      "epoch 66; iter: 0; batch classifier loss: 0.024336; batch adversarial loss: 0.439137\n",
      "epoch 67; iter: 0; batch classifier loss: 0.040193; batch adversarial loss: 0.375921\n",
      "epoch 68; iter: 0; batch classifier loss: 0.043647; batch adversarial loss: 0.343017\n",
      "epoch 69; iter: 0; batch classifier loss: 0.058580; batch adversarial loss: 0.408299\n",
      "epoch 70; iter: 0; batch classifier loss: 0.033261; batch adversarial loss: 0.473337\n",
      "epoch 71; iter: 0; batch classifier loss: 0.075435; batch adversarial loss: 0.432655\n",
      "epoch 72; iter: 0; batch classifier loss: 0.044764; batch adversarial loss: 0.513800\n",
      "epoch 73; iter: 0; batch classifier loss: 0.034889; batch adversarial loss: 0.368492\n",
      "epoch 74; iter: 0; batch classifier loss: 0.058329; batch adversarial loss: 0.317755\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059879; batch adversarial loss: 0.372656\n",
      "epoch 76; iter: 0; batch classifier loss: 0.040005; batch adversarial loss: 0.431353\n",
      "epoch 77; iter: 0; batch classifier loss: 0.039825; batch adversarial loss: 0.538178\n",
      "epoch 78; iter: 0; batch classifier loss: 0.033895; batch adversarial loss: 0.321276\n",
      "epoch 79; iter: 0; batch classifier loss: 0.040174; batch adversarial loss: 0.398529\n",
      "epoch 80; iter: 0; batch classifier loss: 0.027164; batch adversarial loss: 0.441889\n",
      "epoch 81; iter: 0; batch classifier loss: 0.030049; batch adversarial loss: 0.491240\n",
      "epoch 82; iter: 0; batch classifier loss: 0.028079; batch adversarial loss: 0.492856\n",
      "epoch 83; iter: 0; batch classifier loss: 0.045331; batch adversarial loss: 0.487354\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082420; batch adversarial loss: 0.432244\n",
      "epoch 85; iter: 0; batch classifier loss: 0.038104; batch adversarial loss: 0.473135\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054493; batch adversarial loss: 0.482923\n",
      "epoch 87; iter: 0; batch classifier loss: 0.035057; batch adversarial loss: 0.482132\n",
      "epoch 88; iter: 0; batch classifier loss: 0.033868; batch adversarial loss: 0.544980\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052191; batch adversarial loss: 0.339788\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039504; batch adversarial loss: 0.480683\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056255; batch adversarial loss: 0.416272\n",
      "epoch 92; iter: 0; batch classifier loss: 0.042539; batch adversarial loss: 0.411436\n",
      "epoch 93; iter: 0; batch classifier loss: 0.030546; batch adversarial loss: 0.387724\n",
      "epoch 94; iter: 0; batch classifier loss: 0.074256; batch adversarial loss: 0.417876\n",
      "epoch 95; iter: 0; batch classifier loss: 0.032182; batch adversarial loss: 0.394042\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043243; batch adversarial loss: 0.487539\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057613; batch adversarial loss: 0.390712\n",
      "epoch 98; iter: 0; batch classifier loss: 0.024025; batch adversarial loss: 0.413119\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043483; batch adversarial loss: 0.549163\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047067; batch adversarial loss: 0.415813\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057066; batch adversarial loss: 0.468198\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044841; batch adversarial loss: 0.406588\n",
      "epoch 103; iter: 0; batch classifier loss: 0.018114; batch adversarial loss: 0.484292\n",
      "epoch 104; iter: 0; batch classifier loss: 0.042795; batch adversarial loss: 0.448012\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057422; batch adversarial loss: 0.459083\n",
      "epoch 106; iter: 0; batch classifier loss: 0.048042; batch adversarial loss: 0.399039\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046250; batch adversarial loss: 0.419149\n",
      "epoch 108; iter: 0; batch classifier loss: 0.031931; batch adversarial loss: 0.426459\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060277; batch adversarial loss: 0.365131\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031358; batch adversarial loss: 0.463517\n",
      "epoch 111; iter: 0; batch classifier loss: 0.019138; batch adversarial loss: 0.455933\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042479; batch adversarial loss: 0.463315\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039278; batch adversarial loss: 0.437787\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054652; batch adversarial loss: 0.499130\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022117; batch adversarial loss: 0.526964\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027426; batch adversarial loss: 0.422459\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060209; batch adversarial loss: 0.336101\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024873; batch adversarial loss: 0.422671\n",
      "epoch 119; iter: 0; batch classifier loss: 0.061505; batch adversarial loss: 0.419878\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049868; batch adversarial loss: 0.459218\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042530; batch adversarial loss: 0.416706\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028593; batch adversarial loss: 0.413185\n",
      "epoch 123; iter: 0; batch classifier loss: 0.012101; batch adversarial loss: 0.441867\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039022; batch adversarial loss: 0.363440\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057440; batch adversarial loss: 0.442109\n",
      "epoch 126; iter: 0; batch classifier loss: 0.018791; batch adversarial loss: 0.520314\n",
      "epoch 127; iter: 0; batch classifier loss: 0.012920; batch adversarial loss: 0.542060\n",
      "epoch 128; iter: 0; batch classifier loss: 0.020184; batch adversarial loss: 0.468070\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022008; batch adversarial loss: 0.380266\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026190; batch adversarial loss: 0.384452\n",
      "epoch 131; iter: 0; batch classifier loss: 0.080724; batch adversarial loss: 0.354686\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051226; batch adversarial loss: 0.303406\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023657; batch adversarial loss: 0.309768\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027836; batch adversarial loss: 0.449830\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011180; batch adversarial loss: 0.469057\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016082; batch adversarial loss: 0.475906\n",
      "epoch 137; iter: 0; batch classifier loss: 0.014611; batch adversarial loss: 0.408933\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026259; batch adversarial loss: 0.428903\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019820; batch adversarial loss: 0.327567\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035304; batch adversarial loss: 0.500267\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040683; batch adversarial loss: 0.479203\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049223; batch adversarial loss: 0.457253\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043040; batch adversarial loss: 0.403506\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020081; batch adversarial loss: 0.419291\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022081; batch adversarial loss: 0.416508\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029368; batch adversarial loss: 0.321020\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017929; batch adversarial loss: 0.427963\n",
      "epoch 148; iter: 0; batch classifier loss: 0.043450; batch adversarial loss: 0.478116\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025943; batch adversarial loss: 0.549416\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022136; batch adversarial loss: 0.386818\n",
      "epoch 151; iter: 0; batch classifier loss: 0.054171; batch adversarial loss: 0.421340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.037749; batch adversarial loss: 0.424674\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014376; batch adversarial loss: 0.479623\n",
      "epoch 154; iter: 0; batch classifier loss: 0.050018; batch adversarial loss: 0.351390\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011698; batch adversarial loss: 0.591860\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015211; batch adversarial loss: 0.398827\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025461; batch adversarial loss: 0.465483\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011869; batch adversarial loss: 0.459485\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025622; batch adversarial loss: 0.402984\n",
      "epoch 160; iter: 0; batch classifier loss: 0.054504; batch adversarial loss: 0.419774\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031684; batch adversarial loss: 0.451641\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014455; batch adversarial loss: 0.444858\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011258; batch adversarial loss: 0.477188\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016340; batch adversarial loss: 0.330615\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013426; batch adversarial loss: 0.482386\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018891; batch adversarial loss: 0.382724\n",
      "epoch 167; iter: 0; batch classifier loss: 0.005538; batch adversarial loss: 0.437524\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018076; batch adversarial loss: 0.417098\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020564; batch adversarial loss: 0.395430\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022782; batch adversarial loss: 0.385388\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019415; batch adversarial loss: 0.411053\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026881; batch adversarial loss: 0.448619\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012738; batch adversarial loss: 0.504381\n",
      "epoch 174; iter: 0; batch classifier loss: 0.043184; batch adversarial loss: 0.506754\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016918; batch adversarial loss: 0.492054\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045296; batch adversarial loss: 0.374600\n",
      "epoch 177; iter: 0; batch classifier loss: 0.043331; batch adversarial loss: 0.500433\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039841; batch adversarial loss: 0.413564\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027049; batch adversarial loss: 0.352544\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010701; batch adversarial loss: 0.367429\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025937; batch adversarial loss: 0.545202\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019124; batch adversarial loss: 0.394440\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025514; batch adversarial loss: 0.443680\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017652; batch adversarial loss: 0.460809\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023075; batch adversarial loss: 0.497304\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018312; batch adversarial loss: 0.359288\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014882; batch adversarial loss: 0.395276\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009259; batch adversarial loss: 0.459460\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017486; batch adversarial loss: 0.458508\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019447; batch adversarial loss: 0.422907\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033095; batch adversarial loss: 0.417600\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025347; batch adversarial loss: 0.459807\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009586; batch adversarial loss: 0.485957\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033566; batch adversarial loss: 0.420046\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004233; batch adversarial loss: 0.436029\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008991; batch adversarial loss: 0.398624\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027704; batch adversarial loss: 0.419914\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038549; batch adversarial loss: 0.435193\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020056; batch adversarial loss: 0.419531\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687211; batch adversarial loss: 0.690748\n",
      "epoch 1; iter: 0; batch classifier loss: 0.454561; batch adversarial loss: 0.673472\n",
      "epoch 2; iter: 0; batch classifier loss: 0.368284; batch adversarial loss: 0.635341\n",
      "epoch 3; iter: 0; batch classifier loss: 0.417580; batch adversarial loss: 0.587619\n",
      "epoch 4; iter: 0; batch classifier loss: 0.277961; batch adversarial loss: 0.561119\n",
      "epoch 5; iter: 0; batch classifier loss: 0.267386; batch adversarial loss: 0.582734\n",
      "epoch 6; iter: 0; batch classifier loss: 0.308798; batch adversarial loss: 0.498805\n",
      "epoch 7; iter: 0; batch classifier loss: 0.208161; batch adversarial loss: 0.535999\n",
      "epoch 8; iter: 0; batch classifier loss: 0.262539; batch adversarial loss: 0.494416\n",
      "epoch 9; iter: 0; batch classifier loss: 0.216362; batch adversarial loss: 0.477200\n",
      "epoch 10; iter: 0; batch classifier loss: 0.248182; batch adversarial loss: 0.487144\n",
      "epoch 11; iter: 0; batch classifier loss: 0.226611; batch adversarial loss: 0.462430\n",
      "epoch 12; iter: 0; batch classifier loss: 0.149662; batch adversarial loss: 0.435945\n",
      "epoch 13; iter: 0; batch classifier loss: 0.210216; batch adversarial loss: 0.470543\n",
      "epoch 14; iter: 0; batch classifier loss: 0.209285; batch adversarial loss: 0.482283\n",
      "epoch 15; iter: 0; batch classifier loss: 0.124375; batch adversarial loss: 0.505222\n",
      "epoch 16; iter: 0; batch classifier loss: 0.147919; batch adversarial loss: 0.495957\n",
      "epoch 17; iter: 0; batch classifier loss: 0.174158; batch adversarial loss: 0.529944\n",
      "epoch 18; iter: 0; batch classifier loss: 0.174940; batch adversarial loss: 0.465919\n",
      "epoch 19; iter: 0; batch classifier loss: 0.143294; batch adversarial loss: 0.430030\n",
      "epoch 20; iter: 0; batch classifier loss: 0.128433; batch adversarial loss: 0.468300\n",
      "epoch 21; iter: 0; batch classifier loss: 0.140661; batch adversarial loss: 0.492974\n",
      "epoch 22; iter: 0; batch classifier loss: 0.149892; batch adversarial loss: 0.532415\n",
      "epoch 23; iter: 0; batch classifier loss: 0.119145; batch adversarial loss: 0.500911\n",
      "epoch 24; iter: 0; batch classifier loss: 0.110460; batch adversarial loss: 0.417610\n",
      "epoch 25; iter: 0; batch classifier loss: 0.161929; batch adversarial loss: 0.467052\n",
      "epoch 26; iter: 0; batch classifier loss: 0.141012; batch adversarial loss: 0.528403\n",
      "epoch 27; iter: 0; batch classifier loss: 0.178706; batch adversarial loss: 0.553889\n",
      "epoch 28; iter: 0; batch classifier loss: 0.164330; batch adversarial loss: 0.533182\n",
      "epoch 29; iter: 0; batch classifier loss: 0.167002; batch adversarial loss: 0.507402\n",
      "epoch 30; iter: 0; batch classifier loss: 0.173748; batch adversarial loss: 0.458705\n",
      "epoch 31; iter: 0; batch classifier loss: 0.229628; batch adversarial loss: 0.583520\n",
      "epoch 32; iter: 0; batch classifier loss: 0.202922; batch adversarial loss: 0.488011\n",
      "epoch 33; iter: 0; batch classifier loss: 0.235776; batch adversarial loss: 0.463507\n",
      "epoch 34; iter: 0; batch classifier loss: 0.192889; batch adversarial loss: 0.461826\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129883; batch adversarial loss: 0.458732\n",
      "epoch 36; iter: 0; batch classifier loss: 0.159658; batch adversarial loss: 0.519677\n",
      "epoch 37; iter: 0; batch classifier loss: 0.230723; batch adversarial loss: 0.469097\n",
      "epoch 38; iter: 0; batch classifier loss: 0.217882; batch adversarial loss: 0.458594\n",
      "epoch 39; iter: 0; batch classifier loss: 0.168821; batch adversarial loss: 0.486563\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099625; batch adversarial loss: 0.392277\n",
      "epoch 41; iter: 0; batch classifier loss: 0.097128; batch adversarial loss: 0.428926\n",
      "epoch 42; iter: 0; batch classifier loss: 0.068150; batch adversarial loss: 0.423433\n",
      "epoch 43; iter: 0; batch classifier loss: 0.061908; batch adversarial loss: 0.382460\n",
      "epoch 44; iter: 0; batch classifier loss: 0.054740; batch adversarial loss: 0.475860\n",
      "epoch 45; iter: 0; batch classifier loss: 0.116289; batch adversarial loss: 0.460980\n",
      "epoch 46; iter: 0; batch classifier loss: 0.084578; batch adversarial loss: 0.475972\n",
      "epoch 47; iter: 0; batch classifier loss: 0.059801; batch adversarial loss: 0.487534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.086099; batch adversarial loss: 0.512404\n",
      "epoch 49; iter: 0; batch classifier loss: 0.100840; batch adversarial loss: 0.515708\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096746; batch adversarial loss: 0.526589\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070187; batch adversarial loss: 0.444613\n",
      "epoch 52; iter: 0; batch classifier loss: 0.063963; batch adversarial loss: 0.482361\n",
      "epoch 53; iter: 0; batch classifier loss: 0.057040; batch adversarial loss: 0.453185\n",
      "epoch 54; iter: 0; batch classifier loss: 0.057276; batch adversarial loss: 0.377190\n",
      "epoch 55; iter: 0; batch classifier loss: 0.028772; batch adversarial loss: 0.479837\n",
      "epoch 56; iter: 0; batch classifier loss: 0.090476; batch adversarial loss: 0.379816\n",
      "epoch 57; iter: 0; batch classifier loss: 0.049832; batch adversarial loss: 0.412263\n",
      "epoch 58; iter: 0; batch classifier loss: 0.059664; batch adversarial loss: 0.493294\n",
      "epoch 59; iter: 0; batch classifier loss: 0.046259; batch adversarial loss: 0.513437\n",
      "epoch 60; iter: 0; batch classifier loss: 0.098451; batch adversarial loss: 0.404341\n",
      "epoch 61; iter: 0; batch classifier loss: 0.073639; batch adversarial loss: 0.444258\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084504; batch adversarial loss: 0.405469\n",
      "epoch 63; iter: 0; batch classifier loss: 0.053689; batch adversarial loss: 0.507104\n",
      "epoch 64; iter: 0; batch classifier loss: 0.075309; batch adversarial loss: 0.494661\n",
      "epoch 65; iter: 0; batch classifier loss: 0.042853; batch adversarial loss: 0.404139\n",
      "epoch 66; iter: 0; batch classifier loss: 0.063091; batch adversarial loss: 0.466993\n",
      "epoch 67; iter: 0; batch classifier loss: 0.074605; batch adversarial loss: 0.471190\n",
      "epoch 68; iter: 0; batch classifier loss: 0.038019; batch adversarial loss: 0.332919\n",
      "epoch 69; iter: 0; batch classifier loss: 0.067058; batch adversarial loss: 0.470219\n",
      "epoch 70; iter: 0; batch classifier loss: 0.053463; batch adversarial loss: 0.593300\n",
      "epoch 71; iter: 0; batch classifier loss: 0.081674; batch adversarial loss: 0.535437\n",
      "epoch 72; iter: 0; batch classifier loss: 0.029860; batch adversarial loss: 0.496739\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068735; batch adversarial loss: 0.463439\n",
      "epoch 74; iter: 0; batch classifier loss: 0.080678; batch adversarial loss: 0.474749\n",
      "epoch 75; iter: 0; batch classifier loss: 0.050177; batch adversarial loss: 0.419875\n",
      "epoch 76; iter: 0; batch classifier loss: 0.098557; batch adversarial loss: 0.437030\n",
      "epoch 77; iter: 0; batch classifier loss: 0.038139; batch adversarial loss: 0.429682\n",
      "epoch 78; iter: 0; batch classifier loss: 0.083999; batch adversarial loss: 0.450171\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057677; batch adversarial loss: 0.397528\n",
      "epoch 80; iter: 0; batch classifier loss: 0.051430; batch adversarial loss: 0.494505\n",
      "epoch 81; iter: 0; batch classifier loss: 0.054622; batch adversarial loss: 0.449834\n",
      "epoch 82; iter: 0; batch classifier loss: 0.048903; batch adversarial loss: 0.448344\n",
      "epoch 83; iter: 0; batch classifier loss: 0.044439; batch adversarial loss: 0.455931\n",
      "epoch 84; iter: 0; batch classifier loss: 0.109196; batch adversarial loss: 0.400938\n",
      "epoch 85; iter: 0; batch classifier loss: 0.029522; batch adversarial loss: 0.424306\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054796; batch adversarial loss: 0.577166\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056170; batch adversarial loss: 0.445610\n",
      "epoch 88; iter: 0; batch classifier loss: 0.037955; batch adversarial loss: 0.472094\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066384; batch adversarial loss: 0.522327\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052626; batch adversarial loss: 0.458295\n",
      "epoch 91; iter: 0; batch classifier loss: 0.039142; batch adversarial loss: 0.384191\n",
      "epoch 92; iter: 0; batch classifier loss: 0.085974; batch adversarial loss: 0.385183\n",
      "epoch 93; iter: 0; batch classifier loss: 0.059364; batch adversarial loss: 0.498831\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056255; batch adversarial loss: 0.417708\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038204; batch adversarial loss: 0.564462\n",
      "epoch 96; iter: 0; batch classifier loss: 0.029548; batch adversarial loss: 0.490907\n",
      "epoch 97; iter: 0; batch classifier loss: 0.027087; batch adversarial loss: 0.490266\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053608; batch adversarial loss: 0.434740\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052732; batch adversarial loss: 0.458769\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066981; batch adversarial loss: 0.468620\n",
      "epoch 101; iter: 0; batch classifier loss: 0.102190; batch adversarial loss: 0.448487\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033626; batch adversarial loss: 0.555187\n",
      "epoch 103; iter: 0; batch classifier loss: 0.026389; batch adversarial loss: 0.553942\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043774; batch adversarial loss: 0.458919\n",
      "epoch 105; iter: 0; batch classifier loss: 0.107158; batch adversarial loss: 0.428377\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059304; batch adversarial loss: 0.456646\n",
      "epoch 107; iter: 0; batch classifier loss: 0.026582; batch adversarial loss: 0.486888\n",
      "epoch 108; iter: 0; batch classifier loss: 0.072026; batch adversarial loss: 0.530092\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026584; batch adversarial loss: 0.555708\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040262; batch adversarial loss: 0.394127\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053396; batch adversarial loss: 0.439019\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024256; batch adversarial loss: 0.521938\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033717; batch adversarial loss: 0.422176\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032974; batch adversarial loss: 0.485228\n",
      "epoch 115; iter: 0; batch classifier loss: 0.117298; batch adversarial loss: 0.377581\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034764; batch adversarial loss: 0.539910\n",
      "epoch 117; iter: 0; batch classifier loss: 0.072482; batch adversarial loss: 0.497281\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056793; batch adversarial loss: 0.542888\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039845; batch adversarial loss: 0.383531\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035454; batch adversarial loss: 0.437688\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044953; batch adversarial loss: 0.478449\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059772; batch adversarial loss: 0.516393\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029041; batch adversarial loss: 0.470551\n",
      "epoch 124; iter: 0; batch classifier loss: 0.016314; batch adversarial loss: 0.492515\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035310; batch adversarial loss: 0.500509\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032209; batch adversarial loss: 0.454274\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028943; batch adversarial loss: 0.373726\n",
      "epoch 128; iter: 0; batch classifier loss: 0.074903; batch adversarial loss: 0.386363\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026826; batch adversarial loss: 0.462505\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019237; batch adversarial loss: 0.508931\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031276; batch adversarial loss: 0.414780\n",
      "epoch 132; iter: 0; batch classifier loss: 0.018691; batch adversarial loss: 0.411361\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037875; batch adversarial loss: 0.490722\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038852; batch adversarial loss: 0.508700\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037240; batch adversarial loss: 0.426274\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041889; batch adversarial loss: 0.458747\n",
      "epoch 137; iter: 0; batch classifier loss: 0.007735; batch adversarial loss: 0.382512\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029541; batch adversarial loss: 0.393093\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050314; batch adversarial loss: 0.419172\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018546; batch adversarial loss: 0.439255\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019953; batch adversarial loss: 0.415974\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049029; batch adversarial loss: 0.446872\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026211; batch adversarial loss: 0.453635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.014432; batch adversarial loss: 0.467908\n",
      "epoch 145; iter: 0; batch classifier loss: 0.051874; batch adversarial loss: 0.483741\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021289; batch adversarial loss: 0.439008\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017593; batch adversarial loss: 0.437758\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029002; batch adversarial loss: 0.420092\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018244; batch adversarial loss: 0.406821\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013266; batch adversarial loss: 0.459143\n",
      "epoch 151; iter: 0; batch classifier loss: 0.047749; batch adversarial loss: 0.524008\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010201; batch adversarial loss: 0.467453\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018155; batch adversarial loss: 0.459309\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034227; batch adversarial loss: 0.489300\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027446; batch adversarial loss: 0.458069\n",
      "epoch 156; iter: 0; batch classifier loss: 0.046587; batch adversarial loss: 0.537769\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028489; batch adversarial loss: 0.425797\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025847; batch adversarial loss: 0.523651\n",
      "epoch 159; iter: 0; batch classifier loss: 0.007289; batch adversarial loss: 0.537753\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026768; batch adversarial loss: 0.435742\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025834; batch adversarial loss: 0.423366\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018905; batch adversarial loss: 0.514597\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014339; batch adversarial loss: 0.488032\n",
      "epoch 164; iter: 0; batch classifier loss: 0.054175; batch adversarial loss: 0.415692\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034126; batch adversarial loss: 0.450692\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023644; batch adversarial loss: 0.399616\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032750; batch adversarial loss: 0.363737\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023932; batch adversarial loss: 0.412130\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015293; batch adversarial loss: 0.479720\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012224; batch adversarial loss: 0.452058\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021375; batch adversarial loss: 0.494086\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023748; batch adversarial loss: 0.533478\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013952; batch adversarial loss: 0.470333\n",
      "epoch 174; iter: 0; batch classifier loss: 0.034632; batch adversarial loss: 0.412646\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015101; batch adversarial loss: 0.431651\n",
      "epoch 176; iter: 0; batch classifier loss: 0.060123; batch adversarial loss: 0.447661\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009372; batch adversarial loss: 0.451108\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040229; batch adversarial loss: 0.436866\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011064; batch adversarial loss: 0.478887\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020703; batch adversarial loss: 0.426685\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014868; batch adversarial loss: 0.357433\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010792; batch adversarial loss: 0.430140\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013001; batch adversarial loss: 0.386290\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035634; batch adversarial loss: 0.513704\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014972; batch adversarial loss: 0.501656\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020912; batch adversarial loss: 0.526017\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018864; batch adversarial loss: 0.526458\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022947; batch adversarial loss: 0.523811\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019223; batch adversarial loss: 0.489522\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011549; batch adversarial loss: 0.428781\n",
      "epoch 191; iter: 0; batch classifier loss: 0.046567; batch adversarial loss: 0.559950\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019993; batch adversarial loss: 0.349275\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024093; batch adversarial loss: 0.429650\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007702; batch adversarial loss: 0.442862\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013428; batch adversarial loss: 0.417883\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012393; batch adversarial loss: 0.492559\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013964; batch adversarial loss: 0.432689\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031369; batch adversarial loss: 0.402604\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031219; batch adversarial loss: 0.441257\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719712; batch adversarial loss: 0.654860\n",
      "epoch 1; iter: 0; batch classifier loss: 0.525333; batch adversarial loss: 0.642964\n",
      "epoch 2; iter: 0; batch classifier loss: 0.485346; batch adversarial loss: 0.617016\n",
      "epoch 3; iter: 0; batch classifier loss: 0.438464; batch adversarial loss: 0.608870\n",
      "epoch 4; iter: 0; batch classifier loss: 0.447327; batch adversarial loss: 0.567209\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362352; batch adversarial loss: 0.530073\n",
      "epoch 6; iter: 0; batch classifier loss: 0.378131; batch adversarial loss: 0.512412\n",
      "epoch 7; iter: 0; batch classifier loss: 0.360383; batch adversarial loss: 0.530435\n",
      "epoch 8; iter: 0; batch classifier loss: 0.288290; batch adversarial loss: 0.496884\n",
      "epoch 9; iter: 0; batch classifier loss: 0.241844; batch adversarial loss: 0.566664\n",
      "epoch 10; iter: 0; batch classifier loss: 0.323973; batch adversarial loss: 0.569429\n",
      "epoch 11; iter: 0; batch classifier loss: 0.364495; batch adversarial loss: 0.547943\n",
      "epoch 12; iter: 0; batch classifier loss: 0.233001; batch adversarial loss: 0.522309\n",
      "epoch 13; iter: 0; batch classifier loss: 0.258540; batch adversarial loss: 0.646470\n",
      "epoch 14; iter: 0; batch classifier loss: 0.302616; batch adversarial loss: 0.552648\n",
      "epoch 15; iter: 0; batch classifier loss: 0.316253; batch adversarial loss: 0.495322\n",
      "epoch 16; iter: 0; batch classifier loss: 0.253466; batch adversarial loss: 0.570835\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241752; batch adversarial loss: 0.541644\n",
      "epoch 18; iter: 0; batch classifier loss: 0.181583; batch adversarial loss: 0.528047\n",
      "epoch 19; iter: 0; batch classifier loss: 0.249734; batch adversarial loss: 0.471805\n",
      "epoch 20; iter: 0; batch classifier loss: 0.250900; batch adversarial loss: 0.407136\n",
      "epoch 21; iter: 0; batch classifier loss: 0.256199; batch adversarial loss: 0.465887\n",
      "epoch 22; iter: 0; batch classifier loss: 0.220570; batch adversarial loss: 0.497039\n",
      "epoch 23; iter: 0; batch classifier loss: 0.178865; batch adversarial loss: 0.471883\n",
      "epoch 24; iter: 0; batch classifier loss: 0.159339; batch adversarial loss: 0.478930\n",
      "epoch 25; iter: 0; batch classifier loss: 0.198502; batch adversarial loss: 0.381740\n",
      "epoch 26; iter: 0; batch classifier loss: 0.172150; batch adversarial loss: 0.488763\n",
      "epoch 27; iter: 0; batch classifier loss: 0.214384; batch adversarial loss: 0.496612\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173953; batch adversarial loss: 0.487594\n",
      "epoch 29; iter: 0; batch classifier loss: 0.166224; batch adversarial loss: 0.460915\n",
      "epoch 30; iter: 0; batch classifier loss: 0.155023; batch adversarial loss: 0.506650\n",
      "epoch 31; iter: 0; batch classifier loss: 0.169195; batch adversarial loss: 0.428705\n",
      "epoch 32; iter: 0; batch classifier loss: 0.119301; batch adversarial loss: 0.441035\n",
      "epoch 33; iter: 0; batch classifier loss: 0.160843; batch adversarial loss: 0.475399\n",
      "epoch 34; iter: 0; batch classifier loss: 0.225716; batch adversarial loss: 0.487061\n",
      "epoch 35; iter: 0; batch classifier loss: 0.153737; batch adversarial loss: 0.473477\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141619; batch adversarial loss: 0.488604\n",
      "epoch 37; iter: 0; batch classifier loss: 0.179611; batch adversarial loss: 0.446544\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115645; batch adversarial loss: 0.552847\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131009; batch adversarial loss: 0.516923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.114676; batch adversarial loss: 0.395844\n",
      "epoch 41; iter: 0; batch classifier loss: 0.151852; batch adversarial loss: 0.486606\n",
      "epoch 42; iter: 0; batch classifier loss: 0.241292; batch adversarial loss: 0.420940\n",
      "epoch 43; iter: 0; batch classifier loss: 0.145417; batch adversarial loss: 0.418304\n",
      "epoch 44; iter: 0; batch classifier loss: 0.147092; batch adversarial loss: 0.438122\n",
      "epoch 45; iter: 0; batch classifier loss: 0.140429; batch adversarial loss: 0.386747\n",
      "epoch 46; iter: 0; batch classifier loss: 0.099458; batch adversarial loss: 0.484548\n",
      "epoch 47; iter: 0; batch classifier loss: 0.111201; batch adversarial loss: 0.486807\n",
      "epoch 48; iter: 0; batch classifier loss: 0.150299; batch adversarial loss: 0.416156\n",
      "epoch 49; iter: 0; batch classifier loss: 0.171726; batch adversarial loss: 0.446093\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094458; batch adversarial loss: 0.379561\n",
      "epoch 51; iter: 0; batch classifier loss: 0.094729; batch adversarial loss: 0.411793\n",
      "epoch 52; iter: 0; batch classifier loss: 0.126714; batch adversarial loss: 0.510975\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096390; batch adversarial loss: 0.435926\n",
      "epoch 54; iter: 0; batch classifier loss: 0.142401; batch adversarial loss: 0.471433\n",
      "epoch 55; iter: 0; batch classifier loss: 0.168109; batch adversarial loss: 0.483134\n",
      "epoch 56; iter: 0; batch classifier loss: 0.158820; batch adversarial loss: 0.491533\n",
      "epoch 57; iter: 0; batch classifier loss: 0.154512; batch adversarial loss: 0.423166\n",
      "epoch 58; iter: 0; batch classifier loss: 0.128545; batch adversarial loss: 0.536431\n",
      "epoch 59; iter: 0; batch classifier loss: 0.096252; batch adversarial loss: 0.426347\n",
      "epoch 60; iter: 0; batch classifier loss: 0.229020; batch adversarial loss: 0.505514\n",
      "epoch 61; iter: 0; batch classifier loss: 0.126954; batch adversarial loss: 0.369007\n",
      "epoch 62; iter: 0; batch classifier loss: 0.179133; batch adversarial loss: 0.507650\n",
      "epoch 63; iter: 0; batch classifier loss: 0.151922; batch adversarial loss: 0.465783\n",
      "epoch 64; iter: 0; batch classifier loss: 0.113383; batch adversarial loss: 0.507911\n",
      "epoch 65; iter: 0; batch classifier loss: 0.099505; batch adversarial loss: 0.443556\n",
      "epoch 66; iter: 0; batch classifier loss: 0.093744; batch adversarial loss: 0.528174\n",
      "epoch 67; iter: 0; batch classifier loss: 0.091602; batch adversarial loss: 0.524914\n",
      "epoch 68; iter: 0; batch classifier loss: 0.140749; batch adversarial loss: 0.518685\n",
      "epoch 69; iter: 0; batch classifier loss: 0.074235; batch adversarial loss: 0.521051\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067277; batch adversarial loss: 0.417196\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115069; batch adversarial loss: 0.430967\n",
      "epoch 72; iter: 0; batch classifier loss: 0.070027; batch adversarial loss: 0.485684\n",
      "epoch 73; iter: 0; batch classifier loss: 0.096691; batch adversarial loss: 0.495542\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076759; batch adversarial loss: 0.436215\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096791; batch adversarial loss: 0.491538\n",
      "epoch 76; iter: 0; batch classifier loss: 0.062604; batch adversarial loss: 0.446679\n",
      "epoch 77; iter: 0; batch classifier loss: 0.091553; batch adversarial loss: 0.498776\n",
      "epoch 78; iter: 0; batch classifier loss: 0.109815; batch adversarial loss: 0.414724\n",
      "epoch 79; iter: 0; batch classifier loss: 0.059258; batch adversarial loss: 0.477516\n",
      "epoch 80; iter: 0; batch classifier loss: 0.038219; batch adversarial loss: 0.468877\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069860; batch adversarial loss: 0.538205\n",
      "epoch 82; iter: 0; batch classifier loss: 0.055085; batch adversarial loss: 0.454480\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056580; batch adversarial loss: 0.502058\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080280; batch adversarial loss: 0.367863\n",
      "epoch 85; iter: 0; batch classifier loss: 0.062431; batch adversarial loss: 0.498590\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069333; batch adversarial loss: 0.494266\n",
      "epoch 87; iter: 0; batch classifier loss: 0.044666; batch adversarial loss: 0.516402\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049661; batch adversarial loss: 0.511039\n",
      "epoch 89; iter: 0; batch classifier loss: 0.061513; batch adversarial loss: 0.518171\n",
      "epoch 90; iter: 0; batch classifier loss: 0.074823; batch adversarial loss: 0.440575\n",
      "epoch 91; iter: 0; batch classifier loss: 0.061641; batch adversarial loss: 0.472100\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071791; batch adversarial loss: 0.351131\n",
      "epoch 93; iter: 0; batch classifier loss: 0.020324; batch adversarial loss: 0.407357\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048147; batch adversarial loss: 0.426608\n",
      "epoch 95; iter: 0; batch classifier loss: 0.072617; batch adversarial loss: 0.602246\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043834; batch adversarial loss: 0.526432\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046860; batch adversarial loss: 0.420190\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050218; batch adversarial loss: 0.413202\n",
      "epoch 99; iter: 0; batch classifier loss: 0.051207; batch adversarial loss: 0.482181\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065227; batch adversarial loss: 0.410466\n",
      "epoch 101; iter: 0; batch classifier loss: 0.036830; batch adversarial loss: 0.487806\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056069; batch adversarial loss: 0.623289\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053490; batch adversarial loss: 0.488397\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056037; batch adversarial loss: 0.448688\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042771; batch adversarial loss: 0.367548\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034209; batch adversarial loss: 0.527433\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037355; batch adversarial loss: 0.456255\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065096; batch adversarial loss: 0.488899\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051884; batch adversarial loss: 0.401613\n",
      "epoch 110; iter: 0; batch classifier loss: 0.022867; batch adversarial loss: 0.502377\n",
      "epoch 111; iter: 0; batch classifier loss: 0.070140; batch adversarial loss: 0.439252\n",
      "epoch 112; iter: 0; batch classifier loss: 0.029048; batch adversarial loss: 0.536174\n",
      "epoch 113; iter: 0; batch classifier loss: 0.021298; batch adversarial loss: 0.525130\n",
      "epoch 114; iter: 0; batch classifier loss: 0.019831; batch adversarial loss: 0.469803\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029019; batch adversarial loss: 0.446399\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035914; batch adversarial loss: 0.416583\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051001; batch adversarial loss: 0.420794\n",
      "epoch 118; iter: 0; batch classifier loss: 0.012490; batch adversarial loss: 0.352408\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041594; batch adversarial loss: 0.487230\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047426; batch adversarial loss: 0.451439\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025502; batch adversarial loss: 0.428385\n",
      "epoch 122; iter: 0; batch classifier loss: 0.022868; batch adversarial loss: 0.492682\n",
      "epoch 123; iter: 0; batch classifier loss: 0.022176; batch adversarial loss: 0.436630\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030566; batch adversarial loss: 0.611605\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026129; batch adversarial loss: 0.434954\n",
      "epoch 126; iter: 0; batch classifier loss: 0.100028; batch adversarial loss: 0.409143\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023490; batch adversarial loss: 0.488578\n",
      "epoch 128; iter: 0; batch classifier loss: 0.009412; batch adversarial loss: 0.462472\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028418; batch adversarial loss: 0.468374\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026464; batch adversarial loss: 0.407079\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024545; batch adversarial loss: 0.503768\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038807; batch adversarial loss: 0.439734\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022261; batch adversarial loss: 0.538802\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048563; batch adversarial loss: 0.420798\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011917; batch adversarial loss: 0.571601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.058660; batch adversarial loss: 0.468844\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044022; batch adversarial loss: 0.484913\n",
      "epoch 138; iter: 0; batch classifier loss: 0.010767; batch adversarial loss: 0.366253\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026904; batch adversarial loss: 0.404558\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024056; batch adversarial loss: 0.462116\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022732; batch adversarial loss: 0.481766\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039161; batch adversarial loss: 0.435542\n",
      "epoch 143; iter: 0; batch classifier loss: 0.052352; batch adversarial loss: 0.415779\n",
      "epoch 144; iter: 0; batch classifier loss: 0.062458; batch adversarial loss: 0.389697\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024498; batch adversarial loss: 0.500571\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019636; batch adversarial loss: 0.434474\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013215; batch adversarial loss: 0.440430\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046566; batch adversarial loss: 0.477013\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036691; batch adversarial loss: 0.403162\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035058; batch adversarial loss: 0.381706\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032749; batch adversarial loss: 0.506720\n",
      "epoch 152; iter: 0; batch classifier loss: 0.047260; batch adversarial loss: 0.456281\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015052; batch adversarial loss: 0.474696\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029575; batch adversarial loss: 0.421623\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009916; batch adversarial loss: 0.480662\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038674; batch adversarial loss: 0.468514\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019224; batch adversarial loss: 0.420217\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014761; batch adversarial loss: 0.432772\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017303; batch adversarial loss: 0.497820\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037484; batch adversarial loss: 0.439125\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019888; batch adversarial loss: 0.390462\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007839; batch adversarial loss: 0.384207\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035172; batch adversarial loss: 0.519092\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021368; batch adversarial loss: 0.455792\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017198; batch adversarial loss: 0.483013\n",
      "epoch 166; iter: 0; batch classifier loss: 0.009963; batch adversarial loss: 0.484167\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030205; batch adversarial loss: 0.489933\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013105; batch adversarial loss: 0.442359\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018735; batch adversarial loss: 0.506915\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017462; batch adversarial loss: 0.398744\n",
      "epoch 171; iter: 0; batch classifier loss: 0.044561; batch adversarial loss: 0.412288\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024278; batch adversarial loss: 0.466655\n",
      "epoch 173; iter: 0; batch classifier loss: 0.044233; batch adversarial loss: 0.412435\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032872; batch adversarial loss: 0.473343\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012518; batch adversarial loss: 0.447967\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033303; batch adversarial loss: 0.476909\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016517; batch adversarial loss: 0.401139\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015509; batch adversarial loss: 0.477097\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017188; batch adversarial loss: 0.471929\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027340; batch adversarial loss: 0.397470\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021193; batch adversarial loss: 0.564291\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012030; batch adversarial loss: 0.463529\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021967; batch adversarial loss: 0.428260\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008497; batch adversarial loss: 0.457591\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010103; batch adversarial loss: 0.545587\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025351; batch adversarial loss: 0.506153\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014244; batch adversarial loss: 0.505061\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017224; batch adversarial loss: 0.354137\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010939; batch adversarial loss: 0.508885\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005353; batch adversarial loss: 0.379130\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007674; batch adversarial loss: 0.422049\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008586; batch adversarial loss: 0.469856\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035948; batch adversarial loss: 0.482634\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031761; batch adversarial loss: 0.487435\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036167; batch adversarial loss: 0.439857\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032802; batch adversarial loss: 0.520979\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016061; batch adversarial loss: 0.498239\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022004; batch adversarial loss: 0.374772\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005601; batch adversarial loss: 0.470840\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714491; batch adversarial loss: 1.321146\n",
      "epoch 1; iter: 0; batch classifier loss: 0.855709; batch adversarial loss: 1.521329\n",
      "epoch 2; iter: 0; batch classifier loss: 0.888163; batch adversarial loss: 1.460637\n",
      "epoch 3; iter: 0; batch classifier loss: 1.049004; batch adversarial loss: 1.386001\n",
      "epoch 4; iter: 0; batch classifier loss: 1.274451; batch adversarial loss: 1.312097\n",
      "epoch 5; iter: 0; batch classifier loss: 1.190493; batch adversarial loss: 1.168067\n",
      "epoch 6; iter: 0; batch classifier loss: 1.386358; batch adversarial loss: 1.101515\n",
      "epoch 7; iter: 0; batch classifier loss: 1.181170; batch adversarial loss: 0.973676\n",
      "epoch 8; iter: 0; batch classifier loss: 0.963881; batch adversarial loss: 0.870111\n",
      "epoch 9; iter: 0; batch classifier loss: 1.222456; batch adversarial loss: 0.854439\n",
      "epoch 10; iter: 0; batch classifier loss: 1.272909; batch adversarial loss: 0.756890\n",
      "epoch 11; iter: 0; batch classifier loss: 1.183770; batch adversarial loss: 0.721208\n",
      "epoch 12; iter: 0; batch classifier loss: 1.059472; batch adversarial loss: 0.623446\n",
      "epoch 13; iter: 0; batch classifier loss: 1.018827; batch adversarial loss: 0.597806\n",
      "epoch 14; iter: 0; batch classifier loss: 0.864770; batch adversarial loss: 0.562565\n",
      "epoch 15; iter: 0; batch classifier loss: 0.729605; batch adversarial loss: 0.572639\n",
      "epoch 16; iter: 0; batch classifier loss: 0.502211; batch adversarial loss: 0.527715\n",
      "epoch 17; iter: 0; batch classifier loss: 0.470680; batch adversarial loss: 0.502784\n",
      "epoch 18; iter: 0; batch classifier loss: 0.331019; batch adversarial loss: 0.468834\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237130; batch adversarial loss: 0.530232\n",
      "epoch 20; iter: 0; batch classifier loss: 0.272347; batch adversarial loss: 0.477692\n",
      "epoch 21; iter: 0; batch classifier loss: 0.206424; batch adversarial loss: 0.489662\n",
      "epoch 22; iter: 0; batch classifier loss: 0.271838; batch adversarial loss: 0.509788\n",
      "epoch 23; iter: 0; batch classifier loss: 0.195147; batch adversarial loss: 0.519098\n",
      "epoch 24; iter: 0; batch classifier loss: 0.149960; batch adversarial loss: 0.461145\n",
      "epoch 25; iter: 0; batch classifier loss: 0.158240; batch adversarial loss: 0.544069\n",
      "epoch 26; iter: 0; batch classifier loss: 0.229004; batch adversarial loss: 0.449676\n",
      "epoch 27; iter: 0; batch classifier loss: 0.224437; batch adversarial loss: 0.461328\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184513; batch adversarial loss: 0.443855\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210328; batch adversarial loss: 0.441946\n",
      "epoch 30; iter: 0; batch classifier loss: 0.188003; batch adversarial loss: 0.449421\n",
      "epoch 31; iter: 0; batch classifier loss: 0.145616; batch adversarial loss: 0.424300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.170796; batch adversarial loss: 0.488905\n",
      "epoch 33; iter: 0; batch classifier loss: 0.214425; batch adversarial loss: 0.424502\n",
      "epoch 34; iter: 0; batch classifier loss: 0.180394; batch adversarial loss: 0.511196\n",
      "epoch 35; iter: 0; batch classifier loss: 0.161685; batch adversarial loss: 0.513269\n",
      "epoch 36; iter: 0; batch classifier loss: 0.155675; batch adversarial loss: 0.464269\n",
      "epoch 37; iter: 0; batch classifier loss: 0.165140; batch adversarial loss: 0.451779\n",
      "epoch 38; iter: 0; batch classifier loss: 0.164554; batch adversarial loss: 0.424877\n",
      "epoch 39; iter: 0; batch classifier loss: 0.153367; batch adversarial loss: 0.435328\n",
      "epoch 40; iter: 0; batch classifier loss: 0.176431; batch adversarial loss: 0.479036\n",
      "epoch 41; iter: 0; batch classifier loss: 0.206919; batch adversarial loss: 0.485278\n",
      "epoch 42; iter: 0; batch classifier loss: 0.204081; batch adversarial loss: 0.439567\n",
      "epoch 43; iter: 0; batch classifier loss: 0.172110; batch adversarial loss: 0.474163\n",
      "epoch 44; iter: 0; batch classifier loss: 0.129604; batch adversarial loss: 0.403758\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124428; batch adversarial loss: 0.558916\n",
      "epoch 46; iter: 0; batch classifier loss: 0.132039; batch adversarial loss: 0.498164\n",
      "epoch 47; iter: 0; batch classifier loss: 0.125474; batch adversarial loss: 0.371901\n",
      "epoch 48; iter: 0; batch classifier loss: 0.121235; batch adversarial loss: 0.583729\n",
      "epoch 49; iter: 0; batch classifier loss: 0.182185; batch adversarial loss: 0.411247\n",
      "epoch 50; iter: 0; batch classifier loss: 0.163894; batch adversarial loss: 0.421142\n",
      "epoch 51; iter: 0; batch classifier loss: 0.169602; batch adversarial loss: 0.438252\n",
      "epoch 52; iter: 0; batch classifier loss: 0.156649; batch adversarial loss: 0.390196\n",
      "epoch 53; iter: 0; batch classifier loss: 0.215627; batch adversarial loss: 0.455524\n",
      "epoch 54; iter: 0; batch classifier loss: 0.167394; batch adversarial loss: 0.535636\n",
      "epoch 55; iter: 0; batch classifier loss: 0.170350; batch adversarial loss: 0.501115\n",
      "epoch 56; iter: 0; batch classifier loss: 0.138437; batch adversarial loss: 0.495434\n",
      "epoch 57; iter: 0; batch classifier loss: 0.186407; batch adversarial loss: 0.431272\n",
      "epoch 58; iter: 0; batch classifier loss: 0.181990; batch adversarial loss: 0.531571\n",
      "epoch 59; iter: 0; batch classifier loss: 0.152967; batch adversarial loss: 0.428571\n",
      "epoch 60; iter: 0; batch classifier loss: 0.186870; batch adversarial loss: 0.460446\n",
      "epoch 61; iter: 0; batch classifier loss: 0.095105; batch adversarial loss: 0.567119\n",
      "epoch 62; iter: 0; batch classifier loss: 0.107957; batch adversarial loss: 0.470888\n",
      "epoch 63; iter: 0; batch classifier loss: 0.168695; batch adversarial loss: 0.438112\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090894; batch adversarial loss: 0.382852\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122828; batch adversarial loss: 0.468844\n",
      "epoch 66; iter: 0; batch classifier loss: 0.149087; batch adversarial loss: 0.419902\n",
      "epoch 67; iter: 0; batch classifier loss: 0.138116; batch adversarial loss: 0.434063\n",
      "epoch 68; iter: 0; batch classifier loss: 0.202169; batch adversarial loss: 0.446975\n",
      "epoch 69; iter: 0; batch classifier loss: 0.100146; batch adversarial loss: 0.572918\n",
      "epoch 70; iter: 0; batch classifier loss: 0.158465; batch adversarial loss: 0.487316\n",
      "epoch 71; iter: 0; batch classifier loss: 0.145622; batch adversarial loss: 0.418909\n",
      "epoch 72; iter: 0; batch classifier loss: 0.151038; batch adversarial loss: 0.391834\n",
      "epoch 73; iter: 0; batch classifier loss: 0.139830; batch adversarial loss: 0.419806\n",
      "epoch 74; iter: 0; batch classifier loss: 0.156120; batch adversarial loss: 0.485406\n",
      "epoch 75; iter: 0; batch classifier loss: 0.114799; batch adversarial loss: 0.423326\n",
      "epoch 76; iter: 0; batch classifier loss: 0.151270; batch adversarial loss: 0.430464\n",
      "epoch 77; iter: 0; batch classifier loss: 0.103981; batch adversarial loss: 0.488219\n",
      "epoch 78; iter: 0; batch classifier loss: 0.149025; batch adversarial loss: 0.437818\n",
      "epoch 79; iter: 0; batch classifier loss: 0.191664; batch adversarial loss: 0.531617\n",
      "epoch 80; iter: 0; batch classifier loss: 0.163624; batch adversarial loss: 0.457431\n",
      "epoch 81; iter: 0; batch classifier loss: 0.140014; batch adversarial loss: 0.543915\n",
      "epoch 82; iter: 0; batch classifier loss: 0.176993; batch adversarial loss: 0.492025\n",
      "epoch 83; iter: 0; batch classifier loss: 0.125184; batch adversarial loss: 0.378760\n",
      "epoch 84; iter: 0; batch classifier loss: 0.160510; batch adversarial loss: 0.460717\n",
      "epoch 85; iter: 0; batch classifier loss: 0.179523; batch adversarial loss: 0.357902\n",
      "epoch 86; iter: 0; batch classifier loss: 0.148726; batch adversarial loss: 0.445133\n",
      "epoch 87; iter: 0; batch classifier loss: 0.095822; batch adversarial loss: 0.381821\n",
      "epoch 88; iter: 0; batch classifier loss: 0.141960; batch adversarial loss: 0.439015\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080504; batch adversarial loss: 0.500649\n",
      "epoch 90; iter: 0; batch classifier loss: 0.132361; batch adversarial loss: 0.431933\n",
      "epoch 91; iter: 0; batch classifier loss: 0.128278; batch adversarial loss: 0.441207\n",
      "epoch 92; iter: 0; batch classifier loss: 0.083014; batch adversarial loss: 0.486300\n",
      "epoch 93; iter: 0; batch classifier loss: 0.101171; batch adversarial loss: 0.506220\n",
      "epoch 94; iter: 0; batch classifier loss: 0.121966; batch adversarial loss: 0.567463\n",
      "epoch 95; iter: 0; batch classifier loss: 0.172765; batch adversarial loss: 0.374289\n",
      "epoch 96; iter: 0; batch classifier loss: 0.141731; batch adversarial loss: 0.551948\n",
      "epoch 97; iter: 0; batch classifier loss: 0.131958; batch adversarial loss: 0.496837\n",
      "epoch 98; iter: 0; batch classifier loss: 0.118084; batch adversarial loss: 0.481085\n",
      "epoch 99; iter: 0; batch classifier loss: 0.179349; batch adversarial loss: 0.402387\n",
      "epoch 100; iter: 0; batch classifier loss: 0.125603; batch adversarial loss: 0.397042\n",
      "epoch 101; iter: 0; batch classifier loss: 0.172807; batch adversarial loss: 0.336865\n",
      "epoch 102; iter: 0; batch classifier loss: 0.186141; batch adversarial loss: 0.421558\n",
      "epoch 103; iter: 0; batch classifier loss: 0.126633; batch adversarial loss: 0.375069\n",
      "epoch 104; iter: 0; batch classifier loss: 0.134377; batch adversarial loss: 0.395259\n",
      "epoch 105; iter: 0; batch classifier loss: 0.176452; batch adversarial loss: 0.422259\n",
      "epoch 106; iter: 0; batch classifier loss: 0.207545; batch adversarial loss: 0.391664\n",
      "epoch 107; iter: 0; batch classifier loss: 0.145156; batch adversarial loss: 0.386583\n",
      "epoch 108; iter: 0; batch classifier loss: 0.167310; batch adversarial loss: 0.446205\n",
      "epoch 109; iter: 0; batch classifier loss: 0.084771; batch adversarial loss: 0.426295\n",
      "epoch 110; iter: 0; batch classifier loss: 0.155720; batch adversarial loss: 0.403919\n",
      "epoch 111; iter: 0; batch classifier loss: 0.121326; batch adversarial loss: 0.431378\n",
      "epoch 112; iter: 0; batch classifier loss: 0.136961; batch adversarial loss: 0.496844\n",
      "epoch 113; iter: 0; batch classifier loss: 0.093196; batch adversarial loss: 0.463464\n",
      "epoch 114; iter: 0; batch classifier loss: 0.106998; batch adversarial loss: 0.484776\n",
      "epoch 115; iter: 0; batch classifier loss: 0.146420; batch adversarial loss: 0.359893\n",
      "epoch 116; iter: 0; batch classifier loss: 0.190882; batch adversarial loss: 0.560814\n",
      "epoch 117; iter: 0; batch classifier loss: 0.184920; batch adversarial loss: 0.432616\n",
      "epoch 118; iter: 0; batch classifier loss: 0.142304; batch adversarial loss: 0.372731\n",
      "epoch 119; iter: 0; batch classifier loss: 0.149169; batch adversarial loss: 0.456085\n",
      "epoch 120; iter: 0; batch classifier loss: 0.131124; batch adversarial loss: 0.501107\n",
      "epoch 121; iter: 0; batch classifier loss: 0.131379; batch adversarial loss: 0.482580\n",
      "epoch 122; iter: 0; batch classifier loss: 0.207070; batch adversarial loss: 0.374490\n",
      "epoch 123; iter: 0; batch classifier loss: 0.165689; batch adversarial loss: 0.424652\n",
      "epoch 124; iter: 0; batch classifier loss: 0.124804; batch adversarial loss: 0.484046\n",
      "epoch 125; iter: 0; batch classifier loss: 0.152146; batch adversarial loss: 0.468023\n",
      "epoch 126; iter: 0; batch classifier loss: 0.167289; batch adversarial loss: 0.519446\n",
      "epoch 127; iter: 0; batch classifier loss: 0.163120; batch adversarial loss: 0.410175\n",
      "epoch 128; iter: 0; batch classifier loss: 0.171750; batch adversarial loss: 0.525379\n",
      "epoch 129; iter: 0; batch classifier loss: 0.138730; batch adversarial loss: 0.495751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.191339; batch adversarial loss: 0.457229\n",
      "epoch 131; iter: 0; batch classifier loss: 0.150147; batch adversarial loss: 0.470058\n",
      "epoch 132; iter: 0; batch classifier loss: 0.127849; batch adversarial loss: 0.461934\n",
      "epoch 133; iter: 0; batch classifier loss: 0.150003; batch adversarial loss: 0.436422\n",
      "epoch 134; iter: 0; batch classifier loss: 0.147770; batch adversarial loss: 0.460856\n",
      "epoch 135; iter: 0; batch classifier loss: 0.205667; batch adversarial loss: 0.474278\n",
      "epoch 136; iter: 0; batch classifier loss: 0.195641; batch adversarial loss: 0.533573\n",
      "epoch 137; iter: 0; batch classifier loss: 0.163658; batch adversarial loss: 0.521201\n",
      "epoch 138; iter: 0; batch classifier loss: 0.185495; batch adversarial loss: 0.359225\n",
      "epoch 139; iter: 0; batch classifier loss: 0.155641; batch adversarial loss: 0.408129\n",
      "epoch 140; iter: 0; batch classifier loss: 0.168866; batch adversarial loss: 0.372030\n",
      "epoch 141; iter: 0; batch classifier loss: 0.192623; batch adversarial loss: 0.469458\n",
      "epoch 142; iter: 0; batch classifier loss: 0.134109; batch adversarial loss: 0.499283\n",
      "epoch 143; iter: 0; batch classifier loss: 0.158089; batch adversarial loss: 0.422032\n",
      "epoch 144; iter: 0; batch classifier loss: 0.159607; batch adversarial loss: 0.460156\n",
      "epoch 145; iter: 0; batch classifier loss: 0.180686; batch adversarial loss: 0.410143\n",
      "epoch 146; iter: 0; batch classifier loss: 0.141139; batch adversarial loss: 0.458862\n",
      "epoch 147; iter: 0; batch classifier loss: 0.173453; batch adversarial loss: 0.482594\n",
      "epoch 148; iter: 0; batch classifier loss: 0.187707; batch adversarial loss: 0.459101\n",
      "epoch 149; iter: 0; batch classifier loss: 0.122684; batch adversarial loss: 0.409423\n",
      "epoch 150; iter: 0; batch classifier loss: 0.268137; batch adversarial loss: 0.422066\n",
      "epoch 151; iter: 0; batch classifier loss: 0.160014; batch adversarial loss: 0.446469\n",
      "epoch 152; iter: 0; batch classifier loss: 0.049576; batch adversarial loss: 0.470830\n",
      "epoch 153; iter: 0; batch classifier loss: 0.134153; batch adversarial loss: 0.523537\n",
      "epoch 154; iter: 0; batch classifier loss: 0.147883; batch adversarial loss: 0.358730\n",
      "epoch 155; iter: 0; batch classifier loss: 0.146595; batch adversarial loss: 0.497699\n",
      "epoch 156; iter: 0; batch classifier loss: 0.145888; batch adversarial loss: 0.394420\n",
      "epoch 157; iter: 0; batch classifier loss: 0.189105; batch adversarial loss: 0.469586\n",
      "epoch 158; iter: 0; batch classifier loss: 0.151771; batch adversarial loss: 0.556399\n",
      "epoch 159; iter: 0; batch classifier loss: 0.229533; batch adversarial loss: 0.495888\n",
      "epoch 160; iter: 0; batch classifier loss: 0.150468; batch adversarial loss: 0.421538\n",
      "epoch 161; iter: 0; batch classifier loss: 0.180649; batch adversarial loss: 0.483620\n",
      "epoch 162; iter: 0; batch classifier loss: 0.129327; batch adversarial loss: 0.421499\n",
      "epoch 163; iter: 0; batch classifier loss: 0.184277; batch adversarial loss: 0.557929\n",
      "epoch 164; iter: 0; batch classifier loss: 0.210282; batch adversarial loss: 0.384807\n",
      "epoch 165; iter: 0; batch classifier loss: 0.146151; batch adversarial loss: 0.421768\n",
      "epoch 166; iter: 0; batch classifier loss: 0.062612; batch adversarial loss: 0.357636\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032356; batch adversarial loss: 0.429901\n",
      "epoch 168; iter: 0; batch classifier loss: 0.076440; batch adversarial loss: 0.457892\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038465; batch adversarial loss: 0.421128\n",
      "epoch 170; iter: 0; batch classifier loss: 0.051105; batch adversarial loss: 0.418628\n",
      "epoch 171; iter: 0; batch classifier loss: 0.062858; batch adversarial loss: 0.459741\n",
      "epoch 172; iter: 0; batch classifier loss: 0.042041; batch adversarial loss: 0.405495\n",
      "epoch 173; iter: 0; batch classifier loss: 0.060396; batch adversarial loss: 0.407600\n",
      "epoch 174; iter: 0; batch classifier loss: 0.064728; batch adversarial loss: 0.408299\n",
      "epoch 175; iter: 0; batch classifier loss: 0.066562; batch adversarial loss: 0.510121\n",
      "epoch 176; iter: 0; batch classifier loss: 0.065543; batch adversarial loss: 0.463093\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038895; batch adversarial loss: 0.462274\n",
      "epoch 178; iter: 0; batch classifier loss: 0.060522; batch adversarial loss: 0.386300\n",
      "epoch 179; iter: 0; batch classifier loss: 0.067948; batch adversarial loss: 0.509109\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041644; batch adversarial loss: 0.480560\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036526; batch adversarial loss: 0.479213\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036073; batch adversarial loss: 0.481744\n",
      "epoch 183; iter: 0; batch classifier loss: 0.059820; batch adversarial loss: 0.579962\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021851; batch adversarial loss: 0.523236\n",
      "epoch 185; iter: 0; batch classifier loss: 0.050716; batch adversarial loss: 0.470371\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023816; batch adversarial loss: 0.487197\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036978; batch adversarial loss: 0.485860\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035321; batch adversarial loss: 0.511646\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027605; batch adversarial loss: 0.442598\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030047; batch adversarial loss: 0.471724\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027645; batch adversarial loss: 0.367416\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040538; batch adversarial loss: 0.490274\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027001; batch adversarial loss: 0.483674\n",
      "epoch 194; iter: 0; batch classifier loss: 0.056279; batch adversarial loss: 0.484332\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031326; batch adversarial loss: 0.462138\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025062; batch adversarial loss: 0.415361\n",
      "epoch 197; iter: 0; batch classifier loss: 0.064828; batch adversarial loss: 0.386141\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009352; batch adversarial loss: 0.461172\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023925; batch adversarial loss: 0.442289\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681618; batch adversarial loss: 0.938072\n",
      "epoch 1; iter: 0; batch classifier loss: 0.789859; batch adversarial loss: 1.164859\n",
      "epoch 2; iter: 0; batch classifier loss: 1.068085; batch adversarial loss: 1.262527\n",
      "epoch 3; iter: 0; batch classifier loss: 0.962641; batch adversarial loss: 1.051987\n",
      "epoch 4; iter: 0; batch classifier loss: 1.116755; batch adversarial loss: 1.142818\n",
      "epoch 5; iter: 0; batch classifier loss: 0.922186; batch adversarial loss: 0.883883\n",
      "epoch 6; iter: 0; batch classifier loss: 0.886941; batch adversarial loss: 0.839184\n",
      "epoch 7; iter: 0; batch classifier loss: 0.708317; batch adversarial loss: 0.738577\n",
      "epoch 8; iter: 0; batch classifier loss: 0.734964; batch adversarial loss: 0.687412\n",
      "epoch 9; iter: 0; batch classifier loss: 0.737319; batch adversarial loss: 0.639982\n",
      "epoch 10; iter: 0; batch classifier loss: 0.655887; batch adversarial loss: 0.704780\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526516; batch adversarial loss: 0.627044\n",
      "epoch 12; iter: 0; batch classifier loss: 0.442037; batch adversarial loss: 0.529110\n",
      "epoch 13; iter: 0; batch classifier loss: 0.384258; batch adversarial loss: 0.534303\n",
      "epoch 14; iter: 0; batch classifier loss: 0.300465; batch adversarial loss: 0.518650\n",
      "epoch 15; iter: 0; batch classifier loss: 0.297204; batch adversarial loss: 0.586200\n",
      "epoch 16; iter: 0; batch classifier loss: 0.280095; batch adversarial loss: 0.442847\n",
      "epoch 17; iter: 0; batch classifier loss: 0.261622; batch adversarial loss: 0.495272\n",
      "epoch 18; iter: 0; batch classifier loss: 0.303121; batch adversarial loss: 0.550718\n",
      "epoch 19; iter: 0; batch classifier loss: 0.257585; batch adversarial loss: 0.494896\n",
      "epoch 20; iter: 0; batch classifier loss: 0.239094; batch adversarial loss: 0.486890\n",
      "epoch 21; iter: 0; batch classifier loss: 0.236714; batch adversarial loss: 0.442747\n",
      "epoch 22; iter: 0; batch classifier loss: 0.249907; batch adversarial loss: 0.521602\n",
      "epoch 23; iter: 0; batch classifier loss: 0.261993; batch adversarial loss: 0.489201\n",
      "epoch 24; iter: 0; batch classifier loss: 0.207692; batch adversarial loss: 0.538018\n",
      "epoch 25; iter: 0; batch classifier loss: 0.200894; batch adversarial loss: 0.449389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.194536; batch adversarial loss: 0.447514\n",
      "epoch 27; iter: 0; batch classifier loss: 0.211898; batch adversarial loss: 0.529865\n",
      "epoch 28; iter: 0; batch classifier loss: 0.166936; batch adversarial loss: 0.403246\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170194; batch adversarial loss: 0.530996\n",
      "epoch 30; iter: 0; batch classifier loss: 0.182868; batch adversarial loss: 0.450845\n",
      "epoch 31; iter: 0; batch classifier loss: 0.176586; batch adversarial loss: 0.473380\n",
      "epoch 32; iter: 0; batch classifier loss: 0.137182; batch adversarial loss: 0.470793\n",
      "epoch 33; iter: 0; batch classifier loss: 0.166401; batch adversarial loss: 0.408480\n",
      "epoch 34; iter: 0; batch classifier loss: 0.143658; batch adversarial loss: 0.526364\n",
      "epoch 35; iter: 0; batch classifier loss: 0.201177; batch adversarial loss: 0.431758\n",
      "epoch 36; iter: 0; batch classifier loss: 0.151920; batch adversarial loss: 0.460330\n",
      "epoch 37; iter: 0; batch classifier loss: 0.155110; batch adversarial loss: 0.473719\n",
      "epoch 38; iter: 0; batch classifier loss: 0.153321; batch adversarial loss: 0.304956\n",
      "epoch 39; iter: 0; batch classifier loss: 0.136250; batch adversarial loss: 0.471968\n",
      "epoch 40; iter: 0; batch classifier loss: 0.159851; batch adversarial loss: 0.523002\n",
      "epoch 41; iter: 0; batch classifier loss: 0.127570; batch adversarial loss: 0.544600\n",
      "epoch 42; iter: 0; batch classifier loss: 0.120302; batch adversarial loss: 0.477010\n",
      "epoch 43; iter: 0; batch classifier loss: 0.142244; batch adversarial loss: 0.536365\n",
      "epoch 44; iter: 0; batch classifier loss: 0.165963; batch adversarial loss: 0.461599\n",
      "epoch 45; iter: 0; batch classifier loss: 0.215724; batch adversarial loss: 0.390627\n",
      "epoch 46; iter: 0; batch classifier loss: 0.144353; batch adversarial loss: 0.443042\n",
      "epoch 47; iter: 0; batch classifier loss: 0.071839; batch adversarial loss: 0.472258\n",
      "epoch 48; iter: 0; batch classifier loss: 0.135484; batch adversarial loss: 0.503623\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094594; batch adversarial loss: 0.400469\n",
      "epoch 50; iter: 0; batch classifier loss: 0.120613; batch adversarial loss: 0.409757\n",
      "epoch 51; iter: 0; batch classifier loss: 0.167337; batch adversarial loss: 0.425931\n",
      "epoch 52; iter: 0; batch classifier loss: 0.123663; batch adversarial loss: 0.451895\n",
      "epoch 53; iter: 0; batch classifier loss: 0.121977; batch adversarial loss: 0.515319\n",
      "epoch 54; iter: 0; batch classifier loss: 0.151853; batch adversarial loss: 0.464040\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119325; batch adversarial loss: 0.331808\n",
      "epoch 56; iter: 0; batch classifier loss: 0.133156; batch adversarial loss: 0.446884\n",
      "epoch 57; iter: 0; batch classifier loss: 0.141749; batch adversarial loss: 0.451152\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097241; batch adversarial loss: 0.443567\n",
      "epoch 59; iter: 0; batch classifier loss: 0.131504; batch adversarial loss: 0.454957\n",
      "epoch 60; iter: 0; batch classifier loss: 0.173756; batch adversarial loss: 0.645013\n",
      "epoch 61; iter: 0; batch classifier loss: 0.125498; batch adversarial loss: 0.420801\n",
      "epoch 62; iter: 0; batch classifier loss: 0.126125; batch adversarial loss: 0.450033\n",
      "epoch 63; iter: 0; batch classifier loss: 0.127347; batch adversarial loss: 0.468630\n",
      "epoch 64; iter: 0; batch classifier loss: 0.132550; batch adversarial loss: 0.453305\n",
      "epoch 65; iter: 0; batch classifier loss: 0.072315; batch adversarial loss: 0.422992\n",
      "epoch 66; iter: 0; batch classifier loss: 0.093855; batch adversarial loss: 0.432974\n",
      "epoch 67; iter: 0; batch classifier loss: 0.135187; batch adversarial loss: 0.461022\n",
      "epoch 68; iter: 0; batch classifier loss: 0.142765; batch adversarial loss: 0.440603\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095492; batch adversarial loss: 0.426793\n",
      "epoch 70; iter: 0; batch classifier loss: 0.137541; batch adversarial loss: 0.485430\n",
      "epoch 71; iter: 0; batch classifier loss: 0.114831; batch adversarial loss: 0.464201\n",
      "epoch 72; iter: 0; batch classifier loss: 0.085016; batch adversarial loss: 0.417534\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065840; batch adversarial loss: 0.480049\n",
      "epoch 74; iter: 0; batch classifier loss: 0.136135; batch adversarial loss: 0.511822\n",
      "epoch 75; iter: 0; batch classifier loss: 0.105180; batch adversarial loss: 0.411937\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083632; batch adversarial loss: 0.548398\n",
      "epoch 77; iter: 0; batch classifier loss: 0.149863; batch adversarial loss: 0.434553\n",
      "epoch 78; iter: 0; batch classifier loss: 0.106568; batch adversarial loss: 0.474464\n",
      "epoch 79; iter: 0; batch classifier loss: 0.102198; batch adversarial loss: 0.485415\n",
      "epoch 80; iter: 0; batch classifier loss: 0.103302; batch adversarial loss: 0.565479\n",
      "epoch 81; iter: 0; batch classifier loss: 0.106467; batch adversarial loss: 0.504676\n",
      "epoch 82; iter: 0; batch classifier loss: 0.127265; batch adversarial loss: 0.441760\n",
      "epoch 83; iter: 0; batch classifier loss: 0.131990; batch adversarial loss: 0.479717\n",
      "epoch 84; iter: 0; batch classifier loss: 0.107754; batch adversarial loss: 0.367490\n",
      "epoch 85; iter: 0; batch classifier loss: 0.162481; batch adversarial loss: 0.413552\n",
      "epoch 86; iter: 0; batch classifier loss: 0.106732; batch adversarial loss: 0.508072\n",
      "epoch 87; iter: 0; batch classifier loss: 0.110164; batch adversarial loss: 0.484079\n",
      "epoch 88; iter: 0; batch classifier loss: 0.122768; batch adversarial loss: 0.436982\n",
      "epoch 89; iter: 0; batch classifier loss: 0.100363; batch adversarial loss: 0.463401\n",
      "epoch 90; iter: 0; batch classifier loss: 0.128559; batch adversarial loss: 0.483366\n",
      "epoch 91; iter: 0; batch classifier loss: 0.107045; batch adversarial loss: 0.409560\n",
      "epoch 92; iter: 0; batch classifier loss: 0.119463; batch adversarial loss: 0.474446\n",
      "epoch 93; iter: 0; batch classifier loss: 0.091317; batch adversarial loss: 0.527039\n",
      "epoch 94; iter: 0; batch classifier loss: 0.106012; batch adversarial loss: 0.493608\n",
      "epoch 95; iter: 0; batch classifier loss: 0.093808; batch adversarial loss: 0.410103\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082394; batch adversarial loss: 0.393455\n",
      "epoch 97; iter: 0; batch classifier loss: 0.139630; batch adversarial loss: 0.447601\n",
      "epoch 98; iter: 0; batch classifier loss: 0.092098; batch adversarial loss: 0.493058\n",
      "epoch 99; iter: 0; batch classifier loss: 0.137566; batch adversarial loss: 0.381461\n",
      "epoch 100; iter: 0; batch classifier loss: 0.080579; batch adversarial loss: 0.481618\n",
      "epoch 101; iter: 0; batch classifier loss: 0.111442; batch adversarial loss: 0.431769\n",
      "epoch 102; iter: 0; batch classifier loss: 0.143236; batch adversarial loss: 0.437644\n",
      "epoch 103; iter: 0; batch classifier loss: 0.166989; batch adversarial loss: 0.325737\n",
      "epoch 104; iter: 0; batch classifier loss: 0.142608; batch adversarial loss: 0.455365\n",
      "epoch 105; iter: 0; batch classifier loss: 0.079623; batch adversarial loss: 0.450249\n",
      "epoch 106; iter: 0; batch classifier loss: 0.108934; batch adversarial loss: 0.535019\n",
      "epoch 107; iter: 0; batch classifier loss: 0.097978; batch adversarial loss: 0.492139\n",
      "epoch 108; iter: 0; batch classifier loss: 0.092184; batch adversarial loss: 0.419024\n",
      "epoch 109; iter: 0; batch classifier loss: 0.108653; batch adversarial loss: 0.444246\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049047; batch adversarial loss: 0.579357\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061628; batch adversarial loss: 0.492936\n",
      "epoch 112; iter: 0; batch classifier loss: 0.085779; batch adversarial loss: 0.394515\n",
      "epoch 113; iter: 0; batch classifier loss: 0.089125; batch adversarial loss: 0.440406\n",
      "epoch 114; iter: 0; batch classifier loss: 0.116396; batch adversarial loss: 0.432313\n",
      "epoch 115; iter: 0; batch classifier loss: 0.111227; batch adversarial loss: 0.413242\n",
      "epoch 116; iter: 0; batch classifier loss: 0.070346; batch adversarial loss: 0.488432\n",
      "epoch 117; iter: 0; batch classifier loss: 0.082216; batch adversarial loss: 0.510228\n",
      "epoch 118; iter: 0; batch classifier loss: 0.089662; batch adversarial loss: 0.543050\n",
      "epoch 119; iter: 0; batch classifier loss: 0.120318; batch adversarial loss: 0.405968\n",
      "epoch 120; iter: 0; batch classifier loss: 0.052975; batch adversarial loss: 0.498268\n",
      "epoch 121; iter: 0; batch classifier loss: 0.136878; batch adversarial loss: 0.445129\n",
      "epoch 122; iter: 0; batch classifier loss: 0.055519; batch adversarial loss: 0.465111\n",
      "epoch 123; iter: 0; batch classifier loss: 0.069512; batch adversarial loss: 0.495633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.144420; batch adversarial loss: 0.388689\n",
      "epoch 125; iter: 0; batch classifier loss: 0.122678; batch adversarial loss: 0.493078\n",
      "epoch 126; iter: 0; batch classifier loss: 0.091658; batch adversarial loss: 0.530980\n",
      "epoch 127; iter: 0; batch classifier loss: 0.127286; batch adversarial loss: 0.460833\n",
      "epoch 128; iter: 0; batch classifier loss: 0.123775; batch adversarial loss: 0.410954\n",
      "epoch 129; iter: 0; batch classifier loss: 0.111754; batch adversarial loss: 0.528289\n",
      "epoch 130; iter: 0; batch classifier loss: 0.149875; batch adversarial loss: 0.455672\n",
      "epoch 131; iter: 0; batch classifier loss: 0.072761; batch adversarial loss: 0.462145\n",
      "epoch 132; iter: 0; batch classifier loss: 0.124428; batch adversarial loss: 0.421926\n",
      "epoch 133; iter: 0; batch classifier loss: 0.133466; batch adversarial loss: 0.474457\n",
      "epoch 134; iter: 0; batch classifier loss: 0.151250; batch adversarial loss: 0.503236\n",
      "epoch 135; iter: 0; batch classifier loss: 0.182101; batch adversarial loss: 0.480507\n",
      "epoch 136; iter: 0; batch classifier loss: 0.204258; batch adversarial loss: 0.404001\n",
      "epoch 137; iter: 0; batch classifier loss: 0.174920; batch adversarial loss: 0.415814\n",
      "epoch 138; iter: 0; batch classifier loss: 0.165761; batch adversarial loss: 0.479019\n",
      "epoch 139; iter: 0; batch classifier loss: 0.145131; batch adversarial loss: 0.516967\n",
      "epoch 140; iter: 0; batch classifier loss: 0.294614; batch adversarial loss: 0.384537\n",
      "epoch 141; iter: 0; batch classifier loss: 0.262885; batch adversarial loss: 0.408575\n",
      "epoch 142; iter: 0; batch classifier loss: 0.253244; batch adversarial loss: 0.420029\n",
      "epoch 143; iter: 0; batch classifier loss: 0.254614; batch adversarial loss: 0.413864\n",
      "epoch 144; iter: 0; batch classifier loss: 0.231562; batch adversarial loss: 0.421299\n",
      "epoch 145; iter: 0; batch classifier loss: 0.230560; batch adversarial loss: 0.518740\n",
      "epoch 146; iter: 0; batch classifier loss: 0.214263; batch adversarial loss: 0.520084\n",
      "epoch 147; iter: 0; batch classifier loss: 0.248667; batch adversarial loss: 0.387494\n",
      "epoch 148; iter: 0; batch classifier loss: 0.254507; batch adversarial loss: 0.412050\n",
      "epoch 149; iter: 0; batch classifier loss: 0.351533; batch adversarial loss: 0.388286\n",
      "epoch 150; iter: 0; batch classifier loss: 0.190514; batch adversarial loss: 0.400095\n",
      "epoch 151; iter: 0; batch classifier loss: 0.263874; batch adversarial loss: 0.494569\n",
      "epoch 152; iter: 0; batch classifier loss: 0.323222; batch adversarial loss: 0.421763\n",
      "epoch 153; iter: 0; batch classifier loss: 0.233241; batch adversarial loss: 0.400322\n",
      "epoch 154; iter: 0; batch classifier loss: 0.279204; batch adversarial loss: 0.401226\n",
      "epoch 155; iter: 0; batch classifier loss: 0.210679; batch adversarial loss: 0.483031\n",
      "epoch 156; iter: 0; batch classifier loss: 0.177051; batch adversarial loss: 0.430745\n",
      "epoch 157; iter: 0; batch classifier loss: 0.119234; batch adversarial loss: 0.468469\n",
      "epoch 158; iter: 0; batch classifier loss: 0.140968; batch adversarial loss: 0.537659\n",
      "epoch 159; iter: 0; batch classifier loss: 0.174981; batch adversarial loss: 0.455105\n",
      "epoch 160; iter: 0; batch classifier loss: 0.228085; batch adversarial loss: 0.340084\n",
      "epoch 161; iter: 0; batch classifier loss: 0.240308; batch adversarial loss: 0.390144\n",
      "epoch 162; iter: 0; batch classifier loss: 0.197656; batch adversarial loss: 0.410013\n",
      "epoch 163; iter: 0; batch classifier loss: 0.161986; batch adversarial loss: 0.445650\n",
      "epoch 164; iter: 0; batch classifier loss: 0.137223; batch adversarial loss: 0.426823\n",
      "epoch 165; iter: 0; batch classifier loss: 0.187320; batch adversarial loss: 0.355077\n",
      "epoch 166; iter: 0; batch classifier loss: 0.120020; batch adversarial loss: 0.460405\n",
      "epoch 167; iter: 0; batch classifier loss: 0.167246; batch adversarial loss: 0.423235\n",
      "epoch 168; iter: 0; batch classifier loss: 0.119004; batch adversarial loss: 0.465585\n",
      "epoch 169; iter: 0; batch classifier loss: 0.120803; batch adversarial loss: 0.397408\n",
      "epoch 170; iter: 0; batch classifier loss: 0.100827; batch adversarial loss: 0.395393\n",
      "epoch 171; iter: 0; batch classifier loss: 0.082954; batch adversarial loss: 0.414406\n",
      "epoch 172; iter: 0; batch classifier loss: 0.082237; batch adversarial loss: 0.384915\n",
      "epoch 173; iter: 0; batch classifier loss: 0.070635; batch adversarial loss: 0.459715\n",
      "epoch 174; iter: 0; batch classifier loss: 0.107173; batch adversarial loss: 0.472315\n",
      "epoch 175; iter: 0; batch classifier loss: 0.062030; batch adversarial loss: 0.416020\n",
      "epoch 176; iter: 0; batch classifier loss: 0.089478; batch adversarial loss: 0.439170\n",
      "epoch 177; iter: 0; batch classifier loss: 0.113017; batch adversarial loss: 0.371371\n",
      "epoch 178; iter: 0; batch classifier loss: 0.082533; batch adversarial loss: 0.464946\n",
      "epoch 179; iter: 0; batch classifier loss: 0.092182; batch adversarial loss: 0.414055\n",
      "epoch 180; iter: 0; batch classifier loss: 0.059103; batch adversarial loss: 0.462595\n",
      "epoch 181; iter: 0; batch classifier loss: 0.055968; batch adversarial loss: 0.458123\n",
      "epoch 182; iter: 0; batch classifier loss: 0.085527; batch adversarial loss: 0.413862\n",
      "epoch 183; iter: 0; batch classifier loss: 0.093784; batch adversarial loss: 0.379637\n",
      "epoch 184; iter: 0; batch classifier loss: 0.067459; batch adversarial loss: 0.440379\n",
      "epoch 185; iter: 0; batch classifier loss: 0.054613; batch adversarial loss: 0.511572\n",
      "epoch 186; iter: 0; batch classifier loss: 0.080388; batch adversarial loss: 0.429065\n",
      "epoch 187; iter: 0; batch classifier loss: 0.044553; batch adversarial loss: 0.512046\n",
      "epoch 188; iter: 0; batch classifier loss: 0.052769; batch adversarial loss: 0.530890\n",
      "epoch 189; iter: 0; batch classifier loss: 0.059912; batch adversarial loss: 0.409122\n",
      "epoch 190; iter: 0; batch classifier loss: 0.061955; batch adversarial loss: 0.397853\n",
      "epoch 191; iter: 0; batch classifier loss: 0.066529; batch adversarial loss: 0.491768\n",
      "epoch 192; iter: 0; batch classifier loss: 0.059622; batch adversarial loss: 0.444652\n",
      "epoch 193; iter: 0; batch classifier loss: 0.050971; batch adversarial loss: 0.434580\n",
      "epoch 194; iter: 0; batch classifier loss: 0.063327; batch adversarial loss: 0.496882\n",
      "epoch 195; iter: 0; batch classifier loss: 0.066556; batch adversarial loss: 0.419048\n",
      "epoch 196; iter: 0; batch classifier loss: 0.073386; batch adversarial loss: 0.432995\n",
      "epoch 197; iter: 0; batch classifier loss: 0.109218; batch adversarial loss: 0.407481\n",
      "epoch 198; iter: 0; batch classifier loss: 0.055865; batch adversarial loss: 0.449528\n",
      "epoch 199; iter: 0; batch classifier loss: 0.052342; batch adversarial loss: 0.437821\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693100; batch adversarial loss: 0.571918\n",
      "epoch 1; iter: 0; batch classifier loss: 0.409689; batch adversarial loss: 0.592415\n",
      "epoch 2; iter: 0; batch classifier loss: 0.509984; batch adversarial loss: 0.547261\n",
      "epoch 3; iter: 0; batch classifier loss: 0.404603; batch adversarial loss: 0.553904\n",
      "epoch 4; iter: 0; batch classifier loss: 0.358317; batch adversarial loss: 0.568786\n",
      "epoch 5; iter: 0; batch classifier loss: 0.408038; batch adversarial loss: 0.571745\n",
      "epoch 6; iter: 0; batch classifier loss: 0.364753; batch adversarial loss: 0.534224\n",
      "epoch 7; iter: 0; batch classifier loss: 0.288514; batch adversarial loss: 0.564430\n",
      "epoch 8; iter: 0; batch classifier loss: 0.278331; batch adversarial loss: 0.481640\n",
      "epoch 9; iter: 0; batch classifier loss: 0.288859; batch adversarial loss: 0.513008\n",
      "epoch 10; iter: 0; batch classifier loss: 0.315499; batch adversarial loss: 0.571727\n",
      "epoch 11; iter: 0; batch classifier loss: 0.256760; batch adversarial loss: 0.467948\n",
      "epoch 12; iter: 0; batch classifier loss: 0.275073; batch adversarial loss: 0.512653\n",
      "epoch 13; iter: 0; batch classifier loss: 0.214113; batch adversarial loss: 0.487984\n",
      "epoch 14; iter: 0; batch classifier loss: 0.286595; batch adversarial loss: 0.556436\n",
      "epoch 15; iter: 0; batch classifier loss: 0.304356; batch adversarial loss: 0.608156\n",
      "epoch 16; iter: 0; batch classifier loss: 0.296884; batch adversarial loss: 0.552440\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241928; batch adversarial loss: 0.554076\n",
      "epoch 18; iter: 0; batch classifier loss: 0.300115; batch adversarial loss: 0.535399\n",
      "epoch 19; iter: 0; batch classifier loss: 0.354878; batch adversarial loss: 0.563226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.364407; batch adversarial loss: 0.513580\n",
      "epoch 21; iter: 0; batch classifier loss: 0.407060; batch adversarial loss: 0.449869\n",
      "epoch 22; iter: 0; batch classifier loss: 0.534911; batch adversarial loss: 0.535362\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285579; batch adversarial loss: 0.497305\n",
      "epoch 24; iter: 0; batch classifier loss: 0.200777; batch adversarial loss: 0.429770\n",
      "epoch 25; iter: 0; batch classifier loss: 0.216474; batch adversarial loss: 0.456949\n",
      "epoch 26; iter: 0; batch classifier loss: 0.190512; batch adversarial loss: 0.418785\n",
      "epoch 27; iter: 0; batch classifier loss: 0.139734; batch adversarial loss: 0.480352\n",
      "epoch 28; iter: 0; batch classifier loss: 0.140938; batch adversarial loss: 0.453520\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178379; batch adversarial loss: 0.453828\n",
      "epoch 30; iter: 0; batch classifier loss: 0.125560; batch adversarial loss: 0.520945\n",
      "epoch 31; iter: 0; batch classifier loss: 0.106982; batch adversarial loss: 0.416212\n",
      "epoch 32; iter: 0; batch classifier loss: 0.164893; batch adversarial loss: 0.463651\n",
      "epoch 33; iter: 0; batch classifier loss: 0.154147; batch adversarial loss: 0.420107\n",
      "epoch 34; iter: 0; batch classifier loss: 0.111634; batch adversarial loss: 0.473169\n",
      "epoch 35; iter: 0; batch classifier loss: 0.161786; batch adversarial loss: 0.449117\n",
      "epoch 36; iter: 0; batch classifier loss: 0.098756; batch adversarial loss: 0.512009\n",
      "epoch 37; iter: 0; batch classifier loss: 0.148822; batch adversarial loss: 0.459372\n",
      "epoch 38; iter: 0; batch classifier loss: 0.089426; batch adversarial loss: 0.499801\n",
      "epoch 39; iter: 0; batch classifier loss: 0.103685; batch adversarial loss: 0.491192\n",
      "epoch 40; iter: 0; batch classifier loss: 0.132958; batch adversarial loss: 0.424964\n",
      "epoch 41; iter: 0; batch classifier loss: 0.100561; batch adversarial loss: 0.532195\n",
      "epoch 42; iter: 0; batch classifier loss: 0.161576; batch adversarial loss: 0.362325\n",
      "epoch 43; iter: 0; batch classifier loss: 0.125498; batch adversarial loss: 0.492953\n",
      "epoch 44; iter: 0; batch classifier loss: 0.144164; batch adversarial loss: 0.534312\n",
      "epoch 45; iter: 0; batch classifier loss: 0.150168; batch adversarial loss: 0.461385\n",
      "epoch 46; iter: 0; batch classifier loss: 0.083987; batch adversarial loss: 0.423298\n",
      "epoch 47; iter: 0; batch classifier loss: 0.130343; batch adversarial loss: 0.496761\n",
      "epoch 48; iter: 0; batch classifier loss: 0.115913; batch adversarial loss: 0.474784\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119368; batch adversarial loss: 0.455352\n",
      "epoch 50; iter: 0; batch classifier loss: 0.149207; batch adversarial loss: 0.586915\n",
      "epoch 51; iter: 0; batch classifier loss: 0.115773; batch adversarial loss: 0.523663\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111760; batch adversarial loss: 0.453803\n",
      "epoch 53; iter: 0; batch classifier loss: 0.082758; batch adversarial loss: 0.453159\n",
      "epoch 54; iter: 0; batch classifier loss: 0.144070; batch adversarial loss: 0.390046\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089404; batch adversarial loss: 0.459896\n",
      "epoch 56; iter: 0; batch classifier loss: 0.122870; batch adversarial loss: 0.505620\n",
      "epoch 57; iter: 0; batch classifier loss: 0.180024; batch adversarial loss: 0.504794\n",
      "epoch 58; iter: 0; batch classifier loss: 0.137757; batch adversarial loss: 0.428512\n",
      "epoch 59; iter: 0; batch classifier loss: 0.143576; batch adversarial loss: 0.384841\n",
      "epoch 60; iter: 0; batch classifier loss: 0.138689; batch adversarial loss: 0.407075\n",
      "epoch 61; iter: 0; batch classifier loss: 0.144266; batch adversarial loss: 0.427919\n",
      "epoch 62; iter: 0; batch classifier loss: 0.141098; batch adversarial loss: 0.514510\n",
      "epoch 63; iter: 0; batch classifier loss: 0.163439; batch adversarial loss: 0.615131\n",
      "epoch 64; iter: 0; batch classifier loss: 0.129189; batch adversarial loss: 0.473427\n",
      "epoch 65; iter: 0; batch classifier loss: 0.116025; batch adversarial loss: 0.511332\n",
      "epoch 66; iter: 0; batch classifier loss: 0.119004; batch adversarial loss: 0.446141\n",
      "epoch 67; iter: 0; batch classifier loss: 0.112723; batch adversarial loss: 0.447354\n",
      "epoch 68; iter: 0; batch classifier loss: 0.187033; batch adversarial loss: 0.369356\n",
      "epoch 69; iter: 0; batch classifier loss: 0.130870; batch adversarial loss: 0.469868\n",
      "epoch 70; iter: 0; batch classifier loss: 0.085116; batch adversarial loss: 0.511497\n",
      "epoch 71; iter: 0; batch classifier loss: 0.215216; batch adversarial loss: 0.420417\n",
      "epoch 72; iter: 0; batch classifier loss: 0.161443; batch adversarial loss: 0.404569\n",
      "epoch 73; iter: 0; batch classifier loss: 0.163755; batch adversarial loss: 0.483316\n",
      "epoch 74; iter: 0; batch classifier loss: 0.122083; batch adversarial loss: 0.453762\n",
      "epoch 75; iter: 0; batch classifier loss: 0.105399; batch adversarial loss: 0.418232\n",
      "epoch 76; iter: 0; batch classifier loss: 0.148082; batch adversarial loss: 0.443261\n",
      "epoch 77; iter: 0; batch classifier loss: 0.133217; batch adversarial loss: 0.445707\n",
      "epoch 78; iter: 0; batch classifier loss: 0.151456; batch adversarial loss: 0.444361\n",
      "epoch 79; iter: 0; batch classifier loss: 0.099152; batch adversarial loss: 0.393237\n",
      "epoch 80; iter: 0; batch classifier loss: 0.178752; batch adversarial loss: 0.445124\n",
      "epoch 81; iter: 0; batch classifier loss: 0.210573; batch adversarial loss: 0.393224\n",
      "epoch 82; iter: 0; batch classifier loss: 0.189375; batch adversarial loss: 0.436295\n",
      "epoch 83; iter: 0; batch classifier loss: 0.118841; batch adversarial loss: 0.411501\n",
      "epoch 84; iter: 0; batch classifier loss: 0.176146; batch adversarial loss: 0.414777\n",
      "epoch 85; iter: 0; batch classifier loss: 0.133512; batch adversarial loss: 0.473172\n",
      "epoch 86; iter: 0; batch classifier loss: 0.176944; batch adversarial loss: 0.459312\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073471; batch adversarial loss: 0.591558\n",
      "epoch 88; iter: 0; batch classifier loss: 0.183054; batch adversarial loss: 0.515349\n",
      "epoch 89; iter: 0; batch classifier loss: 0.128823; batch adversarial loss: 0.462561\n",
      "epoch 90; iter: 0; batch classifier loss: 0.095974; batch adversarial loss: 0.509048\n",
      "epoch 91; iter: 0; batch classifier loss: 0.156653; batch adversarial loss: 0.494490\n",
      "epoch 92; iter: 0; batch classifier loss: 0.167440; batch adversarial loss: 0.448950\n",
      "epoch 93; iter: 0; batch classifier loss: 0.180608; batch adversarial loss: 0.509440\n",
      "epoch 94; iter: 0; batch classifier loss: 0.127344; batch adversarial loss: 0.421069\n",
      "epoch 95; iter: 0; batch classifier loss: 0.123026; batch adversarial loss: 0.403843\n",
      "epoch 96; iter: 0; batch classifier loss: 0.155569; batch adversarial loss: 0.481492\n",
      "epoch 97; iter: 0; batch classifier loss: 0.134036; batch adversarial loss: 0.425356\n",
      "epoch 98; iter: 0; batch classifier loss: 0.165009; batch adversarial loss: 0.449396\n",
      "epoch 99; iter: 0; batch classifier loss: 0.135273; batch adversarial loss: 0.456542\n",
      "epoch 100; iter: 0; batch classifier loss: 0.150613; batch adversarial loss: 0.336676\n",
      "epoch 101; iter: 0; batch classifier loss: 0.152796; batch adversarial loss: 0.412304\n",
      "epoch 102; iter: 0; batch classifier loss: 0.149149; batch adversarial loss: 0.430831\n",
      "epoch 103; iter: 0; batch classifier loss: 0.149323; batch adversarial loss: 0.519434\n",
      "epoch 104; iter: 0; batch classifier loss: 0.095660; batch adversarial loss: 0.467748\n",
      "epoch 105; iter: 0; batch classifier loss: 0.113004; batch adversarial loss: 0.395337\n",
      "epoch 106; iter: 0; batch classifier loss: 0.065335; batch adversarial loss: 0.434251\n",
      "epoch 107; iter: 0; batch classifier loss: 0.091432; batch adversarial loss: 0.464696\n",
      "epoch 108; iter: 0; batch classifier loss: 0.106479; batch adversarial loss: 0.437257\n",
      "epoch 109; iter: 0; batch classifier loss: 0.115331; batch adversarial loss: 0.369150\n",
      "epoch 110; iter: 0; batch classifier loss: 0.100355; batch adversarial loss: 0.393549\n",
      "epoch 111; iter: 0; batch classifier loss: 0.090841; batch adversarial loss: 0.396013\n",
      "epoch 112; iter: 0; batch classifier loss: 0.076234; batch adversarial loss: 0.495345\n",
      "epoch 113; iter: 0; batch classifier loss: 0.117308; batch adversarial loss: 0.389860\n",
      "epoch 114; iter: 0; batch classifier loss: 0.074357; batch adversarial loss: 0.420785\n",
      "epoch 115; iter: 0; batch classifier loss: 0.086411; batch adversarial loss: 0.462094\n",
      "epoch 116; iter: 0; batch classifier loss: 0.064473; batch adversarial loss: 0.504973\n",
      "epoch 117; iter: 0; batch classifier loss: 0.064017; batch adversarial loss: 0.460751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.061920; batch adversarial loss: 0.541365\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056310; batch adversarial loss: 0.514258\n",
      "epoch 120; iter: 0; batch classifier loss: 0.067105; batch adversarial loss: 0.394726\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044983; batch adversarial loss: 0.418733\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048440; batch adversarial loss: 0.425576\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032020; batch adversarial loss: 0.448235\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050058; batch adversarial loss: 0.380407\n",
      "epoch 125; iter: 0; batch classifier loss: 0.021642; batch adversarial loss: 0.429747\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044647; batch adversarial loss: 0.471945\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021898; batch adversarial loss: 0.530392\n",
      "epoch 128; iter: 0; batch classifier loss: 0.067596; batch adversarial loss: 0.435713\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023854; batch adversarial loss: 0.454096\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043667; batch adversarial loss: 0.458462\n",
      "epoch 131; iter: 0; batch classifier loss: 0.104625; batch adversarial loss: 0.469617\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039283; batch adversarial loss: 0.488380\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039840; batch adversarial loss: 0.409746\n",
      "epoch 134; iter: 0; batch classifier loss: 0.047726; batch adversarial loss: 0.413827\n",
      "epoch 135; iter: 0; batch classifier loss: 0.055636; batch adversarial loss: 0.500536\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038370; batch adversarial loss: 0.395502\n",
      "epoch 137; iter: 0; batch classifier loss: 0.062924; batch adversarial loss: 0.404049\n",
      "epoch 138; iter: 0; batch classifier loss: 0.057431; batch adversarial loss: 0.429002\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044172; batch adversarial loss: 0.456119\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038943; batch adversarial loss: 0.464595\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032370; batch adversarial loss: 0.367320\n",
      "epoch 142; iter: 0; batch classifier loss: 0.070873; batch adversarial loss: 0.476081\n",
      "epoch 143; iter: 0; batch classifier loss: 0.054288; batch adversarial loss: 0.510836\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033097; batch adversarial loss: 0.521531\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032637; batch adversarial loss: 0.494611\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025307; batch adversarial loss: 0.431441\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036020; batch adversarial loss: 0.494900\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028162; batch adversarial loss: 0.351814\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021230; batch adversarial loss: 0.450392\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035641; batch adversarial loss: 0.434435\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027198; batch adversarial loss: 0.463981\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039522; batch adversarial loss: 0.419294\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024916; batch adversarial loss: 0.415457\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033036; batch adversarial loss: 0.457048\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036156; batch adversarial loss: 0.389285\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016618; batch adversarial loss: 0.451994\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031584; batch adversarial loss: 0.462590\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022740; batch adversarial loss: 0.414376\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021279; batch adversarial loss: 0.395151\n",
      "epoch 160; iter: 0; batch classifier loss: 0.060899; batch adversarial loss: 0.451716\n",
      "epoch 161; iter: 0; batch classifier loss: 0.067904; batch adversarial loss: 0.400292\n",
      "epoch 162; iter: 0; batch classifier loss: 0.065606; batch adversarial loss: 0.504448\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035019; batch adversarial loss: 0.466191\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020973; batch adversarial loss: 0.479022\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027592; batch adversarial loss: 0.475902\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020935; batch adversarial loss: 0.430183\n",
      "epoch 167; iter: 0; batch classifier loss: 0.040790; batch adversarial loss: 0.537303\n",
      "epoch 168; iter: 0; batch classifier loss: 0.057582; batch adversarial loss: 0.410552\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034613; batch adversarial loss: 0.414030\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026101; batch adversarial loss: 0.517403\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033425; batch adversarial loss: 0.408396\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028192; batch adversarial loss: 0.385155\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038016; batch adversarial loss: 0.437374\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022908; batch adversarial loss: 0.448710\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008647; batch adversarial loss: 0.600503\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024491; batch adversarial loss: 0.423730\n",
      "epoch 177; iter: 0; batch classifier loss: 0.060095; batch adversarial loss: 0.373848\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022414; batch adversarial loss: 0.476236\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039491; batch adversarial loss: 0.348583\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024363; batch adversarial loss: 0.481033\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013666; batch adversarial loss: 0.428063\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021717; batch adversarial loss: 0.436811\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015968; batch adversarial loss: 0.460382\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029786; batch adversarial loss: 0.471865\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013341; batch adversarial loss: 0.494475\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018295; batch adversarial loss: 0.524923\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009712; batch adversarial loss: 0.393758\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025327; batch adversarial loss: 0.402065\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019535; batch adversarial loss: 0.443100\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014934; batch adversarial loss: 0.353754\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025375; batch adversarial loss: 0.503968\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013280; batch adversarial loss: 0.462862\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007351; batch adversarial loss: 0.421842\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021234; batch adversarial loss: 0.505705\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016862; batch adversarial loss: 0.533729\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028420; batch adversarial loss: 0.542257\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016233; batch adversarial loss: 0.490566\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011074; batch adversarial loss: 0.462346\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012452; batch adversarial loss: 0.446208\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702890; batch adversarial loss: 0.796960\n",
      "epoch 1; iter: 0; batch classifier loss: 0.442129; batch adversarial loss: 0.723357\n",
      "epoch 2; iter: 0; batch classifier loss: 0.527683; batch adversarial loss: 0.698458\n",
      "epoch 3; iter: 0; batch classifier loss: 0.685700; batch adversarial loss: 0.681501\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548359; batch adversarial loss: 0.590548\n",
      "epoch 5; iter: 0; batch classifier loss: 0.502377; batch adversarial loss: 0.599813\n",
      "epoch 6; iter: 0; batch classifier loss: 0.415200; batch adversarial loss: 0.581933\n",
      "epoch 7; iter: 0; batch classifier loss: 0.378528; batch adversarial loss: 0.566388\n",
      "epoch 8; iter: 0; batch classifier loss: 0.321459; batch adversarial loss: 0.529460\n",
      "epoch 9; iter: 0; batch classifier loss: 0.326901; batch adversarial loss: 0.548693\n",
      "epoch 10; iter: 0; batch classifier loss: 0.329689; batch adversarial loss: 0.566682\n",
      "epoch 11; iter: 0; batch classifier loss: 0.371696; batch adversarial loss: 0.529202\n",
      "epoch 12; iter: 0; batch classifier loss: 0.269838; batch adversarial loss: 0.543089\n",
      "epoch 13; iter: 0; batch classifier loss: 0.361626; batch adversarial loss: 0.537452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.314942; batch adversarial loss: 0.496989\n",
      "epoch 15; iter: 0; batch classifier loss: 0.289486; batch adversarial loss: 0.494969\n",
      "epoch 16; iter: 0; batch classifier loss: 0.303130; batch adversarial loss: 0.517394\n",
      "epoch 17; iter: 0; batch classifier loss: 0.303168; batch adversarial loss: 0.500124\n",
      "epoch 18; iter: 0; batch classifier loss: 0.265845; batch adversarial loss: 0.514733\n",
      "epoch 19; iter: 0; batch classifier loss: 0.222470; batch adversarial loss: 0.557499\n",
      "epoch 20; iter: 0; batch classifier loss: 0.288568; batch adversarial loss: 0.512995\n",
      "epoch 21; iter: 0; batch classifier loss: 0.267969; batch adversarial loss: 0.454781\n",
      "epoch 22; iter: 0; batch classifier loss: 0.330083; batch adversarial loss: 0.496096\n",
      "epoch 23; iter: 0; batch classifier loss: 0.307152; batch adversarial loss: 0.505741\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280641; batch adversarial loss: 0.440540\n",
      "epoch 25; iter: 0; batch classifier loss: 0.310117; batch adversarial loss: 0.496903\n",
      "epoch 26; iter: 0; batch classifier loss: 0.261449; batch adversarial loss: 0.419698\n",
      "epoch 27; iter: 0; batch classifier loss: 0.299479; batch adversarial loss: 0.509717\n",
      "epoch 28; iter: 0; batch classifier loss: 0.247194; batch adversarial loss: 0.469622\n",
      "epoch 29; iter: 0; batch classifier loss: 0.262127; batch adversarial loss: 0.434670\n",
      "epoch 30; iter: 0; batch classifier loss: 0.246132; batch adversarial loss: 0.391924\n",
      "epoch 31; iter: 0; batch classifier loss: 0.245140; batch adversarial loss: 0.528231\n",
      "epoch 32; iter: 0; batch classifier loss: 0.185049; batch adversarial loss: 0.495646\n",
      "epoch 33; iter: 0; batch classifier loss: 0.168905; batch adversarial loss: 0.487972\n",
      "epoch 34; iter: 0; batch classifier loss: 0.180000; batch adversarial loss: 0.483626\n",
      "epoch 35; iter: 0; batch classifier loss: 0.202016; batch adversarial loss: 0.460183\n",
      "epoch 36; iter: 0; batch classifier loss: 0.177993; batch adversarial loss: 0.475183\n",
      "epoch 37; iter: 0; batch classifier loss: 0.216129; batch adversarial loss: 0.441048\n",
      "epoch 38; iter: 0; batch classifier loss: 0.227269; batch adversarial loss: 0.404061\n",
      "epoch 39; iter: 0; batch classifier loss: 0.213625; batch adversarial loss: 0.497674\n",
      "epoch 40; iter: 0; batch classifier loss: 0.205921; batch adversarial loss: 0.513353\n",
      "epoch 41; iter: 0; batch classifier loss: 0.214045; batch adversarial loss: 0.449245\n",
      "epoch 42; iter: 0; batch classifier loss: 0.228288; batch adversarial loss: 0.420711\n",
      "epoch 43; iter: 0; batch classifier loss: 0.221413; batch adversarial loss: 0.528351\n",
      "epoch 44; iter: 0; batch classifier loss: 0.261959; batch adversarial loss: 0.509044\n",
      "epoch 45; iter: 0; batch classifier loss: 0.176870; batch adversarial loss: 0.474103\n",
      "epoch 46; iter: 0; batch classifier loss: 0.166707; batch adversarial loss: 0.527810\n",
      "epoch 47; iter: 0; batch classifier loss: 0.235679; batch adversarial loss: 0.438286\n",
      "epoch 48; iter: 0; batch classifier loss: 0.175567; batch adversarial loss: 0.523114\n",
      "epoch 49; iter: 0; batch classifier loss: 0.139965; batch adversarial loss: 0.453912\n",
      "epoch 50; iter: 0; batch classifier loss: 0.170196; batch adversarial loss: 0.466610\n",
      "epoch 51; iter: 0; batch classifier loss: 0.228049; batch adversarial loss: 0.416959\n",
      "epoch 52; iter: 0; batch classifier loss: 0.197001; batch adversarial loss: 0.615815\n",
      "epoch 53; iter: 0; batch classifier loss: 0.167233; batch adversarial loss: 0.559126\n",
      "epoch 54; iter: 0; batch classifier loss: 0.193180; batch adversarial loss: 0.455920\n",
      "epoch 55; iter: 0; batch classifier loss: 0.131889; batch adversarial loss: 0.469122\n",
      "epoch 56; iter: 0; batch classifier loss: 0.146557; batch adversarial loss: 0.469090\n",
      "epoch 57; iter: 0; batch classifier loss: 0.154960; batch adversarial loss: 0.477705\n",
      "epoch 58; iter: 0; batch classifier loss: 0.206539; batch adversarial loss: 0.540819\n",
      "epoch 59; iter: 0; batch classifier loss: 0.177405; batch adversarial loss: 0.518678\n",
      "epoch 60; iter: 0; batch classifier loss: 0.138677; batch adversarial loss: 0.505423\n",
      "epoch 61; iter: 0; batch classifier loss: 0.139806; batch adversarial loss: 0.517870\n",
      "epoch 62; iter: 0; batch classifier loss: 0.144657; batch adversarial loss: 0.505314\n",
      "epoch 63; iter: 0; batch classifier loss: 0.109361; batch adversarial loss: 0.431952\n",
      "epoch 64; iter: 0; batch classifier loss: 0.115155; batch adversarial loss: 0.450019\n",
      "epoch 65; iter: 0; batch classifier loss: 0.111678; batch adversarial loss: 0.407297\n",
      "epoch 66; iter: 0; batch classifier loss: 0.063596; batch adversarial loss: 0.526024\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079241; batch adversarial loss: 0.423992\n",
      "epoch 68; iter: 0; batch classifier loss: 0.075374; batch adversarial loss: 0.492071\n",
      "epoch 69; iter: 0; batch classifier loss: 0.066758; batch adversarial loss: 0.494984\n",
      "epoch 70; iter: 0; batch classifier loss: 0.089259; batch adversarial loss: 0.492682\n",
      "epoch 71; iter: 0; batch classifier loss: 0.076381; batch adversarial loss: 0.446955\n",
      "epoch 72; iter: 0; batch classifier loss: 0.088045; batch adversarial loss: 0.419076\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075196; batch adversarial loss: 0.424797\n",
      "epoch 74; iter: 0; batch classifier loss: 0.052665; batch adversarial loss: 0.553161\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076044; batch adversarial loss: 0.437461\n",
      "epoch 76; iter: 0; batch classifier loss: 0.059938; batch adversarial loss: 0.481436\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050132; batch adversarial loss: 0.501184\n",
      "epoch 78; iter: 0; batch classifier loss: 0.055779; batch adversarial loss: 0.486032\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072252; batch adversarial loss: 0.515515\n",
      "epoch 80; iter: 0; batch classifier loss: 0.085014; batch adversarial loss: 0.484175\n",
      "epoch 81; iter: 0; batch classifier loss: 0.072573; batch adversarial loss: 0.449288\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062039; batch adversarial loss: 0.419118\n",
      "epoch 83; iter: 0; batch classifier loss: 0.039957; batch adversarial loss: 0.500799\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067144; batch adversarial loss: 0.435813\n",
      "epoch 85; iter: 0; batch classifier loss: 0.020312; batch adversarial loss: 0.394946\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067030; batch adversarial loss: 0.428094\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042983; batch adversarial loss: 0.455982\n",
      "epoch 88; iter: 0; batch classifier loss: 0.037005; batch adversarial loss: 0.439603\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048950; batch adversarial loss: 0.414340\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056471; batch adversarial loss: 0.463005\n",
      "epoch 91; iter: 0; batch classifier loss: 0.044336; batch adversarial loss: 0.420755\n",
      "epoch 92; iter: 0; batch classifier loss: 0.036214; batch adversarial loss: 0.383041\n",
      "epoch 93; iter: 0; batch classifier loss: 0.042739; batch adversarial loss: 0.407274\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033113; batch adversarial loss: 0.474581\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054080; batch adversarial loss: 0.487807\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043734; batch adversarial loss: 0.510219\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050563; batch adversarial loss: 0.508494\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048822; batch adversarial loss: 0.503405\n",
      "epoch 99; iter: 0; batch classifier loss: 0.031214; batch adversarial loss: 0.430402\n",
      "epoch 100; iter: 0; batch classifier loss: 0.023736; batch adversarial loss: 0.429547\n",
      "epoch 101; iter: 0; batch classifier loss: 0.022289; batch adversarial loss: 0.375354\n",
      "epoch 102; iter: 0; batch classifier loss: 0.012047; batch adversarial loss: 0.497008\n",
      "epoch 103; iter: 0; batch classifier loss: 0.077556; batch adversarial loss: 0.511761\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027791; batch adversarial loss: 0.521544\n",
      "epoch 105; iter: 0; batch classifier loss: 0.068109; batch adversarial loss: 0.442066\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055291; batch adversarial loss: 0.406155\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040499; batch adversarial loss: 0.366013\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051811; batch adversarial loss: 0.477397\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045060; batch adversarial loss: 0.519970\n",
      "epoch 110; iter: 0; batch classifier loss: 0.017323; batch adversarial loss: 0.368560\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034457; batch adversarial loss: 0.426043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.055813; batch adversarial loss: 0.541738\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059006; batch adversarial loss: 0.490501\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046291; batch adversarial loss: 0.515298\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041102; batch adversarial loss: 0.445137\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030967; batch adversarial loss: 0.459595\n",
      "epoch 117; iter: 0; batch classifier loss: 0.011217; batch adversarial loss: 0.478349\n",
      "epoch 118; iter: 0; batch classifier loss: 0.062685; batch adversarial loss: 0.471290\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040101; batch adversarial loss: 0.456118\n",
      "epoch 120; iter: 0; batch classifier loss: 0.020172; batch adversarial loss: 0.460151\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029385; batch adversarial loss: 0.442099\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033375; batch adversarial loss: 0.429398\n",
      "epoch 123; iter: 0; batch classifier loss: 0.012307; batch adversarial loss: 0.463861\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067689; batch adversarial loss: 0.468856\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022959; batch adversarial loss: 0.490517\n",
      "epoch 126; iter: 0; batch classifier loss: 0.018855; batch adversarial loss: 0.343447\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025814; batch adversarial loss: 0.387635\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023179; batch adversarial loss: 0.456357\n",
      "epoch 129; iter: 0; batch classifier loss: 0.011681; batch adversarial loss: 0.453505\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021084; batch adversarial loss: 0.374723\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047846; batch adversarial loss: 0.424468\n",
      "epoch 132; iter: 0; batch classifier loss: 0.017854; batch adversarial loss: 0.319940\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030039; batch adversarial loss: 0.426026\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033008; batch adversarial loss: 0.503353\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012251; batch adversarial loss: 0.478250\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027635; batch adversarial loss: 0.420730\n",
      "epoch 137; iter: 0; batch classifier loss: 0.047589; batch adversarial loss: 0.517140\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028094; batch adversarial loss: 0.601227\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035579; batch adversarial loss: 0.414417\n",
      "epoch 140; iter: 0; batch classifier loss: 0.012617; batch adversarial loss: 0.410654\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026825; batch adversarial loss: 0.432077\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016902; batch adversarial loss: 0.381309\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011482; batch adversarial loss: 0.395605\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029605; batch adversarial loss: 0.438689\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016667; batch adversarial loss: 0.419527\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021541; batch adversarial loss: 0.482757\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026582; batch adversarial loss: 0.446436\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034345; batch adversarial loss: 0.468384\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037159; batch adversarial loss: 0.466300\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021438; batch adversarial loss: 0.478612\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019868; batch adversarial loss: 0.472172\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019158; batch adversarial loss: 0.434677\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018519; batch adversarial loss: 0.511435\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020884; batch adversarial loss: 0.451701\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046700; batch adversarial loss: 0.364687\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026766; batch adversarial loss: 0.367522\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035615; batch adversarial loss: 0.452367\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012066; batch adversarial loss: 0.388062\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012539; batch adversarial loss: 0.521610\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032163; batch adversarial loss: 0.425950\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038193; batch adversarial loss: 0.390364\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024162; batch adversarial loss: 0.372544\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027943; batch adversarial loss: 0.463731\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024471; batch adversarial loss: 0.455063\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008018; batch adversarial loss: 0.490339\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030481; batch adversarial loss: 0.502988\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023047; batch adversarial loss: 0.436347\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012871; batch adversarial loss: 0.446723\n",
      "epoch 169; iter: 0; batch classifier loss: 0.003350; batch adversarial loss: 0.484177\n",
      "epoch 170; iter: 0; batch classifier loss: 0.007860; batch adversarial loss: 0.489519\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015787; batch adversarial loss: 0.446466\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021420; batch adversarial loss: 0.446617\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016001; batch adversarial loss: 0.471250\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025975; batch adversarial loss: 0.466963\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019061; batch adversarial loss: 0.484173\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018046; batch adversarial loss: 0.449250\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016466; batch adversarial loss: 0.417513\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029949; batch adversarial loss: 0.445737\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006193; batch adversarial loss: 0.555770\n",
      "epoch 180; iter: 0; batch classifier loss: 0.003984; batch adversarial loss: 0.456104\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007368; batch adversarial loss: 0.451513\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023953; batch adversarial loss: 0.431434\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029659; batch adversarial loss: 0.346592\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011796; batch adversarial loss: 0.381951\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028569; batch adversarial loss: 0.506418\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022632; batch adversarial loss: 0.511074\n",
      "epoch 187; iter: 0; batch classifier loss: 0.003778; batch adversarial loss: 0.441752\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005918; batch adversarial loss: 0.358232\n",
      "epoch 189; iter: 0; batch classifier loss: 0.032004; batch adversarial loss: 0.464429\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011028; batch adversarial loss: 0.553616\n",
      "epoch 191; iter: 0; batch classifier loss: 0.004340; batch adversarial loss: 0.430603\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008593; batch adversarial loss: 0.387186\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013702; batch adversarial loss: 0.413040\n",
      "epoch 194; iter: 0; batch classifier loss: 0.043104; batch adversarial loss: 0.491587\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020515; batch adversarial loss: 0.433471\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018494; batch adversarial loss: 0.442176\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016605; batch adversarial loss: 0.458451\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037234; batch adversarial loss: 0.415939\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013322; batch adversarial loss: 0.459110\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680537; batch adversarial loss: 0.567721\n",
      "epoch 1; iter: 0; batch classifier loss: 0.481659; batch adversarial loss: 0.645756\n",
      "epoch 2; iter: 0; batch classifier loss: 0.382610; batch adversarial loss: 0.580584\n",
      "epoch 3; iter: 0; batch classifier loss: 0.380967; batch adversarial loss: 0.565692\n",
      "epoch 4; iter: 0; batch classifier loss: 0.400701; batch adversarial loss: 0.539570\n",
      "epoch 5; iter: 0; batch classifier loss: 0.285136; batch adversarial loss: 0.529595\n",
      "epoch 6; iter: 0; batch classifier loss: 0.292244; batch adversarial loss: 0.557088\n",
      "epoch 7; iter: 0; batch classifier loss: 0.284780; batch adversarial loss: 0.521362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.318431; batch adversarial loss: 0.529177\n",
      "epoch 9; iter: 0; batch classifier loss: 0.221314; batch adversarial loss: 0.518602\n",
      "epoch 10; iter: 0; batch classifier loss: 0.292000; batch adversarial loss: 0.511039\n",
      "epoch 11; iter: 0; batch classifier loss: 0.234285; batch adversarial loss: 0.493527\n",
      "epoch 12; iter: 0; batch classifier loss: 0.242001; batch adversarial loss: 0.488092\n",
      "epoch 13; iter: 0; batch classifier loss: 0.246395; batch adversarial loss: 0.540057\n",
      "epoch 14; iter: 0; batch classifier loss: 0.297951; batch adversarial loss: 0.482028\n",
      "epoch 15; iter: 0; batch classifier loss: 0.235755; batch adversarial loss: 0.544713\n",
      "epoch 16; iter: 0; batch classifier loss: 0.296287; batch adversarial loss: 0.544146\n",
      "epoch 17; iter: 0; batch classifier loss: 0.280972; batch adversarial loss: 0.436897\n",
      "epoch 18; iter: 0; batch classifier loss: 0.284951; batch adversarial loss: 0.429763\n",
      "epoch 19; iter: 0; batch classifier loss: 0.301633; batch adversarial loss: 0.424875\n",
      "epoch 20; iter: 0; batch classifier loss: 0.406258; batch adversarial loss: 0.575508\n",
      "epoch 21; iter: 0; batch classifier loss: 0.476739; batch adversarial loss: 0.576262\n",
      "epoch 22; iter: 0; batch classifier loss: 0.478174; batch adversarial loss: 0.447516\n",
      "epoch 23; iter: 0; batch classifier loss: 0.318876; batch adversarial loss: 0.414989\n",
      "epoch 24; iter: 0; batch classifier loss: 0.283055; batch adversarial loss: 0.449381\n",
      "epoch 25; iter: 0; batch classifier loss: 0.204614; batch adversarial loss: 0.554596\n",
      "epoch 26; iter: 0; batch classifier loss: 0.124965; batch adversarial loss: 0.436518\n",
      "epoch 27; iter: 0; batch classifier loss: 0.169402; batch adversarial loss: 0.428895\n",
      "epoch 28; iter: 0; batch classifier loss: 0.170627; batch adversarial loss: 0.463480\n",
      "epoch 29; iter: 0; batch classifier loss: 0.189540; batch adversarial loss: 0.460508\n",
      "epoch 30; iter: 0; batch classifier loss: 0.118969; batch adversarial loss: 0.496901\n",
      "epoch 31; iter: 0; batch classifier loss: 0.165541; batch adversarial loss: 0.481029\n",
      "epoch 32; iter: 0; batch classifier loss: 0.158422; batch adversarial loss: 0.372829\n",
      "epoch 33; iter: 0; batch classifier loss: 0.109132; batch adversarial loss: 0.402090\n",
      "epoch 34; iter: 0; batch classifier loss: 0.088238; batch adversarial loss: 0.453502\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122484; batch adversarial loss: 0.425244\n",
      "epoch 36; iter: 0; batch classifier loss: 0.151783; batch adversarial loss: 0.481261\n",
      "epoch 37; iter: 0; batch classifier loss: 0.158710; batch adversarial loss: 0.449848\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107149; batch adversarial loss: 0.461768\n",
      "epoch 39; iter: 0; batch classifier loss: 0.090615; batch adversarial loss: 0.450763\n",
      "epoch 40; iter: 0; batch classifier loss: 0.089336; batch adversarial loss: 0.446424\n",
      "epoch 41; iter: 0; batch classifier loss: 0.088301; batch adversarial loss: 0.429129\n",
      "epoch 42; iter: 0; batch classifier loss: 0.102602; batch adversarial loss: 0.421718\n",
      "epoch 43; iter: 0; batch classifier loss: 0.106336; batch adversarial loss: 0.460512\n",
      "epoch 44; iter: 0; batch classifier loss: 0.122055; batch adversarial loss: 0.564932\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102424; batch adversarial loss: 0.466823\n",
      "epoch 46; iter: 0; batch classifier loss: 0.120868; batch adversarial loss: 0.446128\n",
      "epoch 47; iter: 0; batch classifier loss: 0.143648; batch adversarial loss: 0.448607\n",
      "epoch 48; iter: 0; batch classifier loss: 0.154729; batch adversarial loss: 0.464910\n",
      "epoch 49; iter: 0; batch classifier loss: 0.127194; batch adversarial loss: 0.455003\n",
      "epoch 50; iter: 0; batch classifier loss: 0.141328; batch adversarial loss: 0.464330\n",
      "epoch 51; iter: 0; batch classifier loss: 0.107951; batch adversarial loss: 0.441428\n",
      "epoch 52; iter: 0; batch classifier loss: 0.129521; batch adversarial loss: 0.423011\n",
      "epoch 53; iter: 0; batch classifier loss: 0.118458; batch adversarial loss: 0.471963\n",
      "epoch 54; iter: 0; batch classifier loss: 0.117010; batch adversarial loss: 0.440063\n",
      "epoch 55; iter: 0; batch classifier loss: 0.141054; batch adversarial loss: 0.420310\n",
      "epoch 56; iter: 0; batch classifier loss: 0.157937; batch adversarial loss: 0.353585\n",
      "epoch 57; iter: 0; batch classifier loss: 0.064495; batch adversarial loss: 0.483804\n",
      "epoch 58; iter: 0; batch classifier loss: 0.110990; batch adversarial loss: 0.403434\n",
      "epoch 59; iter: 0; batch classifier loss: 0.106564; batch adversarial loss: 0.443833\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105496; batch adversarial loss: 0.454204\n",
      "epoch 61; iter: 0; batch classifier loss: 0.095373; batch adversarial loss: 0.473799\n",
      "epoch 62; iter: 0; batch classifier loss: 0.095804; batch adversarial loss: 0.513646\n",
      "epoch 63; iter: 0; batch classifier loss: 0.126085; batch adversarial loss: 0.497294\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098516; batch adversarial loss: 0.381389\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110120; batch adversarial loss: 0.349266\n",
      "epoch 66; iter: 0; batch classifier loss: 0.117826; batch adversarial loss: 0.383216\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100448; batch adversarial loss: 0.509055\n",
      "epoch 68; iter: 0; batch classifier loss: 0.113236; batch adversarial loss: 0.399076\n",
      "epoch 69; iter: 0; batch classifier loss: 0.089553; batch adversarial loss: 0.480777\n",
      "epoch 70; iter: 0; batch classifier loss: 0.106966; batch adversarial loss: 0.330087\n",
      "epoch 71; iter: 0; batch classifier loss: 0.094984; batch adversarial loss: 0.398730\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064572; batch adversarial loss: 0.455832\n",
      "epoch 73; iter: 0; batch classifier loss: 0.108425; batch adversarial loss: 0.517573\n",
      "epoch 74; iter: 0; batch classifier loss: 0.111843; batch adversarial loss: 0.473230\n",
      "epoch 75; iter: 0; batch classifier loss: 0.107726; batch adversarial loss: 0.408097\n",
      "epoch 76; iter: 0; batch classifier loss: 0.106970; batch adversarial loss: 0.482725\n",
      "epoch 77; iter: 0; batch classifier loss: 0.085527; batch adversarial loss: 0.391497\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064040; batch adversarial loss: 0.401913\n",
      "epoch 79; iter: 0; batch classifier loss: 0.120436; batch adversarial loss: 0.432718\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075221; batch adversarial loss: 0.452756\n",
      "epoch 81; iter: 0; batch classifier loss: 0.108624; batch adversarial loss: 0.380869\n",
      "epoch 82; iter: 0; batch classifier loss: 0.105520; batch adversarial loss: 0.548468\n",
      "epoch 83; iter: 0; batch classifier loss: 0.105105; batch adversarial loss: 0.380013\n",
      "epoch 84; iter: 0; batch classifier loss: 0.090504; batch adversarial loss: 0.346333\n",
      "epoch 85; iter: 0; batch classifier loss: 0.080325; batch adversarial loss: 0.414955\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051675; batch adversarial loss: 0.502463\n",
      "epoch 87; iter: 0; batch classifier loss: 0.087589; batch adversarial loss: 0.429125\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073444; batch adversarial loss: 0.457290\n",
      "epoch 89; iter: 0; batch classifier loss: 0.136500; batch adversarial loss: 0.386081\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057429; batch adversarial loss: 0.377326\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060421; batch adversarial loss: 0.483007\n",
      "epoch 92; iter: 0; batch classifier loss: 0.101109; batch adversarial loss: 0.441240\n",
      "epoch 93; iter: 0; batch classifier loss: 0.123348; batch adversarial loss: 0.496473\n",
      "epoch 94; iter: 0; batch classifier loss: 0.105836; batch adversarial loss: 0.482230\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081958; batch adversarial loss: 0.337219\n",
      "epoch 96; iter: 0; batch classifier loss: 0.101643; batch adversarial loss: 0.430458\n",
      "epoch 97; iter: 0; batch classifier loss: 0.089244; batch adversarial loss: 0.417300\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047004; batch adversarial loss: 0.533121\n",
      "epoch 99; iter: 0; batch classifier loss: 0.111381; batch adversarial loss: 0.372437\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074040; batch adversarial loss: 0.385796\n",
      "epoch 101; iter: 0; batch classifier loss: 0.027678; batch adversarial loss: 0.427620\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066562; batch adversarial loss: 0.420949\n",
      "epoch 103; iter: 0; batch classifier loss: 0.096399; batch adversarial loss: 0.367180\n",
      "epoch 104; iter: 0; batch classifier loss: 0.088350; batch adversarial loss: 0.543244\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029235; batch adversarial loss: 0.430279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.126662; batch adversarial loss: 0.443774\n",
      "epoch 107; iter: 0; batch classifier loss: 0.082349; batch adversarial loss: 0.421829\n",
      "epoch 108; iter: 0; batch classifier loss: 0.063421; batch adversarial loss: 0.398388\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054589; batch adversarial loss: 0.473117\n",
      "epoch 110; iter: 0; batch classifier loss: 0.082724; batch adversarial loss: 0.437738\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050697; batch adversarial loss: 0.416983\n",
      "epoch 112; iter: 0; batch classifier loss: 0.080016; batch adversarial loss: 0.417531\n",
      "epoch 113; iter: 0; batch classifier loss: 0.094039; batch adversarial loss: 0.445219\n",
      "epoch 114; iter: 0; batch classifier loss: 0.112247; batch adversarial loss: 0.451487\n",
      "epoch 115; iter: 0; batch classifier loss: 0.071586; batch adversarial loss: 0.458959\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029790; batch adversarial loss: 0.454410\n",
      "epoch 117; iter: 0; batch classifier loss: 0.090847; batch adversarial loss: 0.538310\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051558; batch adversarial loss: 0.399304\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040891; batch adversarial loss: 0.412821\n",
      "epoch 120; iter: 0; batch classifier loss: 0.088103; batch adversarial loss: 0.425204\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032869; batch adversarial loss: 0.361733\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034024; batch adversarial loss: 0.466519\n",
      "epoch 123; iter: 0; batch classifier loss: 0.067006; batch adversarial loss: 0.426957\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024742; batch adversarial loss: 0.376590\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044096; batch adversarial loss: 0.469211\n",
      "epoch 126; iter: 0; batch classifier loss: 0.081454; batch adversarial loss: 0.382314\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048083; batch adversarial loss: 0.368517\n",
      "epoch 128; iter: 0; batch classifier loss: 0.059343; batch adversarial loss: 0.460598\n",
      "epoch 129; iter: 0; batch classifier loss: 0.055692; batch adversarial loss: 0.478830\n",
      "epoch 130; iter: 0; batch classifier loss: 0.069780; batch adversarial loss: 0.393753\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041064; batch adversarial loss: 0.415958\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050451; batch adversarial loss: 0.407642\n",
      "epoch 133; iter: 0; batch classifier loss: 0.072978; batch adversarial loss: 0.435113\n",
      "epoch 134; iter: 0; batch classifier loss: 0.058764; batch adversarial loss: 0.434969\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049130; batch adversarial loss: 0.500298\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039982; batch adversarial loss: 0.431110\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044386; batch adversarial loss: 0.479860\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031105; batch adversarial loss: 0.441916\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033440; batch adversarial loss: 0.345944\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035089; batch adversarial loss: 0.465187\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032173; batch adversarial loss: 0.470635\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048465; batch adversarial loss: 0.367229\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037404; batch adversarial loss: 0.398688\n",
      "epoch 144; iter: 0; batch classifier loss: 0.066864; batch adversarial loss: 0.415897\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046657; batch adversarial loss: 0.431933\n",
      "epoch 146; iter: 0; batch classifier loss: 0.049152; batch adversarial loss: 0.356054\n",
      "epoch 147; iter: 0; batch classifier loss: 0.083924; batch adversarial loss: 0.465477\n",
      "epoch 148; iter: 0; batch classifier loss: 0.053175; batch adversarial loss: 0.396881\n",
      "epoch 149; iter: 0; batch classifier loss: 0.052125; batch adversarial loss: 0.460232\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023836; batch adversarial loss: 0.555992\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013185; batch adversarial loss: 0.563417\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034428; batch adversarial loss: 0.490632\n",
      "epoch 153; iter: 0; batch classifier loss: 0.037461; batch adversarial loss: 0.445424\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035182; batch adversarial loss: 0.413954\n",
      "epoch 155; iter: 0; batch classifier loss: 0.048430; batch adversarial loss: 0.452924\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024894; batch adversarial loss: 0.396702\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029490; batch adversarial loss: 0.429489\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019816; batch adversarial loss: 0.410943\n",
      "epoch 159; iter: 0; batch classifier loss: 0.071040; batch adversarial loss: 0.417866\n",
      "epoch 160; iter: 0; batch classifier loss: 0.051525; batch adversarial loss: 0.475933\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043607; batch adversarial loss: 0.373115\n",
      "epoch 162; iter: 0; batch classifier loss: 0.040996; batch adversarial loss: 0.478944\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036553; batch adversarial loss: 0.465318\n",
      "epoch 164; iter: 0; batch classifier loss: 0.039315; batch adversarial loss: 0.357725\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008660; batch adversarial loss: 0.426502\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035619; batch adversarial loss: 0.466708\n",
      "epoch 167; iter: 0; batch classifier loss: 0.056798; batch adversarial loss: 0.401140\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021531; batch adversarial loss: 0.369278\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013255; batch adversarial loss: 0.461936\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030978; batch adversarial loss: 0.405091\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033305; batch adversarial loss: 0.527711\n",
      "epoch 172; iter: 0; batch classifier loss: 0.048700; batch adversarial loss: 0.488501\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013529; batch adversarial loss: 0.518554\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007354; batch adversarial loss: 0.529363\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033075; batch adversarial loss: 0.491265\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020581; batch adversarial loss: 0.426668\n",
      "epoch 177; iter: 0; batch classifier loss: 0.066040; batch adversarial loss: 0.470613\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019252; batch adversarial loss: 0.456306\n",
      "epoch 179; iter: 0; batch classifier loss: 0.075369; batch adversarial loss: 0.485751\n",
      "epoch 180; iter: 0; batch classifier loss: 0.107315; batch adversarial loss: 0.330255\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035329; batch adversarial loss: 0.433166\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025831; batch adversarial loss: 0.413565\n",
      "epoch 183; iter: 0; batch classifier loss: 0.046234; batch adversarial loss: 0.396287\n",
      "epoch 184; iter: 0; batch classifier loss: 0.052347; batch adversarial loss: 0.459742\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042684; batch adversarial loss: 0.481126\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040377; batch adversarial loss: 0.492646\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008214; batch adversarial loss: 0.467432\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010757; batch adversarial loss: 0.466633\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041898; batch adversarial loss: 0.418908\n",
      "epoch 190; iter: 0; batch classifier loss: 0.044164; batch adversarial loss: 0.398542\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015409; batch adversarial loss: 0.371628\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037848; batch adversarial loss: 0.449832\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024760; batch adversarial loss: 0.402053\n",
      "epoch 194; iter: 0; batch classifier loss: 0.038179; batch adversarial loss: 0.331214\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015769; batch adversarial loss: 0.390922\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004292; batch adversarial loss: 0.440336\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023587; batch adversarial loss: 0.358453\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026751; batch adversarial loss: 0.475226\n",
      "epoch 199; iter: 0; batch classifier loss: 0.037020; batch adversarial loss: 0.426917\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704091; batch adversarial loss: 0.814300\n",
      "epoch 1; iter: 0; batch classifier loss: 0.538371; batch adversarial loss: 0.764873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.800864; batch adversarial loss: 0.776442\n",
      "epoch 3; iter: 0; batch classifier loss: 0.673939; batch adversarial loss: 0.688201\n",
      "epoch 4; iter: 0; batch classifier loss: 0.537237; batch adversarial loss: 0.624455\n",
      "epoch 5; iter: 0; batch classifier loss: 0.369010; batch adversarial loss: 0.583321\n",
      "epoch 6; iter: 0; batch classifier loss: 0.391319; batch adversarial loss: 0.591975\n",
      "epoch 7; iter: 0; batch classifier loss: 0.303937; batch adversarial loss: 0.593520\n",
      "epoch 8; iter: 0; batch classifier loss: 0.358287; batch adversarial loss: 0.577316\n",
      "epoch 9; iter: 0; batch classifier loss: 0.371752; batch adversarial loss: 0.499313\n",
      "epoch 10; iter: 0; batch classifier loss: 0.282194; batch adversarial loss: 0.551201\n",
      "epoch 11; iter: 0; batch classifier loss: 0.284660; batch adversarial loss: 0.494828\n",
      "epoch 12; iter: 0; batch classifier loss: 0.263759; batch adversarial loss: 0.491039\n",
      "epoch 13; iter: 0; batch classifier loss: 0.278437; batch adversarial loss: 0.528525\n",
      "epoch 14; iter: 0; batch classifier loss: 0.325199; batch adversarial loss: 0.481595\n",
      "epoch 15; iter: 0; batch classifier loss: 0.243574; batch adversarial loss: 0.486243\n",
      "epoch 16; iter: 0; batch classifier loss: 0.271773; batch adversarial loss: 0.457885\n",
      "epoch 17; iter: 0; batch classifier loss: 0.282980; batch adversarial loss: 0.495329\n",
      "epoch 18; iter: 0; batch classifier loss: 0.199621; batch adversarial loss: 0.456457\n",
      "epoch 19; iter: 0; batch classifier loss: 0.238140; batch adversarial loss: 0.461845\n",
      "epoch 20; iter: 0; batch classifier loss: 0.153888; batch adversarial loss: 0.502003\n",
      "epoch 21; iter: 0; batch classifier loss: 0.193249; batch adversarial loss: 0.487537\n",
      "epoch 22; iter: 0; batch classifier loss: 0.283371; batch adversarial loss: 0.494801\n",
      "epoch 23; iter: 0; batch classifier loss: 0.186940; batch adversarial loss: 0.471498\n",
      "epoch 24; iter: 0; batch classifier loss: 0.188570; batch adversarial loss: 0.452570\n",
      "epoch 25; iter: 0; batch classifier loss: 0.185045; batch adversarial loss: 0.501150\n",
      "epoch 26; iter: 0; batch classifier loss: 0.263387; batch adversarial loss: 0.414582\n",
      "epoch 27; iter: 0; batch classifier loss: 0.214590; batch adversarial loss: 0.477239\n",
      "epoch 28; iter: 0; batch classifier loss: 0.167480; batch adversarial loss: 0.445288\n",
      "epoch 29; iter: 0; batch classifier loss: 0.202692; batch adversarial loss: 0.462470\n",
      "epoch 30; iter: 0; batch classifier loss: 0.159383; batch adversarial loss: 0.442882\n",
      "epoch 31; iter: 0; batch classifier loss: 0.227491; batch adversarial loss: 0.501185\n",
      "epoch 32; iter: 0; batch classifier loss: 0.182448; batch adversarial loss: 0.436497\n",
      "epoch 33; iter: 0; batch classifier loss: 0.141853; batch adversarial loss: 0.392793\n",
      "epoch 34; iter: 0; batch classifier loss: 0.165999; batch adversarial loss: 0.436947\n",
      "epoch 35; iter: 0; batch classifier loss: 0.194403; batch adversarial loss: 0.404312\n",
      "epoch 36; iter: 0; batch classifier loss: 0.165343; batch adversarial loss: 0.498905\n",
      "epoch 37; iter: 0; batch classifier loss: 0.230074; batch adversarial loss: 0.459746\n",
      "epoch 38; iter: 0; batch classifier loss: 0.181305; batch adversarial loss: 0.442305\n",
      "epoch 39; iter: 0; batch classifier loss: 0.171278; batch adversarial loss: 0.463329\n",
      "epoch 40; iter: 0; batch classifier loss: 0.210841; batch adversarial loss: 0.467343\n",
      "epoch 41; iter: 0; batch classifier loss: 0.161928; batch adversarial loss: 0.456684\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146531; batch adversarial loss: 0.418757\n",
      "epoch 43; iter: 0; batch classifier loss: 0.201875; batch adversarial loss: 0.459832\n",
      "epoch 44; iter: 0; batch classifier loss: 0.225641; batch adversarial loss: 0.466485\n",
      "epoch 45; iter: 0; batch classifier loss: 0.208406; batch adversarial loss: 0.396836\n",
      "epoch 46; iter: 0; batch classifier loss: 0.172901; batch adversarial loss: 0.590340\n",
      "epoch 47; iter: 0; batch classifier loss: 0.138607; batch adversarial loss: 0.407598\n",
      "epoch 48; iter: 0; batch classifier loss: 0.199322; batch adversarial loss: 0.455728\n",
      "epoch 49; iter: 0; batch classifier loss: 0.150401; batch adversarial loss: 0.449433\n",
      "epoch 50; iter: 0; batch classifier loss: 0.170658; batch adversarial loss: 0.535227\n",
      "epoch 51; iter: 0; batch classifier loss: 0.144534; batch adversarial loss: 0.494679\n",
      "epoch 52; iter: 0; batch classifier loss: 0.118073; batch adversarial loss: 0.559915\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122895; batch adversarial loss: 0.406104\n",
      "epoch 54; iter: 0; batch classifier loss: 0.129120; batch adversarial loss: 0.413910\n",
      "epoch 55; iter: 0; batch classifier loss: 0.147146; batch adversarial loss: 0.556183\n",
      "epoch 56; iter: 0; batch classifier loss: 0.154473; batch adversarial loss: 0.493917\n",
      "epoch 57; iter: 0; batch classifier loss: 0.158472; batch adversarial loss: 0.414781\n",
      "epoch 58; iter: 0; batch classifier loss: 0.138921; batch adversarial loss: 0.472787\n",
      "epoch 59; iter: 0; batch classifier loss: 0.152026; batch adversarial loss: 0.436530\n",
      "epoch 60; iter: 0; batch classifier loss: 0.166530; batch adversarial loss: 0.550320\n",
      "epoch 61; iter: 0; batch classifier loss: 0.186196; batch adversarial loss: 0.362145\n",
      "epoch 62; iter: 0; batch classifier loss: 0.175884; batch adversarial loss: 0.561585\n",
      "epoch 63; iter: 0; batch classifier loss: 0.156103; batch adversarial loss: 0.472291\n",
      "epoch 64; iter: 0; batch classifier loss: 0.146190; batch adversarial loss: 0.472332\n",
      "epoch 65; iter: 0; batch classifier loss: 0.139598; batch adversarial loss: 0.509494\n",
      "epoch 66; iter: 0; batch classifier loss: 0.121776; batch adversarial loss: 0.457403\n",
      "epoch 67; iter: 0; batch classifier loss: 0.184481; batch adversarial loss: 0.526908\n",
      "epoch 68; iter: 0; batch classifier loss: 0.133145; batch adversarial loss: 0.524821\n",
      "epoch 69; iter: 0; batch classifier loss: 0.172702; batch adversarial loss: 0.453320\n",
      "epoch 70; iter: 0; batch classifier loss: 0.181860; batch adversarial loss: 0.425219\n",
      "epoch 71; iter: 0; batch classifier loss: 0.107374; batch adversarial loss: 0.495228\n",
      "epoch 72; iter: 0; batch classifier loss: 0.177255; batch adversarial loss: 0.385371\n",
      "epoch 73; iter: 0; batch classifier loss: 0.107169; batch adversarial loss: 0.445640\n",
      "epoch 74; iter: 0; batch classifier loss: 0.153633; batch adversarial loss: 0.450685\n",
      "epoch 75; iter: 0; batch classifier loss: 0.193639; batch adversarial loss: 0.457620\n",
      "epoch 76; iter: 0; batch classifier loss: 0.154811; batch adversarial loss: 0.573863\n",
      "epoch 77; iter: 0; batch classifier loss: 0.128492; batch adversarial loss: 0.402609\n",
      "epoch 78; iter: 0; batch classifier loss: 0.122962; batch adversarial loss: 0.457833\n",
      "epoch 79; iter: 0; batch classifier loss: 0.087866; batch adversarial loss: 0.420271\n",
      "epoch 80; iter: 0; batch classifier loss: 0.123809; batch adversarial loss: 0.431234\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081592; batch adversarial loss: 0.407918\n",
      "epoch 82; iter: 0; batch classifier loss: 0.119694; batch adversarial loss: 0.440113\n",
      "epoch 83; iter: 0; batch classifier loss: 0.165199; batch adversarial loss: 0.447270\n",
      "epoch 84; iter: 0; batch classifier loss: 0.103023; batch adversarial loss: 0.457719\n",
      "epoch 85; iter: 0; batch classifier loss: 0.150371; batch adversarial loss: 0.406188\n",
      "epoch 86; iter: 0; batch classifier loss: 0.110231; batch adversarial loss: 0.419765\n",
      "epoch 87; iter: 0; batch classifier loss: 0.101978; batch adversarial loss: 0.402353\n",
      "epoch 88; iter: 0; batch classifier loss: 0.079027; batch adversarial loss: 0.433999\n",
      "epoch 89; iter: 0; batch classifier loss: 0.088084; batch adversarial loss: 0.513605\n",
      "epoch 90; iter: 0; batch classifier loss: 0.106505; batch adversarial loss: 0.464881\n",
      "epoch 91; iter: 0; batch classifier loss: 0.058571; batch adversarial loss: 0.405625\n",
      "epoch 92; iter: 0; batch classifier loss: 0.104485; batch adversarial loss: 0.393019\n",
      "epoch 93; iter: 0; batch classifier loss: 0.119425; batch adversarial loss: 0.411015\n",
      "epoch 94; iter: 0; batch classifier loss: 0.096644; batch adversarial loss: 0.464688\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087003; batch adversarial loss: 0.413733\n",
      "epoch 96; iter: 0; batch classifier loss: 0.078217; batch adversarial loss: 0.425287\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060556; batch adversarial loss: 0.449121\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049169; batch adversarial loss: 0.468143\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071054; batch adversarial loss: 0.416493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.071188; batch adversarial loss: 0.505964\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046664; batch adversarial loss: 0.398656\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068197; batch adversarial loss: 0.525376\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054925; batch adversarial loss: 0.484407\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027951; batch adversarial loss: 0.467586\n",
      "epoch 105; iter: 0; batch classifier loss: 0.033086; batch adversarial loss: 0.463784\n",
      "epoch 106; iter: 0; batch classifier loss: 0.077018; batch adversarial loss: 0.421184\n",
      "epoch 107; iter: 0; batch classifier loss: 0.015492; batch adversarial loss: 0.545665\n",
      "epoch 108; iter: 0; batch classifier loss: 0.034905; batch adversarial loss: 0.441362\n",
      "epoch 109; iter: 0; batch classifier loss: 0.028706; batch adversarial loss: 0.450672\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053407; batch adversarial loss: 0.471790\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053867; batch adversarial loss: 0.515914\n",
      "epoch 112; iter: 0; batch classifier loss: 0.074375; batch adversarial loss: 0.503745\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055714; batch adversarial loss: 0.470383\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033038; batch adversarial loss: 0.437468\n",
      "epoch 115; iter: 0; batch classifier loss: 0.066737; batch adversarial loss: 0.404451\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043015; batch adversarial loss: 0.488136\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044697; batch adversarial loss: 0.513053\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041340; batch adversarial loss: 0.425431\n",
      "epoch 119; iter: 0; batch classifier loss: 0.011473; batch adversarial loss: 0.460340\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022203; batch adversarial loss: 0.424569\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032854; batch adversarial loss: 0.396060\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035667; batch adversarial loss: 0.476914\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043414; batch adversarial loss: 0.360559\n",
      "epoch 124; iter: 0; batch classifier loss: 0.053210; batch adversarial loss: 0.399052\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017168; batch adversarial loss: 0.566413\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029048; batch adversarial loss: 0.391810\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035227; batch adversarial loss: 0.416017\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040145; batch adversarial loss: 0.485225\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020551; batch adversarial loss: 0.420028\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017090; batch adversarial loss: 0.362141\n",
      "epoch 131; iter: 0; batch classifier loss: 0.085446; batch adversarial loss: 0.447456\n",
      "epoch 132; iter: 0; batch classifier loss: 0.073824; batch adversarial loss: 0.581861\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024856; batch adversarial loss: 0.446774\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020524; batch adversarial loss: 0.526849\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045784; batch adversarial loss: 0.440474\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040452; batch adversarial loss: 0.545922\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039247; batch adversarial loss: 0.410156\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017523; batch adversarial loss: 0.591756\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018596; batch adversarial loss: 0.409374\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022276; batch adversarial loss: 0.521190\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021531; batch adversarial loss: 0.442586\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020011; batch adversarial loss: 0.459608\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031388; batch adversarial loss: 0.580720\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027390; batch adversarial loss: 0.384400\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023042; batch adversarial loss: 0.400605\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017578; batch adversarial loss: 0.413409\n",
      "epoch 147; iter: 0; batch classifier loss: 0.004726; batch adversarial loss: 0.364545\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021807; batch adversarial loss: 0.476554\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019730; batch adversarial loss: 0.416789\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026616; batch adversarial loss: 0.505584\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023458; batch adversarial loss: 0.444561\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034239; batch adversarial loss: 0.388716\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022322; batch adversarial loss: 0.442781\n",
      "epoch 154; iter: 0; batch classifier loss: 0.045342; batch adversarial loss: 0.420761\n",
      "epoch 155; iter: 0; batch classifier loss: 0.045579; batch adversarial loss: 0.409540\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018392; batch adversarial loss: 0.408664\n",
      "epoch 157; iter: 0; batch classifier loss: 0.045067; batch adversarial loss: 0.423759\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033980; batch adversarial loss: 0.423288\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022218; batch adversarial loss: 0.385053\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008400; batch adversarial loss: 0.467761\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032025; batch adversarial loss: 0.455932\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019682; batch adversarial loss: 0.418319\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017046; batch adversarial loss: 0.436079\n",
      "epoch 164; iter: 0; batch classifier loss: 0.007998; batch adversarial loss: 0.422853\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014170; batch adversarial loss: 0.432118\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025413; batch adversarial loss: 0.449014\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028831; batch adversarial loss: 0.390394\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028175; batch adversarial loss: 0.470697\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017923; batch adversarial loss: 0.414440\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013524; batch adversarial loss: 0.492386\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021391; batch adversarial loss: 0.513418\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018164; batch adversarial loss: 0.475679\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015281; batch adversarial loss: 0.465167\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025443; batch adversarial loss: 0.349381\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012361; batch adversarial loss: 0.405750\n",
      "epoch 176; iter: 0; batch classifier loss: 0.050208; batch adversarial loss: 0.407846\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013889; batch adversarial loss: 0.547880\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008844; batch adversarial loss: 0.495369\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006045; batch adversarial loss: 0.465097\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011275; batch adversarial loss: 0.476292\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024926; batch adversarial loss: 0.396122\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006543; batch adversarial loss: 0.437272\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013028; batch adversarial loss: 0.479394\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012251; batch adversarial loss: 0.434569\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014789; batch adversarial loss: 0.480209\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024952; batch adversarial loss: 0.531402\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013642; batch adversarial loss: 0.389158\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028693; batch adversarial loss: 0.451150\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009163; batch adversarial loss: 0.416265\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031731; batch adversarial loss: 0.336303\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018689; batch adversarial loss: 0.443073\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026638; batch adversarial loss: 0.436786\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016095; batch adversarial loss: 0.410916\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004038; batch adversarial loss: 0.500419\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004888; batch adversarial loss: 0.469240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.015740; batch adversarial loss: 0.501276\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019311; batch adversarial loss: 0.453825\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005977; batch adversarial loss: 0.458806\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007100; batch adversarial loss: 0.481907\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713066; batch adversarial loss: 0.862832\n",
      "epoch 1; iter: 0; batch classifier loss: 0.401061; batch adversarial loss: 0.894426\n",
      "epoch 2; iter: 0; batch classifier loss: 0.296456; batch adversarial loss: 0.787688\n",
      "epoch 3; iter: 0; batch classifier loss: 0.350289; batch adversarial loss: 0.773509\n",
      "epoch 4; iter: 0; batch classifier loss: 0.255456; batch adversarial loss: 0.723960\n",
      "epoch 5; iter: 0; batch classifier loss: 0.308418; batch adversarial loss: 0.701073\n",
      "epoch 6; iter: 0; batch classifier loss: 0.285334; batch adversarial loss: 0.668085\n",
      "epoch 7; iter: 0; batch classifier loss: 0.320748; batch adversarial loss: 0.632004\n",
      "epoch 8; iter: 0; batch classifier loss: 0.306613; batch adversarial loss: 0.631824\n",
      "epoch 9; iter: 0; batch classifier loss: 0.241516; batch adversarial loss: 0.552982\n",
      "epoch 10; iter: 0; batch classifier loss: 0.310007; batch adversarial loss: 0.567064\n",
      "epoch 11; iter: 0; batch classifier loss: 0.264885; batch adversarial loss: 0.524385\n",
      "epoch 12; iter: 0; batch classifier loss: 0.235977; batch adversarial loss: 0.525619\n",
      "epoch 13; iter: 0; batch classifier loss: 0.276329; batch adversarial loss: 0.523166\n",
      "epoch 14; iter: 0; batch classifier loss: 0.241368; batch adversarial loss: 0.543565\n",
      "epoch 15; iter: 0; batch classifier loss: 0.231346; batch adversarial loss: 0.499369\n",
      "epoch 16; iter: 0; batch classifier loss: 0.262416; batch adversarial loss: 0.440749\n",
      "epoch 17; iter: 0; batch classifier loss: 0.230199; batch adversarial loss: 0.491222\n",
      "epoch 18; iter: 0; batch classifier loss: 0.234750; batch adversarial loss: 0.444972\n",
      "epoch 19; iter: 0; batch classifier loss: 0.186981; batch adversarial loss: 0.444339\n",
      "epoch 20; iter: 0; batch classifier loss: 0.214860; batch adversarial loss: 0.484458\n",
      "epoch 21; iter: 0; batch classifier loss: 0.200297; batch adversarial loss: 0.415910\n",
      "epoch 22; iter: 0; batch classifier loss: 0.207700; batch adversarial loss: 0.427658\n",
      "epoch 23; iter: 0; batch classifier loss: 0.186832; batch adversarial loss: 0.452452\n",
      "epoch 24; iter: 0; batch classifier loss: 0.251129; batch adversarial loss: 0.448072\n",
      "epoch 25; iter: 0; batch classifier loss: 0.245661; batch adversarial loss: 0.367473\n",
      "epoch 26; iter: 0; batch classifier loss: 0.199022; batch adversarial loss: 0.415652\n",
      "epoch 27; iter: 0; batch classifier loss: 0.206262; batch adversarial loss: 0.469973\n",
      "epoch 28; iter: 0; batch classifier loss: 0.199094; batch adversarial loss: 0.380636\n",
      "epoch 29; iter: 0; batch classifier loss: 0.181206; batch adversarial loss: 0.438106\n",
      "epoch 30; iter: 0; batch classifier loss: 0.171145; batch adversarial loss: 0.496804\n",
      "epoch 31; iter: 0; batch classifier loss: 0.170944; batch adversarial loss: 0.427056\n",
      "epoch 32; iter: 0; batch classifier loss: 0.170295; batch adversarial loss: 0.473416\n",
      "epoch 33; iter: 0; batch classifier loss: 0.133279; batch adversarial loss: 0.403787\n",
      "epoch 34; iter: 0; batch classifier loss: 0.138066; batch adversarial loss: 0.408005\n",
      "epoch 35; iter: 0; batch classifier loss: 0.139202; batch adversarial loss: 0.453510\n",
      "epoch 36; iter: 0; batch classifier loss: 0.131095; batch adversarial loss: 0.306771\n",
      "epoch 37; iter: 0; batch classifier loss: 0.148268; batch adversarial loss: 0.378600\n",
      "epoch 38; iter: 0; batch classifier loss: 0.161922; batch adversarial loss: 0.362642\n",
      "epoch 39; iter: 0; batch classifier loss: 0.151018; batch adversarial loss: 0.373042\n",
      "epoch 40; iter: 0; batch classifier loss: 0.159800; batch adversarial loss: 0.362148\n",
      "epoch 41; iter: 0; batch classifier loss: 0.146542; batch adversarial loss: 0.377698\n",
      "epoch 42; iter: 0; batch classifier loss: 0.139447; batch adversarial loss: 0.310726\n",
      "epoch 43; iter: 0; batch classifier loss: 0.109423; batch adversarial loss: 0.377400\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101840; batch adversarial loss: 0.432488\n",
      "epoch 45; iter: 0; batch classifier loss: 0.118982; batch adversarial loss: 0.487597\n",
      "epoch 46; iter: 0; batch classifier loss: 0.103796; batch adversarial loss: 0.495177\n",
      "epoch 47; iter: 0; batch classifier loss: 0.108346; batch adversarial loss: 0.414221\n",
      "epoch 48; iter: 0; batch classifier loss: 0.105976; batch adversarial loss: 0.406746\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094247; batch adversarial loss: 0.499002\n",
      "epoch 50; iter: 0; batch classifier loss: 0.117634; batch adversarial loss: 0.425970\n",
      "epoch 51; iter: 0; batch classifier loss: 0.072028; batch adversarial loss: 0.533604\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099819; batch adversarial loss: 0.469394\n",
      "epoch 53; iter: 0; batch classifier loss: 0.079679; batch adversarial loss: 0.366588\n",
      "epoch 54; iter: 0; batch classifier loss: 0.100798; batch adversarial loss: 0.377900\n",
      "epoch 55; iter: 0; batch classifier loss: 0.114181; batch adversarial loss: 0.449591\n",
      "epoch 56; iter: 0; batch classifier loss: 0.086428; batch adversarial loss: 0.454034\n",
      "epoch 57; iter: 0; batch classifier loss: 0.084392; batch adversarial loss: 0.389750\n",
      "epoch 58; iter: 0; batch classifier loss: 0.079809; batch adversarial loss: 0.433121\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090593; batch adversarial loss: 0.361044\n",
      "epoch 60; iter: 0; batch classifier loss: 0.110796; batch adversarial loss: 0.423528\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087968; batch adversarial loss: 0.361071\n",
      "epoch 62; iter: 0; batch classifier loss: 0.091751; batch adversarial loss: 0.341462\n",
      "epoch 63; iter: 0; batch classifier loss: 0.100992; batch adversarial loss: 0.399020\n",
      "epoch 64; iter: 0; batch classifier loss: 0.087273; batch adversarial loss: 0.432258\n",
      "epoch 65; iter: 0; batch classifier loss: 0.113952; batch adversarial loss: 0.445265\n",
      "epoch 66; iter: 0; batch classifier loss: 0.052057; batch adversarial loss: 0.446160\n",
      "epoch 67; iter: 0; batch classifier loss: 0.055446; batch adversarial loss: 0.478237\n",
      "epoch 68; iter: 0; batch classifier loss: 0.063355; batch adversarial loss: 0.444529\n",
      "epoch 69; iter: 0; batch classifier loss: 0.053626; batch adversarial loss: 0.409889\n",
      "epoch 70; iter: 0; batch classifier loss: 0.051828; batch adversarial loss: 0.488841\n",
      "epoch 71; iter: 0; batch classifier loss: 0.055250; batch adversarial loss: 0.378956\n",
      "epoch 72; iter: 0; batch classifier loss: 0.041513; batch adversarial loss: 0.437929\n",
      "epoch 73; iter: 0; batch classifier loss: 0.116003; batch adversarial loss: 0.476522\n",
      "epoch 74; iter: 0; batch classifier loss: 0.052202; batch adversarial loss: 0.443280\n",
      "epoch 75; iter: 0; batch classifier loss: 0.054565; batch adversarial loss: 0.430669\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055795; batch adversarial loss: 0.430391\n",
      "epoch 77; iter: 0; batch classifier loss: 0.047699; batch adversarial loss: 0.523916\n",
      "epoch 78; iter: 0; batch classifier loss: 0.037188; batch adversarial loss: 0.426158\n",
      "epoch 79; iter: 0; batch classifier loss: 0.035759; batch adversarial loss: 0.410688\n",
      "epoch 80; iter: 0; batch classifier loss: 0.052178; batch adversarial loss: 0.573558\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057989; batch adversarial loss: 0.514004\n",
      "epoch 82; iter: 0; batch classifier loss: 0.040903; batch adversarial loss: 0.408040\n",
      "epoch 83; iter: 0; batch classifier loss: 0.093085; batch adversarial loss: 0.540458\n",
      "epoch 84; iter: 0; batch classifier loss: 0.023113; batch adversarial loss: 0.444025\n",
      "epoch 85; iter: 0; batch classifier loss: 0.081202; batch adversarial loss: 0.446878\n",
      "epoch 86; iter: 0; batch classifier loss: 0.027980; batch adversarial loss: 0.471445\n",
      "epoch 87; iter: 0; batch classifier loss: 0.034135; batch adversarial loss: 0.359746\n",
      "epoch 88; iter: 0; batch classifier loss: 0.053786; batch adversarial loss: 0.525226\n",
      "epoch 89; iter: 0; batch classifier loss: 0.023949; batch adversarial loss: 0.372765\n",
      "epoch 90; iter: 0; batch classifier loss: 0.028995; batch adversarial loss: 0.474945\n",
      "epoch 91; iter: 0; batch classifier loss: 0.022245; batch adversarial loss: 0.517184\n",
      "epoch 92; iter: 0; batch classifier loss: 0.040999; batch adversarial loss: 0.527049\n",
      "epoch 93; iter: 0; batch classifier loss: 0.028361; batch adversarial loss: 0.434061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.046642; batch adversarial loss: 0.518355\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056122; batch adversarial loss: 0.439648\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036447; batch adversarial loss: 0.452535\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069831; batch adversarial loss: 0.553689\n",
      "epoch 98; iter: 0; batch classifier loss: 0.082396; batch adversarial loss: 0.463013\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078534; batch adversarial loss: 0.475558\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067839; batch adversarial loss: 0.484032\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049422; batch adversarial loss: 0.473852\n",
      "epoch 102; iter: 0; batch classifier loss: 0.064071; batch adversarial loss: 0.421050\n",
      "epoch 103; iter: 0; batch classifier loss: 0.151297; batch adversarial loss: 0.592856\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046542; batch adversarial loss: 0.463495\n",
      "epoch 105; iter: 0; batch classifier loss: 0.129462; batch adversarial loss: 0.550080\n",
      "epoch 106; iter: 0; batch classifier loss: 0.174012; batch adversarial loss: 0.642895\n",
      "epoch 107; iter: 0; batch classifier loss: 0.080508; batch adversarial loss: 0.551993\n",
      "epoch 108; iter: 0; batch classifier loss: 0.156846; batch adversarial loss: 0.559624\n",
      "epoch 109; iter: 0; batch classifier loss: 0.151086; batch adversarial loss: 0.604525\n",
      "epoch 110; iter: 0; batch classifier loss: 0.126961; batch adversarial loss: 0.506816\n",
      "epoch 111; iter: 0; batch classifier loss: 0.156800; batch adversarial loss: 0.569540\n",
      "epoch 112; iter: 0; batch classifier loss: 0.071745; batch adversarial loss: 0.481808\n",
      "epoch 113; iter: 0; batch classifier loss: 0.142365; batch adversarial loss: 0.470765\n",
      "epoch 114; iter: 0; batch classifier loss: 0.118651; batch adversarial loss: 0.671284\n",
      "epoch 115; iter: 0; batch classifier loss: 0.170178; batch adversarial loss: 0.622524\n",
      "epoch 116; iter: 0; batch classifier loss: 0.148219; batch adversarial loss: 0.541532\n",
      "epoch 117; iter: 0; batch classifier loss: 0.123558; batch adversarial loss: 0.494108\n",
      "epoch 118; iter: 0; batch classifier loss: 0.154187; batch adversarial loss: 0.560371\n",
      "epoch 119; iter: 0; batch classifier loss: 0.130332; batch adversarial loss: 0.578884\n",
      "epoch 120; iter: 0; batch classifier loss: 0.115462; batch adversarial loss: 0.486004\n",
      "epoch 121; iter: 0; batch classifier loss: 0.100712; batch adversarial loss: 0.545978\n",
      "epoch 122; iter: 0; batch classifier loss: 0.149762; batch adversarial loss: 0.496662\n",
      "epoch 123; iter: 0; batch classifier loss: 0.077385; batch adversarial loss: 0.446820\n",
      "epoch 124; iter: 0; batch classifier loss: 0.142695; batch adversarial loss: 0.655019\n",
      "epoch 125; iter: 0; batch classifier loss: 0.126087; batch adversarial loss: 0.605119\n",
      "epoch 126; iter: 0; batch classifier loss: 0.098229; batch adversarial loss: 0.455831\n",
      "epoch 127; iter: 0; batch classifier loss: 0.081733; batch adversarial loss: 0.403686\n",
      "epoch 128; iter: 0; batch classifier loss: 0.101376; batch adversarial loss: 0.477551\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050638; batch adversarial loss: 0.468279\n",
      "epoch 130; iter: 0; batch classifier loss: 0.123246; batch adversarial loss: 0.555708\n",
      "epoch 131; iter: 0; batch classifier loss: 0.078894; batch adversarial loss: 0.525789\n",
      "epoch 132; iter: 0; batch classifier loss: 0.068585; batch adversarial loss: 0.546274\n",
      "epoch 133; iter: 0; batch classifier loss: 0.118679; batch adversarial loss: 0.524143\n",
      "epoch 134; iter: 0; batch classifier loss: 0.081032; batch adversarial loss: 0.445017\n",
      "epoch 135; iter: 0; batch classifier loss: 0.123463; batch adversarial loss: 0.479364\n",
      "epoch 136; iter: 0; batch classifier loss: 0.047665; batch adversarial loss: 0.502832\n",
      "epoch 137; iter: 0; batch classifier loss: 0.058378; batch adversarial loss: 0.514496\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040613; batch adversarial loss: 0.345861\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044816; batch adversarial loss: 0.427619\n",
      "epoch 140; iter: 0; batch classifier loss: 0.054509; batch adversarial loss: 0.419663\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019933; batch adversarial loss: 0.539317\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031240; batch adversarial loss: 0.459373\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032422; batch adversarial loss: 0.462247\n",
      "epoch 144; iter: 0; batch classifier loss: 0.050435; batch adversarial loss: 0.505732\n",
      "epoch 145; iter: 0; batch classifier loss: 0.067683; batch adversarial loss: 0.444248\n",
      "epoch 146; iter: 0; batch classifier loss: 0.060271; batch adversarial loss: 0.453510\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043421; batch adversarial loss: 0.528270\n",
      "epoch 148; iter: 0; batch classifier loss: 0.037225; batch adversarial loss: 0.453374\n",
      "epoch 149; iter: 0; batch classifier loss: 0.068821; batch adversarial loss: 0.480490\n",
      "epoch 150; iter: 0; batch classifier loss: 0.077110; batch adversarial loss: 0.419376\n",
      "epoch 151; iter: 0; batch classifier loss: 0.059941; batch adversarial loss: 0.524748\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035768; batch adversarial loss: 0.393242\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035893; batch adversarial loss: 0.461711\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036170; batch adversarial loss: 0.432591\n",
      "epoch 155; iter: 0; batch classifier loss: 0.059373; batch adversarial loss: 0.385291\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039683; batch adversarial loss: 0.504462\n",
      "epoch 157; iter: 0; batch classifier loss: 0.061337; batch adversarial loss: 0.493300\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045471; batch adversarial loss: 0.469509\n",
      "epoch 159; iter: 0; batch classifier loss: 0.043200; batch adversarial loss: 0.444185\n",
      "epoch 160; iter: 0; batch classifier loss: 0.072842; batch adversarial loss: 0.473225\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036659; batch adversarial loss: 0.405769\n",
      "epoch 162; iter: 0; batch classifier loss: 0.047559; batch adversarial loss: 0.432142\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038389; batch adversarial loss: 0.442619\n",
      "epoch 164; iter: 0; batch classifier loss: 0.055515; batch adversarial loss: 0.409019\n",
      "epoch 165; iter: 0; batch classifier loss: 0.051320; batch adversarial loss: 0.467317\n",
      "epoch 166; iter: 0; batch classifier loss: 0.088408; batch adversarial loss: 0.443038\n",
      "epoch 167; iter: 0; batch classifier loss: 0.045738; batch adversarial loss: 0.408437\n",
      "epoch 168; iter: 0; batch classifier loss: 0.069281; batch adversarial loss: 0.519516\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034754; batch adversarial loss: 0.453503\n",
      "epoch 170; iter: 0; batch classifier loss: 0.058247; batch adversarial loss: 0.425220\n",
      "epoch 171; iter: 0; batch classifier loss: 0.050563; batch adversarial loss: 0.403317\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020570; batch adversarial loss: 0.397045\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024175; batch adversarial loss: 0.586672\n",
      "epoch 174; iter: 0; batch classifier loss: 0.053208; batch adversarial loss: 0.508469\n",
      "epoch 175; iter: 0; batch classifier loss: 0.060938; batch adversarial loss: 0.391144\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025564; batch adversarial loss: 0.492832\n",
      "epoch 177; iter: 0; batch classifier loss: 0.086875; batch adversarial loss: 0.362482\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029500; batch adversarial loss: 0.447856\n",
      "epoch 179; iter: 0; batch classifier loss: 0.057588; batch adversarial loss: 0.452066\n",
      "epoch 180; iter: 0; batch classifier loss: 0.033243; batch adversarial loss: 0.540745\n",
      "epoch 181; iter: 0; batch classifier loss: 0.058842; batch adversarial loss: 0.481977\n",
      "epoch 182; iter: 0; batch classifier loss: 0.048895; batch adversarial loss: 0.458227\n",
      "epoch 183; iter: 0; batch classifier loss: 0.046058; batch adversarial loss: 0.407385\n",
      "epoch 184; iter: 0; batch classifier loss: 0.043583; batch adversarial loss: 0.448183\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016366; batch adversarial loss: 0.393014\n",
      "epoch 186; iter: 0; batch classifier loss: 0.037808; batch adversarial loss: 0.461932\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024048; batch adversarial loss: 0.495184\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029014; batch adversarial loss: 0.443261\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029346; batch adversarial loss: 0.449294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.037004; batch adversarial loss: 0.449790\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023171; batch adversarial loss: 0.416989\n",
      "epoch 192; iter: 0; batch classifier loss: 0.057841; batch adversarial loss: 0.455610\n",
      "epoch 193; iter: 0; batch classifier loss: 0.036301; batch adversarial loss: 0.447347\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014916; batch adversarial loss: 0.442570\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026007; batch adversarial loss: 0.440844\n",
      "epoch 196; iter: 0; batch classifier loss: 0.038996; batch adversarial loss: 0.436994\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015370; batch adversarial loss: 0.443551\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021591; batch adversarial loss: 0.413862\n",
      "epoch 199; iter: 0; batch classifier loss: 0.079020; batch adversarial loss: 0.470087\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695904; batch adversarial loss: 0.617770\n",
      "epoch 1; iter: 0; batch classifier loss: 0.409686; batch adversarial loss: 0.615009\n",
      "epoch 2; iter: 0; batch classifier loss: 0.346612; batch adversarial loss: 0.592231\n",
      "epoch 3; iter: 0; batch classifier loss: 0.322682; batch adversarial loss: 0.605531\n",
      "epoch 4; iter: 0; batch classifier loss: 0.304446; batch adversarial loss: 0.566646\n",
      "epoch 5; iter: 0; batch classifier loss: 0.324015; batch adversarial loss: 0.525443\n",
      "epoch 6; iter: 0; batch classifier loss: 0.311107; batch adversarial loss: 0.549787\n",
      "epoch 7; iter: 0; batch classifier loss: 0.272883; batch adversarial loss: 0.588341\n",
      "epoch 8; iter: 0; batch classifier loss: 0.271416; batch adversarial loss: 0.491565\n",
      "epoch 9; iter: 0; batch classifier loss: 0.311767; batch adversarial loss: 0.553605\n",
      "epoch 10; iter: 0; batch classifier loss: 0.296390; batch adversarial loss: 0.568036\n",
      "epoch 11; iter: 0; batch classifier loss: 0.301240; batch adversarial loss: 0.522662\n",
      "epoch 12; iter: 0; batch classifier loss: 0.261172; batch adversarial loss: 0.544061\n",
      "epoch 13; iter: 0; batch classifier loss: 0.236939; batch adversarial loss: 0.500115\n",
      "epoch 14; iter: 0; batch classifier loss: 0.271654; batch adversarial loss: 0.478917\n",
      "epoch 15; iter: 0; batch classifier loss: 0.256418; batch adversarial loss: 0.524983\n",
      "epoch 16; iter: 0; batch classifier loss: 0.394840; batch adversarial loss: 0.628851\n",
      "epoch 17; iter: 0; batch classifier loss: 0.356768; batch adversarial loss: 0.520934\n",
      "epoch 18; iter: 0; batch classifier loss: 0.456057; batch adversarial loss: 0.536061\n",
      "epoch 19; iter: 0; batch classifier loss: 0.434924; batch adversarial loss: 0.495365\n",
      "epoch 20; iter: 0; batch classifier loss: 0.406724; batch adversarial loss: 0.512691\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258852; batch adversarial loss: 0.441800\n",
      "epoch 22; iter: 0; batch classifier loss: 0.252762; batch adversarial loss: 0.432386\n",
      "epoch 23; iter: 0; batch classifier loss: 0.219754; batch adversarial loss: 0.506344\n",
      "epoch 24; iter: 0; batch classifier loss: 0.139585; batch adversarial loss: 0.467071\n",
      "epoch 25; iter: 0; batch classifier loss: 0.187007; batch adversarial loss: 0.472727\n",
      "epoch 26; iter: 0; batch classifier loss: 0.135778; batch adversarial loss: 0.539880\n",
      "epoch 27; iter: 0; batch classifier loss: 0.118023; batch adversarial loss: 0.382082\n",
      "epoch 28; iter: 0; batch classifier loss: 0.138168; batch adversarial loss: 0.499113\n",
      "epoch 29; iter: 0; batch classifier loss: 0.115692; batch adversarial loss: 0.436605\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153506; batch adversarial loss: 0.496417\n",
      "epoch 31; iter: 0; batch classifier loss: 0.093886; batch adversarial loss: 0.510210\n",
      "epoch 32; iter: 0; batch classifier loss: 0.150590; batch adversarial loss: 0.490930\n",
      "epoch 33; iter: 0; batch classifier loss: 0.116362; batch adversarial loss: 0.445429\n",
      "epoch 34; iter: 0; batch classifier loss: 0.127313; batch adversarial loss: 0.386970\n",
      "epoch 35; iter: 0; batch classifier loss: 0.135056; batch adversarial loss: 0.489954\n",
      "epoch 36; iter: 0; batch classifier loss: 0.132889; batch adversarial loss: 0.345516\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113858; batch adversarial loss: 0.488636\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117273; batch adversarial loss: 0.571331\n",
      "epoch 39; iter: 0; batch classifier loss: 0.114185; batch adversarial loss: 0.447089\n",
      "epoch 40; iter: 0; batch classifier loss: 0.105755; batch adversarial loss: 0.383845\n",
      "epoch 41; iter: 0; batch classifier loss: 0.088851; batch adversarial loss: 0.460485\n",
      "epoch 42; iter: 0; batch classifier loss: 0.118036; batch adversarial loss: 0.461237\n",
      "epoch 43; iter: 0; batch classifier loss: 0.109312; batch adversarial loss: 0.494360\n",
      "epoch 44; iter: 0; batch classifier loss: 0.094137; batch adversarial loss: 0.512113\n",
      "epoch 45; iter: 0; batch classifier loss: 0.110682; batch adversarial loss: 0.414214\n",
      "epoch 46; iter: 0; batch classifier loss: 0.136203; batch adversarial loss: 0.491237\n",
      "epoch 47; iter: 0; batch classifier loss: 0.092149; batch adversarial loss: 0.511876\n",
      "epoch 48; iter: 0; batch classifier loss: 0.115108; batch adversarial loss: 0.374331\n",
      "epoch 49; iter: 0; batch classifier loss: 0.091928; batch adversarial loss: 0.484772\n",
      "epoch 50; iter: 0; batch classifier loss: 0.102531; batch adversarial loss: 0.384207\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092818; batch adversarial loss: 0.554005\n",
      "epoch 52; iter: 0; batch classifier loss: 0.174349; batch adversarial loss: 0.473201\n",
      "epoch 53; iter: 0; batch classifier loss: 0.064175; batch adversarial loss: 0.442674\n",
      "epoch 54; iter: 0; batch classifier loss: 0.073640; batch adversarial loss: 0.421837\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086207; batch adversarial loss: 0.507938\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081740; batch adversarial loss: 0.446289\n",
      "epoch 57; iter: 0; batch classifier loss: 0.084789; batch adversarial loss: 0.345896\n",
      "epoch 58; iter: 0; batch classifier loss: 0.058046; batch adversarial loss: 0.468614\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090133; batch adversarial loss: 0.458172\n",
      "epoch 60; iter: 0; batch classifier loss: 0.129657; batch adversarial loss: 0.476741\n",
      "epoch 61; iter: 0; batch classifier loss: 0.082665; batch adversarial loss: 0.367840\n",
      "epoch 62; iter: 0; batch classifier loss: 0.103840; batch adversarial loss: 0.468049\n",
      "epoch 63; iter: 0; batch classifier loss: 0.118168; batch adversarial loss: 0.429222\n",
      "epoch 64; iter: 0; batch classifier loss: 0.102571; batch adversarial loss: 0.489596\n",
      "epoch 65; iter: 0; batch classifier loss: 0.098637; batch adversarial loss: 0.431713\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085964; batch adversarial loss: 0.518792\n",
      "epoch 67; iter: 0; batch classifier loss: 0.075205; batch adversarial loss: 0.373786\n",
      "epoch 68; iter: 0; batch classifier loss: 0.097384; batch adversarial loss: 0.376257\n",
      "epoch 69; iter: 0; batch classifier loss: 0.074110; batch adversarial loss: 0.411384\n",
      "epoch 70; iter: 0; batch classifier loss: 0.082592; batch adversarial loss: 0.478585\n",
      "epoch 71; iter: 0; batch classifier loss: 0.127030; batch adversarial loss: 0.481279\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077334; batch adversarial loss: 0.497325\n",
      "epoch 73; iter: 0; batch classifier loss: 0.103159; batch adversarial loss: 0.376817\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066411; batch adversarial loss: 0.412322\n",
      "epoch 75; iter: 0; batch classifier loss: 0.097487; batch adversarial loss: 0.412064\n",
      "epoch 76; iter: 0; batch classifier loss: 0.086180; batch adversarial loss: 0.456152\n",
      "epoch 77; iter: 0; batch classifier loss: 0.153575; batch adversarial loss: 0.503452\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059898; batch adversarial loss: 0.372305\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074628; batch adversarial loss: 0.454331\n",
      "epoch 80; iter: 0; batch classifier loss: 0.057829; batch adversarial loss: 0.512613\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084068; batch adversarial loss: 0.379868\n",
      "epoch 82; iter: 0; batch classifier loss: 0.045745; batch adversarial loss: 0.451066\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080238; batch adversarial loss: 0.404010\n",
      "epoch 84; iter: 0; batch classifier loss: 0.122211; batch adversarial loss: 0.461150\n",
      "epoch 85; iter: 0; batch classifier loss: 0.096219; batch adversarial loss: 0.437636\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076224; batch adversarial loss: 0.392523\n",
      "epoch 87; iter: 0; batch classifier loss: 0.104946; batch adversarial loss: 0.509765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.072972; batch adversarial loss: 0.529294\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042335; batch adversarial loss: 0.471161\n",
      "epoch 90; iter: 0; batch classifier loss: 0.097070; batch adversarial loss: 0.451809\n",
      "epoch 91; iter: 0; batch classifier loss: 0.092713; batch adversarial loss: 0.468091\n",
      "epoch 92; iter: 0; batch classifier loss: 0.061250; batch adversarial loss: 0.501591\n",
      "epoch 93; iter: 0; batch classifier loss: 0.104168; batch adversarial loss: 0.349966\n",
      "epoch 94; iter: 0; batch classifier loss: 0.092930; batch adversarial loss: 0.580120\n",
      "epoch 95; iter: 0; batch classifier loss: 0.085729; batch adversarial loss: 0.478729\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045996; batch adversarial loss: 0.480148\n",
      "epoch 97; iter: 0; batch classifier loss: 0.033252; batch adversarial loss: 0.485403\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056438; batch adversarial loss: 0.408532\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056323; batch adversarial loss: 0.524204\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064224; batch adversarial loss: 0.475452\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057836; batch adversarial loss: 0.441022\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042031; batch adversarial loss: 0.382575\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048925; batch adversarial loss: 0.472165\n",
      "epoch 104; iter: 0; batch classifier loss: 0.068281; batch adversarial loss: 0.474410\n",
      "epoch 105; iter: 0; batch classifier loss: 0.036891; batch adversarial loss: 0.472777\n",
      "epoch 106; iter: 0; batch classifier loss: 0.090421; batch adversarial loss: 0.425618\n",
      "epoch 107; iter: 0; batch classifier loss: 0.073224; batch adversarial loss: 0.440171\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045585; batch adversarial loss: 0.648849\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045140; batch adversarial loss: 0.445083\n",
      "epoch 110; iter: 0; batch classifier loss: 0.081591; batch adversarial loss: 0.563463\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032454; batch adversarial loss: 0.484938\n",
      "epoch 112; iter: 0; batch classifier loss: 0.050343; batch adversarial loss: 0.416300\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055447; batch adversarial loss: 0.520467\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030846; batch adversarial loss: 0.504327\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033207; batch adversarial loss: 0.453402\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021925; batch adversarial loss: 0.387831\n",
      "epoch 117; iter: 0; batch classifier loss: 0.059428; batch adversarial loss: 0.394326\n",
      "epoch 118; iter: 0; batch classifier loss: 0.012577; batch adversarial loss: 0.406778\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051711; batch adversarial loss: 0.438072\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041475; batch adversarial loss: 0.434546\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030187; batch adversarial loss: 0.416718\n",
      "epoch 122; iter: 0; batch classifier loss: 0.018802; batch adversarial loss: 0.556654\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040337; batch adversarial loss: 0.471662\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033058; batch adversarial loss: 0.415135\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037777; batch adversarial loss: 0.449638\n",
      "epoch 126; iter: 0; batch classifier loss: 0.074103; batch adversarial loss: 0.414879\n",
      "epoch 127; iter: 0; batch classifier loss: 0.016441; batch adversarial loss: 0.494958\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032197; batch adversarial loss: 0.515701\n",
      "epoch 129; iter: 0; batch classifier loss: 0.096141; batch adversarial loss: 0.365610\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050294; batch adversarial loss: 0.502048\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051453; batch adversarial loss: 0.336848\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041014; batch adversarial loss: 0.535617\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039500; batch adversarial loss: 0.481809\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062440; batch adversarial loss: 0.399219\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033256; batch adversarial loss: 0.521006\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022931; batch adversarial loss: 0.511744\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045786; batch adversarial loss: 0.449051\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018302; batch adversarial loss: 0.480169\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023468; batch adversarial loss: 0.432208\n",
      "epoch 140; iter: 0; batch classifier loss: 0.052053; batch adversarial loss: 0.455207\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036268; batch adversarial loss: 0.451341\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020828; batch adversarial loss: 0.422616\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025699; batch adversarial loss: 0.505618\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025026; batch adversarial loss: 0.403785\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015762; batch adversarial loss: 0.521359\n",
      "epoch 146; iter: 0; batch classifier loss: 0.070793; batch adversarial loss: 0.470342\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015638; batch adversarial loss: 0.433406\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012196; batch adversarial loss: 0.472977\n",
      "epoch 149; iter: 0; batch classifier loss: 0.054214; batch adversarial loss: 0.480454\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023782; batch adversarial loss: 0.482354\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027315; batch adversarial loss: 0.394649\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031950; batch adversarial loss: 0.367323\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036662; batch adversarial loss: 0.509426\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027758; batch adversarial loss: 0.436619\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041570; batch adversarial loss: 0.460807\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021077; batch adversarial loss: 0.452640\n",
      "epoch 157; iter: 0; batch classifier loss: 0.008079; batch adversarial loss: 0.571546\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012479; batch adversarial loss: 0.455430\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024145; batch adversarial loss: 0.425105\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046227; batch adversarial loss: 0.480005\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012460; batch adversarial loss: 0.415665\n",
      "epoch 162; iter: 0; batch classifier loss: 0.042332; batch adversarial loss: 0.380734\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016632; batch adversarial loss: 0.464150\n",
      "epoch 164; iter: 0; batch classifier loss: 0.059234; batch adversarial loss: 0.467714\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009028; batch adversarial loss: 0.507223\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025537; batch adversarial loss: 0.453556\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031173; batch adversarial loss: 0.490072\n",
      "epoch 168; iter: 0; batch classifier loss: 0.049641; batch adversarial loss: 0.568806\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011934; batch adversarial loss: 0.488343\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027800; batch adversarial loss: 0.465062\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030495; batch adversarial loss: 0.393015\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018046; batch adversarial loss: 0.417106\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034751; batch adversarial loss: 0.469798\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029912; batch adversarial loss: 0.432565\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025512; batch adversarial loss: 0.451624\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021426; batch adversarial loss: 0.423485\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032834; batch adversarial loss: 0.373199\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022301; batch adversarial loss: 0.461663\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031605; batch adversarial loss: 0.431355\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012956; batch adversarial loss: 0.388252\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011513; batch adversarial loss: 0.391053\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009634; batch adversarial loss: 0.355673\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026162; batch adversarial loss: 0.465352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.010266; batch adversarial loss: 0.466961\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040675; batch adversarial loss: 0.428120\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006873; batch adversarial loss: 0.430720\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023275; batch adversarial loss: 0.455265\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018468; batch adversarial loss: 0.416139\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018981; batch adversarial loss: 0.396319\n",
      "epoch 190; iter: 0; batch classifier loss: 0.074008; batch adversarial loss: 0.395290\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025088; batch adversarial loss: 0.412414\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011882; batch adversarial loss: 0.531830\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024102; batch adversarial loss: 0.476353\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020117; batch adversarial loss: 0.443907\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017906; batch adversarial loss: 0.399093\n",
      "epoch 196; iter: 0; batch classifier loss: 0.034732; batch adversarial loss: 0.400397\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011821; batch adversarial loss: 0.433963\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011165; batch adversarial loss: 0.455366\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031171; batch adversarial loss: 0.463574\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700611; batch adversarial loss: 0.718962\n",
      "epoch 1; iter: 0; batch classifier loss: 0.510094; batch adversarial loss: 0.663794\n",
      "epoch 2; iter: 0; batch classifier loss: 0.421386; batch adversarial loss: 0.639723\n",
      "epoch 3; iter: 0; batch classifier loss: 0.468521; batch adversarial loss: 0.613720\n",
      "epoch 4; iter: 0; batch classifier loss: 0.399258; batch adversarial loss: 0.577227\n",
      "epoch 5; iter: 0; batch classifier loss: 0.429746; batch adversarial loss: 0.579287\n",
      "epoch 6; iter: 0; batch classifier loss: 0.344359; batch adversarial loss: 0.581146\n",
      "epoch 7; iter: 0; batch classifier loss: 0.339112; batch adversarial loss: 0.572193\n",
      "epoch 8; iter: 0; batch classifier loss: 0.417316; batch adversarial loss: 0.534853\n",
      "epoch 9; iter: 0; batch classifier loss: 0.398576; batch adversarial loss: 0.525771\n",
      "epoch 10; iter: 0; batch classifier loss: 0.400953; batch adversarial loss: 0.511318\n",
      "epoch 11; iter: 0; batch classifier loss: 0.319978; batch adversarial loss: 0.577553\n",
      "epoch 12; iter: 0; batch classifier loss: 0.331722; batch adversarial loss: 0.516462\n",
      "epoch 13; iter: 0; batch classifier loss: 0.384187; batch adversarial loss: 0.486256\n",
      "epoch 14; iter: 0; batch classifier loss: 0.350450; batch adversarial loss: 0.467699\n",
      "epoch 15; iter: 0; batch classifier loss: 0.399260; batch adversarial loss: 0.459566\n",
      "epoch 16; iter: 0; batch classifier loss: 0.280183; batch adversarial loss: 0.511946\n",
      "epoch 17; iter: 0; batch classifier loss: 0.249035; batch adversarial loss: 0.497092\n",
      "epoch 18; iter: 0; batch classifier loss: 0.299087; batch adversarial loss: 0.485496\n",
      "epoch 19; iter: 0; batch classifier loss: 0.234377; batch adversarial loss: 0.494767\n",
      "epoch 20; iter: 0; batch classifier loss: 0.283069; batch adversarial loss: 0.497426\n",
      "epoch 21; iter: 0; batch classifier loss: 0.225219; batch adversarial loss: 0.551265\n",
      "epoch 22; iter: 0; batch classifier loss: 0.271901; batch adversarial loss: 0.487723\n",
      "epoch 23; iter: 0; batch classifier loss: 0.302490; batch adversarial loss: 0.377690\n",
      "epoch 24; iter: 0; batch classifier loss: 0.213969; batch adversarial loss: 0.464502\n",
      "epoch 25; iter: 0; batch classifier loss: 0.159358; batch adversarial loss: 0.577159\n",
      "epoch 26; iter: 0; batch classifier loss: 0.138129; batch adversarial loss: 0.442484\n",
      "epoch 27; iter: 0; batch classifier loss: 0.208768; batch adversarial loss: 0.458966\n",
      "epoch 28; iter: 0; batch classifier loss: 0.166685; batch adversarial loss: 0.426935\n",
      "epoch 29; iter: 0; batch classifier loss: 0.149388; batch adversarial loss: 0.527861\n",
      "epoch 30; iter: 0; batch classifier loss: 0.126456; batch adversarial loss: 0.553501\n",
      "epoch 31; iter: 0; batch classifier loss: 0.188703; batch adversarial loss: 0.388705\n",
      "epoch 32; iter: 0; batch classifier loss: 0.124521; batch adversarial loss: 0.462787\n",
      "epoch 33; iter: 0; batch classifier loss: 0.175738; batch adversarial loss: 0.380087\n",
      "epoch 34; iter: 0; batch classifier loss: 0.140117; batch adversarial loss: 0.447913\n",
      "epoch 35; iter: 0; batch classifier loss: 0.121303; batch adversarial loss: 0.455474\n",
      "epoch 36; iter: 0; batch classifier loss: 0.182854; batch adversarial loss: 0.420478\n",
      "epoch 37; iter: 0; batch classifier loss: 0.148689; batch adversarial loss: 0.458027\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115316; batch adversarial loss: 0.456691\n",
      "epoch 39; iter: 0; batch classifier loss: 0.170028; batch adversarial loss: 0.548135\n",
      "epoch 40; iter: 0; batch classifier loss: 0.094672; batch adversarial loss: 0.450182\n",
      "epoch 41; iter: 0; batch classifier loss: 0.155741; batch adversarial loss: 0.532576\n",
      "epoch 42; iter: 0; batch classifier loss: 0.178782; batch adversarial loss: 0.399212\n",
      "epoch 43; iter: 0; batch classifier loss: 0.080103; batch adversarial loss: 0.440366\n",
      "epoch 44; iter: 0; batch classifier loss: 0.077345; batch adversarial loss: 0.365620\n",
      "epoch 45; iter: 0; batch classifier loss: 0.093517; batch adversarial loss: 0.512196\n",
      "epoch 46; iter: 0; batch classifier loss: 0.068531; batch adversarial loss: 0.424681\n",
      "epoch 47; iter: 0; batch classifier loss: 0.081746; batch adversarial loss: 0.466834\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104815; batch adversarial loss: 0.417600\n",
      "epoch 49; iter: 0; batch classifier loss: 0.082778; batch adversarial loss: 0.466737\n",
      "epoch 50; iter: 0; batch classifier loss: 0.155842; batch adversarial loss: 0.443731\n",
      "epoch 51; iter: 0; batch classifier loss: 0.150356; batch adversarial loss: 0.474200\n",
      "epoch 52; iter: 0; batch classifier loss: 0.065259; batch adversarial loss: 0.426364\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076502; batch adversarial loss: 0.478531\n",
      "epoch 54; iter: 0; batch classifier loss: 0.100133; batch adversarial loss: 0.549881\n",
      "epoch 55; iter: 0; batch classifier loss: 0.065064; batch adversarial loss: 0.441613\n",
      "epoch 56; iter: 0; batch classifier loss: 0.064940; batch adversarial loss: 0.428951\n",
      "epoch 57; iter: 0; batch classifier loss: 0.059100; batch adversarial loss: 0.466431\n",
      "epoch 58; iter: 0; batch classifier loss: 0.062664; batch adversarial loss: 0.507597\n",
      "epoch 59; iter: 0; batch classifier loss: 0.085398; batch adversarial loss: 0.438135\n",
      "epoch 60; iter: 0; batch classifier loss: 0.135402; batch adversarial loss: 0.407047\n",
      "epoch 61; iter: 0; batch classifier loss: 0.056206; batch adversarial loss: 0.514440\n",
      "epoch 62; iter: 0; batch classifier loss: 0.052148; batch adversarial loss: 0.449003\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070088; batch adversarial loss: 0.355606\n",
      "epoch 64; iter: 0; batch classifier loss: 0.117461; batch adversarial loss: 0.443387\n",
      "epoch 65; iter: 0; batch classifier loss: 0.091845; batch adversarial loss: 0.523084\n",
      "epoch 66; iter: 0; batch classifier loss: 0.055727; batch adversarial loss: 0.535031\n",
      "epoch 67; iter: 0; batch classifier loss: 0.078351; batch adversarial loss: 0.371584\n",
      "epoch 68; iter: 0; batch classifier loss: 0.116892; batch adversarial loss: 0.484340\n",
      "epoch 69; iter: 0; batch classifier loss: 0.082067; batch adversarial loss: 0.355265\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090087; batch adversarial loss: 0.410843\n",
      "epoch 71; iter: 0; batch classifier loss: 0.060430; batch adversarial loss: 0.485539\n",
      "epoch 72; iter: 0; batch classifier loss: 0.057880; batch adversarial loss: 0.528503\n",
      "epoch 73; iter: 0; batch classifier loss: 0.031647; batch adversarial loss: 0.446857\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063415; batch adversarial loss: 0.412043\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077680; batch adversarial loss: 0.439500\n",
      "epoch 76; iter: 0; batch classifier loss: 0.049939; batch adversarial loss: 0.356267\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050635; batch adversarial loss: 0.501214\n",
      "epoch 78; iter: 0; batch classifier loss: 0.035303; batch adversarial loss: 0.447912\n",
      "epoch 79; iter: 0; batch classifier loss: 0.037840; batch adversarial loss: 0.373565\n",
      "epoch 80; iter: 0; batch classifier loss: 0.071924; batch adversarial loss: 0.521620\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057401; batch adversarial loss: 0.404889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.082671; batch adversarial loss: 0.433253\n",
      "epoch 83; iter: 0; batch classifier loss: 0.044879; batch adversarial loss: 0.396878\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056829; batch adversarial loss: 0.415119\n",
      "epoch 85; iter: 0; batch classifier loss: 0.094386; batch adversarial loss: 0.442453\n",
      "epoch 86; iter: 0; batch classifier loss: 0.033942; batch adversarial loss: 0.549824\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046539; batch adversarial loss: 0.341809\n",
      "epoch 88; iter: 0; batch classifier loss: 0.036645; batch adversarial loss: 0.449500\n",
      "epoch 89; iter: 0; batch classifier loss: 0.049283; batch adversarial loss: 0.415038\n",
      "epoch 90; iter: 0; batch classifier loss: 0.025189; batch adversarial loss: 0.475019\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062242; batch adversarial loss: 0.402268\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041876; batch adversarial loss: 0.443803\n",
      "epoch 93; iter: 0; batch classifier loss: 0.042012; batch adversarial loss: 0.520172\n",
      "epoch 94; iter: 0; batch classifier loss: 0.023957; batch adversarial loss: 0.398722\n",
      "epoch 95; iter: 0; batch classifier loss: 0.030489; batch adversarial loss: 0.425055\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037003; batch adversarial loss: 0.341232\n",
      "epoch 97; iter: 0; batch classifier loss: 0.068854; batch adversarial loss: 0.387761\n",
      "epoch 98; iter: 0; batch classifier loss: 0.094440; batch adversarial loss: 0.357634\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040295; batch adversarial loss: 0.533535\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055824; batch adversarial loss: 0.590687\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075691; batch adversarial loss: 0.500541\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038319; batch adversarial loss: 0.550912\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049008; batch adversarial loss: 0.449026\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037027; batch adversarial loss: 0.517723\n",
      "epoch 105; iter: 0; batch classifier loss: 0.036302; batch adversarial loss: 0.449846\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030931; batch adversarial loss: 0.532471\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032863; batch adversarial loss: 0.371707\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046292; batch adversarial loss: 0.467948\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061387; batch adversarial loss: 0.429684\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038157; batch adversarial loss: 0.382533\n",
      "epoch 111; iter: 0; batch classifier loss: 0.107213; batch adversarial loss: 0.371307\n",
      "epoch 112; iter: 0; batch classifier loss: 0.048641; batch adversarial loss: 0.417704\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041107; batch adversarial loss: 0.461500\n",
      "epoch 114; iter: 0; batch classifier loss: 0.011534; batch adversarial loss: 0.456760\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036560; batch adversarial loss: 0.574247\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046506; batch adversarial loss: 0.426456\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029926; batch adversarial loss: 0.465151\n",
      "epoch 118; iter: 0; batch classifier loss: 0.068750; batch adversarial loss: 0.503333\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038367; batch adversarial loss: 0.418019\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053172; batch adversarial loss: 0.529350\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024264; batch adversarial loss: 0.436744\n",
      "epoch 122; iter: 0; batch classifier loss: 0.053198; batch adversarial loss: 0.563620\n",
      "epoch 123; iter: 0; batch classifier loss: 0.022117; batch adversarial loss: 0.437371\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022470; batch adversarial loss: 0.407486\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028130; batch adversarial loss: 0.377194\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033887; batch adversarial loss: 0.489985\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034569; batch adversarial loss: 0.519042\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037250; batch adversarial loss: 0.448288\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024185; batch adversarial loss: 0.431076\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038326; batch adversarial loss: 0.469717\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041733; batch adversarial loss: 0.418817\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038752; batch adversarial loss: 0.417310\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021051; batch adversarial loss: 0.399396\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027676; batch adversarial loss: 0.357540\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016249; batch adversarial loss: 0.476615\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016778; batch adversarial loss: 0.504732\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022963; batch adversarial loss: 0.456296\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026602; batch adversarial loss: 0.492062\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044130; batch adversarial loss: 0.479034\n",
      "epoch 140; iter: 0; batch classifier loss: 0.077835; batch adversarial loss: 0.430503\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025179; batch adversarial loss: 0.456627\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043823; batch adversarial loss: 0.469384\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037179; batch adversarial loss: 0.446629\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020333; batch adversarial loss: 0.398144\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037396; batch adversarial loss: 0.332713\n",
      "epoch 146; iter: 0; batch classifier loss: 0.014802; batch adversarial loss: 0.506516\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026024; batch adversarial loss: 0.416093\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028834; batch adversarial loss: 0.481963\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040395; batch adversarial loss: 0.481174\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044545; batch adversarial loss: 0.468836\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041288; batch adversarial loss: 0.475298\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024168; batch adversarial loss: 0.527539\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020585; batch adversarial loss: 0.497309\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015800; batch adversarial loss: 0.406110\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016966; batch adversarial loss: 0.513643\n",
      "epoch 156; iter: 0; batch classifier loss: 0.009865; batch adversarial loss: 0.523114\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012757; batch adversarial loss: 0.461147\n",
      "epoch 158; iter: 0; batch classifier loss: 0.106470; batch adversarial loss: 0.480905\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018780; batch adversarial loss: 0.406351\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023411; batch adversarial loss: 0.413134\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010896; batch adversarial loss: 0.443980\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032837; batch adversarial loss: 0.419126\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011688; batch adversarial loss: 0.469570\n",
      "epoch 164; iter: 0; batch classifier loss: 0.044006; batch adversarial loss: 0.463372\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012040; batch adversarial loss: 0.458784\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024160; batch adversarial loss: 0.448364\n",
      "epoch 167; iter: 0; batch classifier loss: 0.038754; batch adversarial loss: 0.443285\n",
      "epoch 168; iter: 0; batch classifier loss: 0.051948; batch adversarial loss: 0.517794\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022185; batch adversarial loss: 0.388217\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024217; batch adversarial loss: 0.416849\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029586; batch adversarial loss: 0.394358\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019416; batch adversarial loss: 0.393071\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034159; batch adversarial loss: 0.380869\n",
      "epoch 174; iter: 0; batch classifier loss: 0.003817; batch adversarial loss: 0.504647\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018711; batch adversarial loss: 0.444465\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029165; batch adversarial loss: 0.437357\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029112; batch adversarial loss: 0.414375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.031779; batch adversarial loss: 0.532843\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031780; batch adversarial loss: 0.440992\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020235; batch adversarial loss: 0.412473\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025134; batch adversarial loss: 0.437840\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018436; batch adversarial loss: 0.430385\n",
      "epoch 183; iter: 0; batch classifier loss: 0.048078; batch adversarial loss: 0.359889\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014978; batch adversarial loss: 0.508584\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032772; batch adversarial loss: 0.426312\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023260; batch adversarial loss: 0.466769\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016897; batch adversarial loss: 0.411398\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013136; batch adversarial loss: 0.472592\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022193; batch adversarial loss: 0.448543\n",
      "epoch 190; iter: 0; batch classifier loss: 0.048764; batch adversarial loss: 0.469946\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011779; batch adversarial loss: 0.390809\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029328; batch adversarial loss: 0.467908\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004495; batch adversarial loss: 0.488437\n",
      "epoch 194; iter: 0; batch classifier loss: 0.029083; batch adversarial loss: 0.351660\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028380; batch adversarial loss: 0.519862\n",
      "epoch 196; iter: 0; batch classifier loss: 0.042606; batch adversarial loss: 0.340662\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014075; batch adversarial loss: 0.454959\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019034; batch adversarial loss: 0.375756\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031068; batch adversarial loss: 0.427843\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685399; batch adversarial loss: 0.568274\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433062; batch adversarial loss: 0.600444\n",
      "epoch 2; iter: 0; batch classifier loss: 0.472768; batch adversarial loss: 0.573712\n",
      "epoch 3; iter: 0; batch classifier loss: 0.403951; batch adversarial loss: 0.578229\n",
      "epoch 4; iter: 0; batch classifier loss: 0.287682; batch adversarial loss: 0.550343\n",
      "epoch 5; iter: 0; batch classifier loss: 0.384637; batch adversarial loss: 0.573742\n",
      "epoch 6; iter: 0; batch classifier loss: 0.395617; batch adversarial loss: 0.501765\n",
      "epoch 7; iter: 0; batch classifier loss: 0.315688; batch adversarial loss: 0.509666\n",
      "epoch 8; iter: 0; batch classifier loss: 0.384466; batch adversarial loss: 0.586601\n",
      "epoch 9; iter: 0; batch classifier loss: 0.365525; batch adversarial loss: 0.501222\n",
      "epoch 10; iter: 0; batch classifier loss: 0.438260; batch adversarial loss: 0.543716\n",
      "epoch 11; iter: 0; batch classifier loss: 0.663651; batch adversarial loss: 0.594162\n",
      "epoch 12; iter: 0; batch classifier loss: 0.679244; batch adversarial loss: 0.563444\n",
      "epoch 13; iter: 0; batch classifier loss: 0.629491; batch adversarial loss: 0.516237\n",
      "epoch 14; iter: 0; batch classifier loss: 0.356158; batch adversarial loss: 0.493483\n",
      "epoch 15; iter: 0; batch classifier loss: 0.356079; batch adversarial loss: 0.476022\n",
      "epoch 16; iter: 0; batch classifier loss: 0.243587; batch adversarial loss: 0.532792\n",
      "epoch 17; iter: 0; batch classifier loss: 0.239205; batch adversarial loss: 0.531301\n",
      "epoch 18; iter: 0; batch classifier loss: 0.195548; batch adversarial loss: 0.434272\n",
      "epoch 19; iter: 0; batch classifier loss: 0.213105; batch adversarial loss: 0.474918\n",
      "epoch 20; iter: 0; batch classifier loss: 0.202117; batch adversarial loss: 0.509747\n",
      "epoch 21; iter: 0; batch classifier loss: 0.223019; batch adversarial loss: 0.450113\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224910; batch adversarial loss: 0.499438\n",
      "epoch 23; iter: 0; batch classifier loss: 0.188188; batch adversarial loss: 0.416643\n",
      "epoch 24; iter: 0; batch classifier loss: 0.168727; batch adversarial loss: 0.499509\n",
      "epoch 25; iter: 0; batch classifier loss: 0.194529; batch adversarial loss: 0.474782\n",
      "epoch 26; iter: 0; batch classifier loss: 0.245775; batch adversarial loss: 0.453289\n",
      "epoch 27; iter: 0; batch classifier loss: 0.190108; batch adversarial loss: 0.344320\n",
      "epoch 28; iter: 0; batch classifier loss: 0.243119; batch adversarial loss: 0.453879\n",
      "epoch 29; iter: 0; batch classifier loss: 0.193248; batch adversarial loss: 0.423969\n",
      "epoch 30; iter: 0; batch classifier loss: 0.131041; batch adversarial loss: 0.520337\n",
      "epoch 31; iter: 0; batch classifier loss: 0.206060; batch adversarial loss: 0.397023\n",
      "epoch 32; iter: 0; batch classifier loss: 0.168170; batch adversarial loss: 0.463713\n",
      "epoch 33; iter: 0; batch classifier loss: 0.243589; batch adversarial loss: 0.402059\n",
      "epoch 34; iter: 0; batch classifier loss: 0.151272; batch adversarial loss: 0.393243\n",
      "epoch 35; iter: 0; batch classifier loss: 0.128265; batch adversarial loss: 0.476047\n",
      "epoch 36; iter: 0; batch classifier loss: 0.224429; batch adversarial loss: 0.391665\n",
      "epoch 37; iter: 0; batch classifier loss: 0.149227; batch adversarial loss: 0.420486\n",
      "epoch 38; iter: 0; batch classifier loss: 0.173595; batch adversarial loss: 0.443952\n",
      "epoch 39; iter: 0; batch classifier loss: 0.134981; batch adversarial loss: 0.441958\n",
      "epoch 40; iter: 0; batch classifier loss: 0.139549; batch adversarial loss: 0.541717\n",
      "epoch 41; iter: 0; batch classifier loss: 0.177999; batch adversarial loss: 0.452606\n",
      "epoch 42; iter: 0; batch classifier loss: 0.147911; batch adversarial loss: 0.417011\n",
      "epoch 43; iter: 0; batch classifier loss: 0.176086; batch adversarial loss: 0.458815\n",
      "epoch 44; iter: 0; batch classifier loss: 0.190402; batch adversarial loss: 0.430778\n",
      "epoch 45; iter: 0; batch classifier loss: 0.205709; batch adversarial loss: 0.429961\n",
      "epoch 46; iter: 0; batch classifier loss: 0.143943; batch adversarial loss: 0.386800\n",
      "epoch 47; iter: 0; batch classifier loss: 0.116384; batch adversarial loss: 0.522974\n",
      "epoch 48; iter: 0; batch classifier loss: 0.172665; batch adversarial loss: 0.509943\n",
      "epoch 49; iter: 0; batch classifier loss: 0.273612; batch adversarial loss: 0.414944\n",
      "epoch 50; iter: 0; batch classifier loss: 0.160896; batch adversarial loss: 0.396827\n",
      "epoch 51; iter: 0; batch classifier loss: 0.144945; batch adversarial loss: 0.560817\n",
      "epoch 52; iter: 0; batch classifier loss: 0.183655; batch adversarial loss: 0.440558\n",
      "epoch 53; iter: 0; batch classifier loss: 0.139163; batch adversarial loss: 0.442901\n",
      "epoch 54; iter: 0; batch classifier loss: 0.190278; batch adversarial loss: 0.372841\n",
      "epoch 55; iter: 0; batch classifier loss: 0.171400; batch adversarial loss: 0.434036\n",
      "epoch 56; iter: 0; batch classifier loss: 0.107048; batch adversarial loss: 0.479095\n",
      "epoch 57; iter: 0; batch classifier loss: 0.179016; batch adversarial loss: 0.422888\n",
      "epoch 58; iter: 0; batch classifier loss: 0.227250; batch adversarial loss: 0.455352\n",
      "epoch 59; iter: 0; batch classifier loss: 0.170177; batch adversarial loss: 0.391204\n",
      "epoch 60; iter: 0; batch classifier loss: 0.138656; batch adversarial loss: 0.436628\n",
      "epoch 61; iter: 0; batch classifier loss: 0.163580; batch adversarial loss: 0.448719\n",
      "epoch 62; iter: 0; batch classifier loss: 0.221548; batch adversarial loss: 0.438450\n",
      "epoch 63; iter: 0; batch classifier loss: 0.161528; batch adversarial loss: 0.370783\n",
      "epoch 64; iter: 0; batch classifier loss: 0.144315; batch adversarial loss: 0.410538\n",
      "epoch 65; iter: 0; batch classifier loss: 0.220461; batch adversarial loss: 0.437084\n",
      "epoch 66; iter: 0; batch classifier loss: 0.130425; batch adversarial loss: 0.482926\n",
      "epoch 67; iter: 0; batch classifier loss: 0.218581; batch adversarial loss: 0.470287\n",
      "epoch 68; iter: 0; batch classifier loss: 0.176708; batch adversarial loss: 0.435915\n",
      "epoch 69; iter: 0; batch classifier loss: 0.160381; batch adversarial loss: 0.410991\n",
      "epoch 70; iter: 0; batch classifier loss: 0.109026; batch adversarial loss: 0.622151\n",
      "epoch 71; iter: 0; batch classifier loss: 0.148690; batch adversarial loss: 0.496414\n",
      "epoch 72; iter: 0; batch classifier loss: 0.129979; batch adversarial loss: 0.406911\n",
      "epoch 73; iter: 0; batch classifier loss: 0.178445; batch adversarial loss: 0.421113\n",
      "epoch 74; iter: 0; batch classifier loss: 0.184749; batch adversarial loss: 0.456386\n",
      "epoch 75; iter: 0; batch classifier loss: 0.232826; batch adversarial loss: 0.431033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.177626; batch adversarial loss: 0.493624\n",
      "epoch 77; iter: 0; batch classifier loss: 0.177114; batch adversarial loss: 0.484691\n",
      "epoch 78; iter: 0; batch classifier loss: 0.187316; batch adversarial loss: 0.546440\n",
      "epoch 79; iter: 0; batch classifier loss: 0.174671; batch adversarial loss: 0.409356\n",
      "epoch 80; iter: 0; batch classifier loss: 0.199223; batch adversarial loss: 0.420759\n",
      "epoch 81; iter: 0; batch classifier loss: 0.160810; batch adversarial loss: 0.556565\n",
      "epoch 82; iter: 0; batch classifier loss: 0.219580; batch adversarial loss: 0.434274\n",
      "epoch 83; iter: 0; batch classifier loss: 0.253177; batch adversarial loss: 0.382852\n",
      "epoch 84; iter: 0; batch classifier loss: 0.241013; batch adversarial loss: 0.434210\n",
      "epoch 85; iter: 0; batch classifier loss: 0.189766; batch adversarial loss: 0.344684\n",
      "epoch 86; iter: 0; batch classifier loss: 0.202751; batch adversarial loss: 0.447064\n",
      "epoch 87; iter: 0; batch classifier loss: 0.189872; batch adversarial loss: 0.510417\n",
      "epoch 88; iter: 0; batch classifier loss: 0.175638; batch adversarial loss: 0.446276\n",
      "epoch 89; iter: 0; batch classifier loss: 0.215587; batch adversarial loss: 0.406934\n",
      "epoch 90; iter: 0; batch classifier loss: 0.197322; batch adversarial loss: 0.447110\n",
      "epoch 91; iter: 0; batch classifier loss: 0.208254; batch adversarial loss: 0.395905\n",
      "epoch 92; iter: 0; batch classifier loss: 0.196102; batch adversarial loss: 0.421004\n",
      "epoch 93; iter: 0; batch classifier loss: 0.173946; batch adversarial loss: 0.484754\n",
      "epoch 94; iter: 0; batch classifier loss: 0.168932; batch adversarial loss: 0.572204\n",
      "epoch 95; iter: 0; batch classifier loss: 0.228854; batch adversarial loss: 0.333260\n",
      "epoch 96; iter: 0; batch classifier loss: 0.237807; batch adversarial loss: 0.470852\n",
      "epoch 97; iter: 0; batch classifier loss: 0.173348; batch adversarial loss: 0.408583\n",
      "epoch 98; iter: 0; batch classifier loss: 0.189647; batch adversarial loss: 0.420765\n",
      "epoch 99; iter: 0; batch classifier loss: 0.188286; batch adversarial loss: 0.408238\n",
      "epoch 100; iter: 0; batch classifier loss: 0.153401; batch adversarial loss: 0.446353\n",
      "epoch 101; iter: 0; batch classifier loss: 0.220732; batch adversarial loss: 0.371451\n",
      "epoch 102; iter: 0; batch classifier loss: 0.240338; batch adversarial loss: 0.444141\n",
      "epoch 103; iter: 0; batch classifier loss: 0.156708; batch adversarial loss: 0.383422\n",
      "epoch 104; iter: 0; batch classifier loss: 0.165891; batch adversarial loss: 0.433996\n",
      "epoch 105; iter: 0; batch classifier loss: 0.176248; batch adversarial loss: 0.432186\n",
      "epoch 106; iter: 0; batch classifier loss: 0.158110; batch adversarial loss: 0.450340\n",
      "epoch 107; iter: 0; batch classifier loss: 0.196122; batch adversarial loss: 0.381937\n",
      "epoch 108; iter: 0; batch classifier loss: 0.175101; batch adversarial loss: 0.420913\n",
      "epoch 109; iter: 0; batch classifier loss: 0.168210; batch adversarial loss: 0.482850\n",
      "epoch 110; iter: 0; batch classifier loss: 0.218439; batch adversarial loss: 0.511180\n",
      "epoch 111; iter: 0; batch classifier loss: 0.183069; batch adversarial loss: 0.382533\n",
      "epoch 112; iter: 0; batch classifier loss: 0.129262; batch adversarial loss: 0.443024\n",
      "epoch 113; iter: 0; batch classifier loss: 0.160772; batch adversarial loss: 0.445220\n",
      "epoch 114; iter: 0; batch classifier loss: 0.227482; batch adversarial loss: 0.456838\n",
      "epoch 115; iter: 0; batch classifier loss: 0.215707; batch adversarial loss: 0.396308\n",
      "epoch 116; iter: 0; batch classifier loss: 0.152271; batch adversarial loss: 0.458817\n",
      "epoch 117; iter: 0; batch classifier loss: 0.180172; batch adversarial loss: 0.420854\n",
      "epoch 118; iter: 0; batch classifier loss: 0.118253; batch adversarial loss: 0.533851\n",
      "epoch 119; iter: 0; batch classifier loss: 0.115690; batch adversarial loss: 0.435245\n",
      "epoch 120; iter: 0; batch classifier loss: 0.113850; batch adversarial loss: 0.366549\n",
      "epoch 121; iter: 0; batch classifier loss: 0.194328; batch adversarial loss: 0.496000\n",
      "epoch 122; iter: 0; batch classifier loss: 0.221860; batch adversarial loss: 0.483269\n",
      "epoch 123; iter: 0; batch classifier loss: 0.158131; batch adversarial loss: 0.497439\n",
      "epoch 124; iter: 0; batch classifier loss: 0.195297; batch adversarial loss: 0.417043\n",
      "epoch 125; iter: 0; batch classifier loss: 0.207569; batch adversarial loss: 0.534521\n",
      "epoch 126; iter: 0; batch classifier loss: 0.120240; batch adversarial loss: 0.511199\n",
      "epoch 127; iter: 0; batch classifier loss: 0.193343; batch adversarial loss: 0.505222\n",
      "epoch 128; iter: 0; batch classifier loss: 0.087788; batch adversarial loss: 0.519639\n",
      "epoch 129; iter: 0; batch classifier loss: 0.126622; batch adversarial loss: 0.494022\n",
      "epoch 130; iter: 0; batch classifier loss: 0.141644; batch adversarial loss: 0.507805\n",
      "epoch 131; iter: 0; batch classifier loss: 0.132080; batch adversarial loss: 0.524172\n",
      "epoch 132; iter: 0; batch classifier loss: 0.122781; batch adversarial loss: 0.423208\n",
      "epoch 133; iter: 0; batch classifier loss: 0.128320; batch adversarial loss: 0.355803\n",
      "epoch 134; iter: 0; batch classifier loss: 0.145028; batch adversarial loss: 0.378968\n",
      "epoch 135; iter: 0; batch classifier loss: 0.150183; batch adversarial loss: 0.353117\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056069; batch adversarial loss: 0.519994\n",
      "epoch 137; iter: 0; batch classifier loss: 0.095117; batch adversarial loss: 0.401816\n",
      "epoch 138; iter: 0; batch classifier loss: 0.090684; batch adversarial loss: 0.476120\n",
      "epoch 139; iter: 0; batch classifier loss: 0.054639; batch adversarial loss: 0.404912\n",
      "epoch 140; iter: 0; batch classifier loss: 0.052819; batch adversarial loss: 0.487204\n",
      "epoch 141; iter: 0; batch classifier loss: 0.056386; batch adversarial loss: 0.503018\n",
      "epoch 142; iter: 0; batch classifier loss: 0.104017; batch adversarial loss: 0.429316\n",
      "epoch 143; iter: 0; batch classifier loss: 0.067509; batch adversarial loss: 0.480309\n",
      "epoch 144; iter: 0; batch classifier loss: 0.065644; batch adversarial loss: 0.486190\n",
      "epoch 145; iter: 0; batch classifier loss: 0.059660; batch adversarial loss: 0.426360\n",
      "epoch 146; iter: 0; batch classifier loss: 0.063372; batch adversarial loss: 0.511421\n",
      "epoch 147; iter: 0; batch classifier loss: 0.058719; batch adversarial loss: 0.449914\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021369; batch adversarial loss: 0.433122\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026759; batch adversarial loss: 0.388428\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033501; batch adversarial loss: 0.450867\n",
      "epoch 151; iter: 0; batch classifier loss: 0.047756; batch adversarial loss: 0.376441\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034166; batch adversarial loss: 0.503835\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023749; batch adversarial loss: 0.465231\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020717; batch adversarial loss: 0.433684\n",
      "epoch 155; iter: 0; batch classifier loss: 0.053082; batch adversarial loss: 0.479275\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026625; batch adversarial loss: 0.514727\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028358; batch adversarial loss: 0.428838\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025056; batch adversarial loss: 0.376137\n",
      "epoch 159; iter: 0; batch classifier loss: 0.047914; batch adversarial loss: 0.431986\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032569; batch adversarial loss: 0.463190\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031656; batch adversarial loss: 0.489430\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020538; batch adversarial loss: 0.453258\n",
      "epoch 163; iter: 0; batch classifier loss: 0.056269; batch adversarial loss: 0.434429\n",
      "epoch 164; iter: 0; batch classifier loss: 0.042106; batch adversarial loss: 0.460755\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023823; batch adversarial loss: 0.447711\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014699; batch adversarial loss: 0.460784\n",
      "epoch 167; iter: 0; batch classifier loss: 0.027516; batch adversarial loss: 0.476027\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030390; batch adversarial loss: 0.348092\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022505; batch adversarial loss: 0.331657\n",
      "epoch 170; iter: 0; batch classifier loss: 0.053293; batch adversarial loss: 0.487576\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022732; batch adversarial loss: 0.444319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.017776; batch adversarial loss: 0.469712\n",
      "epoch 173; iter: 0; batch classifier loss: 0.058763; batch adversarial loss: 0.365507\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018320; batch adversarial loss: 0.504016\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032112; batch adversarial loss: 0.482233\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026608; batch adversarial loss: 0.488062\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022776; batch adversarial loss: 0.444045\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019656; batch adversarial loss: 0.471698\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029611; batch adversarial loss: 0.400319\n",
      "epoch 180; iter: 0; batch classifier loss: 0.044547; batch adversarial loss: 0.370449\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028752; batch adversarial loss: 0.488921\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019178; batch adversarial loss: 0.498889\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032306; batch adversarial loss: 0.479114\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018050; batch adversarial loss: 0.401778\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019763; batch adversarial loss: 0.327194\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029446; batch adversarial loss: 0.389533\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014501; batch adversarial loss: 0.411529\n",
      "epoch 188; iter: 0; batch classifier loss: 0.052167; batch adversarial loss: 0.494404\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025533; batch adversarial loss: 0.411313\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017808; batch adversarial loss: 0.451090\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021233; batch adversarial loss: 0.472571\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023130; batch adversarial loss: 0.416445\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010039; batch adversarial loss: 0.426448\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014925; batch adversarial loss: 0.389090\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011349; batch adversarial loss: 0.539557\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020892; batch adversarial loss: 0.424550\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032435; batch adversarial loss: 0.502218\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015345; batch adversarial loss: 0.411363\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009972; batch adversarial loss: 0.500500\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710933; batch adversarial loss: 0.798593\n",
      "epoch 1; iter: 0; batch classifier loss: 0.726173; batch adversarial loss: 0.893187\n",
      "epoch 2; iter: 0; batch classifier loss: 0.780965; batch adversarial loss: 0.842462\n",
      "epoch 3; iter: 0; batch classifier loss: 0.809600; batch adversarial loss: 0.768573\n",
      "epoch 4; iter: 0; batch classifier loss: 0.742875; batch adversarial loss: 0.737162\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592253; batch adversarial loss: 0.593913\n",
      "epoch 6; iter: 0; batch classifier loss: 0.528329; batch adversarial loss: 0.583489\n",
      "epoch 7; iter: 0; batch classifier loss: 0.405641; batch adversarial loss: 0.534540\n",
      "epoch 8; iter: 0; batch classifier loss: 0.369218; batch adversarial loss: 0.543375\n",
      "epoch 9; iter: 0; batch classifier loss: 0.277607; batch adversarial loss: 0.592634\n",
      "epoch 10; iter: 0; batch classifier loss: 0.257308; batch adversarial loss: 0.560687\n",
      "epoch 11; iter: 0; batch classifier loss: 0.203251; batch adversarial loss: 0.522884\n",
      "epoch 12; iter: 0; batch classifier loss: 0.261528; batch adversarial loss: 0.533245\n",
      "epoch 13; iter: 0; batch classifier loss: 0.222164; batch adversarial loss: 0.480484\n",
      "epoch 14; iter: 0; batch classifier loss: 0.185224; batch adversarial loss: 0.517779\n",
      "epoch 15; iter: 0; batch classifier loss: 0.215112; batch adversarial loss: 0.455904\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227354; batch adversarial loss: 0.513625\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348331; batch adversarial loss: 0.486011\n",
      "epoch 18; iter: 0; batch classifier loss: 0.230023; batch adversarial loss: 0.456925\n",
      "epoch 19; iter: 0; batch classifier loss: 0.216327; batch adversarial loss: 0.478106\n",
      "epoch 20; iter: 0; batch classifier loss: 0.253515; batch adversarial loss: 0.601812\n",
      "epoch 21; iter: 0; batch classifier loss: 0.196482; batch adversarial loss: 0.474096\n",
      "epoch 22; iter: 0; batch classifier loss: 0.204372; batch adversarial loss: 0.472546\n",
      "epoch 23; iter: 0; batch classifier loss: 0.140943; batch adversarial loss: 0.466321\n",
      "epoch 24; iter: 0; batch classifier loss: 0.188543; batch adversarial loss: 0.482018\n",
      "epoch 25; iter: 0; batch classifier loss: 0.183734; batch adversarial loss: 0.438588\n",
      "epoch 26; iter: 0; batch classifier loss: 0.119206; batch adversarial loss: 0.553433\n",
      "epoch 27; iter: 0; batch classifier loss: 0.138719; batch adversarial loss: 0.432611\n",
      "epoch 28; iter: 0; batch classifier loss: 0.187565; batch adversarial loss: 0.474131\n",
      "epoch 29; iter: 0; batch classifier loss: 0.144246; batch adversarial loss: 0.540556\n",
      "epoch 30; iter: 0; batch classifier loss: 0.123833; batch adversarial loss: 0.591975\n",
      "epoch 31; iter: 0; batch classifier loss: 0.141655; batch adversarial loss: 0.439203\n",
      "epoch 32; iter: 0; batch classifier loss: 0.180237; batch adversarial loss: 0.468913\n",
      "epoch 33; iter: 0; batch classifier loss: 0.192716; batch adversarial loss: 0.402441\n",
      "epoch 34; iter: 0; batch classifier loss: 0.105369; batch adversarial loss: 0.353354\n",
      "epoch 35; iter: 0; batch classifier loss: 0.123091; batch adversarial loss: 0.537407\n",
      "epoch 36; iter: 0; batch classifier loss: 0.136327; batch adversarial loss: 0.383161\n",
      "epoch 37; iter: 0; batch classifier loss: 0.084678; batch adversarial loss: 0.506084\n",
      "epoch 38; iter: 0; batch classifier loss: 0.145205; batch adversarial loss: 0.454644\n",
      "epoch 39; iter: 0; batch classifier loss: 0.150335; batch adversarial loss: 0.372605\n",
      "epoch 40; iter: 0; batch classifier loss: 0.161031; batch adversarial loss: 0.449268\n",
      "epoch 41; iter: 0; batch classifier loss: 0.151260; batch adversarial loss: 0.428114\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106095; batch adversarial loss: 0.507597\n",
      "epoch 43; iter: 0; batch classifier loss: 0.128438; batch adversarial loss: 0.418297\n",
      "epoch 44; iter: 0; batch classifier loss: 0.113064; batch adversarial loss: 0.443011\n",
      "epoch 45; iter: 0; batch classifier loss: 0.068602; batch adversarial loss: 0.548925\n",
      "epoch 46; iter: 0; batch classifier loss: 0.100661; batch adversarial loss: 0.408572\n",
      "epoch 47; iter: 0; batch classifier loss: 0.075839; batch adversarial loss: 0.351728\n",
      "epoch 48; iter: 0; batch classifier loss: 0.092788; batch adversarial loss: 0.450411\n",
      "epoch 49; iter: 0; batch classifier loss: 0.092160; batch adversarial loss: 0.471437\n",
      "epoch 50; iter: 0; batch classifier loss: 0.133400; batch adversarial loss: 0.419234\n",
      "epoch 51; iter: 0; batch classifier loss: 0.131409; batch adversarial loss: 0.484935\n",
      "epoch 52; iter: 0; batch classifier loss: 0.060518; batch adversarial loss: 0.373689\n",
      "epoch 53; iter: 0; batch classifier loss: 0.062659; batch adversarial loss: 0.568355\n",
      "epoch 54; iter: 0; batch classifier loss: 0.102398; batch adversarial loss: 0.407395\n",
      "epoch 55; iter: 0; batch classifier loss: 0.106982; batch adversarial loss: 0.429222\n",
      "epoch 56; iter: 0; batch classifier loss: 0.100304; batch adversarial loss: 0.448680\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086126; batch adversarial loss: 0.458762\n",
      "epoch 58; iter: 0; batch classifier loss: 0.061922; batch adversarial loss: 0.384107\n",
      "epoch 59; iter: 0; batch classifier loss: 0.077097; batch adversarial loss: 0.481014\n",
      "epoch 60; iter: 0; batch classifier loss: 0.099342; batch adversarial loss: 0.502595\n",
      "epoch 61; iter: 0; batch classifier loss: 0.086398; batch adversarial loss: 0.360848\n",
      "epoch 62; iter: 0; batch classifier loss: 0.125204; batch adversarial loss: 0.564919\n",
      "epoch 63; iter: 0; batch classifier loss: 0.114939; batch adversarial loss: 0.410570\n",
      "epoch 64; iter: 0; batch classifier loss: 0.097597; batch adversarial loss: 0.468404\n",
      "epoch 65; iter: 0; batch classifier loss: 0.047940; batch adversarial loss: 0.425773\n",
      "epoch 66; iter: 0; batch classifier loss: 0.093490; batch adversarial loss: 0.476109\n",
      "epoch 67; iter: 0; batch classifier loss: 0.054291; batch adversarial loss: 0.436195\n",
      "epoch 68; iter: 0; batch classifier loss: 0.067783; batch adversarial loss: 0.530989\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064154; batch adversarial loss: 0.491926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.080013; batch adversarial loss: 0.468281\n",
      "epoch 71; iter: 0; batch classifier loss: 0.088987; batch adversarial loss: 0.478230\n",
      "epoch 72; iter: 0; batch classifier loss: 0.070499; batch adversarial loss: 0.465574\n",
      "epoch 73; iter: 0; batch classifier loss: 0.088070; batch adversarial loss: 0.490325\n",
      "epoch 74; iter: 0; batch classifier loss: 0.167899; batch adversarial loss: 0.384373\n",
      "epoch 75; iter: 0; batch classifier loss: 0.110209; batch adversarial loss: 0.506294\n",
      "epoch 76; iter: 0; batch classifier loss: 0.079286; batch adversarial loss: 0.529484\n",
      "epoch 77; iter: 0; batch classifier loss: 0.094298; batch adversarial loss: 0.392936\n",
      "epoch 78; iter: 0; batch classifier loss: 0.053053; batch adversarial loss: 0.533360\n",
      "epoch 79; iter: 0; batch classifier loss: 0.048217; batch adversarial loss: 0.508676\n",
      "epoch 80; iter: 0; batch classifier loss: 0.089490; batch adversarial loss: 0.540064\n",
      "epoch 81; iter: 0; batch classifier loss: 0.048027; batch adversarial loss: 0.440080\n",
      "epoch 82; iter: 0; batch classifier loss: 0.116988; batch adversarial loss: 0.499464\n",
      "epoch 83; iter: 0; batch classifier loss: 0.043337; batch adversarial loss: 0.433029\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070789; batch adversarial loss: 0.439941\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064361; batch adversarial loss: 0.442006\n",
      "epoch 86; iter: 0; batch classifier loss: 0.097546; batch adversarial loss: 0.532110\n",
      "epoch 87; iter: 0; batch classifier loss: 0.126348; batch adversarial loss: 0.412122\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041898; batch adversarial loss: 0.474129\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051214; batch adversarial loss: 0.529159\n",
      "epoch 90; iter: 0; batch classifier loss: 0.094282; batch adversarial loss: 0.474591\n",
      "epoch 91; iter: 0; batch classifier loss: 0.053536; batch adversarial loss: 0.457589\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077985; batch adversarial loss: 0.509300\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067724; batch adversarial loss: 0.444069\n",
      "epoch 94; iter: 0; batch classifier loss: 0.067302; batch adversarial loss: 0.556278\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079742; batch adversarial loss: 0.424945\n",
      "epoch 96; iter: 0; batch classifier loss: 0.094945; batch adversarial loss: 0.396611\n",
      "epoch 97; iter: 0; batch classifier loss: 0.084078; batch adversarial loss: 0.531524\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058987; batch adversarial loss: 0.471465\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071663; batch adversarial loss: 0.347711\n",
      "epoch 100; iter: 0; batch classifier loss: 0.072006; batch adversarial loss: 0.438807\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075763; batch adversarial loss: 0.511360\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048159; batch adversarial loss: 0.370466\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037608; batch adversarial loss: 0.481972\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039178; batch adversarial loss: 0.435901\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076144; batch adversarial loss: 0.491854\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045187; batch adversarial loss: 0.503345\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039949; batch adversarial loss: 0.434814\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039182; batch adversarial loss: 0.448166\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046873; batch adversarial loss: 0.426299\n",
      "epoch 110; iter: 0; batch classifier loss: 0.079659; batch adversarial loss: 0.408657\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033427; batch adversarial loss: 0.454356\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040709; batch adversarial loss: 0.449348\n",
      "epoch 113; iter: 0; batch classifier loss: 0.017266; batch adversarial loss: 0.427912\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027023; batch adversarial loss: 0.453179\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059794; batch adversarial loss: 0.446247\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051341; batch adversarial loss: 0.447430\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040821; batch adversarial loss: 0.511988\n",
      "epoch 118; iter: 0; batch classifier loss: 0.034725; batch adversarial loss: 0.438751\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040871; batch adversarial loss: 0.357402\n",
      "epoch 120; iter: 0; batch classifier loss: 0.052858; batch adversarial loss: 0.420896\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045672; batch adversarial loss: 0.430032\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031174; batch adversarial loss: 0.471105\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026184; batch adversarial loss: 0.510853\n",
      "epoch 124; iter: 0; batch classifier loss: 0.028159; batch adversarial loss: 0.440079\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030832; batch adversarial loss: 0.520569\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039458; batch adversarial loss: 0.412439\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025433; batch adversarial loss: 0.463200\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032316; batch adversarial loss: 0.463762\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037522; batch adversarial loss: 0.320960\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018442; batch adversarial loss: 0.441761\n",
      "epoch 131; iter: 0; batch classifier loss: 0.014114; batch adversarial loss: 0.451472\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047540; batch adversarial loss: 0.383763\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034350; batch adversarial loss: 0.425821\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025434; batch adversarial loss: 0.463208\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030386; batch adversarial loss: 0.426230\n",
      "epoch 136; iter: 0; batch classifier loss: 0.045611; batch adversarial loss: 0.444931\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018780; batch adversarial loss: 0.405644\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028682; batch adversarial loss: 0.378247\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016854; batch adversarial loss: 0.459442\n",
      "epoch 140; iter: 0; batch classifier loss: 0.042441; batch adversarial loss: 0.409399\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030421; batch adversarial loss: 0.518506\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026027; batch adversarial loss: 0.451619\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033824; batch adversarial loss: 0.434338\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026055; batch adversarial loss: 0.533887\n",
      "epoch 145; iter: 0; batch classifier loss: 0.010259; batch adversarial loss: 0.418481\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051394; batch adversarial loss: 0.451494\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038362; batch adversarial loss: 0.478452\n",
      "epoch 148; iter: 0; batch classifier loss: 0.071927; batch adversarial loss: 0.432259\n",
      "epoch 149; iter: 0; batch classifier loss: 0.055076; batch adversarial loss: 0.359544\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043532; batch adversarial loss: 0.400131\n",
      "epoch 151; iter: 0; batch classifier loss: 0.069886; batch adversarial loss: 0.440332\n",
      "epoch 152; iter: 0; batch classifier loss: 0.077461; batch adversarial loss: 0.487097\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025228; batch adversarial loss: 0.443924\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030060; batch adversarial loss: 0.452581\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026557; batch adversarial loss: 0.428722\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023208; batch adversarial loss: 0.383383\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021638; batch adversarial loss: 0.493538\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020770; batch adversarial loss: 0.505003\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022952; batch adversarial loss: 0.480229\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012978; batch adversarial loss: 0.402945\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022077; batch adversarial loss: 0.437459\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018343; batch adversarial loss: 0.467589\n",
      "epoch 163; iter: 0; batch classifier loss: 0.045055; batch adversarial loss: 0.446029\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031546; batch adversarial loss: 0.399013\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016302; batch adversarial loss: 0.439874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.031387; batch adversarial loss: 0.442585\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024735; batch adversarial loss: 0.392175\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028797; batch adversarial loss: 0.456632\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032091; batch adversarial loss: 0.502431\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029381; batch adversarial loss: 0.371739\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027475; batch adversarial loss: 0.524132\n",
      "epoch 172; iter: 0; batch classifier loss: 0.035483; batch adversarial loss: 0.493971\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016119; batch adversarial loss: 0.449453\n",
      "epoch 174; iter: 0; batch classifier loss: 0.053817; batch adversarial loss: 0.450329\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028904; batch adversarial loss: 0.403417\n",
      "epoch 176; iter: 0; batch classifier loss: 0.050108; batch adversarial loss: 0.514255\n",
      "epoch 177; iter: 0; batch classifier loss: 0.044076; batch adversarial loss: 0.355644\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023696; batch adversarial loss: 0.584348\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030911; batch adversarial loss: 0.477020\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012666; batch adversarial loss: 0.511348\n",
      "epoch 181; iter: 0; batch classifier loss: 0.038469; batch adversarial loss: 0.393692\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013320; batch adversarial loss: 0.424960\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008720; batch adversarial loss: 0.562114\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015603; batch adversarial loss: 0.434867\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006827; batch adversarial loss: 0.505604\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033426; batch adversarial loss: 0.436701\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028683; batch adversarial loss: 0.459305\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021400; batch adversarial loss: 0.481391\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015286; batch adversarial loss: 0.376539\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015148; batch adversarial loss: 0.465997\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029014; batch adversarial loss: 0.462745\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037598; batch adversarial loss: 0.502554\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021239; batch adversarial loss: 0.386522\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035019; batch adversarial loss: 0.447064\n",
      "epoch 195; iter: 0; batch classifier loss: 0.047844; batch adversarial loss: 0.412448\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009749; batch adversarial loss: 0.470874\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025469; batch adversarial loss: 0.447481\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024669; batch adversarial loss: 0.369567\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004373; batch adversarial loss: 0.522635\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710572; batch adversarial loss: 0.866420\n",
      "epoch 1; iter: 0; batch classifier loss: 0.551779; batch adversarial loss: 0.827277\n",
      "epoch 2; iter: 0; batch classifier loss: 0.841404; batch adversarial loss: 0.843731\n",
      "epoch 3; iter: 0; batch classifier loss: 0.855109; batch adversarial loss: 0.752895\n",
      "epoch 4; iter: 0; batch classifier loss: 0.886221; batch adversarial loss: 0.689881\n",
      "epoch 5; iter: 0; batch classifier loss: 0.637841; batch adversarial loss: 0.626370\n",
      "epoch 6; iter: 0; batch classifier loss: 0.442621; batch adversarial loss: 0.592801\n",
      "epoch 7; iter: 0; batch classifier loss: 0.329089; batch adversarial loss: 0.561305\n",
      "epoch 8; iter: 0; batch classifier loss: 0.394576; batch adversarial loss: 0.580845\n",
      "epoch 9; iter: 0; batch classifier loss: 0.336373; batch adversarial loss: 0.560142\n",
      "epoch 10; iter: 0; batch classifier loss: 0.383927; batch adversarial loss: 0.515824\n",
      "epoch 11; iter: 0; batch classifier loss: 0.272696; batch adversarial loss: 0.536218\n",
      "epoch 12; iter: 0; batch classifier loss: 0.303055; batch adversarial loss: 0.546711\n",
      "epoch 13; iter: 0; batch classifier loss: 0.245077; batch adversarial loss: 0.519150\n",
      "epoch 14; iter: 0; batch classifier loss: 0.312267; batch adversarial loss: 0.515080\n",
      "epoch 15; iter: 0; batch classifier loss: 0.310510; batch adversarial loss: 0.455732\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281000; batch adversarial loss: 0.543852\n",
      "epoch 17; iter: 0; batch classifier loss: 0.331329; batch adversarial loss: 0.502191\n",
      "epoch 18; iter: 0; batch classifier loss: 0.333331; batch adversarial loss: 0.508173\n",
      "epoch 19; iter: 0; batch classifier loss: 0.260829; batch adversarial loss: 0.514425\n",
      "epoch 20; iter: 0; batch classifier loss: 0.324807; batch adversarial loss: 0.432920\n",
      "epoch 21; iter: 0; batch classifier loss: 0.245540; batch adversarial loss: 0.452864\n",
      "epoch 22; iter: 0; batch classifier loss: 0.340447; batch adversarial loss: 0.508801\n",
      "epoch 23; iter: 0; batch classifier loss: 0.288369; batch adversarial loss: 0.508187\n",
      "epoch 24; iter: 0; batch classifier loss: 0.302763; batch adversarial loss: 0.437148\n",
      "epoch 25; iter: 0; batch classifier loss: 0.266238; batch adversarial loss: 0.434935\n",
      "epoch 26; iter: 0; batch classifier loss: 0.292523; batch adversarial loss: 0.452218\n",
      "epoch 27; iter: 0; batch classifier loss: 0.349169; batch adversarial loss: 0.406065\n",
      "epoch 28; iter: 0; batch classifier loss: 0.288320; batch adversarial loss: 0.436781\n",
      "epoch 29; iter: 0; batch classifier loss: 0.238538; batch adversarial loss: 0.503537\n",
      "epoch 30; iter: 0; batch classifier loss: 0.256457; batch adversarial loss: 0.480192\n",
      "epoch 31; iter: 0; batch classifier loss: 0.168398; batch adversarial loss: 0.465097\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238029; batch adversarial loss: 0.491446\n",
      "epoch 33; iter: 0; batch classifier loss: 0.203065; batch adversarial loss: 0.457824\n",
      "epoch 34; iter: 0; batch classifier loss: 0.190361; batch adversarial loss: 0.440083\n",
      "epoch 35; iter: 0; batch classifier loss: 0.261290; batch adversarial loss: 0.483159\n",
      "epoch 36; iter: 0; batch classifier loss: 0.213387; batch adversarial loss: 0.538548\n",
      "epoch 37; iter: 0; batch classifier loss: 0.257998; batch adversarial loss: 0.403626\n",
      "epoch 38; iter: 0; batch classifier loss: 0.233932; batch adversarial loss: 0.415140\n",
      "epoch 39; iter: 0; batch classifier loss: 0.151856; batch adversarial loss: 0.483123\n",
      "epoch 40; iter: 0; batch classifier loss: 0.196070; batch adversarial loss: 0.505270\n",
      "epoch 41; iter: 0; batch classifier loss: 0.191097; batch adversarial loss: 0.397268\n",
      "epoch 42; iter: 0; batch classifier loss: 0.191166; batch adversarial loss: 0.494594\n",
      "epoch 43; iter: 0; batch classifier loss: 0.204375; batch adversarial loss: 0.445058\n",
      "epoch 44; iter: 0; batch classifier loss: 0.227376; batch adversarial loss: 0.428077\n",
      "epoch 45; iter: 0; batch classifier loss: 0.152724; batch adversarial loss: 0.483897\n",
      "epoch 46; iter: 0; batch classifier loss: 0.134930; batch adversarial loss: 0.474356\n",
      "epoch 47; iter: 0; batch classifier loss: 0.176003; batch adversarial loss: 0.506620\n",
      "epoch 48; iter: 0; batch classifier loss: 0.141996; batch adversarial loss: 0.518648\n",
      "epoch 49; iter: 0; batch classifier loss: 0.206169; batch adversarial loss: 0.435132\n",
      "epoch 50; iter: 0; batch classifier loss: 0.216969; batch adversarial loss: 0.447987\n",
      "epoch 51; iter: 0; batch classifier loss: 0.179208; batch adversarial loss: 0.507731\n",
      "epoch 52; iter: 0; batch classifier loss: 0.153485; batch adversarial loss: 0.420960\n",
      "epoch 53; iter: 0; batch classifier loss: 0.141051; batch adversarial loss: 0.423621\n",
      "epoch 54; iter: 0; batch classifier loss: 0.141843; batch adversarial loss: 0.505921\n",
      "epoch 55; iter: 0; batch classifier loss: 0.146370; batch adversarial loss: 0.457883\n",
      "epoch 56; iter: 0; batch classifier loss: 0.143411; batch adversarial loss: 0.371091\n",
      "epoch 57; iter: 0; batch classifier loss: 0.190795; batch adversarial loss: 0.409987\n",
      "epoch 58; iter: 0; batch classifier loss: 0.201359; batch adversarial loss: 0.384246\n",
      "epoch 59; iter: 0; batch classifier loss: 0.130851; batch adversarial loss: 0.519029\n",
      "epoch 60; iter: 0; batch classifier loss: 0.116804; batch adversarial loss: 0.396628\n",
      "epoch 61; iter: 0; batch classifier loss: 0.109576; batch adversarial loss: 0.420810\n",
      "epoch 62; iter: 0; batch classifier loss: 0.156248; batch adversarial loss: 0.470864\n",
      "epoch 63; iter: 0; batch classifier loss: 0.132452; batch adversarial loss: 0.522384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.125191; batch adversarial loss: 0.546731\n",
      "epoch 65; iter: 0; batch classifier loss: 0.190322; batch adversarial loss: 0.408151\n",
      "epoch 66; iter: 0; batch classifier loss: 0.118134; batch adversarial loss: 0.421597\n",
      "epoch 67; iter: 0; batch classifier loss: 0.132206; batch adversarial loss: 0.610355\n",
      "epoch 68; iter: 0; batch classifier loss: 0.122001; batch adversarial loss: 0.432880\n",
      "epoch 69; iter: 0; batch classifier loss: 0.141103; batch adversarial loss: 0.396385\n",
      "epoch 70; iter: 0; batch classifier loss: 0.207283; batch adversarial loss: 0.471838\n",
      "epoch 71; iter: 0; batch classifier loss: 0.124184; batch adversarial loss: 0.509147\n",
      "epoch 72; iter: 0; batch classifier loss: 0.179404; batch adversarial loss: 0.509614\n",
      "epoch 73; iter: 0; batch classifier loss: 0.127221; batch adversarial loss: 0.421244\n",
      "epoch 74; iter: 0; batch classifier loss: 0.099880; batch adversarial loss: 0.433472\n",
      "epoch 75; iter: 0; batch classifier loss: 0.135728; batch adversarial loss: 0.458743\n",
      "epoch 76; iter: 0; batch classifier loss: 0.143893; batch adversarial loss: 0.459775\n",
      "epoch 77; iter: 0; batch classifier loss: 0.141120; batch adversarial loss: 0.370104\n",
      "epoch 78; iter: 0; batch classifier loss: 0.098697; batch adversarial loss: 0.421285\n",
      "epoch 79; iter: 0; batch classifier loss: 0.109890; batch adversarial loss: 0.483948\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088585; batch adversarial loss: 0.395337\n",
      "epoch 81; iter: 0; batch classifier loss: 0.145664; batch adversarial loss: 0.435382\n",
      "epoch 82; iter: 0; batch classifier loss: 0.099887; batch adversarial loss: 0.344754\n",
      "epoch 83; iter: 0; batch classifier loss: 0.100786; batch adversarial loss: 0.473050\n",
      "epoch 84; iter: 0; batch classifier loss: 0.090363; batch adversarial loss: 0.474303\n",
      "epoch 85; iter: 0; batch classifier loss: 0.202136; batch adversarial loss: 0.405634\n",
      "epoch 86; iter: 0; batch classifier loss: 0.142069; batch adversarial loss: 0.357965\n",
      "epoch 87; iter: 0; batch classifier loss: 0.131795; batch adversarial loss: 0.522338\n",
      "epoch 88; iter: 0; batch classifier loss: 0.115528; batch adversarial loss: 0.473593\n",
      "epoch 89; iter: 0; batch classifier loss: 0.107703; batch adversarial loss: 0.335170\n",
      "epoch 90; iter: 0; batch classifier loss: 0.126141; batch adversarial loss: 0.435419\n",
      "epoch 91; iter: 0; batch classifier loss: 0.098915; batch adversarial loss: 0.442248\n",
      "epoch 92; iter: 0; batch classifier loss: 0.080926; batch adversarial loss: 0.382640\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078979; batch adversarial loss: 0.429173\n",
      "epoch 94; iter: 0; batch classifier loss: 0.097016; batch adversarial loss: 0.444393\n",
      "epoch 95; iter: 0; batch classifier loss: 0.108119; batch adversarial loss: 0.536321\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055977; batch adversarial loss: 0.497737\n",
      "epoch 97; iter: 0; batch classifier loss: 0.109882; batch adversarial loss: 0.372287\n",
      "epoch 98; iter: 0; batch classifier loss: 0.082251; batch adversarial loss: 0.443373\n",
      "epoch 99; iter: 0; batch classifier loss: 0.131982; batch adversarial loss: 0.429037\n",
      "epoch 100; iter: 0; batch classifier loss: 0.080804; batch adversarial loss: 0.409459\n",
      "epoch 101; iter: 0; batch classifier loss: 0.091015; batch adversarial loss: 0.469900\n",
      "epoch 102; iter: 0; batch classifier loss: 0.074577; batch adversarial loss: 0.329490\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059676; batch adversarial loss: 0.432931\n",
      "epoch 104; iter: 0; batch classifier loss: 0.077965; batch adversarial loss: 0.448895\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044338; batch adversarial loss: 0.453851\n",
      "epoch 106; iter: 0; batch classifier loss: 0.078037; batch adversarial loss: 0.459362\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072729; batch adversarial loss: 0.428957\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059740; batch adversarial loss: 0.547765\n",
      "epoch 109; iter: 0; batch classifier loss: 0.087626; batch adversarial loss: 0.394788\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037837; batch adversarial loss: 0.387410\n",
      "epoch 111; iter: 0; batch classifier loss: 0.077635; batch adversarial loss: 0.419192\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047573; batch adversarial loss: 0.390107\n",
      "epoch 113; iter: 0; batch classifier loss: 0.087569; batch adversarial loss: 0.428675\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054799; batch adversarial loss: 0.410495\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059071; batch adversarial loss: 0.456767\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048987; batch adversarial loss: 0.453594\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033797; batch adversarial loss: 0.463752\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069239; batch adversarial loss: 0.445738\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047708; batch adversarial loss: 0.522214\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032557; batch adversarial loss: 0.517632\n",
      "epoch 121; iter: 0; batch classifier loss: 0.070788; batch adversarial loss: 0.392652\n",
      "epoch 122; iter: 0; batch classifier loss: 0.065918; batch adversarial loss: 0.464124\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014342; batch adversarial loss: 0.518507\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025410; batch adversarial loss: 0.433643\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042319; batch adversarial loss: 0.405747\n",
      "epoch 126; iter: 0; batch classifier loss: 0.058162; batch adversarial loss: 0.567714\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030244; batch adversarial loss: 0.428009\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042000; batch adversarial loss: 0.487480\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025327; batch adversarial loss: 0.475751\n",
      "epoch 130; iter: 0; batch classifier loss: 0.086322; batch adversarial loss: 0.397738\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031514; batch adversarial loss: 0.413959\n",
      "epoch 132; iter: 0; batch classifier loss: 0.013155; batch adversarial loss: 0.337134\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042226; batch adversarial loss: 0.480353\n",
      "epoch 134; iter: 0; batch classifier loss: 0.017504; batch adversarial loss: 0.337717\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024790; batch adversarial loss: 0.431108\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031137; batch adversarial loss: 0.415063\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028489; batch adversarial loss: 0.510399\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025758; batch adversarial loss: 0.453615\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032078; batch adversarial loss: 0.382723\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031645; batch adversarial loss: 0.426102\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033960; batch adversarial loss: 0.405037\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022398; batch adversarial loss: 0.454751\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016497; batch adversarial loss: 0.476359\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026209; batch adversarial loss: 0.417878\n",
      "epoch 145; iter: 0; batch classifier loss: 0.047969; batch adversarial loss: 0.336447\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018170; batch adversarial loss: 0.437536\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015520; batch adversarial loss: 0.418703\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017419; batch adversarial loss: 0.365503\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026061; batch adversarial loss: 0.416083\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031158; batch adversarial loss: 0.499379\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026761; batch adversarial loss: 0.454135\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032235; batch adversarial loss: 0.416735\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031766; batch adversarial loss: 0.433416\n",
      "epoch 154; iter: 0; batch classifier loss: 0.051501; batch adversarial loss: 0.442225\n",
      "epoch 155; iter: 0; batch classifier loss: 0.008187; batch adversarial loss: 0.452719\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013823; batch adversarial loss: 0.403858\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019205; batch adversarial loss: 0.466276\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016514; batch adversarial loss: 0.490669\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015824; batch adversarial loss: 0.497628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.010775; batch adversarial loss: 0.495572\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007244; batch adversarial loss: 0.427892\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010612; batch adversarial loss: 0.499471\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015191; batch adversarial loss: 0.478166\n",
      "epoch 164; iter: 0; batch classifier loss: 0.008255; batch adversarial loss: 0.434064\n",
      "epoch 165; iter: 0; batch classifier loss: 0.004231; batch adversarial loss: 0.480295\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027580; batch adversarial loss: 0.490593\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014493; batch adversarial loss: 0.448849\n",
      "epoch 168; iter: 0; batch classifier loss: 0.006041; batch adversarial loss: 0.498604\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026148; batch adversarial loss: 0.362525\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016035; batch adversarial loss: 0.457718\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020789; batch adversarial loss: 0.373304\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013068; batch adversarial loss: 0.464700\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012538; batch adversarial loss: 0.493701\n",
      "epoch 174; iter: 0; batch classifier loss: 0.004534; batch adversarial loss: 0.530174\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032927; batch adversarial loss: 0.441270\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011919; batch adversarial loss: 0.454732\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020921; batch adversarial loss: 0.469654\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022230; batch adversarial loss: 0.498393\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031719; batch adversarial loss: 0.500083\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034050; batch adversarial loss: 0.407655\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027053; batch adversarial loss: 0.468237\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042569; batch adversarial loss: 0.369841\n",
      "epoch 183; iter: 0; batch classifier loss: 0.038910; batch adversarial loss: 0.484900\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008870; batch adversarial loss: 0.455021\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010631; batch adversarial loss: 0.440390\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005381; batch adversarial loss: 0.500613\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023824; batch adversarial loss: 0.473238\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010540; batch adversarial loss: 0.409197\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008736; batch adversarial loss: 0.405990\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022358; batch adversarial loss: 0.544415\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014264; batch adversarial loss: 0.368960\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020805; batch adversarial loss: 0.359964\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015121; batch adversarial loss: 0.586939\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014937; batch adversarial loss: 0.441749\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009407; batch adversarial loss: 0.494020\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007337; batch adversarial loss: 0.507751\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020805; batch adversarial loss: 0.479905\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005984; batch adversarial loss: 0.463896\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011693; batch adversarial loss: 0.510617\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719395; batch adversarial loss: 0.593681\n",
      "epoch 1; iter: 0; batch classifier loss: 0.452003; batch adversarial loss: 0.620173\n",
      "epoch 2; iter: 0; batch classifier loss: 0.424960; batch adversarial loss: 0.582070\n",
      "epoch 3; iter: 0; batch classifier loss: 0.365583; batch adversarial loss: 0.542436\n",
      "epoch 4; iter: 0; batch classifier loss: 0.239215; batch adversarial loss: 0.594576\n",
      "epoch 5; iter: 0; batch classifier loss: 0.287760; batch adversarial loss: 0.506683\n",
      "epoch 6; iter: 0; batch classifier loss: 0.246913; batch adversarial loss: 0.511750\n",
      "epoch 7; iter: 0; batch classifier loss: 0.266320; batch adversarial loss: 0.598456\n",
      "epoch 8; iter: 0; batch classifier loss: 0.270759; batch adversarial loss: 0.473243\n",
      "epoch 9; iter: 0; batch classifier loss: 0.217567; batch adversarial loss: 0.541392\n",
      "epoch 10; iter: 0; batch classifier loss: 0.224232; batch adversarial loss: 0.573045\n",
      "epoch 11; iter: 0; batch classifier loss: 0.284314; batch adversarial loss: 0.531407\n",
      "epoch 12; iter: 0; batch classifier loss: 0.253389; batch adversarial loss: 0.559505\n",
      "epoch 13; iter: 0; batch classifier loss: 0.355682; batch adversarial loss: 0.477268\n",
      "epoch 14; iter: 0; batch classifier loss: 0.234692; batch adversarial loss: 0.521012\n",
      "epoch 15; iter: 0; batch classifier loss: 0.289098; batch adversarial loss: 0.595548\n",
      "epoch 16; iter: 0; batch classifier loss: 0.234242; batch adversarial loss: 0.438492\n",
      "epoch 17; iter: 0; batch classifier loss: 0.271894; batch adversarial loss: 0.503902\n",
      "epoch 18; iter: 0; batch classifier loss: 0.224006; batch adversarial loss: 0.464427\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223834; batch adversarial loss: 0.521725\n",
      "epoch 20; iter: 0; batch classifier loss: 0.295491; batch adversarial loss: 0.440516\n",
      "epoch 21; iter: 0; batch classifier loss: 0.454843; batch adversarial loss: 0.514738\n",
      "epoch 22; iter: 0; batch classifier loss: 0.404685; batch adversarial loss: 0.534592\n",
      "epoch 23; iter: 0; batch classifier loss: 0.259874; batch adversarial loss: 0.559918\n",
      "epoch 24; iter: 0; batch classifier loss: 0.213459; batch adversarial loss: 0.356610\n",
      "epoch 25; iter: 0; batch classifier loss: 0.160662; batch adversarial loss: 0.443717\n",
      "epoch 26; iter: 0; batch classifier loss: 0.159866; batch adversarial loss: 0.475267\n",
      "epoch 27; iter: 0; batch classifier loss: 0.093812; batch adversarial loss: 0.616319\n",
      "epoch 28; iter: 0; batch classifier loss: 0.169008; batch adversarial loss: 0.439718\n",
      "epoch 29; iter: 0; batch classifier loss: 0.111791; batch adversarial loss: 0.449064\n",
      "epoch 30; iter: 0; batch classifier loss: 0.131950; batch adversarial loss: 0.483332\n",
      "epoch 31; iter: 0; batch classifier loss: 0.119213; batch adversarial loss: 0.485506\n",
      "epoch 32; iter: 0; batch classifier loss: 0.118326; batch adversarial loss: 0.477362\n",
      "epoch 33; iter: 0; batch classifier loss: 0.129113; batch adversarial loss: 0.449289\n",
      "epoch 34; iter: 0; batch classifier loss: 0.096845; batch adversarial loss: 0.461994\n",
      "epoch 35; iter: 0; batch classifier loss: 0.178246; batch adversarial loss: 0.434836\n",
      "epoch 36; iter: 0; batch classifier loss: 0.088214; batch adversarial loss: 0.375902\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110406; batch adversarial loss: 0.407001\n",
      "epoch 38; iter: 0; batch classifier loss: 0.070297; batch adversarial loss: 0.550198\n",
      "epoch 39; iter: 0; batch classifier loss: 0.121958; batch adversarial loss: 0.429219\n",
      "epoch 40; iter: 0; batch classifier loss: 0.117726; batch adversarial loss: 0.411670\n",
      "epoch 41; iter: 0; batch classifier loss: 0.084463; batch adversarial loss: 0.413807\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103205; batch adversarial loss: 0.401098\n",
      "epoch 43; iter: 0; batch classifier loss: 0.069737; batch adversarial loss: 0.463406\n",
      "epoch 44; iter: 0; batch classifier loss: 0.052921; batch adversarial loss: 0.470952\n",
      "epoch 45; iter: 0; batch classifier loss: 0.085548; batch adversarial loss: 0.488117\n",
      "epoch 46; iter: 0; batch classifier loss: 0.079335; batch adversarial loss: 0.494233\n",
      "epoch 47; iter: 0; batch classifier loss: 0.101344; batch adversarial loss: 0.492818\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100240; batch adversarial loss: 0.376486\n",
      "epoch 49; iter: 0; batch classifier loss: 0.049795; batch adversarial loss: 0.501235\n",
      "epoch 50; iter: 0; batch classifier loss: 0.106036; batch adversarial loss: 0.575471\n",
      "epoch 51; iter: 0; batch classifier loss: 0.077660; batch adversarial loss: 0.475107\n",
      "epoch 52; iter: 0; batch classifier loss: 0.078843; batch adversarial loss: 0.410760\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122457; batch adversarial loss: 0.489086\n",
      "epoch 54; iter: 0; batch classifier loss: 0.072174; batch adversarial loss: 0.593063\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084714; batch adversarial loss: 0.395319\n",
      "epoch 56; iter: 0; batch classifier loss: 0.050093; batch adversarial loss: 0.374818\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073909; batch adversarial loss: 0.571129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.098952; batch adversarial loss: 0.493170\n",
      "epoch 59; iter: 0; batch classifier loss: 0.104617; batch adversarial loss: 0.370845\n",
      "epoch 60; iter: 0; batch classifier loss: 0.057935; batch adversarial loss: 0.418061\n",
      "epoch 61; iter: 0; batch classifier loss: 0.059150; batch adversarial loss: 0.364091\n",
      "epoch 62; iter: 0; batch classifier loss: 0.125455; batch adversarial loss: 0.411977\n",
      "epoch 63; iter: 0; batch classifier loss: 0.048834; batch adversarial loss: 0.522433\n",
      "epoch 64; iter: 0; batch classifier loss: 0.055941; batch adversarial loss: 0.361548\n",
      "epoch 65; iter: 0; batch classifier loss: 0.100696; batch adversarial loss: 0.447118\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068156; batch adversarial loss: 0.405349\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069680; batch adversarial loss: 0.431566\n",
      "epoch 68; iter: 0; batch classifier loss: 0.086192; batch adversarial loss: 0.463015\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065965; batch adversarial loss: 0.479655\n",
      "epoch 70; iter: 0; batch classifier loss: 0.138316; batch adversarial loss: 0.487259\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078376; batch adversarial loss: 0.414559\n",
      "epoch 72; iter: 0; batch classifier loss: 0.056080; batch adversarial loss: 0.450278\n",
      "epoch 73; iter: 0; batch classifier loss: 0.044747; batch adversarial loss: 0.424240\n",
      "epoch 74; iter: 0; batch classifier loss: 0.085276; batch adversarial loss: 0.429154\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069106; batch adversarial loss: 0.432482\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060977; batch adversarial loss: 0.460300\n",
      "epoch 77; iter: 0; batch classifier loss: 0.060876; batch adversarial loss: 0.480653\n",
      "epoch 78; iter: 0; batch classifier loss: 0.124173; batch adversarial loss: 0.492111\n",
      "epoch 79; iter: 0; batch classifier loss: 0.054498; batch adversarial loss: 0.559345\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054435; batch adversarial loss: 0.446944\n",
      "epoch 81; iter: 0; batch classifier loss: 0.109622; batch adversarial loss: 0.459321\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083760; batch adversarial loss: 0.465978\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071546; batch adversarial loss: 0.334067\n",
      "epoch 84; iter: 0; batch classifier loss: 0.061698; batch adversarial loss: 0.410813\n",
      "epoch 85; iter: 0; batch classifier loss: 0.066800; batch adversarial loss: 0.449809\n",
      "epoch 86; iter: 0; batch classifier loss: 0.033186; batch adversarial loss: 0.440329\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068386; batch adversarial loss: 0.498257\n",
      "epoch 88; iter: 0; batch classifier loss: 0.126309; batch adversarial loss: 0.412596\n",
      "epoch 89; iter: 0; batch classifier loss: 0.046283; batch adversarial loss: 0.518337\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050179; batch adversarial loss: 0.518306\n",
      "epoch 91; iter: 0; batch classifier loss: 0.040912; batch adversarial loss: 0.417758\n",
      "epoch 92; iter: 0; batch classifier loss: 0.045050; batch adversarial loss: 0.384234\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053726; batch adversarial loss: 0.392987\n",
      "epoch 94; iter: 0; batch classifier loss: 0.095144; batch adversarial loss: 0.436261\n",
      "epoch 95; iter: 0; batch classifier loss: 0.049847; batch adversarial loss: 0.444924\n",
      "epoch 96; iter: 0; batch classifier loss: 0.031172; batch adversarial loss: 0.439901\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054791; batch adversarial loss: 0.436516\n",
      "epoch 98; iter: 0; batch classifier loss: 0.029654; batch adversarial loss: 0.401125\n",
      "epoch 99; iter: 0; batch classifier loss: 0.085562; batch adversarial loss: 0.347323\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046507; batch adversarial loss: 0.477864\n",
      "epoch 101; iter: 0; batch classifier loss: 0.024201; batch adversarial loss: 0.560272\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056673; batch adversarial loss: 0.362626\n",
      "epoch 103; iter: 0; batch classifier loss: 0.031054; batch adversarial loss: 0.511422\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059877; batch adversarial loss: 0.489404\n",
      "epoch 105; iter: 0; batch classifier loss: 0.072912; batch adversarial loss: 0.382397\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040147; batch adversarial loss: 0.386287\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049414; batch adversarial loss: 0.462891\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041277; batch adversarial loss: 0.522345\n",
      "epoch 109; iter: 0; batch classifier loss: 0.031997; batch adversarial loss: 0.520199\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038267; batch adversarial loss: 0.469222\n",
      "epoch 111; iter: 0; batch classifier loss: 0.067855; batch adversarial loss: 0.471168\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051412; batch adversarial loss: 0.403039\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035458; batch adversarial loss: 0.494967\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029689; batch adversarial loss: 0.481339\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028442; batch adversarial loss: 0.522081\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028141; batch adversarial loss: 0.473223\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046961; batch adversarial loss: 0.419510\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033723; batch adversarial loss: 0.490239\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031916; batch adversarial loss: 0.422182\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035666; batch adversarial loss: 0.425721\n",
      "epoch 121; iter: 0; batch classifier loss: 0.068223; batch adversarial loss: 0.528307\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036747; batch adversarial loss: 0.357105\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040368; batch adversarial loss: 0.438664\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041179; batch adversarial loss: 0.493602\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033088; batch adversarial loss: 0.462951\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063405; batch adversarial loss: 0.420081\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022438; batch adversarial loss: 0.414253\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024800; batch adversarial loss: 0.444762\n",
      "epoch 129; iter: 0; batch classifier loss: 0.044113; batch adversarial loss: 0.530970\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023392; batch adversarial loss: 0.515603\n",
      "epoch 131; iter: 0; batch classifier loss: 0.010554; batch adversarial loss: 0.485013\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020859; batch adversarial loss: 0.342168\n",
      "epoch 133; iter: 0; batch classifier loss: 0.066470; batch adversarial loss: 0.445920\n",
      "epoch 134; iter: 0; batch classifier loss: 0.071257; batch adversarial loss: 0.463972\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028286; batch adversarial loss: 0.502045\n",
      "epoch 136; iter: 0; batch classifier loss: 0.045915; batch adversarial loss: 0.457580\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039836; batch adversarial loss: 0.451827\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037483; batch adversarial loss: 0.616665\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033685; batch adversarial loss: 0.414070\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033670; batch adversarial loss: 0.489786\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044045; batch adversarial loss: 0.395694\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033858; batch adversarial loss: 0.404678\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032041; batch adversarial loss: 0.458922\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017498; batch adversarial loss: 0.500279\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033188; batch adversarial loss: 0.445610\n",
      "epoch 146; iter: 0; batch classifier loss: 0.007591; batch adversarial loss: 0.468202\n",
      "epoch 147; iter: 0; batch classifier loss: 0.007838; batch adversarial loss: 0.427063\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027681; batch adversarial loss: 0.450252\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017908; batch adversarial loss: 0.539367\n",
      "epoch 150; iter: 0; batch classifier loss: 0.057113; batch adversarial loss: 0.501773\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038157; batch adversarial loss: 0.476196\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025282; batch adversarial loss: 0.468591\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011923; batch adversarial loss: 0.483729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.033306; batch adversarial loss: 0.404108\n",
      "epoch 155; iter: 0; batch classifier loss: 0.055057; batch adversarial loss: 0.546144\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050000; batch adversarial loss: 0.453379\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027169; batch adversarial loss: 0.495337\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015284; batch adversarial loss: 0.599331\n",
      "epoch 159; iter: 0; batch classifier loss: 0.053764; batch adversarial loss: 0.497382\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037732; batch adversarial loss: 0.468357\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024456; batch adversarial loss: 0.463745\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024919; batch adversarial loss: 0.529063\n",
      "epoch 163; iter: 0; batch classifier loss: 0.054702; batch adversarial loss: 0.361550\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013076; batch adversarial loss: 0.529030\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016361; batch adversarial loss: 0.363211\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024676; batch adversarial loss: 0.430610\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008298; batch adversarial loss: 0.374773\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017714; batch adversarial loss: 0.474722\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018084; batch adversarial loss: 0.429386\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031398; batch adversarial loss: 0.443937\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014093; batch adversarial loss: 0.377364\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020846; batch adversarial loss: 0.461948\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018353; batch adversarial loss: 0.423986\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019596; batch adversarial loss: 0.531275\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026269; batch adversarial loss: 0.412894\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031553; batch adversarial loss: 0.383310\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022246; batch adversarial loss: 0.449022\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024507; batch adversarial loss: 0.382533\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033824; batch adversarial loss: 0.494550\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018449; batch adversarial loss: 0.512141\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030274; batch adversarial loss: 0.394511\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028397; batch adversarial loss: 0.457787\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025462; batch adversarial loss: 0.463508\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031385; batch adversarial loss: 0.470633\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015894; batch adversarial loss: 0.402138\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009651; batch adversarial loss: 0.484576\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005119; batch adversarial loss: 0.450084\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013966; batch adversarial loss: 0.452997\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033094; batch adversarial loss: 0.467442\n",
      "epoch 190; iter: 0; batch classifier loss: 0.038324; batch adversarial loss: 0.455814\n",
      "epoch 191; iter: 0; batch classifier loss: 0.078085; batch adversarial loss: 0.435978\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010524; batch adversarial loss: 0.460585\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019497; batch adversarial loss: 0.464921\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008271; batch adversarial loss: 0.500674\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016717; batch adversarial loss: 0.504031\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030724; batch adversarial loss: 0.381120\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011977; batch adversarial loss: 0.498246\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020603; batch adversarial loss: 0.398980\n",
      "epoch 199; iter: 0; batch classifier loss: 0.043857; batch adversarial loss: 0.465753\n",
      "epoch 0; iter: 0; batch classifier loss: 0.732716; batch adversarial loss: 0.526559\n",
      "epoch 1; iter: 0; batch classifier loss: 0.422797; batch adversarial loss: 0.624347\n",
      "epoch 2; iter: 0; batch classifier loss: 0.340053; batch adversarial loss: 0.636883\n",
      "epoch 3; iter: 0; batch classifier loss: 0.442193; batch adversarial loss: 0.590219\n",
      "epoch 4; iter: 0; batch classifier loss: 0.300723; batch adversarial loss: 0.536368\n",
      "epoch 5; iter: 0; batch classifier loss: 0.392778; batch adversarial loss: 0.591812\n",
      "epoch 6; iter: 0; batch classifier loss: 0.304308; batch adversarial loss: 0.486701\n",
      "epoch 7; iter: 0; batch classifier loss: 0.331612; batch adversarial loss: 0.600458\n",
      "epoch 8; iter: 0; batch classifier loss: 0.356646; batch adversarial loss: 0.553412\n",
      "epoch 9; iter: 0; batch classifier loss: 0.404675; batch adversarial loss: 0.552364\n",
      "epoch 10; iter: 0; batch classifier loss: 0.437935; batch adversarial loss: 0.587915\n",
      "epoch 11; iter: 0; batch classifier loss: 0.516051; batch adversarial loss: 0.539332\n",
      "epoch 12; iter: 0; batch classifier loss: 0.434218; batch adversarial loss: 0.525780\n",
      "epoch 13; iter: 0; batch classifier loss: 0.603657; batch adversarial loss: 0.471243\n",
      "epoch 14; iter: 0; batch classifier loss: 0.381689; batch adversarial loss: 0.549155\n",
      "epoch 15; iter: 0; batch classifier loss: 0.324839; batch adversarial loss: 0.416087\n",
      "epoch 16; iter: 0; batch classifier loss: 0.246951; batch adversarial loss: 0.527547\n",
      "epoch 17; iter: 0; batch classifier loss: 0.225734; batch adversarial loss: 0.530422\n",
      "epoch 18; iter: 0; batch classifier loss: 0.260552; batch adversarial loss: 0.473670\n",
      "epoch 19; iter: 0; batch classifier loss: 0.204700; batch adversarial loss: 0.475307\n",
      "epoch 20; iter: 0; batch classifier loss: 0.251297; batch adversarial loss: 0.467471\n",
      "epoch 21; iter: 0; batch classifier loss: 0.195308; batch adversarial loss: 0.443487\n",
      "epoch 22; iter: 0; batch classifier loss: 0.198467; batch adversarial loss: 0.412722\n",
      "epoch 23; iter: 0; batch classifier loss: 0.154936; batch adversarial loss: 0.432928\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199373; batch adversarial loss: 0.486904\n",
      "epoch 25; iter: 0; batch classifier loss: 0.207134; batch adversarial loss: 0.436897\n",
      "epoch 26; iter: 0; batch classifier loss: 0.157829; batch adversarial loss: 0.463000\n",
      "epoch 27; iter: 0; batch classifier loss: 0.186770; batch adversarial loss: 0.470986\n",
      "epoch 28; iter: 0; batch classifier loss: 0.218030; batch adversarial loss: 0.462947\n",
      "epoch 29; iter: 0; batch classifier loss: 0.172491; batch adversarial loss: 0.432459\n",
      "epoch 30; iter: 0; batch classifier loss: 0.119557; batch adversarial loss: 0.421120\n",
      "epoch 31; iter: 0; batch classifier loss: 0.161548; batch adversarial loss: 0.378387\n",
      "epoch 32; iter: 0; batch classifier loss: 0.103562; batch adversarial loss: 0.475822\n",
      "epoch 33; iter: 0; batch classifier loss: 0.135674; batch adversarial loss: 0.433168\n",
      "epoch 34; iter: 0; batch classifier loss: 0.130220; batch adversarial loss: 0.483945\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140568; batch adversarial loss: 0.496493\n",
      "epoch 36; iter: 0; batch classifier loss: 0.137422; batch adversarial loss: 0.410232\n",
      "epoch 37; iter: 0; batch classifier loss: 0.145379; batch adversarial loss: 0.458433\n",
      "epoch 38; iter: 0; batch classifier loss: 0.134676; batch adversarial loss: 0.435805\n",
      "epoch 39; iter: 0; batch classifier loss: 0.152956; batch adversarial loss: 0.428289\n",
      "epoch 40; iter: 0; batch classifier loss: 0.156248; batch adversarial loss: 0.414379\n",
      "epoch 41; iter: 0; batch classifier loss: 0.115320; batch adversarial loss: 0.515947\n",
      "epoch 42; iter: 0; batch classifier loss: 0.093798; batch adversarial loss: 0.510178\n",
      "epoch 43; iter: 0; batch classifier loss: 0.108569; batch adversarial loss: 0.367670\n",
      "epoch 44; iter: 0; batch classifier loss: 0.164201; batch adversarial loss: 0.399279\n",
      "epoch 45; iter: 0; batch classifier loss: 0.152534; batch adversarial loss: 0.491631\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116708; batch adversarial loss: 0.446452\n",
      "epoch 47; iter: 0; batch classifier loss: 0.099645; batch adversarial loss: 0.424879\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100063; batch adversarial loss: 0.470954\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099404; batch adversarial loss: 0.460475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.114864; batch adversarial loss: 0.411336\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121381; batch adversarial loss: 0.468249\n",
      "epoch 52; iter: 0; batch classifier loss: 0.122171; batch adversarial loss: 0.443654\n",
      "epoch 53; iter: 0; batch classifier loss: 0.085015; batch adversarial loss: 0.401587\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110768; batch adversarial loss: 0.398191\n",
      "epoch 55; iter: 0; batch classifier loss: 0.113532; batch adversarial loss: 0.432891\n",
      "epoch 56; iter: 0; batch classifier loss: 0.187617; batch adversarial loss: 0.494161\n",
      "epoch 57; iter: 0; batch classifier loss: 0.071109; batch adversarial loss: 0.485343\n",
      "epoch 58; iter: 0; batch classifier loss: 0.102973; batch adversarial loss: 0.347047\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083784; batch adversarial loss: 0.437911\n",
      "epoch 60; iter: 0; batch classifier loss: 0.107036; batch adversarial loss: 0.445032\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074311; batch adversarial loss: 0.496745\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080682; batch adversarial loss: 0.522534\n",
      "epoch 63; iter: 0; batch classifier loss: 0.116668; batch adversarial loss: 0.448122\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078060; batch adversarial loss: 0.427114\n",
      "epoch 65; iter: 0; batch classifier loss: 0.119942; batch adversarial loss: 0.426346\n",
      "epoch 66; iter: 0; batch classifier loss: 0.076469; batch adversarial loss: 0.393564\n",
      "epoch 67; iter: 0; batch classifier loss: 0.173852; batch adversarial loss: 0.351947\n",
      "epoch 68; iter: 0; batch classifier loss: 0.116029; batch adversarial loss: 0.372949\n",
      "epoch 69; iter: 0; batch classifier loss: 0.130495; batch adversarial loss: 0.403989\n",
      "epoch 70; iter: 0; batch classifier loss: 0.096188; batch adversarial loss: 0.469940\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064478; batch adversarial loss: 0.465926\n",
      "epoch 72; iter: 0; batch classifier loss: 0.084874; batch adversarial loss: 0.457117\n",
      "epoch 73; iter: 0; batch classifier loss: 0.109486; batch adversarial loss: 0.326525\n",
      "epoch 74; iter: 0; batch classifier loss: 0.106850; batch adversarial loss: 0.460575\n",
      "epoch 75; iter: 0; batch classifier loss: 0.083927; batch adversarial loss: 0.442535\n",
      "epoch 76; iter: 0; batch classifier loss: 0.095222; batch adversarial loss: 0.443160\n",
      "epoch 77; iter: 0; batch classifier loss: 0.123665; batch adversarial loss: 0.395171\n",
      "epoch 78; iter: 0; batch classifier loss: 0.077331; batch adversarial loss: 0.484386\n",
      "epoch 79; iter: 0; batch classifier loss: 0.055254; batch adversarial loss: 0.431735\n",
      "epoch 80; iter: 0; batch classifier loss: 0.071148; batch adversarial loss: 0.422886\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069357; batch adversarial loss: 0.572725\n",
      "epoch 82; iter: 0; batch classifier loss: 0.098564; batch adversarial loss: 0.552369\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080312; batch adversarial loss: 0.384019\n",
      "epoch 84; iter: 0; batch classifier loss: 0.053838; batch adversarial loss: 0.502751\n",
      "epoch 85; iter: 0; batch classifier loss: 0.054977; batch adversarial loss: 0.427627\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061810; batch adversarial loss: 0.516983\n",
      "epoch 87; iter: 0; batch classifier loss: 0.063889; batch adversarial loss: 0.390226\n",
      "epoch 88; iter: 0; batch classifier loss: 0.039338; batch adversarial loss: 0.416326\n",
      "epoch 89; iter: 0; batch classifier loss: 0.078515; batch adversarial loss: 0.509343\n",
      "epoch 90; iter: 0; batch classifier loss: 0.077812; batch adversarial loss: 0.508660\n",
      "epoch 91; iter: 0; batch classifier loss: 0.069707; batch adversarial loss: 0.378067\n",
      "epoch 92; iter: 0; batch classifier loss: 0.099136; batch adversarial loss: 0.453901\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067940; batch adversarial loss: 0.509285\n",
      "epoch 94; iter: 0; batch classifier loss: 0.036807; batch adversarial loss: 0.450910\n",
      "epoch 95; iter: 0; batch classifier loss: 0.062007; batch adversarial loss: 0.470040\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036558; batch adversarial loss: 0.506133\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066026; batch adversarial loss: 0.410121\n",
      "epoch 98; iter: 0; batch classifier loss: 0.096908; batch adversarial loss: 0.455043\n",
      "epoch 99; iter: 0; batch classifier loss: 0.085742; batch adversarial loss: 0.462175\n",
      "epoch 100; iter: 0; batch classifier loss: 0.082268; batch adversarial loss: 0.421564\n",
      "epoch 101; iter: 0; batch classifier loss: 0.079416; batch adversarial loss: 0.557250\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062538; batch adversarial loss: 0.336776\n",
      "epoch 103; iter: 0; batch classifier loss: 0.099871; batch adversarial loss: 0.444883\n",
      "epoch 104; iter: 0; batch classifier loss: 0.105778; batch adversarial loss: 0.505175\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058019; batch adversarial loss: 0.373975\n",
      "epoch 106; iter: 0; batch classifier loss: 0.102249; batch adversarial loss: 0.407976\n",
      "epoch 107; iter: 0; batch classifier loss: 0.107804; batch adversarial loss: 0.430895\n",
      "epoch 108; iter: 0; batch classifier loss: 0.078298; batch adversarial loss: 0.405539\n",
      "epoch 109; iter: 0; batch classifier loss: 0.073248; batch adversarial loss: 0.545814\n",
      "epoch 110; iter: 0; batch classifier loss: 0.065953; batch adversarial loss: 0.496202\n",
      "epoch 111; iter: 0; batch classifier loss: 0.078122; batch adversarial loss: 0.487177\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075043; batch adversarial loss: 0.473563\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037051; batch adversarial loss: 0.390151\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054820; batch adversarial loss: 0.425193\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024664; batch adversarial loss: 0.482981\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033872; batch adversarial loss: 0.492777\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031893; batch adversarial loss: 0.436974\n",
      "epoch 118; iter: 0; batch classifier loss: 0.085319; batch adversarial loss: 0.464626\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044453; batch adversarial loss: 0.408258\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049959; batch adversarial loss: 0.489739\n",
      "epoch 121; iter: 0; batch classifier loss: 0.097180; batch adversarial loss: 0.379594\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066186; batch adversarial loss: 0.442468\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057891; batch adversarial loss: 0.384407\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019045; batch adversarial loss: 0.348098\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043121; batch adversarial loss: 0.395148\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031153; batch adversarial loss: 0.486817\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034840; batch adversarial loss: 0.355359\n",
      "epoch 128; iter: 0; batch classifier loss: 0.046239; batch adversarial loss: 0.447160\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022638; batch adversarial loss: 0.392133\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037091; batch adversarial loss: 0.533221\n",
      "epoch 131; iter: 0; batch classifier loss: 0.053604; batch adversarial loss: 0.370335\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023174; batch adversarial loss: 0.385637\n",
      "epoch 133; iter: 0; batch classifier loss: 0.047332; batch adversarial loss: 0.441406\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049392; batch adversarial loss: 0.503316\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029369; batch adversarial loss: 0.358571\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025642; batch adversarial loss: 0.333546\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018116; batch adversarial loss: 0.399388\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040692; batch adversarial loss: 0.358640\n",
      "epoch 139; iter: 0; batch classifier loss: 0.064619; batch adversarial loss: 0.426691\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031883; batch adversarial loss: 0.451312\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032341; batch adversarial loss: 0.414407\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044428; batch adversarial loss: 0.450584\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043449; batch adversarial loss: 0.404269\n",
      "epoch 144; iter: 0; batch classifier loss: 0.038950; batch adversarial loss: 0.395265\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021732; batch adversarial loss: 0.472495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.019342; batch adversarial loss: 0.493180\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039583; batch adversarial loss: 0.429418\n",
      "epoch 148; iter: 0; batch classifier loss: 0.051304; batch adversarial loss: 0.417902\n",
      "epoch 149; iter: 0; batch classifier loss: 0.042646; batch adversarial loss: 0.444991\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028643; batch adversarial loss: 0.456566\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026523; batch adversarial loss: 0.409304\n",
      "epoch 152; iter: 0; batch classifier loss: 0.053817; batch adversarial loss: 0.405737\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019806; batch adversarial loss: 0.368346\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035092; batch adversarial loss: 0.432385\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025918; batch adversarial loss: 0.399188\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042610; batch adversarial loss: 0.432394\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042855; batch adversarial loss: 0.501025\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033318; batch adversarial loss: 0.452018\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023294; batch adversarial loss: 0.414354\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032286; batch adversarial loss: 0.434288\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038674; batch adversarial loss: 0.493192\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022414; batch adversarial loss: 0.355550\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015547; batch adversarial loss: 0.526886\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034195; batch adversarial loss: 0.462362\n",
      "epoch 165; iter: 0; batch classifier loss: 0.039574; batch adversarial loss: 0.433537\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026329; batch adversarial loss: 0.414519\n",
      "epoch 167; iter: 0; batch classifier loss: 0.027706; batch adversarial loss: 0.504839\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023760; batch adversarial loss: 0.520691\n",
      "epoch 169; iter: 0; batch classifier loss: 0.060871; batch adversarial loss: 0.472340\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011563; batch adversarial loss: 0.348447\n",
      "epoch 171; iter: 0; batch classifier loss: 0.053327; batch adversarial loss: 0.396436\n",
      "epoch 172; iter: 0; batch classifier loss: 0.046001; batch adversarial loss: 0.427619\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028487; batch adversarial loss: 0.481663\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032627; batch adversarial loss: 0.472113\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038798; batch adversarial loss: 0.534238\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008530; batch adversarial loss: 0.378398\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025221; batch adversarial loss: 0.414392\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035447; batch adversarial loss: 0.352742\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031337; batch adversarial loss: 0.377960\n",
      "epoch 180; iter: 0; batch classifier loss: 0.065976; batch adversarial loss: 0.443969\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035796; batch adversarial loss: 0.419890\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009067; batch adversarial loss: 0.479335\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010732; batch adversarial loss: 0.490524\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038655; batch adversarial loss: 0.453837\n",
      "epoch 185; iter: 0; batch classifier loss: 0.063683; batch adversarial loss: 0.491211\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026484; batch adversarial loss: 0.437621\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042513; batch adversarial loss: 0.375560\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031851; batch adversarial loss: 0.420463\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014361; batch adversarial loss: 0.398779\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011539; batch adversarial loss: 0.445293\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010363; batch adversarial loss: 0.410024\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018935; batch adversarial loss: 0.435907\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035479; batch adversarial loss: 0.350620\n",
      "epoch 194; iter: 0; batch classifier loss: 0.051108; batch adversarial loss: 0.492013\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016653; batch adversarial loss: 0.432036\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030456; batch adversarial loss: 0.415487\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019022; batch adversarial loss: 0.368013\n",
      "epoch 198; iter: 0; batch classifier loss: 0.039612; batch adversarial loss: 0.505253\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032882; batch adversarial loss: 0.348135\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710040; batch adversarial loss: 0.846025\n",
      "epoch 1; iter: 0; batch classifier loss: 0.385284; batch adversarial loss: 0.907933\n",
      "epoch 2; iter: 0; batch classifier loss: 0.457111; batch adversarial loss: 0.882821\n",
      "epoch 3; iter: 0; batch classifier loss: 0.410112; batch adversarial loss: 0.764241\n",
      "epoch 4; iter: 0; batch classifier loss: 0.423499; batch adversarial loss: 0.805541\n",
      "epoch 5; iter: 0; batch classifier loss: 0.381055; batch adversarial loss: 0.740846\n",
      "epoch 6; iter: 0; batch classifier loss: 0.280946; batch adversarial loss: 0.707387\n",
      "epoch 7; iter: 0; batch classifier loss: 0.363001; batch adversarial loss: 0.678685\n",
      "epoch 8; iter: 0; batch classifier loss: 0.309613; batch adversarial loss: 0.661524\n",
      "epoch 9; iter: 0; batch classifier loss: 0.278059; batch adversarial loss: 0.609553\n",
      "epoch 10; iter: 0; batch classifier loss: 0.246754; batch adversarial loss: 0.645188\n",
      "epoch 11; iter: 0; batch classifier loss: 0.302796; batch adversarial loss: 0.563830\n",
      "epoch 12; iter: 0; batch classifier loss: 0.248840; batch adversarial loss: 0.543066\n",
      "epoch 13; iter: 0; batch classifier loss: 0.240725; batch adversarial loss: 0.512244\n",
      "epoch 14; iter: 0; batch classifier loss: 0.250508; batch adversarial loss: 0.516255\n",
      "epoch 15; iter: 0; batch classifier loss: 0.212621; batch adversarial loss: 0.548462\n",
      "epoch 16; iter: 0; batch classifier loss: 0.287950; batch adversarial loss: 0.445054\n",
      "epoch 17; iter: 0; batch classifier loss: 0.257893; batch adversarial loss: 0.477346\n",
      "epoch 18; iter: 0; batch classifier loss: 0.213528; batch adversarial loss: 0.501034\n",
      "epoch 19; iter: 0; batch classifier loss: 0.221601; batch adversarial loss: 0.457772\n",
      "epoch 20; iter: 0; batch classifier loss: 0.205559; batch adversarial loss: 0.447024\n",
      "epoch 21; iter: 0; batch classifier loss: 0.222055; batch adversarial loss: 0.441786\n",
      "epoch 22; iter: 0; batch classifier loss: 0.178488; batch adversarial loss: 0.490328\n",
      "epoch 23; iter: 0; batch classifier loss: 0.220913; batch adversarial loss: 0.359135\n",
      "epoch 24; iter: 0; batch classifier loss: 0.141618; batch adversarial loss: 0.535582\n",
      "epoch 25; iter: 0; batch classifier loss: 0.126530; batch adversarial loss: 0.506257\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182152; batch adversarial loss: 0.505599\n",
      "epoch 27; iter: 0; batch classifier loss: 0.163535; batch adversarial loss: 0.400884\n",
      "epoch 28; iter: 0; batch classifier loss: 0.116403; batch adversarial loss: 0.396837\n",
      "epoch 29; iter: 0; batch classifier loss: 0.140180; batch adversarial loss: 0.414426\n",
      "epoch 30; iter: 0; batch classifier loss: 0.132302; batch adversarial loss: 0.405375\n",
      "epoch 31; iter: 0; batch classifier loss: 0.145508; batch adversarial loss: 0.469463\n",
      "epoch 32; iter: 0; batch classifier loss: 0.177894; batch adversarial loss: 0.500140\n",
      "epoch 33; iter: 0; batch classifier loss: 0.117086; batch adversarial loss: 0.433256\n",
      "epoch 34; iter: 0; batch classifier loss: 0.120059; batch adversarial loss: 0.418884\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160923; batch adversarial loss: 0.487876\n",
      "epoch 36; iter: 0; batch classifier loss: 0.111598; batch adversarial loss: 0.396795\n",
      "epoch 37; iter: 0; batch classifier loss: 0.155618; batch adversarial loss: 0.387795\n",
      "epoch 38; iter: 0; batch classifier loss: 0.178761; batch adversarial loss: 0.428762\n",
      "epoch 39; iter: 0; batch classifier loss: 0.128061; batch adversarial loss: 0.392580\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154412; batch adversarial loss: 0.466371\n",
      "epoch 41; iter: 0; batch classifier loss: 0.088965; batch adversarial loss: 0.412799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.108185; batch adversarial loss: 0.466871\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110568; batch adversarial loss: 0.397964\n",
      "epoch 44; iter: 0; batch classifier loss: 0.095208; batch adversarial loss: 0.386912\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104645; batch adversarial loss: 0.385384\n",
      "epoch 46; iter: 0; batch classifier loss: 0.094607; batch adversarial loss: 0.416898\n",
      "epoch 47; iter: 0; batch classifier loss: 0.156546; batch adversarial loss: 0.436139\n",
      "epoch 48; iter: 0; batch classifier loss: 0.072243; batch adversarial loss: 0.448552\n",
      "epoch 49; iter: 0; batch classifier loss: 0.086830; batch adversarial loss: 0.413353\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096582; batch adversarial loss: 0.464501\n",
      "epoch 51; iter: 0; batch classifier loss: 0.095679; batch adversarial loss: 0.414696\n",
      "epoch 52; iter: 0; batch classifier loss: 0.109543; batch adversarial loss: 0.420304\n",
      "epoch 53; iter: 0; batch classifier loss: 0.064107; batch adversarial loss: 0.354975\n",
      "epoch 54; iter: 0; batch classifier loss: 0.071031; batch adversarial loss: 0.445623\n",
      "epoch 55; iter: 0; batch classifier loss: 0.082467; batch adversarial loss: 0.330061\n",
      "epoch 56; iter: 0; batch classifier loss: 0.079100; batch adversarial loss: 0.341792\n",
      "epoch 57; iter: 0; batch classifier loss: 0.074400; batch adversarial loss: 0.415193\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077975; batch adversarial loss: 0.448000\n",
      "epoch 59; iter: 0; batch classifier loss: 0.065427; batch adversarial loss: 0.403421\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065333; batch adversarial loss: 0.394871\n",
      "epoch 61; iter: 0; batch classifier loss: 0.105789; batch adversarial loss: 0.371636\n",
      "epoch 62; iter: 0; batch classifier loss: 0.066782; batch adversarial loss: 0.384151\n",
      "epoch 63; iter: 0; batch classifier loss: 0.077179; batch adversarial loss: 0.542997\n",
      "epoch 64; iter: 0; batch classifier loss: 0.065295; batch adversarial loss: 0.451836\n",
      "epoch 65; iter: 0; batch classifier loss: 0.059738; batch adversarial loss: 0.487792\n",
      "epoch 66; iter: 0; batch classifier loss: 0.082288; batch adversarial loss: 0.427148\n",
      "epoch 67; iter: 0; batch classifier loss: 0.072305; batch adversarial loss: 0.500479\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078796; batch adversarial loss: 0.430979\n",
      "epoch 69; iter: 0; batch classifier loss: 0.045361; batch adversarial loss: 0.573436\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067973; batch adversarial loss: 0.468718\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058118; batch adversarial loss: 0.469433\n",
      "epoch 72; iter: 0; batch classifier loss: 0.043512; batch adversarial loss: 0.449061\n",
      "epoch 73; iter: 0; batch classifier loss: 0.048583; batch adversarial loss: 0.352150\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067005; batch adversarial loss: 0.447780\n",
      "epoch 75; iter: 0; batch classifier loss: 0.038322; batch adversarial loss: 0.378618\n",
      "epoch 76; iter: 0; batch classifier loss: 0.062020; batch adversarial loss: 0.448628\n",
      "epoch 77; iter: 0; batch classifier loss: 0.035475; batch adversarial loss: 0.430841\n",
      "epoch 78; iter: 0; batch classifier loss: 0.042906; batch adversarial loss: 0.365966\n",
      "epoch 79; iter: 0; batch classifier loss: 0.091781; batch adversarial loss: 0.439366\n",
      "epoch 80; iter: 0; batch classifier loss: 0.042086; batch adversarial loss: 0.461545\n",
      "epoch 81; iter: 0; batch classifier loss: 0.056877; batch adversarial loss: 0.517385\n",
      "epoch 82; iter: 0; batch classifier loss: 0.050315; batch adversarial loss: 0.462444\n",
      "epoch 83; iter: 0; batch classifier loss: 0.023859; batch adversarial loss: 0.405610\n",
      "epoch 84; iter: 0; batch classifier loss: 0.027152; batch adversarial loss: 0.502516\n",
      "epoch 85; iter: 0; batch classifier loss: 0.033131; batch adversarial loss: 0.401707\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061281; batch adversarial loss: 0.429410\n",
      "epoch 87; iter: 0; batch classifier loss: 0.040204; batch adversarial loss: 0.467729\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041679; batch adversarial loss: 0.460706\n",
      "epoch 89; iter: 0; batch classifier loss: 0.044492; batch adversarial loss: 0.535454\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042514; batch adversarial loss: 0.499852\n",
      "epoch 91; iter: 0; batch classifier loss: 0.024570; batch adversarial loss: 0.490262\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052437; batch adversarial loss: 0.457957\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044656; batch adversarial loss: 0.454954\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044967; batch adversarial loss: 0.424092\n",
      "epoch 95; iter: 0; batch classifier loss: 0.029700; batch adversarial loss: 0.427709\n",
      "epoch 96; iter: 0; batch classifier loss: 0.039325; batch adversarial loss: 0.535686\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055104; batch adversarial loss: 0.487491\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051902; batch adversarial loss: 0.521993\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074283; batch adversarial loss: 0.404846\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038245; batch adversarial loss: 0.606964\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039175; batch adversarial loss: 0.523958\n",
      "epoch 102; iter: 0; batch classifier loss: 0.085164; batch adversarial loss: 0.450033\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066768; batch adversarial loss: 0.460326\n",
      "epoch 104; iter: 0; batch classifier loss: 0.123362; batch adversarial loss: 0.557817\n",
      "epoch 105; iter: 0; batch classifier loss: 0.113200; batch adversarial loss: 0.628394\n",
      "epoch 106; iter: 0; batch classifier loss: 0.086041; batch adversarial loss: 0.650329\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062467; batch adversarial loss: 0.475151\n",
      "epoch 108; iter: 0; batch classifier loss: 0.105741; batch adversarial loss: 0.628240\n",
      "epoch 109; iter: 0; batch classifier loss: 0.102565; batch adversarial loss: 0.532170\n",
      "epoch 110; iter: 0; batch classifier loss: 0.126597; batch adversarial loss: 0.614374\n",
      "epoch 111; iter: 0; batch classifier loss: 0.093996; batch adversarial loss: 0.613375\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054142; batch adversarial loss: 0.424726\n",
      "epoch 113; iter: 0; batch classifier loss: 0.154280; batch adversarial loss: 0.613978\n",
      "epoch 114; iter: 0; batch classifier loss: 0.191039; batch adversarial loss: 0.739913\n",
      "epoch 115; iter: 0; batch classifier loss: 0.125461; batch adversarial loss: 0.454877\n",
      "epoch 116; iter: 0; batch classifier loss: 0.152477; batch adversarial loss: 0.508944\n",
      "epoch 117; iter: 0; batch classifier loss: 0.197462; batch adversarial loss: 0.669674\n",
      "epoch 118; iter: 0; batch classifier loss: 0.112650; batch adversarial loss: 0.479328\n",
      "epoch 119; iter: 0; batch classifier loss: 0.072593; batch adversarial loss: 0.393664\n",
      "epoch 120; iter: 0; batch classifier loss: 0.147088; batch adversarial loss: 0.544782\n",
      "epoch 121; iter: 0; batch classifier loss: 0.153570; batch adversarial loss: 0.532567\n",
      "epoch 122; iter: 0; batch classifier loss: 0.149285; batch adversarial loss: 0.510726\n",
      "epoch 123; iter: 0; batch classifier loss: 0.123381; batch adversarial loss: 0.549621\n",
      "epoch 124; iter: 0; batch classifier loss: 0.101323; batch adversarial loss: 0.458330\n",
      "epoch 125; iter: 0; batch classifier loss: 0.103064; batch adversarial loss: 0.502071\n",
      "epoch 126; iter: 0; batch classifier loss: 0.098551; batch adversarial loss: 0.456553\n",
      "epoch 127; iter: 0; batch classifier loss: 0.083100; batch adversarial loss: 0.453237\n",
      "epoch 128; iter: 0; batch classifier loss: 0.097986; batch adversarial loss: 0.447808\n",
      "epoch 129; iter: 0; batch classifier loss: 0.101792; batch adversarial loss: 0.566912\n",
      "epoch 130; iter: 0; batch classifier loss: 0.137116; batch adversarial loss: 0.540452\n",
      "epoch 131; iter: 0; batch classifier loss: 0.074251; batch adversarial loss: 0.459276\n",
      "epoch 132; iter: 0; batch classifier loss: 0.088702; batch adversarial loss: 0.461328\n",
      "epoch 133; iter: 0; batch classifier loss: 0.089975; batch adversarial loss: 0.442813\n",
      "epoch 134; iter: 0; batch classifier loss: 0.120869; batch adversarial loss: 0.506297\n",
      "epoch 135; iter: 0; batch classifier loss: 0.121574; batch adversarial loss: 0.489821\n",
      "epoch 136; iter: 0; batch classifier loss: 0.118416; batch adversarial loss: 0.495754\n",
      "epoch 137; iter: 0; batch classifier loss: 0.138715; batch adversarial loss: 0.443705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.067091; batch adversarial loss: 0.542278\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038313; batch adversarial loss: 0.441929\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036710; batch adversarial loss: 0.470612\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027954; batch adversarial loss: 0.515965\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027659; batch adversarial loss: 0.437024\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028026; batch adversarial loss: 0.588489\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013974; batch adversarial loss: 0.478739\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015186; batch adversarial loss: 0.434620\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031657; batch adversarial loss: 0.483465\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041767; batch adversarial loss: 0.387699\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013262; batch adversarial loss: 0.475950\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027997; batch adversarial loss: 0.443942\n",
      "epoch 150; iter: 0; batch classifier loss: 0.055919; batch adversarial loss: 0.476865\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037218; batch adversarial loss: 0.350594\n",
      "epoch 152; iter: 0; batch classifier loss: 0.066738; batch adversarial loss: 0.479041\n",
      "epoch 153; iter: 0; batch classifier loss: 0.088891; batch adversarial loss: 0.425520\n",
      "epoch 154; iter: 0; batch classifier loss: 0.070457; batch adversarial loss: 0.430028\n",
      "epoch 155; iter: 0; batch classifier loss: 0.065162; batch adversarial loss: 0.400567\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020907; batch adversarial loss: 0.409576\n",
      "epoch 157; iter: 0; batch classifier loss: 0.047485; batch adversarial loss: 0.503199\n",
      "epoch 158; iter: 0; batch classifier loss: 0.070493; batch adversarial loss: 0.536154\n",
      "epoch 159; iter: 0; batch classifier loss: 0.057725; batch adversarial loss: 0.484265\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020068; batch adversarial loss: 0.424418\n",
      "epoch 161; iter: 0; batch classifier loss: 0.095609; batch adversarial loss: 0.398696\n",
      "epoch 162; iter: 0; batch classifier loss: 0.089621; batch adversarial loss: 0.447868\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033015; batch adversarial loss: 0.557465\n",
      "epoch 164; iter: 0; batch classifier loss: 0.043399; batch adversarial loss: 0.502772\n",
      "epoch 165; iter: 0; batch classifier loss: 0.103844; batch adversarial loss: 0.452548\n",
      "epoch 166; iter: 0; batch classifier loss: 0.078318; batch adversarial loss: 0.426125\n",
      "epoch 167; iter: 0; batch classifier loss: 0.094677; batch adversarial loss: 0.412554\n",
      "epoch 168; iter: 0; batch classifier loss: 0.049944; batch adversarial loss: 0.450641\n",
      "epoch 169; iter: 0; batch classifier loss: 0.043335; batch adversarial loss: 0.489715\n",
      "epoch 170; iter: 0; batch classifier loss: 0.059055; batch adversarial loss: 0.377031\n",
      "epoch 171; iter: 0; batch classifier loss: 0.048938; batch adversarial loss: 0.411978\n",
      "epoch 172; iter: 0; batch classifier loss: 0.059402; batch adversarial loss: 0.410356\n",
      "epoch 173; iter: 0; batch classifier loss: 0.055571; batch adversarial loss: 0.495866\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032537; batch adversarial loss: 0.410464\n",
      "epoch 175; iter: 0; batch classifier loss: 0.102204; batch adversarial loss: 0.604305\n",
      "epoch 176; iter: 0; batch classifier loss: 0.067507; batch adversarial loss: 0.391824\n",
      "epoch 177; iter: 0; batch classifier loss: 0.068741; batch adversarial loss: 0.457679\n",
      "epoch 178; iter: 0; batch classifier loss: 0.080282; batch adversarial loss: 0.462675\n",
      "epoch 179; iter: 0; batch classifier loss: 0.047963; batch adversarial loss: 0.452576\n",
      "epoch 180; iter: 0; batch classifier loss: 0.048723; batch adversarial loss: 0.498489\n",
      "epoch 181; iter: 0; batch classifier loss: 0.050606; batch adversarial loss: 0.444879\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015610; batch adversarial loss: 0.483571\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027050; batch adversarial loss: 0.497298\n",
      "epoch 184; iter: 0; batch classifier loss: 0.055369; batch adversarial loss: 0.578372\n",
      "epoch 185; iter: 0; batch classifier loss: 0.039118; batch adversarial loss: 0.418458\n",
      "epoch 186; iter: 0; batch classifier loss: 0.038238; batch adversarial loss: 0.463124\n",
      "epoch 187; iter: 0; batch classifier loss: 0.078261; batch adversarial loss: 0.534920\n",
      "epoch 188; iter: 0; batch classifier loss: 0.046898; batch adversarial loss: 0.388717\n",
      "epoch 189; iter: 0; batch classifier loss: 0.045716; batch adversarial loss: 0.518136\n",
      "epoch 190; iter: 0; batch classifier loss: 0.074268; batch adversarial loss: 0.488623\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015244; batch adversarial loss: 0.408801\n",
      "epoch 192; iter: 0; batch classifier loss: 0.057086; batch adversarial loss: 0.397183\n",
      "epoch 193; iter: 0; batch classifier loss: 0.041969; batch adversarial loss: 0.424023\n",
      "epoch 194; iter: 0; batch classifier loss: 0.044132; batch adversarial loss: 0.480229\n",
      "epoch 195; iter: 0; batch classifier loss: 0.050416; batch adversarial loss: 0.488991\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027449; batch adversarial loss: 0.470497\n",
      "epoch 197; iter: 0; batch classifier loss: 0.053117; batch adversarial loss: 0.416326\n",
      "epoch 198; iter: 0; batch classifier loss: 0.050823; batch adversarial loss: 0.488878\n",
      "epoch 199; iter: 0; batch classifier loss: 0.029531; batch adversarial loss: 0.392929\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711509; batch adversarial loss: 0.760643\n",
      "epoch 1; iter: 0; batch classifier loss: 0.474742; batch adversarial loss: 0.707717\n",
      "epoch 2; iter: 0; batch classifier loss: 0.493907; batch adversarial loss: 0.653054\n",
      "epoch 3; iter: 0; batch classifier loss: 0.418953; batch adversarial loss: 0.613012\n",
      "epoch 4; iter: 0; batch classifier loss: 0.311520; batch adversarial loss: 0.602063\n",
      "epoch 5; iter: 0; batch classifier loss: 0.447662; batch adversarial loss: 0.594376\n",
      "epoch 6; iter: 0; batch classifier loss: 0.445079; batch adversarial loss: 0.552235\n",
      "epoch 7; iter: 0; batch classifier loss: 0.293986; batch adversarial loss: 0.564191\n",
      "epoch 8; iter: 0; batch classifier loss: 0.299565; batch adversarial loss: 0.553220\n",
      "epoch 9; iter: 0; batch classifier loss: 0.375377; batch adversarial loss: 0.526082\n",
      "epoch 10; iter: 0; batch classifier loss: 0.300482; batch adversarial loss: 0.581679\n",
      "epoch 11; iter: 0; batch classifier loss: 0.310578; batch adversarial loss: 0.561136\n",
      "epoch 12; iter: 0; batch classifier loss: 0.407529; batch adversarial loss: 0.508524\n",
      "epoch 13; iter: 0; batch classifier loss: 0.313088; batch adversarial loss: 0.533476\n",
      "epoch 14; iter: 0; batch classifier loss: 0.276798; batch adversarial loss: 0.538557\n",
      "epoch 15; iter: 0; batch classifier loss: 0.313691; batch adversarial loss: 0.547468\n",
      "epoch 16; iter: 0; batch classifier loss: 0.384091; batch adversarial loss: 0.463225\n",
      "epoch 17; iter: 0; batch classifier loss: 0.301057; batch adversarial loss: 0.507361\n",
      "epoch 18; iter: 0; batch classifier loss: 0.257328; batch adversarial loss: 0.460411\n",
      "epoch 19; iter: 0; batch classifier loss: 0.365448; batch adversarial loss: 0.514219\n",
      "epoch 20; iter: 0; batch classifier loss: 0.253220; batch adversarial loss: 0.578232\n",
      "epoch 21; iter: 0; batch classifier loss: 0.310434; batch adversarial loss: 0.451990\n",
      "epoch 22; iter: 0; batch classifier loss: 0.443175; batch adversarial loss: 0.412903\n",
      "epoch 23; iter: 0; batch classifier loss: 0.283458; batch adversarial loss: 0.422881\n",
      "epoch 24; iter: 0; batch classifier loss: 0.264982; batch adversarial loss: 0.439038\n",
      "epoch 25; iter: 0; batch classifier loss: 0.397994; batch adversarial loss: 0.424740\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193329; batch adversarial loss: 0.490650\n",
      "epoch 27; iter: 0; batch classifier loss: 0.254084; batch adversarial loss: 0.538230\n",
      "epoch 28; iter: 0; batch classifier loss: 0.258048; batch adversarial loss: 0.441937\n",
      "epoch 29; iter: 0; batch classifier loss: 0.218614; batch adversarial loss: 0.511872\n",
      "epoch 30; iter: 0; batch classifier loss: 0.240029; batch adversarial loss: 0.452680\n",
      "epoch 31; iter: 0; batch classifier loss: 0.257769; batch adversarial loss: 0.400784\n",
      "epoch 32; iter: 0; batch classifier loss: 0.216716; batch adversarial loss: 0.475121\n",
      "epoch 33; iter: 0; batch classifier loss: 0.231522; batch adversarial loss: 0.423755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.207651; batch adversarial loss: 0.482785\n",
      "epoch 35; iter: 0; batch classifier loss: 0.233430; batch adversarial loss: 0.485061\n",
      "epoch 36; iter: 0; batch classifier loss: 0.198623; batch adversarial loss: 0.478393\n",
      "epoch 37; iter: 0; batch classifier loss: 0.182228; batch adversarial loss: 0.480143\n",
      "epoch 38; iter: 0; batch classifier loss: 0.254856; batch adversarial loss: 0.521587\n",
      "epoch 39; iter: 0; batch classifier loss: 0.198018; batch adversarial loss: 0.564058\n",
      "epoch 40; iter: 0; batch classifier loss: 0.177401; batch adversarial loss: 0.502044\n",
      "epoch 41; iter: 0; batch classifier loss: 0.201647; batch adversarial loss: 0.555454\n",
      "epoch 42; iter: 0; batch classifier loss: 0.212051; batch adversarial loss: 0.423991\n",
      "epoch 43; iter: 0; batch classifier loss: 0.168412; batch adversarial loss: 0.495451\n",
      "epoch 44; iter: 0; batch classifier loss: 0.182924; batch adversarial loss: 0.510810\n",
      "epoch 45; iter: 0; batch classifier loss: 0.206560; batch adversarial loss: 0.392468\n",
      "epoch 46; iter: 0; batch classifier loss: 0.279424; batch adversarial loss: 0.464473\n",
      "epoch 47; iter: 0; batch classifier loss: 0.224055; batch adversarial loss: 0.438204\n",
      "epoch 48; iter: 0; batch classifier loss: 0.224751; batch adversarial loss: 0.451827\n",
      "epoch 49; iter: 0; batch classifier loss: 0.201837; batch adversarial loss: 0.410682\n",
      "epoch 50; iter: 0; batch classifier loss: 0.290793; batch adversarial loss: 0.365742\n",
      "epoch 51; iter: 0; batch classifier loss: 0.169600; batch adversarial loss: 0.397325\n",
      "epoch 52; iter: 0; batch classifier loss: 0.207813; batch adversarial loss: 0.341362\n",
      "epoch 53; iter: 0; batch classifier loss: 0.228729; batch adversarial loss: 0.483658\n",
      "epoch 54; iter: 0; batch classifier loss: 0.243817; batch adversarial loss: 0.519040\n",
      "epoch 55; iter: 0; batch classifier loss: 0.231603; batch adversarial loss: 0.520960\n",
      "epoch 56; iter: 0; batch classifier loss: 0.221902; batch adversarial loss: 0.471261\n",
      "epoch 57; iter: 0; batch classifier loss: 0.196388; batch adversarial loss: 0.408642\n",
      "epoch 58; iter: 0; batch classifier loss: 0.237693; batch adversarial loss: 0.515662\n",
      "epoch 59; iter: 0; batch classifier loss: 0.205139; batch adversarial loss: 0.375317\n",
      "epoch 60; iter: 0; batch classifier loss: 0.202040; batch adversarial loss: 0.459844\n",
      "epoch 61; iter: 0; batch classifier loss: 0.188963; batch adversarial loss: 0.531973\n",
      "epoch 62; iter: 0; batch classifier loss: 0.253602; batch adversarial loss: 0.434275\n",
      "epoch 63; iter: 0; batch classifier loss: 0.204320; batch adversarial loss: 0.421378\n",
      "epoch 64; iter: 0; batch classifier loss: 0.190330; batch adversarial loss: 0.435650\n",
      "epoch 65; iter: 0; batch classifier loss: 0.231353; batch adversarial loss: 0.434736\n",
      "epoch 66; iter: 0; batch classifier loss: 0.261482; batch adversarial loss: 0.434485\n",
      "epoch 67; iter: 0; batch classifier loss: 0.237869; batch adversarial loss: 0.458530\n",
      "epoch 68; iter: 0; batch classifier loss: 0.206915; batch adversarial loss: 0.458776\n",
      "epoch 69; iter: 0; batch classifier loss: 0.157187; batch adversarial loss: 0.518891\n",
      "epoch 70; iter: 0; batch classifier loss: 0.291219; batch adversarial loss: 0.361786\n",
      "epoch 71; iter: 0; batch classifier loss: 0.170688; batch adversarial loss: 0.458324\n",
      "epoch 72; iter: 0; batch classifier loss: 0.193399; batch adversarial loss: 0.410841\n",
      "epoch 73; iter: 0; batch classifier loss: 0.168604; batch adversarial loss: 0.470485\n",
      "epoch 74; iter: 0; batch classifier loss: 0.213835; batch adversarial loss: 0.409636\n",
      "epoch 75; iter: 0; batch classifier loss: 0.174151; batch adversarial loss: 0.497125\n",
      "epoch 76; iter: 0; batch classifier loss: 0.238516; batch adversarial loss: 0.373036\n",
      "epoch 77; iter: 0; batch classifier loss: 0.174814; batch adversarial loss: 0.531965\n",
      "epoch 78; iter: 0; batch classifier loss: 0.210311; batch adversarial loss: 0.446083\n",
      "epoch 79; iter: 0; batch classifier loss: 0.139865; batch adversarial loss: 0.495731\n",
      "epoch 80; iter: 0; batch classifier loss: 0.170391; batch adversarial loss: 0.472796\n",
      "epoch 81; iter: 0; batch classifier loss: 0.205475; batch adversarial loss: 0.446845\n",
      "epoch 82; iter: 0; batch classifier loss: 0.121818; batch adversarial loss: 0.445994\n",
      "epoch 83; iter: 0; batch classifier loss: 0.154294; batch adversarial loss: 0.471280\n",
      "epoch 84; iter: 0; batch classifier loss: 0.149494; batch adversarial loss: 0.445952\n",
      "epoch 85; iter: 0; batch classifier loss: 0.206140; batch adversarial loss: 0.483467\n",
      "epoch 86; iter: 0; batch classifier loss: 0.179801; batch adversarial loss: 0.544735\n",
      "epoch 87; iter: 0; batch classifier loss: 0.168930; batch adversarial loss: 0.519195\n",
      "epoch 88; iter: 0; batch classifier loss: 0.186661; batch adversarial loss: 0.396521\n",
      "epoch 89; iter: 0; batch classifier loss: 0.206695; batch adversarial loss: 0.579603\n",
      "epoch 90; iter: 0; batch classifier loss: 0.138704; batch adversarial loss: 0.496309\n",
      "epoch 91; iter: 0; batch classifier loss: 0.121319; batch adversarial loss: 0.431922\n",
      "epoch 92; iter: 0; batch classifier loss: 0.083472; batch adversarial loss: 0.547501\n",
      "epoch 93; iter: 0; batch classifier loss: 0.147618; batch adversarial loss: 0.458216\n",
      "epoch 94; iter: 0; batch classifier loss: 0.087473; batch adversarial loss: 0.453867\n",
      "epoch 95; iter: 0; batch classifier loss: 0.096894; batch adversarial loss: 0.443509\n",
      "epoch 96; iter: 0; batch classifier loss: 0.081381; batch adversarial loss: 0.398285\n",
      "epoch 97; iter: 0; batch classifier loss: 0.087615; batch adversarial loss: 0.420766\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063294; batch adversarial loss: 0.456698\n",
      "epoch 99; iter: 0; batch classifier loss: 0.095604; batch adversarial loss: 0.555238\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050022; batch adversarial loss: 0.492425\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071624; batch adversarial loss: 0.456220\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068729; batch adversarial loss: 0.462947\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038845; batch adversarial loss: 0.481488\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060690; batch adversarial loss: 0.416763\n",
      "epoch 105; iter: 0; batch classifier loss: 0.025137; batch adversarial loss: 0.519512\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049379; batch adversarial loss: 0.464893\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049117; batch adversarial loss: 0.496723\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048029; batch adversarial loss: 0.467121\n",
      "epoch 109; iter: 0; batch classifier loss: 0.056387; batch adversarial loss: 0.531188\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036753; batch adversarial loss: 0.345282\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055609; batch adversarial loss: 0.464337\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038795; batch adversarial loss: 0.475172\n",
      "epoch 113; iter: 0; batch classifier loss: 0.032181; batch adversarial loss: 0.488685\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029219; batch adversarial loss: 0.492993\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038722; batch adversarial loss: 0.379588\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048670; batch adversarial loss: 0.388791\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061832; batch adversarial loss: 0.524875\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046577; batch adversarial loss: 0.483264\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021050; batch adversarial loss: 0.445532\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054676; batch adversarial loss: 0.478033\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018754; batch adversarial loss: 0.449693\n",
      "epoch 122; iter: 0; batch classifier loss: 0.021455; batch adversarial loss: 0.454389\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025107; batch adversarial loss: 0.411642\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050727; batch adversarial loss: 0.400533\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034073; batch adversarial loss: 0.547780\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030299; batch adversarial loss: 0.356724\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028292; batch adversarial loss: 0.517385\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021823; batch adversarial loss: 0.504087\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028408; batch adversarial loss: 0.445560\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041415; batch adversarial loss: 0.434920\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022871; batch adversarial loss: 0.480104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.062632; batch adversarial loss: 0.554171\n",
      "epoch 133; iter: 0; batch classifier loss: 0.054512; batch adversarial loss: 0.429769\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021919; batch adversarial loss: 0.474656\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044694; batch adversarial loss: 0.469919\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027588; batch adversarial loss: 0.385915\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026352; batch adversarial loss: 0.424344\n",
      "epoch 138; iter: 0; batch classifier loss: 0.012674; batch adversarial loss: 0.352192\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010450; batch adversarial loss: 0.463900\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022144; batch adversarial loss: 0.455436\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036766; batch adversarial loss: 0.441723\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043032; batch adversarial loss: 0.513836\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027202; batch adversarial loss: 0.466065\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022655; batch adversarial loss: 0.505465\n",
      "epoch 145; iter: 0; batch classifier loss: 0.052217; batch adversarial loss: 0.517313\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038778; batch adversarial loss: 0.449742\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033001; batch adversarial loss: 0.418083\n",
      "epoch 148; iter: 0; batch classifier loss: 0.055222; batch adversarial loss: 0.335195\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028115; batch adversarial loss: 0.491806\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018203; batch adversarial loss: 0.441728\n",
      "epoch 151; iter: 0; batch classifier loss: 0.051892; batch adversarial loss: 0.315147\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024549; batch adversarial loss: 0.590125\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018327; batch adversarial loss: 0.524926\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017484; batch adversarial loss: 0.375200\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023439; batch adversarial loss: 0.416006\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012968; batch adversarial loss: 0.553411\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018576; batch adversarial loss: 0.387071\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037681; batch adversarial loss: 0.414277\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028126; batch adversarial loss: 0.473543\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014683; batch adversarial loss: 0.466898\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024714; batch adversarial loss: 0.456458\n",
      "epoch 162; iter: 0; batch classifier loss: 0.063366; batch adversarial loss: 0.383027\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036142; batch adversarial loss: 0.445316\n",
      "epoch 164; iter: 0; batch classifier loss: 0.041258; batch adversarial loss: 0.399891\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027443; batch adversarial loss: 0.471708\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025348; batch adversarial loss: 0.533859\n",
      "epoch 167; iter: 0; batch classifier loss: 0.047801; batch adversarial loss: 0.394393\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024545; batch adversarial loss: 0.377311\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020330; batch adversarial loss: 0.457450\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022453; batch adversarial loss: 0.402597\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015103; batch adversarial loss: 0.444592\n",
      "epoch 172; iter: 0; batch classifier loss: 0.037742; batch adversarial loss: 0.448047\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006549; batch adversarial loss: 0.420037\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032990; batch adversarial loss: 0.521163\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008231; batch adversarial loss: 0.398966\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026258; batch adversarial loss: 0.530557\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038619; batch adversarial loss: 0.503579\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019792; batch adversarial loss: 0.407921\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006291; batch adversarial loss: 0.471496\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008628; batch adversarial loss: 0.461783\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021259; batch adversarial loss: 0.518395\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026163; batch adversarial loss: 0.498825\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009670; batch adversarial loss: 0.503685\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019343; batch adversarial loss: 0.458190\n",
      "epoch 185; iter: 0; batch classifier loss: 0.059007; batch adversarial loss: 0.475813\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021761; batch adversarial loss: 0.386242\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007099; batch adversarial loss: 0.427545\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017484; batch adversarial loss: 0.377398\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007026; batch adversarial loss: 0.472021\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028553; batch adversarial loss: 0.447587\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009997; batch adversarial loss: 0.449213\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027526; batch adversarial loss: 0.447523\n",
      "epoch 193; iter: 0; batch classifier loss: 0.041151; batch adversarial loss: 0.555996\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026336; batch adversarial loss: 0.451775\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023928; batch adversarial loss: 0.472740\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019947; batch adversarial loss: 0.443180\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011310; batch adversarial loss: 0.460968\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023066; batch adversarial loss: 0.423282\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015337; batch adversarial loss: 0.512990\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667388; batch adversarial loss: 0.804716\n",
      "epoch 1; iter: 0; batch classifier loss: 0.340393; batch adversarial loss: 0.740727\n",
      "epoch 2; iter: 0; batch classifier loss: 0.347363; batch adversarial loss: 0.697938\n",
      "epoch 3; iter: 0; batch classifier loss: 0.352208; batch adversarial loss: 0.661582\n",
      "epoch 4; iter: 0; batch classifier loss: 0.310788; batch adversarial loss: 0.640948\n",
      "epoch 5; iter: 0; batch classifier loss: 0.428649; batch adversarial loss: 0.604988\n",
      "epoch 6; iter: 0; batch classifier loss: 0.326012; batch adversarial loss: 0.597705\n",
      "epoch 7; iter: 0; batch classifier loss: 0.315444; batch adversarial loss: 0.548393\n",
      "epoch 8; iter: 0; batch classifier loss: 0.303892; batch adversarial loss: 0.527501\n",
      "epoch 9; iter: 0; batch classifier loss: 0.265181; batch adversarial loss: 0.524022\n",
      "epoch 10; iter: 0; batch classifier loss: 0.349689; batch adversarial loss: 0.472780\n",
      "epoch 11; iter: 0; batch classifier loss: 0.247954; batch adversarial loss: 0.470660\n",
      "epoch 12; iter: 0; batch classifier loss: 0.276993; batch adversarial loss: 0.458323\n",
      "epoch 13; iter: 0; batch classifier loss: 0.200359; batch adversarial loss: 0.449354\n",
      "epoch 14; iter: 0; batch classifier loss: 0.202758; batch adversarial loss: 0.426426\n",
      "epoch 15; iter: 0; batch classifier loss: 0.239459; batch adversarial loss: 0.421006\n",
      "epoch 16; iter: 0; batch classifier loss: 0.196098; batch adversarial loss: 0.429568\n",
      "epoch 17; iter: 0; batch classifier loss: 0.180543; batch adversarial loss: 0.458858\n",
      "epoch 18; iter: 0; batch classifier loss: 0.177148; batch adversarial loss: 0.411251\n",
      "epoch 19; iter: 0; batch classifier loss: 0.266388; batch adversarial loss: 0.377006\n",
      "epoch 20; iter: 0; batch classifier loss: 0.194260; batch adversarial loss: 0.449842\n",
      "epoch 21; iter: 0; batch classifier loss: 0.212900; batch adversarial loss: 0.463275\n",
      "epoch 22; iter: 0; batch classifier loss: 0.159826; batch adversarial loss: 0.442189\n",
      "epoch 23; iter: 0; batch classifier loss: 0.159811; batch adversarial loss: 0.372737\n",
      "epoch 24; iter: 0; batch classifier loss: 0.145653; batch adversarial loss: 0.416880\n",
      "epoch 25; iter: 0; batch classifier loss: 0.160759; batch adversarial loss: 0.398045\n",
      "epoch 26; iter: 0; batch classifier loss: 0.130995; batch adversarial loss: 0.365825\n",
      "epoch 27; iter: 0; batch classifier loss: 0.176212; batch adversarial loss: 0.365682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.158285; batch adversarial loss: 0.399735\n",
      "epoch 29; iter: 0; batch classifier loss: 0.221203; batch adversarial loss: 0.426580\n",
      "epoch 30; iter: 0; batch classifier loss: 0.134486; batch adversarial loss: 0.396154\n",
      "epoch 31; iter: 0; batch classifier loss: 0.207354; batch adversarial loss: 0.369988\n",
      "epoch 32; iter: 0; batch classifier loss: 0.149878; batch adversarial loss: 0.527315\n",
      "epoch 33; iter: 0; batch classifier loss: 0.134989; batch adversarial loss: 0.427006\n",
      "epoch 34; iter: 0; batch classifier loss: 0.171708; batch adversarial loss: 0.393802\n",
      "epoch 35; iter: 0; batch classifier loss: 0.118464; batch adversarial loss: 0.386517\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141674; batch adversarial loss: 0.372204\n",
      "epoch 37; iter: 0; batch classifier loss: 0.097229; batch adversarial loss: 0.363137\n",
      "epoch 38; iter: 0; batch classifier loss: 0.153752; batch adversarial loss: 0.470386\n",
      "epoch 39; iter: 0; batch classifier loss: 0.124247; batch adversarial loss: 0.383004\n",
      "epoch 40; iter: 0; batch classifier loss: 0.161226; batch adversarial loss: 0.377192\n",
      "epoch 41; iter: 0; batch classifier loss: 0.177921; batch adversarial loss: 0.435809\n",
      "epoch 42; iter: 0; batch classifier loss: 0.134673; batch adversarial loss: 0.416181\n",
      "epoch 43; iter: 0; batch classifier loss: 0.107674; batch adversarial loss: 0.456772\n",
      "epoch 44; iter: 0; batch classifier loss: 0.107925; batch adversarial loss: 0.436381\n",
      "epoch 45; iter: 0; batch classifier loss: 0.113343; batch adversarial loss: 0.463110\n",
      "epoch 46; iter: 0; batch classifier loss: 0.110662; batch adversarial loss: 0.392121\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112015; batch adversarial loss: 0.376266\n",
      "epoch 48; iter: 0; batch classifier loss: 0.126451; batch adversarial loss: 0.426708\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101831; batch adversarial loss: 0.387243\n",
      "epoch 50; iter: 0; batch classifier loss: 0.062030; batch adversarial loss: 0.330556\n",
      "epoch 51; iter: 0; batch classifier loss: 0.097675; batch adversarial loss: 0.420723\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099189; batch adversarial loss: 0.402800\n",
      "epoch 53; iter: 0; batch classifier loss: 0.120595; batch adversarial loss: 0.391050\n",
      "epoch 54; iter: 0; batch classifier loss: 0.117685; batch adversarial loss: 0.387442\n",
      "epoch 55; iter: 0; batch classifier loss: 0.093793; batch adversarial loss: 0.400272\n",
      "epoch 56; iter: 0; batch classifier loss: 0.076850; batch adversarial loss: 0.319941\n",
      "epoch 57; iter: 0; batch classifier loss: 0.162084; batch adversarial loss: 0.349082\n",
      "epoch 58; iter: 0; batch classifier loss: 0.075855; batch adversarial loss: 0.468904\n",
      "epoch 59; iter: 0; batch classifier loss: 0.094970; batch adversarial loss: 0.402908\n",
      "epoch 60; iter: 0; batch classifier loss: 0.070891; batch adversarial loss: 0.398447\n",
      "epoch 61; iter: 0; batch classifier loss: 0.079608; batch adversarial loss: 0.399097\n",
      "epoch 62; iter: 0; batch classifier loss: 0.087897; batch adversarial loss: 0.519701\n",
      "epoch 63; iter: 0; batch classifier loss: 0.124818; batch adversarial loss: 0.407334\n",
      "epoch 64; iter: 0; batch classifier loss: 0.109724; batch adversarial loss: 0.432410\n",
      "epoch 65; iter: 0; batch classifier loss: 0.100961; batch adversarial loss: 0.513368\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075792; batch adversarial loss: 0.431704\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101043; batch adversarial loss: 0.380081\n",
      "epoch 68; iter: 0; batch classifier loss: 0.051090; batch adversarial loss: 0.339709\n",
      "epoch 69; iter: 0; batch classifier loss: 0.106607; batch adversarial loss: 0.417598\n",
      "epoch 70; iter: 0; batch classifier loss: 0.089584; batch adversarial loss: 0.349362\n",
      "epoch 71; iter: 0; batch classifier loss: 0.106902; batch adversarial loss: 0.447071\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080393; batch adversarial loss: 0.361557\n",
      "epoch 73; iter: 0; batch classifier loss: 0.109121; batch adversarial loss: 0.376768\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081986; batch adversarial loss: 0.445709\n",
      "epoch 75; iter: 0; batch classifier loss: 0.049899; batch adversarial loss: 0.441381\n",
      "epoch 76; iter: 0; batch classifier loss: 0.067384; batch adversarial loss: 0.484200\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062125; batch adversarial loss: 0.384721\n",
      "epoch 78; iter: 0; batch classifier loss: 0.044634; batch adversarial loss: 0.374340\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057194; batch adversarial loss: 0.420119\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056761; batch adversarial loss: 0.402766\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066177; batch adversarial loss: 0.513248\n",
      "epoch 82; iter: 0; batch classifier loss: 0.111521; batch adversarial loss: 0.458223\n",
      "epoch 83; iter: 0; batch classifier loss: 0.067107; batch adversarial loss: 0.442003\n",
      "epoch 84; iter: 0; batch classifier loss: 0.049181; batch adversarial loss: 0.417763\n",
      "epoch 85; iter: 0; batch classifier loss: 0.112934; batch adversarial loss: 0.407820\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062197; batch adversarial loss: 0.373419\n",
      "epoch 87; iter: 0; batch classifier loss: 0.065925; batch adversarial loss: 0.438481\n",
      "epoch 88; iter: 0; batch classifier loss: 0.107658; batch adversarial loss: 0.465622\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065305; batch adversarial loss: 0.390435\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063951; batch adversarial loss: 0.423866\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077598; batch adversarial loss: 0.439432\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060471; batch adversarial loss: 0.369803\n",
      "epoch 93; iter: 0; batch classifier loss: 0.094506; batch adversarial loss: 0.407679\n",
      "epoch 94; iter: 0; batch classifier loss: 0.073864; batch adversarial loss: 0.389407\n",
      "epoch 95; iter: 0; batch classifier loss: 0.091716; batch adversarial loss: 0.373455\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082783; batch adversarial loss: 0.268470\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057128; batch adversarial loss: 0.443330\n",
      "epoch 98; iter: 0; batch classifier loss: 0.088690; batch adversarial loss: 0.421426\n",
      "epoch 99; iter: 0; batch classifier loss: 0.060927; batch adversarial loss: 0.384435\n",
      "epoch 100; iter: 0; batch classifier loss: 0.068982; batch adversarial loss: 0.540894\n",
      "epoch 101; iter: 0; batch classifier loss: 0.069747; batch adversarial loss: 0.353109\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066374; batch adversarial loss: 0.478612\n",
      "epoch 103; iter: 0; batch classifier loss: 0.082324; batch adversarial loss: 0.440673\n",
      "epoch 104; iter: 0; batch classifier loss: 0.125197; batch adversarial loss: 0.378296\n",
      "epoch 105; iter: 0; batch classifier loss: 0.080494; batch adversarial loss: 0.465794\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068246; batch adversarial loss: 0.353761\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072453; batch adversarial loss: 0.423689\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056643; batch adversarial loss: 0.315434\n",
      "epoch 109; iter: 0; batch classifier loss: 0.063748; batch adversarial loss: 0.332823\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043754; batch adversarial loss: 0.345990\n",
      "epoch 111; iter: 0; batch classifier loss: 0.089079; batch adversarial loss: 0.307721\n",
      "epoch 112; iter: 0; batch classifier loss: 0.058365; batch adversarial loss: 0.421297\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035075; batch adversarial loss: 0.405398\n",
      "epoch 114; iter: 0; batch classifier loss: 0.076082; batch adversarial loss: 0.399804\n",
      "epoch 115; iter: 0; batch classifier loss: 0.055669; batch adversarial loss: 0.382732\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052351; batch adversarial loss: 0.391379\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051572; batch adversarial loss: 0.368767\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056091; batch adversarial loss: 0.421761\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038223; batch adversarial loss: 0.353611\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044983; batch adversarial loss: 0.375557\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057480; batch adversarial loss: 0.456256\n",
      "epoch 122; iter: 0; batch classifier loss: 0.060426; batch adversarial loss: 0.448413\n",
      "epoch 123; iter: 0; batch classifier loss: 0.054404; batch adversarial loss: 0.382231\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026840; batch adversarial loss: 0.337873\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054446; batch adversarial loss: 0.390058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.035702; batch adversarial loss: 0.417623\n",
      "epoch 127; iter: 0; batch classifier loss: 0.065744; batch adversarial loss: 0.405679\n",
      "epoch 128; iter: 0; batch classifier loss: 0.048801; batch adversarial loss: 0.357287\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038672; batch adversarial loss: 0.443698\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051447; batch adversarial loss: 0.504308\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035340; batch adversarial loss: 0.386774\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035253; batch adversarial loss: 0.402017\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036911; batch adversarial loss: 0.425703\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052781; batch adversarial loss: 0.376761\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024238; batch adversarial loss: 0.420843\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028021; batch adversarial loss: 0.360866\n",
      "epoch 137; iter: 0; batch classifier loss: 0.056218; batch adversarial loss: 0.479782\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028094; batch adversarial loss: 0.399646\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030092; batch adversarial loss: 0.426156\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033254; batch adversarial loss: 0.406988\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033532; batch adversarial loss: 0.549272\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030948; batch adversarial loss: 0.418762\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027669; batch adversarial loss: 0.451742\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022374; batch adversarial loss: 0.339911\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023295; batch adversarial loss: 0.465213\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048488; batch adversarial loss: 0.556042\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028325; batch adversarial loss: 0.439487\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045722; batch adversarial loss: 0.414382\n",
      "epoch 149; iter: 0; batch classifier loss: 0.045903; batch adversarial loss: 0.374538\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028696; batch adversarial loss: 0.457189\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038062; batch adversarial loss: 0.457876\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017347; batch adversarial loss: 0.345723\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039054; batch adversarial loss: 0.504506\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044510; batch adversarial loss: 0.440356\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014945; batch adversarial loss: 0.541479\n",
      "epoch 156; iter: 0; batch classifier loss: 0.069695; batch adversarial loss: 0.481395\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022088; batch adversarial loss: 0.440239\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029661; batch adversarial loss: 0.407106\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028982; batch adversarial loss: 0.412171\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031669; batch adversarial loss: 0.448533\n",
      "epoch 161; iter: 0; batch classifier loss: 0.045146; batch adversarial loss: 0.473095\n",
      "epoch 162; iter: 0; batch classifier loss: 0.091213; batch adversarial loss: 0.641130\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033159; batch adversarial loss: 0.522883\n",
      "epoch 164; iter: 0; batch classifier loss: 0.049679; batch adversarial loss: 0.481073\n",
      "epoch 165; iter: 0; batch classifier loss: 0.062202; batch adversarial loss: 0.631740\n",
      "epoch 166; iter: 0; batch classifier loss: 0.099186; batch adversarial loss: 0.662877\n",
      "epoch 167; iter: 0; batch classifier loss: 0.146788; batch adversarial loss: 0.593267\n",
      "epoch 168; iter: 0; batch classifier loss: 0.111998; batch adversarial loss: 0.606091\n",
      "epoch 169; iter: 0; batch classifier loss: 0.141299; batch adversarial loss: 0.812907\n",
      "epoch 170; iter: 0; batch classifier loss: 0.112240; batch adversarial loss: 0.584388\n",
      "epoch 171; iter: 0; batch classifier loss: 0.193591; batch adversarial loss: 0.727359\n",
      "epoch 172; iter: 0; batch classifier loss: 0.132298; batch adversarial loss: 0.659526\n",
      "epoch 173; iter: 0; batch classifier loss: 0.149464; batch adversarial loss: 0.589970\n",
      "epoch 174; iter: 0; batch classifier loss: 0.125506; batch adversarial loss: 0.586749\n",
      "epoch 175; iter: 0; batch classifier loss: 0.137907; batch adversarial loss: 0.661449\n",
      "epoch 176; iter: 0; batch classifier loss: 0.113462; batch adversarial loss: 0.589956\n",
      "epoch 177; iter: 0; batch classifier loss: 0.179963; batch adversarial loss: 0.712109\n",
      "epoch 178; iter: 0; batch classifier loss: 0.116032; batch adversarial loss: 0.625362\n",
      "epoch 179; iter: 0; batch classifier loss: 0.128779; batch adversarial loss: 0.533930\n",
      "epoch 180; iter: 0; batch classifier loss: 0.135486; batch adversarial loss: 0.665801\n",
      "epoch 181; iter: 0; batch classifier loss: 0.221465; batch adversarial loss: 0.725896\n",
      "epoch 182; iter: 0; batch classifier loss: 0.215683; batch adversarial loss: 0.757965\n",
      "epoch 183; iter: 0; batch classifier loss: 0.101491; batch adversarial loss: 0.533559\n",
      "epoch 184; iter: 0; batch classifier loss: 0.131685; batch adversarial loss: 0.653304\n",
      "epoch 185; iter: 0; batch classifier loss: 0.156112; batch adversarial loss: 0.666851\n",
      "epoch 186; iter: 0; batch classifier loss: 0.101087; batch adversarial loss: 0.413269\n",
      "epoch 187; iter: 0; batch classifier loss: 0.121543; batch adversarial loss: 0.535808\n",
      "epoch 188; iter: 0; batch classifier loss: 0.141997; batch adversarial loss: 0.620762\n",
      "epoch 189; iter: 0; batch classifier loss: 0.117964; batch adversarial loss: 0.587559\n",
      "epoch 190; iter: 0; batch classifier loss: 0.113068; batch adversarial loss: 0.556939\n",
      "epoch 191; iter: 0; batch classifier loss: 0.187956; batch adversarial loss: 0.657887\n",
      "epoch 192; iter: 0; batch classifier loss: 0.115351; batch adversarial loss: 0.411965\n",
      "epoch 193; iter: 0; batch classifier loss: 0.163734; batch adversarial loss: 0.550615\n",
      "epoch 194; iter: 0; batch classifier loss: 0.190238; batch adversarial loss: 0.709735\n",
      "epoch 195; iter: 0; batch classifier loss: 0.191913; batch adversarial loss: 0.591834\n",
      "epoch 196; iter: 0; batch classifier loss: 0.138891; batch adversarial loss: 0.549604\n",
      "epoch 197; iter: 0; batch classifier loss: 0.232356; batch adversarial loss: 0.710594\n",
      "epoch 198; iter: 0; batch classifier loss: 0.121534; batch adversarial loss: 0.579976\n",
      "epoch 199; iter: 0; batch classifier loss: 0.189990; batch adversarial loss: 0.549009\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695148; batch adversarial loss: 0.730446\n",
      "epoch 1; iter: 0; batch classifier loss: 0.402236; batch adversarial loss: 0.686282\n",
      "epoch 2; iter: 0; batch classifier loss: 0.456939; batch adversarial loss: 0.643623\n",
      "epoch 3; iter: 0; batch classifier loss: 0.467894; batch adversarial loss: 0.603060\n",
      "epoch 4; iter: 0; batch classifier loss: 0.367493; batch adversarial loss: 0.583084\n",
      "epoch 5; iter: 0; batch classifier loss: 0.328919; batch adversarial loss: 0.616033\n",
      "epoch 6; iter: 0; batch classifier loss: 0.404515; batch adversarial loss: 0.557695\n",
      "epoch 7; iter: 0; batch classifier loss: 0.379478; batch adversarial loss: 0.561357\n",
      "epoch 8; iter: 0; batch classifier loss: 0.477091; batch adversarial loss: 0.543217\n",
      "epoch 9; iter: 0; batch classifier loss: 0.476942; batch adversarial loss: 0.521286\n",
      "epoch 10; iter: 0; batch classifier loss: 0.471104; batch adversarial loss: 0.526889\n",
      "epoch 11; iter: 0; batch classifier loss: 0.478822; batch adversarial loss: 0.541622\n",
      "epoch 12; iter: 0; batch classifier loss: 0.440883; batch adversarial loss: 0.527626\n",
      "epoch 13; iter: 0; batch classifier loss: 0.371604; batch adversarial loss: 0.515397\n",
      "epoch 14; iter: 0; batch classifier loss: 0.336181; batch adversarial loss: 0.448076\n",
      "epoch 15; iter: 0; batch classifier loss: 0.343266; batch adversarial loss: 0.454051\n",
      "epoch 16; iter: 0; batch classifier loss: 0.321905; batch adversarial loss: 0.470055\n",
      "epoch 17; iter: 0; batch classifier loss: 0.295698; batch adversarial loss: 0.453694\n",
      "epoch 18; iter: 0; batch classifier loss: 0.341543; batch adversarial loss: 0.585651\n",
      "epoch 19; iter: 0; batch classifier loss: 0.340266; batch adversarial loss: 0.452787\n",
      "epoch 20; iter: 0; batch classifier loss: 0.333020; batch adversarial loss: 0.543608\n",
      "epoch 21; iter: 0; batch classifier loss: 0.304257; batch adversarial loss: 0.495688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.312418; batch adversarial loss: 0.446357\n",
      "epoch 23; iter: 0; batch classifier loss: 0.350795; batch adversarial loss: 0.451706\n",
      "epoch 24; iter: 0; batch classifier loss: 0.236483; batch adversarial loss: 0.524258\n",
      "epoch 25; iter: 0; batch classifier loss: 0.213519; batch adversarial loss: 0.429182\n",
      "epoch 26; iter: 0; batch classifier loss: 0.261291; batch adversarial loss: 0.441870\n",
      "epoch 27; iter: 0; batch classifier loss: 0.217255; batch adversarial loss: 0.455341\n",
      "epoch 28; iter: 0; batch classifier loss: 0.257922; batch adversarial loss: 0.426490\n",
      "epoch 29; iter: 0; batch classifier loss: 0.292657; batch adversarial loss: 0.383261\n",
      "epoch 30; iter: 0; batch classifier loss: 0.293902; batch adversarial loss: 0.470411\n",
      "epoch 31; iter: 0; batch classifier loss: 0.272257; batch adversarial loss: 0.402472\n",
      "epoch 32; iter: 0; batch classifier loss: 0.263168; batch adversarial loss: 0.402242\n",
      "epoch 33; iter: 0; batch classifier loss: 0.220384; batch adversarial loss: 0.416527\n",
      "epoch 34; iter: 0; batch classifier loss: 0.161322; batch adversarial loss: 0.518862\n",
      "epoch 35; iter: 0; batch classifier loss: 0.204565; batch adversarial loss: 0.394032\n",
      "epoch 36; iter: 0; batch classifier loss: 0.231108; batch adversarial loss: 0.529204\n",
      "epoch 37; iter: 0; batch classifier loss: 0.207119; batch adversarial loss: 0.373374\n",
      "epoch 38; iter: 0; batch classifier loss: 0.273946; batch adversarial loss: 0.406717\n",
      "epoch 39; iter: 0; batch classifier loss: 0.237235; batch adversarial loss: 0.439494\n",
      "epoch 40; iter: 0; batch classifier loss: 0.195176; batch adversarial loss: 0.378890\n",
      "epoch 41; iter: 0; batch classifier loss: 0.166776; batch adversarial loss: 0.504217\n",
      "epoch 42; iter: 0; batch classifier loss: 0.167857; batch adversarial loss: 0.528589\n",
      "epoch 43; iter: 0; batch classifier loss: 0.175057; batch adversarial loss: 0.452037\n",
      "epoch 44; iter: 0; batch classifier loss: 0.193442; batch adversarial loss: 0.438697\n",
      "epoch 45; iter: 0; batch classifier loss: 0.209541; batch adversarial loss: 0.442659\n",
      "epoch 46; iter: 0; batch classifier loss: 0.266840; batch adversarial loss: 0.414921\n",
      "epoch 47; iter: 0; batch classifier loss: 0.169450; batch adversarial loss: 0.518968\n",
      "epoch 48; iter: 0; batch classifier loss: 0.210699; batch adversarial loss: 0.489598\n",
      "epoch 49; iter: 0; batch classifier loss: 0.252463; batch adversarial loss: 0.387144\n",
      "epoch 50; iter: 0; batch classifier loss: 0.194797; batch adversarial loss: 0.489306\n",
      "epoch 51; iter: 0; batch classifier loss: 0.188582; batch adversarial loss: 0.494831\n",
      "epoch 52; iter: 0; batch classifier loss: 0.315203; batch adversarial loss: 0.413449\n",
      "epoch 53; iter: 0; batch classifier loss: 0.311945; batch adversarial loss: 0.435193\n",
      "epoch 54; iter: 0; batch classifier loss: 0.215330; batch adversarial loss: 0.448636\n",
      "epoch 55; iter: 0; batch classifier loss: 0.281984; batch adversarial loss: 0.337691\n",
      "epoch 56; iter: 0; batch classifier loss: 0.237392; batch adversarial loss: 0.460187\n",
      "epoch 57; iter: 0; batch classifier loss: 0.237786; batch adversarial loss: 0.473509\n",
      "epoch 58; iter: 0; batch classifier loss: 0.143192; batch adversarial loss: 0.460869\n",
      "epoch 59; iter: 0; batch classifier loss: 0.227285; batch adversarial loss: 0.459213\n",
      "epoch 60; iter: 0; batch classifier loss: 0.316513; batch adversarial loss: 0.360565\n",
      "epoch 61; iter: 0; batch classifier loss: 0.210480; batch adversarial loss: 0.385341\n",
      "epoch 62; iter: 0; batch classifier loss: 0.176755; batch adversarial loss: 0.396955\n",
      "epoch 63; iter: 0; batch classifier loss: 0.130730; batch adversarial loss: 0.582012\n",
      "epoch 64; iter: 0; batch classifier loss: 0.164654; batch adversarial loss: 0.508320\n",
      "epoch 65; iter: 0; batch classifier loss: 0.205332; batch adversarial loss: 0.373429\n",
      "epoch 66; iter: 0; batch classifier loss: 0.168389; batch adversarial loss: 0.420420\n",
      "epoch 67; iter: 0; batch classifier loss: 0.167615; batch adversarial loss: 0.420265\n",
      "epoch 68; iter: 0; batch classifier loss: 0.174120; batch adversarial loss: 0.483482\n",
      "epoch 69; iter: 0; batch classifier loss: 0.217542; batch adversarial loss: 0.459349\n",
      "epoch 70; iter: 0; batch classifier loss: 0.150662; batch adversarial loss: 0.520710\n",
      "epoch 71; iter: 0; batch classifier loss: 0.231272; batch adversarial loss: 0.457833\n",
      "epoch 72; iter: 0; batch classifier loss: 0.228819; batch adversarial loss: 0.446629\n",
      "epoch 73; iter: 0; batch classifier loss: 0.176886; batch adversarial loss: 0.445966\n",
      "epoch 74; iter: 0; batch classifier loss: 0.159918; batch adversarial loss: 0.534670\n",
      "epoch 75; iter: 0; batch classifier loss: 0.271972; batch adversarial loss: 0.384642\n",
      "epoch 76; iter: 0; batch classifier loss: 0.201652; batch adversarial loss: 0.470903\n",
      "epoch 77; iter: 0; batch classifier loss: 0.089692; batch adversarial loss: 0.467878\n",
      "epoch 78; iter: 0; batch classifier loss: 0.208548; batch adversarial loss: 0.433994\n",
      "epoch 79; iter: 0; batch classifier loss: 0.277447; batch adversarial loss: 0.448615\n",
      "epoch 80; iter: 0; batch classifier loss: 0.205492; batch adversarial loss: 0.457883\n",
      "epoch 81; iter: 0; batch classifier loss: 0.154931; batch adversarial loss: 0.510824\n",
      "epoch 82; iter: 0; batch classifier loss: 0.248882; batch adversarial loss: 0.418711\n",
      "epoch 83; iter: 0; batch classifier loss: 0.159191; batch adversarial loss: 0.408195\n",
      "epoch 84; iter: 0; batch classifier loss: 0.237202; batch adversarial loss: 0.509972\n",
      "epoch 85; iter: 0; batch classifier loss: 0.232147; batch adversarial loss: 0.422050\n",
      "epoch 86; iter: 0; batch classifier loss: 0.224419; batch adversarial loss: 0.409521\n",
      "epoch 87; iter: 0; batch classifier loss: 0.188363; batch adversarial loss: 0.371677\n",
      "epoch 88; iter: 0; batch classifier loss: 0.220015; batch adversarial loss: 0.446486\n",
      "epoch 89; iter: 0; batch classifier loss: 0.095449; batch adversarial loss: 0.458090\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054829; batch adversarial loss: 0.432888\n",
      "epoch 91; iter: 0; batch classifier loss: 0.036621; batch adversarial loss: 0.429264\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060571; batch adversarial loss: 0.465480\n",
      "epoch 93; iter: 0; batch classifier loss: 0.080927; batch adversarial loss: 0.327146\n",
      "epoch 94; iter: 0; batch classifier loss: 0.052659; batch adversarial loss: 0.526188\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058162; batch adversarial loss: 0.410041\n",
      "epoch 96; iter: 0; batch classifier loss: 0.071640; batch adversarial loss: 0.433327\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065950; batch adversarial loss: 0.471653\n",
      "epoch 98; iter: 0; batch classifier loss: 0.032408; batch adversarial loss: 0.477747\n",
      "epoch 99; iter: 0; batch classifier loss: 0.088792; batch adversarial loss: 0.458576\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059920; batch adversarial loss: 0.346089\n",
      "epoch 101; iter: 0; batch classifier loss: 0.065064; batch adversarial loss: 0.492993\n",
      "epoch 102; iter: 0; batch classifier loss: 0.065298; batch adversarial loss: 0.346971\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060764; batch adversarial loss: 0.480452\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059285; batch adversarial loss: 0.404094\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064054; batch adversarial loss: 0.464350\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030980; batch adversarial loss: 0.476425\n",
      "epoch 107; iter: 0; batch classifier loss: 0.042308; batch adversarial loss: 0.516390\n",
      "epoch 108; iter: 0; batch classifier loss: 0.081746; batch adversarial loss: 0.509630\n",
      "epoch 109; iter: 0; batch classifier loss: 0.075524; batch adversarial loss: 0.389547\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048799; batch adversarial loss: 0.418832\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029966; batch adversarial loss: 0.392020\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053337; batch adversarial loss: 0.402241\n",
      "epoch 113; iter: 0; batch classifier loss: 0.074856; batch adversarial loss: 0.439895\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026127; batch adversarial loss: 0.475985\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065620; batch adversarial loss: 0.392477\n",
      "epoch 116; iter: 0; batch classifier loss: 0.081506; batch adversarial loss: 0.435862\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046101; batch adversarial loss: 0.333441\n",
      "epoch 118; iter: 0; batch classifier loss: 0.027148; batch adversarial loss: 0.401627\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026061; batch adversarial loss: 0.380065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.046048; batch adversarial loss: 0.487222\n",
      "epoch 121; iter: 0; batch classifier loss: 0.087735; batch adversarial loss: 0.344456\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051651; batch adversarial loss: 0.355184\n",
      "epoch 123; iter: 0; batch classifier loss: 0.099289; batch adversarial loss: 0.502120\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046516; batch adversarial loss: 0.427831\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022863; batch adversarial loss: 0.417840\n",
      "epoch 126; iter: 0; batch classifier loss: 0.090545; batch adversarial loss: 0.426875\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026666; batch adversarial loss: 0.482821\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041222; batch adversarial loss: 0.362777\n",
      "epoch 129; iter: 0; batch classifier loss: 0.044395; batch adversarial loss: 0.429321\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057268; batch adversarial loss: 0.354581\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044490; batch adversarial loss: 0.472944\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040982; batch adversarial loss: 0.383850\n",
      "epoch 133; iter: 0; batch classifier loss: 0.104332; batch adversarial loss: 0.441498\n",
      "epoch 134; iter: 0; batch classifier loss: 0.046230; batch adversarial loss: 0.341651\n",
      "epoch 135; iter: 0; batch classifier loss: 0.054079; batch adversarial loss: 0.507684\n",
      "epoch 136; iter: 0; batch classifier loss: 0.047284; batch adversarial loss: 0.445266\n",
      "epoch 137; iter: 0; batch classifier loss: 0.099453; batch adversarial loss: 0.362571\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045435; batch adversarial loss: 0.436169\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022130; batch adversarial loss: 0.462959\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050028; batch adversarial loss: 0.463444\n",
      "epoch 141; iter: 0; batch classifier loss: 0.054581; batch adversarial loss: 0.415757\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040172; batch adversarial loss: 0.393652\n",
      "epoch 143; iter: 0; batch classifier loss: 0.058536; batch adversarial loss: 0.453690\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048124; batch adversarial loss: 0.394707\n",
      "epoch 145; iter: 0; batch classifier loss: 0.068979; batch adversarial loss: 0.351868\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044887; batch adversarial loss: 0.336707\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023369; batch adversarial loss: 0.340607\n",
      "epoch 148; iter: 0; batch classifier loss: 0.065343; batch adversarial loss: 0.486753\n",
      "epoch 149; iter: 0; batch classifier loss: 0.064301; batch adversarial loss: 0.397657\n",
      "epoch 150; iter: 0; batch classifier loss: 0.068370; batch adversarial loss: 0.450850\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038831; batch adversarial loss: 0.438793\n",
      "epoch 152; iter: 0; batch classifier loss: 0.068322; batch adversarial loss: 0.441753\n",
      "epoch 153; iter: 0; batch classifier loss: 0.067573; batch adversarial loss: 0.426676\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039754; batch adversarial loss: 0.400441\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052428; batch adversarial loss: 0.320367\n",
      "epoch 156; iter: 0; batch classifier loss: 0.048780; batch adversarial loss: 0.401670\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032589; batch adversarial loss: 0.508804\n",
      "epoch 158; iter: 0; batch classifier loss: 0.063251; batch adversarial loss: 0.430360\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032740; batch adversarial loss: 0.447838\n",
      "epoch 160; iter: 0; batch classifier loss: 0.042828; batch adversarial loss: 0.498493\n",
      "epoch 161; iter: 0; batch classifier loss: 0.049043; batch adversarial loss: 0.495989\n",
      "epoch 162; iter: 0; batch classifier loss: 0.061479; batch adversarial loss: 0.391239\n",
      "epoch 163; iter: 0; batch classifier loss: 0.076854; batch adversarial loss: 0.419734\n",
      "epoch 164; iter: 0; batch classifier loss: 0.071935; batch adversarial loss: 0.390931\n",
      "epoch 165; iter: 0; batch classifier loss: 0.054447; batch adversarial loss: 0.391998\n",
      "epoch 166; iter: 0; batch classifier loss: 0.071133; batch adversarial loss: 0.449018\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031887; batch adversarial loss: 0.445505\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023599; batch adversarial loss: 0.366120\n",
      "epoch 169; iter: 0; batch classifier loss: 0.060982; batch adversarial loss: 0.447095\n",
      "epoch 170; iter: 0; batch classifier loss: 0.069506; batch adversarial loss: 0.397341\n",
      "epoch 171; iter: 0; batch classifier loss: 0.046716; batch adversarial loss: 0.382351\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036294; batch adversarial loss: 0.382526\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040886; batch adversarial loss: 0.378236\n",
      "epoch 174; iter: 0; batch classifier loss: 0.045007; batch adversarial loss: 0.554650\n",
      "epoch 175; iter: 0; batch classifier loss: 0.048624; batch adversarial loss: 0.470780\n",
      "epoch 176; iter: 0; batch classifier loss: 0.053085; batch adversarial loss: 0.345433\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019534; batch adversarial loss: 0.414932\n",
      "epoch 178; iter: 0; batch classifier loss: 0.045764; batch adversarial loss: 0.434620\n",
      "epoch 179; iter: 0; batch classifier loss: 0.047951; batch adversarial loss: 0.495913\n",
      "epoch 180; iter: 0; batch classifier loss: 0.055881; batch adversarial loss: 0.399432\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029778; batch adversarial loss: 0.356442\n",
      "epoch 182; iter: 0; batch classifier loss: 0.048373; batch adversarial loss: 0.390587\n",
      "epoch 183; iter: 0; batch classifier loss: 0.053739; batch adversarial loss: 0.549845\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035291; batch adversarial loss: 0.429660\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038921; batch adversarial loss: 0.368997\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033167; batch adversarial loss: 0.446391\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028750; batch adversarial loss: 0.400785\n",
      "epoch 188; iter: 0; batch classifier loss: 0.044945; batch adversarial loss: 0.494129\n",
      "epoch 189; iter: 0; batch classifier loss: 0.062047; batch adversarial loss: 0.366116\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030180; batch adversarial loss: 0.377011\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026339; batch adversarial loss: 0.506672\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020674; batch adversarial loss: 0.440900\n",
      "epoch 193; iter: 0; batch classifier loss: 0.036943; batch adversarial loss: 0.418376\n",
      "epoch 194; iter: 0; batch classifier loss: 0.047941; batch adversarial loss: 0.471157\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036679; batch adversarial loss: 0.402584\n",
      "epoch 196; iter: 0; batch classifier loss: 0.056929; batch adversarial loss: 0.439698\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033738; batch adversarial loss: 0.424213\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037395; batch adversarial loss: 0.318228\n",
      "epoch 199; iter: 0; batch classifier loss: 0.069268; batch adversarial loss: 0.378928\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694432; batch adversarial loss: 0.842719\n",
      "epoch 1; iter: 0; batch classifier loss: 0.501223; batch adversarial loss: 0.830438\n",
      "epoch 2; iter: 0; batch classifier loss: 0.403487; batch adversarial loss: 0.748010\n",
      "epoch 3; iter: 0; batch classifier loss: 0.397487; batch adversarial loss: 0.712794\n",
      "epoch 4; iter: 0; batch classifier loss: 0.435337; batch adversarial loss: 0.654942\n",
      "epoch 5; iter: 0; batch classifier loss: 0.454261; batch adversarial loss: 0.607500\n",
      "epoch 6; iter: 0; batch classifier loss: 0.451327; batch adversarial loss: 0.591928\n",
      "epoch 7; iter: 0; batch classifier loss: 0.249080; batch adversarial loss: 0.551114\n",
      "epoch 8; iter: 0; batch classifier loss: 0.317780; batch adversarial loss: 0.549782\n",
      "epoch 9; iter: 0; batch classifier loss: 0.265991; batch adversarial loss: 0.520712\n",
      "epoch 10; iter: 0; batch classifier loss: 0.246043; batch adversarial loss: 0.527215\n",
      "epoch 11; iter: 0; batch classifier loss: 0.253222; batch adversarial loss: 0.493449\n",
      "epoch 12; iter: 0; batch classifier loss: 0.234465; batch adversarial loss: 0.472034\n",
      "epoch 13; iter: 0; batch classifier loss: 0.269950; batch adversarial loss: 0.502376\n",
      "epoch 14; iter: 0; batch classifier loss: 0.226176; batch adversarial loss: 0.547852\n",
      "epoch 15; iter: 0; batch classifier loss: 0.191591; batch adversarial loss: 0.526625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.150963; batch adversarial loss: 0.448703\n",
      "epoch 17; iter: 0; batch classifier loss: 0.214717; batch adversarial loss: 0.453372\n",
      "epoch 18; iter: 0; batch classifier loss: 0.185062; batch adversarial loss: 0.498822\n",
      "epoch 19; iter: 0; batch classifier loss: 0.149346; batch adversarial loss: 0.507742\n",
      "epoch 20; iter: 0; batch classifier loss: 0.188943; batch adversarial loss: 0.479888\n",
      "epoch 21; iter: 0; batch classifier loss: 0.230385; batch adversarial loss: 0.505270\n",
      "epoch 22; iter: 0; batch classifier loss: 0.202796; batch adversarial loss: 0.517755\n",
      "epoch 23; iter: 0; batch classifier loss: 0.274123; batch adversarial loss: 0.475478\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280832; batch adversarial loss: 0.459509\n",
      "epoch 25; iter: 0; batch classifier loss: 0.211697; batch adversarial loss: 0.451075\n",
      "epoch 26; iter: 0; batch classifier loss: 0.188656; batch adversarial loss: 0.461092\n",
      "epoch 27; iter: 0; batch classifier loss: 0.299311; batch adversarial loss: 0.416653\n",
      "epoch 28; iter: 0; batch classifier loss: 0.201348; batch adversarial loss: 0.447161\n",
      "epoch 29; iter: 0; batch classifier loss: 0.189060; batch adversarial loss: 0.445797\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144389; batch adversarial loss: 0.381159\n",
      "epoch 31; iter: 0; batch classifier loss: 0.144495; batch adversarial loss: 0.467241\n",
      "epoch 32; iter: 0; batch classifier loss: 0.105236; batch adversarial loss: 0.491463\n",
      "epoch 33; iter: 0; batch classifier loss: 0.129864; batch adversarial loss: 0.496153\n",
      "epoch 34; iter: 0; batch classifier loss: 0.124940; batch adversarial loss: 0.498277\n",
      "epoch 35; iter: 0; batch classifier loss: 0.152949; batch adversarial loss: 0.410061\n",
      "epoch 36; iter: 0; batch classifier loss: 0.178472; batch adversarial loss: 0.456471\n",
      "epoch 37; iter: 0; batch classifier loss: 0.134099; batch adversarial loss: 0.541860\n",
      "epoch 38; iter: 0; batch classifier loss: 0.143267; batch adversarial loss: 0.484437\n",
      "epoch 39; iter: 0; batch classifier loss: 0.104609; batch adversarial loss: 0.436006\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091171; batch adversarial loss: 0.526596\n",
      "epoch 41; iter: 0; batch classifier loss: 0.160185; batch adversarial loss: 0.466957\n",
      "epoch 42; iter: 0; batch classifier loss: 0.114179; batch adversarial loss: 0.457551\n",
      "epoch 43; iter: 0; batch classifier loss: 0.120225; batch adversarial loss: 0.490651\n",
      "epoch 44; iter: 0; batch classifier loss: 0.139298; batch adversarial loss: 0.427893\n",
      "epoch 45; iter: 0; batch classifier loss: 0.139548; batch adversarial loss: 0.465628\n",
      "epoch 46; iter: 0; batch classifier loss: 0.103136; batch adversarial loss: 0.313553\n",
      "epoch 47; iter: 0; batch classifier loss: 0.152322; batch adversarial loss: 0.421985\n",
      "epoch 48; iter: 0; batch classifier loss: 0.071328; batch adversarial loss: 0.441216\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119198; batch adversarial loss: 0.438763\n",
      "epoch 50; iter: 0; batch classifier loss: 0.135795; batch adversarial loss: 0.458624\n",
      "epoch 51; iter: 0; batch classifier loss: 0.117617; batch adversarial loss: 0.378361\n",
      "epoch 52; iter: 0; batch classifier loss: 0.126674; batch adversarial loss: 0.452274\n",
      "epoch 53; iter: 0; batch classifier loss: 0.105400; batch adversarial loss: 0.423274\n",
      "epoch 54; iter: 0; batch classifier loss: 0.068578; batch adversarial loss: 0.474841\n",
      "epoch 55; iter: 0; batch classifier loss: 0.074432; batch adversarial loss: 0.475842\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098952; batch adversarial loss: 0.414785\n",
      "epoch 57; iter: 0; batch classifier loss: 0.144796; batch adversarial loss: 0.499682\n",
      "epoch 58; iter: 0; batch classifier loss: 0.151065; batch adversarial loss: 0.535850\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083214; batch adversarial loss: 0.475324\n",
      "epoch 60; iter: 0; batch classifier loss: 0.098297; batch adversarial loss: 0.434889\n",
      "epoch 61; iter: 0; batch classifier loss: 0.127526; batch adversarial loss: 0.384862\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085802; batch adversarial loss: 0.390855\n",
      "epoch 63; iter: 0; batch classifier loss: 0.080418; batch adversarial loss: 0.434533\n",
      "epoch 64; iter: 0; batch classifier loss: 0.066618; batch adversarial loss: 0.429182\n",
      "epoch 65; iter: 0; batch classifier loss: 0.103180; batch adversarial loss: 0.491060\n",
      "epoch 66; iter: 0; batch classifier loss: 0.093818; batch adversarial loss: 0.431311\n",
      "epoch 67; iter: 0; batch classifier loss: 0.126865; batch adversarial loss: 0.447225\n",
      "epoch 68; iter: 0; batch classifier loss: 0.077886; batch adversarial loss: 0.496039\n",
      "epoch 69; iter: 0; batch classifier loss: 0.082693; batch adversarial loss: 0.513215\n",
      "epoch 70; iter: 0; batch classifier loss: 0.150244; batch adversarial loss: 0.445047\n",
      "epoch 71; iter: 0; batch classifier loss: 0.062930; batch adversarial loss: 0.493671\n",
      "epoch 72; iter: 0; batch classifier loss: 0.047126; batch adversarial loss: 0.401399\n",
      "epoch 73; iter: 0; batch classifier loss: 0.118891; batch adversarial loss: 0.420031\n",
      "epoch 74; iter: 0; batch classifier loss: 0.100031; batch adversarial loss: 0.446862\n",
      "epoch 75; iter: 0; batch classifier loss: 0.078475; batch adversarial loss: 0.349661\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069187; batch adversarial loss: 0.396178\n",
      "epoch 77; iter: 0; batch classifier loss: 0.080769; batch adversarial loss: 0.379823\n",
      "epoch 78; iter: 0; batch classifier loss: 0.121632; batch adversarial loss: 0.482456\n",
      "epoch 79; iter: 0; batch classifier loss: 0.048464; batch adversarial loss: 0.543600\n",
      "epoch 80; iter: 0; batch classifier loss: 0.052839; batch adversarial loss: 0.544165\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083414; batch adversarial loss: 0.535032\n",
      "epoch 82; iter: 0; batch classifier loss: 0.058756; batch adversarial loss: 0.474082\n",
      "epoch 83; iter: 0; batch classifier loss: 0.093326; batch adversarial loss: 0.445704\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046046; batch adversarial loss: 0.402212\n",
      "epoch 85; iter: 0; batch classifier loss: 0.050719; batch adversarial loss: 0.421832\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070482; batch adversarial loss: 0.456883\n",
      "epoch 87; iter: 0; batch classifier loss: 0.090395; batch adversarial loss: 0.403949\n",
      "epoch 88; iter: 0; batch classifier loss: 0.053539; batch adversarial loss: 0.384405\n",
      "epoch 89; iter: 0; batch classifier loss: 0.067004; batch adversarial loss: 0.465023\n",
      "epoch 90; iter: 0; batch classifier loss: 0.028076; batch adversarial loss: 0.421829\n",
      "epoch 91; iter: 0; batch classifier loss: 0.069099; batch adversarial loss: 0.518159\n",
      "epoch 92; iter: 0; batch classifier loss: 0.036164; batch adversarial loss: 0.423040\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054550; batch adversarial loss: 0.493818\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050086; batch adversarial loss: 0.497270\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064174; batch adversarial loss: 0.353913\n",
      "epoch 96; iter: 0; batch classifier loss: 0.029200; batch adversarial loss: 0.361916\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052840; batch adversarial loss: 0.345676\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059458; batch adversarial loss: 0.483940\n",
      "epoch 99; iter: 0; batch classifier loss: 0.060017; batch adversarial loss: 0.480211\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036379; batch adversarial loss: 0.368638\n",
      "epoch 101; iter: 0; batch classifier loss: 0.034559; batch adversarial loss: 0.494776\n",
      "epoch 102; iter: 0; batch classifier loss: 0.084284; batch adversarial loss: 0.419664\n",
      "epoch 103; iter: 0; batch classifier loss: 0.088926; batch adversarial loss: 0.383272\n",
      "epoch 104; iter: 0; batch classifier loss: 0.096461; batch adversarial loss: 0.453552\n",
      "epoch 105; iter: 0; batch classifier loss: 0.067054; batch adversarial loss: 0.459248\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062336; batch adversarial loss: 0.524523\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059802; batch adversarial loss: 0.483052\n",
      "epoch 108; iter: 0; batch classifier loss: 0.017499; batch adversarial loss: 0.585106\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026554; batch adversarial loss: 0.484851\n",
      "epoch 110; iter: 0; batch classifier loss: 0.073396; batch adversarial loss: 0.372833\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047940; batch adversarial loss: 0.443696\n",
      "epoch 112; iter: 0; batch classifier loss: 0.064565; batch adversarial loss: 0.429872\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028652; batch adversarial loss: 0.435500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.057898; batch adversarial loss: 0.430214\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024568; batch adversarial loss: 0.380555\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055160; batch adversarial loss: 0.438767\n",
      "epoch 117; iter: 0; batch classifier loss: 0.024290; batch adversarial loss: 0.465535\n",
      "epoch 118; iter: 0; batch classifier loss: 0.015396; batch adversarial loss: 0.433559\n",
      "epoch 119; iter: 0; batch classifier loss: 0.020594; batch adversarial loss: 0.559654\n",
      "epoch 120; iter: 0; batch classifier loss: 0.014649; batch adversarial loss: 0.598574\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032013; batch adversarial loss: 0.426295\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031054; batch adversarial loss: 0.488325\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041333; batch adversarial loss: 0.526961\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036539; batch adversarial loss: 0.478241\n",
      "epoch 125; iter: 0; batch classifier loss: 0.015616; batch adversarial loss: 0.507635\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037334; batch adversarial loss: 0.400162\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039416; batch adversarial loss: 0.386596\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028601; batch adversarial loss: 0.402296\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032013; batch adversarial loss: 0.491648\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021948; batch adversarial loss: 0.514068\n",
      "epoch 131; iter: 0; batch classifier loss: 0.081928; batch adversarial loss: 0.489063\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050738; batch adversarial loss: 0.354737\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049638; batch adversarial loss: 0.404107\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045437; batch adversarial loss: 0.453531\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018175; batch adversarial loss: 0.375388\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031425; batch adversarial loss: 0.509961\n",
      "epoch 137; iter: 0; batch classifier loss: 0.066039; batch adversarial loss: 0.526853\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035168; batch adversarial loss: 0.491727\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029956; batch adversarial loss: 0.388393\n",
      "epoch 140; iter: 0; batch classifier loss: 0.064195; batch adversarial loss: 0.438135\n",
      "epoch 141; iter: 0; batch classifier loss: 0.066140; batch adversarial loss: 0.411895\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050999; batch adversarial loss: 0.469420\n",
      "epoch 143; iter: 0; batch classifier loss: 0.057446; batch adversarial loss: 0.484902\n",
      "epoch 144; iter: 0; batch classifier loss: 0.065509; batch adversarial loss: 0.412647\n",
      "epoch 145; iter: 0; batch classifier loss: 0.049838; batch adversarial loss: 0.405872\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025495; batch adversarial loss: 0.464179\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042462; batch adversarial loss: 0.475529\n",
      "epoch 148; iter: 0; batch classifier loss: 0.052766; batch adversarial loss: 0.341915\n",
      "epoch 149; iter: 0; batch classifier loss: 0.003769; batch adversarial loss: 0.455610\n",
      "epoch 150; iter: 0; batch classifier loss: 0.046814; batch adversarial loss: 0.402557\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012297; batch adversarial loss: 0.406841\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029854; batch adversarial loss: 0.416446\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019989; batch adversarial loss: 0.515800\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029039; batch adversarial loss: 0.503995\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012460; batch adversarial loss: 0.455198\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017656; batch adversarial loss: 0.393004\n",
      "epoch 157; iter: 0; batch classifier loss: 0.050254; batch adversarial loss: 0.450660\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023941; batch adversarial loss: 0.492025\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025214; batch adversarial loss: 0.507533\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021761; batch adversarial loss: 0.509652\n",
      "epoch 161; iter: 0; batch classifier loss: 0.044363; batch adversarial loss: 0.515926\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037836; batch adversarial loss: 0.374885\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012407; batch adversarial loss: 0.466990\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016310; batch adversarial loss: 0.510773\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035749; batch adversarial loss: 0.438758\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010357; batch adversarial loss: 0.526911\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022107; batch adversarial loss: 0.400679\n",
      "epoch 168; iter: 0; batch classifier loss: 0.046334; batch adversarial loss: 0.558418\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038217; batch adversarial loss: 0.505213\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032046; batch adversarial loss: 0.488519\n",
      "epoch 171; iter: 0; batch classifier loss: 0.037738; batch adversarial loss: 0.464002\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012862; batch adversarial loss: 0.423794\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023381; batch adversarial loss: 0.420704\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040696; batch adversarial loss: 0.428712\n",
      "epoch 175; iter: 0; batch classifier loss: 0.043699; batch adversarial loss: 0.447375\n",
      "epoch 176; iter: 0; batch classifier loss: 0.060158; batch adversarial loss: 0.443064\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022716; batch adversarial loss: 0.432272\n",
      "epoch 178; iter: 0; batch classifier loss: 0.053084; batch adversarial loss: 0.466608\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007853; batch adversarial loss: 0.463819\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017733; batch adversarial loss: 0.458691\n",
      "epoch 181; iter: 0; batch classifier loss: 0.031989; batch adversarial loss: 0.470234\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017073; batch adversarial loss: 0.430324\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017978; batch adversarial loss: 0.464154\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028349; batch adversarial loss: 0.503103\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017030; batch adversarial loss: 0.429337\n",
      "epoch 186; iter: 0; batch classifier loss: 0.062543; batch adversarial loss: 0.377822\n",
      "epoch 187; iter: 0; batch classifier loss: 0.054113; batch adversarial loss: 0.407472\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019770; batch adversarial loss: 0.483957\n",
      "epoch 189; iter: 0; batch classifier loss: 0.054277; batch adversarial loss: 0.378350\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014199; batch adversarial loss: 0.448329\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022756; batch adversarial loss: 0.427621\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022331; batch adversarial loss: 0.414126\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025386; batch adversarial loss: 0.490707\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020302; batch adversarial loss: 0.345706\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020075; batch adversarial loss: 0.393572\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020349; batch adversarial loss: 0.584385\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039417; batch adversarial loss: 0.384007\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013670; batch adversarial loss: 0.382770\n",
      "epoch 199; iter: 0; batch classifier loss: 0.037728; batch adversarial loss: 0.481143\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695359; batch adversarial loss: 0.798972\n",
      "epoch 1; iter: 0; batch classifier loss: 0.510771; batch adversarial loss: 0.746332\n",
      "epoch 2; iter: 0; batch classifier loss: 0.388486; batch adversarial loss: 0.705678\n",
      "epoch 3; iter: 0; batch classifier loss: 0.371330; batch adversarial loss: 0.694099\n",
      "epoch 4; iter: 0; batch classifier loss: 0.353618; batch adversarial loss: 0.646816\n",
      "epoch 5; iter: 0; batch classifier loss: 0.334912; batch adversarial loss: 0.636512\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331943; batch adversarial loss: 0.562330\n",
      "epoch 7; iter: 0; batch classifier loss: 0.296965; batch adversarial loss: 0.536226\n",
      "epoch 8; iter: 0; batch classifier loss: 0.295649; batch adversarial loss: 0.542426\n",
      "epoch 9; iter: 0; batch classifier loss: 0.233117; batch adversarial loss: 0.511947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.314945; batch adversarial loss: 0.474706\n",
      "epoch 11; iter: 0; batch classifier loss: 0.222355; batch adversarial loss: 0.474231\n",
      "epoch 12; iter: 0; batch classifier loss: 0.263344; batch adversarial loss: 0.425539\n",
      "epoch 13; iter: 0; batch classifier loss: 0.206483; batch adversarial loss: 0.451334\n",
      "epoch 14; iter: 0; batch classifier loss: 0.231729; batch adversarial loss: 0.463973\n",
      "epoch 15; iter: 0; batch classifier loss: 0.191177; batch adversarial loss: 0.373976\n",
      "epoch 16; iter: 0; batch classifier loss: 0.285875; batch adversarial loss: 0.460637\n",
      "epoch 17; iter: 0; batch classifier loss: 0.181491; batch adversarial loss: 0.428615\n",
      "epoch 18; iter: 0; batch classifier loss: 0.221014; batch adversarial loss: 0.413538\n",
      "epoch 19; iter: 0; batch classifier loss: 0.212871; batch adversarial loss: 0.431246\n",
      "epoch 20; iter: 0; batch classifier loss: 0.251547; batch adversarial loss: 0.398542\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186416; batch adversarial loss: 0.383023\n",
      "epoch 22; iter: 0; batch classifier loss: 0.190324; batch adversarial loss: 0.389434\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171399; batch adversarial loss: 0.378485\n",
      "epoch 24; iter: 0; batch classifier loss: 0.210247; batch adversarial loss: 0.399064\n",
      "epoch 25; iter: 0; batch classifier loss: 0.178695; batch adversarial loss: 0.356165\n",
      "epoch 26; iter: 0; batch classifier loss: 0.196418; batch adversarial loss: 0.426975\n",
      "epoch 27; iter: 0; batch classifier loss: 0.193650; batch adversarial loss: 0.422455\n",
      "epoch 28; iter: 0; batch classifier loss: 0.128378; batch adversarial loss: 0.383489\n",
      "epoch 29; iter: 0; batch classifier loss: 0.167971; batch adversarial loss: 0.356009\n",
      "epoch 30; iter: 0; batch classifier loss: 0.124567; batch adversarial loss: 0.346797\n",
      "epoch 31; iter: 0; batch classifier loss: 0.153299; batch adversarial loss: 0.455039\n",
      "epoch 32; iter: 0; batch classifier loss: 0.156963; batch adversarial loss: 0.400510\n",
      "epoch 33; iter: 0; batch classifier loss: 0.136884; batch adversarial loss: 0.335826\n",
      "epoch 34; iter: 0; batch classifier loss: 0.128816; batch adversarial loss: 0.413672\n",
      "epoch 35; iter: 0; batch classifier loss: 0.150088; batch adversarial loss: 0.348653\n",
      "epoch 36; iter: 0; batch classifier loss: 0.154691; batch adversarial loss: 0.370603\n",
      "epoch 37; iter: 0; batch classifier loss: 0.213246; batch adversarial loss: 0.391333\n",
      "epoch 38; iter: 0; batch classifier loss: 0.089886; batch adversarial loss: 0.396781\n",
      "epoch 39; iter: 0; batch classifier loss: 0.082848; batch adversarial loss: 0.453802\n",
      "epoch 40; iter: 0; batch classifier loss: 0.165711; batch adversarial loss: 0.480487\n",
      "epoch 41; iter: 0; batch classifier loss: 0.118308; batch adversarial loss: 0.431713\n",
      "epoch 42; iter: 0; batch classifier loss: 0.139647; batch adversarial loss: 0.425587\n",
      "epoch 43; iter: 0; batch classifier loss: 0.131050; batch adversarial loss: 0.384194\n",
      "epoch 44; iter: 0; batch classifier loss: 0.117211; batch adversarial loss: 0.529669\n",
      "epoch 45; iter: 0; batch classifier loss: 0.119350; batch adversarial loss: 0.472762\n",
      "epoch 46; iter: 0; batch classifier loss: 0.085348; batch adversarial loss: 0.420570\n",
      "epoch 47; iter: 0; batch classifier loss: 0.101928; batch adversarial loss: 0.375569\n",
      "epoch 48; iter: 0; batch classifier loss: 0.106601; batch adversarial loss: 0.421052\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119978; batch adversarial loss: 0.399013\n",
      "epoch 50; iter: 0; batch classifier loss: 0.093678; batch adversarial loss: 0.408117\n",
      "epoch 51; iter: 0; batch classifier loss: 0.105543; batch adversarial loss: 0.452948\n",
      "epoch 52; iter: 0; batch classifier loss: 0.118030; batch adversarial loss: 0.440805\n",
      "epoch 53; iter: 0; batch classifier loss: 0.077457; batch adversarial loss: 0.441790\n",
      "epoch 54; iter: 0; batch classifier loss: 0.081051; batch adversarial loss: 0.487019\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087369; batch adversarial loss: 0.463099\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103583; batch adversarial loss: 0.432707\n",
      "epoch 57; iter: 0; batch classifier loss: 0.039544; batch adversarial loss: 0.387370\n",
      "epoch 58; iter: 0; batch classifier loss: 0.109794; batch adversarial loss: 0.401450\n",
      "epoch 59; iter: 0; batch classifier loss: 0.071676; batch adversarial loss: 0.432929\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081035; batch adversarial loss: 0.407741\n",
      "epoch 61; iter: 0; batch classifier loss: 0.073326; batch adversarial loss: 0.380251\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094390; batch adversarial loss: 0.353573\n",
      "epoch 63; iter: 0; batch classifier loss: 0.114798; batch adversarial loss: 0.532300\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080250; batch adversarial loss: 0.387078\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075223; batch adversarial loss: 0.410585\n",
      "epoch 66; iter: 0; batch classifier loss: 0.065742; batch adversarial loss: 0.406983\n",
      "epoch 67; iter: 0; batch classifier loss: 0.060330; batch adversarial loss: 0.453584\n",
      "epoch 68; iter: 0; batch classifier loss: 0.064202; batch adversarial loss: 0.405397\n",
      "epoch 69; iter: 0; batch classifier loss: 0.079263; batch adversarial loss: 0.368077\n",
      "epoch 70; iter: 0; batch classifier loss: 0.071282; batch adversarial loss: 0.438500\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078989; batch adversarial loss: 0.454389\n",
      "epoch 72; iter: 0; batch classifier loss: 0.058591; batch adversarial loss: 0.377386\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047896; batch adversarial loss: 0.415372\n",
      "epoch 74; iter: 0; batch classifier loss: 0.098252; batch adversarial loss: 0.359821\n",
      "epoch 75; iter: 0; batch classifier loss: 0.072689; batch adversarial loss: 0.371870\n",
      "epoch 76; iter: 0; batch classifier loss: 0.092568; batch adversarial loss: 0.419551\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076559; batch adversarial loss: 0.494322\n",
      "epoch 78; iter: 0; batch classifier loss: 0.041530; batch adversarial loss: 0.395907\n",
      "epoch 79; iter: 0; batch classifier loss: 0.078435; batch adversarial loss: 0.382664\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060911; batch adversarial loss: 0.444566\n",
      "epoch 81; iter: 0; batch classifier loss: 0.070254; batch adversarial loss: 0.319756\n",
      "epoch 82; iter: 0; batch classifier loss: 0.061384; batch adversarial loss: 0.410094\n",
      "epoch 83; iter: 0; batch classifier loss: 0.058017; batch adversarial loss: 0.397178\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052631; batch adversarial loss: 0.371991\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064050; batch adversarial loss: 0.426007\n",
      "epoch 86; iter: 0; batch classifier loss: 0.060994; batch adversarial loss: 0.415447\n",
      "epoch 87; iter: 0; batch classifier loss: 0.058836; batch adversarial loss: 0.493416\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049383; batch adversarial loss: 0.397398\n",
      "epoch 89; iter: 0; batch classifier loss: 0.079164; batch adversarial loss: 0.367321\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059257; batch adversarial loss: 0.399310\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066583; batch adversarial loss: 0.277667\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058487; batch adversarial loss: 0.365547\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069401; batch adversarial loss: 0.476452\n",
      "epoch 94; iter: 0; batch classifier loss: 0.071915; batch adversarial loss: 0.337853\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038327; batch adversarial loss: 0.414655\n",
      "epoch 96; iter: 0; batch classifier loss: 0.034956; batch adversarial loss: 0.370150\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073070; batch adversarial loss: 0.478736\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039289; batch adversarial loss: 0.445992\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074848; batch adversarial loss: 0.384047\n",
      "epoch 100; iter: 0; batch classifier loss: 0.063683; batch adversarial loss: 0.373817\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057617; batch adversarial loss: 0.432232\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060075; batch adversarial loss: 0.470126\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059869; batch adversarial loss: 0.443097\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033407; batch adversarial loss: 0.423760\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049108; batch adversarial loss: 0.376571\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035629; batch adversarial loss: 0.411883\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044866; batch adversarial loss: 0.309861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.093635; batch adversarial loss: 0.490332\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051220; batch adversarial loss: 0.365982\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036766; batch adversarial loss: 0.391450\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064289; batch adversarial loss: 0.435267\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024440; batch adversarial loss: 0.374966\n",
      "epoch 113; iter: 0; batch classifier loss: 0.071898; batch adversarial loss: 0.437659\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048366; batch adversarial loss: 0.354493\n",
      "epoch 115; iter: 0; batch classifier loss: 0.030100; batch adversarial loss: 0.506228\n",
      "epoch 116; iter: 0; batch classifier loss: 0.064580; batch adversarial loss: 0.524225\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061779; batch adversarial loss: 0.481927\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047163; batch adversarial loss: 0.432829\n",
      "epoch 119; iter: 0; batch classifier loss: 0.027442; batch adversarial loss: 0.392937\n",
      "epoch 120; iter: 0; batch classifier loss: 0.024967; batch adversarial loss: 0.367181\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027557; batch adversarial loss: 0.426195\n",
      "epoch 122; iter: 0; batch classifier loss: 0.068529; batch adversarial loss: 0.483437\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045375; batch adversarial loss: 0.465420\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031012; batch adversarial loss: 0.437820\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058882; batch adversarial loss: 0.356943\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057918; batch adversarial loss: 0.445186\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045243; batch adversarial loss: 0.476469\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017671; batch adversarial loss: 0.432089\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048077; batch adversarial loss: 0.400807\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047323; batch adversarial loss: 0.409455\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029623; batch adversarial loss: 0.457229\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033461; batch adversarial loss: 0.468051\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022629; batch adversarial loss: 0.468308\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037202; batch adversarial loss: 0.373224\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028722; batch adversarial loss: 0.400433\n",
      "epoch 136; iter: 0; batch classifier loss: 0.053428; batch adversarial loss: 0.442653\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032884; batch adversarial loss: 0.430468\n",
      "epoch 138; iter: 0; batch classifier loss: 0.054111; batch adversarial loss: 0.376853\n",
      "epoch 139; iter: 0; batch classifier loss: 0.027087; batch adversarial loss: 0.428424\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025369; batch adversarial loss: 0.450267\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017779; batch adversarial loss: 0.419128\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028789; batch adversarial loss: 0.517643\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022603; batch adversarial loss: 0.462190\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020501; batch adversarial loss: 0.518111\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031646; batch adversarial loss: 0.480105\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010207; batch adversarial loss: 0.437539\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039563; batch adversarial loss: 0.453057\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034252; batch adversarial loss: 0.341092\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015682; batch adversarial loss: 0.443802\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021452; batch adversarial loss: 0.505996\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022100; batch adversarial loss: 0.407959\n",
      "epoch 152; iter: 0; batch classifier loss: 0.066214; batch adversarial loss: 0.352050\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014182; batch adversarial loss: 0.390718\n",
      "epoch 154; iter: 0; batch classifier loss: 0.051566; batch adversarial loss: 0.476296\n",
      "epoch 155; iter: 0; batch classifier loss: 0.054134; batch adversarial loss: 0.447342\n",
      "epoch 156; iter: 0; batch classifier loss: 0.064455; batch adversarial loss: 0.481272\n",
      "epoch 157; iter: 0; batch classifier loss: 0.047493; batch adversarial loss: 0.495771\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020618; batch adversarial loss: 0.459594\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049347; batch adversarial loss: 0.462077\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031022; batch adversarial loss: 0.613992\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018681; batch adversarial loss: 0.449386\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041266; batch adversarial loss: 0.430955\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024262; batch adversarial loss: 0.394953\n",
      "epoch 164; iter: 0; batch classifier loss: 0.141847; batch adversarial loss: 0.703495\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025050; batch adversarial loss: 0.530430\n",
      "epoch 166; iter: 0; batch classifier loss: 0.058880; batch adversarial loss: 0.559988\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042748; batch adversarial loss: 0.339603\n",
      "epoch 168; iter: 0; batch classifier loss: 0.060775; batch adversarial loss: 0.521763\n",
      "epoch 169; iter: 0; batch classifier loss: 0.105034; batch adversarial loss: 0.581888\n",
      "epoch 170; iter: 0; batch classifier loss: 0.061111; batch adversarial loss: 0.578231\n",
      "epoch 171; iter: 0; batch classifier loss: 0.109842; batch adversarial loss: 0.664703\n",
      "epoch 172; iter: 0; batch classifier loss: 0.080211; batch adversarial loss: 0.545652\n",
      "epoch 173; iter: 0; batch classifier loss: 0.198123; batch adversarial loss: 0.862634\n",
      "epoch 174; iter: 0; batch classifier loss: 0.102667; batch adversarial loss: 0.681365\n",
      "epoch 175; iter: 0; batch classifier loss: 0.158628; batch adversarial loss: 0.622298\n",
      "epoch 176; iter: 0; batch classifier loss: 0.171062; batch adversarial loss: 0.681538\n",
      "epoch 177; iter: 0; batch classifier loss: 0.171571; batch adversarial loss: 0.767355\n",
      "epoch 178; iter: 0; batch classifier loss: 0.166054; batch adversarial loss: 0.756892\n",
      "epoch 179; iter: 0; batch classifier loss: 0.179239; batch adversarial loss: 0.657443\n",
      "epoch 180; iter: 0; batch classifier loss: 0.098047; batch adversarial loss: 0.568974\n",
      "epoch 181; iter: 0; batch classifier loss: 0.306899; batch adversarial loss: 0.829728\n",
      "epoch 182; iter: 0; batch classifier loss: 0.136785; batch adversarial loss: 0.677309\n",
      "epoch 183; iter: 0; batch classifier loss: 0.187998; batch adversarial loss: 0.682347\n",
      "epoch 184; iter: 0; batch classifier loss: 0.183247; batch adversarial loss: 0.666669\n",
      "epoch 185; iter: 0; batch classifier loss: 0.127334; batch adversarial loss: 0.639700\n",
      "epoch 186; iter: 0; batch classifier loss: 0.166611; batch adversarial loss: 0.679422\n",
      "epoch 187; iter: 0; batch classifier loss: 0.119560; batch adversarial loss: 0.616973\n",
      "epoch 188; iter: 0; batch classifier loss: 0.207028; batch adversarial loss: 0.719334\n",
      "epoch 189; iter: 0; batch classifier loss: 0.112047; batch adversarial loss: 0.558190\n",
      "epoch 190; iter: 0; batch classifier loss: 0.127622; batch adversarial loss: 0.480325\n",
      "epoch 191; iter: 0; batch classifier loss: 0.116482; batch adversarial loss: 0.579371\n",
      "epoch 192; iter: 0; batch classifier loss: 0.156883; batch adversarial loss: 0.627282\n",
      "epoch 193; iter: 0; batch classifier loss: 0.103362; batch adversarial loss: 0.558053\n",
      "epoch 194; iter: 0; batch classifier loss: 0.177874; batch adversarial loss: 0.655759\n",
      "epoch 195; iter: 0; batch classifier loss: 0.180723; batch adversarial loss: 0.526147\n",
      "epoch 196; iter: 0; batch classifier loss: 0.207932; batch adversarial loss: 0.714364\n",
      "epoch 197; iter: 0; batch classifier loss: 0.188370; batch adversarial loss: 0.687928\n",
      "epoch 198; iter: 0; batch classifier loss: 0.157557; batch adversarial loss: 0.570728\n",
      "epoch 199; iter: 0; batch classifier loss: 0.220452; batch adversarial loss: 0.611393\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698911; batch adversarial loss: 0.672693\n",
      "epoch 1; iter: 0; batch classifier loss: 0.449121; batch adversarial loss: 0.664569\n",
      "epoch 2; iter: 0; batch classifier loss: 0.531117; batch adversarial loss: 0.603243\n",
      "epoch 3; iter: 0; batch classifier loss: 0.344890; batch adversarial loss: 0.587811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.347654; batch adversarial loss: 0.563055\n",
      "epoch 5; iter: 0; batch classifier loss: 0.316064; batch adversarial loss: 0.538130\n",
      "epoch 6; iter: 0; batch classifier loss: 0.277141; batch adversarial loss: 0.529815\n",
      "epoch 7; iter: 0; batch classifier loss: 0.259756; batch adversarial loss: 0.530538\n",
      "epoch 8; iter: 0; batch classifier loss: 0.272858; batch adversarial loss: 0.485700\n",
      "epoch 9; iter: 0; batch classifier loss: 0.267780; batch adversarial loss: 0.536983\n",
      "epoch 10; iter: 0; batch classifier loss: 0.233609; batch adversarial loss: 0.476033\n",
      "epoch 11; iter: 0; batch classifier loss: 0.246425; batch adversarial loss: 0.479627\n",
      "epoch 12; iter: 0; batch classifier loss: 0.156033; batch adversarial loss: 0.495317\n",
      "epoch 13; iter: 0; batch classifier loss: 0.159343; batch adversarial loss: 0.494924\n",
      "epoch 14; iter: 0; batch classifier loss: 0.209648; batch adversarial loss: 0.436624\n",
      "epoch 15; iter: 0; batch classifier loss: 0.179303; batch adversarial loss: 0.467779\n",
      "epoch 16; iter: 0; batch classifier loss: 0.179469; batch adversarial loss: 0.502951\n",
      "epoch 17; iter: 0; batch classifier loss: 0.150776; batch adversarial loss: 0.449918\n",
      "epoch 18; iter: 0; batch classifier loss: 0.155600; batch adversarial loss: 0.469210\n",
      "epoch 19; iter: 0; batch classifier loss: 0.133150; batch adversarial loss: 0.464378\n",
      "epoch 20; iter: 0; batch classifier loss: 0.142433; batch adversarial loss: 0.363138\n",
      "epoch 21; iter: 0; batch classifier loss: 0.194980; batch adversarial loss: 0.479683\n",
      "epoch 22; iter: 0; batch classifier loss: 0.173558; batch adversarial loss: 0.466169\n",
      "epoch 23; iter: 0; batch classifier loss: 0.183595; batch adversarial loss: 0.473355\n",
      "epoch 24; iter: 0; batch classifier loss: 0.161907; batch adversarial loss: 0.456897\n",
      "epoch 25; iter: 0; batch classifier loss: 0.117034; batch adversarial loss: 0.446769\n",
      "epoch 26; iter: 0; batch classifier loss: 0.156307; batch adversarial loss: 0.452314\n",
      "epoch 27; iter: 0; batch classifier loss: 0.214040; batch adversarial loss: 0.550623\n",
      "epoch 28; iter: 0; batch classifier loss: 0.165427; batch adversarial loss: 0.444143\n",
      "epoch 29; iter: 0; batch classifier loss: 0.199730; batch adversarial loss: 0.522410\n",
      "epoch 30; iter: 0; batch classifier loss: 0.146894; batch adversarial loss: 0.457450\n",
      "epoch 31; iter: 0; batch classifier loss: 0.224383; batch adversarial loss: 0.491922\n",
      "epoch 32; iter: 0; batch classifier loss: 0.231094; batch adversarial loss: 0.493462\n",
      "epoch 33; iter: 0; batch classifier loss: 0.238007; batch adversarial loss: 0.511066\n",
      "epoch 34; iter: 0; batch classifier loss: 0.304228; batch adversarial loss: 0.511783\n",
      "epoch 35; iter: 0; batch classifier loss: 0.267163; batch adversarial loss: 0.415149\n",
      "epoch 36; iter: 0; batch classifier loss: 0.125438; batch adversarial loss: 0.487759\n",
      "epoch 37; iter: 0; batch classifier loss: 0.160410; batch adversarial loss: 0.452749\n",
      "epoch 38; iter: 0; batch classifier loss: 0.075565; batch adversarial loss: 0.554169\n",
      "epoch 39; iter: 0; batch classifier loss: 0.119222; batch adversarial loss: 0.449775\n",
      "epoch 40; iter: 0; batch classifier loss: 0.111764; batch adversarial loss: 0.353067\n",
      "epoch 41; iter: 0; batch classifier loss: 0.104419; batch adversarial loss: 0.501981\n",
      "epoch 42; iter: 0; batch classifier loss: 0.074743; batch adversarial loss: 0.477570\n",
      "epoch 43; iter: 0; batch classifier loss: 0.124842; batch adversarial loss: 0.357331\n",
      "epoch 44; iter: 0; batch classifier loss: 0.087029; batch adversarial loss: 0.491128\n",
      "epoch 45; iter: 0; batch classifier loss: 0.059776; batch adversarial loss: 0.424492\n",
      "epoch 46; iter: 0; batch classifier loss: 0.085921; batch adversarial loss: 0.471253\n",
      "epoch 47; iter: 0; batch classifier loss: 0.084548; batch adversarial loss: 0.474607\n",
      "epoch 48; iter: 0; batch classifier loss: 0.097188; batch adversarial loss: 0.403458\n",
      "epoch 49; iter: 0; batch classifier loss: 0.047808; batch adversarial loss: 0.465898\n",
      "epoch 50; iter: 0; batch classifier loss: 0.051141; batch adversarial loss: 0.452440\n",
      "epoch 51; iter: 0; batch classifier loss: 0.055176; batch adversarial loss: 0.480228\n",
      "epoch 52; iter: 0; batch classifier loss: 0.105944; batch adversarial loss: 0.507848\n",
      "epoch 53; iter: 0; batch classifier loss: 0.063826; batch adversarial loss: 0.357533\n",
      "epoch 54; iter: 0; batch classifier loss: 0.063420; batch adversarial loss: 0.482105\n",
      "epoch 55; iter: 0; batch classifier loss: 0.065970; batch adversarial loss: 0.308628\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082658; batch adversarial loss: 0.434790\n",
      "epoch 57; iter: 0; batch classifier loss: 0.064679; batch adversarial loss: 0.422463\n",
      "epoch 58; iter: 0; batch classifier loss: 0.060304; batch adversarial loss: 0.471800\n",
      "epoch 59; iter: 0; batch classifier loss: 0.074447; batch adversarial loss: 0.571361\n",
      "epoch 60; iter: 0; batch classifier loss: 0.082623; batch adversarial loss: 0.509382\n",
      "epoch 61; iter: 0; batch classifier loss: 0.051190; batch adversarial loss: 0.433814\n",
      "epoch 62; iter: 0; batch classifier loss: 0.072509; batch adversarial loss: 0.407458\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104241; batch adversarial loss: 0.427632\n",
      "epoch 64; iter: 0; batch classifier loss: 0.061889; batch adversarial loss: 0.448172\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074765; batch adversarial loss: 0.436181\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073867; batch adversarial loss: 0.503781\n",
      "epoch 67; iter: 0; batch classifier loss: 0.070632; batch adversarial loss: 0.494378\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078309; batch adversarial loss: 0.547347\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102063; batch adversarial loss: 0.397556\n",
      "epoch 70; iter: 0; batch classifier loss: 0.044210; batch adversarial loss: 0.468101\n",
      "epoch 71; iter: 0; batch classifier loss: 0.062856; batch adversarial loss: 0.392877\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072235; batch adversarial loss: 0.462906\n",
      "epoch 73; iter: 0; batch classifier loss: 0.108940; batch adversarial loss: 0.518421\n",
      "epoch 74; iter: 0; batch classifier loss: 0.065355; batch adversarial loss: 0.539957\n",
      "epoch 75; iter: 0; batch classifier loss: 0.072201; batch adversarial loss: 0.425895\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083144; batch adversarial loss: 0.391197\n",
      "epoch 77; iter: 0; batch classifier loss: 0.046478; batch adversarial loss: 0.460460\n",
      "epoch 78; iter: 0; batch classifier loss: 0.097926; batch adversarial loss: 0.487743\n",
      "epoch 79; iter: 0; batch classifier loss: 0.079456; batch adversarial loss: 0.445764\n",
      "epoch 80; iter: 0; batch classifier loss: 0.035071; batch adversarial loss: 0.399298\n",
      "epoch 81; iter: 0; batch classifier loss: 0.056327; batch adversarial loss: 0.450959\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059936; batch adversarial loss: 0.458079\n",
      "epoch 83; iter: 0; batch classifier loss: 0.101712; batch adversarial loss: 0.451449\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048878; batch adversarial loss: 0.526058\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067570; batch adversarial loss: 0.385637\n",
      "epoch 86; iter: 0; batch classifier loss: 0.039813; batch adversarial loss: 0.434072\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073595; batch adversarial loss: 0.421852\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051637; batch adversarial loss: 0.428897\n",
      "epoch 89; iter: 0; batch classifier loss: 0.070684; batch adversarial loss: 0.436118\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039372; batch adversarial loss: 0.378291\n",
      "epoch 91; iter: 0; batch classifier loss: 0.019627; batch adversarial loss: 0.405868\n",
      "epoch 92; iter: 0; batch classifier loss: 0.037987; batch adversarial loss: 0.438570\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043489; batch adversarial loss: 0.449970\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056653; batch adversarial loss: 0.370380\n",
      "epoch 95; iter: 0; batch classifier loss: 0.040650; batch adversarial loss: 0.337918\n",
      "epoch 96; iter: 0; batch classifier loss: 0.080199; batch adversarial loss: 0.404364\n",
      "epoch 97; iter: 0; batch classifier loss: 0.029356; batch adversarial loss: 0.452364\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047118; batch adversarial loss: 0.439472\n",
      "epoch 99; iter: 0; batch classifier loss: 0.051243; batch adversarial loss: 0.454691\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045557; batch adversarial loss: 0.501427\n",
      "epoch 101; iter: 0; batch classifier loss: 0.069932; batch adversarial loss: 0.457261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.053201; batch adversarial loss: 0.400156\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032022; batch adversarial loss: 0.443270\n",
      "epoch 104; iter: 0; batch classifier loss: 0.018061; batch adversarial loss: 0.508816\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046126; batch adversarial loss: 0.510514\n",
      "epoch 106; iter: 0; batch classifier loss: 0.064715; batch adversarial loss: 0.459216\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041356; batch adversarial loss: 0.419013\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033897; batch adversarial loss: 0.388371\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046395; batch adversarial loss: 0.480976\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058539; batch adversarial loss: 0.576767\n",
      "epoch 111; iter: 0; batch classifier loss: 0.091036; batch adversarial loss: 0.488342\n",
      "epoch 112; iter: 0; batch classifier loss: 0.029800; batch adversarial loss: 0.477547\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059326; batch adversarial loss: 0.406623\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028481; batch adversarial loss: 0.470429\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032202; batch adversarial loss: 0.464832\n",
      "epoch 116; iter: 0; batch classifier loss: 0.015042; batch adversarial loss: 0.563938\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033720; batch adversarial loss: 0.449154\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033755; batch adversarial loss: 0.434659\n",
      "epoch 119; iter: 0; batch classifier loss: 0.017548; batch adversarial loss: 0.544961\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035555; batch adversarial loss: 0.354424\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031254; batch adversarial loss: 0.664802\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052986; batch adversarial loss: 0.428549\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021075; batch adversarial loss: 0.463260\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024195; batch adversarial loss: 0.467966\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025349; batch adversarial loss: 0.449853\n",
      "epoch 126; iter: 0; batch classifier loss: 0.061349; batch adversarial loss: 0.368201\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026460; batch adversarial loss: 0.418786\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041864; batch adversarial loss: 0.602311\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027975; batch adversarial loss: 0.393748\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034828; batch adversarial loss: 0.448031\n",
      "epoch 131; iter: 0; batch classifier loss: 0.011130; batch adversarial loss: 0.606977\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033967; batch adversarial loss: 0.451610\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040520; batch adversarial loss: 0.442714\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037205; batch adversarial loss: 0.405102\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018594; batch adversarial loss: 0.499719\n",
      "epoch 136; iter: 0; batch classifier loss: 0.074415; batch adversarial loss: 0.470612\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042678; batch adversarial loss: 0.444424\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023736; batch adversarial loss: 0.329237\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014101; batch adversarial loss: 0.436176\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032456; batch adversarial loss: 0.467317\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024290; batch adversarial loss: 0.511734\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027726; batch adversarial loss: 0.446232\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019753; batch adversarial loss: 0.394089\n",
      "epoch 144; iter: 0; batch classifier loss: 0.067856; batch adversarial loss: 0.500362\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017684; batch adversarial loss: 0.494317\n",
      "epoch 146; iter: 0; batch classifier loss: 0.012398; batch adversarial loss: 0.433087\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015711; batch adversarial loss: 0.401814\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027176; batch adversarial loss: 0.455571\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012447; batch adversarial loss: 0.457254\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020588; batch adversarial loss: 0.379728\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041226; batch adversarial loss: 0.416876\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021203; batch adversarial loss: 0.352925\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026751; batch adversarial loss: 0.509188\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039861; batch adversarial loss: 0.388384\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025328; batch adversarial loss: 0.434874\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041581; batch adversarial loss: 0.428917\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022696; batch adversarial loss: 0.452085\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036045; batch adversarial loss: 0.446585\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034211; batch adversarial loss: 0.440899\n",
      "epoch 160; iter: 0; batch classifier loss: 0.087657; batch adversarial loss: 0.498871\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028325; batch adversarial loss: 0.505251\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024740; batch adversarial loss: 0.453591\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021739; batch adversarial loss: 0.453174\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013322; batch adversarial loss: 0.445555\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037574; batch adversarial loss: 0.403712\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034084; batch adversarial loss: 0.377793\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023375; batch adversarial loss: 0.406129\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030748; batch adversarial loss: 0.340836\n",
      "epoch 169; iter: 0; batch classifier loss: 0.041779; batch adversarial loss: 0.444481\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015632; batch adversarial loss: 0.421129\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026107; batch adversarial loss: 0.398538\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026113; batch adversarial loss: 0.446543\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010000; batch adversarial loss: 0.465071\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010749; batch adversarial loss: 0.483225\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041853; batch adversarial loss: 0.319355\n",
      "epoch 176; iter: 0; batch classifier loss: 0.054968; batch adversarial loss: 0.484081\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008296; batch adversarial loss: 0.411514\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028408; batch adversarial loss: 0.457406\n",
      "epoch 179; iter: 0; batch classifier loss: 0.041221; batch adversarial loss: 0.481555\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039737; batch adversarial loss: 0.401349\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023537; batch adversarial loss: 0.443707\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021433; batch adversarial loss: 0.365027\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014065; batch adversarial loss: 0.458268\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017897; batch adversarial loss: 0.393824\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029357; batch adversarial loss: 0.423543\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008154; batch adversarial loss: 0.515611\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014687; batch adversarial loss: 0.509946\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018508; batch adversarial loss: 0.411803\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017408; batch adversarial loss: 0.415459\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016432; batch adversarial loss: 0.515483\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005849; batch adversarial loss: 0.491370\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006782; batch adversarial loss: 0.473806\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029176; batch adversarial loss: 0.367558\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026026; batch adversarial loss: 0.468873\n",
      "epoch 195; iter: 0; batch classifier loss: 0.048504; batch adversarial loss: 0.388705\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025264; batch adversarial loss: 0.458784\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009638; batch adversarial loss: 0.401684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.030716; batch adversarial loss: 0.326737\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019177; batch adversarial loss: 0.380417\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696538; batch adversarial loss: 0.687378\n",
      "epoch 1; iter: 0; batch classifier loss: 0.484024; batch adversarial loss: 0.672694\n",
      "epoch 2; iter: 0; batch classifier loss: 0.421293; batch adversarial loss: 0.645577\n",
      "epoch 3; iter: 0; batch classifier loss: 0.355780; batch adversarial loss: 0.620854\n",
      "epoch 4; iter: 0; batch classifier loss: 0.337949; batch adversarial loss: 0.553219\n",
      "epoch 5; iter: 0; batch classifier loss: 0.278027; batch adversarial loss: 0.555065\n",
      "epoch 6; iter: 0; batch classifier loss: 0.342682; batch adversarial loss: 0.556636\n",
      "epoch 7; iter: 0; batch classifier loss: 0.308664; batch adversarial loss: 0.528368\n",
      "epoch 8; iter: 0; batch classifier loss: 0.257366; batch adversarial loss: 0.495969\n",
      "epoch 9; iter: 0; batch classifier loss: 0.195266; batch adversarial loss: 0.509416\n",
      "epoch 10; iter: 0; batch classifier loss: 0.252243; batch adversarial loss: 0.532082\n",
      "epoch 11; iter: 0; batch classifier loss: 0.224629; batch adversarial loss: 0.425691\n",
      "epoch 12; iter: 0; batch classifier loss: 0.280797; batch adversarial loss: 0.510583\n",
      "epoch 13; iter: 0; batch classifier loss: 0.199233; batch adversarial loss: 0.501738\n",
      "epoch 14; iter: 0; batch classifier loss: 0.178867; batch adversarial loss: 0.460782\n",
      "epoch 15; iter: 0; batch classifier loss: 0.206315; batch adversarial loss: 0.433219\n",
      "epoch 16; iter: 0; batch classifier loss: 0.169473; batch adversarial loss: 0.391164\n",
      "epoch 17; iter: 0; batch classifier loss: 0.207837; batch adversarial loss: 0.436425\n",
      "epoch 18; iter: 0; batch classifier loss: 0.176320; batch adversarial loss: 0.437751\n",
      "epoch 19; iter: 0; batch classifier loss: 0.140383; batch adversarial loss: 0.472256\n",
      "epoch 20; iter: 0; batch classifier loss: 0.109434; batch adversarial loss: 0.543901\n",
      "epoch 21; iter: 0; batch classifier loss: 0.184488; batch adversarial loss: 0.444849\n",
      "epoch 22; iter: 0; batch classifier loss: 0.170307; batch adversarial loss: 0.471698\n",
      "epoch 23; iter: 0; batch classifier loss: 0.120034; batch adversarial loss: 0.386979\n",
      "epoch 24; iter: 0; batch classifier loss: 0.111111; batch adversarial loss: 0.473002\n",
      "epoch 25; iter: 0; batch classifier loss: 0.133213; batch adversarial loss: 0.431610\n",
      "epoch 26; iter: 0; batch classifier loss: 0.158541; batch adversarial loss: 0.413431\n",
      "epoch 27; iter: 0; batch classifier loss: 0.157753; batch adversarial loss: 0.395501\n",
      "epoch 28; iter: 0; batch classifier loss: 0.153397; batch adversarial loss: 0.455645\n",
      "epoch 29; iter: 0; batch classifier loss: 0.140739; batch adversarial loss: 0.365327\n",
      "epoch 30; iter: 0; batch classifier loss: 0.193328; batch adversarial loss: 0.433607\n",
      "epoch 31; iter: 0; batch classifier loss: 0.163351; batch adversarial loss: 0.448050\n",
      "epoch 32; iter: 0; batch classifier loss: 0.109286; batch adversarial loss: 0.369596\n",
      "epoch 33; iter: 0; batch classifier loss: 0.106175; batch adversarial loss: 0.344445\n",
      "epoch 34; iter: 0; batch classifier loss: 0.154762; batch adversarial loss: 0.417308\n",
      "epoch 35; iter: 0; batch classifier loss: 0.095616; batch adversarial loss: 0.435915\n",
      "epoch 36; iter: 0; batch classifier loss: 0.110625; batch adversarial loss: 0.419479\n",
      "epoch 37; iter: 0; batch classifier loss: 0.122352; batch adversarial loss: 0.401854\n",
      "epoch 38; iter: 0; batch classifier loss: 0.066578; batch adversarial loss: 0.405434\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125060; batch adversarial loss: 0.432650\n",
      "epoch 40; iter: 0; batch classifier loss: 0.129856; batch adversarial loss: 0.383987\n",
      "epoch 41; iter: 0; batch classifier loss: 0.103376; batch adversarial loss: 0.492676\n",
      "epoch 42; iter: 0; batch classifier loss: 0.086007; batch adversarial loss: 0.447250\n",
      "epoch 43; iter: 0; batch classifier loss: 0.087321; batch adversarial loss: 0.513284\n",
      "epoch 44; iter: 0; batch classifier loss: 0.134632; batch adversarial loss: 0.450828\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091060; batch adversarial loss: 0.318310\n",
      "epoch 46; iter: 0; batch classifier loss: 0.096522; batch adversarial loss: 0.438422\n",
      "epoch 47; iter: 0; batch classifier loss: 0.086544; batch adversarial loss: 0.438055\n",
      "epoch 48; iter: 0; batch classifier loss: 0.068949; batch adversarial loss: 0.353032\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094965; batch adversarial loss: 0.485373\n",
      "epoch 50; iter: 0; batch classifier loss: 0.093701; batch adversarial loss: 0.500219\n",
      "epoch 51; iter: 0; batch classifier loss: 0.059221; batch adversarial loss: 0.371329\n",
      "epoch 52; iter: 0; batch classifier loss: 0.093008; batch adversarial loss: 0.356840\n",
      "epoch 53; iter: 0; batch classifier loss: 0.077588; batch adversarial loss: 0.447503\n",
      "epoch 54; iter: 0; batch classifier loss: 0.060266; batch adversarial loss: 0.331289\n",
      "epoch 55; iter: 0; batch classifier loss: 0.076162; batch adversarial loss: 0.407985\n",
      "epoch 56; iter: 0; batch classifier loss: 0.064905; batch adversarial loss: 0.410558\n",
      "epoch 57; iter: 0; batch classifier loss: 0.092274; batch adversarial loss: 0.316811\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077434; batch adversarial loss: 0.457824\n",
      "epoch 59; iter: 0; batch classifier loss: 0.060268; batch adversarial loss: 0.439587\n",
      "epoch 60; iter: 0; batch classifier loss: 0.113868; batch adversarial loss: 0.378937\n",
      "epoch 61; iter: 0; batch classifier loss: 0.111737; batch adversarial loss: 0.488258\n",
      "epoch 62; iter: 0; batch classifier loss: 0.079560; batch adversarial loss: 0.448135\n",
      "epoch 63; iter: 0; batch classifier loss: 0.091686; batch adversarial loss: 0.520492\n",
      "epoch 64; iter: 0; batch classifier loss: 0.104196; batch adversarial loss: 0.448303\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065390; batch adversarial loss: 0.504996\n",
      "epoch 66; iter: 0; batch classifier loss: 0.103945; batch adversarial loss: 0.416445\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096378; batch adversarial loss: 0.386077\n",
      "epoch 68; iter: 0; batch classifier loss: 0.131827; batch adversarial loss: 0.463294\n",
      "epoch 69; iter: 0; batch classifier loss: 0.050124; batch adversarial loss: 0.459662\n",
      "epoch 70; iter: 0; batch classifier loss: 0.095948; batch adversarial loss: 0.441518\n",
      "epoch 71; iter: 0; batch classifier loss: 0.065211; batch adversarial loss: 0.435378\n",
      "epoch 72; iter: 0; batch classifier loss: 0.111251; batch adversarial loss: 0.420760\n",
      "epoch 73; iter: 0; batch classifier loss: 0.112005; batch adversarial loss: 0.320306\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101717; batch adversarial loss: 0.507003\n",
      "epoch 75; iter: 0; batch classifier loss: 0.046685; batch adversarial loss: 0.392755\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065948; batch adversarial loss: 0.399774\n",
      "epoch 77; iter: 0; batch classifier loss: 0.070767; batch adversarial loss: 0.426374\n",
      "epoch 78; iter: 0; batch classifier loss: 0.046416; batch adversarial loss: 0.425626\n",
      "epoch 79; iter: 0; batch classifier loss: 0.046700; batch adversarial loss: 0.455263\n",
      "epoch 80; iter: 0; batch classifier loss: 0.071948; batch adversarial loss: 0.432245\n",
      "epoch 81; iter: 0; batch classifier loss: 0.051306; batch adversarial loss: 0.396252\n",
      "epoch 82; iter: 0; batch classifier loss: 0.072774; batch adversarial loss: 0.442744\n",
      "epoch 83; iter: 0; batch classifier loss: 0.060641; batch adversarial loss: 0.330068\n",
      "epoch 84; iter: 0; batch classifier loss: 0.110141; batch adversarial loss: 0.541396\n",
      "epoch 85; iter: 0; batch classifier loss: 0.080507; batch adversarial loss: 0.424246\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067179; batch adversarial loss: 0.479301\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072487; batch adversarial loss: 0.421341\n",
      "epoch 88; iter: 0; batch classifier loss: 0.072130; batch adversarial loss: 0.327202\n",
      "epoch 89; iter: 0; batch classifier loss: 0.099597; batch adversarial loss: 0.394676\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059690; batch adversarial loss: 0.495760\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055040; batch adversarial loss: 0.444832\n",
      "epoch 92; iter: 0; batch classifier loss: 0.047702; batch adversarial loss: 0.368958\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063025; batch adversarial loss: 0.337470\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038345; batch adversarial loss: 0.450389\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048008; batch adversarial loss: 0.482729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.039237; batch adversarial loss: 0.458531\n",
      "epoch 97; iter: 0; batch classifier loss: 0.145860; batch adversarial loss: 0.529724\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035095; batch adversarial loss: 0.384054\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052919; batch adversarial loss: 0.403936\n",
      "epoch 100; iter: 0; batch classifier loss: 0.042226; batch adversarial loss: 0.343755\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046099; batch adversarial loss: 0.454146\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033439; batch adversarial loss: 0.492845\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054661; batch adversarial loss: 0.437060\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033007; batch adversarial loss: 0.586583\n",
      "epoch 105; iter: 0; batch classifier loss: 0.032888; batch adversarial loss: 0.474836\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036210; batch adversarial loss: 0.487427\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034603; batch adversarial loss: 0.437284\n",
      "epoch 108; iter: 0; batch classifier loss: 0.018159; batch adversarial loss: 0.410916\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059504; batch adversarial loss: 0.455797\n",
      "epoch 110; iter: 0; batch classifier loss: 0.029147; batch adversarial loss: 0.431498\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035519; batch adversarial loss: 0.415039\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025172; batch adversarial loss: 0.452776\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051237; batch adversarial loss: 0.392904\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028388; batch adversarial loss: 0.429470\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032953; batch adversarial loss: 0.462889\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037499; batch adversarial loss: 0.435707\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038880; batch adversarial loss: 0.456547\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054859; batch adversarial loss: 0.532001\n",
      "epoch 119; iter: 0; batch classifier loss: 0.015862; batch adversarial loss: 0.431830\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028128; batch adversarial loss: 0.457880\n",
      "epoch 121; iter: 0; batch classifier loss: 0.069181; batch adversarial loss: 0.652470\n",
      "epoch 122; iter: 0; batch classifier loss: 0.064131; batch adversarial loss: 0.475221\n",
      "epoch 123; iter: 0; batch classifier loss: 0.094664; batch adversarial loss: 0.454453\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051576; batch adversarial loss: 0.512055\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054196; batch adversarial loss: 0.562616\n",
      "epoch 126; iter: 0; batch classifier loss: 0.150578; batch adversarial loss: 0.646118\n",
      "epoch 127; iter: 0; batch classifier loss: 0.056851; batch adversarial loss: 0.493245\n",
      "epoch 128; iter: 0; batch classifier loss: 0.098825; batch adversarial loss: 0.630458\n",
      "epoch 129; iter: 0; batch classifier loss: 0.139952; batch adversarial loss: 0.610702\n",
      "epoch 130; iter: 0; batch classifier loss: 0.098428; batch adversarial loss: 0.578062\n",
      "epoch 131; iter: 0; batch classifier loss: 0.090244; batch adversarial loss: 0.525173\n",
      "epoch 132; iter: 0; batch classifier loss: 0.109224; batch adversarial loss: 0.555206\n",
      "epoch 133; iter: 0; batch classifier loss: 0.131969; batch adversarial loss: 0.656063\n",
      "epoch 134; iter: 0; batch classifier loss: 0.136845; batch adversarial loss: 0.679864\n",
      "epoch 135; iter: 0; batch classifier loss: 0.079472; batch adversarial loss: 0.510678\n",
      "epoch 136; iter: 0; batch classifier loss: 0.178424; batch adversarial loss: 0.635956\n",
      "epoch 137; iter: 0; batch classifier loss: 0.186751; batch adversarial loss: 0.668623\n",
      "epoch 138; iter: 0; batch classifier loss: 0.112276; batch adversarial loss: 0.605062\n",
      "epoch 139; iter: 0; batch classifier loss: 0.103969; batch adversarial loss: 0.565717\n",
      "epoch 140; iter: 0; batch classifier loss: 0.202608; batch adversarial loss: 0.666148\n",
      "epoch 141; iter: 0; batch classifier loss: 0.113209; batch adversarial loss: 0.615007\n",
      "epoch 142; iter: 0; batch classifier loss: 0.176816; batch adversarial loss: 0.585033\n",
      "epoch 143; iter: 0; batch classifier loss: 0.146188; batch adversarial loss: 0.599934\n",
      "epoch 144; iter: 0; batch classifier loss: 0.189654; batch adversarial loss: 0.659663\n",
      "epoch 145; iter: 0; batch classifier loss: 0.168639; batch adversarial loss: 0.649065\n",
      "epoch 146; iter: 0; batch classifier loss: 0.087950; batch adversarial loss: 0.457560\n",
      "epoch 147; iter: 0; batch classifier loss: 0.127435; batch adversarial loss: 0.585663\n",
      "epoch 148; iter: 0; batch classifier loss: 0.126314; batch adversarial loss: 0.468572\n",
      "epoch 149; iter: 0; batch classifier loss: 0.131452; batch adversarial loss: 0.534538\n",
      "epoch 150; iter: 0; batch classifier loss: 0.086711; batch adversarial loss: 0.478353\n",
      "epoch 151; iter: 0; batch classifier loss: 0.129656; batch adversarial loss: 0.544446\n",
      "epoch 152; iter: 0; batch classifier loss: 0.174642; batch adversarial loss: 0.555570\n",
      "epoch 153; iter: 0; batch classifier loss: 0.096246; batch adversarial loss: 0.457276\n",
      "epoch 154; iter: 0; batch classifier loss: 0.083915; batch adversarial loss: 0.394124\n",
      "epoch 155; iter: 0; batch classifier loss: 0.129620; batch adversarial loss: 0.547400\n",
      "epoch 156; iter: 0; batch classifier loss: 0.132230; batch adversarial loss: 0.494426\n",
      "epoch 157; iter: 0; batch classifier loss: 0.139149; batch adversarial loss: 0.431319\n",
      "epoch 158; iter: 0; batch classifier loss: 0.096631; batch adversarial loss: 0.538339\n",
      "epoch 159; iter: 0; batch classifier loss: 0.137429; batch adversarial loss: 0.442810\n",
      "epoch 160; iter: 0; batch classifier loss: 0.138395; batch adversarial loss: 0.534905\n",
      "epoch 161; iter: 0; batch classifier loss: 0.090689; batch adversarial loss: 0.465089\n",
      "epoch 162; iter: 0; batch classifier loss: 0.117395; batch adversarial loss: 0.383324\n",
      "epoch 163; iter: 0; batch classifier loss: 0.124839; batch adversarial loss: 0.458006\n",
      "epoch 164; iter: 0; batch classifier loss: 0.092023; batch adversarial loss: 0.542571\n",
      "epoch 165; iter: 0; batch classifier loss: 0.079208; batch adversarial loss: 0.491323\n",
      "epoch 166; iter: 0; batch classifier loss: 0.076781; batch adversarial loss: 0.436925\n",
      "epoch 167; iter: 0; batch classifier loss: 0.093493; batch adversarial loss: 0.422408\n",
      "epoch 168; iter: 0; batch classifier loss: 0.112857; batch adversarial loss: 0.420277\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036791; batch adversarial loss: 0.395826\n",
      "epoch 170; iter: 0; batch classifier loss: 0.083677; batch adversarial loss: 0.429436\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036643; batch adversarial loss: 0.372606\n",
      "epoch 172; iter: 0; batch classifier loss: 0.047000; batch adversarial loss: 0.432115\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034642; batch adversarial loss: 0.415937\n",
      "epoch 174; iter: 0; batch classifier loss: 0.043887; batch adversarial loss: 0.485251\n",
      "epoch 175; iter: 0; batch classifier loss: 0.071272; batch adversarial loss: 0.353832\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018905; batch adversarial loss: 0.380531\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033710; batch adversarial loss: 0.364844\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038502; batch adversarial loss: 0.455562\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034739; batch adversarial loss: 0.420678\n",
      "epoch 180; iter: 0; batch classifier loss: 0.044798; batch adversarial loss: 0.542656\n",
      "epoch 181; iter: 0; batch classifier loss: 0.052313; batch adversarial loss: 0.511572\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032105; batch adversarial loss: 0.489356\n",
      "epoch 183; iter: 0; batch classifier loss: 0.044399; batch adversarial loss: 0.437486\n",
      "epoch 184; iter: 0; batch classifier loss: 0.053381; batch adversarial loss: 0.414794\n",
      "epoch 185; iter: 0; batch classifier loss: 0.078398; batch adversarial loss: 0.498458\n",
      "epoch 186; iter: 0; batch classifier loss: 0.072126; batch adversarial loss: 0.475439\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030103; batch adversarial loss: 0.528977\n",
      "epoch 188; iter: 0; batch classifier loss: 0.056143; batch adversarial loss: 0.456691\n",
      "epoch 189; iter: 0; batch classifier loss: 0.069326; batch adversarial loss: 0.522266\n",
      "epoch 190; iter: 0; batch classifier loss: 0.077052; batch adversarial loss: 0.503930\n",
      "epoch 191; iter: 0; batch classifier loss: 0.078771; batch adversarial loss: 0.512403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.072968; batch adversarial loss: 0.473906\n",
      "epoch 193; iter: 0; batch classifier loss: 0.110392; batch adversarial loss: 0.504189\n",
      "epoch 194; iter: 0; batch classifier loss: 0.057744; batch adversarial loss: 0.331763\n",
      "epoch 195; iter: 0; batch classifier loss: 0.065352; batch adversarial loss: 0.440362\n",
      "epoch 196; iter: 0; batch classifier loss: 0.102238; batch adversarial loss: 0.486616\n",
      "epoch 197; iter: 0; batch classifier loss: 0.090810; batch adversarial loss: 0.542146\n",
      "epoch 198; iter: 0; batch classifier loss: 0.060063; batch adversarial loss: 0.308035\n",
      "epoch 199; iter: 0; batch classifier loss: 0.100054; batch adversarial loss: 0.397443\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694361; batch adversarial loss: 0.662868\n",
      "epoch 1; iter: 0; batch classifier loss: 0.441143; batch adversarial loss: 0.654411\n",
      "epoch 2; iter: 0; batch classifier loss: 0.430603; batch adversarial loss: 0.626408\n",
      "epoch 3; iter: 0; batch classifier loss: 0.419061; batch adversarial loss: 0.635778\n",
      "epoch 4; iter: 0; batch classifier loss: 0.439905; batch adversarial loss: 0.623604\n",
      "epoch 5; iter: 0; batch classifier loss: 0.337601; batch adversarial loss: 0.593674\n",
      "epoch 6; iter: 0; batch classifier loss: 0.464406; batch adversarial loss: 0.573203\n",
      "epoch 7; iter: 0; batch classifier loss: 0.458501; batch adversarial loss: 0.595861\n",
      "epoch 8; iter: 0; batch classifier loss: 0.437077; batch adversarial loss: 0.556008\n",
      "epoch 9; iter: 0; batch classifier loss: 0.471165; batch adversarial loss: 0.564968\n",
      "epoch 10; iter: 0; batch classifier loss: 0.466469; batch adversarial loss: 0.533326\n",
      "epoch 11; iter: 0; batch classifier loss: 0.416426; batch adversarial loss: 0.561805\n",
      "epoch 12; iter: 0; batch classifier loss: 0.306913; batch adversarial loss: 0.518739\n",
      "epoch 13; iter: 0; batch classifier loss: 0.381600; batch adversarial loss: 0.448583\n",
      "epoch 14; iter: 0; batch classifier loss: 0.336243; batch adversarial loss: 0.512530\n",
      "epoch 15; iter: 0; batch classifier loss: 0.287649; batch adversarial loss: 0.559860\n",
      "epoch 16; iter: 0; batch classifier loss: 0.280810; batch adversarial loss: 0.470378\n",
      "epoch 17; iter: 0; batch classifier loss: 0.335348; batch adversarial loss: 0.488271\n",
      "epoch 18; iter: 0; batch classifier loss: 0.240348; batch adversarial loss: 0.474937\n",
      "epoch 19; iter: 0; batch classifier loss: 0.231468; batch adversarial loss: 0.533436\n",
      "epoch 20; iter: 0; batch classifier loss: 0.313911; batch adversarial loss: 0.498407\n",
      "epoch 21; iter: 0; batch classifier loss: 0.269073; batch adversarial loss: 0.504725\n",
      "epoch 22; iter: 0; batch classifier loss: 0.203010; batch adversarial loss: 0.528377\n",
      "epoch 23; iter: 0; batch classifier loss: 0.198730; batch adversarial loss: 0.526087\n",
      "epoch 24; iter: 0; batch classifier loss: 0.232724; batch adversarial loss: 0.435918\n",
      "epoch 25; iter: 0; batch classifier loss: 0.218511; batch adversarial loss: 0.478295\n",
      "epoch 26; iter: 0; batch classifier loss: 0.232361; batch adversarial loss: 0.511980\n",
      "epoch 27; iter: 0; batch classifier loss: 0.265857; batch adversarial loss: 0.508714\n",
      "epoch 28; iter: 0; batch classifier loss: 0.149798; batch adversarial loss: 0.402765\n",
      "epoch 29; iter: 0; batch classifier loss: 0.226394; batch adversarial loss: 0.484756\n",
      "epoch 30; iter: 0; batch classifier loss: 0.163860; batch adversarial loss: 0.462136\n",
      "epoch 31; iter: 0; batch classifier loss: 0.174531; batch adversarial loss: 0.433888\n",
      "epoch 32; iter: 0; batch classifier loss: 0.204405; batch adversarial loss: 0.419988\n",
      "epoch 33; iter: 0; batch classifier loss: 0.139824; batch adversarial loss: 0.483551\n",
      "epoch 34; iter: 0; batch classifier loss: 0.157991; batch adversarial loss: 0.556347\n",
      "epoch 35; iter: 0; batch classifier loss: 0.145813; batch adversarial loss: 0.512827\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140755; batch adversarial loss: 0.492793\n",
      "epoch 37; iter: 0; batch classifier loss: 0.173847; batch adversarial loss: 0.454725\n",
      "epoch 38; iter: 0; batch classifier loss: 0.181091; batch adversarial loss: 0.465815\n",
      "epoch 39; iter: 0; batch classifier loss: 0.164135; batch adversarial loss: 0.525595\n",
      "epoch 40; iter: 0; batch classifier loss: 0.163052; batch adversarial loss: 0.471889\n",
      "epoch 41; iter: 0; batch classifier loss: 0.204932; batch adversarial loss: 0.456483\n",
      "epoch 42; iter: 0; batch classifier loss: 0.161297; batch adversarial loss: 0.568959\n",
      "epoch 43; iter: 0; batch classifier loss: 0.083541; batch adversarial loss: 0.422155\n",
      "epoch 44; iter: 0; batch classifier loss: 0.152901; batch adversarial loss: 0.402456\n",
      "epoch 45; iter: 0; batch classifier loss: 0.163755; batch adversarial loss: 0.482104\n",
      "epoch 46; iter: 0; batch classifier loss: 0.152534; batch adversarial loss: 0.474379\n",
      "epoch 47; iter: 0; batch classifier loss: 0.179225; batch adversarial loss: 0.523258\n",
      "epoch 48; iter: 0; batch classifier loss: 0.136260; batch adversarial loss: 0.518102\n",
      "epoch 49; iter: 0; batch classifier loss: 0.128497; batch adversarial loss: 0.373985\n",
      "epoch 50; iter: 0; batch classifier loss: 0.152671; batch adversarial loss: 0.442245\n",
      "epoch 51; iter: 0; batch classifier loss: 0.133272; batch adversarial loss: 0.441624\n",
      "epoch 52; iter: 0; batch classifier loss: 0.118843; batch adversarial loss: 0.477525\n",
      "epoch 53; iter: 0; batch classifier loss: 0.152664; batch adversarial loss: 0.502500\n",
      "epoch 54; iter: 0; batch classifier loss: 0.145645; batch adversarial loss: 0.448053\n",
      "epoch 55; iter: 0; batch classifier loss: 0.113591; batch adversarial loss: 0.495468\n",
      "epoch 56; iter: 0; batch classifier loss: 0.118262; batch adversarial loss: 0.488662\n",
      "epoch 57; iter: 0; batch classifier loss: 0.102269; batch adversarial loss: 0.519275\n",
      "epoch 58; iter: 0; batch classifier loss: 0.076515; batch adversarial loss: 0.531947\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090153; batch adversarial loss: 0.586586\n",
      "epoch 60; iter: 0; batch classifier loss: 0.141123; batch adversarial loss: 0.400053\n",
      "epoch 61; iter: 0; batch classifier loss: 0.079937; batch adversarial loss: 0.462399\n",
      "epoch 62; iter: 0; batch classifier loss: 0.138569; batch adversarial loss: 0.464304\n",
      "epoch 63; iter: 0; batch classifier loss: 0.100596; batch adversarial loss: 0.434550\n",
      "epoch 64; iter: 0; batch classifier loss: 0.109127; batch adversarial loss: 0.399006\n",
      "epoch 65; iter: 0; batch classifier loss: 0.117876; batch adversarial loss: 0.568044\n",
      "epoch 66; iter: 0; batch classifier loss: 0.171250; batch adversarial loss: 0.391310\n",
      "epoch 67; iter: 0; batch classifier loss: 0.114322; batch adversarial loss: 0.509586\n",
      "epoch 68; iter: 0; batch classifier loss: 0.150546; batch adversarial loss: 0.460560\n",
      "epoch 69; iter: 0; batch classifier loss: 0.089077; batch adversarial loss: 0.492282\n",
      "epoch 70; iter: 0; batch classifier loss: 0.085772; batch adversarial loss: 0.453366\n",
      "epoch 71; iter: 0; batch classifier loss: 0.140324; batch adversarial loss: 0.433450\n",
      "epoch 72; iter: 0; batch classifier loss: 0.065750; batch adversarial loss: 0.382712\n",
      "epoch 73; iter: 0; batch classifier loss: 0.118636; batch adversarial loss: 0.534920\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069368; batch adversarial loss: 0.411889\n",
      "epoch 75; iter: 0; batch classifier loss: 0.065748; batch adversarial loss: 0.478453\n",
      "epoch 76; iter: 0; batch classifier loss: 0.141603; batch adversarial loss: 0.441476\n",
      "epoch 77; iter: 0; batch classifier loss: 0.149494; batch adversarial loss: 0.414654\n",
      "epoch 78; iter: 0; batch classifier loss: 0.081914; batch adversarial loss: 0.488565\n",
      "epoch 79; iter: 0; batch classifier loss: 0.097147; batch adversarial loss: 0.487520\n",
      "epoch 80; iter: 0; batch classifier loss: 0.062522; batch adversarial loss: 0.435251\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069525; batch adversarial loss: 0.529937\n",
      "epoch 82; iter: 0; batch classifier loss: 0.077836; batch adversarial loss: 0.479758\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063199; batch adversarial loss: 0.539901\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067279; batch adversarial loss: 0.475250\n",
      "epoch 85; iter: 0; batch classifier loss: 0.101416; batch adversarial loss: 0.405919\n",
      "epoch 86; iter: 0; batch classifier loss: 0.098756; batch adversarial loss: 0.320991\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059959; batch adversarial loss: 0.528515\n",
      "epoch 88; iter: 0; batch classifier loss: 0.113475; batch adversarial loss: 0.441824\n",
      "epoch 89; iter: 0; batch classifier loss: 0.064405; batch adversarial loss: 0.507104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.113090; batch adversarial loss: 0.409528\n",
      "epoch 91; iter: 0; batch classifier loss: 0.058749; batch adversarial loss: 0.473142\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068289; batch adversarial loss: 0.479264\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053519; batch adversarial loss: 0.542887\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047011; batch adversarial loss: 0.511026\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087181; batch adversarial loss: 0.435960\n",
      "epoch 96; iter: 0; batch classifier loss: 0.076315; batch adversarial loss: 0.500806\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057098; batch adversarial loss: 0.442854\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079774; batch adversarial loss: 0.548870\n",
      "epoch 99; iter: 0; batch classifier loss: 0.070251; batch adversarial loss: 0.404064\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054822; batch adversarial loss: 0.388088\n",
      "epoch 101; iter: 0; batch classifier loss: 0.030051; batch adversarial loss: 0.499843\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033823; batch adversarial loss: 0.530330\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059226; batch adversarial loss: 0.458597\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057121; batch adversarial loss: 0.466505\n",
      "epoch 105; iter: 0; batch classifier loss: 0.031850; batch adversarial loss: 0.549848\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025676; batch adversarial loss: 0.502642\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028867; batch adversarial loss: 0.444115\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048280; batch adversarial loss: 0.501689\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039665; batch adversarial loss: 0.516447\n",
      "epoch 110; iter: 0; batch classifier loss: 0.027313; batch adversarial loss: 0.558331\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061402; batch adversarial loss: 0.472066\n",
      "epoch 112; iter: 0; batch classifier loss: 0.023159; batch adversarial loss: 0.501200\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033145; batch adversarial loss: 0.528238\n",
      "epoch 114; iter: 0; batch classifier loss: 0.016250; batch adversarial loss: 0.475679\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059208; batch adversarial loss: 0.488732\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034251; batch adversarial loss: 0.444531\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040158; batch adversarial loss: 0.461414\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036337; batch adversarial loss: 0.479967\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043826; batch adversarial loss: 0.484961\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047091; batch adversarial loss: 0.543754\n",
      "epoch 121; iter: 0; batch classifier loss: 0.078160; batch adversarial loss: 0.464072\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032950; batch adversarial loss: 0.397766\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028102; batch adversarial loss: 0.520750\n",
      "epoch 124; iter: 0; batch classifier loss: 0.014572; batch adversarial loss: 0.415472\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025937; batch adversarial loss: 0.489874\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022808; batch adversarial loss: 0.518350\n",
      "epoch 127; iter: 0; batch classifier loss: 0.013607; batch adversarial loss: 0.447613\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027775; batch adversarial loss: 0.408437\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037016; batch adversarial loss: 0.490621\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024157; batch adversarial loss: 0.465610\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017904; batch adversarial loss: 0.531280\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020788; batch adversarial loss: 0.428462\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032640; batch adversarial loss: 0.445825\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021506; batch adversarial loss: 0.424966\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045809; batch adversarial loss: 0.483965\n",
      "epoch 136; iter: 0; batch classifier loss: 0.051509; batch adversarial loss: 0.378168\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029998; batch adversarial loss: 0.483471\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034417; batch adversarial loss: 0.388560\n",
      "epoch 139; iter: 0; batch classifier loss: 0.027808; batch adversarial loss: 0.458794\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050152; batch adversarial loss: 0.389210\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029282; batch adversarial loss: 0.344500\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022263; batch adversarial loss: 0.492350\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041166; batch adversarial loss: 0.407227\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017294; batch adversarial loss: 0.414915\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020502; batch adversarial loss: 0.468395\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017459; batch adversarial loss: 0.441246\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040822; batch adversarial loss: 0.389750\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046167; batch adversarial loss: 0.512304\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020500; batch adversarial loss: 0.386171\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025034; batch adversarial loss: 0.464633\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025816; batch adversarial loss: 0.461630\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011453; batch adversarial loss: 0.413865\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028676; batch adversarial loss: 0.411459\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011021; batch adversarial loss: 0.444594\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023244; batch adversarial loss: 0.417209\n",
      "epoch 156; iter: 0; batch classifier loss: 0.008486; batch adversarial loss: 0.490997\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036904; batch adversarial loss: 0.456319\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023896; batch adversarial loss: 0.469471\n",
      "epoch 159; iter: 0; batch classifier loss: 0.009831; batch adversarial loss: 0.388579\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014231; batch adversarial loss: 0.485921\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020526; batch adversarial loss: 0.466519\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019391; batch adversarial loss: 0.517505\n",
      "epoch 163; iter: 0; batch classifier loss: 0.041740; batch adversarial loss: 0.384174\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019816; batch adversarial loss: 0.468506\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010222; batch adversarial loss: 0.349798\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017128; batch adversarial loss: 0.478533\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017604; batch adversarial loss: 0.476704\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023799; batch adversarial loss: 0.460963\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009861; batch adversarial loss: 0.519406\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013321; batch adversarial loss: 0.512835\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022067; batch adversarial loss: 0.496995\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016281; batch adversarial loss: 0.449620\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036970; batch adversarial loss: 0.474344\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026274; batch adversarial loss: 0.521284\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013500; batch adversarial loss: 0.453698\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011031; batch adversarial loss: 0.403578\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018527; batch adversarial loss: 0.455619\n",
      "epoch 178; iter: 0; batch classifier loss: 0.041118; batch adversarial loss: 0.435118\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033283; batch adversarial loss: 0.457205\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014881; batch adversarial loss: 0.463465\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033257; batch adversarial loss: 0.386007\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012511; batch adversarial loss: 0.459128\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030755; batch adversarial loss: 0.478046\n",
      "epoch 184; iter: 0; batch classifier loss: 0.005109; batch adversarial loss: 0.496713\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015450; batch adversarial loss: 0.447337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.037594; batch adversarial loss: 0.561622\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011050; batch adversarial loss: 0.396998\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008290; batch adversarial loss: 0.485652\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022636; batch adversarial loss: 0.530780\n",
      "epoch 190; iter: 0; batch classifier loss: 0.083119; batch adversarial loss: 0.464663\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025155; batch adversarial loss: 0.468279\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031101; batch adversarial loss: 0.487384\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014151; batch adversarial loss: 0.429212\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015391; batch adversarial loss: 0.429328\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013646; batch adversarial loss: 0.395433\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004937; batch adversarial loss: 0.436825\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007110; batch adversarial loss: 0.497298\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012565; batch adversarial loss: 0.403967\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012276; batch adversarial loss: 0.378201\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698797; batch adversarial loss: 0.696488\n",
      "epoch 1; iter: 0; batch classifier loss: 0.447040; batch adversarial loss: 0.660338\n",
      "epoch 2; iter: 0; batch classifier loss: 0.378340; batch adversarial loss: 0.630633\n",
      "epoch 3; iter: 0; batch classifier loss: 0.461896; batch adversarial loss: 0.611958\n",
      "epoch 4; iter: 0; batch classifier loss: 0.418500; batch adversarial loss: 0.578058\n",
      "epoch 5; iter: 0; batch classifier loss: 0.346532; batch adversarial loss: 0.584770\n",
      "epoch 6; iter: 0; batch classifier loss: 0.383247; batch adversarial loss: 0.545679\n",
      "epoch 7; iter: 0; batch classifier loss: 0.295589; batch adversarial loss: 0.549377\n",
      "epoch 8; iter: 0; batch classifier loss: 0.367275; batch adversarial loss: 0.502215\n",
      "epoch 9; iter: 0; batch classifier loss: 0.504815; batch adversarial loss: 0.542617\n",
      "epoch 10; iter: 0; batch classifier loss: 0.419166; batch adversarial loss: 0.520627\n",
      "epoch 11; iter: 0; batch classifier loss: 0.360833; batch adversarial loss: 0.570747\n",
      "epoch 12; iter: 0; batch classifier loss: 0.432485; batch adversarial loss: 0.519158\n",
      "epoch 13; iter: 0; batch classifier loss: 0.453217; batch adversarial loss: 0.530562\n",
      "epoch 14; iter: 0; batch classifier loss: 0.337900; batch adversarial loss: 0.538452\n",
      "epoch 15; iter: 0; batch classifier loss: 0.386451; batch adversarial loss: 0.509893\n",
      "epoch 16; iter: 0; batch classifier loss: 0.307765; batch adversarial loss: 0.516793\n",
      "epoch 17; iter: 0; batch classifier loss: 0.346993; batch adversarial loss: 0.551739\n",
      "epoch 18; iter: 0; batch classifier loss: 0.408582; batch adversarial loss: 0.488537\n",
      "epoch 19; iter: 0; batch classifier loss: 0.354301; batch adversarial loss: 0.478908\n",
      "epoch 20; iter: 0; batch classifier loss: 0.359229; batch adversarial loss: 0.535560\n",
      "epoch 21; iter: 0; batch classifier loss: 0.345860; batch adversarial loss: 0.454933\n",
      "epoch 22; iter: 0; batch classifier loss: 0.312232; batch adversarial loss: 0.558935\n",
      "epoch 23; iter: 0; batch classifier loss: 0.357005; batch adversarial loss: 0.446134\n",
      "epoch 24; iter: 0; batch classifier loss: 0.380558; batch adversarial loss: 0.584231\n",
      "epoch 25; iter: 0; batch classifier loss: 0.326579; batch adversarial loss: 0.448042\n",
      "epoch 26; iter: 0; batch classifier loss: 0.358121; batch adversarial loss: 0.458116\n",
      "epoch 27; iter: 0; batch classifier loss: 0.304674; batch adversarial loss: 0.531557\n",
      "epoch 28; iter: 0; batch classifier loss: 0.328791; batch adversarial loss: 0.478248\n",
      "epoch 29; iter: 0; batch classifier loss: 0.313012; batch adversarial loss: 0.417667\n",
      "epoch 30; iter: 0; batch classifier loss: 0.363659; batch adversarial loss: 0.437428\n",
      "epoch 31; iter: 0; batch classifier loss: 0.258912; batch adversarial loss: 0.434687\n",
      "epoch 32; iter: 0; batch classifier loss: 0.253638; batch adversarial loss: 0.456736\n",
      "epoch 33; iter: 0; batch classifier loss: 0.217872; batch adversarial loss: 0.488737\n",
      "epoch 34; iter: 0; batch classifier loss: 0.337849; batch adversarial loss: 0.442927\n",
      "epoch 35; iter: 0; batch classifier loss: 0.217587; batch adversarial loss: 0.515481\n",
      "epoch 36; iter: 0; batch classifier loss: 0.191813; batch adversarial loss: 0.524524\n",
      "epoch 37; iter: 0; batch classifier loss: 0.316635; batch adversarial loss: 0.494323\n",
      "epoch 38; iter: 0; batch classifier loss: 0.211339; batch adversarial loss: 0.506688\n",
      "epoch 39; iter: 0; batch classifier loss: 0.296045; batch adversarial loss: 0.524957\n",
      "epoch 40; iter: 0; batch classifier loss: 0.289781; batch adversarial loss: 0.577448\n",
      "epoch 41; iter: 0; batch classifier loss: 0.287921; batch adversarial loss: 0.517706\n",
      "epoch 42; iter: 0; batch classifier loss: 0.249213; batch adversarial loss: 0.481393\n",
      "epoch 43; iter: 0; batch classifier loss: 0.270407; batch adversarial loss: 0.471210\n",
      "epoch 44; iter: 0; batch classifier loss: 0.288893; batch adversarial loss: 0.551412\n",
      "epoch 45; iter: 0; batch classifier loss: 0.289402; batch adversarial loss: 0.413332\n",
      "epoch 46; iter: 0; batch classifier loss: 0.228085; batch adversarial loss: 0.482851\n",
      "epoch 47; iter: 0; batch classifier loss: 0.110850; batch adversarial loss: 0.529832\n",
      "epoch 48; iter: 0; batch classifier loss: 0.134084; batch adversarial loss: 0.399123\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113217; batch adversarial loss: 0.440931\n",
      "epoch 50; iter: 0; batch classifier loss: 0.131950; batch adversarial loss: 0.522014\n",
      "epoch 51; iter: 0; batch classifier loss: 0.315790; batch adversarial loss: 0.353227\n",
      "epoch 52; iter: 0; batch classifier loss: 0.263356; batch adversarial loss: 0.412500\n",
      "epoch 53; iter: 0; batch classifier loss: 0.200101; batch adversarial loss: 0.422301\n",
      "epoch 54; iter: 0; batch classifier loss: 0.186903; batch adversarial loss: 0.460656\n",
      "epoch 55; iter: 0; batch classifier loss: 0.269393; batch adversarial loss: 0.470869\n",
      "epoch 56; iter: 0; batch classifier loss: 0.238746; batch adversarial loss: 0.485038\n",
      "epoch 57; iter: 0; batch classifier loss: 0.230901; batch adversarial loss: 0.397811\n",
      "epoch 58; iter: 0; batch classifier loss: 0.237889; batch adversarial loss: 0.494865\n",
      "epoch 59; iter: 0; batch classifier loss: 0.228870; batch adversarial loss: 0.470873\n",
      "epoch 60; iter: 0; batch classifier loss: 0.229583; batch adversarial loss: 0.519342\n",
      "epoch 61; iter: 0; batch classifier loss: 0.075473; batch adversarial loss: 0.421899\n",
      "epoch 62; iter: 0; batch classifier loss: 0.074259; batch adversarial loss: 0.467143\n",
      "epoch 63; iter: 0; batch classifier loss: 0.054542; batch adversarial loss: 0.481586\n",
      "epoch 64; iter: 0; batch classifier loss: 0.068477; batch adversarial loss: 0.445920\n",
      "epoch 65; iter: 0; batch classifier loss: 0.064711; batch adversarial loss: 0.394692\n",
      "epoch 66; iter: 0; batch classifier loss: 0.045718; batch adversarial loss: 0.467490\n",
      "epoch 67; iter: 0; batch classifier loss: 0.117653; batch adversarial loss: 0.507949\n",
      "epoch 68; iter: 0; batch classifier loss: 0.064475; batch adversarial loss: 0.434477\n",
      "epoch 69; iter: 0; batch classifier loss: 0.048321; batch adversarial loss: 0.520175\n",
      "epoch 70; iter: 0; batch classifier loss: 0.091512; batch adversarial loss: 0.465578\n",
      "epoch 71; iter: 0; batch classifier loss: 0.145083; batch adversarial loss: 0.393667\n",
      "epoch 72; iter: 0; batch classifier loss: 0.098622; batch adversarial loss: 0.493342\n",
      "epoch 73; iter: 0; batch classifier loss: 0.057822; batch adversarial loss: 0.417598\n",
      "epoch 74; iter: 0; batch classifier loss: 0.049220; batch adversarial loss: 0.489130\n",
      "epoch 75; iter: 0; batch classifier loss: 0.088197; batch adversarial loss: 0.511186\n",
      "epoch 76; iter: 0; batch classifier loss: 0.094819; batch adversarial loss: 0.327476\n",
      "epoch 77; iter: 0; batch classifier loss: 0.066035; batch adversarial loss: 0.410212\n",
      "epoch 78; iter: 0; batch classifier loss: 0.057285; batch adversarial loss: 0.337447\n",
      "epoch 79; iter: 0; batch classifier loss: 0.039359; batch adversarial loss: 0.449844\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076142; batch adversarial loss: 0.512771\n",
      "epoch 81; iter: 0; batch classifier loss: 0.046175; batch adversarial loss: 0.437360\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059251; batch adversarial loss: 0.472292\n",
      "epoch 83; iter: 0; batch classifier loss: 0.058450; batch adversarial loss: 0.338075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.019262; batch adversarial loss: 0.407542\n",
      "epoch 85; iter: 0; batch classifier loss: 0.048588; batch adversarial loss: 0.459461\n",
      "epoch 86; iter: 0; batch classifier loss: 0.042462; batch adversarial loss: 0.401413\n",
      "epoch 87; iter: 0; batch classifier loss: 0.061453; batch adversarial loss: 0.475059\n",
      "epoch 88; iter: 0; batch classifier loss: 0.046814; batch adversarial loss: 0.382021\n",
      "epoch 89; iter: 0; batch classifier loss: 0.046264; batch adversarial loss: 0.451384\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039837; batch adversarial loss: 0.425831\n",
      "epoch 91; iter: 0; batch classifier loss: 0.049543; batch adversarial loss: 0.477687\n",
      "epoch 92; iter: 0; batch classifier loss: 0.040432; batch adversarial loss: 0.426354\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041986; batch adversarial loss: 0.446946\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048148; batch adversarial loss: 0.520261\n",
      "epoch 95; iter: 0; batch classifier loss: 0.055300; batch adversarial loss: 0.446363\n",
      "epoch 96; iter: 0; batch classifier loss: 0.076174; batch adversarial loss: 0.448728\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043368; batch adversarial loss: 0.421679\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039374; batch adversarial loss: 0.481592\n",
      "epoch 99; iter: 0; batch classifier loss: 0.080778; batch adversarial loss: 0.433458\n",
      "epoch 100; iter: 0; batch classifier loss: 0.080930; batch adversarial loss: 0.389707\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048916; batch adversarial loss: 0.477021\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046434; batch adversarial loss: 0.357065\n",
      "epoch 103; iter: 0; batch classifier loss: 0.031214; batch adversarial loss: 0.507591\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043126; batch adversarial loss: 0.408208\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048290; batch adversarial loss: 0.461226\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067236; batch adversarial loss: 0.518537\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048650; batch adversarial loss: 0.421087\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040121; batch adversarial loss: 0.454715\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039237; batch adversarial loss: 0.531084\n",
      "epoch 110; iter: 0; batch classifier loss: 0.074768; batch adversarial loss: 0.411824\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053887; batch adversarial loss: 0.413830\n",
      "epoch 112; iter: 0; batch classifier loss: 0.060195; batch adversarial loss: 0.491084\n",
      "epoch 113; iter: 0; batch classifier loss: 0.062743; batch adversarial loss: 0.424943\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050632; batch adversarial loss: 0.352684\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048595; batch adversarial loss: 0.381285\n",
      "epoch 116; iter: 0; batch classifier loss: 0.064383; batch adversarial loss: 0.482519\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035921; batch adversarial loss: 0.413634\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045944; batch adversarial loss: 0.479499\n",
      "epoch 119; iter: 0; batch classifier loss: 0.068692; batch adversarial loss: 0.403660\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049501; batch adversarial loss: 0.447831\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044523; batch adversarial loss: 0.362823\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031815; batch adversarial loss: 0.425833\n",
      "epoch 123; iter: 0; batch classifier loss: 0.054991; batch adversarial loss: 0.389449\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051674; batch adversarial loss: 0.409165\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032911; batch adversarial loss: 0.487106\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038972; batch adversarial loss: 0.537579\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030386; batch adversarial loss: 0.466417\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049083; batch adversarial loss: 0.420216\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046118; batch adversarial loss: 0.439474\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048210; batch adversarial loss: 0.356940\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047252; batch adversarial loss: 0.414786\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024418; batch adversarial loss: 0.399562\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027132; batch adversarial loss: 0.490911\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031617; batch adversarial loss: 0.377743\n",
      "epoch 135; iter: 0; batch classifier loss: 0.078116; batch adversarial loss: 0.379203\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040601; batch adversarial loss: 0.351260\n",
      "epoch 137; iter: 0; batch classifier loss: 0.059143; batch adversarial loss: 0.462469\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034972; batch adversarial loss: 0.416443\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030186; batch adversarial loss: 0.484939\n",
      "epoch 140; iter: 0; batch classifier loss: 0.084794; batch adversarial loss: 0.459540\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038991; batch adversarial loss: 0.412997\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027513; batch adversarial loss: 0.474564\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043910; batch adversarial loss: 0.469573\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017939; batch adversarial loss: 0.424828\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043064; batch adversarial loss: 0.400379\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027599; batch adversarial loss: 0.506306\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027763; batch adversarial loss: 0.481895\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039977; batch adversarial loss: 0.441432\n",
      "epoch 149; iter: 0; batch classifier loss: 0.046971; batch adversarial loss: 0.432693\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042675; batch adversarial loss: 0.414950\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024602; batch adversarial loss: 0.499682\n",
      "epoch 152; iter: 0; batch classifier loss: 0.051325; batch adversarial loss: 0.471103\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030209; batch adversarial loss: 0.450127\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028356; batch adversarial loss: 0.419827\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020889; batch adversarial loss: 0.399597\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035873; batch adversarial loss: 0.505420\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018371; batch adversarial loss: 0.511869\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015456; batch adversarial loss: 0.382446\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030781; batch adversarial loss: 0.394818\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025640; batch adversarial loss: 0.470467\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038876; batch adversarial loss: 0.490610\n",
      "epoch 162; iter: 0; batch classifier loss: 0.057885; batch adversarial loss: 0.469160\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023133; batch adversarial loss: 0.400787\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033159; batch adversarial loss: 0.473898\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013368; batch adversarial loss: 0.460814\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025796; batch adversarial loss: 0.456650\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025277; batch adversarial loss: 0.389430\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012217; batch adversarial loss: 0.452663\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023143; batch adversarial loss: 0.407604\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021663; batch adversarial loss: 0.468269\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025573; batch adversarial loss: 0.493946\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018025; batch adversarial loss: 0.607262\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021489; batch adversarial loss: 0.454589\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015956; batch adversarial loss: 0.477263\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016226; batch adversarial loss: 0.474145\n",
      "epoch 176; iter: 0; batch classifier loss: 0.048236; batch adversarial loss: 0.476156\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022522; batch adversarial loss: 0.513624\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023343; batch adversarial loss: 0.385539\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013533; batch adversarial loss: 0.401997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.038140; batch adversarial loss: 0.326767\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018432; batch adversarial loss: 0.502972\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014526; batch adversarial loss: 0.420726\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019007; batch adversarial loss: 0.476653\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014239; batch adversarial loss: 0.393921\n",
      "epoch 185; iter: 0; batch classifier loss: 0.030076; batch adversarial loss: 0.515495\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019873; batch adversarial loss: 0.423746\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009954; batch adversarial loss: 0.409897\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023159; batch adversarial loss: 0.485591\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034084; batch adversarial loss: 0.443903\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011076; batch adversarial loss: 0.477792\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030960; batch adversarial loss: 0.439385\n",
      "epoch 192; iter: 0; batch classifier loss: 0.042288; batch adversarial loss: 0.432107\n",
      "epoch 193; iter: 0; batch classifier loss: 0.038055; batch adversarial loss: 0.378953\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012733; batch adversarial loss: 0.397195\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021642; batch adversarial loss: 0.458866\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013926; batch adversarial loss: 0.461690\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024662; batch adversarial loss: 0.404951\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038629; batch adversarial loss: 0.447556\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019734; batch adversarial loss: 0.449619\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681151; batch adversarial loss: 1.026214\n",
      "epoch 1; iter: 0; batch classifier loss: 0.688094; batch adversarial loss: 1.304219\n",
      "epoch 2; iter: 0; batch classifier loss: 0.984129; batch adversarial loss: 1.427480\n",
      "epoch 3; iter: 0; batch classifier loss: 1.086476; batch adversarial loss: 1.296394\n",
      "epoch 4; iter: 0; batch classifier loss: 1.293452; batch adversarial loss: 1.204379\n",
      "epoch 5; iter: 0; batch classifier loss: 1.087272; batch adversarial loss: 1.059595\n",
      "epoch 6; iter: 0; batch classifier loss: 1.128721; batch adversarial loss: 0.984190\n",
      "epoch 7; iter: 0; batch classifier loss: 1.137187; batch adversarial loss: 0.888642\n",
      "epoch 8; iter: 0; batch classifier loss: 1.230350; batch adversarial loss: 0.835476\n",
      "epoch 9; iter: 0; batch classifier loss: 1.293109; batch adversarial loss: 0.759104\n",
      "epoch 10; iter: 0; batch classifier loss: 1.261578; batch adversarial loss: 0.708246\n",
      "epoch 11; iter: 0; batch classifier loss: 1.211451; batch adversarial loss: 0.652883\n",
      "epoch 12; iter: 0; batch classifier loss: 0.988185; batch adversarial loss: 0.609942\n",
      "epoch 13; iter: 0; batch classifier loss: 0.904532; batch adversarial loss: 0.574630\n",
      "epoch 14; iter: 0; batch classifier loss: 0.636840; batch adversarial loss: 0.544505\n",
      "epoch 15; iter: 0; batch classifier loss: 0.509268; batch adversarial loss: 0.504454\n",
      "epoch 16; iter: 0; batch classifier loss: 0.389026; batch adversarial loss: 0.490880\n",
      "epoch 17; iter: 0; batch classifier loss: 0.352984; batch adversarial loss: 0.446925\n",
      "epoch 18; iter: 0; batch classifier loss: 0.258728; batch adversarial loss: 0.511326\n",
      "epoch 19; iter: 0; batch classifier loss: 0.264832; batch adversarial loss: 0.491319\n",
      "epoch 20; iter: 0; batch classifier loss: 0.285683; batch adversarial loss: 0.505108\n",
      "epoch 21; iter: 0; batch classifier loss: 0.185328; batch adversarial loss: 0.505763\n",
      "epoch 22; iter: 0; batch classifier loss: 0.291875; batch adversarial loss: 0.465669\n",
      "epoch 23; iter: 0; batch classifier loss: 0.169865; batch adversarial loss: 0.514184\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195771; batch adversarial loss: 0.518802\n",
      "epoch 25; iter: 0; batch classifier loss: 0.228759; batch adversarial loss: 0.471989\n",
      "epoch 26; iter: 0; batch classifier loss: 0.159779; batch adversarial loss: 0.488759\n",
      "epoch 27; iter: 0; batch classifier loss: 0.253409; batch adversarial loss: 0.425728\n",
      "epoch 28; iter: 0; batch classifier loss: 0.162671; batch adversarial loss: 0.474833\n",
      "epoch 29; iter: 0; batch classifier loss: 0.150792; batch adversarial loss: 0.539616\n",
      "epoch 30; iter: 0; batch classifier loss: 0.188899; batch adversarial loss: 0.428539\n",
      "epoch 31; iter: 0; batch classifier loss: 0.163633; batch adversarial loss: 0.476397\n",
      "epoch 32; iter: 0; batch classifier loss: 0.206296; batch adversarial loss: 0.411026\n",
      "epoch 33; iter: 0; batch classifier loss: 0.157259; batch adversarial loss: 0.394428\n",
      "epoch 34; iter: 0; batch classifier loss: 0.227014; batch adversarial loss: 0.460752\n",
      "epoch 35; iter: 0; batch classifier loss: 0.167062; batch adversarial loss: 0.387156\n",
      "epoch 36; iter: 0; batch classifier loss: 0.170684; batch adversarial loss: 0.356671\n",
      "epoch 37; iter: 0; batch classifier loss: 0.175552; batch adversarial loss: 0.499120\n",
      "epoch 38; iter: 0; batch classifier loss: 0.206433; batch adversarial loss: 0.525670\n",
      "epoch 39; iter: 0; batch classifier loss: 0.175825; batch adversarial loss: 0.424371\n",
      "epoch 40; iter: 0; batch classifier loss: 0.120436; batch adversarial loss: 0.425435\n",
      "epoch 41; iter: 0; batch classifier loss: 0.166061; batch adversarial loss: 0.454004\n",
      "epoch 42; iter: 0; batch classifier loss: 0.141097; batch adversarial loss: 0.332959\n",
      "epoch 43; iter: 0; batch classifier loss: 0.134988; batch adversarial loss: 0.395816\n",
      "epoch 44; iter: 0; batch classifier loss: 0.138268; batch adversarial loss: 0.366493\n",
      "epoch 45; iter: 0; batch classifier loss: 0.172869; batch adversarial loss: 0.445118\n",
      "epoch 46; iter: 0; batch classifier loss: 0.118884; batch adversarial loss: 0.483344\n",
      "epoch 47; iter: 0; batch classifier loss: 0.169603; batch adversarial loss: 0.380592\n",
      "epoch 48; iter: 0; batch classifier loss: 0.161084; batch adversarial loss: 0.497672\n",
      "epoch 49; iter: 0; batch classifier loss: 0.117126; batch adversarial loss: 0.544291\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098911; batch adversarial loss: 0.510736\n",
      "epoch 51; iter: 0; batch classifier loss: 0.144145; batch adversarial loss: 0.546945\n",
      "epoch 52; iter: 0; batch classifier loss: 0.165229; batch adversarial loss: 0.498926\n",
      "epoch 53; iter: 0; batch classifier loss: 0.173927; batch adversarial loss: 0.455652\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074940; batch adversarial loss: 0.519585\n",
      "epoch 55; iter: 0; batch classifier loss: 0.066530; batch adversarial loss: 0.469986\n",
      "epoch 56; iter: 0; batch classifier loss: 0.144762; batch adversarial loss: 0.435616\n",
      "epoch 57; iter: 0; batch classifier loss: 0.137437; batch adversarial loss: 0.463170\n",
      "epoch 58; iter: 0; batch classifier loss: 0.199808; batch adversarial loss: 0.495411\n",
      "epoch 59; iter: 0; batch classifier loss: 0.141063; batch adversarial loss: 0.498559\n",
      "epoch 60; iter: 0; batch classifier loss: 0.156494; batch adversarial loss: 0.387523\n",
      "epoch 61; iter: 0; batch classifier loss: 0.178346; batch adversarial loss: 0.445828\n",
      "epoch 62; iter: 0; batch classifier loss: 0.071732; batch adversarial loss: 0.498141\n",
      "epoch 63; iter: 0; batch classifier loss: 0.141124; batch adversarial loss: 0.442101\n",
      "epoch 64; iter: 0; batch classifier loss: 0.124298; batch adversarial loss: 0.395246\n",
      "epoch 65; iter: 0; batch classifier loss: 0.124027; batch adversarial loss: 0.477066\n",
      "epoch 66; iter: 0; batch classifier loss: 0.098210; batch adversarial loss: 0.420188\n",
      "epoch 67; iter: 0; batch classifier loss: 0.159840; batch adversarial loss: 0.517358\n",
      "epoch 68; iter: 0; batch classifier loss: 0.097536; batch adversarial loss: 0.448161\n",
      "epoch 69; iter: 0; batch classifier loss: 0.126420; batch adversarial loss: 0.420555\n",
      "epoch 70; iter: 0; batch classifier loss: 0.112308; batch adversarial loss: 0.469873\n",
      "epoch 71; iter: 0; batch classifier loss: 0.200876; batch adversarial loss: 0.431079\n",
      "epoch 72; iter: 0; batch classifier loss: 0.137288; batch adversarial loss: 0.506410\n",
      "epoch 73; iter: 0; batch classifier loss: 0.091321; batch adversarial loss: 0.458605\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089681; batch adversarial loss: 0.357101\n",
      "epoch 75; iter: 0; batch classifier loss: 0.144559; batch adversarial loss: 0.524268\n",
      "epoch 76; iter: 0; batch classifier loss: 0.128906; batch adversarial loss: 0.414318\n",
      "epoch 77; iter: 0; batch classifier loss: 0.130492; batch adversarial loss: 0.391098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.102148; batch adversarial loss: 0.522291\n",
      "epoch 79; iter: 0; batch classifier loss: 0.147477; batch adversarial loss: 0.510556\n",
      "epoch 80; iter: 0; batch classifier loss: 0.116773; batch adversarial loss: 0.402154\n",
      "epoch 81; iter: 0; batch classifier loss: 0.109822; batch adversarial loss: 0.419125\n",
      "epoch 82; iter: 0; batch classifier loss: 0.124189; batch adversarial loss: 0.410417\n",
      "epoch 83; iter: 0; batch classifier loss: 0.114515; batch adversarial loss: 0.411058\n",
      "epoch 84; iter: 0; batch classifier loss: 0.089274; batch adversarial loss: 0.503507\n",
      "epoch 85; iter: 0; batch classifier loss: 0.114177; batch adversarial loss: 0.482925\n",
      "epoch 86; iter: 0; batch classifier loss: 0.132852; batch adversarial loss: 0.510782\n",
      "epoch 87; iter: 0; batch classifier loss: 0.114187; batch adversarial loss: 0.424575\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058473; batch adversarial loss: 0.470273\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080031; batch adversarial loss: 0.437661\n",
      "epoch 90; iter: 0; batch classifier loss: 0.133215; batch adversarial loss: 0.471885\n",
      "epoch 91; iter: 0; batch classifier loss: 0.090106; batch adversarial loss: 0.420668\n",
      "epoch 92; iter: 0; batch classifier loss: 0.089595; batch adversarial loss: 0.490178\n",
      "epoch 93; iter: 0; batch classifier loss: 0.146243; batch adversarial loss: 0.393028\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050876; batch adversarial loss: 0.473000\n",
      "epoch 95; iter: 0; batch classifier loss: 0.099357; batch adversarial loss: 0.408291\n",
      "epoch 96; iter: 0; batch classifier loss: 0.072587; batch adversarial loss: 0.443967\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073494; batch adversarial loss: 0.387555\n",
      "epoch 98; iter: 0; batch classifier loss: 0.144481; batch adversarial loss: 0.465315\n",
      "epoch 99; iter: 0; batch classifier loss: 0.113585; batch adversarial loss: 0.469948\n",
      "epoch 100; iter: 0; batch classifier loss: 0.148642; batch adversarial loss: 0.412898\n",
      "epoch 101; iter: 0; batch classifier loss: 0.093000; batch adversarial loss: 0.445303\n",
      "epoch 102; iter: 0; batch classifier loss: 0.125734; batch adversarial loss: 0.382820\n",
      "epoch 103; iter: 0; batch classifier loss: 0.185550; batch adversarial loss: 0.545444\n",
      "epoch 104; iter: 0; batch classifier loss: 0.100715; batch adversarial loss: 0.462953\n",
      "epoch 105; iter: 0; batch classifier loss: 0.115675; batch adversarial loss: 0.484359\n",
      "epoch 106; iter: 0; batch classifier loss: 0.162123; batch adversarial loss: 0.426095\n",
      "epoch 107; iter: 0; batch classifier loss: 0.101296; batch adversarial loss: 0.473158\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058257; batch adversarial loss: 0.479360\n",
      "epoch 109; iter: 0; batch classifier loss: 0.109810; batch adversarial loss: 0.502980\n",
      "epoch 110; iter: 0; batch classifier loss: 0.115586; batch adversarial loss: 0.423545\n",
      "epoch 111; iter: 0; batch classifier loss: 0.104667; batch adversarial loss: 0.413089\n",
      "epoch 112; iter: 0; batch classifier loss: 0.101401; batch adversarial loss: 0.330107\n",
      "epoch 113; iter: 0; batch classifier loss: 0.107003; batch adversarial loss: 0.471790\n",
      "epoch 114; iter: 0; batch classifier loss: 0.141023; batch adversarial loss: 0.396950\n",
      "epoch 115; iter: 0; batch classifier loss: 0.107967; batch adversarial loss: 0.424710\n",
      "epoch 116; iter: 0; batch classifier loss: 0.146705; batch adversarial loss: 0.428300\n",
      "epoch 117; iter: 0; batch classifier loss: 0.084940; batch adversarial loss: 0.531608\n",
      "epoch 118; iter: 0; batch classifier loss: 0.131160; batch adversarial loss: 0.479095\n",
      "epoch 119; iter: 0; batch classifier loss: 0.084879; batch adversarial loss: 0.382049\n",
      "epoch 120; iter: 0; batch classifier loss: 0.117841; batch adversarial loss: 0.416661\n",
      "epoch 121; iter: 0; batch classifier loss: 0.168228; batch adversarial loss: 0.445466\n",
      "epoch 122; iter: 0; batch classifier loss: 0.100332; batch adversarial loss: 0.490591\n",
      "epoch 123; iter: 0; batch classifier loss: 0.110504; batch adversarial loss: 0.448485\n",
      "epoch 124; iter: 0; batch classifier loss: 0.145363; batch adversarial loss: 0.431498\n",
      "epoch 125; iter: 0; batch classifier loss: 0.120295; batch adversarial loss: 0.483404\n",
      "epoch 126; iter: 0; batch classifier loss: 0.071253; batch adversarial loss: 0.468016\n",
      "epoch 127; iter: 0; batch classifier loss: 0.119606; batch adversarial loss: 0.529501\n",
      "epoch 128; iter: 0; batch classifier loss: 0.132193; batch adversarial loss: 0.458570\n",
      "epoch 129; iter: 0; batch classifier loss: 0.132638; batch adversarial loss: 0.432942\n",
      "epoch 130; iter: 0; batch classifier loss: 0.095143; batch adversarial loss: 0.454335\n",
      "epoch 131; iter: 0; batch classifier loss: 0.094692; batch adversarial loss: 0.423530\n",
      "epoch 132; iter: 0; batch classifier loss: 0.094054; batch adversarial loss: 0.404233\n",
      "epoch 133; iter: 0; batch classifier loss: 0.169281; batch adversarial loss: 0.433589\n",
      "epoch 134; iter: 0; batch classifier loss: 0.155177; batch adversarial loss: 0.483938\n",
      "epoch 135; iter: 0; batch classifier loss: 0.123390; batch adversarial loss: 0.386282\n",
      "epoch 136; iter: 0; batch classifier loss: 0.118137; batch adversarial loss: 0.343377\n",
      "epoch 137; iter: 0; batch classifier loss: 0.174649; batch adversarial loss: 0.349466\n",
      "epoch 138; iter: 0; batch classifier loss: 0.092601; batch adversarial loss: 0.429531\n",
      "epoch 139; iter: 0; batch classifier loss: 0.096127; batch adversarial loss: 0.385693\n",
      "epoch 140; iter: 0; batch classifier loss: 0.067755; batch adversarial loss: 0.493827\n",
      "epoch 141; iter: 0; batch classifier loss: 0.096203; batch adversarial loss: 0.496530\n",
      "epoch 142; iter: 0; batch classifier loss: 0.108987; batch adversarial loss: 0.531030\n",
      "epoch 143; iter: 0; batch classifier loss: 0.155582; batch adversarial loss: 0.461613\n",
      "epoch 144; iter: 0; batch classifier loss: 0.118039; batch adversarial loss: 0.432056\n",
      "epoch 145; iter: 0; batch classifier loss: 0.092695; batch adversarial loss: 0.420489\n",
      "epoch 146; iter: 0; batch classifier loss: 0.113100; batch adversarial loss: 0.423563\n",
      "epoch 147; iter: 0; batch classifier loss: 0.209254; batch adversarial loss: 0.452757\n",
      "epoch 148; iter: 0; batch classifier loss: 0.117122; batch adversarial loss: 0.612970\n",
      "epoch 149; iter: 0; batch classifier loss: 0.125925; batch adversarial loss: 0.510065\n",
      "epoch 150; iter: 0; batch classifier loss: 0.124040; batch adversarial loss: 0.434368\n",
      "epoch 151; iter: 0; batch classifier loss: 0.118752; batch adversarial loss: 0.414915\n",
      "epoch 152; iter: 0; batch classifier loss: 0.145568; batch adversarial loss: 0.370895\n",
      "epoch 153; iter: 0; batch classifier loss: 0.142390; batch adversarial loss: 0.442572\n",
      "epoch 154; iter: 0; batch classifier loss: 0.135110; batch adversarial loss: 0.470106\n",
      "epoch 155; iter: 0; batch classifier loss: 0.130867; batch adversarial loss: 0.394882\n",
      "epoch 156; iter: 0; batch classifier loss: 0.187154; batch adversarial loss: 0.433844\n",
      "epoch 157; iter: 0; batch classifier loss: 0.139704; batch adversarial loss: 0.470641\n",
      "epoch 158; iter: 0; batch classifier loss: 0.164771; batch adversarial loss: 0.463196\n",
      "epoch 159; iter: 0; batch classifier loss: 0.199016; batch adversarial loss: 0.432924\n",
      "epoch 160; iter: 0; batch classifier loss: 0.178852; batch adversarial loss: 0.508640\n",
      "epoch 161; iter: 0; batch classifier loss: 0.193766; batch adversarial loss: 0.410337\n",
      "epoch 162; iter: 0; batch classifier loss: 0.247541; batch adversarial loss: 0.434086\n",
      "epoch 163; iter: 0; batch classifier loss: 0.230564; batch adversarial loss: 0.421573\n",
      "epoch 164; iter: 0; batch classifier loss: 0.226270; batch adversarial loss: 0.545536\n",
      "epoch 165; iter: 0; batch classifier loss: 0.050404; batch adversarial loss: 0.446178\n",
      "epoch 166; iter: 0; batch classifier loss: 0.146201; batch adversarial loss: 0.409515\n",
      "epoch 167; iter: 0; batch classifier loss: 0.154259; batch adversarial loss: 0.472278\n",
      "epoch 168; iter: 0; batch classifier loss: 0.181474; batch adversarial loss: 0.409135\n",
      "epoch 169; iter: 0; batch classifier loss: 0.188442; batch adversarial loss: 0.383508\n",
      "epoch 170; iter: 0; batch classifier loss: 0.221050; batch adversarial loss: 0.471000\n",
      "epoch 171; iter: 0; batch classifier loss: 0.232597; batch adversarial loss: 0.421801\n",
      "epoch 172; iter: 0; batch classifier loss: 0.148434; batch adversarial loss: 0.409095\n",
      "epoch 173; iter: 0; batch classifier loss: 0.109388; batch adversarial loss: 0.433521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.102283; batch adversarial loss: 0.458877\n",
      "epoch 175; iter: 0; batch classifier loss: 0.175274; batch adversarial loss: 0.507280\n",
      "epoch 176; iter: 0; batch classifier loss: 0.157891; batch adversarial loss: 0.408042\n",
      "epoch 177; iter: 0; batch classifier loss: 0.098012; batch adversarial loss: 0.508474\n",
      "epoch 178; iter: 0; batch classifier loss: 0.175197; batch adversarial loss: 0.420112\n",
      "epoch 179; iter: 0; batch classifier loss: 0.168755; batch adversarial loss: 0.446078\n",
      "epoch 180; iter: 0; batch classifier loss: 0.158138; batch adversarial loss: 0.495042\n",
      "epoch 181; iter: 0; batch classifier loss: 0.131630; batch adversarial loss: 0.459640\n",
      "epoch 182; iter: 0; batch classifier loss: 0.157300; batch adversarial loss: 0.584467\n",
      "epoch 183; iter: 0; batch classifier loss: 0.169562; batch adversarial loss: 0.446925\n",
      "epoch 184; iter: 0; batch classifier loss: 0.086508; batch adversarial loss: 0.508960\n",
      "epoch 185; iter: 0; batch classifier loss: 0.155145; batch adversarial loss: 0.523775\n",
      "epoch 186; iter: 0; batch classifier loss: 0.149227; batch adversarial loss: 0.496991\n",
      "epoch 187; iter: 0; batch classifier loss: 0.091887; batch adversarial loss: 0.446210\n",
      "epoch 188; iter: 0; batch classifier loss: 0.089410; batch adversarial loss: 0.444522\n",
      "epoch 189; iter: 0; batch classifier loss: 0.065554; batch adversarial loss: 0.451553\n",
      "epoch 190; iter: 0; batch classifier loss: 0.076852; batch adversarial loss: 0.399054\n",
      "epoch 191; iter: 0; batch classifier loss: 0.062863; batch adversarial loss: 0.478444\n",
      "epoch 192; iter: 0; batch classifier loss: 0.097538; batch adversarial loss: 0.503080\n",
      "epoch 193; iter: 0; batch classifier loss: 0.042370; batch adversarial loss: 0.416955\n",
      "epoch 194; iter: 0; batch classifier loss: 0.091217; batch adversarial loss: 0.531872\n",
      "epoch 195; iter: 0; batch classifier loss: 0.056741; batch adversarial loss: 0.442770\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037728; batch adversarial loss: 0.449930\n",
      "epoch 197; iter: 0; batch classifier loss: 0.030690; batch adversarial loss: 0.446516\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032255; batch adversarial loss: 0.390382\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027045; batch adversarial loss: 0.455647\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699183; batch adversarial loss: 0.732586\n",
      "epoch 1; iter: 0; batch classifier loss: 0.467217; batch adversarial loss: 0.663770\n",
      "epoch 2; iter: 0; batch classifier loss: 0.360150; batch adversarial loss: 0.631679\n",
      "epoch 3; iter: 0; batch classifier loss: 0.305718; batch adversarial loss: 0.599551\n",
      "epoch 4; iter: 0; batch classifier loss: 0.308074; batch adversarial loss: 0.601974\n",
      "epoch 5; iter: 0; batch classifier loss: 0.367967; batch adversarial loss: 0.593280\n",
      "epoch 6; iter: 0; batch classifier loss: 0.349136; batch adversarial loss: 0.557057\n",
      "epoch 7; iter: 0; batch classifier loss: 0.350970; batch adversarial loss: 0.570387\n",
      "epoch 8; iter: 0; batch classifier loss: 0.289694; batch adversarial loss: 0.549113\n",
      "epoch 9; iter: 0; batch classifier loss: 0.417098; batch adversarial loss: 0.555514\n",
      "epoch 10; iter: 0; batch classifier loss: 0.385004; batch adversarial loss: 0.565140\n",
      "epoch 11; iter: 0; batch classifier loss: 0.325209; batch adversarial loss: 0.539604\n",
      "epoch 12; iter: 0; batch classifier loss: 0.345007; batch adversarial loss: 0.486115\n",
      "epoch 13; iter: 0; batch classifier loss: 0.276359; batch adversarial loss: 0.520990\n",
      "epoch 14; iter: 0; batch classifier loss: 0.260789; batch adversarial loss: 0.480811\n",
      "epoch 15; iter: 0; batch classifier loss: 0.276468; batch adversarial loss: 0.518423\n",
      "epoch 16; iter: 0; batch classifier loss: 0.239348; batch adversarial loss: 0.470114\n",
      "epoch 17; iter: 0; batch classifier loss: 0.383345; batch adversarial loss: 0.480368\n",
      "epoch 18; iter: 0; batch classifier loss: 0.311014; batch adversarial loss: 0.441002\n",
      "epoch 19; iter: 0; batch classifier loss: 0.298097; batch adversarial loss: 0.528253\n",
      "epoch 20; iter: 0; batch classifier loss: 0.305433; batch adversarial loss: 0.492211\n",
      "epoch 21; iter: 0; batch classifier loss: 0.320580; batch adversarial loss: 0.438962\n",
      "epoch 22; iter: 0; batch classifier loss: 0.261591; batch adversarial loss: 0.468266\n",
      "epoch 23; iter: 0; batch classifier loss: 0.276212; batch adversarial loss: 0.468990\n",
      "epoch 24; iter: 0; batch classifier loss: 0.221502; batch adversarial loss: 0.458963\n",
      "epoch 25; iter: 0; batch classifier loss: 0.280240; batch adversarial loss: 0.515076\n",
      "epoch 26; iter: 0; batch classifier loss: 0.241144; batch adversarial loss: 0.507125\n",
      "epoch 27; iter: 0; batch classifier loss: 0.247793; batch adversarial loss: 0.476481\n",
      "epoch 28; iter: 0; batch classifier loss: 0.208646; batch adversarial loss: 0.481394\n",
      "epoch 29; iter: 0; batch classifier loss: 0.155250; batch adversarial loss: 0.508237\n",
      "epoch 30; iter: 0; batch classifier loss: 0.250388; batch adversarial loss: 0.479949\n",
      "epoch 31; iter: 0; batch classifier loss: 0.300088; batch adversarial loss: 0.441514\n",
      "epoch 32; iter: 0; batch classifier loss: 0.203579; batch adversarial loss: 0.414596\n",
      "epoch 33; iter: 0; batch classifier loss: 0.202318; batch adversarial loss: 0.476848\n",
      "epoch 34; iter: 0; batch classifier loss: 0.183416; batch adversarial loss: 0.475255\n",
      "epoch 35; iter: 0; batch classifier loss: 0.223789; batch adversarial loss: 0.519040\n",
      "epoch 36; iter: 0; batch classifier loss: 0.271450; batch adversarial loss: 0.412701\n",
      "epoch 37; iter: 0; batch classifier loss: 0.215955; batch adversarial loss: 0.463001\n",
      "epoch 38; iter: 0; batch classifier loss: 0.173562; batch adversarial loss: 0.431726\n",
      "epoch 39; iter: 0; batch classifier loss: 0.193661; batch adversarial loss: 0.453187\n",
      "epoch 40; iter: 0; batch classifier loss: 0.227887; batch adversarial loss: 0.422872\n",
      "epoch 41; iter: 0; batch classifier loss: 0.256947; batch adversarial loss: 0.509562\n",
      "epoch 42; iter: 0; batch classifier loss: 0.190969; batch adversarial loss: 0.493979\n",
      "epoch 43; iter: 0; batch classifier loss: 0.154537; batch adversarial loss: 0.514607\n",
      "epoch 44; iter: 0; batch classifier loss: 0.174730; batch adversarial loss: 0.456617\n",
      "epoch 45; iter: 0; batch classifier loss: 0.168576; batch adversarial loss: 0.409501\n",
      "epoch 46; iter: 0; batch classifier loss: 0.207223; batch adversarial loss: 0.411438\n",
      "epoch 47; iter: 0; batch classifier loss: 0.233672; batch adversarial loss: 0.483143\n",
      "epoch 48; iter: 0; batch classifier loss: 0.200114; batch adversarial loss: 0.514826\n",
      "epoch 49; iter: 0; batch classifier loss: 0.170914; batch adversarial loss: 0.448082\n",
      "epoch 50; iter: 0; batch classifier loss: 0.208658; batch adversarial loss: 0.495490\n",
      "epoch 51; iter: 0; batch classifier loss: 0.155582; batch adversarial loss: 0.517836\n",
      "epoch 52; iter: 0; batch classifier loss: 0.174371; batch adversarial loss: 0.495759\n",
      "epoch 53; iter: 0; batch classifier loss: 0.211809; batch adversarial loss: 0.384730\n",
      "epoch 54; iter: 0; batch classifier loss: 0.189367; batch adversarial loss: 0.423413\n",
      "epoch 55; iter: 0; batch classifier loss: 0.179019; batch adversarial loss: 0.483122\n",
      "epoch 56; iter: 0; batch classifier loss: 0.167932; batch adversarial loss: 0.532316\n",
      "epoch 57; iter: 0; batch classifier loss: 0.170072; batch adversarial loss: 0.482536\n",
      "epoch 58; iter: 0; batch classifier loss: 0.182282; batch adversarial loss: 0.508135\n",
      "epoch 59; iter: 0; batch classifier loss: 0.113034; batch adversarial loss: 0.361116\n",
      "epoch 60; iter: 0; batch classifier loss: 0.240857; batch adversarial loss: 0.459996\n",
      "epoch 61; iter: 0; batch classifier loss: 0.204324; batch adversarial loss: 0.508700\n",
      "epoch 62; iter: 0; batch classifier loss: 0.109548; batch adversarial loss: 0.409167\n",
      "epoch 63; iter: 0; batch classifier loss: 0.109538; batch adversarial loss: 0.421258\n",
      "epoch 64; iter: 0; batch classifier loss: 0.188159; batch adversarial loss: 0.419967\n",
      "epoch 65; iter: 0; batch classifier loss: 0.137351; batch adversarial loss: 0.396598\n",
      "epoch 66; iter: 0; batch classifier loss: 0.137260; batch adversarial loss: 0.371249\n",
      "epoch 67; iter: 0; batch classifier loss: 0.122433; batch adversarial loss: 0.435456\n",
      "epoch 68; iter: 0; batch classifier loss: 0.143662; batch adversarial loss: 0.416793\n",
      "epoch 69; iter: 0; batch classifier loss: 0.107934; batch adversarial loss: 0.431803\n",
      "epoch 70; iter: 0; batch classifier loss: 0.144192; batch adversarial loss: 0.482218\n",
      "epoch 71; iter: 0; batch classifier loss: 0.127523; batch adversarial loss: 0.536816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.115668; batch adversarial loss: 0.434783\n",
      "epoch 73; iter: 0; batch classifier loss: 0.139212; batch adversarial loss: 0.507338\n",
      "epoch 74; iter: 0; batch classifier loss: 0.166079; batch adversarial loss: 0.445192\n",
      "epoch 75; iter: 0; batch classifier loss: 0.082676; batch adversarial loss: 0.409042\n",
      "epoch 76; iter: 0; batch classifier loss: 0.116191; batch adversarial loss: 0.495956\n",
      "epoch 77; iter: 0; batch classifier loss: 0.089899; batch adversarial loss: 0.483451\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090125; batch adversarial loss: 0.447698\n",
      "epoch 79; iter: 0; batch classifier loss: 0.108465; batch adversarial loss: 0.546560\n",
      "epoch 80; iter: 0; batch classifier loss: 0.092503; batch adversarial loss: 0.463335\n",
      "epoch 81; iter: 0; batch classifier loss: 0.087044; batch adversarial loss: 0.487382\n",
      "epoch 82; iter: 0; batch classifier loss: 0.132712; batch adversarial loss: 0.417446\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059160; batch adversarial loss: 0.421461\n",
      "epoch 84; iter: 0; batch classifier loss: 0.122870; batch adversarial loss: 0.455127\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046077; batch adversarial loss: 0.523162\n",
      "epoch 86; iter: 0; batch classifier loss: 0.115427; batch adversarial loss: 0.436538\n",
      "epoch 87; iter: 0; batch classifier loss: 0.123205; batch adversarial loss: 0.411431\n",
      "epoch 88; iter: 0; batch classifier loss: 0.080768; batch adversarial loss: 0.406048\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081011; batch adversarial loss: 0.371625\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064590; batch adversarial loss: 0.607792\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082658; batch adversarial loss: 0.408551\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070315; batch adversarial loss: 0.362548\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062484; batch adversarial loss: 0.482815\n",
      "epoch 94; iter: 0; batch classifier loss: 0.068141; batch adversarial loss: 0.450153\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052753; batch adversarial loss: 0.457239\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063986; batch adversarial loss: 0.465383\n",
      "epoch 97; iter: 0; batch classifier loss: 0.058386; batch adversarial loss: 0.499306\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052983; batch adversarial loss: 0.341525\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043529; batch adversarial loss: 0.402272\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067590; batch adversarial loss: 0.455155\n",
      "epoch 101; iter: 0; batch classifier loss: 0.092617; batch adversarial loss: 0.482942\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050350; batch adversarial loss: 0.448798\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064796; batch adversarial loss: 0.426095\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083487; batch adversarial loss: 0.353670\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052811; batch adversarial loss: 0.527433\n",
      "epoch 106; iter: 0; batch classifier loss: 0.029059; batch adversarial loss: 0.430288\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066057; batch adversarial loss: 0.475848\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053997; batch adversarial loss: 0.500016\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026266; batch adversarial loss: 0.419776\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068305; batch adversarial loss: 0.551847\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033033; batch adversarial loss: 0.510348\n",
      "epoch 112; iter: 0; batch classifier loss: 0.094226; batch adversarial loss: 0.397758\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048937; batch adversarial loss: 0.387132\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068869; batch adversarial loss: 0.427301\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035223; batch adversarial loss: 0.413646\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038150; batch adversarial loss: 0.483270\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031824; batch adversarial loss: 0.506412\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044299; batch adversarial loss: 0.395018\n",
      "epoch 119; iter: 0; batch classifier loss: 0.016203; batch adversarial loss: 0.458378\n",
      "epoch 120; iter: 0; batch classifier loss: 0.029864; batch adversarial loss: 0.469455\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030051; batch adversarial loss: 0.497988\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045954; batch adversarial loss: 0.543270\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053424; batch adversarial loss: 0.470196\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020757; batch adversarial loss: 0.447004\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032908; batch adversarial loss: 0.465147\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025011; batch adversarial loss: 0.522766\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035835; batch adversarial loss: 0.500894\n",
      "epoch 128; iter: 0; batch classifier loss: 0.055512; batch adversarial loss: 0.377980\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039081; batch adversarial loss: 0.340843\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032654; batch adversarial loss: 0.500093\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022849; batch adversarial loss: 0.394582\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039430; batch adversarial loss: 0.533174\n",
      "epoch 133; iter: 0; batch classifier loss: 0.061333; batch adversarial loss: 0.403253\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030435; batch adversarial loss: 0.399475\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023542; batch adversarial loss: 0.507120\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038023; batch adversarial loss: 0.417220\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045859; batch adversarial loss: 0.431458\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036368; batch adversarial loss: 0.395055\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045360; batch adversarial loss: 0.388969\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037225; batch adversarial loss: 0.455510\n",
      "epoch 141; iter: 0; batch classifier loss: 0.059730; batch adversarial loss: 0.381869\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034507; batch adversarial loss: 0.538455\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028781; batch adversarial loss: 0.431241\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020038; batch adversarial loss: 0.539188\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026879; batch adversarial loss: 0.518031\n",
      "epoch 146; iter: 0; batch classifier loss: 0.036482; batch adversarial loss: 0.470072\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043616; batch adversarial loss: 0.501743\n",
      "epoch 148; iter: 0; batch classifier loss: 0.011738; batch adversarial loss: 0.516150\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031394; batch adversarial loss: 0.471680\n",
      "epoch 150; iter: 0; batch classifier loss: 0.009149; batch adversarial loss: 0.493996\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022041; batch adversarial loss: 0.421044\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028996; batch adversarial loss: 0.427416\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021781; batch adversarial loss: 0.453504\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015420; batch adversarial loss: 0.558488\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022371; batch adversarial loss: 0.389031\n",
      "epoch 156; iter: 0; batch classifier loss: 0.005728; batch adversarial loss: 0.466948\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021326; batch adversarial loss: 0.513234\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015293; batch adversarial loss: 0.437920\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026740; batch adversarial loss: 0.476787\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008040; batch adversarial loss: 0.446570\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012556; batch adversarial loss: 0.388922\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018874; batch adversarial loss: 0.402475\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030883; batch adversarial loss: 0.345430\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032199; batch adversarial loss: 0.471451\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012988; batch adversarial loss: 0.389741\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025926; batch adversarial loss: 0.373105\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021417; batch adversarial loss: 0.484139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.033314; batch adversarial loss: 0.536991\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019995; batch adversarial loss: 0.479900\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016283; batch adversarial loss: 0.494221\n",
      "epoch 171; iter: 0; batch classifier loss: 0.050591; batch adversarial loss: 0.470157\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011814; batch adversarial loss: 0.451363\n",
      "epoch 173; iter: 0; batch classifier loss: 0.051363; batch adversarial loss: 0.507213\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012136; batch adversarial loss: 0.426268\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015698; batch adversarial loss: 0.364247\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037182; batch adversarial loss: 0.393371\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009566; batch adversarial loss: 0.519752\n",
      "epoch 178; iter: 0; batch classifier loss: 0.004045; batch adversarial loss: 0.459160\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010179; batch adversarial loss: 0.535206\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037748; batch adversarial loss: 0.387741\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027747; batch adversarial loss: 0.417574\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008748; batch adversarial loss: 0.453897\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005504; batch adversarial loss: 0.450333\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013625; batch adversarial loss: 0.469070\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014802; batch adversarial loss: 0.405991\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020352; batch adversarial loss: 0.402073\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013886; batch adversarial loss: 0.399278\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025937; batch adversarial loss: 0.439733\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004162; batch adversarial loss: 0.390618\n",
      "epoch 190; iter: 0; batch classifier loss: 0.002865; batch adversarial loss: 0.516065\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018250; batch adversarial loss: 0.456978\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013667; batch adversarial loss: 0.416448\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021849; batch adversarial loss: 0.531601\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022598; batch adversarial loss: 0.568365\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018693; batch adversarial loss: 0.436989\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012907; batch adversarial loss: 0.400553\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019708; batch adversarial loss: 0.413431\n",
      "epoch 198; iter: 0; batch classifier loss: 0.035654; batch adversarial loss: 0.445156\n",
      "epoch 199; iter: 0; batch classifier loss: 0.051707; batch adversarial loss: 0.475398\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693357; batch adversarial loss: 0.651237\n",
      "epoch 1; iter: 0; batch classifier loss: 0.445296; batch adversarial loss: 0.652554\n",
      "epoch 2; iter: 0; batch classifier loss: 0.408095; batch adversarial loss: 0.622601\n",
      "epoch 3; iter: 0; batch classifier loss: 0.427542; batch adversarial loss: 0.614957\n",
      "epoch 4; iter: 0; batch classifier loss: 0.457405; batch adversarial loss: 0.645224\n",
      "epoch 5; iter: 0; batch classifier loss: 0.474287; batch adversarial loss: 0.627755\n",
      "epoch 6; iter: 0; batch classifier loss: 0.546348; batch adversarial loss: 0.613475\n",
      "epoch 7; iter: 0; batch classifier loss: 0.430384; batch adversarial loss: 0.603658\n",
      "epoch 8; iter: 0; batch classifier loss: 0.362841; batch adversarial loss: 0.571372\n",
      "epoch 9; iter: 0; batch classifier loss: 0.442869; batch adversarial loss: 0.526637\n",
      "epoch 10; iter: 0; batch classifier loss: 0.365369; batch adversarial loss: 0.537097\n",
      "epoch 11; iter: 0; batch classifier loss: 0.345677; batch adversarial loss: 0.497677\n",
      "epoch 12; iter: 0; batch classifier loss: 0.363339; batch adversarial loss: 0.519718\n",
      "epoch 13; iter: 0; batch classifier loss: 0.368083; batch adversarial loss: 0.528896\n",
      "epoch 14; iter: 0; batch classifier loss: 0.313181; batch adversarial loss: 0.489032\n",
      "epoch 15; iter: 0; batch classifier loss: 0.259555; batch adversarial loss: 0.484785\n",
      "epoch 16; iter: 0; batch classifier loss: 0.242526; batch adversarial loss: 0.539371\n",
      "epoch 17; iter: 0; batch classifier loss: 0.278540; batch adversarial loss: 0.456527\n",
      "epoch 18; iter: 0; batch classifier loss: 0.226271; batch adversarial loss: 0.427044\n",
      "epoch 19; iter: 0; batch classifier loss: 0.325298; batch adversarial loss: 0.506016\n",
      "epoch 20; iter: 0; batch classifier loss: 0.340911; batch adversarial loss: 0.438191\n",
      "epoch 21; iter: 0; batch classifier loss: 0.250284; batch adversarial loss: 0.558104\n",
      "epoch 22; iter: 0; batch classifier loss: 0.248348; batch adversarial loss: 0.556980\n",
      "epoch 23; iter: 0; batch classifier loss: 0.246872; batch adversarial loss: 0.452590\n",
      "epoch 24; iter: 0; batch classifier loss: 0.209798; batch adversarial loss: 0.563960\n",
      "epoch 25; iter: 0; batch classifier loss: 0.206593; batch adversarial loss: 0.493943\n",
      "epoch 26; iter: 0; batch classifier loss: 0.186584; batch adversarial loss: 0.469014\n",
      "epoch 27; iter: 0; batch classifier loss: 0.206812; batch adversarial loss: 0.462798\n",
      "epoch 28; iter: 0; batch classifier loss: 0.131141; batch adversarial loss: 0.465812\n",
      "epoch 29; iter: 0; batch classifier loss: 0.204056; batch adversarial loss: 0.397345\n",
      "epoch 30; iter: 0; batch classifier loss: 0.179164; batch adversarial loss: 0.393427\n",
      "epoch 31; iter: 0; batch classifier loss: 0.261321; batch adversarial loss: 0.394158\n",
      "epoch 32; iter: 0; batch classifier loss: 0.210562; batch adversarial loss: 0.486479\n",
      "epoch 33; iter: 0; batch classifier loss: 0.219065; batch adversarial loss: 0.483225\n",
      "epoch 34; iter: 0; batch classifier loss: 0.184245; batch adversarial loss: 0.507957\n",
      "epoch 35; iter: 0; batch classifier loss: 0.190742; batch adversarial loss: 0.435417\n",
      "epoch 36; iter: 0; batch classifier loss: 0.183968; batch adversarial loss: 0.533535\n",
      "epoch 37; iter: 0; batch classifier loss: 0.163081; batch adversarial loss: 0.509335\n",
      "epoch 38; iter: 0; batch classifier loss: 0.198206; batch adversarial loss: 0.415759\n",
      "epoch 39; iter: 0; batch classifier loss: 0.158470; batch adversarial loss: 0.385992\n",
      "epoch 40; iter: 0; batch classifier loss: 0.165128; batch adversarial loss: 0.423318\n",
      "epoch 41; iter: 0; batch classifier loss: 0.146950; batch adversarial loss: 0.406764\n",
      "epoch 42; iter: 0; batch classifier loss: 0.194902; batch adversarial loss: 0.501608\n",
      "epoch 43; iter: 0; batch classifier loss: 0.132347; batch adversarial loss: 0.495499\n",
      "epoch 44; iter: 0; batch classifier loss: 0.146697; batch adversarial loss: 0.452865\n",
      "epoch 45; iter: 0; batch classifier loss: 0.141502; batch adversarial loss: 0.426233\n",
      "epoch 46; iter: 0; batch classifier loss: 0.146219; batch adversarial loss: 0.443241\n",
      "epoch 47; iter: 0; batch classifier loss: 0.187730; batch adversarial loss: 0.406362\n",
      "epoch 48; iter: 0; batch classifier loss: 0.129781; batch adversarial loss: 0.428465\n",
      "epoch 49; iter: 0; batch classifier loss: 0.149864; batch adversarial loss: 0.532656\n",
      "epoch 50; iter: 0; batch classifier loss: 0.124382; batch adversarial loss: 0.472778\n",
      "epoch 51; iter: 0; batch classifier loss: 0.101632; batch adversarial loss: 0.548040\n",
      "epoch 52; iter: 0; batch classifier loss: 0.191115; batch adversarial loss: 0.464753\n",
      "epoch 53; iter: 0; batch classifier loss: 0.157067; batch adversarial loss: 0.524787\n",
      "epoch 54; iter: 0; batch classifier loss: 0.174496; batch adversarial loss: 0.472059\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122035; batch adversarial loss: 0.367291\n",
      "epoch 56; iter: 0; batch classifier loss: 0.154070; batch adversarial loss: 0.469250\n",
      "epoch 57; iter: 0; batch classifier loss: 0.184969; batch adversarial loss: 0.487890\n",
      "epoch 58; iter: 0; batch classifier loss: 0.130867; batch adversarial loss: 0.515904\n",
      "epoch 59; iter: 0; batch classifier loss: 0.179490; batch adversarial loss: 0.389098\n",
      "epoch 60; iter: 0; batch classifier loss: 0.106533; batch adversarial loss: 0.507480\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104180; batch adversarial loss: 0.492920\n",
      "epoch 62; iter: 0; batch classifier loss: 0.166396; batch adversarial loss: 0.503800\n",
      "epoch 63; iter: 0; batch classifier loss: 0.115693; batch adversarial loss: 0.543478\n",
      "epoch 64; iter: 0; batch classifier loss: 0.136904; batch adversarial loss: 0.462455\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110551; batch adversarial loss: 0.454436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.099836; batch adversarial loss: 0.384433\n",
      "epoch 67; iter: 0; batch classifier loss: 0.116377; batch adversarial loss: 0.465838\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076626; batch adversarial loss: 0.526151\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072066; batch adversarial loss: 0.478090\n",
      "epoch 70; iter: 0; batch classifier loss: 0.151868; batch adversarial loss: 0.458213\n",
      "epoch 71; iter: 0; batch classifier loss: 0.110649; batch adversarial loss: 0.534493\n",
      "epoch 72; iter: 0; batch classifier loss: 0.065148; batch adversarial loss: 0.461446\n",
      "epoch 73; iter: 0; batch classifier loss: 0.102121; batch adversarial loss: 0.418127\n",
      "epoch 74; iter: 0; batch classifier loss: 0.098419; batch adversarial loss: 0.379109\n",
      "epoch 75; iter: 0; batch classifier loss: 0.109680; batch adversarial loss: 0.529509\n",
      "epoch 76; iter: 0; batch classifier loss: 0.078511; batch adversarial loss: 0.437668\n",
      "epoch 77; iter: 0; batch classifier loss: 0.117264; batch adversarial loss: 0.417163\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079229; batch adversarial loss: 0.415206\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044866; batch adversarial loss: 0.459782\n",
      "epoch 80; iter: 0; batch classifier loss: 0.117009; batch adversarial loss: 0.503915\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096347; batch adversarial loss: 0.389628\n",
      "epoch 82; iter: 0; batch classifier loss: 0.092197; batch adversarial loss: 0.497583\n",
      "epoch 83; iter: 0; batch classifier loss: 0.044252; batch adversarial loss: 0.432943\n",
      "epoch 84; iter: 0; batch classifier loss: 0.034974; batch adversarial loss: 0.500695\n",
      "epoch 85; iter: 0; batch classifier loss: 0.069559; batch adversarial loss: 0.457528\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061117; batch adversarial loss: 0.442470\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082742; batch adversarial loss: 0.396192\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051548; batch adversarial loss: 0.502823\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053186; batch adversarial loss: 0.519003\n",
      "epoch 90; iter: 0; batch classifier loss: 0.046985; batch adversarial loss: 0.506655\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074993; batch adversarial loss: 0.430503\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041218; batch adversarial loss: 0.432778\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063037; batch adversarial loss: 0.368054\n",
      "epoch 94; iter: 0; batch classifier loss: 0.055119; batch adversarial loss: 0.466642\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079148; batch adversarial loss: 0.485141\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049670; batch adversarial loss: 0.481704\n",
      "epoch 97; iter: 0; batch classifier loss: 0.116769; batch adversarial loss: 0.515445\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045513; batch adversarial loss: 0.438594\n",
      "epoch 99; iter: 0; batch classifier loss: 0.032874; batch adversarial loss: 0.530705\n",
      "epoch 100; iter: 0; batch classifier loss: 0.028022; batch adversarial loss: 0.455873\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057452; batch adversarial loss: 0.476359\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048962; batch adversarial loss: 0.451919\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046588; batch adversarial loss: 0.368269\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037764; batch adversarial loss: 0.454803\n",
      "epoch 105; iter: 0; batch classifier loss: 0.027507; batch adversarial loss: 0.402048\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043366; batch adversarial loss: 0.450341\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039414; batch adversarial loss: 0.507861\n",
      "epoch 108; iter: 0; batch classifier loss: 0.014659; batch adversarial loss: 0.468673\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029400; batch adversarial loss: 0.454330\n",
      "epoch 110; iter: 0; batch classifier loss: 0.015137; batch adversarial loss: 0.491347\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058700; batch adversarial loss: 0.477190\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043314; batch adversarial loss: 0.434240\n",
      "epoch 113; iter: 0; batch classifier loss: 0.026758; batch adversarial loss: 0.512212\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034164; batch adversarial loss: 0.561135\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053540; batch adversarial loss: 0.544108\n",
      "epoch 116; iter: 0; batch classifier loss: 0.059235; batch adversarial loss: 0.463618\n",
      "epoch 117; iter: 0; batch classifier loss: 0.054970; batch adversarial loss: 0.455718\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043878; batch adversarial loss: 0.490188\n",
      "epoch 119; iter: 0; batch classifier loss: 0.076132; batch adversarial loss: 0.458611\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033027; batch adversarial loss: 0.384588\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060564; batch adversarial loss: 0.487478\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037641; batch adversarial loss: 0.402503\n",
      "epoch 123; iter: 0; batch classifier loss: 0.013021; batch adversarial loss: 0.441607\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046042; batch adversarial loss: 0.484659\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043331; batch adversarial loss: 0.436193\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038295; batch adversarial loss: 0.521962\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022058; batch adversarial loss: 0.598012\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018635; batch adversarial loss: 0.575551\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036158; batch adversarial loss: 0.456753\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046679; batch adversarial loss: 0.501515\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025284; batch adversarial loss: 0.386316\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057757; batch adversarial loss: 0.461644\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030022; batch adversarial loss: 0.436709\n",
      "epoch 134; iter: 0; batch classifier loss: 0.057562; batch adversarial loss: 0.504085\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018495; batch adversarial loss: 0.476455\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013314; batch adversarial loss: 0.388486\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035592; batch adversarial loss: 0.556437\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016086; batch adversarial loss: 0.550126\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041316; batch adversarial loss: 0.555504\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021324; batch adversarial loss: 0.444414\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030494; batch adversarial loss: 0.492869\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017476; batch adversarial loss: 0.396597\n",
      "epoch 143; iter: 0; batch classifier loss: 0.058352; batch adversarial loss: 0.392094\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029147; batch adversarial loss: 0.504193\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012729; batch adversarial loss: 0.469277\n",
      "epoch 146; iter: 0; batch classifier loss: 0.036591; batch adversarial loss: 0.514827\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022367; batch adversarial loss: 0.432572\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032615; batch adversarial loss: 0.481826\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011782; batch adversarial loss: 0.476956\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025311; batch adversarial loss: 0.584932\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021274; batch adversarial loss: 0.455683\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036715; batch adversarial loss: 0.524397\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040755; batch adversarial loss: 0.471062\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022220; batch adversarial loss: 0.475462\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020708; batch adversarial loss: 0.515285\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015947; batch adversarial loss: 0.416940\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021723; batch adversarial loss: 0.440880\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036402; batch adversarial loss: 0.563061\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018894; batch adversarial loss: 0.450453\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019623; batch adversarial loss: 0.428748\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026578; batch adversarial loss: 0.412897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.028371; batch adversarial loss: 0.512903\n",
      "epoch 163; iter: 0; batch classifier loss: 0.005742; batch adversarial loss: 0.467190\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013375; batch adversarial loss: 0.475389\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021850; batch adversarial loss: 0.449708\n",
      "epoch 166; iter: 0; batch classifier loss: 0.044133; batch adversarial loss: 0.365653\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025053; batch adversarial loss: 0.448436\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017962; batch adversarial loss: 0.491878\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006047; batch adversarial loss: 0.512890\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024014; batch adversarial loss: 0.509992\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009629; batch adversarial loss: 0.537501\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020817; batch adversarial loss: 0.431327\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015537; batch adversarial loss: 0.413598\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016142; batch adversarial loss: 0.484655\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019599; batch adversarial loss: 0.529292\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022138; batch adversarial loss: 0.452011\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010665; batch adversarial loss: 0.570178\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010946; batch adversarial loss: 0.471277\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044202; batch adversarial loss: 0.417819\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010868; batch adversarial loss: 0.353962\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010715; batch adversarial loss: 0.467944\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013054; batch adversarial loss: 0.589140\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018265; batch adversarial loss: 0.472071\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020164; batch adversarial loss: 0.501858\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010198; batch adversarial loss: 0.444780\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012229; batch adversarial loss: 0.470017\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024103; batch adversarial loss: 0.446362\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024997; batch adversarial loss: 0.436102\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027762; batch adversarial loss: 0.398270\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018662; batch adversarial loss: 0.359351\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025572; batch adversarial loss: 0.410350\n",
      "epoch 192; iter: 0; batch classifier loss: 0.034617; batch adversarial loss: 0.469738\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020866; batch adversarial loss: 0.415129\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020803; batch adversarial loss: 0.533145\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018550; batch adversarial loss: 0.385412\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013959; batch adversarial loss: 0.449244\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015893; batch adversarial loss: 0.460235\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006854; batch adversarial loss: 0.458564\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009380; batch adversarial loss: 0.503413\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720724; batch adversarial loss: 1.091105\n",
      "epoch 1; iter: 0; batch classifier loss: 0.572824; batch adversarial loss: 1.240259\n",
      "epoch 2; iter: 0; batch classifier loss: 0.697649; batch adversarial loss: 1.271660\n",
      "epoch 3; iter: 0; batch classifier loss: 1.011083; batch adversarial loss: 1.120611\n",
      "epoch 4; iter: 0; batch classifier loss: 0.959511; batch adversarial loss: 1.021725\n",
      "epoch 5; iter: 0; batch classifier loss: 0.884840; batch adversarial loss: 0.937318\n",
      "epoch 6; iter: 0; batch classifier loss: 0.999909; batch adversarial loss: 0.850455\n",
      "epoch 7; iter: 0; batch classifier loss: 0.799553; batch adversarial loss: 0.792818\n",
      "epoch 8; iter: 0; batch classifier loss: 0.868707; batch adversarial loss: 0.714010\n",
      "epoch 9; iter: 0; batch classifier loss: 0.785910; batch adversarial loss: 0.650694\n",
      "epoch 10; iter: 0; batch classifier loss: 0.386604; batch adversarial loss: 0.610164\n",
      "epoch 11; iter: 0; batch classifier loss: 0.247322; batch adversarial loss: 0.570867\n",
      "epoch 12; iter: 0; batch classifier loss: 0.197513; batch adversarial loss: 0.606330\n",
      "epoch 13; iter: 0; batch classifier loss: 0.238377; batch adversarial loss: 0.533095\n",
      "epoch 14; iter: 0; batch classifier loss: 0.200930; batch adversarial loss: 0.552816\n",
      "epoch 15; iter: 0; batch classifier loss: 0.276164; batch adversarial loss: 0.551694\n",
      "epoch 16; iter: 0; batch classifier loss: 0.268102; batch adversarial loss: 0.502535\n",
      "epoch 17; iter: 0; batch classifier loss: 0.249164; batch adversarial loss: 0.504274\n",
      "epoch 18; iter: 0; batch classifier loss: 0.194424; batch adversarial loss: 0.546235\n",
      "epoch 19; iter: 0; batch classifier loss: 0.270181; batch adversarial loss: 0.547571\n",
      "epoch 20; iter: 0; batch classifier loss: 0.170037; batch adversarial loss: 0.466525\n",
      "epoch 21; iter: 0; batch classifier loss: 0.218178; batch adversarial loss: 0.475452\n",
      "epoch 22; iter: 0; batch classifier loss: 0.196872; batch adversarial loss: 0.521678\n",
      "epoch 23; iter: 0; batch classifier loss: 0.175222; batch adversarial loss: 0.435653\n",
      "epoch 24; iter: 0; batch classifier loss: 0.133082; batch adversarial loss: 0.449268\n",
      "epoch 25; iter: 0; batch classifier loss: 0.196874; batch adversarial loss: 0.512678\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187181; batch adversarial loss: 0.453508\n",
      "epoch 27; iter: 0; batch classifier loss: 0.140337; batch adversarial loss: 0.450211\n",
      "epoch 28; iter: 0; batch classifier loss: 0.188870; batch adversarial loss: 0.462774\n",
      "epoch 29; iter: 0; batch classifier loss: 0.137907; batch adversarial loss: 0.456334\n",
      "epoch 30; iter: 0; batch classifier loss: 0.113334; batch adversarial loss: 0.490906\n",
      "epoch 31; iter: 0; batch classifier loss: 0.110254; batch adversarial loss: 0.484832\n",
      "epoch 32; iter: 0; batch classifier loss: 0.103494; batch adversarial loss: 0.468924\n",
      "epoch 33; iter: 0; batch classifier loss: 0.103819; batch adversarial loss: 0.401716\n",
      "epoch 34; iter: 0; batch classifier loss: 0.080526; batch adversarial loss: 0.461529\n",
      "epoch 35; iter: 0; batch classifier loss: 0.113872; batch adversarial loss: 0.415443\n",
      "epoch 36; iter: 0; batch classifier loss: 0.053493; batch adversarial loss: 0.431991\n",
      "epoch 37; iter: 0; batch classifier loss: 0.095304; batch adversarial loss: 0.452793\n",
      "epoch 38; iter: 0; batch classifier loss: 0.056182; batch adversarial loss: 0.480446\n",
      "epoch 39; iter: 0; batch classifier loss: 0.084860; batch adversarial loss: 0.505143\n",
      "epoch 40; iter: 0; batch classifier loss: 0.083816; batch adversarial loss: 0.433319\n",
      "epoch 41; iter: 0; batch classifier loss: 0.062096; batch adversarial loss: 0.407264\n",
      "epoch 42; iter: 0; batch classifier loss: 0.067288; batch adversarial loss: 0.390964\n",
      "epoch 43; iter: 0; batch classifier loss: 0.064881; batch adversarial loss: 0.391868\n",
      "epoch 44; iter: 0; batch classifier loss: 0.045929; batch adversarial loss: 0.466459\n",
      "epoch 45; iter: 0; batch classifier loss: 0.084907; batch adversarial loss: 0.495225\n",
      "epoch 46; iter: 0; batch classifier loss: 0.060935; batch adversarial loss: 0.460761\n",
      "epoch 47; iter: 0; batch classifier loss: 0.055277; batch adversarial loss: 0.410306\n",
      "epoch 48; iter: 0; batch classifier loss: 0.046704; batch adversarial loss: 0.471262\n",
      "epoch 49; iter: 0; batch classifier loss: 0.077947; batch adversarial loss: 0.465629\n",
      "epoch 50; iter: 0; batch classifier loss: 0.083353; batch adversarial loss: 0.443063\n",
      "epoch 51; iter: 0; batch classifier loss: 0.067557; batch adversarial loss: 0.427237\n",
      "epoch 52; iter: 0; batch classifier loss: 0.057988; batch adversarial loss: 0.460286\n",
      "epoch 53; iter: 0; batch classifier loss: 0.047619; batch adversarial loss: 0.356697\n",
      "epoch 54; iter: 0; batch classifier loss: 0.064279; batch adversarial loss: 0.485261\n",
      "epoch 55; iter: 0; batch classifier loss: 0.064644; batch adversarial loss: 0.400595\n",
      "epoch 56; iter: 0; batch classifier loss: 0.078427; batch adversarial loss: 0.398758\n",
      "epoch 57; iter: 0; batch classifier loss: 0.123859; batch adversarial loss: 0.503750\n",
      "epoch 58; iter: 0; batch classifier loss: 0.110591; batch adversarial loss: 0.430727\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081824; batch adversarial loss: 0.538497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.066533; batch adversarial loss: 0.493344\n",
      "epoch 61; iter: 0; batch classifier loss: 0.082179; batch adversarial loss: 0.449980\n",
      "epoch 62; iter: 0; batch classifier loss: 0.047773; batch adversarial loss: 0.426320\n",
      "epoch 63; iter: 0; batch classifier loss: 0.068037; batch adversarial loss: 0.453706\n",
      "epoch 64; iter: 0; batch classifier loss: 0.065067; batch adversarial loss: 0.361048\n",
      "epoch 65; iter: 0; batch classifier loss: 0.049621; batch adversarial loss: 0.442707\n",
      "epoch 66; iter: 0; batch classifier loss: 0.064721; batch adversarial loss: 0.417943\n",
      "epoch 67; iter: 0; batch classifier loss: 0.072107; batch adversarial loss: 0.487194\n",
      "epoch 68; iter: 0; batch classifier loss: 0.050966; batch adversarial loss: 0.456835\n",
      "epoch 69; iter: 0; batch classifier loss: 0.067459; batch adversarial loss: 0.400759\n",
      "epoch 70; iter: 0; batch classifier loss: 0.097467; batch adversarial loss: 0.361997\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071661; batch adversarial loss: 0.374859\n",
      "epoch 72; iter: 0; batch classifier loss: 0.095646; batch adversarial loss: 0.507958\n",
      "epoch 73; iter: 0; batch classifier loss: 0.034379; batch adversarial loss: 0.531960\n",
      "epoch 74; iter: 0; batch classifier loss: 0.023112; batch adversarial loss: 0.513036\n",
      "epoch 75; iter: 0; batch classifier loss: 0.046380; batch adversarial loss: 0.516390\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081015; batch adversarial loss: 0.433503\n",
      "epoch 77; iter: 0; batch classifier loss: 0.033054; batch adversarial loss: 0.507661\n",
      "epoch 78; iter: 0; batch classifier loss: 0.053860; batch adversarial loss: 0.368707\n",
      "epoch 79; iter: 0; batch classifier loss: 0.046787; batch adversarial loss: 0.428197\n",
      "epoch 80; iter: 0; batch classifier loss: 0.029479; batch adversarial loss: 0.381963\n",
      "epoch 81; iter: 0; batch classifier loss: 0.091351; batch adversarial loss: 0.491128\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065866; batch adversarial loss: 0.393155\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054862; batch adversarial loss: 0.457502\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056490; batch adversarial loss: 0.396405\n",
      "epoch 85; iter: 0; batch classifier loss: 0.039089; batch adversarial loss: 0.479064\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057420; batch adversarial loss: 0.444520\n",
      "epoch 87; iter: 0; batch classifier loss: 0.021367; batch adversarial loss: 0.509746\n",
      "epoch 88; iter: 0; batch classifier loss: 0.038251; batch adversarial loss: 0.455530\n",
      "epoch 89; iter: 0; batch classifier loss: 0.033225; batch adversarial loss: 0.517910\n",
      "epoch 90; iter: 0; batch classifier loss: 0.022918; batch adversarial loss: 0.459354\n",
      "epoch 91; iter: 0; batch classifier loss: 0.037545; batch adversarial loss: 0.499442\n",
      "epoch 92; iter: 0; batch classifier loss: 0.054480; batch adversarial loss: 0.487932\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051060; batch adversarial loss: 0.361934\n",
      "epoch 94; iter: 0; batch classifier loss: 0.024468; batch adversarial loss: 0.534333\n",
      "epoch 95; iter: 0; batch classifier loss: 0.044485; batch adversarial loss: 0.429835\n",
      "epoch 96; iter: 0; batch classifier loss: 0.052949; batch adversarial loss: 0.434035\n",
      "epoch 97; iter: 0; batch classifier loss: 0.038475; batch adversarial loss: 0.425756\n",
      "epoch 98; iter: 0; batch classifier loss: 0.037394; batch adversarial loss: 0.467374\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058474; batch adversarial loss: 0.353730\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054860; batch adversarial loss: 0.483610\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042016; batch adversarial loss: 0.455494\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049348; batch adversarial loss: 0.428249\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038106; batch adversarial loss: 0.403275\n",
      "epoch 104; iter: 0; batch classifier loss: 0.064821; batch adversarial loss: 0.506620\n",
      "epoch 105; iter: 0; batch classifier loss: 0.113407; batch adversarial loss: 0.457460\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034986; batch adversarial loss: 0.538459\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032884; batch adversarial loss: 0.501902\n",
      "epoch 108; iter: 0; batch classifier loss: 0.050056; batch adversarial loss: 0.447050\n",
      "epoch 109; iter: 0; batch classifier loss: 0.020086; batch adversarial loss: 0.459968\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051629; batch adversarial loss: 0.494269\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035832; batch adversarial loss: 0.519846\n",
      "epoch 112; iter: 0; batch classifier loss: 0.005892; batch adversarial loss: 0.586975\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052723; batch adversarial loss: 0.399951\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039197; batch adversarial loss: 0.430924\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044344; batch adversarial loss: 0.550468\n",
      "epoch 116; iter: 0; batch classifier loss: 0.013460; batch adversarial loss: 0.462366\n",
      "epoch 117; iter: 0; batch classifier loss: 0.018312; batch adversarial loss: 0.405015\n",
      "epoch 118; iter: 0; batch classifier loss: 0.021409; batch adversarial loss: 0.457809\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041816; batch adversarial loss: 0.466443\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030219; batch adversarial loss: 0.479552\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018995; batch adversarial loss: 0.460584\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040595; batch adversarial loss: 0.418814\n",
      "epoch 123; iter: 0; batch classifier loss: 0.073951; batch adversarial loss: 0.500761\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052005; batch adversarial loss: 0.475244\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022288; batch adversarial loss: 0.472884\n",
      "epoch 126; iter: 0; batch classifier loss: 0.009283; batch adversarial loss: 0.476470\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024459; batch adversarial loss: 0.518711\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037999; batch adversarial loss: 0.441262\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017713; batch adversarial loss: 0.428764\n",
      "epoch 130; iter: 0; batch classifier loss: 0.015149; batch adversarial loss: 0.413334\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047711; batch adversarial loss: 0.439499\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041279; batch adversarial loss: 0.502290\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029262; batch adversarial loss: 0.476313\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028123; batch adversarial loss: 0.454147\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059370; batch adversarial loss: 0.486818\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036776; batch adversarial loss: 0.432192\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043732; batch adversarial loss: 0.497195\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033024; batch adversarial loss: 0.463483\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039340; batch adversarial loss: 0.483166\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044422; batch adversarial loss: 0.415141\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025661; batch adversarial loss: 0.474584\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016744; batch adversarial loss: 0.401382\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025381; batch adversarial loss: 0.403218\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016166; batch adversarial loss: 0.405906\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039798; batch adversarial loss: 0.426081\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048112; batch adversarial loss: 0.535462\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025960; batch adversarial loss: 0.412594\n",
      "epoch 148; iter: 0; batch classifier loss: 0.044918; batch adversarial loss: 0.526287\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019296; batch adversarial loss: 0.435638\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032946; batch adversarial loss: 0.535767\n",
      "epoch 151; iter: 0; batch classifier loss: 0.047430; batch adversarial loss: 0.524894\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017614; batch adversarial loss: 0.453771\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019779; batch adversarial loss: 0.399857\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023055; batch adversarial loss: 0.458470\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038266; batch adversarial loss: 0.560657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.023626; batch adversarial loss: 0.391219\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029132; batch adversarial loss: 0.421257\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035335; batch adversarial loss: 0.424829\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023352; batch adversarial loss: 0.500652\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019838; batch adversarial loss: 0.451344\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013324; batch adversarial loss: 0.416782\n",
      "epoch 162; iter: 0; batch classifier loss: 0.062099; batch adversarial loss: 0.517120\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017635; batch adversarial loss: 0.478150\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009310; batch adversarial loss: 0.451781\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016249; batch adversarial loss: 0.468070\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017214; batch adversarial loss: 0.400795\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007974; batch adversarial loss: 0.471926\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015210; batch adversarial loss: 0.531517\n",
      "epoch 169; iter: 0; batch classifier loss: 0.043013; batch adversarial loss: 0.513239\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017187; batch adversarial loss: 0.507698\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030084; batch adversarial loss: 0.499700\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030908; batch adversarial loss: 0.352864\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019465; batch adversarial loss: 0.455617\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015683; batch adversarial loss: 0.465909\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023705; batch adversarial loss: 0.508621\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013495; batch adversarial loss: 0.483840\n",
      "epoch 177; iter: 0; batch classifier loss: 0.004869; batch adversarial loss: 0.461761\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032766; batch adversarial loss: 0.352117\n",
      "epoch 179; iter: 0; batch classifier loss: 0.045330; batch adversarial loss: 0.369566\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035849; batch adversarial loss: 0.447204\n",
      "epoch 181; iter: 0; batch classifier loss: 0.060291; batch adversarial loss: 0.420946\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009195; batch adversarial loss: 0.544877\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006902; batch adversarial loss: 0.407599\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026814; batch adversarial loss: 0.393182\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012852; batch adversarial loss: 0.445281\n",
      "epoch 186; iter: 0; batch classifier loss: 0.004697; batch adversarial loss: 0.489672\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008723; batch adversarial loss: 0.484404\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011289; batch adversarial loss: 0.393564\n",
      "epoch 189; iter: 0; batch classifier loss: 0.057146; batch adversarial loss: 0.357061\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006794; batch adversarial loss: 0.437682\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012319; batch adversarial loss: 0.436128\n",
      "epoch 192; iter: 0; batch classifier loss: 0.034825; batch adversarial loss: 0.512771\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026168; batch adversarial loss: 0.400790\n",
      "epoch 194; iter: 0; batch classifier loss: 0.003852; batch adversarial loss: 0.492326\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025495; batch adversarial loss: 0.401000\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019873; batch adversarial loss: 0.503303\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024628; batch adversarial loss: 0.434062\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015615; batch adversarial loss: 0.408298\n",
      "epoch 199; iter: 0; batch classifier loss: 0.050116; batch adversarial loss: 0.508268\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673722; batch adversarial loss: 0.641914\n",
      "epoch 1; iter: 0; batch classifier loss: 0.535701; batch adversarial loss: 0.605295\n",
      "epoch 2; iter: 0; batch classifier loss: 0.486662; batch adversarial loss: 0.609731\n",
      "epoch 3; iter: 0; batch classifier loss: 0.444526; batch adversarial loss: 0.615707\n",
      "epoch 4; iter: 0; batch classifier loss: 0.358972; batch adversarial loss: 0.579212\n",
      "epoch 5; iter: 0; batch classifier loss: 0.461427; batch adversarial loss: 0.594007\n",
      "epoch 6; iter: 0; batch classifier loss: 0.471520; batch adversarial loss: 0.576189\n",
      "epoch 7; iter: 0; batch classifier loss: 0.337724; batch adversarial loss: 0.565061\n",
      "epoch 8; iter: 0; batch classifier loss: 0.450648; batch adversarial loss: 0.544325\n",
      "epoch 9; iter: 0; batch classifier loss: 0.384519; batch adversarial loss: 0.569277\n",
      "epoch 10; iter: 0; batch classifier loss: 0.415126; batch adversarial loss: 0.540488\n",
      "epoch 11; iter: 0; batch classifier loss: 0.339343; batch adversarial loss: 0.539163\n",
      "epoch 12; iter: 0; batch classifier loss: 0.401320; batch adversarial loss: 0.556270\n",
      "epoch 13; iter: 0; batch classifier loss: 0.323499; batch adversarial loss: 0.510153\n",
      "epoch 14; iter: 0; batch classifier loss: 0.190358; batch adversarial loss: 0.498174\n",
      "epoch 15; iter: 0; batch classifier loss: 0.296943; batch adversarial loss: 0.513276\n",
      "epoch 16; iter: 0; batch classifier loss: 0.278437; batch adversarial loss: 0.502784\n",
      "epoch 17; iter: 0; batch classifier loss: 0.244165; batch adversarial loss: 0.464170\n",
      "epoch 18; iter: 0; batch classifier loss: 0.219750; batch adversarial loss: 0.441272\n",
      "epoch 19; iter: 0; batch classifier loss: 0.262088; batch adversarial loss: 0.357143\n",
      "epoch 20; iter: 0; batch classifier loss: 0.373736; batch adversarial loss: 0.429121\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234431; batch adversarial loss: 0.481500\n",
      "epoch 22; iter: 0; batch classifier loss: 0.191385; batch adversarial loss: 0.500522\n",
      "epoch 23; iter: 0; batch classifier loss: 0.188109; batch adversarial loss: 0.452368\n",
      "epoch 24; iter: 0; batch classifier loss: 0.219006; batch adversarial loss: 0.488104\n",
      "epoch 25; iter: 0; batch classifier loss: 0.201102; batch adversarial loss: 0.579273\n",
      "epoch 26; iter: 0; batch classifier loss: 0.168787; batch adversarial loss: 0.497257\n",
      "epoch 27; iter: 0; batch classifier loss: 0.178153; batch adversarial loss: 0.479932\n",
      "epoch 28; iter: 0; batch classifier loss: 0.246849; batch adversarial loss: 0.448162\n",
      "epoch 29; iter: 0; batch classifier loss: 0.275706; batch adversarial loss: 0.582556\n",
      "epoch 30; iter: 0; batch classifier loss: 0.237081; batch adversarial loss: 0.419838\n",
      "epoch 31; iter: 0; batch classifier loss: 0.236593; batch adversarial loss: 0.471291\n",
      "epoch 32; iter: 0; batch classifier loss: 0.246508; batch adversarial loss: 0.400076\n",
      "epoch 33; iter: 0; batch classifier loss: 0.270372; batch adversarial loss: 0.469646\n",
      "epoch 34; iter: 0; batch classifier loss: 0.155191; batch adversarial loss: 0.507949\n",
      "epoch 35; iter: 0; batch classifier loss: 0.217434; batch adversarial loss: 0.433601\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187179; batch adversarial loss: 0.491066\n",
      "epoch 37; iter: 0; batch classifier loss: 0.256897; batch adversarial loss: 0.486854\n",
      "epoch 38; iter: 0; batch classifier loss: 0.244381; batch adversarial loss: 0.468244\n",
      "epoch 39; iter: 0; batch classifier loss: 0.276017; batch adversarial loss: 0.448807\n",
      "epoch 40; iter: 0; batch classifier loss: 0.228731; batch adversarial loss: 0.529233\n",
      "epoch 41; iter: 0; batch classifier loss: 0.247667; batch adversarial loss: 0.420552\n",
      "epoch 42; iter: 0; batch classifier loss: 0.306556; batch adversarial loss: 0.395923\n",
      "epoch 43; iter: 0; batch classifier loss: 0.204217; batch adversarial loss: 0.430262\n",
      "epoch 44; iter: 0; batch classifier loss: 0.214745; batch adversarial loss: 0.458121\n",
      "epoch 45; iter: 0; batch classifier loss: 0.263106; batch adversarial loss: 0.413561\n",
      "epoch 46; iter: 0; batch classifier loss: 0.285169; batch adversarial loss: 0.432449\n",
      "epoch 47; iter: 0; batch classifier loss: 0.250016; batch adversarial loss: 0.508107\n",
      "epoch 48; iter: 0; batch classifier loss: 0.262574; batch adversarial loss: 0.483795\n",
      "epoch 49; iter: 0; batch classifier loss: 0.235877; batch adversarial loss: 0.386664\n",
      "epoch 50; iter: 0; batch classifier loss: 0.143708; batch adversarial loss: 0.506840\n",
      "epoch 51; iter: 0; batch classifier loss: 0.180220; batch adversarial loss: 0.471287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.101965; batch adversarial loss: 0.422973\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098450; batch adversarial loss: 0.319896\n",
      "epoch 54; iter: 0; batch classifier loss: 0.211811; batch adversarial loss: 0.446997\n",
      "epoch 55; iter: 0; batch classifier loss: 0.286750; batch adversarial loss: 0.434031\n",
      "epoch 56; iter: 0; batch classifier loss: 0.159933; batch adversarial loss: 0.556332\n",
      "epoch 57; iter: 0; batch classifier loss: 0.198786; batch adversarial loss: 0.431928\n",
      "epoch 58; iter: 0; batch classifier loss: 0.217213; batch adversarial loss: 0.469066\n",
      "epoch 59; iter: 0; batch classifier loss: 0.251259; batch adversarial loss: 0.507516\n",
      "epoch 60; iter: 0; batch classifier loss: 0.186921; batch adversarial loss: 0.433546\n",
      "epoch 61; iter: 0; batch classifier loss: 0.177506; batch adversarial loss: 0.471099\n",
      "epoch 62; iter: 0; batch classifier loss: 0.227558; batch adversarial loss: 0.472582\n",
      "epoch 63; iter: 0; batch classifier loss: 0.166764; batch adversarial loss: 0.470783\n",
      "epoch 64; iter: 0; batch classifier loss: 0.128868; batch adversarial loss: 0.397148\n",
      "epoch 65; iter: 0; batch classifier loss: 0.216617; batch adversarial loss: 0.397060\n",
      "epoch 66; iter: 0; batch classifier loss: 0.167975; batch adversarial loss: 0.483386\n",
      "epoch 67; iter: 0; batch classifier loss: 0.234067; batch adversarial loss: 0.459852\n",
      "epoch 68; iter: 0; batch classifier loss: 0.229295; batch adversarial loss: 0.433845\n",
      "epoch 69; iter: 0; batch classifier loss: 0.100032; batch adversarial loss: 0.445974\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067290; batch adversarial loss: 0.455607\n",
      "epoch 71; iter: 0; batch classifier loss: 0.110144; batch adversarial loss: 0.378318\n",
      "epoch 72; iter: 0; batch classifier loss: 0.076020; batch adversarial loss: 0.480413\n",
      "epoch 73; iter: 0; batch classifier loss: 0.086951; batch adversarial loss: 0.583970\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063763; batch adversarial loss: 0.427060\n",
      "epoch 75; iter: 0; batch classifier loss: 0.087153; batch adversarial loss: 0.495176\n",
      "epoch 76; iter: 0; batch classifier loss: 0.112073; batch adversarial loss: 0.480035\n",
      "epoch 77; iter: 0; batch classifier loss: 0.145042; batch adversarial loss: 0.339453\n",
      "epoch 78; iter: 0; batch classifier loss: 0.157173; batch adversarial loss: 0.474487\n",
      "epoch 79; iter: 0; batch classifier loss: 0.131577; batch adversarial loss: 0.446899\n",
      "epoch 80; iter: 0; batch classifier loss: 0.130209; batch adversarial loss: 0.392658\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084327; batch adversarial loss: 0.475465\n",
      "epoch 82; iter: 0; batch classifier loss: 0.129648; batch adversarial loss: 0.452400\n",
      "epoch 83; iter: 0; batch classifier loss: 0.100627; batch adversarial loss: 0.461685\n",
      "epoch 84; iter: 0; batch classifier loss: 0.073882; batch adversarial loss: 0.418110\n",
      "epoch 85; iter: 0; batch classifier loss: 0.100570; batch adversarial loss: 0.416352\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051641; batch adversarial loss: 0.408046\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062285; batch adversarial loss: 0.364118\n",
      "epoch 88; iter: 0; batch classifier loss: 0.128555; batch adversarial loss: 0.480359\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048236; batch adversarial loss: 0.368214\n",
      "epoch 90; iter: 0; batch classifier loss: 0.088832; batch adversarial loss: 0.452276\n",
      "epoch 91; iter: 0; batch classifier loss: 0.098232; batch adversarial loss: 0.422980\n",
      "epoch 92; iter: 0; batch classifier loss: 0.107104; batch adversarial loss: 0.375227\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077644; batch adversarial loss: 0.437816\n",
      "epoch 94; iter: 0; batch classifier loss: 0.088985; batch adversarial loss: 0.462273\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080043; batch adversarial loss: 0.464062\n",
      "epoch 96; iter: 0; batch classifier loss: 0.071654; batch adversarial loss: 0.499805\n",
      "epoch 97; iter: 0; batch classifier loss: 0.084429; batch adversarial loss: 0.430936\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062557; batch adversarial loss: 0.453035\n",
      "epoch 99; iter: 0; batch classifier loss: 0.089521; batch adversarial loss: 0.431096\n",
      "epoch 100; iter: 0; batch classifier loss: 0.096582; batch adversarial loss: 0.508876\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048008; batch adversarial loss: 0.454390\n",
      "epoch 102; iter: 0; batch classifier loss: 0.070995; batch adversarial loss: 0.500552\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047821; batch adversarial loss: 0.472970\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027848; batch adversarial loss: 0.433678\n",
      "epoch 105; iter: 0; batch classifier loss: 0.068996; batch adversarial loss: 0.416486\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052684; batch adversarial loss: 0.388951\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046542; batch adversarial loss: 0.390636\n",
      "epoch 108; iter: 0; batch classifier loss: 0.032201; batch adversarial loss: 0.479629\n",
      "epoch 109; iter: 0; batch classifier loss: 0.071346; batch adversarial loss: 0.467949\n",
      "epoch 110; iter: 0; batch classifier loss: 0.019815; batch adversarial loss: 0.471230\n",
      "epoch 111; iter: 0; batch classifier loss: 0.020557; batch adversarial loss: 0.434462\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036250; batch adversarial loss: 0.459399\n",
      "epoch 113; iter: 0; batch classifier loss: 0.026951; batch adversarial loss: 0.397784\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033272; batch adversarial loss: 0.422188\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045152; batch adversarial loss: 0.452335\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039185; batch adversarial loss: 0.529838\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045045; batch adversarial loss: 0.529264\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051587; batch adversarial loss: 0.449099\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048778; batch adversarial loss: 0.458116\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045992; batch adversarial loss: 0.516800\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024467; batch adversarial loss: 0.609944\n",
      "epoch 122; iter: 0; batch classifier loss: 0.078018; batch adversarial loss: 0.432829\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014682; batch adversarial loss: 0.479433\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023202; batch adversarial loss: 0.455449\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045047; batch adversarial loss: 0.499620\n",
      "epoch 126; iter: 0; batch classifier loss: 0.054083; batch adversarial loss: 0.458141\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033010; batch adversarial loss: 0.430067\n",
      "epoch 128; iter: 0; batch classifier loss: 0.015361; batch adversarial loss: 0.420077\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031277; batch adversarial loss: 0.498996\n",
      "epoch 130; iter: 0; batch classifier loss: 0.052035; batch adversarial loss: 0.504278\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019172; batch adversarial loss: 0.437070\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050440; batch adversarial loss: 0.458856\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038856; batch adversarial loss: 0.380950\n",
      "epoch 134; iter: 0; batch classifier loss: 0.008914; batch adversarial loss: 0.432592\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028639; batch adversarial loss: 0.505166\n",
      "epoch 136; iter: 0; batch classifier loss: 0.075028; batch adversarial loss: 0.457030\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028100; batch adversarial loss: 0.429683\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018816; batch adversarial loss: 0.430764\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025857; batch adversarial loss: 0.333317\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031909; batch adversarial loss: 0.488061\n",
      "epoch 141; iter: 0; batch classifier loss: 0.015250; batch adversarial loss: 0.407641\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018257; batch adversarial loss: 0.436929\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037309; batch adversarial loss: 0.411044\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028156; batch adversarial loss: 0.490172\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022455; batch adversarial loss: 0.513982\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028586; batch adversarial loss: 0.439013\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026751; batch adversarial loss: 0.425095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.018653; batch adversarial loss: 0.461336\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016769; batch adversarial loss: 0.415611\n",
      "epoch 150; iter: 0; batch classifier loss: 0.008826; batch adversarial loss: 0.534769\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031876; batch adversarial loss: 0.457095\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024414; batch adversarial loss: 0.460291\n",
      "epoch 153; iter: 0; batch classifier loss: 0.009484; batch adversarial loss: 0.463353\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033957; batch adversarial loss: 0.475838\n",
      "epoch 155; iter: 0; batch classifier loss: 0.007411; batch adversarial loss: 0.542184\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027061; batch adversarial loss: 0.397237\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010946; batch adversarial loss: 0.439654\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021864; batch adversarial loss: 0.305140\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022891; batch adversarial loss: 0.464740\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023578; batch adversarial loss: 0.453264\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013119; batch adversarial loss: 0.325486\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028251; batch adversarial loss: 0.435001\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028951; batch adversarial loss: 0.478937\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020956; batch adversarial loss: 0.341282\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014935; batch adversarial loss: 0.469532\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012495; batch adversarial loss: 0.420594\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028196; batch adversarial loss: 0.442103\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017076; batch adversarial loss: 0.510076\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015854; batch adversarial loss: 0.481612\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033455; batch adversarial loss: 0.412625\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010928; batch adversarial loss: 0.399275\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030566; batch adversarial loss: 0.456631\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007210; batch adversarial loss: 0.427369\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022023; batch adversarial loss: 0.371939\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007530; batch adversarial loss: 0.462162\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028556; batch adversarial loss: 0.568875\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030430; batch adversarial loss: 0.451195\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011323; batch adversarial loss: 0.459295\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019294; batch adversarial loss: 0.412204\n",
      "epoch 180; iter: 0; batch classifier loss: 0.002378; batch adversarial loss: 0.510806\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017552; batch adversarial loss: 0.442484\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011499; batch adversarial loss: 0.435997\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019611; batch adversarial loss: 0.407698\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036975; batch adversarial loss: 0.465252\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016747; batch adversarial loss: 0.440488\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018609; batch adversarial loss: 0.590004\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016817; batch adversarial loss: 0.423746\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006132; batch adversarial loss: 0.437215\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026169; batch adversarial loss: 0.445280\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014528; batch adversarial loss: 0.509014\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017060; batch adversarial loss: 0.421374\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013132; batch adversarial loss: 0.384073\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009281; batch adversarial loss: 0.446808\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018390; batch adversarial loss: 0.510755\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012712; batch adversarial loss: 0.480099\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010937; batch adversarial loss: 0.465729\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004993; batch adversarial loss: 0.452559\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006721; batch adversarial loss: 0.423546\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010879; batch adversarial loss: 0.466218\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711707; batch adversarial loss: 0.944450\n",
      "epoch 1; iter: 0; batch classifier loss: 0.654929; batch adversarial loss: 0.966165\n",
      "epoch 2; iter: 0; batch classifier loss: 0.930720; batch adversarial loss: 0.999192\n",
      "epoch 3; iter: 0; batch classifier loss: 0.917307; batch adversarial loss: 0.910261\n",
      "epoch 4; iter: 0; batch classifier loss: 1.160510; batch adversarial loss: 0.898456\n",
      "epoch 5; iter: 0; batch classifier loss: 0.808207; batch adversarial loss: 0.736804\n",
      "epoch 6; iter: 0; batch classifier loss: 0.821828; batch adversarial loss: 0.697787\n",
      "epoch 7; iter: 0; batch classifier loss: 0.675601; batch adversarial loss: 0.659713\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588569; batch adversarial loss: 0.579789\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520514; batch adversarial loss: 0.543925\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374506; batch adversarial loss: 0.552492\n",
      "epoch 11; iter: 0; batch classifier loss: 0.316665; batch adversarial loss: 0.550537\n",
      "epoch 12; iter: 0; batch classifier loss: 0.331049; batch adversarial loss: 0.482281\n",
      "epoch 13; iter: 0; batch classifier loss: 0.282212; batch adversarial loss: 0.521210\n",
      "epoch 14; iter: 0; batch classifier loss: 0.338194; batch adversarial loss: 0.535474\n",
      "epoch 15; iter: 0; batch classifier loss: 0.270455; batch adversarial loss: 0.475399\n",
      "epoch 16; iter: 0; batch classifier loss: 0.249128; batch adversarial loss: 0.458635\n",
      "epoch 17; iter: 0; batch classifier loss: 0.216689; batch adversarial loss: 0.474152\n",
      "epoch 18; iter: 0; batch classifier loss: 0.199890; batch adversarial loss: 0.470096\n",
      "epoch 19; iter: 0; batch classifier loss: 0.251814; batch adversarial loss: 0.504465\n",
      "epoch 20; iter: 0; batch classifier loss: 0.235704; batch adversarial loss: 0.500057\n",
      "epoch 21; iter: 0; batch classifier loss: 0.197840; batch adversarial loss: 0.496043\n",
      "epoch 22; iter: 0; batch classifier loss: 0.246716; batch adversarial loss: 0.464809\n",
      "epoch 23; iter: 0; batch classifier loss: 0.265685; batch adversarial loss: 0.430909\n",
      "epoch 24; iter: 0; batch classifier loss: 0.144493; batch adversarial loss: 0.510806\n",
      "epoch 25; iter: 0; batch classifier loss: 0.203570; batch adversarial loss: 0.448926\n",
      "epoch 26; iter: 0; batch classifier loss: 0.245831; batch adversarial loss: 0.449523\n",
      "epoch 27; iter: 0; batch classifier loss: 0.189862; batch adversarial loss: 0.474128\n",
      "epoch 28; iter: 0; batch classifier loss: 0.208062; batch adversarial loss: 0.448942\n",
      "epoch 29; iter: 0; batch classifier loss: 0.155652; batch adversarial loss: 0.434552\n",
      "epoch 30; iter: 0; batch classifier loss: 0.162727; batch adversarial loss: 0.422310\n",
      "epoch 31; iter: 0; batch classifier loss: 0.174432; batch adversarial loss: 0.435113\n",
      "epoch 32; iter: 0; batch classifier loss: 0.135846; batch adversarial loss: 0.483237\n",
      "epoch 33; iter: 0; batch classifier loss: 0.157532; batch adversarial loss: 0.463765\n",
      "epoch 34; iter: 0; batch classifier loss: 0.126944; batch adversarial loss: 0.477757\n",
      "epoch 35; iter: 0; batch classifier loss: 0.155517; batch adversarial loss: 0.476438\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109096; batch adversarial loss: 0.423985\n",
      "epoch 37; iter: 0; batch classifier loss: 0.146582; batch adversarial loss: 0.525360\n",
      "epoch 38; iter: 0; batch classifier loss: 0.080152; batch adversarial loss: 0.446318\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131027; batch adversarial loss: 0.477746\n",
      "epoch 40; iter: 0; batch classifier loss: 0.153796; batch adversarial loss: 0.419456\n",
      "epoch 41; iter: 0; batch classifier loss: 0.159414; batch adversarial loss: 0.475232\n",
      "epoch 42; iter: 0; batch classifier loss: 0.065106; batch adversarial loss: 0.457960\n",
      "epoch 43; iter: 0; batch classifier loss: 0.076438; batch adversarial loss: 0.459043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.101806; batch adversarial loss: 0.441902\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108400; batch adversarial loss: 0.432178\n",
      "epoch 46; iter: 0; batch classifier loss: 0.131464; batch adversarial loss: 0.435098\n",
      "epoch 47; iter: 0; batch classifier loss: 0.121521; batch adversarial loss: 0.413124\n",
      "epoch 48; iter: 0; batch classifier loss: 0.124043; batch adversarial loss: 0.512123\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107551; batch adversarial loss: 0.430943\n",
      "epoch 50; iter: 0; batch classifier loss: 0.132145; batch adversarial loss: 0.429054\n",
      "epoch 51; iter: 0; batch classifier loss: 0.105543; batch adversarial loss: 0.399849\n",
      "epoch 52; iter: 0; batch classifier loss: 0.084398; batch adversarial loss: 0.459811\n",
      "epoch 53; iter: 0; batch classifier loss: 0.132679; batch adversarial loss: 0.395821\n",
      "epoch 54; iter: 0; batch classifier loss: 0.068173; batch adversarial loss: 0.390505\n",
      "epoch 55; iter: 0; batch classifier loss: 0.113038; batch adversarial loss: 0.491421\n",
      "epoch 56; iter: 0; batch classifier loss: 0.075614; batch adversarial loss: 0.361964\n",
      "epoch 57; iter: 0; batch classifier loss: 0.123581; batch adversarial loss: 0.508022\n",
      "epoch 58; iter: 0; batch classifier loss: 0.074240; batch adversarial loss: 0.387139\n",
      "epoch 59; iter: 0; batch classifier loss: 0.097064; batch adversarial loss: 0.430221\n",
      "epoch 60; iter: 0; batch classifier loss: 0.063775; batch adversarial loss: 0.431248\n",
      "epoch 61; iter: 0; batch classifier loss: 0.066607; batch adversarial loss: 0.419653\n",
      "epoch 62; iter: 0; batch classifier loss: 0.088689; batch adversarial loss: 0.423873\n",
      "epoch 63; iter: 0; batch classifier loss: 0.083910; batch adversarial loss: 0.388392\n",
      "epoch 64; iter: 0; batch classifier loss: 0.062154; batch adversarial loss: 0.471987\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074722; batch adversarial loss: 0.459251\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091869; batch adversarial loss: 0.460886\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069789; batch adversarial loss: 0.442971\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082039; batch adversarial loss: 0.506825\n",
      "epoch 69; iter: 0; batch classifier loss: 0.104571; batch adversarial loss: 0.381262\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065595; batch adversarial loss: 0.446892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064043; batch adversarial loss: 0.535174\n",
      "epoch 72; iter: 0; batch classifier loss: 0.075246; batch adversarial loss: 0.494686\n",
      "epoch 73; iter: 0; batch classifier loss: 0.060888; batch adversarial loss: 0.473007\n",
      "epoch 74; iter: 0; batch classifier loss: 0.055571; batch adversarial loss: 0.451518\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059078; batch adversarial loss: 0.621523\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058868; batch adversarial loss: 0.475584\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065983; batch adversarial loss: 0.360499\n",
      "epoch 78; iter: 0; batch classifier loss: 0.124800; batch adversarial loss: 0.373674\n",
      "epoch 79; iter: 0; batch classifier loss: 0.054989; batch adversarial loss: 0.595343\n",
      "epoch 80; iter: 0; batch classifier loss: 0.053246; batch adversarial loss: 0.303905\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075786; batch adversarial loss: 0.464662\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075252; batch adversarial loss: 0.451216\n",
      "epoch 83; iter: 0; batch classifier loss: 0.037355; batch adversarial loss: 0.484504\n",
      "epoch 84; iter: 0; batch classifier loss: 0.038405; batch adversarial loss: 0.408974\n",
      "epoch 85; iter: 0; batch classifier loss: 0.042648; batch adversarial loss: 0.390561\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046245; batch adversarial loss: 0.517409\n",
      "epoch 87; iter: 0; batch classifier loss: 0.045512; batch adversarial loss: 0.496851\n",
      "epoch 88; iter: 0; batch classifier loss: 0.032099; batch adversarial loss: 0.468150\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068488; batch adversarial loss: 0.413444\n",
      "epoch 90; iter: 0; batch classifier loss: 0.084218; batch adversarial loss: 0.489552\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075149; batch adversarial loss: 0.483910\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074921; batch adversarial loss: 0.487788\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078995; batch adversarial loss: 0.476080\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047291; batch adversarial loss: 0.450071\n",
      "epoch 95; iter: 0; batch classifier loss: 0.029881; batch adversarial loss: 0.541698\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048153; batch adversarial loss: 0.449724\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050520; batch adversarial loss: 0.456531\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052274; batch adversarial loss: 0.414701\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044101; batch adversarial loss: 0.470994\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034171; batch adversarial loss: 0.403478\n",
      "epoch 101; iter: 0; batch classifier loss: 0.060973; batch adversarial loss: 0.424656\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071374; batch adversarial loss: 0.466451\n",
      "epoch 103; iter: 0; batch classifier loss: 0.085751; batch adversarial loss: 0.317762\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065260; batch adversarial loss: 0.569650\n",
      "epoch 105; iter: 0; batch classifier loss: 0.134382; batch adversarial loss: 0.415628\n",
      "epoch 106; iter: 0; batch classifier loss: 0.064272; batch adversarial loss: 0.339562\n",
      "epoch 107; iter: 0; batch classifier loss: 0.110978; batch adversarial loss: 0.388317\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045808; batch adversarial loss: 0.406551\n",
      "epoch 109; iter: 0; batch classifier loss: 0.055539; batch adversarial loss: 0.394953\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030891; batch adversarial loss: 0.482970\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050916; batch adversarial loss: 0.460343\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038797; batch adversarial loss: 0.405712\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044378; batch adversarial loss: 0.473639\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043510; batch adversarial loss: 0.476440\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037444; batch adversarial loss: 0.424747\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034189; batch adversarial loss: 0.517214\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031127; batch adversarial loss: 0.513164\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051828; batch adversarial loss: 0.331338\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038721; batch adversarial loss: 0.423875\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043241; batch adversarial loss: 0.327973\n",
      "epoch 121; iter: 0; batch classifier loss: 0.056632; batch adversarial loss: 0.483716\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043782; batch adversarial loss: 0.447171\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019811; batch adversarial loss: 0.496518\n",
      "epoch 124; iter: 0; batch classifier loss: 0.028113; batch adversarial loss: 0.538647\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029183; batch adversarial loss: 0.388071\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036922; batch adversarial loss: 0.376187\n",
      "epoch 127; iter: 0; batch classifier loss: 0.074027; batch adversarial loss: 0.390369\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021822; batch adversarial loss: 0.433267\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029616; batch adversarial loss: 0.384981\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050473; batch adversarial loss: 0.349086\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032756; batch adversarial loss: 0.524955\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044935; batch adversarial loss: 0.490267\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022150; batch adversarial loss: 0.450073\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039921; batch adversarial loss: 0.500930\n",
      "epoch 135; iter: 0; batch classifier loss: 0.062955; batch adversarial loss: 0.375774\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028213; batch adversarial loss: 0.506039\n",
      "epoch 137; iter: 0; batch classifier loss: 0.050480; batch adversarial loss: 0.492411\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024143; batch adversarial loss: 0.400507\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033040; batch adversarial loss: 0.458673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.031657; batch adversarial loss: 0.370644\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018749; batch adversarial loss: 0.409705\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017405; batch adversarial loss: 0.395476\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019458; batch adversarial loss: 0.385466\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014123; batch adversarial loss: 0.359950\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013977; batch adversarial loss: 0.563352\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029076; batch adversarial loss: 0.397082\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029721; batch adversarial loss: 0.401700\n",
      "epoch 148; iter: 0; batch classifier loss: 0.058764; batch adversarial loss: 0.378000\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038943; batch adversarial loss: 0.510654\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029604; batch adversarial loss: 0.588677\n",
      "epoch 151; iter: 0; batch classifier loss: 0.050495; batch adversarial loss: 0.426311\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022380; batch adversarial loss: 0.421963\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013836; batch adversarial loss: 0.578547\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034298; batch adversarial loss: 0.541442\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041034; batch adversarial loss: 0.418588\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043576; batch adversarial loss: 0.430007\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011050; batch adversarial loss: 0.473777\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020626; batch adversarial loss: 0.399131\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011653; batch adversarial loss: 0.518145\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012049; batch adversarial loss: 0.390080\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038148; batch adversarial loss: 0.367801\n",
      "epoch 162; iter: 0; batch classifier loss: 0.044928; batch adversarial loss: 0.451265\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025379; batch adversarial loss: 0.469688\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017622; batch adversarial loss: 0.488507\n",
      "epoch 165; iter: 0; batch classifier loss: 0.053110; batch adversarial loss: 0.399368\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007803; batch adversarial loss: 0.464603\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032500; batch adversarial loss: 0.470339\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013969; batch adversarial loss: 0.368560\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019286; batch adversarial loss: 0.381971\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010580; batch adversarial loss: 0.427908\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014971; batch adversarial loss: 0.462691\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023138; batch adversarial loss: 0.514540\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007961; batch adversarial loss: 0.444032\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030137; batch adversarial loss: 0.441648\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030577; batch adversarial loss: 0.387113\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023708; batch adversarial loss: 0.493053\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033843; batch adversarial loss: 0.525425\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024114; batch adversarial loss: 0.627002\n",
      "epoch 179; iter: 0; batch classifier loss: 0.042135; batch adversarial loss: 0.451710\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007732; batch adversarial loss: 0.356902\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008216; batch adversarial loss: 0.507860\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016135; batch adversarial loss: 0.392084\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011839; batch adversarial loss: 0.343198\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009460; batch adversarial loss: 0.410286\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015484; batch adversarial loss: 0.418750\n",
      "epoch 186; iter: 0; batch classifier loss: 0.003303; batch adversarial loss: 0.412323\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020380; batch adversarial loss: 0.418232\n",
      "epoch 188; iter: 0; batch classifier loss: 0.004551; batch adversarial loss: 0.505839\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015972; batch adversarial loss: 0.358057\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018470; batch adversarial loss: 0.344892\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013911; batch adversarial loss: 0.348450\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035089; batch adversarial loss: 0.364578\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007552; batch adversarial loss: 0.397468\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011391; batch adversarial loss: 0.464536\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030373; batch adversarial loss: 0.381443\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031636; batch adversarial loss: 0.547541\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016108; batch adversarial loss: 0.441128\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007857; batch adversarial loss: 0.424144\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004806; batch adversarial loss: 0.453038\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720955; batch adversarial loss: 0.539778\n",
      "epoch 1; iter: 0; batch classifier loss: 0.449581; batch adversarial loss: 0.613753\n",
      "epoch 2; iter: 0; batch classifier loss: 0.391314; batch adversarial loss: 0.571592\n",
      "epoch 3; iter: 0; batch classifier loss: 0.377812; batch adversarial loss: 0.584828\n",
      "epoch 4; iter: 0; batch classifier loss: 0.358306; batch adversarial loss: 0.515211\n",
      "epoch 5; iter: 0; batch classifier loss: 0.251845; batch adversarial loss: 0.573066\n",
      "epoch 6; iter: 0; batch classifier loss: 0.282998; batch adversarial loss: 0.505528\n",
      "epoch 7; iter: 0; batch classifier loss: 0.255468; batch adversarial loss: 0.485102\n",
      "epoch 8; iter: 0; batch classifier loss: 0.288494; batch adversarial loss: 0.495874\n",
      "epoch 9; iter: 0; batch classifier loss: 0.279573; batch adversarial loss: 0.485078\n",
      "epoch 10; iter: 0; batch classifier loss: 0.264978; batch adversarial loss: 0.508288\n",
      "epoch 11; iter: 0; batch classifier loss: 0.290425; batch adversarial loss: 0.534684\n",
      "epoch 12; iter: 0; batch classifier loss: 0.281093; batch adversarial loss: 0.528002\n",
      "epoch 13; iter: 0; batch classifier loss: 0.293581; batch adversarial loss: 0.535917\n",
      "epoch 14; iter: 0; batch classifier loss: 0.248218; batch adversarial loss: 0.521589\n",
      "epoch 15; iter: 0; batch classifier loss: 0.212186; batch adversarial loss: 0.586265\n",
      "epoch 16; iter: 0; batch classifier loss: 0.257947; batch adversarial loss: 0.508117\n",
      "epoch 17; iter: 0; batch classifier loss: 0.203770; batch adversarial loss: 0.605800\n",
      "epoch 18; iter: 0; batch classifier loss: 0.294985; batch adversarial loss: 0.543531\n",
      "epoch 19; iter: 0; batch classifier loss: 0.226539; batch adversarial loss: 0.554499\n",
      "epoch 20; iter: 0; batch classifier loss: 0.279695; batch adversarial loss: 0.523589\n",
      "epoch 21; iter: 0; batch classifier loss: 0.287270; batch adversarial loss: 0.530479\n",
      "epoch 22; iter: 0; batch classifier loss: 0.249319; batch adversarial loss: 0.501222\n",
      "epoch 23; iter: 0; batch classifier loss: 0.226611; batch adversarial loss: 0.367594\n",
      "epoch 24; iter: 0; batch classifier loss: 0.282125; batch adversarial loss: 0.447625\n",
      "epoch 25; iter: 0; batch classifier loss: 0.306822; batch adversarial loss: 0.443492\n",
      "epoch 26; iter: 0; batch classifier loss: 0.227889; batch adversarial loss: 0.443757\n",
      "epoch 27; iter: 0; batch classifier loss: 0.137315; batch adversarial loss: 0.555238\n",
      "epoch 28; iter: 0; batch classifier loss: 0.174097; batch adversarial loss: 0.448945\n",
      "epoch 29; iter: 0; batch classifier loss: 0.108866; batch adversarial loss: 0.416492\n",
      "epoch 30; iter: 0; batch classifier loss: 0.111545; batch adversarial loss: 0.487101\n",
      "epoch 31; iter: 0; batch classifier loss: 0.133574; batch adversarial loss: 0.463943\n",
      "epoch 32; iter: 0; batch classifier loss: 0.137301; batch adversarial loss: 0.477172\n",
      "epoch 33; iter: 0; batch classifier loss: 0.137713; batch adversarial loss: 0.428511\n",
      "epoch 34; iter: 0; batch classifier loss: 0.123407; batch adversarial loss: 0.441660\n",
      "epoch 35; iter: 0; batch classifier loss: 0.150128; batch adversarial loss: 0.417695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.111402; batch adversarial loss: 0.442212\n",
      "epoch 37; iter: 0; batch classifier loss: 0.104190; batch adversarial loss: 0.471019\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127727; batch adversarial loss: 0.442808\n",
      "epoch 39; iter: 0; batch classifier loss: 0.124207; batch adversarial loss: 0.429639\n",
      "epoch 40; iter: 0; batch classifier loss: 0.138568; batch adversarial loss: 0.373878\n",
      "epoch 41; iter: 0; batch classifier loss: 0.069831; batch adversarial loss: 0.433302\n",
      "epoch 42; iter: 0; batch classifier loss: 0.121579; batch adversarial loss: 0.423360\n",
      "epoch 43; iter: 0; batch classifier loss: 0.094786; batch adversarial loss: 0.380645\n",
      "epoch 44; iter: 0; batch classifier loss: 0.045354; batch adversarial loss: 0.422292\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103448; batch adversarial loss: 0.404681\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126872; batch adversarial loss: 0.399873\n",
      "epoch 47; iter: 0; batch classifier loss: 0.084967; batch adversarial loss: 0.393069\n",
      "epoch 48; iter: 0; batch classifier loss: 0.073286; batch adversarial loss: 0.398900\n",
      "epoch 49; iter: 0; batch classifier loss: 0.128375; batch adversarial loss: 0.486598\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108808; batch adversarial loss: 0.483380\n",
      "epoch 51; iter: 0; batch classifier loss: 0.068485; batch adversarial loss: 0.545403\n",
      "epoch 52; iter: 0; batch classifier loss: 0.119870; batch adversarial loss: 0.456689\n",
      "epoch 53; iter: 0; batch classifier loss: 0.060539; batch adversarial loss: 0.431057\n",
      "epoch 54; iter: 0; batch classifier loss: 0.056150; batch adversarial loss: 0.500085\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096475; batch adversarial loss: 0.468938\n",
      "epoch 56; iter: 0; batch classifier loss: 0.112746; batch adversarial loss: 0.367855\n",
      "epoch 57; iter: 0; batch classifier loss: 0.070038; batch adversarial loss: 0.404258\n",
      "epoch 58; iter: 0; batch classifier loss: 0.099715; batch adversarial loss: 0.379128\n",
      "epoch 59; iter: 0; batch classifier loss: 0.091918; batch adversarial loss: 0.506432\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097214; batch adversarial loss: 0.378368\n",
      "epoch 61; iter: 0; batch classifier loss: 0.091204; batch adversarial loss: 0.360260\n",
      "epoch 62; iter: 0; batch classifier loss: 0.111029; batch adversarial loss: 0.387164\n",
      "epoch 63; iter: 0; batch classifier loss: 0.094404; batch adversarial loss: 0.392821\n",
      "epoch 64; iter: 0; batch classifier loss: 0.060358; batch adversarial loss: 0.568928\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088492; batch adversarial loss: 0.470580\n",
      "epoch 66; iter: 0; batch classifier loss: 0.046934; batch adversarial loss: 0.520013\n",
      "epoch 67; iter: 0; batch classifier loss: 0.074751; batch adversarial loss: 0.377581\n",
      "epoch 68; iter: 0; batch classifier loss: 0.063663; batch adversarial loss: 0.479308\n",
      "epoch 69; iter: 0; batch classifier loss: 0.080600; batch adversarial loss: 0.427744\n",
      "epoch 70; iter: 0; batch classifier loss: 0.109894; batch adversarial loss: 0.470686\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071620; batch adversarial loss: 0.370772\n",
      "epoch 72; iter: 0; batch classifier loss: 0.052162; batch adversarial loss: 0.385672\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069447; batch adversarial loss: 0.516479\n",
      "epoch 74; iter: 0; batch classifier loss: 0.071176; batch adversarial loss: 0.536498\n",
      "epoch 75; iter: 0; batch classifier loss: 0.064388; batch adversarial loss: 0.378516\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065393; batch adversarial loss: 0.445258\n",
      "epoch 77; iter: 0; batch classifier loss: 0.054636; batch adversarial loss: 0.460705\n",
      "epoch 78; iter: 0; batch classifier loss: 0.043570; batch adversarial loss: 0.357414\n",
      "epoch 79; iter: 0; batch classifier loss: 0.104247; batch adversarial loss: 0.521701\n",
      "epoch 80; iter: 0; batch classifier loss: 0.046382; batch adversarial loss: 0.459846\n",
      "epoch 81; iter: 0; batch classifier loss: 0.101831; batch adversarial loss: 0.427906\n",
      "epoch 82; iter: 0; batch classifier loss: 0.078684; batch adversarial loss: 0.389025\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056598; batch adversarial loss: 0.381316\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075593; batch adversarial loss: 0.500650\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064575; batch adversarial loss: 0.505651\n",
      "epoch 86; iter: 0; batch classifier loss: 0.094287; batch adversarial loss: 0.527057\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068360; batch adversarial loss: 0.492140\n",
      "epoch 88; iter: 0; batch classifier loss: 0.065091; batch adversarial loss: 0.460797\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048255; batch adversarial loss: 0.413337\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048330; batch adversarial loss: 0.481356\n",
      "epoch 91; iter: 0; batch classifier loss: 0.079900; batch adversarial loss: 0.393444\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060325; batch adversarial loss: 0.382326\n",
      "epoch 93; iter: 0; batch classifier loss: 0.023920; batch adversarial loss: 0.432944\n",
      "epoch 94; iter: 0; batch classifier loss: 0.102853; batch adversarial loss: 0.458233\n",
      "epoch 95; iter: 0; batch classifier loss: 0.026111; batch adversarial loss: 0.446613\n",
      "epoch 96; iter: 0; batch classifier loss: 0.108041; batch adversarial loss: 0.588881\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062581; batch adversarial loss: 0.514230\n",
      "epoch 98; iter: 0; batch classifier loss: 0.057914; batch adversarial loss: 0.434563\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057159; batch adversarial loss: 0.479369\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039098; batch adversarial loss: 0.402106\n",
      "epoch 101; iter: 0; batch classifier loss: 0.117221; batch adversarial loss: 0.357620\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047006; batch adversarial loss: 0.371650\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045817; batch adversarial loss: 0.455303\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043420; batch adversarial loss: 0.442773\n",
      "epoch 105; iter: 0; batch classifier loss: 0.036918; batch adversarial loss: 0.392428\n",
      "epoch 106; iter: 0; batch classifier loss: 0.020515; batch adversarial loss: 0.434347\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059417; batch adversarial loss: 0.506354\n",
      "epoch 108; iter: 0; batch classifier loss: 0.018268; batch adversarial loss: 0.457481\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054632; batch adversarial loss: 0.461860\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067109; batch adversarial loss: 0.299883\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066933; batch adversarial loss: 0.407699\n",
      "epoch 112; iter: 0; batch classifier loss: 0.049419; batch adversarial loss: 0.411134\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044995; batch adversarial loss: 0.414507\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060586; batch adversarial loss: 0.421098\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024164; batch adversarial loss: 0.475543\n",
      "epoch 116; iter: 0; batch classifier loss: 0.063711; batch adversarial loss: 0.492230\n",
      "epoch 117; iter: 0; batch classifier loss: 0.078076; batch adversarial loss: 0.412010\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052922; batch adversarial loss: 0.499573\n",
      "epoch 119; iter: 0; batch classifier loss: 0.098651; batch adversarial loss: 0.499731\n",
      "epoch 120; iter: 0; batch classifier loss: 0.073121; batch adversarial loss: 0.405765\n",
      "epoch 121; iter: 0; batch classifier loss: 0.073281; batch adversarial loss: 0.456900\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033236; batch adversarial loss: 0.368647\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044055; batch adversarial loss: 0.545532\n",
      "epoch 124; iter: 0; batch classifier loss: 0.079653; batch adversarial loss: 0.499720\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041244; batch adversarial loss: 0.524362\n",
      "epoch 126; iter: 0; batch classifier loss: 0.091254; batch adversarial loss: 0.436724\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040345; batch adversarial loss: 0.511272\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036402; batch adversarial loss: 0.481120\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022847; batch adversarial loss: 0.492445\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033333; batch adversarial loss: 0.537973\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025534; batch adversarial loss: 0.461908\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036166; batch adversarial loss: 0.455735\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019531; batch adversarial loss: 0.499416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.074621; batch adversarial loss: 0.385342\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044232; batch adversarial loss: 0.404986\n",
      "epoch 136; iter: 0; batch classifier loss: 0.073312; batch adversarial loss: 0.424437\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046927; batch adversarial loss: 0.490807\n",
      "epoch 138; iter: 0; batch classifier loss: 0.067123; batch adversarial loss: 0.437057\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018237; batch adversarial loss: 0.453090\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019097; batch adversarial loss: 0.382335\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023131; batch adversarial loss: 0.595122\n",
      "epoch 142; iter: 0; batch classifier loss: 0.054587; batch adversarial loss: 0.438180\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039074; batch adversarial loss: 0.460512\n",
      "epoch 144; iter: 0; batch classifier loss: 0.071292; batch adversarial loss: 0.468450\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042598; batch adversarial loss: 0.431094\n",
      "epoch 146; iter: 0; batch classifier loss: 0.071279; batch adversarial loss: 0.373065\n",
      "epoch 147; iter: 0; batch classifier loss: 0.071485; batch adversarial loss: 0.430173\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027190; batch adversarial loss: 0.428065\n",
      "epoch 149; iter: 0; batch classifier loss: 0.008496; batch adversarial loss: 0.511400\n",
      "epoch 150; iter: 0; batch classifier loss: 0.046119; batch adversarial loss: 0.349935\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038822; batch adversarial loss: 0.427001\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019291; batch adversarial loss: 0.423128\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025422; batch adversarial loss: 0.462683\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044511; batch adversarial loss: 0.409160\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041325; batch adversarial loss: 0.412198\n",
      "epoch 156; iter: 0; batch classifier loss: 0.114361; batch adversarial loss: 0.401284\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021200; batch adversarial loss: 0.420831\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023879; batch adversarial loss: 0.477142\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031019; batch adversarial loss: 0.549246\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025296; batch adversarial loss: 0.431735\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033522; batch adversarial loss: 0.450719\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017434; batch adversarial loss: 0.499461\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026487; batch adversarial loss: 0.409582\n",
      "epoch 164; iter: 0; batch classifier loss: 0.073617; batch adversarial loss: 0.452447\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044219; batch adversarial loss: 0.341045\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021452; batch adversarial loss: 0.381396\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033915; batch adversarial loss: 0.440156\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014789; batch adversarial loss: 0.512745\n",
      "epoch 169; iter: 0; batch classifier loss: 0.046659; batch adversarial loss: 0.420358\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027177; batch adversarial loss: 0.458803\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038622; batch adversarial loss: 0.549636\n",
      "epoch 172; iter: 0; batch classifier loss: 0.035991; batch adversarial loss: 0.419297\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033892; batch adversarial loss: 0.468634\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023171; batch adversarial loss: 0.390246\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028557; batch adversarial loss: 0.419798\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027941; batch adversarial loss: 0.431993\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020636; batch adversarial loss: 0.406789\n",
      "epoch 178; iter: 0; batch classifier loss: 0.047814; batch adversarial loss: 0.394901\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034903; batch adversarial loss: 0.469453\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014045; batch adversarial loss: 0.419462\n",
      "epoch 181; iter: 0; batch classifier loss: 0.049566; batch adversarial loss: 0.406970\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013844; batch adversarial loss: 0.533239\n",
      "epoch 183; iter: 0; batch classifier loss: 0.040648; batch adversarial loss: 0.506305\n",
      "epoch 184; iter: 0; batch classifier loss: 0.055336; batch adversarial loss: 0.361157\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028157; batch adversarial loss: 0.431316\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019199; batch adversarial loss: 0.407708\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035910; batch adversarial loss: 0.411640\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026542; batch adversarial loss: 0.418920\n",
      "epoch 189; iter: 0; batch classifier loss: 0.050365; batch adversarial loss: 0.434503\n",
      "epoch 190; iter: 0; batch classifier loss: 0.039106; batch adversarial loss: 0.455963\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030402; batch adversarial loss: 0.471678\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025127; batch adversarial loss: 0.468493\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011750; batch adversarial loss: 0.528337\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026758; batch adversarial loss: 0.503327\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018047; batch adversarial loss: 0.472320\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015959; batch adversarial loss: 0.437416\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027451; batch adversarial loss: 0.514809\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016960; batch adversarial loss: 0.505850\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007582; batch adversarial loss: 0.416236\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689354; batch adversarial loss: 0.826709\n",
      "epoch 1; iter: 0; batch classifier loss: 0.439175; batch adversarial loss: 0.785172\n",
      "epoch 2; iter: 0; batch classifier loss: 0.414444; batch adversarial loss: 0.744136\n",
      "epoch 3; iter: 0; batch classifier loss: 0.485783; batch adversarial loss: 0.674909\n",
      "epoch 4; iter: 0; batch classifier loss: 0.279473; batch adversarial loss: 0.654217\n",
      "epoch 5; iter: 0; batch classifier loss: 0.334251; batch adversarial loss: 0.625555\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331361; batch adversarial loss: 0.591965\n",
      "epoch 7; iter: 0; batch classifier loss: 0.247559; batch adversarial loss: 0.562967\n",
      "epoch 8; iter: 0; batch classifier loss: 0.286391; batch adversarial loss: 0.553299\n",
      "epoch 9; iter: 0; batch classifier loss: 0.281454; batch adversarial loss: 0.525029\n",
      "epoch 10; iter: 0; batch classifier loss: 0.229918; batch adversarial loss: 0.562542\n",
      "epoch 11; iter: 0; batch classifier loss: 0.251725; batch adversarial loss: 0.473404\n",
      "epoch 12; iter: 0; batch classifier loss: 0.250706; batch adversarial loss: 0.498686\n",
      "epoch 13; iter: 0; batch classifier loss: 0.250113; batch adversarial loss: 0.497685\n",
      "epoch 14; iter: 0; batch classifier loss: 0.217722; batch adversarial loss: 0.445395\n",
      "epoch 15; iter: 0; batch classifier loss: 0.213045; batch adversarial loss: 0.471968\n",
      "epoch 16; iter: 0; batch classifier loss: 0.168419; batch adversarial loss: 0.437399\n",
      "epoch 17; iter: 0; batch classifier loss: 0.189060; batch adversarial loss: 0.420428\n",
      "epoch 18; iter: 0; batch classifier loss: 0.203656; batch adversarial loss: 0.423771\n",
      "epoch 19; iter: 0; batch classifier loss: 0.259807; batch adversarial loss: 0.464916\n",
      "epoch 20; iter: 0; batch classifier loss: 0.146703; batch adversarial loss: 0.466870\n",
      "epoch 21; iter: 0; batch classifier loss: 0.213853; batch adversarial loss: 0.472458\n",
      "epoch 22; iter: 0; batch classifier loss: 0.138350; batch adversarial loss: 0.431374\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168328; batch adversarial loss: 0.435535\n",
      "epoch 24; iter: 0; batch classifier loss: 0.173871; batch adversarial loss: 0.422433\n",
      "epoch 25; iter: 0; batch classifier loss: 0.189898; batch adversarial loss: 0.465591\n",
      "epoch 26; iter: 0; batch classifier loss: 0.139030; batch adversarial loss: 0.488065\n",
      "epoch 27; iter: 0; batch classifier loss: 0.158194; batch adversarial loss: 0.425815\n",
      "epoch 28; iter: 0; batch classifier loss: 0.156441; batch adversarial loss: 0.400177\n",
      "epoch 29; iter: 0; batch classifier loss: 0.187434; batch adversarial loss: 0.491398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.124752; batch adversarial loss: 0.340332\n",
      "epoch 31; iter: 0; batch classifier loss: 0.181099; batch adversarial loss: 0.428414\n",
      "epoch 32; iter: 0; batch classifier loss: 0.110033; batch adversarial loss: 0.444410\n",
      "epoch 33; iter: 0; batch classifier loss: 0.134015; batch adversarial loss: 0.394477\n",
      "epoch 34; iter: 0; batch classifier loss: 0.149978; batch adversarial loss: 0.426539\n",
      "epoch 35; iter: 0; batch classifier loss: 0.096690; batch adversarial loss: 0.371871\n",
      "epoch 36; iter: 0; batch classifier loss: 0.084530; batch adversarial loss: 0.359059\n",
      "epoch 37; iter: 0; batch classifier loss: 0.140927; batch adversarial loss: 0.386130\n",
      "epoch 38; iter: 0; batch classifier loss: 0.109669; batch adversarial loss: 0.427950\n",
      "epoch 39; iter: 0; batch classifier loss: 0.138549; batch adversarial loss: 0.425282\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154276; batch adversarial loss: 0.417568\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106283; batch adversarial loss: 0.511062\n",
      "epoch 42; iter: 0; batch classifier loss: 0.104942; batch adversarial loss: 0.423348\n",
      "epoch 43; iter: 0; batch classifier loss: 0.115949; batch adversarial loss: 0.381560\n",
      "epoch 44; iter: 0; batch classifier loss: 0.114678; batch adversarial loss: 0.410454\n",
      "epoch 45; iter: 0; batch classifier loss: 0.133421; batch adversarial loss: 0.465671\n",
      "epoch 46; iter: 0; batch classifier loss: 0.109965; batch adversarial loss: 0.435094\n",
      "epoch 47; iter: 0; batch classifier loss: 0.118198; batch adversarial loss: 0.408247\n",
      "epoch 48; iter: 0; batch classifier loss: 0.086367; batch adversarial loss: 0.408253\n",
      "epoch 49; iter: 0; batch classifier loss: 0.081880; batch adversarial loss: 0.428798\n",
      "epoch 50; iter: 0; batch classifier loss: 0.137976; batch adversarial loss: 0.424980\n",
      "epoch 51; iter: 0; batch classifier loss: 0.078807; batch adversarial loss: 0.428663\n",
      "epoch 52; iter: 0; batch classifier loss: 0.107270; batch adversarial loss: 0.481821\n",
      "epoch 53; iter: 0; batch classifier loss: 0.092348; batch adversarial loss: 0.412721\n",
      "epoch 54; iter: 0; batch classifier loss: 0.098802; batch adversarial loss: 0.456172\n",
      "epoch 55; iter: 0; batch classifier loss: 0.067688; batch adversarial loss: 0.412995\n",
      "epoch 56; iter: 0; batch classifier loss: 0.076220; batch adversarial loss: 0.376075\n",
      "epoch 57; iter: 0; batch classifier loss: 0.065863; batch adversarial loss: 0.383864\n",
      "epoch 58; iter: 0; batch classifier loss: 0.068535; batch adversarial loss: 0.399001\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087728; batch adversarial loss: 0.370695\n",
      "epoch 60; iter: 0; batch classifier loss: 0.071548; batch adversarial loss: 0.583476\n",
      "epoch 61; iter: 0; batch classifier loss: 0.064734; batch adversarial loss: 0.430862\n",
      "epoch 62; iter: 0; batch classifier loss: 0.120768; batch adversarial loss: 0.442380\n",
      "epoch 63; iter: 0; batch classifier loss: 0.067386; batch adversarial loss: 0.376425\n",
      "epoch 64; iter: 0; batch classifier loss: 0.059977; batch adversarial loss: 0.443212\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079480; batch adversarial loss: 0.455532\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073832; batch adversarial loss: 0.445186\n",
      "epoch 67; iter: 0; batch classifier loss: 0.083331; batch adversarial loss: 0.355025\n",
      "epoch 68; iter: 0; batch classifier loss: 0.145447; batch adversarial loss: 0.440696\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076762; batch adversarial loss: 0.362085\n",
      "epoch 70; iter: 0; batch classifier loss: 0.092795; batch adversarial loss: 0.337234\n",
      "epoch 71; iter: 0; batch classifier loss: 0.046710; batch adversarial loss: 0.447719\n",
      "epoch 72; iter: 0; batch classifier loss: 0.124741; batch adversarial loss: 0.428124\n",
      "epoch 73; iter: 0; batch classifier loss: 0.094150; batch adversarial loss: 0.376051\n",
      "epoch 74; iter: 0; batch classifier loss: 0.047758; batch adversarial loss: 0.309040\n",
      "epoch 75; iter: 0; batch classifier loss: 0.064511; batch adversarial loss: 0.409896\n",
      "epoch 76; iter: 0; batch classifier loss: 0.053250; batch adversarial loss: 0.443220\n",
      "epoch 77; iter: 0; batch classifier loss: 0.046557; batch adversarial loss: 0.501740\n",
      "epoch 78; iter: 0; batch classifier loss: 0.091058; batch adversarial loss: 0.415460\n",
      "epoch 79; iter: 0; batch classifier loss: 0.097913; batch adversarial loss: 0.444072\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054633; batch adversarial loss: 0.405942\n",
      "epoch 81; iter: 0; batch classifier loss: 0.063355; batch adversarial loss: 0.467050\n",
      "epoch 82; iter: 0; batch classifier loss: 0.070476; batch adversarial loss: 0.415642\n",
      "epoch 83; iter: 0; batch classifier loss: 0.093917; batch adversarial loss: 0.442065\n",
      "epoch 84; iter: 0; batch classifier loss: 0.095928; batch adversarial loss: 0.365215\n",
      "epoch 85; iter: 0; batch classifier loss: 0.133831; batch adversarial loss: 0.352977\n",
      "epoch 86; iter: 0; batch classifier loss: 0.133756; batch adversarial loss: 0.319738\n",
      "epoch 87; iter: 0; batch classifier loss: 0.099885; batch adversarial loss: 0.467196\n",
      "epoch 88; iter: 0; batch classifier loss: 0.081982; batch adversarial loss: 0.460793\n",
      "epoch 89; iter: 0; batch classifier loss: 0.070512; batch adversarial loss: 0.465445\n",
      "epoch 90; iter: 0; batch classifier loss: 0.076577; batch adversarial loss: 0.439076\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046847; batch adversarial loss: 0.500285\n",
      "epoch 92; iter: 0; batch classifier loss: 0.088725; batch adversarial loss: 0.455822\n",
      "epoch 93; iter: 0; batch classifier loss: 0.068089; batch adversarial loss: 0.377900\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033328; batch adversarial loss: 0.413697\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045961; batch adversarial loss: 0.373786\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059501; batch adversarial loss: 0.375020\n",
      "epoch 97; iter: 0; batch classifier loss: 0.035980; batch adversarial loss: 0.372120\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079082; batch adversarial loss: 0.501458\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045674; batch adversarial loss: 0.434132\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061899; batch adversarial loss: 0.378865\n",
      "epoch 101; iter: 0; batch classifier loss: 0.103861; batch adversarial loss: 0.434310\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057045; batch adversarial loss: 0.464841\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059274; batch adversarial loss: 0.480683\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062327; batch adversarial loss: 0.392573\n",
      "epoch 105; iter: 0; batch classifier loss: 0.079019; batch adversarial loss: 0.405444\n",
      "epoch 106; iter: 0; batch classifier loss: 0.092446; batch adversarial loss: 0.403023\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051622; batch adversarial loss: 0.444925\n",
      "epoch 108; iter: 0; batch classifier loss: 0.063990; batch adversarial loss: 0.476338\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057109; batch adversarial loss: 0.387885\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049042; batch adversarial loss: 0.423455\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050815; batch adversarial loss: 0.521888\n",
      "epoch 112; iter: 0; batch classifier loss: 0.067600; batch adversarial loss: 0.439301\n",
      "epoch 113; iter: 0; batch classifier loss: 0.100241; batch adversarial loss: 0.452656\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047287; batch adversarial loss: 0.442704\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052676; batch adversarial loss: 0.437421\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052531; batch adversarial loss: 0.427955\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052228; batch adversarial loss: 0.389715\n",
      "epoch 118; iter: 0; batch classifier loss: 0.088556; batch adversarial loss: 0.392240\n",
      "epoch 119; iter: 0; batch classifier loss: 0.074751; batch adversarial loss: 0.314542\n",
      "epoch 120; iter: 0; batch classifier loss: 0.021194; batch adversarial loss: 0.485277\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047469; batch adversarial loss: 0.415185\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037852; batch adversarial loss: 0.479430\n",
      "epoch 123; iter: 0; batch classifier loss: 0.079617; batch adversarial loss: 0.464701\n",
      "epoch 124; iter: 0; batch classifier loss: 0.068386; batch adversarial loss: 0.401275\n",
      "epoch 125; iter: 0; batch classifier loss: 0.078715; batch adversarial loss: 0.355956\n",
      "epoch 126; iter: 0; batch classifier loss: 0.052878; batch adversarial loss: 0.483233\n",
      "epoch 127; iter: 0; batch classifier loss: 0.065962; batch adversarial loss: 0.412190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.047720; batch adversarial loss: 0.338901\n",
      "epoch 129; iter: 0; batch classifier loss: 0.073993; batch adversarial loss: 0.405888\n",
      "epoch 130; iter: 0; batch classifier loss: 0.049782; batch adversarial loss: 0.451024\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034902; batch adversarial loss: 0.459158\n",
      "epoch 132; iter: 0; batch classifier loss: 0.056745; batch adversarial loss: 0.465649\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060515; batch adversarial loss: 0.386347\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050003; batch adversarial loss: 0.421286\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028447; batch adversarial loss: 0.456735\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022729; batch adversarial loss: 0.338640\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043281; batch adversarial loss: 0.492207\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030413; batch adversarial loss: 0.498757\n",
      "epoch 139; iter: 0; batch classifier loss: 0.053263; batch adversarial loss: 0.464857\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051750; batch adversarial loss: 0.513743\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037383; batch adversarial loss: 0.443749\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041757; batch adversarial loss: 0.394772\n",
      "epoch 143; iter: 0; batch classifier loss: 0.052702; batch adversarial loss: 0.396950\n",
      "epoch 144; iter: 0; batch classifier loss: 0.081922; batch adversarial loss: 0.423640\n",
      "epoch 145; iter: 0; batch classifier loss: 0.092116; batch adversarial loss: 0.506184\n",
      "epoch 146; iter: 0; batch classifier loss: 0.066864; batch adversarial loss: 0.356807\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040237; batch adversarial loss: 0.413582\n",
      "epoch 148; iter: 0; batch classifier loss: 0.044690; batch adversarial loss: 0.381077\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027768; batch adversarial loss: 0.539096\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038179; batch adversarial loss: 0.458634\n",
      "epoch 151; iter: 0; batch classifier loss: 0.066184; batch adversarial loss: 0.386365\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037939; batch adversarial loss: 0.455599\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035713; batch adversarial loss: 0.398774\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025635; batch adversarial loss: 0.483540\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015971; batch adversarial loss: 0.499931\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022999; batch adversarial loss: 0.389523\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033525; batch adversarial loss: 0.362647\n",
      "epoch 158; iter: 0; batch classifier loss: 0.057869; batch adversarial loss: 0.423745\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014092; batch adversarial loss: 0.457754\n",
      "epoch 160; iter: 0; batch classifier loss: 0.011732; batch adversarial loss: 0.510373\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023475; batch adversarial loss: 0.340077\n",
      "epoch 162; iter: 0; batch classifier loss: 0.055867; batch adversarial loss: 0.545660\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030092; batch adversarial loss: 0.486842\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026816; batch adversarial loss: 0.467531\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038396; batch adversarial loss: 0.449008\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029329; batch adversarial loss: 0.416803\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020231; batch adversarial loss: 0.405482\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036161; batch adversarial loss: 0.357796\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022594; batch adversarial loss: 0.467506\n",
      "epoch 170; iter: 0; batch classifier loss: 0.054074; batch adversarial loss: 0.536905\n",
      "epoch 171; iter: 0; batch classifier loss: 0.037835; batch adversarial loss: 0.446916\n",
      "epoch 172; iter: 0; batch classifier loss: 0.071459; batch adversarial loss: 0.673585\n",
      "epoch 173; iter: 0; batch classifier loss: 0.089783; batch adversarial loss: 0.526999\n",
      "epoch 174; iter: 0; batch classifier loss: 0.084021; batch adversarial loss: 0.706387\n",
      "epoch 175; iter: 0; batch classifier loss: 0.103287; batch adversarial loss: 0.652289\n",
      "epoch 176; iter: 0; batch classifier loss: 0.135373; batch adversarial loss: 0.649871\n",
      "epoch 177; iter: 0; batch classifier loss: 0.071288; batch adversarial loss: 0.447994\n",
      "epoch 178; iter: 0; batch classifier loss: 0.093478; batch adversarial loss: 0.569522\n",
      "epoch 179; iter: 0; batch classifier loss: 0.128078; batch adversarial loss: 0.653274\n",
      "epoch 180; iter: 0; batch classifier loss: 0.092649; batch adversarial loss: 0.592668\n",
      "epoch 181; iter: 0; batch classifier loss: 0.237365; batch adversarial loss: 0.733226\n",
      "epoch 182; iter: 0; batch classifier loss: 0.101662; batch adversarial loss: 0.499985\n",
      "epoch 183; iter: 0; batch classifier loss: 0.184815; batch adversarial loss: 0.664069\n",
      "epoch 184; iter: 0; batch classifier loss: 0.164988; batch adversarial loss: 0.660844\n",
      "epoch 185; iter: 0; batch classifier loss: 0.172539; batch adversarial loss: 0.551896\n",
      "epoch 186; iter: 0; batch classifier loss: 0.329407; batch adversarial loss: 0.768712\n",
      "epoch 187; iter: 0; batch classifier loss: 0.107375; batch adversarial loss: 0.442748\n",
      "epoch 188; iter: 0; batch classifier loss: 0.290486; batch adversarial loss: 0.925039\n",
      "epoch 189; iter: 0; batch classifier loss: 0.150215; batch adversarial loss: 0.618559\n",
      "epoch 190; iter: 0; batch classifier loss: 0.176366; batch adversarial loss: 0.657749\n",
      "epoch 191; iter: 0; batch classifier loss: 0.208806; batch adversarial loss: 0.703113\n",
      "epoch 192; iter: 0; batch classifier loss: 0.247353; batch adversarial loss: 0.696955\n",
      "epoch 193; iter: 0; batch classifier loss: 0.140481; batch adversarial loss: 0.547222\n",
      "epoch 194; iter: 0; batch classifier loss: 0.206708; batch adversarial loss: 0.606401\n",
      "epoch 195; iter: 0; batch classifier loss: 0.212885; batch adversarial loss: 0.732723\n",
      "epoch 196; iter: 0; batch classifier loss: 0.230728; batch adversarial loss: 0.617442\n",
      "epoch 197; iter: 0; batch classifier loss: 0.123628; batch adversarial loss: 0.505256\n",
      "epoch 198; iter: 0; batch classifier loss: 0.114795; batch adversarial loss: 0.457532\n",
      "epoch 199; iter: 0; batch classifier loss: 0.132484; batch adversarial loss: 0.510871\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707064; batch adversarial loss: 0.597126\n",
      "epoch 1; iter: 0; batch classifier loss: 0.480959; batch adversarial loss: 0.612846\n",
      "epoch 2; iter: 0; batch classifier loss: 0.367883; batch adversarial loss: 0.587398\n",
      "epoch 3; iter: 0; batch classifier loss: 0.333251; batch adversarial loss: 0.565677\n",
      "epoch 4; iter: 0; batch classifier loss: 0.253011; batch adversarial loss: 0.603590\n",
      "epoch 5; iter: 0; batch classifier loss: 0.313754; batch adversarial loss: 0.496763\n",
      "epoch 6; iter: 0; batch classifier loss: 0.282846; batch adversarial loss: 0.496658\n",
      "epoch 7; iter: 0; batch classifier loss: 0.291482; batch adversarial loss: 0.558254\n",
      "epoch 8; iter: 0; batch classifier loss: 0.387149; batch adversarial loss: 0.498096\n",
      "epoch 9; iter: 0; batch classifier loss: 0.334428; batch adversarial loss: 0.550666\n",
      "epoch 10; iter: 0; batch classifier loss: 0.272775; batch adversarial loss: 0.528437\n",
      "epoch 11; iter: 0; batch classifier loss: 0.208275; batch adversarial loss: 0.469112\n",
      "epoch 12; iter: 0; batch classifier loss: 0.185372; batch adversarial loss: 0.574427\n",
      "epoch 13; iter: 0; batch classifier loss: 0.244220; batch adversarial loss: 0.540284\n",
      "epoch 14; iter: 0; batch classifier loss: 0.229845; batch adversarial loss: 0.530621\n",
      "epoch 15; iter: 0; batch classifier loss: 0.260715; batch adversarial loss: 0.550792\n",
      "epoch 16; iter: 0; batch classifier loss: 0.231465; batch adversarial loss: 0.488987\n",
      "epoch 17; iter: 0; batch classifier loss: 0.243504; batch adversarial loss: 0.570492\n",
      "epoch 18; iter: 0; batch classifier loss: 0.292270; batch adversarial loss: 0.483161\n",
      "epoch 19; iter: 0; batch classifier loss: 0.366419; batch adversarial loss: 0.613236\n",
      "epoch 20; iter: 0; batch classifier loss: 0.195982; batch adversarial loss: 0.499655\n",
      "epoch 21; iter: 0; batch classifier loss: 0.315027; batch adversarial loss: 0.579525\n",
      "epoch 22; iter: 0; batch classifier loss: 0.295243; batch adversarial loss: 0.533888\n",
      "epoch 23; iter: 0; batch classifier loss: 0.331232; batch adversarial loss: 0.510638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.289377; batch adversarial loss: 0.444208\n",
      "epoch 25; iter: 0; batch classifier loss: 0.418975; batch adversarial loss: 0.398321\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223822; batch adversarial loss: 0.430813\n",
      "epoch 27; iter: 0; batch classifier loss: 0.139133; batch adversarial loss: 0.457576\n",
      "epoch 28; iter: 0; batch classifier loss: 0.126599; batch adversarial loss: 0.480361\n",
      "epoch 29; iter: 0; batch classifier loss: 0.175143; batch adversarial loss: 0.455089\n",
      "epoch 30; iter: 0; batch classifier loss: 0.122758; batch adversarial loss: 0.367924\n",
      "epoch 31; iter: 0; batch classifier loss: 0.151037; batch adversarial loss: 0.534969\n",
      "epoch 32; iter: 0; batch classifier loss: 0.122540; batch adversarial loss: 0.459901\n",
      "epoch 33; iter: 0; batch classifier loss: 0.154664; batch adversarial loss: 0.453121\n",
      "epoch 34; iter: 0; batch classifier loss: 0.119667; batch adversarial loss: 0.545648\n",
      "epoch 35; iter: 0; batch classifier loss: 0.154619; batch adversarial loss: 0.487787\n",
      "epoch 36; iter: 0; batch classifier loss: 0.100430; batch adversarial loss: 0.495385\n",
      "epoch 37; iter: 0; batch classifier loss: 0.087435; batch adversarial loss: 0.415209\n",
      "epoch 38; iter: 0; batch classifier loss: 0.080390; batch adversarial loss: 0.484893\n",
      "epoch 39; iter: 0; batch classifier loss: 0.115985; batch adversarial loss: 0.486127\n",
      "epoch 40; iter: 0; batch classifier loss: 0.138084; batch adversarial loss: 0.466829\n",
      "epoch 41; iter: 0; batch classifier loss: 0.135102; batch adversarial loss: 0.420169\n",
      "epoch 42; iter: 0; batch classifier loss: 0.119395; batch adversarial loss: 0.450429\n",
      "epoch 43; iter: 0; batch classifier loss: 0.116843; batch adversarial loss: 0.359603\n",
      "epoch 44; iter: 0; batch classifier loss: 0.091262; batch adversarial loss: 0.486054\n",
      "epoch 45; iter: 0; batch classifier loss: 0.098818; batch adversarial loss: 0.468318\n",
      "epoch 46; iter: 0; batch classifier loss: 0.059995; batch adversarial loss: 0.474272\n",
      "epoch 47; iter: 0; batch classifier loss: 0.074280; batch adversarial loss: 0.501265\n",
      "epoch 48; iter: 0; batch classifier loss: 0.163776; batch adversarial loss: 0.523637\n",
      "epoch 49; iter: 0; batch classifier loss: 0.163427; batch adversarial loss: 0.492589\n",
      "epoch 50; iter: 0; batch classifier loss: 0.058776; batch adversarial loss: 0.429892\n",
      "epoch 51; iter: 0; batch classifier loss: 0.072979; batch adversarial loss: 0.394637\n",
      "epoch 52; iter: 0; batch classifier loss: 0.050925; batch adversarial loss: 0.439733\n",
      "epoch 53; iter: 0; batch classifier loss: 0.075540; batch adversarial loss: 0.419411\n",
      "epoch 54; iter: 0; batch classifier loss: 0.081911; batch adversarial loss: 0.429094\n",
      "epoch 55; iter: 0; batch classifier loss: 0.064018; batch adversarial loss: 0.433095\n",
      "epoch 56; iter: 0; batch classifier loss: 0.073423; batch adversarial loss: 0.393232\n",
      "epoch 57; iter: 0; batch classifier loss: 0.119852; batch adversarial loss: 0.326955\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077378; batch adversarial loss: 0.436061\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070246; batch adversarial loss: 0.467358\n",
      "epoch 60; iter: 0; batch classifier loss: 0.047442; batch adversarial loss: 0.489607\n",
      "epoch 61; iter: 0; batch classifier loss: 0.059914; batch adversarial loss: 0.474420\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078727; batch adversarial loss: 0.337334\n",
      "epoch 63; iter: 0; batch classifier loss: 0.042210; batch adversarial loss: 0.504051\n",
      "epoch 64; iter: 0; batch classifier loss: 0.052144; batch adversarial loss: 0.471137\n",
      "epoch 65; iter: 0; batch classifier loss: 0.085040; batch adversarial loss: 0.422085\n",
      "epoch 66; iter: 0; batch classifier loss: 0.102883; batch adversarial loss: 0.365218\n",
      "epoch 67; iter: 0; batch classifier loss: 0.077436; batch adversarial loss: 0.455523\n",
      "epoch 68; iter: 0; batch classifier loss: 0.058677; batch adversarial loss: 0.453408\n",
      "epoch 69; iter: 0; batch classifier loss: 0.099743; batch adversarial loss: 0.408775\n",
      "epoch 70; iter: 0; batch classifier loss: 0.073194; batch adversarial loss: 0.482449\n",
      "epoch 71; iter: 0; batch classifier loss: 0.053259; batch adversarial loss: 0.426736\n",
      "epoch 72; iter: 0; batch classifier loss: 0.073961; batch adversarial loss: 0.526290\n",
      "epoch 73; iter: 0; batch classifier loss: 0.087502; batch adversarial loss: 0.446221\n",
      "epoch 74; iter: 0; batch classifier loss: 0.106847; batch adversarial loss: 0.408299\n",
      "epoch 75; iter: 0; batch classifier loss: 0.120280; batch adversarial loss: 0.454576\n",
      "epoch 76; iter: 0; batch classifier loss: 0.089346; batch adversarial loss: 0.432045\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055268; batch adversarial loss: 0.435050\n",
      "epoch 78; iter: 0; batch classifier loss: 0.111934; batch adversarial loss: 0.397351\n",
      "epoch 79; iter: 0; batch classifier loss: 0.119012; batch adversarial loss: 0.459126\n",
      "epoch 80; iter: 0; batch classifier loss: 0.096671; batch adversarial loss: 0.352207\n",
      "epoch 81; iter: 0; batch classifier loss: 0.041150; batch adversarial loss: 0.474497\n",
      "epoch 82; iter: 0; batch classifier loss: 0.056369; batch adversarial loss: 0.563805\n",
      "epoch 83; iter: 0; batch classifier loss: 0.050607; batch adversarial loss: 0.458113\n",
      "epoch 84; iter: 0; batch classifier loss: 0.073784; batch adversarial loss: 0.489105\n",
      "epoch 85; iter: 0; batch classifier loss: 0.058067; batch adversarial loss: 0.416777\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072816; batch adversarial loss: 0.484792\n",
      "epoch 87; iter: 0; batch classifier loss: 0.115421; batch adversarial loss: 0.489285\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055798; batch adversarial loss: 0.368696\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098562; batch adversarial loss: 0.490094\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064631; batch adversarial loss: 0.404758\n",
      "epoch 91; iter: 0; batch classifier loss: 0.037582; batch adversarial loss: 0.375285\n",
      "epoch 92; iter: 0; batch classifier loss: 0.061427; batch adversarial loss: 0.409376\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072539; batch adversarial loss: 0.366540\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046424; batch adversarial loss: 0.405392\n",
      "epoch 95; iter: 0; batch classifier loss: 0.069630; batch adversarial loss: 0.423474\n",
      "epoch 96; iter: 0; batch classifier loss: 0.086522; batch adversarial loss: 0.455980\n",
      "epoch 97; iter: 0; batch classifier loss: 0.029656; batch adversarial loss: 0.501860\n",
      "epoch 98; iter: 0; batch classifier loss: 0.088173; batch adversarial loss: 0.518209\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058444; batch adversarial loss: 0.446522\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056342; batch adversarial loss: 0.412413\n",
      "epoch 101; iter: 0; batch classifier loss: 0.098495; batch adversarial loss: 0.400159\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079466; batch adversarial loss: 0.377678\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037405; batch adversarial loss: 0.463074\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066142; batch adversarial loss: 0.386775\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055139; batch adversarial loss: 0.480699\n",
      "epoch 106; iter: 0; batch classifier loss: 0.101707; batch adversarial loss: 0.317950\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044721; batch adversarial loss: 0.463049\n",
      "epoch 108; iter: 0; batch classifier loss: 0.070578; batch adversarial loss: 0.451501\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059580; batch adversarial loss: 0.403813\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041417; batch adversarial loss: 0.475879\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050584; batch adversarial loss: 0.402966\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037968; batch adversarial loss: 0.392421\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029740; batch adversarial loss: 0.479389\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051905; batch adversarial loss: 0.418861\n",
      "epoch 115; iter: 0; batch classifier loss: 0.078812; batch adversarial loss: 0.380124\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042376; batch adversarial loss: 0.458126\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045430; batch adversarial loss: 0.452449\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054546; batch adversarial loss: 0.391522\n",
      "epoch 119; iter: 0; batch classifier loss: 0.019237; batch adversarial loss: 0.490339\n",
      "epoch 120; iter: 0; batch classifier loss: 0.083907; batch adversarial loss: 0.503771\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049905; batch adversarial loss: 0.426913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.061718; batch adversarial loss: 0.445305\n",
      "epoch 123; iter: 0; batch classifier loss: 0.052066; batch adversarial loss: 0.428545\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050486; batch adversarial loss: 0.558090\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045658; batch adversarial loss: 0.447657\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043796; batch adversarial loss: 0.371072\n",
      "epoch 127; iter: 0; batch classifier loss: 0.075299; batch adversarial loss: 0.435868\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038876; batch adversarial loss: 0.454282\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017067; batch adversarial loss: 0.388241\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039217; batch adversarial loss: 0.522533\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039243; batch adversarial loss: 0.478845\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025225; batch adversarial loss: 0.408438\n",
      "epoch 133; iter: 0; batch classifier loss: 0.083344; batch adversarial loss: 0.344443\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030340; batch adversarial loss: 0.405918\n",
      "epoch 135; iter: 0; batch classifier loss: 0.067324; batch adversarial loss: 0.465116\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043622; batch adversarial loss: 0.496070\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027942; batch adversarial loss: 0.431034\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037836; batch adversarial loss: 0.402504\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028097; batch adversarial loss: 0.424476\n",
      "epoch 140; iter: 0; batch classifier loss: 0.016333; batch adversarial loss: 0.454776\n",
      "epoch 141; iter: 0; batch classifier loss: 0.075344; batch adversarial loss: 0.459821\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025870; batch adversarial loss: 0.485550\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018033; batch adversarial loss: 0.388336\n",
      "epoch 144; iter: 0; batch classifier loss: 0.064962; batch adversarial loss: 0.442842\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032583; batch adversarial loss: 0.349078\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035828; batch adversarial loss: 0.410333\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038689; batch adversarial loss: 0.552829\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046944; batch adversarial loss: 0.407986\n",
      "epoch 149; iter: 0; batch classifier loss: 0.062732; batch adversarial loss: 0.477633\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018666; batch adversarial loss: 0.397436\n",
      "epoch 151; iter: 0; batch classifier loss: 0.045404; batch adversarial loss: 0.412965\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035724; batch adversarial loss: 0.451043\n",
      "epoch 153; iter: 0; batch classifier loss: 0.047142; batch adversarial loss: 0.438174\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041488; batch adversarial loss: 0.346814\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031066; batch adversarial loss: 0.378540\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039804; batch adversarial loss: 0.344900\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011072; batch adversarial loss: 0.424558\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019657; batch adversarial loss: 0.496700\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013078; batch adversarial loss: 0.429711\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034538; batch adversarial loss: 0.508597\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031356; batch adversarial loss: 0.380073\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031136; batch adversarial loss: 0.426586\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021557; batch adversarial loss: 0.473100\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029172; batch adversarial loss: 0.600752\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014148; batch adversarial loss: 0.403867\n",
      "epoch 166; iter: 0; batch classifier loss: 0.054578; batch adversarial loss: 0.578726\n",
      "epoch 167; iter: 0; batch classifier loss: 0.063221; batch adversarial loss: 0.451963\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011472; batch adversarial loss: 0.396938\n",
      "epoch 169; iter: 0; batch classifier loss: 0.056188; batch adversarial loss: 0.455795\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015612; batch adversarial loss: 0.440693\n",
      "epoch 171; iter: 0; batch classifier loss: 0.005252; batch adversarial loss: 0.397018\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028931; batch adversarial loss: 0.519739\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033833; batch adversarial loss: 0.541495\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023292; batch adversarial loss: 0.582573\n",
      "epoch 175; iter: 0; batch classifier loss: 0.071485; batch adversarial loss: 0.467178\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026396; batch adversarial loss: 0.354427\n",
      "epoch 177; iter: 0; batch classifier loss: 0.048927; batch adversarial loss: 0.456377\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019005; batch adversarial loss: 0.512536\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024813; batch adversarial loss: 0.430116\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007521; batch adversarial loss: 0.414237\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006274; batch adversarial loss: 0.470022\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018556; batch adversarial loss: 0.509351\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024803; batch adversarial loss: 0.422821\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013501; batch adversarial loss: 0.417916\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025431; batch adversarial loss: 0.346348\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018931; batch adversarial loss: 0.363861\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027185; batch adversarial loss: 0.420151\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034589; batch adversarial loss: 0.387437\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007340; batch adversarial loss: 0.455133\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022539; batch adversarial loss: 0.483887\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026716; batch adversarial loss: 0.464827\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015945; batch adversarial loss: 0.460548\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035480; batch adversarial loss: 0.507585\n",
      "epoch 194; iter: 0; batch classifier loss: 0.047374; batch adversarial loss: 0.467924\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029346; batch adversarial loss: 0.397539\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021800; batch adversarial loss: 0.423084\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020632; batch adversarial loss: 0.530186\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031598; batch adversarial loss: 0.425269\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023620; batch adversarial loss: 0.486580\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698597; batch adversarial loss: 0.481796\n",
      "epoch 1; iter: 0; batch classifier loss: 0.483946; batch adversarial loss: 0.582742\n",
      "epoch 2; iter: 0; batch classifier loss: 0.349055; batch adversarial loss: 0.621728\n",
      "epoch 3; iter: 0; batch classifier loss: 0.432125; batch adversarial loss: 0.590178\n",
      "epoch 4; iter: 0; batch classifier loss: 0.524251; batch adversarial loss: 0.606640\n",
      "epoch 5; iter: 0; batch classifier loss: 0.344208; batch adversarial loss: 0.654425\n",
      "epoch 6; iter: 0; batch classifier loss: 0.429359; batch adversarial loss: 0.534818\n",
      "epoch 7; iter: 0; batch classifier loss: 0.364760; batch adversarial loss: 0.589901\n",
      "epoch 8; iter: 0; batch classifier loss: 0.455952; batch adversarial loss: 0.550202\n",
      "epoch 9; iter: 0; batch classifier loss: 0.386472; batch adversarial loss: 0.587750\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535053; batch adversarial loss: 0.535937\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563159; batch adversarial loss: 0.536481\n",
      "epoch 12; iter: 0; batch classifier loss: 0.426406; batch adversarial loss: 0.511852\n",
      "epoch 13; iter: 0; batch classifier loss: 0.414578; batch adversarial loss: 0.500878\n",
      "epoch 14; iter: 0; batch classifier loss: 0.338370; batch adversarial loss: 0.457752\n",
      "epoch 15; iter: 0; batch classifier loss: 0.313796; batch adversarial loss: 0.508067\n",
      "epoch 16; iter: 0; batch classifier loss: 0.236074; batch adversarial loss: 0.444341\n",
      "epoch 17; iter: 0; batch classifier loss: 0.171997; batch adversarial loss: 0.452648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.198016; batch adversarial loss: 0.450919\n",
      "epoch 19; iter: 0; batch classifier loss: 0.164184; batch adversarial loss: 0.438234\n",
      "epoch 20; iter: 0; batch classifier loss: 0.187978; batch adversarial loss: 0.431935\n",
      "epoch 21; iter: 0; batch classifier loss: 0.195756; batch adversarial loss: 0.469197\n",
      "epoch 22; iter: 0; batch classifier loss: 0.198189; batch adversarial loss: 0.402097\n",
      "epoch 23; iter: 0; batch classifier loss: 0.186824; batch adversarial loss: 0.439297\n",
      "epoch 24; iter: 0; batch classifier loss: 0.183840; batch adversarial loss: 0.489898\n",
      "epoch 25; iter: 0; batch classifier loss: 0.109389; batch adversarial loss: 0.471441\n",
      "epoch 26; iter: 0; batch classifier loss: 0.192419; batch adversarial loss: 0.502802\n",
      "epoch 27; iter: 0; batch classifier loss: 0.165542; batch adversarial loss: 0.494159\n",
      "epoch 28; iter: 0; batch classifier loss: 0.125981; batch adversarial loss: 0.420737\n",
      "epoch 29; iter: 0; batch classifier loss: 0.149844; batch adversarial loss: 0.409119\n",
      "epoch 30; iter: 0; batch classifier loss: 0.135610; batch adversarial loss: 0.418984\n",
      "epoch 31; iter: 0; batch classifier loss: 0.091051; batch adversarial loss: 0.527342\n",
      "epoch 32; iter: 0; batch classifier loss: 0.099158; batch adversarial loss: 0.472780\n",
      "epoch 33; iter: 0; batch classifier loss: 0.101492; batch adversarial loss: 0.493593\n",
      "epoch 34; iter: 0; batch classifier loss: 0.132602; batch adversarial loss: 0.444603\n",
      "epoch 35; iter: 0; batch classifier loss: 0.121686; batch adversarial loss: 0.457431\n",
      "epoch 36; iter: 0; batch classifier loss: 0.132945; batch adversarial loss: 0.490086\n",
      "epoch 37; iter: 0; batch classifier loss: 0.170670; batch adversarial loss: 0.435021\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107395; batch adversarial loss: 0.471429\n",
      "epoch 39; iter: 0; batch classifier loss: 0.114308; batch adversarial loss: 0.396718\n",
      "epoch 40; iter: 0; batch classifier loss: 0.064750; batch adversarial loss: 0.450324\n",
      "epoch 41; iter: 0; batch classifier loss: 0.142389; batch adversarial loss: 0.378512\n",
      "epoch 42; iter: 0; batch classifier loss: 0.102442; batch adversarial loss: 0.443127\n",
      "epoch 43; iter: 0; batch classifier loss: 0.090302; batch adversarial loss: 0.433839\n",
      "epoch 44; iter: 0; batch classifier loss: 0.102767; batch adversarial loss: 0.410797\n",
      "epoch 45; iter: 0; batch classifier loss: 0.095151; batch adversarial loss: 0.441310\n",
      "epoch 46; iter: 0; batch classifier loss: 0.087793; batch adversarial loss: 0.396136\n",
      "epoch 47; iter: 0; batch classifier loss: 0.092229; batch adversarial loss: 0.477763\n",
      "epoch 48; iter: 0; batch classifier loss: 0.058147; batch adversarial loss: 0.400841\n",
      "epoch 49; iter: 0; batch classifier loss: 0.108136; batch adversarial loss: 0.546724\n",
      "epoch 50; iter: 0; batch classifier loss: 0.124868; batch adversarial loss: 0.529667\n",
      "epoch 51; iter: 0; batch classifier loss: 0.117588; batch adversarial loss: 0.499610\n",
      "epoch 52; iter: 0; batch classifier loss: 0.121940; batch adversarial loss: 0.395603\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084818; batch adversarial loss: 0.470809\n",
      "epoch 54; iter: 0; batch classifier loss: 0.117776; batch adversarial loss: 0.380658\n",
      "epoch 55; iter: 0; batch classifier loss: 0.054799; batch adversarial loss: 0.517361\n",
      "epoch 56; iter: 0; batch classifier loss: 0.068220; batch adversarial loss: 0.506997\n",
      "epoch 57; iter: 0; batch classifier loss: 0.042323; batch adversarial loss: 0.460128\n",
      "epoch 58; iter: 0; batch classifier loss: 0.064046; batch adversarial loss: 0.510305\n",
      "epoch 59; iter: 0; batch classifier loss: 0.125567; batch adversarial loss: 0.434111\n",
      "epoch 60; iter: 0; batch classifier loss: 0.068729; batch adversarial loss: 0.513194\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078450; batch adversarial loss: 0.389002\n",
      "epoch 62; iter: 0; batch classifier loss: 0.079414; batch adversarial loss: 0.496105\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095943; batch adversarial loss: 0.596202\n",
      "epoch 64; iter: 0; batch classifier loss: 0.052440; batch adversarial loss: 0.415945\n",
      "epoch 65; iter: 0; batch classifier loss: 0.069532; batch adversarial loss: 0.425177\n",
      "epoch 66; iter: 0; batch classifier loss: 0.109752; batch adversarial loss: 0.412284\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069318; batch adversarial loss: 0.471796\n",
      "epoch 68; iter: 0; batch classifier loss: 0.057688; batch adversarial loss: 0.448846\n",
      "epoch 69; iter: 0; batch classifier loss: 0.063037; batch adversarial loss: 0.487667\n",
      "epoch 70; iter: 0; batch classifier loss: 0.063225; batch adversarial loss: 0.401674\n",
      "epoch 71; iter: 0; batch classifier loss: 0.018410; batch adversarial loss: 0.483970\n",
      "epoch 72; iter: 0; batch classifier loss: 0.090541; batch adversarial loss: 0.531320\n",
      "epoch 73; iter: 0; batch classifier loss: 0.107178; batch adversarial loss: 0.479154\n",
      "epoch 74; iter: 0; batch classifier loss: 0.077409; batch adversarial loss: 0.449820\n",
      "epoch 75; iter: 0; batch classifier loss: 0.045727; batch adversarial loss: 0.470181\n",
      "epoch 76; iter: 0; batch classifier loss: 0.068240; batch adversarial loss: 0.436347\n",
      "epoch 77; iter: 0; batch classifier loss: 0.052084; batch adversarial loss: 0.508201\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054240; batch adversarial loss: 0.483221\n",
      "epoch 79; iter: 0; batch classifier loss: 0.045771; batch adversarial loss: 0.422340\n",
      "epoch 80; iter: 0; batch classifier loss: 0.057136; batch adversarial loss: 0.483113\n",
      "epoch 81; iter: 0; batch classifier loss: 0.040496; batch adversarial loss: 0.530984\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060622; batch adversarial loss: 0.430665\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071126; batch adversarial loss: 0.375333\n",
      "epoch 84; iter: 0; batch classifier loss: 0.113752; batch adversarial loss: 0.494868\n",
      "epoch 85; iter: 0; batch classifier loss: 0.038814; batch adversarial loss: 0.405791\n",
      "epoch 86; iter: 0; batch classifier loss: 0.034552; batch adversarial loss: 0.594207\n",
      "epoch 87; iter: 0; batch classifier loss: 0.023721; batch adversarial loss: 0.476272\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078358; batch adversarial loss: 0.366051\n",
      "epoch 89; iter: 0; batch classifier loss: 0.094747; batch adversarial loss: 0.511210\n",
      "epoch 90; iter: 0; batch classifier loss: 0.038483; batch adversarial loss: 0.504112\n",
      "epoch 91; iter: 0; batch classifier loss: 0.070499; batch adversarial loss: 0.458214\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062722; batch adversarial loss: 0.463513\n",
      "epoch 93; iter: 0; batch classifier loss: 0.076979; batch adversarial loss: 0.433451\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066141; batch adversarial loss: 0.417250\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050301; batch adversarial loss: 0.410395\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051632; batch adversarial loss: 0.401541\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077854; batch adversarial loss: 0.520942\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046526; batch adversarial loss: 0.387687\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078773; batch adversarial loss: 0.462291\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061338; batch adversarial loss: 0.428916\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068471; batch adversarial loss: 0.413163\n",
      "epoch 102; iter: 0; batch classifier loss: 0.014773; batch adversarial loss: 0.473928\n",
      "epoch 103; iter: 0; batch classifier loss: 0.030328; batch adversarial loss: 0.431748\n",
      "epoch 104; iter: 0; batch classifier loss: 0.030929; batch adversarial loss: 0.494542\n",
      "epoch 105; iter: 0; batch classifier loss: 0.097118; batch adversarial loss: 0.406235\n",
      "epoch 106; iter: 0; batch classifier loss: 0.069848; batch adversarial loss: 0.412407\n",
      "epoch 107; iter: 0; batch classifier loss: 0.030325; batch adversarial loss: 0.387926\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038974; batch adversarial loss: 0.528207\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046747; batch adversarial loss: 0.434164\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038225; batch adversarial loss: 0.510404\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055897; batch adversarial loss: 0.444989\n",
      "epoch 112; iter: 0; batch classifier loss: 0.029920; batch adversarial loss: 0.489241\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027279; batch adversarial loss: 0.429089\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032688; batch adversarial loss: 0.474274\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051038; batch adversarial loss: 0.520660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.016536; batch adversarial loss: 0.467783\n",
      "epoch 117; iter: 0; batch classifier loss: 0.054103; batch adversarial loss: 0.518255\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040535; batch adversarial loss: 0.425637\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050243; batch adversarial loss: 0.403915\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032373; batch adversarial loss: 0.420162\n",
      "epoch 121; iter: 0; batch classifier loss: 0.087398; batch adversarial loss: 0.474693\n",
      "epoch 122; iter: 0; batch classifier loss: 0.047645; batch adversarial loss: 0.448287\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045084; batch adversarial loss: 0.421029\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022890; batch adversarial loss: 0.399053\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039511; batch adversarial loss: 0.534543\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030529; batch adversarial loss: 0.535503\n",
      "epoch 127; iter: 0; batch classifier loss: 0.055518; batch adversarial loss: 0.508593\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053108; batch adversarial loss: 0.456322\n",
      "epoch 129; iter: 0; batch classifier loss: 0.127484; batch adversarial loss: 0.403557\n",
      "epoch 130; iter: 0; batch classifier loss: 0.015343; batch adversarial loss: 0.403419\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033885; batch adversarial loss: 0.480747\n",
      "epoch 132; iter: 0; batch classifier loss: 0.017454; batch adversarial loss: 0.475939\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027966; batch adversarial loss: 0.431547\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052418; batch adversarial loss: 0.378595\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043492; batch adversarial loss: 0.407478\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037911; batch adversarial loss: 0.460963\n",
      "epoch 137; iter: 0; batch classifier loss: 0.047931; batch adversarial loss: 0.416674\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041617; batch adversarial loss: 0.503727\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037998; batch adversarial loss: 0.413380\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029196; batch adversarial loss: 0.436970\n",
      "epoch 141; iter: 0; batch classifier loss: 0.011146; batch adversarial loss: 0.476902\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036130; batch adversarial loss: 0.441866\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030110; batch adversarial loss: 0.392691\n",
      "epoch 144; iter: 0; batch classifier loss: 0.061853; batch adversarial loss: 0.476689\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027143; batch adversarial loss: 0.539698\n",
      "epoch 146; iter: 0; batch classifier loss: 0.071696; batch adversarial loss: 0.311057\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020448; batch adversarial loss: 0.569892\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023107; batch adversarial loss: 0.464953\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033208; batch adversarial loss: 0.466288\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026277; batch adversarial loss: 0.510888\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021759; batch adversarial loss: 0.534880\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019189; batch adversarial loss: 0.440244\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025598; batch adversarial loss: 0.480127\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025509; batch adversarial loss: 0.408002\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020917; batch adversarial loss: 0.444625\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032421; batch adversarial loss: 0.413679\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033685; batch adversarial loss: 0.408407\n",
      "epoch 158; iter: 0; batch classifier loss: 0.055341; batch adversarial loss: 0.479114\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023948; batch adversarial loss: 0.496276\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014845; batch adversarial loss: 0.406708\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024668; batch adversarial loss: 0.501718\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018955; batch adversarial loss: 0.387247\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023565; batch adversarial loss: 0.421868\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020038; batch adversarial loss: 0.338621\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015162; batch adversarial loss: 0.425851\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016504; batch adversarial loss: 0.476333\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010836; batch adversarial loss: 0.421390\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038032; batch adversarial loss: 0.383193\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025757; batch adversarial loss: 0.441773\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023204; batch adversarial loss: 0.398576\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028791; batch adversarial loss: 0.428138\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023625; batch adversarial loss: 0.352524\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035545; batch adversarial loss: 0.366206\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019806; batch adversarial loss: 0.489814\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041860; batch adversarial loss: 0.425852\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023404; batch adversarial loss: 0.489915\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023193; batch adversarial loss: 0.469526\n",
      "epoch 178; iter: 0; batch classifier loss: 0.054109; batch adversarial loss: 0.453974\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013074; batch adversarial loss: 0.477104\n",
      "epoch 180; iter: 0; batch classifier loss: 0.046096; batch adversarial loss: 0.384070\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013960; batch adversarial loss: 0.421008\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011703; batch adversarial loss: 0.473877\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026800; batch adversarial loss: 0.394357\n",
      "epoch 184; iter: 0; batch classifier loss: 0.086603; batch adversarial loss: 0.540378\n",
      "epoch 185; iter: 0; batch classifier loss: 0.065961; batch adversarial loss: 0.486430\n",
      "epoch 186; iter: 0; batch classifier loss: 0.036638; batch adversarial loss: 0.456280\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025541; batch adversarial loss: 0.507342\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019543; batch adversarial loss: 0.447596\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015461; batch adversarial loss: 0.432835\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034081; batch adversarial loss: 0.503481\n",
      "epoch 191; iter: 0; batch classifier loss: 0.060926; batch adversarial loss: 0.445162\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009967; batch adversarial loss: 0.444144\n",
      "epoch 193; iter: 0; batch classifier loss: 0.043811; batch adversarial loss: 0.465797\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007328; batch adversarial loss: 0.519823\n",
      "epoch 195; iter: 0; batch classifier loss: 0.043670; batch adversarial loss: 0.385244\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017233; batch adversarial loss: 0.527676\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029980; batch adversarial loss: 0.441361\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005584; batch adversarial loss: 0.439518\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004037; batch adversarial loss: 0.428647\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705041; batch adversarial loss: 0.758569\n",
      "epoch 1; iter: 0; batch classifier loss: 0.504388; batch adversarial loss: 0.713844\n",
      "epoch 2; iter: 0; batch classifier loss: 0.473494; batch adversarial loss: 0.662691\n",
      "epoch 3; iter: 0; batch classifier loss: 0.415129; batch adversarial loss: 0.628840\n",
      "epoch 4; iter: 0; batch classifier loss: 0.355110; batch adversarial loss: 0.598378\n",
      "epoch 5; iter: 0; batch classifier loss: 0.291635; batch adversarial loss: 0.595626\n",
      "epoch 6; iter: 0; batch classifier loss: 0.430717; batch adversarial loss: 0.570812\n",
      "epoch 7; iter: 0; batch classifier loss: 0.375749; batch adversarial loss: 0.557005\n",
      "epoch 8; iter: 0; batch classifier loss: 0.410192; batch adversarial loss: 0.561131\n",
      "epoch 9; iter: 0; batch classifier loss: 0.353523; batch adversarial loss: 0.557923\n",
      "epoch 10; iter: 0; batch classifier loss: 0.395070; batch adversarial loss: 0.554844\n",
      "epoch 11; iter: 0; batch classifier loss: 0.399440; batch adversarial loss: 0.503324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.462579; batch adversarial loss: 0.517330\n",
      "epoch 13; iter: 0; batch classifier loss: 0.407547; batch adversarial loss: 0.580284\n",
      "epoch 14; iter: 0; batch classifier loss: 0.313676; batch adversarial loss: 0.498228\n",
      "epoch 15; iter: 0; batch classifier loss: 0.394234; batch adversarial loss: 0.510204\n",
      "epoch 16; iter: 0; batch classifier loss: 0.385423; batch adversarial loss: 0.478898\n",
      "epoch 17; iter: 0; batch classifier loss: 0.372136; batch adversarial loss: 0.491014\n",
      "epoch 18; iter: 0; batch classifier loss: 0.334695; batch adversarial loss: 0.490178\n",
      "epoch 19; iter: 0; batch classifier loss: 0.341982; batch adversarial loss: 0.509923\n",
      "epoch 20; iter: 0; batch classifier loss: 0.269822; batch adversarial loss: 0.460045\n",
      "epoch 21; iter: 0; batch classifier loss: 0.329438; batch adversarial loss: 0.461468\n",
      "epoch 22; iter: 0; batch classifier loss: 0.356774; batch adversarial loss: 0.472596\n",
      "epoch 23; iter: 0; batch classifier loss: 0.268760; batch adversarial loss: 0.448417\n",
      "epoch 24; iter: 0; batch classifier loss: 0.351130; batch adversarial loss: 0.478489\n",
      "epoch 25; iter: 0; batch classifier loss: 0.320113; batch adversarial loss: 0.410080\n",
      "epoch 26; iter: 0; batch classifier loss: 0.334218; batch adversarial loss: 0.457903\n",
      "epoch 27; iter: 0; batch classifier loss: 0.251656; batch adversarial loss: 0.445597\n",
      "epoch 28; iter: 0; batch classifier loss: 0.277075; batch adversarial loss: 0.505166\n",
      "epoch 29; iter: 0; batch classifier loss: 0.269396; batch adversarial loss: 0.489096\n",
      "epoch 30; iter: 0; batch classifier loss: 0.285852; batch adversarial loss: 0.529649\n",
      "epoch 31; iter: 0; batch classifier loss: 0.150265; batch adversarial loss: 0.489303\n",
      "epoch 32; iter: 0; batch classifier loss: 0.222846; batch adversarial loss: 0.486391\n",
      "epoch 33; iter: 0; batch classifier loss: 0.243681; batch adversarial loss: 0.461800\n",
      "epoch 34; iter: 0; batch classifier loss: 0.177285; batch adversarial loss: 0.458148\n",
      "epoch 35; iter: 0; batch classifier loss: 0.195118; batch adversarial loss: 0.458469\n",
      "epoch 36; iter: 0; batch classifier loss: 0.247488; batch adversarial loss: 0.413253\n",
      "epoch 37; iter: 0; batch classifier loss: 0.323880; batch adversarial loss: 0.472082\n",
      "epoch 38; iter: 0; batch classifier loss: 0.131250; batch adversarial loss: 0.397615\n",
      "epoch 39; iter: 0; batch classifier loss: 0.237960; batch adversarial loss: 0.458284\n",
      "epoch 40; iter: 0; batch classifier loss: 0.193108; batch adversarial loss: 0.494866\n",
      "epoch 41; iter: 0; batch classifier loss: 0.219732; batch adversarial loss: 0.456789\n",
      "epoch 42; iter: 0; batch classifier loss: 0.159984; batch adversarial loss: 0.578035\n",
      "epoch 43; iter: 0; batch classifier loss: 0.186327; batch adversarial loss: 0.375923\n",
      "epoch 44; iter: 0; batch classifier loss: 0.165867; batch adversarial loss: 0.456080\n",
      "epoch 45; iter: 0; batch classifier loss: 0.222256; batch adversarial loss: 0.447186\n",
      "epoch 46; iter: 0; batch classifier loss: 0.189042; batch adversarial loss: 0.472191\n",
      "epoch 47; iter: 0; batch classifier loss: 0.249055; batch adversarial loss: 0.464872\n",
      "epoch 48; iter: 0; batch classifier loss: 0.189191; batch adversarial loss: 0.328496\n",
      "epoch 49; iter: 0; batch classifier loss: 0.207413; batch adversarial loss: 0.376870\n",
      "epoch 50; iter: 0; batch classifier loss: 0.188978; batch adversarial loss: 0.451818\n",
      "epoch 51; iter: 0; batch classifier loss: 0.225388; batch adversarial loss: 0.479175\n",
      "epoch 52; iter: 0; batch classifier loss: 0.199533; batch adversarial loss: 0.452067\n",
      "epoch 53; iter: 0; batch classifier loss: 0.183055; batch adversarial loss: 0.481453\n",
      "epoch 54; iter: 0; batch classifier loss: 0.165691; batch adversarial loss: 0.485523\n",
      "epoch 55; iter: 0; batch classifier loss: 0.192803; batch adversarial loss: 0.473767\n",
      "epoch 56; iter: 0; batch classifier loss: 0.157706; batch adversarial loss: 0.384958\n",
      "epoch 57; iter: 0; batch classifier loss: 0.211765; batch adversarial loss: 0.424901\n",
      "epoch 58; iter: 0; batch classifier loss: 0.159325; batch adversarial loss: 0.398469\n",
      "epoch 59; iter: 0; batch classifier loss: 0.196421; batch adversarial loss: 0.396682\n",
      "epoch 60; iter: 0; batch classifier loss: 0.178603; batch adversarial loss: 0.421093\n",
      "epoch 61; iter: 0; batch classifier loss: 0.225121; batch adversarial loss: 0.422411\n",
      "epoch 62; iter: 0; batch classifier loss: 0.261161; batch adversarial loss: 0.433894\n",
      "epoch 63; iter: 0; batch classifier loss: 0.144195; batch adversarial loss: 0.458656\n",
      "epoch 64; iter: 0; batch classifier loss: 0.164597; batch adversarial loss: 0.408998\n",
      "epoch 65; iter: 0; batch classifier loss: 0.180621; batch adversarial loss: 0.446368\n",
      "epoch 66; iter: 0; batch classifier loss: 0.167925; batch adversarial loss: 0.408376\n",
      "epoch 67; iter: 0; batch classifier loss: 0.225675; batch adversarial loss: 0.408926\n",
      "epoch 68; iter: 0; batch classifier loss: 0.182405; batch adversarial loss: 0.384241\n",
      "epoch 69; iter: 0; batch classifier loss: 0.125983; batch adversarial loss: 0.434362\n",
      "epoch 70; iter: 0; batch classifier loss: 0.123391; batch adversarial loss: 0.433985\n",
      "epoch 71; iter: 0; batch classifier loss: 0.227652; batch adversarial loss: 0.433273\n",
      "epoch 72; iter: 0; batch classifier loss: 0.212165; batch adversarial loss: 0.433538\n",
      "epoch 73; iter: 0; batch classifier loss: 0.107348; batch adversarial loss: 0.445745\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089533; batch adversarial loss: 0.432574\n",
      "epoch 75; iter: 0; batch classifier loss: 0.141161; batch adversarial loss: 0.432350\n",
      "epoch 76; iter: 0; batch classifier loss: 0.123307; batch adversarial loss: 0.583003\n",
      "epoch 77; iter: 0; batch classifier loss: 0.146737; batch adversarial loss: 0.457946\n",
      "epoch 78; iter: 0; batch classifier loss: 0.153194; batch adversarial loss: 0.408816\n",
      "epoch 79; iter: 0; batch classifier loss: 0.166815; batch adversarial loss: 0.420042\n",
      "epoch 80; iter: 0; batch classifier loss: 0.166524; batch adversarial loss: 0.454144\n",
      "epoch 81; iter: 0; batch classifier loss: 0.087841; batch adversarial loss: 0.468105\n",
      "epoch 82; iter: 0; batch classifier loss: 0.085258; batch adversarial loss: 0.468263\n",
      "epoch 83; iter: 0; batch classifier loss: 0.127764; batch adversarial loss: 0.477917\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056465; batch adversarial loss: 0.456026\n",
      "epoch 85; iter: 0; batch classifier loss: 0.089521; batch adversarial loss: 0.518544\n",
      "epoch 86; iter: 0; batch classifier loss: 0.048941; batch adversarial loss: 0.376583\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067041; batch adversarial loss: 0.370023\n",
      "epoch 88; iter: 0; batch classifier loss: 0.085617; batch adversarial loss: 0.432790\n",
      "epoch 89; iter: 0; batch classifier loss: 0.092114; batch adversarial loss: 0.472406\n",
      "epoch 90; iter: 0; batch classifier loss: 0.093374; batch adversarial loss: 0.444531\n",
      "epoch 91; iter: 0; batch classifier loss: 0.050942; batch adversarial loss: 0.395170\n",
      "epoch 92; iter: 0; batch classifier loss: 0.054184; batch adversarial loss: 0.475034\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050816; batch adversarial loss: 0.393765\n",
      "epoch 94; iter: 0; batch classifier loss: 0.037185; batch adversarial loss: 0.561953\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063380; batch adversarial loss: 0.508752\n",
      "epoch 96; iter: 0; batch classifier loss: 0.085771; batch adversarial loss: 0.466880\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037207; batch adversarial loss: 0.481482\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054341; batch adversarial loss: 0.427595\n",
      "epoch 99; iter: 0; batch classifier loss: 0.048780; batch adversarial loss: 0.485187\n",
      "epoch 100; iter: 0; batch classifier loss: 0.100839; batch adversarial loss: 0.450799\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040128; batch adversarial loss: 0.484036\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032972; batch adversarial loss: 0.490170\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045627; batch adversarial loss: 0.383401\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065380; batch adversarial loss: 0.385068\n",
      "epoch 105; iter: 0; batch classifier loss: 0.020102; batch adversarial loss: 0.389490\n",
      "epoch 106; iter: 0; batch classifier loss: 0.027463; batch adversarial loss: 0.375430\n",
      "epoch 107; iter: 0; batch classifier loss: 0.054494; batch adversarial loss: 0.409872\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036267; batch adversarial loss: 0.465573\n",
      "epoch 109; iter: 0; batch classifier loss: 0.031355; batch adversarial loss: 0.499171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.029565; batch adversarial loss: 0.506956\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028324; batch adversarial loss: 0.504101\n",
      "epoch 112; iter: 0; batch classifier loss: 0.018864; batch adversarial loss: 0.404796\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033888; batch adversarial loss: 0.293951\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029060; batch adversarial loss: 0.418217\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029332; batch adversarial loss: 0.390696\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029147; batch adversarial loss: 0.465456\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032916; batch adversarial loss: 0.352628\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029818; batch adversarial loss: 0.505435\n",
      "epoch 119; iter: 0; batch classifier loss: 0.071049; batch adversarial loss: 0.385130\n",
      "epoch 120; iter: 0; batch classifier loss: 0.019661; batch adversarial loss: 0.382193\n",
      "epoch 121; iter: 0; batch classifier loss: 0.020693; batch adversarial loss: 0.503549\n",
      "epoch 122; iter: 0; batch classifier loss: 0.074807; batch adversarial loss: 0.332075\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036343; batch adversarial loss: 0.421954\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030388; batch adversarial loss: 0.500292\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022106; batch adversarial loss: 0.510692\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030002; batch adversarial loss: 0.486928\n",
      "epoch 127; iter: 0; batch classifier loss: 0.008686; batch adversarial loss: 0.498632\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028896; batch adversarial loss: 0.447142\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027528; batch adversarial loss: 0.414484\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018567; batch adversarial loss: 0.473722\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029498; batch adversarial loss: 0.417076\n",
      "epoch 132; iter: 0; batch classifier loss: 0.013721; batch adversarial loss: 0.388395\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037056; batch adversarial loss: 0.457403\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043414; batch adversarial loss: 0.417654\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034163; batch adversarial loss: 0.464885\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028149; batch adversarial loss: 0.467688\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033005; batch adversarial loss: 0.461995\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045231; batch adversarial loss: 0.444929\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031167; batch adversarial loss: 0.487404\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048739; batch adversarial loss: 0.386947\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016057; batch adversarial loss: 0.409746\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017258; batch adversarial loss: 0.392706\n",
      "epoch 143; iter: 0; batch classifier loss: 0.065274; batch adversarial loss: 0.509664\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019163; batch adversarial loss: 0.364050\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014907; batch adversarial loss: 0.414662\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031402; batch adversarial loss: 0.384023\n",
      "epoch 147; iter: 0; batch classifier loss: 0.007902; batch adversarial loss: 0.476957\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015110; batch adversarial loss: 0.448462\n",
      "epoch 149; iter: 0; batch classifier loss: 0.046980; batch adversarial loss: 0.396622\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020355; batch adversarial loss: 0.383297\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019220; batch adversarial loss: 0.375805\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029392; batch adversarial loss: 0.421097\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019098; batch adversarial loss: 0.326140\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011914; batch adversarial loss: 0.511279\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022319; batch adversarial loss: 0.474810\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034501; batch adversarial loss: 0.355905\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021738; batch adversarial loss: 0.448081\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026557; batch adversarial loss: 0.366033\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023439; batch adversarial loss: 0.401591\n",
      "epoch 160; iter: 0; batch classifier loss: 0.006754; batch adversarial loss: 0.360235\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012583; batch adversarial loss: 0.476111\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034283; batch adversarial loss: 0.458988\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022559; batch adversarial loss: 0.492182\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021969; batch adversarial loss: 0.473170\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022716; batch adversarial loss: 0.376886\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019249; batch adversarial loss: 0.458780\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012142; batch adversarial loss: 0.377856\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024850; batch adversarial loss: 0.438162\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020513; batch adversarial loss: 0.436261\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011689; batch adversarial loss: 0.482446\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008012; batch adversarial loss: 0.469854\n",
      "epoch 172; iter: 0; batch classifier loss: 0.051527; batch adversarial loss: 0.457943\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031306; batch adversarial loss: 0.523235\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038856; batch adversarial loss: 0.371230\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031482; batch adversarial loss: 0.432801\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028817; batch adversarial loss: 0.526808\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037509; batch adversarial loss: 0.411502\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007604; batch adversarial loss: 0.428345\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031100; batch adversarial loss: 0.454197\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017062; batch adversarial loss: 0.411376\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018097; batch adversarial loss: 0.450262\n",
      "epoch 182; iter: 0; batch classifier loss: 0.004430; batch adversarial loss: 0.412423\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009916; batch adversarial loss: 0.483433\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017610; batch adversarial loss: 0.544465\n",
      "epoch 185; iter: 0; batch classifier loss: 0.005619; batch adversarial loss: 0.514703\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031756; batch adversarial loss: 0.434877\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018100; batch adversarial loss: 0.304233\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014742; batch adversarial loss: 0.483015\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017446; batch adversarial loss: 0.453941\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012485; batch adversarial loss: 0.385480\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014030; batch adversarial loss: 0.525273\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028740; batch adversarial loss: 0.367478\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011858; batch adversarial loss: 0.425484\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006203; batch adversarial loss: 0.366380\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029111; batch adversarial loss: 0.357016\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008809; batch adversarial loss: 0.419203\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013508; batch adversarial loss: 0.478423\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009677; batch adversarial loss: 0.397954\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007399; batch adversarial loss: 0.435999\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686289; batch adversarial loss: 0.830638\n",
      "epoch 1; iter: 0; batch classifier loss: 0.425133; batch adversarial loss: 0.793798\n",
      "epoch 2; iter: 0; batch classifier loss: 0.431541; batch adversarial loss: 0.744344\n",
      "epoch 3; iter: 0; batch classifier loss: 0.447914; batch adversarial loss: 0.706505\n",
      "epoch 4; iter: 0; batch classifier loss: 0.387172; batch adversarial loss: 0.650721\n",
      "epoch 5; iter: 0; batch classifier loss: 0.327095; batch adversarial loss: 0.596821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.395285; batch adversarial loss: 0.586460\n",
      "epoch 7; iter: 0; batch classifier loss: 0.251991; batch adversarial loss: 0.549822\n",
      "epoch 8; iter: 0; batch classifier loss: 0.205929; batch adversarial loss: 0.545890\n",
      "epoch 9; iter: 0; batch classifier loss: 0.283468; batch adversarial loss: 0.541482\n",
      "epoch 10; iter: 0; batch classifier loss: 0.289888; batch adversarial loss: 0.547542\n",
      "epoch 11; iter: 0; batch classifier loss: 0.231783; batch adversarial loss: 0.480329\n",
      "epoch 12; iter: 0; batch classifier loss: 0.280426; batch adversarial loss: 0.488637\n",
      "epoch 13; iter: 0; batch classifier loss: 0.157767; batch adversarial loss: 0.476618\n",
      "epoch 14; iter: 0; batch classifier loss: 0.180008; batch adversarial loss: 0.479248\n",
      "epoch 15; iter: 0; batch classifier loss: 0.208196; batch adversarial loss: 0.430307\n",
      "epoch 16; iter: 0; batch classifier loss: 0.212294; batch adversarial loss: 0.502007\n",
      "epoch 17; iter: 0; batch classifier loss: 0.164155; batch adversarial loss: 0.459819\n",
      "epoch 18; iter: 0; batch classifier loss: 0.150364; batch adversarial loss: 0.494831\n",
      "epoch 19; iter: 0; batch classifier loss: 0.181879; batch adversarial loss: 0.487967\n",
      "epoch 20; iter: 0; batch classifier loss: 0.124016; batch adversarial loss: 0.389719\n",
      "epoch 21; iter: 0; batch classifier loss: 0.135339; batch adversarial loss: 0.395450\n",
      "epoch 22; iter: 0; batch classifier loss: 0.162745; batch adversarial loss: 0.500437\n",
      "epoch 23; iter: 0; batch classifier loss: 0.159762; batch adversarial loss: 0.450232\n",
      "epoch 24; iter: 0; batch classifier loss: 0.201530; batch adversarial loss: 0.454652\n",
      "epoch 25; iter: 0; batch classifier loss: 0.144918; batch adversarial loss: 0.423825\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193124; batch adversarial loss: 0.451610\n",
      "epoch 27; iter: 0; batch classifier loss: 0.179205; batch adversarial loss: 0.494165\n",
      "epoch 28; iter: 0; batch classifier loss: 0.228058; batch adversarial loss: 0.514977\n",
      "epoch 29; iter: 0; batch classifier loss: 0.200396; batch adversarial loss: 0.473427\n",
      "epoch 30; iter: 0; batch classifier loss: 0.234464; batch adversarial loss: 0.444087\n",
      "epoch 31; iter: 0; batch classifier loss: 0.096484; batch adversarial loss: 0.465316\n",
      "epoch 32; iter: 0; batch classifier loss: 0.141050; batch adversarial loss: 0.417376\n",
      "epoch 33; iter: 0; batch classifier loss: 0.111278; batch adversarial loss: 0.498189\n",
      "epoch 34; iter: 0; batch classifier loss: 0.144857; batch adversarial loss: 0.436911\n",
      "epoch 35; iter: 0; batch classifier loss: 0.113160; batch adversarial loss: 0.477821\n",
      "epoch 36; iter: 0; batch classifier loss: 0.107319; batch adversarial loss: 0.451598\n",
      "epoch 37; iter: 0; batch classifier loss: 0.103989; batch adversarial loss: 0.396351\n",
      "epoch 38; iter: 0; batch classifier loss: 0.142058; batch adversarial loss: 0.406474\n",
      "epoch 39; iter: 0; batch classifier loss: 0.112536; batch adversarial loss: 0.346637\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095855; batch adversarial loss: 0.488526\n",
      "epoch 41; iter: 0; batch classifier loss: 0.149118; batch adversarial loss: 0.467126\n",
      "epoch 42; iter: 0; batch classifier loss: 0.064598; batch adversarial loss: 0.477834\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104559; batch adversarial loss: 0.430451\n",
      "epoch 44; iter: 0; batch classifier loss: 0.103273; batch adversarial loss: 0.456401\n",
      "epoch 45; iter: 0; batch classifier loss: 0.064612; batch adversarial loss: 0.439668\n",
      "epoch 46; iter: 0; batch classifier loss: 0.087447; batch adversarial loss: 0.525172\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112610; batch adversarial loss: 0.484729\n",
      "epoch 48; iter: 0; batch classifier loss: 0.148177; batch adversarial loss: 0.425463\n",
      "epoch 49; iter: 0; batch classifier loss: 0.059596; batch adversarial loss: 0.423103\n",
      "epoch 50; iter: 0; batch classifier loss: 0.069763; batch adversarial loss: 0.519615\n",
      "epoch 51; iter: 0; batch classifier loss: 0.075122; batch adversarial loss: 0.455932\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112188; batch adversarial loss: 0.430458\n",
      "epoch 53; iter: 0; batch classifier loss: 0.075954; batch adversarial loss: 0.436646\n",
      "epoch 54; iter: 0; batch classifier loss: 0.077468; batch adversarial loss: 0.418045\n",
      "epoch 55; iter: 0; batch classifier loss: 0.065439; batch adversarial loss: 0.446528\n",
      "epoch 56; iter: 0; batch classifier loss: 0.090287; batch adversarial loss: 0.434979\n",
      "epoch 57; iter: 0; batch classifier loss: 0.051655; batch adversarial loss: 0.456328\n",
      "epoch 58; iter: 0; batch classifier loss: 0.087907; batch adversarial loss: 0.344565\n",
      "epoch 59; iter: 0; batch classifier loss: 0.047804; batch adversarial loss: 0.438569\n",
      "epoch 60; iter: 0; batch classifier loss: 0.054647; batch adversarial loss: 0.416406\n",
      "epoch 61; iter: 0; batch classifier loss: 0.116394; batch adversarial loss: 0.484955\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085500; batch adversarial loss: 0.523965\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092198; batch adversarial loss: 0.421178\n",
      "epoch 64; iter: 0; batch classifier loss: 0.067996; batch adversarial loss: 0.410861\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070437; batch adversarial loss: 0.448516\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060899; batch adversarial loss: 0.489662\n",
      "epoch 67; iter: 0; batch classifier loss: 0.087689; batch adversarial loss: 0.370576\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061301; batch adversarial loss: 0.504171\n",
      "epoch 69; iter: 0; batch classifier loss: 0.043766; batch adversarial loss: 0.407086\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079786; batch adversarial loss: 0.426398\n",
      "epoch 71; iter: 0; batch classifier loss: 0.101019; batch adversarial loss: 0.484618\n",
      "epoch 72; iter: 0; batch classifier loss: 0.045918; batch adversarial loss: 0.542516\n",
      "epoch 73; iter: 0; batch classifier loss: 0.088922; batch adversarial loss: 0.490243\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063024; batch adversarial loss: 0.394334\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059836; batch adversarial loss: 0.508932\n",
      "epoch 76; iter: 0; batch classifier loss: 0.052080; batch adversarial loss: 0.436858\n",
      "epoch 77; iter: 0; batch classifier loss: 0.022871; batch adversarial loss: 0.395208\n",
      "epoch 78; iter: 0; batch classifier loss: 0.050789; batch adversarial loss: 0.454603\n",
      "epoch 79; iter: 0; batch classifier loss: 0.092076; batch adversarial loss: 0.381995\n",
      "epoch 80; iter: 0; batch classifier loss: 0.053396; batch adversarial loss: 0.419512\n",
      "epoch 81; iter: 0; batch classifier loss: 0.060264; batch adversarial loss: 0.408748\n",
      "epoch 82; iter: 0; batch classifier loss: 0.064627; batch adversarial loss: 0.521790\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079645; batch adversarial loss: 0.416344\n",
      "epoch 84; iter: 0; batch classifier loss: 0.039946; batch adversarial loss: 0.488620\n",
      "epoch 85; iter: 0; batch classifier loss: 0.056689; batch adversarial loss: 0.414100\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063137; batch adversarial loss: 0.383599\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079584; batch adversarial loss: 0.444111\n",
      "epoch 88; iter: 0; batch classifier loss: 0.033826; batch adversarial loss: 0.479041\n",
      "epoch 89; iter: 0; batch classifier loss: 0.038177; batch adversarial loss: 0.389597\n",
      "epoch 90; iter: 0; batch classifier loss: 0.041615; batch adversarial loss: 0.493654\n",
      "epoch 91; iter: 0; batch classifier loss: 0.030541; batch adversarial loss: 0.498683\n",
      "epoch 92; iter: 0; batch classifier loss: 0.045711; batch adversarial loss: 0.520441\n",
      "epoch 93; iter: 0; batch classifier loss: 0.060849; batch adversarial loss: 0.431509\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058049; batch adversarial loss: 0.491089\n",
      "epoch 95; iter: 0; batch classifier loss: 0.040475; batch adversarial loss: 0.455182\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041147; batch adversarial loss: 0.459405\n",
      "epoch 97; iter: 0; batch classifier loss: 0.035349; batch adversarial loss: 0.410865\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048287; batch adversarial loss: 0.476598\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038564; batch adversarial loss: 0.329587\n",
      "epoch 100; iter: 0; batch classifier loss: 0.052801; batch adversarial loss: 0.495032\n",
      "epoch 101; iter: 0; batch classifier loss: 0.025379; batch adversarial loss: 0.463821\n",
      "epoch 102; iter: 0; batch classifier loss: 0.040540; batch adversarial loss: 0.392935\n",
      "epoch 103; iter: 0; batch classifier loss: 0.027371; batch adversarial loss: 0.336737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.034974; batch adversarial loss: 0.353229\n",
      "epoch 105; iter: 0; batch classifier loss: 0.031089; batch adversarial loss: 0.494513\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035501; batch adversarial loss: 0.341541\n",
      "epoch 107; iter: 0; batch classifier loss: 0.030223; batch adversarial loss: 0.471183\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036191; batch adversarial loss: 0.486935\n",
      "epoch 109; iter: 0; batch classifier loss: 0.031844; batch adversarial loss: 0.397033\n",
      "epoch 110; iter: 0; batch classifier loss: 0.032794; batch adversarial loss: 0.479799\n",
      "epoch 111; iter: 0; batch classifier loss: 0.052035; batch adversarial loss: 0.355089\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036764; batch adversarial loss: 0.478483\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051434; batch adversarial loss: 0.424755\n",
      "epoch 114; iter: 0; batch classifier loss: 0.009241; batch adversarial loss: 0.424383\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039672; batch adversarial loss: 0.405781\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033051; batch adversarial loss: 0.402258\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033455; batch adversarial loss: 0.522600\n",
      "epoch 118; iter: 0; batch classifier loss: 0.020222; batch adversarial loss: 0.517128\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030471; batch adversarial loss: 0.449237\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034947; batch adversarial loss: 0.522750\n",
      "epoch 121; iter: 0; batch classifier loss: 0.017157; batch adversarial loss: 0.404991\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032400; batch adversarial loss: 0.465253\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042462; batch adversarial loss: 0.540820\n",
      "epoch 124; iter: 0; batch classifier loss: 0.053867; batch adversarial loss: 0.505395\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046138; batch adversarial loss: 0.576290\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031451; batch adversarial loss: 0.487382\n",
      "epoch 127; iter: 0; batch classifier loss: 0.020476; batch adversarial loss: 0.378815\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041998; batch adversarial loss: 0.469606\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037601; batch adversarial loss: 0.528215\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026672; batch adversarial loss: 0.512025\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037007; batch adversarial loss: 0.501264\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031256; batch adversarial loss: 0.523184\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028220; batch adversarial loss: 0.337562\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035726; batch adversarial loss: 0.429605\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023383; batch adversarial loss: 0.527038\n",
      "epoch 136; iter: 0; batch classifier loss: 0.007489; batch adversarial loss: 0.519239\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042186; batch adversarial loss: 0.371667\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036062; batch adversarial loss: 0.524666\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046013; batch adversarial loss: 0.451797\n",
      "epoch 140; iter: 0; batch classifier loss: 0.010680; batch adversarial loss: 0.425777\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022726; batch adversarial loss: 0.457758\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019013; batch adversarial loss: 0.542944\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033996; batch adversarial loss: 0.438540\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030807; batch adversarial loss: 0.413348\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032828; batch adversarial loss: 0.393040\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024945; batch adversarial loss: 0.483312\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025990; batch adversarial loss: 0.481872\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035305; batch adversarial loss: 0.384897\n",
      "epoch 149; iter: 0; batch classifier loss: 0.054497; batch adversarial loss: 0.462967\n",
      "epoch 150; iter: 0; batch classifier loss: 0.047499; batch adversarial loss: 0.526732\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035063; batch adversarial loss: 0.489864\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021625; batch adversarial loss: 0.358527\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028303; batch adversarial loss: 0.418502\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020689; batch adversarial loss: 0.420199\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022634; batch adversarial loss: 0.417858\n",
      "epoch 156; iter: 0; batch classifier loss: 0.049587; batch adversarial loss: 0.425483\n",
      "epoch 157; iter: 0; batch classifier loss: 0.050353; batch adversarial loss: 0.390512\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017188; batch adversarial loss: 0.437628\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018439; batch adversarial loss: 0.415346\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035506; batch adversarial loss: 0.467440\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007996; batch adversarial loss: 0.444584\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036278; batch adversarial loss: 0.511584\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024712; batch adversarial loss: 0.541316\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016605; batch adversarial loss: 0.409789\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037569; batch adversarial loss: 0.510001\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022876; batch adversarial loss: 0.520788\n",
      "epoch 167; iter: 0; batch classifier loss: 0.056630; batch adversarial loss: 0.497310\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016101; batch adversarial loss: 0.411549\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037986; batch adversarial loss: 0.504305\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020847; batch adversarial loss: 0.452286\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012798; batch adversarial loss: 0.521757\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009144; batch adversarial loss: 0.523605\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011800; batch adversarial loss: 0.422057\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022643; batch adversarial loss: 0.420372\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025685; batch adversarial loss: 0.427451\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013917; batch adversarial loss: 0.499302\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006401; batch adversarial loss: 0.429802\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012262; batch adversarial loss: 0.511219\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017621; batch adversarial loss: 0.430534\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025324; batch adversarial loss: 0.476745\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024621; batch adversarial loss: 0.475145\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020939; batch adversarial loss: 0.368138\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019715; batch adversarial loss: 0.418745\n",
      "epoch 184; iter: 0; batch classifier loss: 0.039151; batch adversarial loss: 0.457293\n",
      "epoch 185; iter: 0; batch classifier loss: 0.043065; batch adversarial loss: 0.484940\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016623; batch adversarial loss: 0.486184\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029336; batch adversarial loss: 0.359202\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015192; batch adversarial loss: 0.410320\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014335; batch adversarial loss: 0.404492\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013583; batch adversarial loss: 0.445748\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018532; batch adversarial loss: 0.460610\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013458; batch adversarial loss: 0.497387\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009165; batch adversarial loss: 0.373801\n",
      "epoch 194; iter: 0; batch classifier loss: 0.029974; batch adversarial loss: 0.440128\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010234; batch adversarial loss: 0.383564\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010876; batch adversarial loss: 0.465478\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013364; batch adversarial loss: 0.453238\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013127; batch adversarial loss: 0.452687\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008999; batch adversarial loss: 0.538854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.692004; batch adversarial loss: 0.562393\n",
      "epoch 1; iter: 0; batch classifier loss: 0.467936; batch adversarial loss: 0.582666\n",
      "epoch 2; iter: 0; batch classifier loss: 0.371824; batch adversarial loss: 0.621374\n",
      "epoch 3; iter: 0; batch classifier loss: 0.385669; batch adversarial loss: 0.644063\n",
      "epoch 4; iter: 0; batch classifier loss: 0.345141; batch adversarial loss: 0.506764\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362900; batch adversarial loss: 0.595883\n",
      "epoch 6; iter: 0; batch classifier loss: 0.369888; batch adversarial loss: 0.649212\n",
      "epoch 7; iter: 0; batch classifier loss: 0.456801; batch adversarial loss: 0.615445\n",
      "epoch 8; iter: 0; batch classifier loss: 0.507245; batch adversarial loss: 0.595950\n",
      "epoch 9; iter: 0; batch classifier loss: 0.577396; batch adversarial loss: 0.522576\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536788; batch adversarial loss: 0.507787\n",
      "epoch 11; iter: 0; batch classifier loss: 0.411542; batch adversarial loss: 0.544845\n",
      "epoch 12; iter: 0; batch classifier loss: 0.304669; batch adversarial loss: 0.507175\n",
      "epoch 13; iter: 0; batch classifier loss: 0.339789; batch adversarial loss: 0.470438\n",
      "epoch 14; iter: 0; batch classifier loss: 0.224842; batch adversarial loss: 0.499041\n",
      "epoch 15; iter: 0; batch classifier loss: 0.204853; batch adversarial loss: 0.470486\n",
      "epoch 16; iter: 0; batch classifier loss: 0.249478; batch adversarial loss: 0.525806\n",
      "epoch 17; iter: 0; batch classifier loss: 0.254547; batch adversarial loss: 0.449360\n",
      "epoch 18; iter: 0; batch classifier loss: 0.231623; batch adversarial loss: 0.462322\n",
      "epoch 19; iter: 0; batch classifier loss: 0.210482; batch adversarial loss: 0.397092\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204221; batch adversarial loss: 0.432482\n",
      "epoch 21; iter: 0; batch classifier loss: 0.193707; batch adversarial loss: 0.424201\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189579; batch adversarial loss: 0.412349\n",
      "epoch 23; iter: 0; batch classifier loss: 0.203052; batch adversarial loss: 0.408386\n",
      "epoch 24; iter: 0; batch classifier loss: 0.141781; batch adversarial loss: 0.457576\n",
      "epoch 25; iter: 0; batch classifier loss: 0.167903; batch adversarial loss: 0.420076\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193330; batch adversarial loss: 0.403174\n",
      "epoch 27; iter: 0; batch classifier loss: 0.150405; batch adversarial loss: 0.457599\n",
      "epoch 28; iter: 0; batch classifier loss: 0.120883; batch adversarial loss: 0.524603\n",
      "epoch 29; iter: 0; batch classifier loss: 0.161583; batch adversarial loss: 0.433217\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167891; batch adversarial loss: 0.449866\n",
      "epoch 31; iter: 0; batch classifier loss: 0.139291; batch adversarial loss: 0.435198\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154734; batch adversarial loss: 0.529858\n",
      "epoch 33; iter: 0; batch classifier loss: 0.151802; batch adversarial loss: 0.415567\n",
      "epoch 34; iter: 0; batch classifier loss: 0.180370; batch adversarial loss: 0.468911\n",
      "epoch 35; iter: 0; batch classifier loss: 0.178557; batch adversarial loss: 0.375794\n",
      "epoch 36; iter: 0; batch classifier loss: 0.144851; batch adversarial loss: 0.491587\n",
      "epoch 37; iter: 0; batch classifier loss: 0.120391; batch adversarial loss: 0.477556\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148080; batch adversarial loss: 0.463988\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148081; batch adversarial loss: 0.415607\n",
      "epoch 40; iter: 0; batch classifier loss: 0.107308; batch adversarial loss: 0.564384\n",
      "epoch 41; iter: 0; batch classifier loss: 0.100623; batch adversarial loss: 0.480710\n",
      "epoch 42; iter: 0; batch classifier loss: 0.108241; batch adversarial loss: 0.475618\n",
      "epoch 43; iter: 0; batch classifier loss: 0.092205; batch adversarial loss: 0.368697\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124240; batch adversarial loss: 0.455605\n",
      "epoch 45; iter: 0; batch classifier loss: 0.107530; batch adversarial loss: 0.464364\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102255; batch adversarial loss: 0.477478\n",
      "epoch 47; iter: 0; batch classifier loss: 0.156249; batch adversarial loss: 0.495225\n",
      "epoch 48; iter: 0; batch classifier loss: 0.116384; batch adversarial loss: 0.405694\n",
      "epoch 49; iter: 0; batch classifier loss: 0.121508; batch adversarial loss: 0.474378\n",
      "epoch 50; iter: 0; batch classifier loss: 0.178400; batch adversarial loss: 0.457609\n",
      "epoch 51; iter: 0; batch classifier loss: 0.133865; batch adversarial loss: 0.409227\n",
      "epoch 52; iter: 0; batch classifier loss: 0.230155; batch adversarial loss: 0.500019\n",
      "epoch 53; iter: 0; batch classifier loss: 0.150011; batch adversarial loss: 0.403037\n",
      "epoch 54; iter: 0; batch classifier loss: 0.172833; batch adversarial loss: 0.535388\n",
      "epoch 55; iter: 0; batch classifier loss: 0.201543; batch adversarial loss: 0.440435\n",
      "epoch 56; iter: 0; batch classifier loss: 0.143518; batch adversarial loss: 0.432589\n",
      "epoch 57; iter: 0; batch classifier loss: 0.141882; batch adversarial loss: 0.498801\n",
      "epoch 58; iter: 0; batch classifier loss: 0.124300; batch adversarial loss: 0.477970\n",
      "epoch 59; iter: 0; batch classifier loss: 0.137441; batch adversarial loss: 0.531597\n",
      "epoch 60; iter: 0; batch classifier loss: 0.111451; batch adversarial loss: 0.445983\n",
      "epoch 61; iter: 0; batch classifier loss: 0.201223; batch adversarial loss: 0.375998\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085045; batch adversarial loss: 0.426118\n",
      "epoch 63; iter: 0; batch classifier loss: 0.117972; batch adversarial loss: 0.519545\n",
      "epoch 64; iter: 0; batch classifier loss: 0.104090; batch adversarial loss: 0.432744\n",
      "epoch 65; iter: 0; batch classifier loss: 0.185032; batch adversarial loss: 0.515398\n",
      "epoch 66; iter: 0; batch classifier loss: 0.172977; batch adversarial loss: 0.435129\n",
      "epoch 67; iter: 0; batch classifier loss: 0.119420; batch adversarial loss: 0.523123\n",
      "epoch 68; iter: 0; batch classifier loss: 0.114011; batch adversarial loss: 0.517894\n",
      "epoch 69; iter: 0; batch classifier loss: 0.181180; batch adversarial loss: 0.493574\n",
      "epoch 70; iter: 0; batch classifier loss: 0.133372; batch adversarial loss: 0.508556\n",
      "epoch 71; iter: 0; batch classifier loss: 0.189052; batch adversarial loss: 0.432338\n",
      "epoch 72; iter: 0; batch classifier loss: 0.114464; batch adversarial loss: 0.434814\n",
      "epoch 73; iter: 0; batch classifier loss: 0.218400; batch adversarial loss: 0.373255\n",
      "epoch 74; iter: 0; batch classifier loss: 0.209838; batch adversarial loss: 0.454516\n",
      "epoch 75; iter: 0; batch classifier loss: 0.163123; batch adversarial loss: 0.375508\n",
      "epoch 76; iter: 0; batch classifier loss: 0.115927; batch adversarial loss: 0.506088\n",
      "epoch 77; iter: 0; batch classifier loss: 0.149350; batch adversarial loss: 0.507009\n",
      "epoch 78; iter: 0; batch classifier loss: 0.176864; batch adversarial loss: 0.463683\n",
      "epoch 79; iter: 0; batch classifier loss: 0.156485; batch adversarial loss: 0.470692\n",
      "epoch 80; iter: 0; batch classifier loss: 0.123587; batch adversarial loss: 0.587800\n",
      "epoch 81; iter: 0; batch classifier loss: 0.178111; batch adversarial loss: 0.355520\n",
      "epoch 82; iter: 0; batch classifier loss: 0.168979; batch adversarial loss: 0.460436\n",
      "epoch 83; iter: 0; batch classifier loss: 0.165611; batch adversarial loss: 0.398885\n",
      "epoch 84; iter: 0; batch classifier loss: 0.135890; batch adversarial loss: 0.423143\n",
      "epoch 85; iter: 0; batch classifier loss: 0.226132; batch adversarial loss: 0.370760\n",
      "epoch 86; iter: 0; batch classifier loss: 0.115800; batch adversarial loss: 0.458947\n",
      "epoch 87; iter: 0; batch classifier loss: 0.199716; batch adversarial loss: 0.492760\n",
      "epoch 88; iter: 0; batch classifier loss: 0.184823; batch adversarial loss: 0.486054\n",
      "epoch 89; iter: 0; batch classifier loss: 0.140159; batch adversarial loss: 0.396490\n",
      "epoch 90; iter: 0; batch classifier loss: 0.129749; batch adversarial loss: 0.444262\n",
      "epoch 91; iter: 0; batch classifier loss: 0.139555; batch adversarial loss: 0.385989\n",
      "epoch 92; iter: 0; batch classifier loss: 0.147687; batch adversarial loss: 0.428328\n",
      "epoch 93; iter: 0; batch classifier loss: 0.178836; batch adversarial loss: 0.408141\n",
      "epoch 94; iter: 0; batch classifier loss: 0.122363; batch adversarial loss: 0.465589\n",
      "epoch 95; iter: 0; batch classifier loss: 0.151263; batch adversarial loss: 0.471077\n",
      "epoch 96; iter: 0; batch classifier loss: 0.205611; batch adversarial loss: 0.364217\n",
      "epoch 97; iter: 0; batch classifier loss: 0.137443; batch adversarial loss: 0.491604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.208991; batch adversarial loss: 0.478206\n",
      "epoch 99; iter: 0; batch classifier loss: 0.179576; batch adversarial loss: 0.406623\n",
      "epoch 100; iter: 0; batch classifier loss: 0.088406; batch adversarial loss: 0.497531\n",
      "epoch 101; iter: 0; batch classifier loss: 0.130976; batch adversarial loss: 0.508413\n",
      "epoch 102; iter: 0; batch classifier loss: 0.153964; batch adversarial loss: 0.368843\n",
      "epoch 103; iter: 0; batch classifier loss: 0.165494; batch adversarial loss: 0.468422\n",
      "epoch 104; iter: 0; batch classifier loss: 0.156913; batch adversarial loss: 0.475311\n",
      "epoch 105; iter: 0; batch classifier loss: 0.119856; batch adversarial loss: 0.406374\n",
      "epoch 106; iter: 0; batch classifier loss: 0.153477; batch adversarial loss: 0.389795\n",
      "epoch 107; iter: 0; batch classifier loss: 0.108543; batch adversarial loss: 0.530792\n",
      "epoch 108; iter: 0; batch classifier loss: 0.127106; batch adversarial loss: 0.452931\n",
      "epoch 109; iter: 0; batch classifier loss: 0.131436; batch adversarial loss: 0.559244\n",
      "epoch 110; iter: 0; batch classifier loss: 0.151311; batch adversarial loss: 0.441622\n",
      "epoch 111; iter: 0; batch classifier loss: 0.130170; batch adversarial loss: 0.445647\n",
      "epoch 112; iter: 0; batch classifier loss: 0.122851; batch adversarial loss: 0.572679\n",
      "epoch 113; iter: 0; batch classifier loss: 0.162680; batch adversarial loss: 0.408614\n",
      "epoch 114; iter: 0; batch classifier loss: 0.083246; batch adversarial loss: 0.443996\n",
      "epoch 115; iter: 0; batch classifier loss: 0.114326; batch adversarial loss: 0.447717\n",
      "epoch 116; iter: 0; batch classifier loss: 0.092700; batch adversarial loss: 0.424234\n",
      "epoch 117; iter: 0; batch classifier loss: 0.115772; batch adversarial loss: 0.444050\n",
      "epoch 118; iter: 0; batch classifier loss: 0.068279; batch adversarial loss: 0.482741\n",
      "epoch 119; iter: 0; batch classifier loss: 0.078398; batch adversarial loss: 0.515299\n",
      "epoch 120; iter: 0; batch classifier loss: 0.060088; batch adversarial loss: 0.503329\n",
      "epoch 121; iter: 0; batch classifier loss: 0.078300; batch adversarial loss: 0.422163\n",
      "epoch 122; iter: 0; batch classifier loss: 0.105375; batch adversarial loss: 0.418697\n",
      "epoch 123; iter: 0; batch classifier loss: 0.082659; batch adversarial loss: 0.460341\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054552; batch adversarial loss: 0.432141\n",
      "epoch 125; iter: 0; batch classifier loss: 0.098809; batch adversarial loss: 0.522009\n",
      "epoch 126; iter: 0; batch classifier loss: 0.064409; batch adversarial loss: 0.516957\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048176; batch adversarial loss: 0.552695\n",
      "epoch 128; iter: 0; batch classifier loss: 0.048879; batch adversarial loss: 0.472512\n",
      "epoch 129; iter: 0; batch classifier loss: 0.072221; batch adversarial loss: 0.448361\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040521; batch adversarial loss: 0.476968\n",
      "epoch 131; iter: 0; batch classifier loss: 0.069197; batch adversarial loss: 0.396391\n",
      "epoch 132; iter: 0; batch classifier loss: 0.065297; batch adversarial loss: 0.417022\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032821; batch adversarial loss: 0.351157\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042047; batch adversarial loss: 0.473736\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040305; batch adversarial loss: 0.509917\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032789; batch adversarial loss: 0.478928\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015158; batch adversarial loss: 0.442116\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039500; batch adversarial loss: 0.491361\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038519; batch adversarial loss: 0.447556\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038010; batch adversarial loss: 0.432579\n",
      "epoch 141; iter: 0; batch classifier loss: 0.065509; batch adversarial loss: 0.377599\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042274; batch adversarial loss: 0.424176\n",
      "epoch 143; iter: 0; batch classifier loss: 0.052895; batch adversarial loss: 0.542956\n",
      "epoch 144; iter: 0; batch classifier loss: 0.066647; batch adversarial loss: 0.499907\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025648; batch adversarial loss: 0.452409\n",
      "epoch 146; iter: 0; batch classifier loss: 0.068172; batch adversarial loss: 0.357058\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046554; batch adversarial loss: 0.429043\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046514; batch adversarial loss: 0.443439\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053011; batch adversarial loss: 0.438034\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016557; batch adversarial loss: 0.426853\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022688; batch adversarial loss: 0.421767\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023449; batch adversarial loss: 0.445048\n",
      "epoch 153; iter: 0; batch classifier loss: 0.069180; batch adversarial loss: 0.434188\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020587; batch adversarial loss: 0.485698\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022254; batch adversarial loss: 0.374928\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014968; batch adversarial loss: 0.487204\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040739; batch adversarial loss: 0.473730\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016563; batch adversarial loss: 0.485960\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017232; batch adversarial loss: 0.474610\n",
      "epoch 160; iter: 0; batch classifier loss: 0.043192; batch adversarial loss: 0.517804\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022714; batch adversarial loss: 0.454434\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037684; batch adversarial loss: 0.458173\n",
      "epoch 163; iter: 0; batch classifier loss: 0.069111; batch adversarial loss: 0.432107\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025832; batch adversarial loss: 0.561597\n",
      "epoch 165; iter: 0; batch classifier loss: 0.048762; batch adversarial loss: 0.418265\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021315; batch adversarial loss: 0.503050\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021661; batch adversarial loss: 0.425676\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040397; batch adversarial loss: 0.446741\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030861; batch adversarial loss: 0.461044\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021472; batch adversarial loss: 0.430745\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007930; batch adversarial loss: 0.432746\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019158; batch adversarial loss: 0.425773\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023376; batch adversarial loss: 0.489039\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015027; batch adversarial loss: 0.488339\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022081; batch adversarial loss: 0.433419\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023799; batch adversarial loss: 0.426953\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036516; batch adversarial loss: 0.476921\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018846; batch adversarial loss: 0.442298\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030122; batch adversarial loss: 0.543356\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012393; batch adversarial loss: 0.410028\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036702; batch adversarial loss: 0.369872\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014196; batch adversarial loss: 0.428458\n",
      "epoch 183; iter: 0; batch classifier loss: 0.038437; batch adversarial loss: 0.500543\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014087; batch adversarial loss: 0.478996\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007619; batch adversarial loss: 0.419733\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023109; batch adversarial loss: 0.487924\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023525; batch adversarial loss: 0.474425\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027883; batch adversarial loss: 0.472288\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014874; batch adversarial loss: 0.422413\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015813; batch adversarial loss: 0.507605\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013617; batch adversarial loss: 0.388114\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023057; batch adversarial loss: 0.459365\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010406; batch adversarial loss: 0.411176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.025073; batch adversarial loss: 0.444695\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015754; batch adversarial loss: 0.420596\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014299; batch adversarial loss: 0.523260\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012532; batch adversarial loss: 0.524845\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023977; batch adversarial loss: 0.416807\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021510; batch adversarial loss: 0.485299\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696928; batch adversarial loss: 0.819376\n",
      "epoch 1; iter: 0; batch classifier loss: 0.659315; batch adversarial loss: 0.831316\n",
      "epoch 2; iter: 0; batch classifier loss: 0.773764; batch adversarial loss: 0.782474\n",
      "epoch 3; iter: 0; batch classifier loss: 0.673423; batch adversarial loss: 0.685309\n",
      "epoch 4; iter: 0; batch classifier loss: 0.621065; batch adversarial loss: 0.643471\n",
      "epoch 5; iter: 0; batch classifier loss: 0.405671; batch adversarial loss: 0.593061\n",
      "epoch 6; iter: 0; batch classifier loss: 0.369552; batch adversarial loss: 0.520303\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338129; batch adversarial loss: 0.592359\n",
      "epoch 8; iter: 0; batch classifier loss: 0.342771; batch adversarial loss: 0.504904\n",
      "epoch 9; iter: 0; batch classifier loss: 0.274896; batch adversarial loss: 0.512322\n",
      "epoch 10; iter: 0; batch classifier loss: 0.280574; batch adversarial loss: 0.527627\n",
      "epoch 11; iter: 0; batch classifier loss: 0.267119; batch adversarial loss: 0.471834\n",
      "epoch 12; iter: 0; batch classifier loss: 0.296033; batch adversarial loss: 0.495707\n",
      "epoch 13; iter: 0; batch classifier loss: 0.270762; batch adversarial loss: 0.508514\n",
      "epoch 14; iter: 0; batch classifier loss: 0.237375; batch adversarial loss: 0.488488\n",
      "epoch 15; iter: 0; batch classifier loss: 0.217154; batch adversarial loss: 0.549266\n",
      "epoch 16; iter: 0; batch classifier loss: 0.184555; batch adversarial loss: 0.528132\n",
      "epoch 17; iter: 0; batch classifier loss: 0.285053; batch adversarial loss: 0.454323\n",
      "epoch 18; iter: 0; batch classifier loss: 0.110635; batch adversarial loss: 0.517789\n",
      "epoch 19; iter: 0; batch classifier loss: 0.235680; batch adversarial loss: 0.525221\n",
      "epoch 20; iter: 0; batch classifier loss: 0.160773; batch adversarial loss: 0.519610\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202641; batch adversarial loss: 0.546140\n",
      "epoch 22; iter: 0; batch classifier loss: 0.196983; batch adversarial loss: 0.484655\n",
      "epoch 23; iter: 0; batch classifier loss: 0.179503; batch adversarial loss: 0.550994\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192714; batch adversarial loss: 0.424636\n",
      "epoch 25; iter: 0; batch classifier loss: 0.169907; batch adversarial loss: 0.610056\n",
      "epoch 26; iter: 0; batch classifier loss: 0.149639; batch adversarial loss: 0.477914\n",
      "epoch 27; iter: 0; batch classifier loss: 0.234222; batch adversarial loss: 0.436132\n",
      "epoch 28; iter: 0; batch classifier loss: 0.141768; batch adversarial loss: 0.480742\n",
      "epoch 29; iter: 0; batch classifier loss: 0.131006; batch adversarial loss: 0.542687\n",
      "epoch 30; iter: 0; batch classifier loss: 0.150021; batch adversarial loss: 0.408936\n",
      "epoch 31; iter: 0; batch classifier loss: 0.208101; batch adversarial loss: 0.565094\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126303; batch adversarial loss: 0.511193\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143296; batch adversarial loss: 0.494460\n",
      "epoch 34; iter: 0; batch classifier loss: 0.159637; batch adversarial loss: 0.432988\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137632; batch adversarial loss: 0.427962\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150185; batch adversarial loss: 0.470251\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153435; batch adversarial loss: 0.461971\n",
      "epoch 38; iter: 0; batch classifier loss: 0.135504; batch adversarial loss: 0.456473\n",
      "epoch 39; iter: 0; batch classifier loss: 0.117318; batch adversarial loss: 0.436272\n",
      "epoch 40; iter: 0; batch classifier loss: 0.144829; batch adversarial loss: 0.556310\n",
      "epoch 41; iter: 0; batch classifier loss: 0.134466; batch adversarial loss: 0.449434\n",
      "epoch 42; iter: 0; batch classifier loss: 0.112955; batch adversarial loss: 0.394412\n",
      "epoch 43; iter: 0; batch classifier loss: 0.157446; batch adversarial loss: 0.493335\n",
      "epoch 44; iter: 0; batch classifier loss: 0.120091; batch adversarial loss: 0.489436\n",
      "epoch 45; iter: 0; batch classifier loss: 0.081317; batch adversarial loss: 0.460540\n",
      "epoch 46; iter: 0; batch classifier loss: 0.135819; batch adversarial loss: 0.428406\n",
      "epoch 47; iter: 0; batch classifier loss: 0.133447; batch adversarial loss: 0.434552\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082785; batch adversarial loss: 0.516195\n",
      "epoch 49; iter: 0; batch classifier loss: 0.093445; batch adversarial loss: 0.489896\n",
      "epoch 50; iter: 0; batch classifier loss: 0.111100; batch adversarial loss: 0.541338\n",
      "epoch 51; iter: 0; batch classifier loss: 0.088100; batch adversarial loss: 0.426152\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082746; batch adversarial loss: 0.444286\n",
      "epoch 53; iter: 0; batch classifier loss: 0.089554; batch adversarial loss: 0.520736\n",
      "epoch 54; iter: 0; batch classifier loss: 0.105334; batch adversarial loss: 0.512643\n",
      "epoch 55; iter: 0; batch classifier loss: 0.070751; batch adversarial loss: 0.391289\n",
      "epoch 56; iter: 0; batch classifier loss: 0.113993; batch adversarial loss: 0.477724\n",
      "epoch 57; iter: 0; batch classifier loss: 0.078570; batch adversarial loss: 0.535099\n",
      "epoch 58; iter: 0; batch classifier loss: 0.088552; batch adversarial loss: 0.493105\n",
      "epoch 59; iter: 0; batch classifier loss: 0.160823; batch adversarial loss: 0.496014\n",
      "epoch 60; iter: 0; batch classifier loss: 0.101879; batch adversarial loss: 0.458350\n",
      "epoch 61; iter: 0; batch classifier loss: 0.128584; batch adversarial loss: 0.422837\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108072; batch adversarial loss: 0.497055\n",
      "epoch 63; iter: 0; batch classifier loss: 0.105301; batch adversarial loss: 0.466269\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082674; batch adversarial loss: 0.399392\n",
      "epoch 65; iter: 0; batch classifier loss: 0.059500; batch adversarial loss: 0.452299\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084408; batch adversarial loss: 0.394026\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095286; batch adversarial loss: 0.433109\n",
      "epoch 68; iter: 0; batch classifier loss: 0.042571; batch adversarial loss: 0.525023\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081279; batch adversarial loss: 0.409652\n",
      "epoch 70; iter: 0; batch classifier loss: 0.092547; batch adversarial loss: 0.422784\n",
      "epoch 71; iter: 0; batch classifier loss: 0.098294; batch adversarial loss: 0.518099\n",
      "epoch 72; iter: 0; batch classifier loss: 0.065944; batch adversarial loss: 0.359461\n",
      "epoch 73; iter: 0; batch classifier loss: 0.059959; batch adversarial loss: 0.448192\n",
      "epoch 74; iter: 0; batch classifier loss: 0.092037; batch adversarial loss: 0.505415\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075164; batch adversarial loss: 0.433916\n",
      "epoch 76; iter: 0; batch classifier loss: 0.112802; batch adversarial loss: 0.458518\n",
      "epoch 77; iter: 0; batch classifier loss: 0.074503; batch adversarial loss: 0.465370\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079548; batch adversarial loss: 0.464800\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082857; batch adversarial loss: 0.460640\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070290; batch adversarial loss: 0.524470\n",
      "epoch 81; iter: 0; batch classifier loss: 0.058290; batch adversarial loss: 0.496141\n",
      "epoch 82; iter: 0; batch classifier loss: 0.080929; batch adversarial loss: 0.495791\n",
      "epoch 83; iter: 0; batch classifier loss: 0.082918; batch adversarial loss: 0.390356\n",
      "epoch 84; iter: 0; batch classifier loss: 0.063589; batch adversarial loss: 0.435522\n",
      "epoch 85; iter: 0; batch classifier loss: 0.102004; batch adversarial loss: 0.431955\n",
      "epoch 86; iter: 0; batch classifier loss: 0.026554; batch adversarial loss: 0.442463\n",
      "epoch 87; iter: 0; batch classifier loss: 0.050554; batch adversarial loss: 0.408887\n",
      "epoch 88; iter: 0; batch classifier loss: 0.081850; batch adversarial loss: 0.410940\n",
      "epoch 89; iter: 0; batch classifier loss: 0.055406; batch adversarial loss: 0.513980\n",
      "epoch 90; iter: 0; batch classifier loss: 0.038333; batch adversarial loss: 0.432333\n",
      "epoch 91; iter: 0; batch classifier loss: 0.039482; batch adversarial loss: 0.558708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.055520; batch adversarial loss: 0.482440\n",
      "epoch 93; iter: 0; batch classifier loss: 0.075606; batch adversarial loss: 0.471772\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044010; batch adversarial loss: 0.569440\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054584; batch adversarial loss: 0.457272\n",
      "epoch 96; iter: 0; batch classifier loss: 0.038167; batch adversarial loss: 0.447296\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064539; batch adversarial loss: 0.408304\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046655; batch adversarial loss: 0.413040\n",
      "epoch 99; iter: 0; batch classifier loss: 0.088480; batch adversarial loss: 0.459426\n",
      "epoch 100; iter: 0; batch classifier loss: 0.042770; batch adversarial loss: 0.473094\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044766; batch adversarial loss: 0.412503\n",
      "epoch 102; iter: 0; batch classifier loss: 0.030907; batch adversarial loss: 0.488149\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048384; batch adversarial loss: 0.432781\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059101; batch adversarial loss: 0.418972\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054002; batch adversarial loss: 0.438235\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035432; batch adversarial loss: 0.491606\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065489; batch adversarial loss: 0.511980\n",
      "epoch 108; iter: 0; batch classifier loss: 0.085719; batch adversarial loss: 0.529721\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051064; batch adversarial loss: 0.400169\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045759; batch adversarial loss: 0.489756\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043604; batch adversarial loss: 0.481204\n",
      "epoch 112; iter: 0; batch classifier loss: 0.029208; batch adversarial loss: 0.384511\n",
      "epoch 113; iter: 0; batch classifier loss: 0.026395; batch adversarial loss: 0.434885\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046920; batch adversarial loss: 0.432225\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062075; batch adversarial loss: 0.491831\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040124; batch adversarial loss: 0.459004\n",
      "epoch 117; iter: 0; batch classifier loss: 0.074555; batch adversarial loss: 0.478098\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044737; batch adversarial loss: 0.477812\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053283; batch adversarial loss: 0.455376\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037058; batch adversarial loss: 0.417108\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051322; batch adversarial loss: 0.394209\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046288; batch adversarial loss: 0.410839\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035005; batch adversarial loss: 0.439316\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027388; batch adversarial loss: 0.409276\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023095; batch adversarial loss: 0.468704\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051540; batch adversarial loss: 0.409024\n",
      "epoch 127; iter: 0; batch classifier loss: 0.056252; batch adversarial loss: 0.351617\n",
      "epoch 128; iter: 0; batch classifier loss: 0.072231; batch adversarial loss: 0.483031\n",
      "epoch 129; iter: 0; batch classifier loss: 0.049078; batch adversarial loss: 0.445032\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029761; batch adversarial loss: 0.437320\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040950; batch adversarial loss: 0.368328\n",
      "epoch 132; iter: 0; batch classifier loss: 0.066676; batch adversarial loss: 0.467676\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020772; batch adversarial loss: 0.451313\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030248; batch adversarial loss: 0.433021\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036722; batch adversarial loss: 0.399343\n",
      "epoch 136; iter: 0; batch classifier loss: 0.010699; batch adversarial loss: 0.489130\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023068; batch adversarial loss: 0.489435\n",
      "epoch 138; iter: 0; batch classifier loss: 0.009767; batch adversarial loss: 0.454752\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022797; batch adversarial loss: 0.458569\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029647; batch adversarial loss: 0.519943\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025987; batch adversarial loss: 0.424863\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017137; batch adversarial loss: 0.405436\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023501; batch adversarial loss: 0.390610\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012522; batch adversarial loss: 0.422458\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029677; batch adversarial loss: 0.507248\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030946; batch adversarial loss: 0.470213\n",
      "epoch 147; iter: 0; batch classifier loss: 0.054601; batch adversarial loss: 0.381501\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028957; batch adversarial loss: 0.364997\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022138; batch adversarial loss: 0.386260\n",
      "epoch 150; iter: 0; batch classifier loss: 0.076786; batch adversarial loss: 0.491595\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026130; batch adversarial loss: 0.479093\n",
      "epoch 152; iter: 0; batch classifier loss: 0.012337; batch adversarial loss: 0.479199\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039080; batch adversarial loss: 0.468234\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017874; batch adversarial loss: 0.392546\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028532; batch adversarial loss: 0.489581\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020097; batch adversarial loss: 0.453177\n",
      "epoch 157; iter: 0; batch classifier loss: 0.047788; batch adversarial loss: 0.507444\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010540; batch adversarial loss: 0.367429\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027052; batch adversarial loss: 0.390761\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031087; batch adversarial loss: 0.544446\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025152; batch adversarial loss: 0.482803\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029357; batch adversarial loss: 0.474360\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012960; batch adversarial loss: 0.438702\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018754; batch adversarial loss: 0.423118\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026879; batch adversarial loss: 0.452962\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023331; batch adversarial loss: 0.421215\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017502; batch adversarial loss: 0.424873\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007363; batch adversarial loss: 0.493269\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034385; batch adversarial loss: 0.443938\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031627; batch adversarial loss: 0.374937\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025732; batch adversarial loss: 0.436758\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021738; batch adversarial loss: 0.482422\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025217; batch adversarial loss: 0.440235\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041936; batch adversarial loss: 0.344385\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023479; batch adversarial loss: 0.430305\n",
      "epoch 176; iter: 0; batch classifier loss: 0.038868; batch adversarial loss: 0.461539\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021517; batch adversarial loss: 0.472441\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027425; batch adversarial loss: 0.471848\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012425; batch adversarial loss: 0.402991\n",
      "epoch 180; iter: 0; batch classifier loss: 0.004599; batch adversarial loss: 0.415291\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016098; batch adversarial loss: 0.469117\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023187; batch adversarial loss: 0.407768\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017723; batch adversarial loss: 0.460887\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026695; batch adversarial loss: 0.400440\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007391; batch adversarial loss: 0.391191\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010144; batch adversarial loss: 0.417592\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021538; batch adversarial loss: 0.463453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.007730; batch adversarial loss: 0.575027\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011799; batch adversarial loss: 0.532560\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008029; batch adversarial loss: 0.437231\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026449; batch adversarial loss: 0.428871\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011868; batch adversarial loss: 0.447497\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019515; batch adversarial loss: 0.341478\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005967; batch adversarial loss: 0.452488\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012466; batch adversarial loss: 0.520577\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023411; batch adversarial loss: 0.468991\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006811; batch adversarial loss: 0.532564\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015414; batch adversarial loss: 0.461627\n",
      "epoch 199; iter: 0; batch classifier loss: 0.045915; batch adversarial loss: 0.458952\n",
      "epoch 0; iter: 0; batch classifier loss: 0.733441; batch adversarial loss: 0.631931\n",
      "epoch 1; iter: 0; batch classifier loss: 0.483217; batch adversarial loss: 0.617393\n",
      "epoch 2; iter: 0; batch classifier loss: 0.418312; batch adversarial loss: 0.620038\n",
      "epoch 3; iter: 0; batch classifier loss: 0.365904; batch adversarial loss: 0.605979\n",
      "epoch 4; iter: 0; batch classifier loss: 0.427469; batch adversarial loss: 0.601114\n",
      "epoch 5; iter: 0; batch classifier loss: 0.358219; batch adversarial loss: 0.592723\n",
      "epoch 6; iter: 0; batch classifier loss: 0.419738; batch adversarial loss: 0.510921\n",
      "epoch 7; iter: 0; batch classifier loss: 0.389284; batch adversarial loss: 0.558931\n",
      "epoch 8; iter: 0; batch classifier loss: 0.531513; batch adversarial loss: 0.585377\n",
      "epoch 9; iter: 0; batch classifier loss: 0.495355; batch adversarial loss: 0.558920\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568300; batch adversarial loss: 0.479858\n",
      "epoch 11; iter: 0; batch classifier loss: 0.468025; batch adversarial loss: 0.531090\n",
      "epoch 12; iter: 0; batch classifier loss: 0.381120; batch adversarial loss: 0.468315\n",
      "epoch 13; iter: 0; batch classifier loss: 0.393092; batch adversarial loss: 0.513490\n",
      "epoch 14; iter: 0; batch classifier loss: 0.258797; batch adversarial loss: 0.482178\n",
      "epoch 15; iter: 0; batch classifier loss: 0.300237; batch adversarial loss: 0.449744\n",
      "epoch 16; iter: 0; batch classifier loss: 0.298363; batch adversarial loss: 0.489931\n",
      "epoch 17; iter: 0; batch classifier loss: 0.245482; batch adversarial loss: 0.508551\n",
      "epoch 18; iter: 0; batch classifier loss: 0.343713; batch adversarial loss: 0.468572\n",
      "epoch 19; iter: 0; batch classifier loss: 0.311841; batch adversarial loss: 0.483846\n",
      "epoch 20; iter: 0; batch classifier loss: 0.281778; batch adversarial loss: 0.445353\n",
      "epoch 21; iter: 0; batch classifier loss: 0.247982; batch adversarial loss: 0.476799\n",
      "epoch 22; iter: 0; batch classifier loss: 0.237788; batch adversarial loss: 0.502270\n",
      "epoch 23; iter: 0; batch classifier loss: 0.249404; batch adversarial loss: 0.443437\n",
      "epoch 24; iter: 0; batch classifier loss: 0.203369; batch adversarial loss: 0.473175\n",
      "epoch 25; iter: 0; batch classifier loss: 0.193299; batch adversarial loss: 0.458205\n",
      "epoch 26; iter: 0; batch classifier loss: 0.196385; batch adversarial loss: 0.455156\n",
      "epoch 27; iter: 0; batch classifier loss: 0.163356; batch adversarial loss: 0.453091\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217833; batch adversarial loss: 0.415058\n",
      "epoch 29; iter: 0; batch classifier loss: 0.208324; batch adversarial loss: 0.447808\n",
      "epoch 30; iter: 0; batch classifier loss: 0.168775; batch adversarial loss: 0.481285\n",
      "epoch 31; iter: 0; batch classifier loss: 0.207751; batch adversarial loss: 0.436823\n",
      "epoch 32; iter: 0; batch classifier loss: 0.132147; batch adversarial loss: 0.495872\n",
      "epoch 33; iter: 0; batch classifier loss: 0.237246; batch adversarial loss: 0.417915\n",
      "epoch 34; iter: 0; batch classifier loss: 0.194968; batch adversarial loss: 0.512825\n",
      "epoch 35; iter: 0; batch classifier loss: 0.176101; batch adversarial loss: 0.404703\n",
      "epoch 36; iter: 0; batch classifier loss: 0.175628; batch adversarial loss: 0.528444\n",
      "epoch 37; iter: 0; batch classifier loss: 0.176654; batch adversarial loss: 0.469243\n",
      "epoch 38; iter: 0; batch classifier loss: 0.200437; batch adversarial loss: 0.458683\n",
      "epoch 39; iter: 0; batch classifier loss: 0.237867; batch adversarial loss: 0.446508\n",
      "epoch 40; iter: 0; batch classifier loss: 0.136796; batch adversarial loss: 0.394890\n",
      "epoch 41; iter: 0; batch classifier loss: 0.150070; batch adversarial loss: 0.454655\n",
      "epoch 42; iter: 0; batch classifier loss: 0.213891; batch adversarial loss: 0.387892\n",
      "epoch 43; iter: 0; batch classifier loss: 0.137070; batch adversarial loss: 0.450651\n",
      "epoch 44; iter: 0; batch classifier loss: 0.142377; batch adversarial loss: 0.409558\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102531; batch adversarial loss: 0.522848\n",
      "epoch 46; iter: 0; batch classifier loss: 0.128741; batch adversarial loss: 0.368142\n",
      "epoch 47; iter: 0; batch classifier loss: 0.111530; batch adversarial loss: 0.442632\n",
      "epoch 48; iter: 0; batch classifier loss: 0.158480; batch adversarial loss: 0.424087\n",
      "epoch 49; iter: 0; batch classifier loss: 0.147302; batch adversarial loss: 0.454484\n",
      "epoch 50; iter: 0; batch classifier loss: 0.132311; batch adversarial loss: 0.422067\n",
      "epoch 51; iter: 0; batch classifier loss: 0.205804; batch adversarial loss: 0.392319\n",
      "epoch 52; iter: 0; batch classifier loss: 0.164038; batch adversarial loss: 0.412884\n",
      "epoch 53; iter: 0; batch classifier loss: 0.130217; batch adversarial loss: 0.410929\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108861; batch adversarial loss: 0.518547\n",
      "epoch 55; iter: 0; batch classifier loss: 0.138016; batch adversarial loss: 0.466022\n",
      "epoch 56; iter: 0; batch classifier loss: 0.153811; batch adversarial loss: 0.505232\n",
      "epoch 57; iter: 0; batch classifier loss: 0.116615; batch adversarial loss: 0.464565\n",
      "epoch 58; iter: 0; batch classifier loss: 0.187739; batch adversarial loss: 0.445632\n",
      "epoch 59; iter: 0; batch classifier loss: 0.166902; batch adversarial loss: 0.359653\n",
      "epoch 60; iter: 0; batch classifier loss: 0.101013; batch adversarial loss: 0.356406\n",
      "epoch 61; iter: 0; batch classifier loss: 0.151543; batch adversarial loss: 0.397118\n",
      "epoch 62; iter: 0; batch classifier loss: 0.138216; batch adversarial loss: 0.353026\n",
      "epoch 63; iter: 0; batch classifier loss: 0.082881; batch adversarial loss: 0.572279\n",
      "epoch 64; iter: 0; batch classifier loss: 0.123052; batch adversarial loss: 0.338980\n",
      "epoch 65; iter: 0; batch classifier loss: 0.099018; batch adversarial loss: 0.397548\n",
      "epoch 66; iter: 0; batch classifier loss: 0.165390; batch adversarial loss: 0.404439\n",
      "epoch 67; iter: 0; batch classifier loss: 0.121522; batch adversarial loss: 0.476590\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081099; batch adversarial loss: 0.459277\n",
      "epoch 69; iter: 0; batch classifier loss: 0.110875; batch adversarial loss: 0.423725\n",
      "epoch 70; iter: 0; batch classifier loss: 0.100800; batch adversarial loss: 0.461475\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079036; batch adversarial loss: 0.505668\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087389; batch adversarial loss: 0.509591\n",
      "epoch 73; iter: 0; batch classifier loss: 0.091661; batch adversarial loss: 0.551400\n",
      "epoch 74; iter: 0; batch classifier loss: 0.099445; batch adversarial loss: 0.508543\n",
      "epoch 75; iter: 0; batch classifier loss: 0.110014; batch adversarial loss: 0.402106\n",
      "epoch 76; iter: 0; batch classifier loss: 0.086892; batch adversarial loss: 0.506092\n",
      "epoch 77; iter: 0; batch classifier loss: 0.061807; batch adversarial loss: 0.404710\n",
      "epoch 78; iter: 0; batch classifier loss: 0.068173; batch adversarial loss: 0.451972\n",
      "epoch 79; iter: 0; batch classifier loss: 0.098280; batch adversarial loss: 0.452816\n",
      "epoch 80; iter: 0; batch classifier loss: 0.104629; batch adversarial loss: 0.400412\n",
      "epoch 81; iter: 0; batch classifier loss: 0.122943; batch adversarial loss: 0.448810\n",
      "epoch 82; iter: 0; batch classifier loss: 0.069034; batch adversarial loss: 0.517938\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078051; batch adversarial loss: 0.505253\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062292; batch adversarial loss: 0.440779\n",
      "epoch 85; iter: 0; batch classifier loss: 0.141144; batch adversarial loss: 0.456825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.072797; batch adversarial loss: 0.401353\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056488; batch adversarial loss: 0.470300\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054890; batch adversarial loss: 0.425569\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073979; batch adversarial loss: 0.462298\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060536; batch adversarial loss: 0.507335\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077589; batch adversarial loss: 0.439877\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048337; batch adversarial loss: 0.441894\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054756; batch adversarial loss: 0.450380\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051700; batch adversarial loss: 0.371012\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068693; batch adversarial loss: 0.416558\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046352; batch adversarial loss: 0.393170\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049397; batch adversarial loss: 0.446340\n",
      "epoch 98; iter: 0; batch classifier loss: 0.131476; batch adversarial loss: 0.454511\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055194; batch adversarial loss: 0.488065\n",
      "epoch 100; iter: 0; batch classifier loss: 0.079764; batch adversarial loss: 0.383042\n",
      "epoch 101; iter: 0; batch classifier loss: 0.106380; batch adversarial loss: 0.438294\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049534; batch adversarial loss: 0.284791\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043084; batch adversarial loss: 0.456841\n",
      "epoch 104; iter: 0; batch classifier loss: 0.022591; batch adversarial loss: 0.541434\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052566; batch adversarial loss: 0.430756\n",
      "epoch 106; iter: 0; batch classifier loss: 0.072306; batch adversarial loss: 0.445073\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061217; batch adversarial loss: 0.491177\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039157; batch adversarial loss: 0.470942\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045597; batch adversarial loss: 0.483521\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061478; batch adversarial loss: 0.413794\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030904; batch adversarial loss: 0.488294\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037970; batch adversarial loss: 0.472467\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034763; batch adversarial loss: 0.432282\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049545; batch adversarial loss: 0.481591\n",
      "epoch 115; iter: 0; batch classifier loss: 0.074949; batch adversarial loss: 0.458822\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051339; batch adversarial loss: 0.456919\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056270; batch adversarial loss: 0.446628\n",
      "epoch 118; iter: 0; batch classifier loss: 0.064718; batch adversarial loss: 0.390251\n",
      "epoch 119; iter: 0; batch classifier loss: 0.016261; batch adversarial loss: 0.469056\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034978; batch adversarial loss: 0.434515\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042469; batch adversarial loss: 0.410557\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048788; batch adversarial loss: 0.414296\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041658; batch adversarial loss: 0.467153\n",
      "epoch 124; iter: 0; batch classifier loss: 0.062122; batch adversarial loss: 0.445650\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052812; batch adversarial loss: 0.439951\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034183; batch adversarial loss: 0.467403\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035418; batch adversarial loss: 0.430954\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039054; batch adversarial loss: 0.556314\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048957; batch adversarial loss: 0.424409\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021590; batch adversarial loss: 0.398804\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051062; batch adversarial loss: 0.395112\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033877; batch adversarial loss: 0.440675\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041212; batch adversarial loss: 0.449065\n",
      "epoch 134; iter: 0; batch classifier loss: 0.010190; batch adversarial loss: 0.444681\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035551; batch adversarial loss: 0.349809\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039761; batch adversarial loss: 0.488118\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036477; batch adversarial loss: 0.456947\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029980; batch adversarial loss: 0.490556\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035221; batch adversarial loss: 0.390720\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051958; batch adversarial loss: 0.369320\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042275; batch adversarial loss: 0.528951\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022346; batch adversarial loss: 0.477744\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035301; batch adversarial loss: 0.425160\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017299; batch adversarial loss: 0.394629\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019674; batch adversarial loss: 0.394157\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034264; batch adversarial loss: 0.437782\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014795; batch adversarial loss: 0.485445\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014992; batch adversarial loss: 0.453045\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017544; batch adversarial loss: 0.367712\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033067; batch adversarial loss: 0.486118\n",
      "epoch 151; iter: 0; batch classifier loss: 0.047949; batch adversarial loss: 0.545523\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013009; batch adversarial loss: 0.373809\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028581; batch adversarial loss: 0.425599\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028113; batch adversarial loss: 0.388881\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028098; batch adversarial loss: 0.469113\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032766; batch adversarial loss: 0.437405\n",
      "epoch 157; iter: 0; batch classifier loss: 0.008151; batch adversarial loss: 0.384956\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016338; batch adversarial loss: 0.366836\n",
      "epoch 159; iter: 0; batch classifier loss: 0.063356; batch adversarial loss: 0.378153\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032573; batch adversarial loss: 0.419376\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031152; batch adversarial loss: 0.424486\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021887; batch adversarial loss: 0.518317\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018715; batch adversarial loss: 0.401926\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019142; batch adversarial loss: 0.454119\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027863; batch adversarial loss: 0.502816\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012064; batch adversarial loss: 0.418585\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010476; batch adversarial loss: 0.483735\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011307; batch adversarial loss: 0.355800\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011692; batch adversarial loss: 0.484564\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027750; batch adversarial loss: 0.365905\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010496; batch adversarial loss: 0.539958\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027183; batch adversarial loss: 0.458396\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014208; batch adversarial loss: 0.456939\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028280; batch adversarial loss: 0.512041\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039281; batch adversarial loss: 0.456255\n",
      "epoch 176; iter: 0; batch classifier loss: 0.046168; batch adversarial loss: 0.441191\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019291; batch adversarial loss: 0.503867\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016623; batch adversarial loss: 0.489783\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021847; batch adversarial loss: 0.505786\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015671; batch adversarial loss: 0.512276\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039793; batch adversarial loss: 0.367730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.049016; batch adversarial loss: 0.454921\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015662; batch adversarial loss: 0.432756\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023266; batch adversarial loss: 0.439978\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029237; batch adversarial loss: 0.415733\n",
      "epoch 186; iter: 0; batch classifier loss: 0.054886; batch adversarial loss: 0.505279\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019386; batch adversarial loss: 0.501344\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018928; batch adversarial loss: 0.355280\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018719; batch adversarial loss: 0.429832\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009202; batch adversarial loss: 0.407645\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022564; batch adversarial loss: 0.476898\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010073; batch adversarial loss: 0.473992\n",
      "epoch 193; iter: 0; batch classifier loss: 0.033693; batch adversarial loss: 0.483434\n",
      "epoch 194; iter: 0; batch classifier loss: 0.037609; batch adversarial loss: 0.410958\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019211; batch adversarial loss: 0.518481\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030149; batch adversarial loss: 0.470430\n",
      "epoch 197; iter: 0; batch classifier loss: 0.003439; batch adversarial loss: 0.489860\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008531; batch adversarial loss: 0.456497\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017845; batch adversarial loss: 0.397564\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723305; batch adversarial loss: 0.487569\n",
      "epoch 1; iter: 0; batch classifier loss: 0.407700; batch adversarial loss: 0.582733\n",
      "epoch 2; iter: 0; batch classifier loss: 0.334424; batch adversarial loss: 0.551865\n",
      "epoch 3; iter: 0; batch classifier loss: 0.320939; batch adversarial loss: 0.612548\n",
      "epoch 4; iter: 0; batch classifier loss: 0.352761; batch adversarial loss: 0.549258\n",
      "epoch 5; iter: 0; batch classifier loss: 0.393509; batch adversarial loss: 0.560683\n",
      "epoch 6; iter: 0; batch classifier loss: 0.328146; batch adversarial loss: 0.596903\n",
      "epoch 7; iter: 0; batch classifier loss: 0.400210; batch adversarial loss: 0.547783\n",
      "epoch 8; iter: 0; batch classifier loss: 0.414255; batch adversarial loss: 0.676093\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416597; batch adversarial loss: 0.516499\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484406; batch adversarial loss: 0.589696\n",
      "epoch 11; iter: 0; batch classifier loss: 0.438559; batch adversarial loss: 0.552488\n",
      "epoch 12; iter: 0; batch classifier loss: 0.579466; batch adversarial loss: 0.542271\n",
      "epoch 13; iter: 0; batch classifier loss: 0.460018; batch adversarial loss: 0.518830\n",
      "epoch 14; iter: 0; batch classifier loss: 0.592455; batch adversarial loss: 0.482638\n",
      "epoch 15; iter: 0; batch classifier loss: 0.302251; batch adversarial loss: 0.458655\n",
      "epoch 16; iter: 0; batch classifier loss: 0.318924; batch adversarial loss: 0.445235\n",
      "epoch 17; iter: 0; batch classifier loss: 0.248998; batch adversarial loss: 0.532172\n",
      "epoch 18; iter: 0; batch classifier loss: 0.245106; batch adversarial loss: 0.539729\n",
      "epoch 19; iter: 0; batch classifier loss: 0.209799; batch adversarial loss: 0.545137\n",
      "epoch 20; iter: 0; batch classifier loss: 0.226535; batch adversarial loss: 0.388711\n",
      "epoch 21; iter: 0; batch classifier loss: 0.175928; batch adversarial loss: 0.447029\n",
      "epoch 22; iter: 0; batch classifier loss: 0.173674; batch adversarial loss: 0.554415\n",
      "epoch 23; iter: 0; batch classifier loss: 0.206467; batch adversarial loss: 0.551857\n",
      "epoch 24; iter: 0; batch classifier loss: 0.204841; batch adversarial loss: 0.460672\n",
      "epoch 25; iter: 0; batch classifier loss: 0.173810; batch adversarial loss: 0.438048\n",
      "epoch 26; iter: 0; batch classifier loss: 0.152178; batch adversarial loss: 0.444731\n",
      "epoch 27; iter: 0; batch classifier loss: 0.169414; batch adversarial loss: 0.464685\n",
      "epoch 28; iter: 0; batch classifier loss: 0.194548; batch adversarial loss: 0.527203\n",
      "epoch 29; iter: 0; batch classifier loss: 0.167505; batch adversarial loss: 0.430087\n",
      "epoch 30; iter: 0; batch classifier loss: 0.145249; batch adversarial loss: 0.425739\n",
      "epoch 31; iter: 0; batch classifier loss: 0.160884; batch adversarial loss: 0.461981\n",
      "epoch 32; iter: 0; batch classifier loss: 0.224222; batch adversarial loss: 0.493216\n",
      "epoch 33; iter: 0; batch classifier loss: 0.186974; batch adversarial loss: 0.419418\n",
      "epoch 34; iter: 0; batch classifier loss: 0.150733; batch adversarial loss: 0.504829\n",
      "epoch 35; iter: 0; batch classifier loss: 0.166283; batch adversarial loss: 0.466944\n",
      "epoch 36; iter: 0; batch classifier loss: 0.107141; batch adversarial loss: 0.404697\n",
      "epoch 37; iter: 0; batch classifier loss: 0.202356; batch adversarial loss: 0.526963\n",
      "epoch 38; iter: 0; batch classifier loss: 0.133498; batch adversarial loss: 0.488885\n",
      "epoch 39; iter: 0; batch classifier loss: 0.116612; batch adversarial loss: 0.517565\n",
      "epoch 40; iter: 0; batch classifier loss: 0.156051; batch adversarial loss: 0.480985\n",
      "epoch 41; iter: 0; batch classifier loss: 0.111726; batch adversarial loss: 0.467773\n",
      "epoch 42; iter: 0; batch classifier loss: 0.155422; batch adversarial loss: 0.501104\n",
      "epoch 43; iter: 0; batch classifier loss: 0.098705; batch adversarial loss: 0.424080\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136092; batch adversarial loss: 0.519983\n",
      "epoch 45; iter: 0; batch classifier loss: 0.113384; batch adversarial loss: 0.426859\n",
      "epoch 46; iter: 0; batch classifier loss: 0.092765; batch adversarial loss: 0.425059\n",
      "epoch 47; iter: 0; batch classifier loss: 0.143868; batch adversarial loss: 0.406227\n",
      "epoch 48; iter: 0; batch classifier loss: 0.115068; batch adversarial loss: 0.504001\n",
      "epoch 49; iter: 0; batch classifier loss: 0.134644; batch adversarial loss: 0.484477\n",
      "epoch 50; iter: 0; batch classifier loss: 0.125451; batch adversarial loss: 0.428233\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098599; batch adversarial loss: 0.478567\n",
      "epoch 52; iter: 0; batch classifier loss: 0.131672; batch adversarial loss: 0.479869\n",
      "epoch 53; iter: 0; batch classifier loss: 0.099475; batch adversarial loss: 0.367878\n",
      "epoch 54; iter: 0; batch classifier loss: 0.127657; batch adversarial loss: 0.543836\n",
      "epoch 55; iter: 0; batch classifier loss: 0.120022; batch adversarial loss: 0.479183\n",
      "epoch 56; iter: 0; batch classifier loss: 0.114782; batch adversarial loss: 0.491042\n",
      "epoch 57; iter: 0; batch classifier loss: 0.105642; batch adversarial loss: 0.516733\n",
      "epoch 58; iter: 0; batch classifier loss: 0.119342; batch adversarial loss: 0.443045\n",
      "epoch 59; iter: 0; batch classifier loss: 0.131344; batch adversarial loss: 0.499728\n",
      "epoch 60; iter: 0; batch classifier loss: 0.190994; batch adversarial loss: 0.501554\n",
      "epoch 61; iter: 0; batch classifier loss: 0.127719; batch adversarial loss: 0.334365\n",
      "epoch 62; iter: 0; batch classifier loss: 0.143567; batch adversarial loss: 0.514196\n",
      "epoch 63; iter: 0; batch classifier loss: 0.131378; batch adversarial loss: 0.551246\n",
      "epoch 64; iter: 0; batch classifier loss: 0.122715; batch adversarial loss: 0.383437\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074151; batch adversarial loss: 0.453437\n",
      "epoch 66; iter: 0; batch classifier loss: 0.194677; batch adversarial loss: 0.439652\n",
      "epoch 67; iter: 0; batch classifier loss: 0.078266; batch adversarial loss: 0.506809\n",
      "epoch 68; iter: 0; batch classifier loss: 0.139408; batch adversarial loss: 0.506329\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103670; batch adversarial loss: 0.491910\n",
      "epoch 70; iter: 0; batch classifier loss: 0.137775; batch adversarial loss: 0.420645\n",
      "epoch 71; iter: 0; batch classifier loss: 0.106063; batch adversarial loss: 0.410555\n",
      "epoch 72; iter: 0; batch classifier loss: 0.126347; batch adversarial loss: 0.414189\n",
      "epoch 73; iter: 0; batch classifier loss: 0.108259; batch adversarial loss: 0.540377\n",
      "epoch 74; iter: 0; batch classifier loss: 0.086125; batch adversarial loss: 0.401838\n",
      "epoch 75; iter: 0; batch classifier loss: 0.092298; batch adversarial loss: 0.389085\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083118; batch adversarial loss: 0.474365\n",
      "epoch 77; iter: 0; batch classifier loss: 0.085743; batch adversarial loss: 0.406356\n",
      "epoch 78; iter: 0; batch classifier loss: 0.114541; batch adversarial loss: 0.536125\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072536; batch adversarial loss: 0.488000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.084922; batch adversarial loss: 0.356252\n",
      "epoch 81; iter: 0; batch classifier loss: 0.077580; batch adversarial loss: 0.380958\n",
      "epoch 82; iter: 0; batch classifier loss: 0.103818; batch adversarial loss: 0.454083\n",
      "epoch 83; iter: 0; batch classifier loss: 0.097704; batch adversarial loss: 0.570911\n",
      "epoch 84; iter: 0; batch classifier loss: 0.114146; batch adversarial loss: 0.335670\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077020; batch adversarial loss: 0.376180\n",
      "epoch 86; iter: 0; batch classifier loss: 0.111206; batch adversarial loss: 0.452765\n",
      "epoch 87; iter: 0; batch classifier loss: 0.124962; batch adversarial loss: 0.410872\n",
      "epoch 88; iter: 0; batch classifier loss: 0.113349; batch adversarial loss: 0.445213\n",
      "epoch 89; iter: 0; batch classifier loss: 0.125240; batch adversarial loss: 0.448514\n",
      "epoch 90; iter: 0; batch classifier loss: 0.045838; batch adversarial loss: 0.456811\n",
      "epoch 91; iter: 0; batch classifier loss: 0.096105; batch adversarial loss: 0.473880\n",
      "epoch 92; iter: 0; batch classifier loss: 0.132839; batch adversarial loss: 0.346529\n",
      "epoch 93; iter: 0; batch classifier loss: 0.116965; batch adversarial loss: 0.475786\n",
      "epoch 94; iter: 0; batch classifier loss: 0.082468; batch adversarial loss: 0.444362\n",
      "epoch 95; iter: 0; batch classifier loss: 0.093548; batch adversarial loss: 0.453784\n",
      "epoch 96; iter: 0; batch classifier loss: 0.100149; batch adversarial loss: 0.361049\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072228; batch adversarial loss: 0.421285\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047245; batch adversarial loss: 0.483308\n",
      "epoch 99; iter: 0; batch classifier loss: 0.122444; batch adversarial loss: 0.431290\n",
      "epoch 100; iter: 0; batch classifier loss: 0.093218; batch adversarial loss: 0.410246\n",
      "epoch 101; iter: 0; batch classifier loss: 0.028099; batch adversarial loss: 0.447618\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058588; batch adversarial loss: 0.531108\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064042; batch adversarial loss: 0.484178\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083641; batch adversarial loss: 0.449977\n",
      "epoch 105; iter: 0; batch classifier loss: 0.069548; batch adversarial loss: 0.465010\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055506; batch adversarial loss: 0.470870\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072226; batch adversarial loss: 0.583557\n",
      "epoch 108; iter: 0; batch classifier loss: 0.100790; batch adversarial loss: 0.449533\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058644; batch adversarial loss: 0.395616\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057140; batch adversarial loss: 0.474605\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051898; batch adversarial loss: 0.467808\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030327; batch adversarial loss: 0.457930\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048608; batch adversarial loss: 0.423054\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034094; batch adversarial loss: 0.517356\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032975; batch adversarial loss: 0.489463\n",
      "epoch 116; iter: 0; batch classifier loss: 0.084749; batch adversarial loss: 0.527189\n",
      "epoch 117; iter: 0; batch classifier loss: 0.097257; batch adversarial loss: 0.390611\n",
      "epoch 118; iter: 0; batch classifier loss: 0.093228; batch adversarial loss: 0.508056\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049972; batch adversarial loss: 0.445859\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047620; batch adversarial loss: 0.448343\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053930; batch adversarial loss: 0.440498\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052639; batch adversarial loss: 0.417277\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064884; batch adversarial loss: 0.403172\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050573; batch adversarial loss: 0.485733\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036046; batch adversarial loss: 0.460685\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022347; batch adversarial loss: 0.493346\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051729; batch adversarial loss: 0.393771\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031876; batch adversarial loss: 0.491266\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041651; batch adversarial loss: 0.427943\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046207; batch adversarial loss: 0.331609\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040861; batch adversarial loss: 0.441897\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044680; batch adversarial loss: 0.423682\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033312; batch adversarial loss: 0.444341\n",
      "epoch 134; iter: 0; batch classifier loss: 0.068306; batch adversarial loss: 0.447356\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021414; batch adversarial loss: 0.414939\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041575; batch adversarial loss: 0.383003\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031896; batch adversarial loss: 0.425651\n",
      "epoch 138; iter: 0; batch classifier loss: 0.085920; batch adversarial loss: 0.365677\n",
      "epoch 139; iter: 0; batch classifier loss: 0.057964; batch adversarial loss: 0.537247\n",
      "epoch 140; iter: 0; batch classifier loss: 0.073640; batch adversarial loss: 0.518584\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042961; batch adversarial loss: 0.412700\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021884; batch adversarial loss: 0.412408\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033609; batch adversarial loss: 0.343286\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045904; batch adversarial loss: 0.481030\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027581; batch adversarial loss: 0.559331\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038455; batch adversarial loss: 0.476045\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035290; batch adversarial loss: 0.491291\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029719; batch adversarial loss: 0.336350\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034081; batch adversarial loss: 0.491778\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022315; batch adversarial loss: 0.473567\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011224; batch adversarial loss: 0.421855\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039771; batch adversarial loss: 0.454905\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020338; batch adversarial loss: 0.560880\n",
      "epoch 154; iter: 0; batch classifier loss: 0.047795; batch adversarial loss: 0.345075\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019707; batch adversarial loss: 0.436015\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033100; batch adversarial loss: 0.396313\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042156; batch adversarial loss: 0.493384\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029866; batch adversarial loss: 0.512701\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024796; batch adversarial loss: 0.460477\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013914; batch adversarial loss: 0.447524\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024623; batch adversarial loss: 0.441826\n",
      "epoch 162; iter: 0; batch classifier loss: 0.049818; batch adversarial loss: 0.471305\n",
      "epoch 163; iter: 0; batch classifier loss: 0.044735; batch adversarial loss: 0.384611\n",
      "epoch 164; iter: 0; batch classifier loss: 0.041834; batch adversarial loss: 0.351540\n",
      "epoch 165; iter: 0; batch classifier loss: 0.005667; batch adversarial loss: 0.520898\n",
      "epoch 166; iter: 0; batch classifier loss: 0.041690; batch adversarial loss: 0.450305\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026699; batch adversarial loss: 0.436286\n",
      "epoch 168; iter: 0; batch classifier loss: 0.056784; batch adversarial loss: 0.465114\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031339; batch adversarial loss: 0.480688\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030177; batch adversarial loss: 0.407051\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019351; batch adversarial loss: 0.487431\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009976; batch adversarial loss: 0.505663\n",
      "epoch 173; iter: 0; batch classifier loss: 0.044488; batch adversarial loss: 0.508281\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037657; batch adversarial loss: 0.463186\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025105; batch adversarial loss: 0.485249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.011746; batch adversarial loss: 0.550454\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024684; batch adversarial loss: 0.396087\n",
      "epoch 178; iter: 0; batch classifier loss: 0.069406; batch adversarial loss: 0.445921\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035580; batch adversarial loss: 0.431597\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018120; batch adversarial loss: 0.340235\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022982; batch adversarial loss: 0.408968\n",
      "epoch 182; iter: 0; batch classifier loss: 0.043166; batch adversarial loss: 0.491001\n",
      "epoch 183; iter: 0; batch classifier loss: 0.039449; batch adversarial loss: 0.503362\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027851; batch adversarial loss: 0.458011\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021467; batch adversarial loss: 0.413588\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026525; batch adversarial loss: 0.474113\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019014; batch adversarial loss: 0.391299\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025394; batch adversarial loss: 0.466672\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027342; batch adversarial loss: 0.366410\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035053; batch adversarial loss: 0.387007\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017281; batch adversarial loss: 0.459715\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019857; batch adversarial loss: 0.394507\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035063; batch adversarial loss: 0.390475\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020402; batch adversarial loss: 0.525249\n",
      "epoch 195; iter: 0; batch classifier loss: 0.041753; batch adversarial loss: 0.478582\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033216; batch adversarial loss: 0.517649\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018741; batch adversarial loss: 0.426440\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021053; batch adversarial loss: 0.383814\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019595; batch adversarial loss: 0.430567\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678478; batch adversarial loss: 0.647316\n",
      "epoch 1; iter: 0; batch classifier loss: 0.457725; batch adversarial loss: 0.618180\n",
      "epoch 2; iter: 0; batch classifier loss: 0.492216; batch adversarial loss: 0.578479\n",
      "epoch 3; iter: 0; batch classifier loss: 0.428661; batch adversarial loss: 0.527962\n",
      "epoch 4; iter: 0; batch classifier loss: 0.389902; batch adversarial loss: 0.558897\n",
      "epoch 5; iter: 0; batch classifier loss: 0.498707; batch adversarial loss: 0.546459\n",
      "epoch 6; iter: 0; batch classifier loss: 0.406076; batch adversarial loss: 0.563617\n",
      "epoch 7; iter: 0; batch classifier loss: 0.443151; batch adversarial loss: 0.604405\n",
      "epoch 8; iter: 0; batch classifier loss: 0.368582; batch adversarial loss: 0.573244\n",
      "epoch 9; iter: 0; batch classifier loss: 0.379895; batch adversarial loss: 0.589381\n",
      "epoch 10; iter: 0; batch classifier loss: 0.350182; batch adversarial loss: 0.486226\n",
      "epoch 11; iter: 0; batch classifier loss: 0.359835; batch adversarial loss: 0.492611\n",
      "epoch 12; iter: 0; batch classifier loss: 0.390348; batch adversarial loss: 0.499991\n",
      "epoch 13; iter: 0; batch classifier loss: 0.295593; batch adversarial loss: 0.530330\n",
      "epoch 14; iter: 0; batch classifier loss: 0.273486; batch adversarial loss: 0.472134\n",
      "epoch 15; iter: 0; batch classifier loss: 0.249098; batch adversarial loss: 0.453768\n",
      "epoch 16; iter: 0; batch classifier loss: 0.234561; batch adversarial loss: 0.419552\n",
      "epoch 17; iter: 0; batch classifier loss: 0.250376; batch adversarial loss: 0.483131\n",
      "epoch 18; iter: 0; batch classifier loss: 0.283018; batch adversarial loss: 0.470203\n",
      "epoch 19; iter: 0; batch classifier loss: 0.254648; batch adversarial loss: 0.482785\n",
      "epoch 20; iter: 0; batch classifier loss: 0.246822; batch adversarial loss: 0.429129\n",
      "epoch 21; iter: 0; batch classifier loss: 0.207493; batch adversarial loss: 0.473213\n",
      "epoch 22; iter: 0; batch classifier loss: 0.245607; batch adversarial loss: 0.386912\n",
      "epoch 23; iter: 0; batch classifier loss: 0.283322; batch adversarial loss: 0.425133\n",
      "epoch 24; iter: 0; batch classifier loss: 0.259931; batch adversarial loss: 0.496340\n",
      "epoch 25; iter: 0; batch classifier loss: 0.271873; batch adversarial loss: 0.495652\n",
      "epoch 26; iter: 0; batch classifier loss: 0.256972; batch adversarial loss: 0.377234\n",
      "epoch 27; iter: 0; batch classifier loss: 0.156258; batch adversarial loss: 0.415731\n",
      "epoch 28; iter: 0; batch classifier loss: 0.188025; batch adversarial loss: 0.462821\n",
      "epoch 29; iter: 0; batch classifier loss: 0.129711; batch adversarial loss: 0.484194\n",
      "epoch 30; iter: 0; batch classifier loss: 0.198371; batch adversarial loss: 0.411082\n",
      "epoch 31; iter: 0; batch classifier loss: 0.203899; batch adversarial loss: 0.459986\n",
      "epoch 32; iter: 0; batch classifier loss: 0.162252; batch adversarial loss: 0.430944\n",
      "epoch 33; iter: 0; batch classifier loss: 0.155893; batch adversarial loss: 0.569465\n",
      "epoch 34; iter: 0; batch classifier loss: 0.194211; batch adversarial loss: 0.421283\n",
      "epoch 35; iter: 0; batch classifier loss: 0.200052; batch adversarial loss: 0.504277\n",
      "epoch 36; iter: 0; batch classifier loss: 0.213129; batch adversarial loss: 0.497050\n",
      "epoch 37; iter: 0; batch classifier loss: 0.200382; batch adversarial loss: 0.537827\n",
      "epoch 38; iter: 0; batch classifier loss: 0.188354; batch adversarial loss: 0.395272\n",
      "epoch 39; iter: 0; batch classifier loss: 0.144816; batch adversarial loss: 0.488228\n",
      "epoch 40; iter: 0; batch classifier loss: 0.164833; batch adversarial loss: 0.513881\n",
      "epoch 41; iter: 0; batch classifier loss: 0.252734; batch adversarial loss: 0.505220\n",
      "epoch 42; iter: 0; batch classifier loss: 0.157052; batch adversarial loss: 0.430323\n",
      "epoch 43; iter: 0; batch classifier loss: 0.185745; batch adversarial loss: 0.485583\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123099; batch adversarial loss: 0.526864\n",
      "epoch 45; iter: 0; batch classifier loss: 0.144125; batch adversarial loss: 0.405528\n",
      "epoch 46; iter: 0; batch classifier loss: 0.199778; batch adversarial loss: 0.376933\n",
      "epoch 47; iter: 0; batch classifier loss: 0.174359; batch adversarial loss: 0.476509\n",
      "epoch 48; iter: 0; batch classifier loss: 0.122556; batch adversarial loss: 0.439399\n",
      "epoch 49; iter: 0; batch classifier loss: 0.165856; batch adversarial loss: 0.458657\n",
      "epoch 50; iter: 0; batch classifier loss: 0.165990; batch adversarial loss: 0.437117\n",
      "epoch 51; iter: 0; batch classifier loss: 0.159632; batch adversarial loss: 0.477372\n",
      "epoch 52; iter: 0; batch classifier loss: 0.143582; batch adversarial loss: 0.427728\n",
      "epoch 53; iter: 0; batch classifier loss: 0.200615; batch adversarial loss: 0.339594\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103334; batch adversarial loss: 0.382577\n",
      "epoch 55; iter: 0; batch classifier loss: 0.176446; batch adversarial loss: 0.432932\n",
      "epoch 56; iter: 0; batch classifier loss: 0.129006; batch adversarial loss: 0.490719\n",
      "epoch 57; iter: 0; batch classifier loss: 0.160094; batch adversarial loss: 0.516602\n",
      "epoch 58; iter: 0; batch classifier loss: 0.150502; batch adversarial loss: 0.422949\n",
      "epoch 59; iter: 0; batch classifier loss: 0.133756; batch adversarial loss: 0.435476\n",
      "epoch 60; iter: 0; batch classifier loss: 0.149299; batch adversarial loss: 0.457925\n",
      "epoch 61; iter: 0; batch classifier loss: 0.108488; batch adversarial loss: 0.461368\n",
      "epoch 62; iter: 0; batch classifier loss: 0.151426; batch adversarial loss: 0.488029\n",
      "epoch 63; iter: 0; batch classifier loss: 0.128940; batch adversarial loss: 0.405315\n",
      "epoch 64; iter: 0; batch classifier loss: 0.154696; batch adversarial loss: 0.449589\n",
      "epoch 65; iter: 0; batch classifier loss: 0.138433; batch adversarial loss: 0.435149\n",
      "epoch 66; iter: 0; batch classifier loss: 0.152629; batch adversarial loss: 0.472705\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107862; batch adversarial loss: 0.470760\n",
      "epoch 68; iter: 0; batch classifier loss: 0.143594; batch adversarial loss: 0.397701\n",
      "epoch 69; iter: 0; batch classifier loss: 0.112658; batch adversarial loss: 0.436569\n",
      "epoch 70; iter: 0; batch classifier loss: 0.133295; batch adversarial loss: 0.447028\n",
      "epoch 71; iter: 0; batch classifier loss: 0.178929; batch adversarial loss: 0.456387\n",
      "epoch 72; iter: 0; batch classifier loss: 0.140699; batch adversarial loss: 0.468930\n",
      "epoch 73; iter: 0; batch classifier loss: 0.128823; batch adversarial loss: 0.433851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.154425; batch adversarial loss: 0.489460\n",
      "epoch 75; iter: 0; batch classifier loss: 0.143916; batch adversarial loss: 0.406950\n",
      "epoch 76; iter: 0; batch classifier loss: 0.079137; batch adversarial loss: 0.479138\n",
      "epoch 77; iter: 0; batch classifier loss: 0.129185; batch adversarial loss: 0.471986\n",
      "epoch 78; iter: 0; batch classifier loss: 0.118897; batch adversarial loss: 0.364590\n",
      "epoch 79; iter: 0; batch classifier loss: 0.119084; batch adversarial loss: 0.564489\n",
      "epoch 80; iter: 0; batch classifier loss: 0.167671; batch adversarial loss: 0.409690\n",
      "epoch 81; iter: 0; batch classifier loss: 0.154780; batch adversarial loss: 0.458107\n",
      "epoch 82; iter: 0; batch classifier loss: 0.096356; batch adversarial loss: 0.416618\n",
      "epoch 83; iter: 0; batch classifier loss: 0.095674; batch adversarial loss: 0.447352\n",
      "epoch 84; iter: 0; batch classifier loss: 0.127681; batch adversarial loss: 0.499310\n",
      "epoch 85; iter: 0; batch classifier loss: 0.123796; batch adversarial loss: 0.455498\n",
      "epoch 86; iter: 0; batch classifier loss: 0.110089; batch adversarial loss: 0.481348\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082484; batch adversarial loss: 0.465802\n",
      "epoch 88; iter: 0; batch classifier loss: 0.060461; batch adversarial loss: 0.532047\n",
      "epoch 89; iter: 0; batch classifier loss: 0.099490; batch adversarial loss: 0.406407\n",
      "epoch 90; iter: 0; batch classifier loss: 0.133148; batch adversarial loss: 0.380824\n",
      "epoch 91; iter: 0; batch classifier loss: 0.079103; batch adversarial loss: 0.408866\n",
      "epoch 92; iter: 0; batch classifier loss: 0.085675; batch adversarial loss: 0.467382\n",
      "epoch 93; iter: 0; batch classifier loss: 0.100575; batch adversarial loss: 0.479967\n",
      "epoch 94; iter: 0; batch classifier loss: 0.120943; batch adversarial loss: 0.301060\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079090; batch adversarial loss: 0.366475\n",
      "epoch 96; iter: 0; batch classifier loss: 0.074840; batch adversarial loss: 0.460386\n",
      "epoch 97; iter: 0; batch classifier loss: 0.108409; batch adversarial loss: 0.453896\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051573; batch adversarial loss: 0.404715\n",
      "epoch 99; iter: 0; batch classifier loss: 0.066297; batch adversarial loss: 0.460215\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038291; batch adversarial loss: 0.396927\n",
      "epoch 101; iter: 0; batch classifier loss: 0.104023; batch adversarial loss: 0.493756\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042732; batch adversarial loss: 0.393914\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047759; batch adversarial loss: 0.424243\n",
      "epoch 104; iter: 0; batch classifier loss: 0.082535; batch adversarial loss: 0.423668\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056066; batch adversarial loss: 0.362532\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057247; batch adversarial loss: 0.432634\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031166; batch adversarial loss: 0.452065\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069584; batch adversarial loss: 0.430690\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042832; batch adversarial loss: 0.474626\n",
      "epoch 110; iter: 0; batch classifier loss: 0.034459; batch adversarial loss: 0.387978\n",
      "epoch 111; iter: 0; batch classifier loss: 0.074925; batch adversarial loss: 0.341906\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042051; batch adversarial loss: 0.448893\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042364; batch adversarial loss: 0.442392\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051020; batch adversarial loss: 0.424520\n",
      "epoch 115; iter: 0; batch classifier loss: 0.086659; batch adversarial loss: 0.416739\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028515; batch adversarial loss: 0.392453\n",
      "epoch 117; iter: 0; batch classifier loss: 0.054950; batch adversarial loss: 0.312958\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028197; batch adversarial loss: 0.462903\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073919; batch adversarial loss: 0.395947\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046644; batch adversarial loss: 0.478179\n",
      "epoch 121; iter: 0; batch classifier loss: 0.100730; batch adversarial loss: 0.544145\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031382; batch adversarial loss: 0.357908\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032305; batch adversarial loss: 0.481289\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036779; batch adversarial loss: 0.429885\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058864; batch adversarial loss: 0.418635\n",
      "epoch 126; iter: 0; batch classifier loss: 0.009697; batch adversarial loss: 0.501645\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028202; batch adversarial loss: 0.404956\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041500; batch adversarial loss: 0.586871\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016374; batch adversarial loss: 0.478211\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036434; batch adversarial loss: 0.455181\n",
      "epoch 131; iter: 0; batch classifier loss: 0.058334; batch adversarial loss: 0.506964\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032675; batch adversarial loss: 0.509566\n",
      "epoch 133; iter: 0; batch classifier loss: 0.051225; batch adversarial loss: 0.396123\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026961; batch adversarial loss: 0.352422\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033566; batch adversarial loss: 0.481085\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034240; batch adversarial loss: 0.512686\n",
      "epoch 137; iter: 0; batch classifier loss: 0.021015; batch adversarial loss: 0.513314\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016082; batch adversarial loss: 0.437792\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015411; batch adversarial loss: 0.439106\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031264; batch adversarial loss: 0.405916\n",
      "epoch 141; iter: 0; batch classifier loss: 0.012698; batch adversarial loss: 0.611483\n",
      "epoch 142; iter: 0; batch classifier loss: 0.006577; batch adversarial loss: 0.456287\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024258; batch adversarial loss: 0.520575\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033465; batch adversarial loss: 0.427957\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041686; batch adversarial loss: 0.406745\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044084; batch adversarial loss: 0.470189\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024594; batch adversarial loss: 0.396328\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019060; batch adversarial loss: 0.408158\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027007; batch adversarial loss: 0.373970\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013321; batch adversarial loss: 0.517763\n",
      "epoch 151; iter: 0; batch classifier loss: 0.047383; batch adversarial loss: 0.431542\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010580; batch adversarial loss: 0.478458\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008415; batch adversarial loss: 0.442120\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029098; batch adversarial loss: 0.515570\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011221; batch adversarial loss: 0.347087\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015651; batch adversarial loss: 0.407375\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036930; batch adversarial loss: 0.311809\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024094; batch adversarial loss: 0.441387\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036951; batch adversarial loss: 0.389792\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027588; batch adversarial loss: 0.427947\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014431; batch adversarial loss: 0.469429\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009217; batch adversarial loss: 0.399863\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030544; batch adversarial loss: 0.413607\n",
      "epoch 164; iter: 0; batch classifier loss: 0.008202; batch adversarial loss: 0.409439\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037164; batch adversarial loss: 0.462045\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032317; batch adversarial loss: 0.374860\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022821; batch adversarial loss: 0.391874\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014730; batch adversarial loss: 0.502640\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010633; batch adversarial loss: 0.408015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.026146; batch adversarial loss: 0.440601\n",
      "epoch 171; iter: 0; batch classifier loss: 0.003272; batch adversarial loss: 0.469536\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019694; batch adversarial loss: 0.397227\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009834; batch adversarial loss: 0.463309\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022967; batch adversarial loss: 0.421880\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019270; batch adversarial loss: 0.478639\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017415; batch adversarial loss: 0.479015\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014891; batch adversarial loss: 0.397534\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021646; batch adversarial loss: 0.418741\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039317; batch adversarial loss: 0.442462\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006156; batch adversarial loss: 0.473233\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012512; batch adversarial loss: 0.469213\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012747; batch adversarial loss: 0.429326\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018731; batch adversarial loss: 0.380085\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006848; batch adversarial loss: 0.466601\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012580; batch adversarial loss: 0.492907\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016176; batch adversarial loss: 0.433878\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021733; batch adversarial loss: 0.426276\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010514; batch adversarial loss: 0.554327\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012980; batch adversarial loss: 0.426544\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011000; batch adversarial loss: 0.344445\n",
      "epoch 191; iter: 0; batch classifier loss: 0.069198; batch adversarial loss: 0.416660\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008274; batch adversarial loss: 0.398479\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024427; batch adversarial loss: 0.371200\n",
      "epoch 194; iter: 0; batch classifier loss: 0.059307; batch adversarial loss: 0.454530\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017404; batch adversarial loss: 0.439879\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019380; batch adversarial loss: 0.472220\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020477; batch adversarial loss: 0.402447\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003747; batch adversarial loss: 0.539831\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023597; batch adversarial loss: 0.453001\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708956; batch adversarial loss: 1.022654\n",
      "epoch 1; iter: 0; batch classifier loss: 0.632384; batch adversarial loss: 1.065549\n",
      "epoch 2; iter: 0; batch classifier loss: 0.817722; batch adversarial loss: 1.102853\n",
      "epoch 3; iter: 0; batch classifier loss: 0.975966; batch adversarial loss: 1.051862\n",
      "epoch 4; iter: 0; batch classifier loss: 1.018650; batch adversarial loss: 0.946002\n",
      "epoch 5; iter: 0; batch classifier loss: 1.056173; batch adversarial loss: 0.857300\n",
      "epoch 6; iter: 0; batch classifier loss: 1.030419; batch adversarial loss: 0.786824\n",
      "epoch 7; iter: 0; batch classifier loss: 0.992922; batch adversarial loss: 0.694892\n",
      "epoch 8; iter: 0; batch classifier loss: 0.902013; batch adversarial loss: 0.659317\n",
      "epoch 9; iter: 0; batch classifier loss: 0.883843; batch adversarial loss: 0.603165\n",
      "epoch 10; iter: 0; batch classifier loss: 0.933821; batch adversarial loss: 0.562902\n",
      "epoch 11; iter: 0; batch classifier loss: 0.719825; batch adversarial loss: 0.534310\n",
      "epoch 12; iter: 0; batch classifier loss: 0.677303; batch adversarial loss: 0.559405\n",
      "epoch 13; iter: 0; batch classifier loss: 0.645366; batch adversarial loss: 0.503166\n",
      "epoch 14; iter: 0; batch classifier loss: 0.557964; batch adversarial loss: 0.478567\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487637; batch adversarial loss: 0.475922\n",
      "epoch 16; iter: 0; batch classifier loss: 0.501230; batch adversarial loss: 0.465866\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501349; batch adversarial loss: 0.437190\n",
      "epoch 18; iter: 0; batch classifier loss: 0.358063; batch adversarial loss: 0.433837\n",
      "epoch 19; iter: 0; batch classifier loss: 0.395879; batch adversarial loss: 0.417337\n",
      "epoch 20; iter: 0; batch classifier loss: 0.276785; batch adversarial loss: 0.426905\n",
      "epoch 21; iter: 0; batch classifier loss: 0.284475; batch adversarial loss: 0.437885\n",
      "epoch 22; iter: 0; batch classifier loss: 0.251470; batch adversarial loss: 0.408709\n",
      "epoch 23; iter: 0; batch classifier loss: 0.179442; batch adversarial loss: 0.420369\n",
      "epoch 24; iter: 0; batch classifier loss: 0.228269; batch adversarial loss: 0.449008\n",
      "epoch 25; iter: 0; batch classifier loss: 0.233529; batch adversarial loss: 0.442472\n",
      "epoch 26; iter: 0; batch classifier loss: 0.158980; batch adversarial loss: 0.450816\n",
      "epoch 27; iter: 0; batch classifier loss: 0.195637; batch adversarial loss: 0.423104\n",
      "epoch 28; iter: 0; batch classifier loss: 0.105608; batch adversarial loss: 0.404664\n",
      "epoch 29; iter: 0; batch classifier loss: 0.174537; batch adversarial loss: 0.458231\n",
      "epoch 30; iter: 0; batch classifier loss: 0.126140; batch adversarial loss: 0.406891\n",
      "epoch 31; iter: 0; batch classifier loss: 0.093927; batch adversarial loss: 0.349422\n",
      "epoch 32; iter: 0; batch classifier loss: 0.123179; batch adversarial loss: 0.444252\n",
      "epoch 33; iter: 0; batch classifier loss: 0.113080; batch adversarial loss: 0.446601\n",
      "epoch 34; iter: 0; batch classifier loss: 0.099832; batch adversarial loss: 0.449464\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130346; batch adversarial loss: 0.442486\n",
      "epoch 36; iter: 0; batch classifier loss: 0.078287; batch adversarial loss: 0.469452\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113618; batch adversarial loss: 0.491850\n",
      "epoch 38; iter: 0; batch classifier loss: 0.077205; batch adversarial loss: 0.419000\n",
      "epoch 39; iter: 0; batch classifier loss: 0.095642; batch adversarial loss: 0.453852\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095037; batch adversarial loss: 0.416731\n",
      "epoch 41; iter: 0; batch classifier loss: 0.071552; batch adversarial loss: 0.367797\n",
      "epoch 42; iter: 0; batch classifier loss: 0.070908; batch adversarial loss: 0.440485\n",
      "epoch 43; iter: 0; batch classifier loss: 0.067634; batch adversarial loss: 0.371610\n",
      "epoch 44; iter: 0; batch classifier loss: 0.084000; batch adversarial loss: 0.457848\n",
      "epoch 45; iter: 0; batch classifier loss: 0.140308; batch adversarial loss: 0.504720\n",
      "epoch 46; iter: 0; batch classifier loss: 0.078753; batch adversarial loss: 0.464665\n",
      "epoch 47; iter: 0; batch classifier loss: 0.069339; batch adversarial loss: 0.444286\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081822; batch adversarial loss: 0.446321\n",
      "epoch 49; iter: 0; batch classifier loss: 0.067369; batch adversarial loss: 0.325138\n",
      "epoch 50; iter: 0; batch classifier loss: 0.057813; batch adversarial loss: 0.378609\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083082; batch adversarial loss: 0.442574\n",
      "epoch 52; iter: 0; batch classifier loss: 0.063454; batch adversarial loss: 0.510812\n",
      "epoch 53; iter: 0; batch classifier loss: 0.062095; batch adversarial loss: 0.456815\n",
      "epoch 54; iter: 0; batch classifier loss: 0.094655; batch adversarial loss: 0.398151\n",
      "epoch 55; iter: 0; batch classifier loss: 0.090497; batch adversarial loss: 0.458679\n",
      "epoch 56; iter: 0; batch classifier loss: 0.060942; batch adversarial loss: 0.371392\n",
      "epoch 57; iter: 0; batch classifier loss: 0.070294; batch adversarial loss: 0.409145\n",
      "epoch 58; iter: 0; batch classifier loss: 0.062657; batch adversarial loss: 0.404629\n",
      "epoch 59; iter: 0; batch classifier loss: 0.073783; batch adversarial loss: 0.389586\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072906; batch adversarial loss: 0.407800\n",
      "epoch 61; iter: 0; batch classifier loss: 0.089630; batch adversarial loss: 0.361402\n",
      "epoch 62; iter: 0; batch classifier loss: 0.063056; batch adversarial loss: 0.395285\n",
      "epoch 63; iter: 0; batch classifier loss: 0.050380; batch adversarial loss: 0.592704\n",
      "epoch 64; iter: 0; batch classifier loss: 0.064203; batch adversarial loss: 0.395736\n",
      "epoch 65; iter: 0; batch classifier loss: 0.080830; batch adversarial loss: 0.437343\n",
      "epoch 66; iter: 0; batch classifier loss: 0.030843; batch adversarial loss: 0.400607\n",
      "epoch 67; iter: 0; batch classifier loss: 0.063470; batch adversarial loss: 0.495377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.064282; batch adversarial loss: 0.409689\n",
      "epoch 69; iter: 0; batch classifier loss: 0.080104; batch adversarial loss: 0.468804\n",
      "epoch 70; iter: 0; batch classifier loss: 0.107152; batch adversarial loss: 0.455120\n",
      "epoch 71; iter: 0; batch classifier loss: 0.069103; batch adversarial loss: 0.414523\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082783; batch adversarial loss: 0.481982\n",
      "epoch 73; iter: 0; batch classifier loss: 0.048562; batch adversarial loss: 0.433335\n",
      "epoch 74; iter: 0; batch classifier loss: 0.096160; batch adversarial loss: 0.476334\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063018; batch adversarial loss: 0.441455\n",
      "epoch 76; iter: 0; batch classifier loss: 0.048385; batch adversarial loss: 0.511078\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056380; batch adversarial loss: 0.438883\n",
      "epoch 78; iter: 0; batch classifier loss: 0.040341; batch adversarial loss: 0.454278\n",
      "epoch 79; iter: 0; batch classifier loss: 0.049034; batch adversarial loss: 0.436539\n",
      "epoch 80; iter: 0; batch classifier loss: 0.029205; batch adversarial loss: 0.499596\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066899; batch adversarial loss: 0.386739\n",
      "epoch 82; iter: 0; batch classifier loss: 0.023800; batch adversarial loss: 0.388203\n",
      "epoch 83; iter: 0; batch classifier loss: 0.031122; batch adversarial loss: 0.417468\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070004; batch adversarial loss: 0.463570\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052125; batch adversarial loss: 0.440422\n",
      "epoch 86; iter: 0; batch classifier loss: 0.043738; batch adversarial loss: 0.342302\n",
      "epoch 87; iter: 0; batch classifier loss: 0.031633; batch adversarial loss: 0.401488\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059727; batch adversarial loss: 0.507693\n",
      "epoch 89; iter: 0; batch classifier loss: 0.085232; batch adversarial loss: 0.438460\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054862; batch adversarial loss: 0.446985\n",
      "epoch 91; iter: 0; batch classifier loss: 0.069137; batch adversarial loss: 0.461280\n",
      "epoch 92; iter: 0; batch classifier loss: 0.084304; batch adversarial loss: 0.479340\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052012; batch adversarial loss: 0.462711\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053569; batch adversarial loss: 0.449187\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048456; batch adversarial loss: 0.407495\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036964; batch adversarial loss: 0.469758\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048768; batch adversarial loss: 0.449716\n",
      "epoch 98; iter: 0; batch classifier loss: 0.030713; batch adversarial loss: 0.459748\n",
      "epoch 99; iter: 0; batch classifier loss: 0.048181; batch adversarial loss: 0.465361\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045196; batch adversarial loss: 0.440973\n",
      "epoch 101; iter: 0; batch classifier loss: 0.059658; batch adversarial loss: 0.480062\n",
      "epoch 102; iter: 0; batch classifier loss: 0.024425; batch adversarial loss: 0.389376\n",
      "epoch 103; iter: 0; batch classifier loss: 0.051618; batch adversarial loss: 0.350113\n",
      "epoch 104; iter: 0; batch classifier loss: 0.070779; batch adversarial loss: 0.406217\n",
      "epoch 105; iter: 0; batch classifier loss: 0.031870; batch adversarial loss: 0.522769\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063890; batch adversarial loss: 0.450839\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044646; batch adversarial loss: 0.461527\n",
      "epoch 108; iter: 0; batch classifier loss: 0.034400; batch adversarial loss: 0.418099\n",
      "epoch 109; iter: 0; batch classifier loss: 0.031685; batch adversarial loss: 0.333355\n",
      "epoch 110; iter: 0; batch classifier loss: 0.070004; batch adversarial loss: 0.481567\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053549; batch adversarial loss: 0.478574\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046966; batch adversarial loss: 0.432810\n",
      "epoch 113; iter: 0; batch classifier loss: 0.102938; batch adversarial loss: 0.447511\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029326; batch adversarial loss: 0.408985\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054132; batch adversarial loss: 0.492822\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021834; batch adversarial loss: 0.403865\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028635; batch adversarial loss: 0.418786\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063232; batch adversarial loss: 0.460503\n",
      "epoch 119; iter: 0; batch classifier loss: 0.077927; batch adversarial loss: 0.444135\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035807; batch adversarial loss: 0.467390\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050818; batch adversarial loss: 0.499476\n",
      "epoch 122; iter: 0; batch classifier loss: 0.076229; batch adversarial loss: 0.376878\n",
      "epoch 123; iter: 0; batch classifier loss: 0.060043; batch adversarial loss: 0.432661\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050523; batch adversarial loss: 0.486008\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048259; batch adversarial loss: 0.460669\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047670; batch adversarial loss: 0.494198\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034628; batch adversarial loss: 0.463802\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027235; batch adversarial loss: 0.385038\n",
      "epoch 129; iter: 0; batch classifier loss: 0.061700; batch adversarial loss: 0.474333\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022573; batch adversarial loss: 0.464015\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034734; batch adversarial loss: 0.410996\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027661; batch adversarial loss: 0.453518\n",
      "epoch 133; iter: 0; batch classifier loss: 0.067080; batch adversarial loss: 0.431382\n",
      "epoch 134; iter: 0; batch classifier loss: 0.088928; batch adversarial loss: 0.489668\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035035; batch adversarial loss: 0.453407\n",
      "epoch 136; iter: 0; batch classifier loss: 0.046701; batch adversarial loss: 0.589018\n",
      "epoch 137; iter: 0; batch classifier loss: 0.064517; batch adversarial loss: 0.510282\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035760; batch adversarial loss: 0.396571\n",
      "epoch 139; iter: 0; batch classifier loss: 0.066291; batch adversarial loss: 0.470834\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026947; batch adversarial loss: 0.380512\n",
      "epoch 141; iter: 0; batch classifier loss: 0.041349; batch adversarial loss: 0.420167\n",
      "epoch 142; iter: 0; batch classifier loss: 0.012943; batch adversarial loss: 0.452224\n",
      "epoch 143; iter: 0; batch classifier loss: 0.047993; batch adversarial loss: 0.419019\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025637; batch adversarial loss: 0.422769\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032197; batch adversarial loss: 0.424040\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028306; batch adversarial loss: 0.361951\n",
      "epoch 147; iter: 0; batch classifier loss: 0.047636; batch adversarial loss: 0.441007\n",
      "epoch 148; iter: 0; batch classifier loss: 0.041814; batch adversarial loss: 0.465364\n",
      "epoch 149; iter: 0; batch classifier loss: 0.045853; batch adversarial loss: 0.536157\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031642; batch adversarial loss: 0.480894\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039777; batch adversarial loss: 0.510852\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023190; batch adversarial loss: 0.412526\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029240; batch adversarial loss: 0.451366\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034929; batch adversarial loss: 0.442087\n",
      "epoch 155; iter: 0; batch classifier loss: 0.056066; batch adversarial loss: 0.431794\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041978; batch adversarial loss: 0.532725\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038887; batch adversarial loss: 0.544086\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037231; batch adversarial loss: 0.414201\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025695; batch adversarial loss: 0.371933\n",
      "epoch 160; iter: 0; batch classifier loss: 0.055939; batch adversarial loss: 0.535263\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040789; batch adversarial loss: 0.516164\n",
      "epoch 162; iter: 0; batch classifier loss: 0.049446; batch adversarial loss: 0.475598\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038016; batch adversarial loss: 0.450019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.056874; batch adversarial loss: 0.404229\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029732; batch adversarial loss: 0.395842\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040595; batch adversarial loss: 0.591711\n",
      "epoch 167; iter: 0; batch classifier loss: 0.065432; batch adversarial loss: 0.492864\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022823; batch adversarial loss: 0.342128\n",
      "epoch 169; iter: 0; batch classifier loss: 0.092447; batch adversarial loss: 0.432147\n",
      "epoch 170; iter: 0; batch classifier loss: 0.041016; batch adversarial loss: 0.407202\n",
      "epoch 171; iter: 0; batch classifier loss: 0.044353; batch adversarial loss: 0.415125\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034386; batch adversarial loss: 0.378193\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017851; batch adversarial loss: 0.459765\n",
      "epoch 174; iter: 0; batch classifier loss: 0.058002; batch adversarial loss: 0.363228\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018442; batch adversarial loss: 0.300658\n",
      "epoch 176; iter: 0; batch classifier loss: 0.065837; batch adversarial loss: 0.444269\n",
      "epoch 177; iter: 0; batch classifier loss: 0.039423; batch adversarial loss: 0.473207\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040321; batch adversarial loss: 0.468968\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029338; batch adversarial loss: 0.426584\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049973; batch adversarial loss: 0.405724\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033549; batch adversarial loss: 0.368235\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036161; batch adversarial loss: 0.385563\n",
      "epoch 183; iter: 0; batch classifier loss: 0.035604; batch adversarial loss: 0.467301\n",
      "epoch 184; iter: 0; batch classifier loss: 0.054666; batch adversarial loss: 0.406780\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017965; batch adversarial loss: 0.508914\n",
      "epoch 186; iter: 0; batch classifier loss: 0.068420; batch adversarial loss: 0.444682\n",
      "epoch 187; iter: 0; batch classifier loss: 0.058821; batch adversarial loss: 0.463094\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024240; batch adversarial loss: 0.461163\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036225; batch adversarial loss: 0.415689\n",
      "epoch 190; iter: 0; batch classifier loss: 0.033583; batch adversarial loss: 0.448411\n",
      "epoch 191; iter: 0; batch classifier loss: 0.041904; batch adversarial loss: 0.487111\n",
      "epoch 192; iter: 0; batch classifier loss: 0.053222; batch adversarial loss: 0.481390\n",
      "epoch 193; iter: 0; batch classifier loss: 0.041278; batch adversarial loss: 0.466096\n",
      "epoch 194; iter: 0; batch classifier loss: 0.053263; batch adversarial loss: 0.431122\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011184; batch adversarial loss: 0.336068\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026893; batch adversarial loss: 0.395453\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045123; batch adversarial loss: 0.338641\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010394; batch adversarial loss: 0.432087\n",
      "epoch 199; iter: 0; batch classifier loss: 0.055855; batch adversarial loss: 0.498872\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671667; batch adversarial loss: 0.691163\n",
      "epoch 1; iter: 0; batch classifier loss: 0.440778; batch adversarial loss: 0.668726\n",
      "epoch 2; iter: 0; batch classifier loss: 0.492432; batch adversarial loss: 0.604898\n",
      "epoch 3; iter: 0; batch classifier loss: 0.365455; batch adversarial loss: 0.587588\n",
      "epoch 4; iter: 0; batch classifier loss: 0.331457; batch adversarial loss: 0.546694\n",
      "epoch 5; iter: 0; batch classifier loss: 0.380023; batch adversarial loss: 0.546535\n",
      "epoch 6; iter: 0; batch classifier loss: 0.272149; batch adversarial loss: 0.530270\n",
      "epoch 7; iter: 0; batch classifier loss: 0.249271; batch adversarial loss: 0.527672\n",
      "epoch 8; iter: 0; batch classifier loss: 0.277121; batch adversarial loss: 0.469423\n",
      "epoch 9; iter: 0; batch classifier loss: 0.308575; batch adversarial loss: 0.502668\n",
      "epoch 10; iter: 0; batch classifier loss: 0.231875; batch adversarial loss: 0.492298\n",
      "epoch 11; iter: 0; batch classifier loss: 0.256011; batch adversarial loss: 0.455346\n",
      "epoch 12; iter: 0; batch classifier loss: 0.237359; batch adversarial loss: 0.466456\n",
      "epoch 13; iter: 0; batch classifier loss: 0.235677; batch adversarial loss: 0.447342\n",
      "epoch 14; iter: 0; batch classifier loss: 0.188049; batch adversarial loss: 0.490499\n",
      "epoch 15; iter: 0; batch classifier loss: 0.176199; batch adversarial loss: 0.499580\n",
      "epoch 16; iter: 0; batch classifier loss: 0.211628; batch adversarial loss: 0.468726\n",
      "epoch 17; iter: 0; batch classifier loss: 0.157583; batch adversarial loss: 0.451490\n",
      "epoch 18; iter: 0; batch classifier loss: 0.120536; batch adversarial loss: 0.486189\n",
      "epoch 19; iter: 0; batch classifier loss: 0.169138; batch adversarial loss: 0.418386\n",
      "epoch 20; iter: 0; batch classifier loss: 0.182165; batch adversarial loss: 0.425677\n",
      "epoch 21; iter: 0; batch classifier loss: 0.171008; batch adversarial loss: 0.424454\n",
      "epoch 22; iter: 0; batch classifier loss: 0.159213; batch adversarial loss: 0.415418\n",
      "epoch 23; iter: 0; batch classifier loss: 0.148061; batch adversarial loss: 0.469891\n",
      "epoch 24; iter: 0; batch classifier loss: 0.141935; batch adversarial loss: 0.408952\n",
      "epoch 25; iter: 0; batch classifier loss: 0.147803; batch adversarial loss: 0.525544\n",
      "epoch 26; iter: 0; batch classifier loss: 0.146673; batch adversarial loss: 0.506501\n",
      "epoch 27; iter: 0; batch classifier loss: 0.201717; batch adversarial loss: 0.483617\n",
      "epoch 28; iter: 0; batch classifier loss: 0.189136; batch adversarial loss: 0.459070\n",
      "epoch 29; iter: 0; batch classifier loss: 0.198660; batch adversarial loss: 0.490244\n",
      "epoch 30; iter: 0; batch classifier loss: 0.131927; batch adversarial loss: 0.446234\n",
      "epoch 31; iter: 0; batch classifier loss: 0.176445; batch adversarial loss: 0.445024\n",
      "epoch 32; iter: 0; batch classifier loss: 0.175362; batch adversarial loss: 0.443071\n",
      "epoch 33; iter: 0; batch classifier loss: 0.213201; batch adversarial loss: 0.474356\n",
      "epoch 34; iter: 0; batch classifier loss: 0.160293; batch adversarial loss: 0.439446\n",
      "epoch 35; iter: 0; batch classifier loss: 0.253782; batch adversarial loss: 0.470201\n",
      "epoch 36; iter: 0; batch classifier loss: 0.272720; batch adversarial loss: 0.428892\n",
      "epoch 37; iter: 0; batch classifier loss: 0.329358; batch adversarial loss: 0.495333\n",
      "epoch 38; iter: 0; batch classifier loss: 0.134893; batch adversarial loss: 0.455847\n",
      "epoch 39; iter: 0; batch classifier loss: 0.167189; batch adversarial loss: 0.468600\n",
      "epoch 40; iter: 0; batch classifier loss: 0.134844; batch adversarial loss: 0.413010\n",
      "epoch 41; iter: 0; batch classifier loss: 0.070759; batch adversarial loss: 0.542964\n",
      "epoch 42; iter: 0; batch classifier loss: 0.066030; batch adversarial loss: 0.454927\n",
      "epoch 43; iter: 0; batch classifier loss: 0.132743; batch adversarial loss: 0.414962\n",
      "epoch 44; iter: 0; batch classifier loss: 0.060729; batch adversarial loss: 0.485559\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108679; batch adversarial loss: 0.476226\n",
      "epoch 46; iter: 0; batch classifier loss: 0.103931; batch adversarial loss: 0.491154\n",
      "epoch 47; iter: 0; batch classifier loss: 0.097403; batch adversarial loss: 0.449690\n",
      "epoch 48; iter: 0; batch classifier loss: 0.080597; batch adversarial loss: 0.354036\n",
      "epoch 49; iter: 0; batch classifier loss: 0.088906; batch adversarial loss: 0.497204\n",
      "epoch 50; iter: 0; batch classifier loss: 0.081629; batch adversarial loss: 0.414613\n",
      "epoch 51; iter: 0; batch classifier loss: 0.085200; batch adversarial loss: 0.537406\n",
      "epoch 52; iter: 0; batch classifier loss: 0.064723; batch adversarial loss: 0.431760\n",
      "epoch 53; iter: 0; batch classifier loss: 0.107092; batch adversarial loss: 0.533753\n",
      "epoch 54; iter: 0; batch classifier loss: 0.048764; batch adversarial loss: 0.521769\n",
      "epoch 55; iter: 0; batch classifier loss: 0.105019; batch adversarial loss: 0.472663\n",
      "epoch 56; iter: 0; batch classifier loss: 0.068437; batch adversarial loss: 0.385049\n",
      "epoch 57; iter: 0; batch classifier loss: 0.102688; batch adversarial loss: 0.416404\n",
      "epoch 58; iter: 0; batch classifier loss: 0.112117; batch adversarial loss: 0.465259\n",
      "epoch 59; iter: 0; batch classifier loss: 0.075998; batch adversarial loss: 0.417173\n",
      "epoch 60; iter: 0; batch classifier loss: 0.104427; batch adversarial loss: 0.485695\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088453; batch adversarial loss: 0.501529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.064267; batch adversarial loss: 0.468836\n",
      "epoch 63; iter: 0; batch classifier loss: 0.087273; batch adversarial loss: 0.489802\n",
      "epoch 64; iter: 0; batch classifier loss: 0.111163; batch adversarial loss: 0.552011\n",
      "epoch 65; iter: 0; batch classifier loss: 0.131573; batch adversarial loss: 0.464201\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078370; batch adversarial loss: 0.366236\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110677; batch adversarial loss: 0.437838\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061206; batch adversarial loss: 0.437977\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095369; batch adversarial loss: 0.540673\n",
      "epoch 70; iter: 0; batch classifier loss: 0.125452; batch adversarial loss: 0.466899\n",
      "epoch 71; iter: 0; batch classifier loss: 0.162080; batch adversarial loss: 0.442644\n",
      "epoch 72; iter: 0; batch classifier loss: 0.102587; batch adversarial loss: 0.455846\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069470; batch adversarial loss: 0.463412\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101924; batch adversarial loss: 0.510548\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067247; batch adversarial loss: 0.371497\n",
      "epoch 76; iter: 0; batch classifier loss: 0.115631; batch adversarial loss: 0.391384\n",
      "epoch 77; iter: 0; batch classifier loss: 0.145255; batch adversarial loss: 0.469164\n",
      "epoch 78; iter: 0; batch classifier loss: 0.084499; batch adversarial loss: 0.426324\n",
      "epoch 79; iter: 0; batch classifier loss: 0.095495; batch adversarial loss: 0.403495\n",
      "epoch 80; iter: 0; batch classifier loss: 0.128798; batch adversarial loss: 0.435501\n",
      "epoch 81; iter: 0; batch classifier loss: 0.108945; batch adversarial loss: 0.413022\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071339; batch adversarial loss: 0.429227\n",
      "epoch 83; iter: 0; batch classifier loss: 0.108521; batch adversarial loss: 0.449814\n",
      "epoch 84; iter: 0; batch classifier loss: 0.058852; batch adversarial loss: 0.489736\n",
      "epoch 85; iter: 0; batch classifier loss: 0.114336; batch adversarial loss: 0.531229\n",
      "epoch 86; iter: 0; batch classifier loss: 0.102697; batch adversarial loss: 0.446665\n",
      "epoch 87; iter: 0; batch classifier loss: 0.111436; batch adversarial loss: 0.477250\n",
      "epoch 88; iter: 0; batch classifier loss: 0.079976; batch adversarial loss: 0.497675\n",
      "epoch 89; iter: 0; batch classifier loss: 0.137606; batch adversarial loss: 0.429454\n",
      "epoch 90; iter: 0; batch classifier loss: 0.055255; batch adversarial loss: 0.478322\n",
      "epoch 91; iter: 0; batch classifier loss: 0.085499; batch adversarial loss: 0.499172\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070823; batch adversarial loss: 0.505776\n",
      "epoch 93; iter: 0; batch classifier loss: 0.109412; batch adversarial loss: 0.468154\n",
      "epoch 94; iter: 0; batch classifier loss: 0.096416; batch adversarial loss: 0.438644\n",
      "epoch 95; iter: 0; batch classifier loss: 0.082812; batch adversarial loss: 0.402877\n",
      "epoch 96; iter: 0; batch classifier loss: 0.105410; batch adversarial loss: 0.459249\n",
      "epoch 97; iter: 0; batch classifier loss: 0.124717; batch adversarial loss: 0.412519\n",
      "epoch 98; iter: 0; batch classifier loss: 0.075715; batch adversarial loss: 0.423450\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050556; batch adversarial loss: 0.420548\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061220; batch adversarial loss: 0.468437\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048169; batch adversarial loss: 0.352228\n",
      "epoch 102; iter: 0; batch classifier loss: 0.078428; batch adversarial loss: 0.417292\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056169; batch adversarial loss: 0.423198\n",
      "epoch 104; iter: 0; batch classifier loss: 0.082731; batch adversarial loss: 0.448127\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053622; batch adversarial loss: 0.428692\n",
      "epoch 106; iter: 0; batch classifier loss: 0.101624; batch adversarial loss: 0.493047\n",
      "epoch 107; iter: 0; batch classifier loss: 0.106995; batch adversarial loss: 0.431170\n",
      "epoch 108; iter: 0; batch classifier loss: 0.085259; batch adversarial loss: 0.515111\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051361; batch adversarial loss: 0.401319\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028483; batch adversarial loss: 0.415788\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051775; batch adversarial loss: 0.395240\n",
      "epoch 112; iter: 0; batch classifier loss: 0.072368; batch adversarial loss: 0.480680\n",
      "epoch 113; iter: 0; batch classifier loss: 0.062456; batch adversarial loss: 0.381789\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041938; batch adversarial loss: 0.440587\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070823; batch adversarial loss: 0.438433\n",
      "epoch 116; iter: 0; batch classifier loss: 0.085542; batch adversarial loss: 0.558399\n",
      "epoch 117; iter: 0; batch classifier loss: 0.072207; batch adversarial loss: 0.423881\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039418; batch adversarial loss: 0.429165\n",
      "epoch 119; iter: 0; batch classifier loss: 0.058157; batch adversarial loss: 0.444313\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039100; batch adversarial loss: 0.476845\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036946; batch adversarial loss: 0.457994\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042162; batch adversarial loss: 0.428381\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043059; batch adversarial loss: 0.406783\n",
      "epoch 124; iter: 0; batch classifier loss: 0.083691; batch adversarial loss: 0.552056\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056189; batch adversarial loss: 0.499812\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026554; batch adversarial loss: 0.441384\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036805; batch adversarial loss: 0.485937\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056176; batch adversarial loss: 0.457448\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042461; batch adversarial loss: 0.409458\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021368; batch adversarial loss: 0.485803\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033248; batch adversarial loss: 0.478520\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026644; batch adversarial loss: 0.464704\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032138; batch adversarial loss: 0.334832\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042633; batch adversarial loss: 0.408281\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025643; batch adversarial loss: 0.540036\n",
      "epoch 136; iter: 0; batch classifier loss: 0.053946; batch adversarial loss: 0.389029\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032632; batch adversarial loss: 0.378988\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049702; batch adversarial loss: 0.445505\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015981; batch adversarial loss: 0.321135\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041576; batch adversarial loss: 0.491245\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029658; batch adversarial loss: 0.531030\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043785; batch adversarial loss: 0.417548\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040384; batch adversarial loss: 0.521155\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034426; batch adversarial loss: 0.472853\n",
      "epoch 145; iter: 0; batch classifier loss: 0.063266; batch adversarial loss: 0.451786\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042706; batch adversarial loss: 0.393362\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034672; batch adversarial loss: 0.454121\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042658; batch adversarial loss: 0.467076\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039720; batch adversarial loss: 0.394532\n",
      "epoch 150; iter: 0; batch classifier loss: 0.051293; batch adversarial loss: 0.458241\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042939; batch adversarial loss: 0.408612\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036883; batch adversarial loss: 0.354975\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039857; batch adversarial loss: 0.434579\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046345; batch adversarial loss: 0.403805\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020903; batch adversarial loss: 0.375672\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027503; batch adversarial loss: 0.394749\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039839; batch adversarial loss: 0.376147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.022225; batch adversarial loss: 0.449257\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020156; batch adversarial loss: 0.465148\n",
      "epoch 160; iter: 0; batch classifier loss: 0.038580; batch adversarial loss: 0.370641\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010645; batch adversarial loss: 0.455873\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032189; batch adversarial loss: 0.420770\n",
      "epoch 163; iter: 0; batch classifier loss: 0.031928; batch adversarial loss: 0.432282\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036240; batch adversarial loss: 0.439973\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038115; batch adversarial loss: 0.456321\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024849; batch adversarial loss: 0.460622\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011387; batch adversarial loss: 0.382533\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029389; batch adversarial loss: 0.372163\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028324; batch adversarial loss: 0.469381\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023474; batch adversarial loss: 0.485215\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029108; batch adversarial loss: 0.438995\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027589; batch adversarial loss: 0.378716\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022064; batch adversarial loss: 0.553748\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035656; batch adversarial loss: 0.563999\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027090; batch adversarial loss: 0.478706\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024795; batch adversarial loss: 0.527531\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042807; batch adversarial loss: 0.544429\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026263; batch adversarial loss: 0.590415\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024708; batch adversarial loss: 0.492670\n",
      "epoch 180; iter: 0; batch classifier loss: 0.064922; batch adversarial loss: 0.441409\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035287; batch adversarial loss: 0.379078\n",
      "epoch 182; iter: 0; batch classifier loss: 0.058969; batch adversarial loss: 0.441110\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034710; batch adversarial loss: 0.447646\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007822; batch adversarial loss: 0.468896\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022308; batch adversarial loss: 0.437289\n",
      "epoch 186; iter: 0; batch classifier loss: 0.042828; batch adversarial loss: 0.433690\n",
      "epoch 187; iter: 0; batch classifier loss: 0.055555; batch adversarial loss: 0.478315\n",
      "epoch 188; iter: 0; batch classifier loss: 0.043085; batch adversarial loss: 0.427435\n",
      "epoch 189; iter: 0; batch classifier loss: 0.069141; batch adversarial loss: 0.445605\n",
      "epoch 190; iter: 0; batch classifier loss: 0.057882; batch adversarial loss: 0.416498\n",
      "epoch 191; iter: 0; batch classifier loss: 0.047521; batch adversarial loss: 0.443207\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012778; batch adversarial loss: 0.463159\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017166; batch adversarial loss: 0.415119\n",
      "epoch 194; iter: 0; batch classifier loss: 0.083409; batch adversarial loss: 0.476331\n",
      "epoch 195; iter: 0; batch classifier loss: 0.056975; batch adversarial loss: 0.451795\n",
      "epoch 196; iter: 0; batch classifier loss: 0.060618; batch adversarial loss: 0.467222\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020150; batch adversarial loss: 0.509480\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006567; batch adversarial loss: 0.417570\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022546; batch adversarial loss: 0.410329\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719956; batch adversarial loss: 0.809199\n",
      "epoch 1; iter: 0; batch classifier loss: 0.492646; batch adversarial loss: 0.730642\n",
      "epoch 2; iter: 0; batch classifier loss: 0.740272; batch adversarial loss: 0.728335\n",
      "epoch 3; iter: 0; batch classifier loss: 0.673422; batch adversarial loss: 0.680724\n",
      "epoch 4; iter: 0; batch classifier loss: 0.448634; batch adversarial loss: 0.609513\n",
      "epoch 5; iter: 0; batch classifier loss: 0.418016; batch adversarial loss: 0.573167\n",
      "epoch 6; iter: 0; batch classifier loss: 0.286275; batch adversarial loss: 0.590159\n",
      "epoch 7; iter: 0; batch classifier loss: 0.353675; batch adversarial loss: 0.559648\n",
      "epoch 8; iter: 0; batch classifier loss: 0.373669; batch adversarial loss: 0.534908\n",
      "epoch 9; iter: 0; batch classifier loss: 0.278280; batch adversarial loss: 0.585083\n",
      "epoch 10; iter: 0; batch classifier loss: 0.316422; batch adversarial loss: 0.557039\n",
      "epoch 11; iter: 0; batch classifier loss: 0.319172; batch adversarial loss: 0.520267\n",
      "epoch 12; iter: 0; batch classifier loss: 0.353887; batch adversarial loss: 0.460932\n",
      "epoch 13; iter: 0; batch classifier loss: 0.284732; batch adversarial loss: 0.520142\n",
      "epoch 14; iter: 0; batch classifier loss: 0.304222; batch adversarial loss: 0.475480\n",
      "epoch 15; iter: 0; batch classifier loss: 0.334149; batch adversarial loss: 0.481484\n",
      "epoch 16; iter: 0; batch classifier loss: 0.178975; batch adversarial loss: 0.564289\n",
      "epoch 17; iter: 0; batch classifier loss: 0.288807; batch adversarial loss: 0.500939\n",
      "epoch 18; iter: 0; batch classifier loss: 0.230961; batch adversarial loss: 0.487058\n",
      "epoch 19; iter: 0; batch classifier loss: 0.210871; batch adversarial loss: 0.476915\n",
      "epoch 20; iter: 0; batch classifier loss: 0.211729; batch adversarial loss: 0.450644\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186130; batch adversarial loss: 0.526886\n",
      "epoch 22; iter: 0; batch classifier loss: 0.240877; batch adversarial loss: 0.495017\n",
      "epoch 23; iter: 0; batch classifier loss: 0.209978; batch adversarial loss: 0.443188\n",
      "epoch 24; iter: 0; batch classifier loss: 0.249195; batch adversarial loss: 0.450259\n",
      "epoch 25; iter: 0; batch classifier loss: 0.234734; batch adversarial loss: 0.490078\n",
      "epoch 26; iter: 0; batch classifier loss: 0.169570; batch adversarial loss: 0.419118\n",
      "epoch 27; iter: 0; batch classifier loss: 0.158730; batch adversarial loss: 0.462819\n",
      "epoch 28; iter: 0; batch classifier loss: 0.240656; batch adversarial loss: 0.512033\n",
      "epoch 29; iter: 0; batch classifier loss: 0.163851; batch adversarial loss: 0.464561\n",
      "epoch 30; iter: 0; batch classifier loss: 0.185041; batch adversarial loss: 0.519793\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156558; batch adversarial loss: 0.400963\n",
      "epoch 32; iter: 0; batch classifier loss: 0.201859; batch adversarial loss: 0.464861\n",
      "epoch 33; iter: 0; batch classifier loss: 0.113138; batch adversarial loss: 0.473190\n",
      "epoch 34; iter: 0; batch classifier loss: 0.181473; batch adversarial loss: 0.467492\n",
      "epoch 35; iter: 0; batch classifier loss: 0.143455; batch adversarial loss: 0.485078\n",
      "epoch 36; iter: 0; batch classifier loss: 0.120082; batch adversarial loss: 0.469095\n",
      "epoch 37; iter: 0; batch classifier loss: 0.080751; batch adversarial loss: 0.340219\n",
      "epoch 38; iter: 0; batch classifier loss: 0.112490; batch adversarial loss: 0.371204\n",
      "epoch 39; iter: 0; batch classifier loss: 0.077067; batch adversarial loss: 0.438143\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095401; batch adversarial loss: 0.509310\n",
      "epoch 41; iter: 0; batch classifier loss: 0.080846; batch adversarial loss: 0.517273\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146604; batch adversarial loss: 0.480332\n",
      "epoch 43; iter: 0; batch classifier loss: 0.094984; batch adversarial loss: 0.485691\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119935; batch adversarial loss: 0.459530\n",
      "epoch 45; iter: 0; batch classifier loss: 0.081336; batch adversarial loss: 0.590119\n",
      "epoch 46; iter: 0; batch classifier loss: 0.094696; batch adversarial loss: 0.413621\n",
      "epoch 47; iter: 0; batch classifier loss: 0.079056; batch adversarial loss: 0.452161\n",
      "epoch 48; iter: 0; batch classifier loss: 0.088875; batch adversarial loss: 0.407548\n",
      "epoch 49; iter: 0; batch classifier loss: 0.078121; batch adversarial loss: 0.526131\n",
      "epoch 50; iter: 0; batch classifier loss: 0.077681; batch adversarial loss: 0.539324\n",
      "epoch 51; iter: 0; batch classifier loss: 0.107745; batch adversarial loss: 0.473705\n",
      "epoch 52; iter: 0; batch classifier loss: 0.097797; batch adversarial loss: 0.439815\n",
      "epoch 53; iter: 0; batch classifier loss: 0.066431; batch adversarial loss: 0.416987\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110642; batch adversarial loss: 0.440833\n",
      "epoch 55; iter: 0; batch classifier loss: 0.068829; batch adversarial loss: 0.507974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.071315; batch adversarial loss: 0.446508\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082214; batch adversarial loss: 0.507187\n",
      "epoch 58; iter: 0; batch classifier loss: 0.083844; batch adversarial loss: 0.461232\n",
      "epoch 59; iter: 0; batch classifier loss: 0.094626; batch adversarial loss: 0.384438\n",
      "epoch 60; iter: 0; batch classifier loss: 0.090264; batch adversarial loss: 0.452371\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090674; batch adversarial loss: 0.500247\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089921; batch adversarial loss: 0.492882\n",
      "epoch 63; iter: 0; batch classifier loss: 0.048626; batch adversarial loss: 0.385052\n",
      "epoch 64; iter: 0; batch classifier loss: 0.039290; batch adversarial loss: 0.443237\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065793; batch adversarial loss: 0.433156\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060761; batch adversarial loss: 0.408129\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079279; batch adversarial loss: 0.368199\n",
      "epoch 68; iter: 0; batch classifier loss: 0.068968; batch adversarial loss: 0.489584\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078801; batch adversarial loss: 0.494625\n",
      "epoch 70; iter: 0; batch classifier loss: 0.115988; batch adversarial loss: 0.443658\n",
      "epoch 71; iter: 0; batch classifier loss: 0.052570; batch adversarial loss: 0.428244\n",
      "epoch 72; iter: 0; batch classifier loss: 0.066004; batch adversarial loss: 0.444456\n",
      "epoch 73; iter: 0; batch classifier loss: 0.095870; batch adversarial loss: 0.338444\n",
      "epoch 74; iter: 0; batch classifier loss: 0.041457; batch adversarial loss: 0.625046\n",
      "epoch 75; iter: 0; batch classifier loss: 0.047524; batch adversarial loss: 0.406830\n",
      "epoch 76; iter: 0; batch classifier loss: 0.090412; batch adversarial loss: 0.421489\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076466; batch adversarial loss: 0.480571\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059848; batch adversarial loss: 0.432425\n",
      "epoch 79; iter: 0; batch classifier loss: 0.045167; batch adversarial loss: 0.456516\n",
      "epoch 80; iter: 0; batch classifier loss: 0.059516; batch adversarial loss: 0.419187\n",
      "epoch 81; iter: 0; batch classifier loss: 0.047509; batch adversarial loss: 0.491573\n",
      "epoch 82; iter: 0; batch classifier loss: 0.023034; batch adversarial loss: 0.496484\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054374; batch adversarial loss: 0.380253\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060104; batch adversarial loss: 0.404927\n",
      "epoch 85; iter: 0; batch classifier loss: 0.044490; batch adversarial loss: 0.510518\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046267; batch adversarial loss: 0.310648\n",
      "epoch 87; iter: 0; batch classifier loss: 0.089366; batch adversarial loss: 0.514413\n",
      "epoch 88; iter: 0; batch classifier loss: 0.105729; batch adversarial loss: 0.425123\n",
      "epoch 89; iter: 0; batch classifier loss: 0.071527; batch adversarial loss: 0.459450\n",
      "epoch 90; iter: 0; batch classifier loss: 0.038377; batch adversarial loss: 0.436318\n",
      "epoch 91; iter: 0; batch classifier loss: 0.026319; batch adversarial loss: 0.477345\n",
      "epoch 92; iter: 0; batch classifier loss: 0.026075; batch adversarial loss: 0.475857\n",
      "epoch 93; iter: 0; batch classifier loss: 0.060911; batch adversarial loss: 0.398339\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048677; batch adversarial loss: 0.435442\n",
      "epoch 95; iter: 0; batch classifier loss: 0.046690; batch adversarial loss: 0.375111\n",
      "epoch 96; iter: 0; batch classifier loss: 0.026229; batch adversarial loss: 0.395902\n",
      "epoch 97; iter: 0; batch classifier loss: 0.061373; batch adversarial loss: 0.467915\n",
      "epoch 98; iter: 0; batch classifier loss: 0.041141; batch adversarial loss: 0.398136\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063815; batch adversarial loss: 0.470133\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049676; batch adversarial loss: 0.489620\n",
      "epoch 101; iter: 0; batch classifier loss: 0.016012; batch adversarial loss: 0.466381\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036734; batch adversarial loss: 0.383402\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049792; batch adversarial loss: 0.423973\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063533; batch adversarial loss: 0.473657\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029114; batch adversarial loss: 0.440003\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045885; batch adversarial loss: 0.440555\n",
      "epoch 107; iter: 0; batch classifier loss: 0.026958; batch adversarial loss: 0.379002\n",
      "epoch 108; iter: 0; batch classifier loss: 0.032082; batch adversarial loss: 0.468691\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030267; batch adversarial loss: 0.358578\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039681; batch adversarial loss: 0.432961\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037387; batch adversarial loss: 0.400449\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038902; batch adversarial loss: 0.508241\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025949; batch adversarial loss: 0.419977\n",
      "epoch 114; iter: 0; batch classifier loss: 0.022128; batch adversarial loss: 0.435921\n",
      "epoch 115; iter: 0; batch classifier loss: 0.018940; batch adversarial loss: 0.486183\n",
      "epoch 116; iter: 0; batch classifier loss: 0.031019; batch adversarial loss: 0.397827\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023784; batch adversarial loss: 0.553834\n",
      "epoch 118; iter: 0; batch classifier loss: 0.013865; batch adversarial loss: 0.342019\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055218; batch adversarial loss: 0.499096\n",
      "epoch 120; iter: 0; batch classifier loss: 0.011120; batch adversarial loss: 0.450663\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025693; batch adversarial loss: 0.474943\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043431; batch adversarial loss: 0.394545\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051582; batch adversarial loss: 0.398799\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024116; batch adversarial loss: 0.503136\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041023; batch adversarial loss: 0.397702\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034646; batch adversarial loss: 0.506294\n",
      "epoch 127; iter: 0; batch classifier loss: 0.011078; batch adversarial loss: 0.430416\n",
      "epoch 128; iter: 0; batch classifier loss: 0.016435; batch adversarial loss: 0.414172\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025471; batch adversarial loss: 0.441060\n",
      "epoch 130; iter: 0; batch classifier loss: 0.014142; batch adversarial loss: 0.454555\n",
      "epoch 131; iter: 0; batch classifier loss: 0.010533; batch adversarial loss: 0.353304\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028792; batch adversarial loss: 0.440196\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018726; batch adversarial loss: 0.381386\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062433; batch adversarial loss: 0.371747\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018928; batch adversarial loss: 0.507455\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042984; batch adversarial loss: 0.453778\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030009; batch adversarial loss: 0.421084\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045666; batch adversarial loss: 0.488563\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032796; batch adversarial loss: 0.509483\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047601; batch adversarial loss: 0.511103\n",
      "epoch 141; iter: 0; batch classifier loss: 0.011912; batch adversarial loss: 0.481142\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043394; batch adversarial loss: 0.412985\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028987; batch adversarial loss: 0.521338\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026054; batch adversarial loss: 0.546192\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011342; batch adversarial loss: 0.470733\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032109; batch adversarial loss: 0.465937\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019315; batch adversarial loss: 0.563892\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026458; batch adversarial loss: 0.408799\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034102; batch adversarial loss: 0.382387\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044467; batch adversarial loss: 0.459540\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022465; batch adversarial loss: 0.473711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.013270; batch adversarial loss: 0.437182\n",
      "epoch 153; iter: 0; batch classifier loss: 0.009519; batch adversarial loss: 0.436779\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032178; batch adversarial loss: 0.486576\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013488; batch adversarial loss: 0.470914\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021759; batch adversarial loss: 0.393231\n",
      "epoch 157; iter: 0; batch classifier loss: 0.045517; batch adversarial loss: 0.484814\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015608; batch adversarial loss: 0.412808\n",
      "epoch 159; iter: 0; batch classifier loss: 0.007896; batch adversarial loss: 0.408863\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012533; batch adversarial loss: 0.453788\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015901; batch adversarial loss: 0.431285\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012946; batch adversarial loss: 0.497963\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019510; batch adversarial loss: 0.427397\n",
      "epoch 164; iter: 0; batch classifier loss: 0.044248; batch adversarial loss: 0.423868\n",
      "epoch 165; iter: 0; batch classifier loss: 0.006769; batch adversarial loss: 0.495615\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032961; batch adversarial loss: 0.450896\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035914; batch adversarial loss: 0.482381\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009991; batch adversarial loss: 0.542559\n",
      "epoch 169; iter: 0; batch classifier loss: 0.047304; batch adversarial loss: 0.453093\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027178; batch adversarial loss: 0.491951\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008908; batch adversarial loss: 0.484181\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021544; batch adversarial loss: 0.459691\n",
      "epoch 173; iter: 0; batch classifier loss: 0.067443; batch adversarial loss: 0.480676\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018873; batch adversarial loss: 0.590845\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013293; batch adversarial loss: 0.489844\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015801; batch adversarial loss: 0.454020\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008175; batch adversarial loss: 0.412079\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022478; batch adversarial loss: 0.338061\n",
      "epoch 179; iter: 0; batch classifier loss: 0.002416; batch adversarial loss: 0.542000\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017327; batch adversarial loss: 0.530261\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016868; batch adversarial loss: 0.421320\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016293; batch adversarial loss: 0.510820\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034487; batch adversarial loss: 0.532127\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006351; batch adversarial loss: 0.403935\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029577; batch adversarial loss: 0.488057\n",
      "epoch 186; iter: 0; batch classifier loss: 0.003785; batch adversarial loss: 0.473828\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028222; batch adversarial loss: 0.410608\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025787; batch adversarial loss: 0.489124\n",
      "epoch 189; iter: 0; batch classifier loss: 0.051112; batch adversarial loss: 0.396548\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011582; batch adversarial loss: 0.469791\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019270; batch adversarial loss: 0.492246\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006567; batch adversarial loss: 0.455693\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016755; batch adversarial loss: 0.386379\n",
      "epoch 194; iter: 0; batch classifier loss: 0.046620; batch adversarial loss: 0.445133\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015492; batch adversarial loss: 0.374623\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010437; batch adversarial loss: 0.495716\n",
      "epoch 197; iter: 0; batch classifier loss: 0.037160; batch adversarial loss: 0.480530\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012364; batch adversarial loss: 0.412061\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007718; batch adversarial loss: 0.333719\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719506; batch adversarial loss: 0.925947\n",
      "epoch 1; iter: 0; batch classifier loss: 0.789589; batch adversarial loss: 1.016226\n",
      "epoch 2; iter: 0; batch classifier loss: 0.930197; batch adversarial loss: 0.995341\n",
      "epoch 3; iter: 0; batch classifier loss: 0.930027; batch adversarial loss: 0.875874\n",
      "epoch 4; iter: 0; batch classifier loss: 0.975507; batch adversarial loss: 0.869367\n",
      "epoch 5; iter: 0; batch classifier loss: 0.852204; batch adversarial loss: 0.758704\n",
      "epoch 6; iter: 0; batch classifier loss: 0.770085; batch adversarial loss: 0.677899\n",
      "epoch 7; iter: 0; batch classifier loss: 0.632509; batch adversarial loss: 0.641113\n",
      "epoch 8; iter: 0; batch classifier loss: 0.602734; batch adversarial loss: 0.614043\n",
      "epoch 9; iter: 0; batch classifier loss: 0.514330; batch adversarial loss: 0.588080\n",
      "epoch 10; iter: 0; batch classifier loss: 0.355538; batch adversarial loss: 0.506489\n",
      "epoch 11; iter: 0; batch classifier loss: 0.282482; batch adversarial loss: 0.548311\n",
      "epoch 12; iter: 0; batch classifier loss: 0.306373; batch adversarial loss: 0.575627\n",
      "epoch 13; iter: 0; batch classifier loss: 0.268686; batch adversarial loss: 0.561521\n",
      "epoch 14; iter: 0; batch classifier loss: 0.220628; batch adversarial loss: 0.486274\n",
      "epoch 15; iter: 0; batch classifier loss: 0.219959; batch adversarial loss: 0.537585\n",
      "epoch 16; iter: 0; batch classifier loss: 0.248648; batch adversarial loss: 0.520678\n",
      "epoch 17; iter: 0; batch classifier loss: 0.254738; batch adversarial loss: 0.534701\n",
      "epoch 18; iter: 0; batch classifier loss: 0.257856; batch adversarial loss: 0.560570\n",
      "epoch 19; iter: 0; batch classifier loss: 0.215669; batch adversarial loss: 0.487525\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220358; batch adversarial loss: 0.566524\n",
      "epoch 21; iter: 0; batch classifier loss: 0.162982; batch adversarial loss: 0.443093\n",
      "epoch 22; iter: 0; batch classifier loss: 0.199528; batch adversarial loss: 0.506610\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285180; batch adversarial loss: 0.462151\n",
      "epoch 24; iter: 0; batch classifier loss: 0.246603; batch adversarial loss: 0.485307\n",
      "epoch 25; iter: 0; batch classifier loss: 0.198712; batch adversarial loss: 0.424763\n",
      "epoch 26; iter: 0; batch classifier loss: 0.210771; batch adversarial loss: 0.403032\n",
      "epoch 27; iter: 0; batch classifier loss: 0.215874; batch adversarial loss: 0.465481\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217048; batch adversarial loss: 0.524648\n",
      "epoch 29; iter: 0; batch classifier loss: 0.168634; batch adversarial loss: 0.488447\n",
      "epoch 30; iter: 0; batch classifier loss: 0.209268; batch adversarial loss: 0.395693\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178480; batch adversarial loss: 0.363243\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154268; batch adversarial loss: 0.468746\n",
      "epoch 33; iter: 0; batch classifier loss: 0.171811; batch adversarial loss: 0.393577\n",
      "epoch 34; iter: 0; batch classifier loss: 0.147443; batch adversarial loss: 0.393700\n",
      "epoch 35; iter: 0; batch classifier loss: 0.183956; batch adversarial loss: 0.354678\n",
      "epoch 36; iter: 0; batch classifier loss: 0.100246; batch adversarial loss: 0.423653\n",
      "epoch 37; iter: 0; batch classifier loss: 0.170823; batch adversarial loss: 0.479026\n",
      "epoch 38; iter: 0; batch classifier loss: 0.120817; batch adversarial loss: 0.425820\n",
      "epoch 39; iter: 0; batch classifier loss: 0.187896; batch adversarial loss: 0.450590\n",
      "epoch 40; iter: 0; batch classifier loss: 0.134854; batch adversarial loss: 0.452645\n",
      "epoch 41; iter: 0; batch classifier loss: 0.150258; batch adversarial loss: 0.507787\n",
      "epoch 42; iter: 0; batch classifier loss: 0.101966; batch adversarial loss: 0.355591\n",
      "epoch 43; iter: 0; batch classifier loss: 0.091029; batch adversarial loss: 0.465677\n",
      "epoch 44; iter: 0; batch classifier loss: 0.169688; batch adversarial loss: 0.410345\n",
      "epoch 45; iter: 0; batch classifier loss: 0.147416; batch adversarial loss: 0.424635\n",
      "epoch 46; iter: 0; batch classifier loss: 0.167952; batch adversarial loss: 0.382373\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119857; batch adversarial loss: 0.412318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.134400; batch adversarial loss: 0.475486\n",
      "epoch 49; iter: 0; batch classifier loss: 0.132105; batch adversarial loss: 0.486574\n",
      "epoch 50; iter: 0; batch classifier loss: 0.128569; batch adversarial loss: 0.470447\n",
      "epoch 51; iter: 0; batch classifier loss: 0.080795; batch adversarial loss: 0.442393\n",
      "epoch 52; iter: 0; batch classifier loss: 0.129400; batch adversarial loss: 0.357126\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122631; batch adversarial loss: 0.415968\n",
      "epoch 54; iter: 0; batch classifier loss: 0.136661; batch adversarial loss: 0.377356\n",
      "epoch 55; iter: 0; batch classifier loss: 0.103636; batch adversarial loss: 0.448531\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098295; batch adversarial loss: 0.496826\n",
      "epoch 57; iter: 0; batch classifier loss: 0.076285; batch adversarial loss: 0.451228\n",
      "epoch 58; iter: 0; batch classifier loss: 0.095776; batch adversarial loss: 0.368282\n",
      "epoch 59; iter: 0; batch classifier loss: 0.116097; batch adversarial loss: 0.459261\n",
      "epoch 60; iter: 0; batch classifier loss: 0.101716; batch adversarial loss: 0.333543\n",
      "epoch 61; iter: 0; batch classifier loss: 0.106628; batch adversarial loss: 0.390340\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094768; batch adversarial loss: 0.432752\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095505; batch adversarial loss: 0.337646\n",
      "epoch 64; iter: 0; batch classifier loss: 0.055720; batch adversarial loss: 0.478644\n",
      "epoch 65; iter: 0; batch classifier loss: 0.134296; batch adversarial loss: 0.514479\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066171; batch adversarial loss: 0.357558\n",
      "epoch 67; iter: 0; batch classifier loss: 0.065367; batch adversarial loss: 0.456928\n",
      "epoch 68; iter: 0; batch classifier loss: 0.055171; batch adversarial loss: 0.491632\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103103; batch adversarial loss: 0.425518\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066388; batch adversarial loss: 0.484927\n",
      "epoch 71; iter: 0; batch classifier loss: 0.068319; batch adversarial loss: 0.454293\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074698; batch adversarial loss: 0.455787\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084891; batch adversarial loss: 0.381862\n",
      "epoch 74; iter: 0; batch classifier loss: 0.073333; batch adversarial loss: 0.407332\n",
      "epoch 75; iter: 0; batch classifier loss: 0.055893; batch adversarial loss: 0.432530\n",
      "epoch 76; iter: 0; batch classifier loss: 0.059889; batch adversarial loss: 0.417909\n",
      "epoch 77; iter: 0; batch classifier loss: 0.123555; batch adversarial loss: 0.435131\n",
      "epoch 78; iter: 0; batch classifier loss: 0.038404; batch adversarial loss: 0.425449\n",
      "epoch 79; iter: 0; batch classifier loss: 0.062659; batch adversarial loss: 0.530516\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075572; batch adversarial loss: 0.358430\n",
      "epoch 81; iter: 0; batch classifier loss: 0.045726; batch adversarial loss: 0.503514\n",
      "epoch 82; iter: 0; batch classifier loss: 0.061658; batch adversarial loss: 0.470954\n",
      "epoch 83; iter: 0; batch classifier loss: 0.124483; batch adversarial loss: 0.556743\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082009; batch adversarial loss: 0.423928\n",
      "epoch 85; iter: 0; batch classifier loss: 0.145619; batch adversarial loss: 0.449449\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067890; batch adversarial loss: 0.443363\n",
      "epoch 87; iter: 0; batch classifier loss: 0.112092; batch adversarial loss: 0.499202\n",
      "epoch 88; iter: 0; batch classifier loss: 0.052341; batch adversarial loss: 0.413084\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052132; batch adversarial loss: 0.440971\n",
      "epoch 90; iter: 0; batch classifier loss: 0.088810; batch adversarial loss: 0.430438\n",
      "epoch 91; iter: 0; batch classifier loss: 0.038906; batch adversarial loss: 0.417673\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048852; batch adversarial loss: 0.501861\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048351; batch adversarial loss: 0.449653\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075121; batch adversarial loss: 0.426666\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038935; batch adversarial loss: 0.442585\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049596; batch adversarial loss: 0.683245\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039871; batch adversarial loss: 0.530856\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056529; batch adversarial loss: 0.386388\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058058; batch adversarial loss: 0.475165\n",
      "epoch 100; iter: 0; batch classifier loss: 0.040764; batch adversarial loss: 0.413728\n",
      "epoch 101; iter: 0; batch classifier loss: 0.032882; batch adversarial loss: 0.505946\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055118; batch adversarial loss: 0.528259\n",
      "epoch 103; iter: 0; batch classifier loss: 0.083866; batch adversarial loss: 0.454750\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041361; batch adversarial loss: 0.472497\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054074; batch adversarial loss: 0.475021\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043153; batch adversarial loss: 0.462694\n",
      "epoch 107; iter: 0; batch classifier loss: 0.025636; batch adversarial loss: 0.533936\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041846; batch adversarial loss: 0.452119\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037128; batch adversarial loss: 0.428509\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028633; batch adversarial loss: 0.320522\n",
      "epoch 111; iter: 0; batch classifier loss: 0.038373; batch adversarial loss: 0.477264\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035283; batch adversarial loss: 0.528562\n",
      "epoch 113; iter: 0; batch classifier loss: 0.030632; batch adversarial loss: 0.389146\n",
      "epoch 114; iter: 0; batch classifier loss: 0.023665; batch adversarial loss: 0.538318\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059618; batch adversarial loss: 0.436863\n",
      "epoch 116; iter: 0; batch classifier loss: 0.076698; batch adversarial loss: 0.449755\n",
      "epoch 117; iter: 0; batch classifier loss: 0.057767; batch adversarial loss: 0.445105\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059808; batch adversarial loss: 0.435343\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036135; batch adversarial loss: 0.430811\n",
      "epoch 120; iter: 0; batch classifier loss: 0.071955; batch adversarial loss: 0.528780\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031909; batch adversarial loss: 0.449996\n",
      "epoch 122; iter: 0; batch classifier loss: 0.069554; batch adversarial loss: 0.431330\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035699; batch adversarial loss: 0.462761\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046433; batch adversarial loss: 0.375071\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037427; batch adversarial loss: 0.338677\n",
      "epoch 126; iter: 0; batch classifier loss: 0.070127; batch adversarial loss: 0.382391\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043575; batch adversarial loss: 0.432906\n",
      "epoch 128; iter: 0; batch classifier loss: 0.014816; batch adversarial loss: 0.458256\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036587; batch adversarial loss: 0.444149\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027130; batch adversarial loss: 0.397555\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031580; batch adversarial loss: 0.349641\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022122; batch adversarial loss: 0.399558\n",
      "epoch 133; iter: 0; batch classifier loss: 0.055917; batch adversarial loss: 0.373973\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037324; batch adversarial loss: 0.408274\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043207; batch adversarial loss: 0.474743\n",
      "epoch 136; iter: 0; batch classifier loss: 0.080895; batch adversarial loss: 0.507140\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048341; batch adversarial loss: 0.431606\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018726; batch adversarial loss: 0.508413\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049842; batch adversarial loss: 0.513424\n",
      "epoch 140; iter: 0; batch classifier loss: 0.071614; batch adversarial loss: 0.381571\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049606; batch adversarial loss: 0.508937\n",
      "epoch 142; iter: 0; batch classifier loss: 0.060620; batch adversarial loss: 0.405926\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036693; batch adversarial loss: 0.535722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.015226; batch adversarial loss: 0.356833\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043012; batch adversarial loss: 0.427987\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028930; batch adversarial loss: 0.393740\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029934; batch adversarial loss: 0.328536\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030807; batch adversarial loss: 0.429267\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022941; batch adversarial loss: 0.545673\n",
      "epoch 150; iter: 0; batch classifier loss: 0.047356; batch adversarial loss: 0.438037\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021511; batch adversarial loss: 0.466753\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027260; batch adversarial loss: 0.491684\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018320; batch adversarial loss: 0.402860\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044788; batch adversarial loss: 0.474207\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018889; batch adversarial loss: 0.520327\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032367; batch adversarial loss: 0.462151\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039085; batch adversarial loss: 0.486532\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018310; batch adversarial loss: 0.346870\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025242; batch adversarial loss: 0.488341\n",
      "epoch 160; iter: 0; batch classifier loss: 0.058836; batch adversarial loss: 0.511901\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017015; batch adversarial loss: 0.431415\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021731; batch adversarial loss: 0.467695\n",
      "epoch 163; iter: 0; batch classifier loss: 0.051022; batch adversarial loss: 0.367501\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025696; batch adversarial loss: 0.467019\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033771; batch adversarial loss: 0.448066\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034312; batch adversarial loss: 0.536651\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035471; batch adversarial loss: 0.389867\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026794; batch adversarial loss: 0.374076\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015769; batch adversarial loss: 0.478903\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020567; batch adversarial loss: 0.471524\n",
      "epoch 171; iter: 0; batch classifier loss: 0.042577; batch adversarial loss: 0.484794\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020825; batch adversarial loss: 0.433167\n",
      "epoch 173; iter: 0; batch classifier loss: 0.046172; batch adversarial loss: 0.517170\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020770; batch adversarial loss: 0.458950\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020573; batch adversarial loss: 0.467258\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015166; batch adversarial loss: 0.353906\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030215; batch adversarial loss: 0.373685\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038103; batch adversarial loss: 0.373502\n",
      "epoch 179; iter: 0; batch classifier loss: 0.050472; batch adversarial loss: 0.424854\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023144; batch adversarial loss: 0.546046\n",
      "epoch 181; iter: 0; batch classifier loss: 0.042080; batch adversarial loss: 0.540470\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021445; batch adversarial loss: 0.465452\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042420; batch adversarial loss: 0.339191\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024142; batch adversarial loss: 0.475684\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031907; batch adversarial loss: 0.423723\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024726; batch adversarial loss: 0.356657\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020185; batch adversarial loss: 0.402893\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018331; batch adversarial loss: 0.430672\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014112; batch adversarial loss: 0.379612\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036918; batch adversarial loss: 0.504733\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023260; batch adversarial loss: 0.497559\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013016; batch adversarial loss: 0.332971\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004065; batch adversarial loss: 0.474870\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020356; batch adversarial loss: 0.530508\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004379; batch adversarial loss: 0.452471\n",
      "epoch 196; iter: 0; batch classifier loss: 0.043194; batch adversarial loss: 0.460415\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034449; batch adversarial loss: 0.355608\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021772; batch adversarial loss: 0.476407\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016145; batch adversarial loss: 0.478024\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680332; batch adversarial loss: 0.685084\n",
      "epoch 1; iter: 0; batch classifier loss: 0.543237; batch adversarial loss: 0.637865\n",
      "epoch 2; iter: 0; batch classifier loss: 0.424879; batch adversarial loss: 0.595660\n",
      "epoch 3; iter: 0; batch classifier loss: 0.410261; batch adversarial loss: 0.597064\n",
      "epoch 4; iter: 0; batch classifier loss: 0.349914; batch adversarial loss: 0.592087\n",
      "epoch 5; iter: 0; batch classifier loss: 0.440418; batch adversarial loss: 0.589730\n",
      "epoch 6; iter: 0; batch classifier loss: 0.408250; batch adversarial loss: 0.556059\n",
      "epoch 7; iter: 0; batch classifier loss: 0.404822; batch adversarial loss: 0.523552\n",
      "epoch 8; iter: 0; batch classifier loss: 0.366403; batch adversarial loss: 0.551471\n",
      "epoch 9; iter: 0; batch classifier loss: 0.331924; batch adversarial loss: 0.552400\n",
      "epoch 10; iter: 0; batch classifier loss: 0.329994; batch adversarial loss: 0.542754\n",
      "epoch 11; iter: 0; batch classifier loss: 0.306995; batch adversarial loss: 0.583208\n",
      "epoch 12; iter: 0; batch classifier loss: 0.319365; batch adversarial loss: 0.483673\n",
      "epoch 13; iter: 0; batch classifier loss: 0.298822; batch adversarial loss: 0.499584\n",
      "epoch 14; iter: 0; batch classifier loss: 0.326470; batch adversarial loss: 0.531802\n",
      "epoch 15; iter: 0; batch classifier loss: 0.345907; batch adversarial loss: 0.509190\n",
      "epoch 16; iter: 0; batch classifier loss: 0.246908; batch adversarial loss: 0.427517\n",
      "epoch 17; iter: 0; batch classifier loss: 0.311897; batch adversarial loss: 0.484096\n",
      "epoch 18; iter: 0; batch classifier loss: 0.219547; batch adversarial loss: 0.496335\n",
      "epoch 19; iter: 0; batch classifier loss: 0.315152; batch adversarial loss: 0.548124\n",
      "epoch 20; iter: 0; batch classifier loss: 0.333963; batch adversarial loss: 0.439858\n",
      "epoch 21; iter: 0; batch classifier loss: 0.290886; batch adversarial loss: 0.478818\n",
      "epoch 22; iter: 0; batch classifier loss: 0.359211; batch adversarial loss: 0.518755\n",
      "epoch 23; iter: 0; batch classifier loss: 0.304293; batch adversarial loss: 0.451609\n",
      "epoch 24; iter: 0; batch classifier loss: 0.231831; batch adversarial loss: 0.521890\n",
      "epoch 25; iter: 0; batch classifier loss: 0.278408; batch adversarial loss: 0.439557\n",
      "epoch 26; iter: 0; batch classifier loss: 0.277263; batch adversarial loss: 0.507467\n",
      "epoch 27; iter: 0; batch classifier loss: 0.266546; batch adversarial loss: 0.493028\n",
      "epoch 28; iter: 0; batch classifier loss: 0.223123; batch adversarial loss: 0.460579\n",
      "epoch 29; iter: 0; batch classifier loss: 0.223885; batch adversarial loss: 0.466669\n",
      "epoch 30; iter: 0; batch classifier loss: 0.275253; batch adversarial loss: 0.434567\n",
      "epoch 31; iter: 0; batch classifier loss: 0.285470; batch adversarial loss: 0.430827\n",
      "epoch 32; iter: 0; batch classifier loss: 0.247639; batch adversarial loss: 0.489886\n",
      "epoch 33; iter: 0; batch classifier loss: 0.195541; batch adversarial loss: 0.550810\n",
      "epoch 34; iter: 0; batch classifier loss: 0.213693; batch adversarial loss: 0.575020\n",
      "epoch 35; iter: 0; batch classifier loss: 0.260163; batch adversarial loss: 0.535970\n",
      "epoch 36; iter: 0; batch classifier loss: 0.247291; batch adversarial loss: 0.443004\n",
      "epoch 37; iter: 0; batch classifier loss: 0.251658; batch adversarial loss: 0.450159\n",
      "epoch 38; iter: 0; batch classifier loss: 0.249424; batch adversarial loss: 0.465838\n",
      "epoch 39; iter: 0; batch classifier loss: 0.225342; batch adversarial loss: 0.450065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.178846; batch adversarial loss: 0.508859\n",
      "epoch 41; iter: 0; batch classifier loss: 0.230530; batch adversarial loss: 0.436658\n",
      "epoch 42; iter: 0; batch classifier loss: 0.291001; batch adversarial loss: 0.404011\n",
      "epoch 43; iter: 0; batch classifier loss: 0.239209; batch adversarial loss: 0.517687\n",
      "epoch 44; iter: 0; batch classifier loss: 0.252485; batch adversarial loss: 0.436832\n",
      "epoch 45; iter: 0; batch classifier loss: 0.272999; batch adversarial loss: 0.376873\n",
      "epoch 46; iter: 0; batch classifier loss: 0.176844; batch adversarial loss: 0.470673\n",
      "epoch 47; iter: 0; batch classifier loss: 0.153612; batch adversarial loss: 0.507607\n",
      "epoch 48; iter: 0; batch classifier loss: 0.259221; batch adversarial loss: 0.485166\n",
      "epoch 49; iter: 0; batch classifier loss: 0.122132; batch adversarial loss: 0.543782\n",
      "epoch 50; iter: 0; batch classifier loss: 0.213989; batch adversarial loss: 0.400204\n",
      "epoch 51; iter: 0; batch classifier loss: 0.224551; batch adversarial loss: 0.495770\n",
      "epoch 52; iter: 0; batch classifier loss: 0.206753; batch adversarial loss: 0.385457\n",
      "epoch 53; iter: 0; batch classifier loss: 0.191066; batch adversarial loss: 0.434039\n",
      "epoch 54; iter: 0; batch classifier loss: 0.249858; batch adversarial loss: 0.410159\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125333; batch adversarial loss: 0.605595\n",
      "epoch 56; iter: 0; batch classifier loss: 0.114452; batch adversarial loss: 0.446707\n",
      "epoch 57; iter: 0; batch classifier loss: 0.182892; batch adversarial loss: 0.398828\n",
      "epoch 58; iter: 0; batch classifier loss: 0.137392; batch adversarial loss: 0.421866\n",
      "epoch 59; iter: 0; batch classifier loss: 0.108669; batch adversarial loss: 0.458837\n",
      "epoch 60; iter: 0; batch classifier loss: 0.223825; batch adversarial loss: 0.446412\n",
      "epoch 61; iter: 0; batch classifier loss: 0.216820; batch adversarial loss: 0.434139\n",
      "epoch 62; iter: 0; batch classifier loss: 0.102153; batch adversarial loss: 0.433162\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095408; batch adversarial loss: 0.446219\n",
      "epoch 64; iter: 0; batch classifier loss: 0.099529; batch adversarial loss: 0.435015\n",
      "epoch 65; iter: 0; batch classifier loss: 0.203989; batch adversarial loss: 0.471057\n",
      "epoch 66; iter: 0; batch classifier loss: 0.178054; batch adversarial loss: 0.434572\n",
      "epoch 67; iter: 0; batch classifier loss: 0.155995; batch adversarial loss: 0.396377\n",
      "epoch 68; iter: 0; batch classifier loss: 0.142510; batch adversarial loss: 0.521185\n",
      "epoch 69; iter: 0; batch classifier loss: 0.221404; batch adversarial loss: 0.497278\n",
      "epoch 70; iter: 0; batch classifier loss: 0.202526; batch adversarial loss: 0.470685\n",
      "epoch 71; iter: 0; batch classifier loss: 0.154433; batch adversarial loss: 0.448445\n",
      "epoch 72; iter: 0; batch classifier loss: 0.179079; batch adversarial loss: 0.385533\n",
      "epoch 73; iter: 0; batch classifier loss: 0.147466; batch adversarial loss: 0.530661\n",
      "epoch 74; iter: 0; batch classifier loss: 0.234754; batch adversarial loss: 0.520067\n",
      "epoch 75; iter: 0; batch classifier loss: 0.170401; batch adversarial loss: 0.422486\n",
      "epoch 76; iter: 0; batch classifier loss: 0.142981; batch adversarial loss: 0.422319\n",
      "epoch 77; iter: 0; batch classifier loss: 0.118247; batch adversarial loss: 0.495550\n",
      "epoch 78; iter: 0; batch classifier loss: 0.252620; batch adversarial loss: 0.447198\n",
      "epoch 79; iter: 0; batch classifier loss: 0.086327; batch adversarial loss: 0.446030\n",
      "epoch 80; iter: 0; batch classifier loss: 0.071606; batch adversarial loss: 0.557072\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064259; batch adversarial loss: 0.356283\n",
      "epoch 82; iter: 0; batch classifier loss: 0.047788; batch adversarial loss: 0.452497\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054864; batch adversarial loss: 0.376507\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051346; batch adversarial loss: 0.489820\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046072; batch adversarial loss: 0.449490\n",
      "epoch 86; iter: 0; batch classifier loss: 0.038025; batch adversarial loss: 0.405920\n",
      "epoch 87; iter: 0; batch classifier loss: 0.074349; batch adversarial loss: 0.577474\n",
      "epoch 88; iter: 0; batch classifier loss: 0.038747; batch adversarial loss: 0.504354\n",
      "epoch 89; iter: 0; batch classifier loss: 0.093800; batch adversarial loss: 0.506111\n",
      "epoch 90; iter: 0; batch classifier loss: 0.055658; batch adversarial loss: 0.474314\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066440; batch adversarial loss: 0.524331\n",
      "epoch 92; iter: 0; batch classifier loss: 0.045191; batch adversarial loss: 0.401444\n",
      "epoch 93; iter: 0; batch classifier loss: 0.030565; batch adversarial loss: 0.431021\n",
      "epoch 94; iter: 0; batch classifier loss: 0.057617; batch adversarial loss: 0.365677\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048790; batch adversarial loss: 0.424480\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035845; batch adversarial loss: 0.450458\n",
      "epoch 97; iter: 0; batch classifier loss: 0.045320; batch adversarial loss: 0.522402\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055591; batch adversarial loss: 0.389626\n",
      "epoch 99; iter: 0; batch classifier loss: 0.024765; batch adversarial loss: 0.508656\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067715; batch adversarial loss: 0.435506\n",
      "epoch 101; iter: 0; batch classifier loss: 0.047027; batch adversarial loss: 0.468213\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044328; batch adversarial loss: 0.448967\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053204; batch adversarial loss: 0.423089\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043538; batch adversarial loss: 0.344255\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062404; batch adversarial loss: 0.412461\n",
      "epoch 106; iter: 0; batch classifier loss: 0.038969; batch adversarial loss: 0.497379\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031654; batch adversarial loss: 0.379934\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051886; batch adversarial loss: 0.443568\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053766; batch adversarial loss: 0.454529\n",
      "epoch 110; iter: 0; batch classifier loss: 0.021992; batch adversarial loss: 0.455919\n",
      "epoch 111; iter: 0; batch classifier loss: 0.016271; batch adversarial loss: 0.466919\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030515; batch adversarial loss: 0.454754\n",
      "epoch 113; iter: 0; batch classifier loss: 0.050653; batch adversarial loss: 0.487181\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062986; batch adversarial loss: 0.450954\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027472; batch adversarial loss: 0.442312\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039493; batch adversarial loss: 0.394028\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043125; batch adversarial loss: 0.472378\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035099; batch adversarial loss: 0.441561\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047715; batch adversarial loss: 0.552540\n",
      "epoch 120; iter: 0; batch classifier loss: 0.017560; batch adversarial loss: 0.454388\n",
      "epoch 121; iter: 0; batch classifier loss: 0.019845; batch adversarial loss: 0.493955\n",
      "epoch 122; iter: 0; batch classifier loss: 0.022828; batch adversarial loss: 0.415914\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043521; batch adversarial loss: 0.460519\n",
      "epoch 124; iter: 0; batch classifier loss: 0.071332; batch adversarial loss: 0.483400\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041838; batch adversarial loss: 0.312854\n",
      "epoch 126; iter: 0; batch classifier loss: 0.009709; batch adversarial loss: 0.471996\n",
      "epoch 127; iter: 0; batch classifier loss: 0.018046; batch adversarial loss: 0.488330\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028807; batch adversarial loss: 0.430736\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029363; batch adversarial loss: 0.455772\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051746; batch adversarial loss: 0.520186\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042353; batch adversarial loss: 0.468469\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015570; batch adversarial loss: 0.429804\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049110; batch adversarial loss: 0.505189\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019284; batch adversarial loss: 0.399326\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018636; batch adversarial loss: 0.487305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.025098; batch adversarial loss: 0.431178\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025486; batch adversarial loss: 0.376592\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014588; batch adversarial loss: 0.437359\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016662; batch adversarial loss: 0.370992\n",
      "epoch 140; iter: 0; batch classifier loss: 0.057910; batch adversarial loss: 0.425950\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022556; batch adversarial loss: 0.410758\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027843; batch adversarial loss: 0.365740\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035149; batch adversarial loss: 0.476356\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025769; batch adversarial loss: 0.546763\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012731; batch adversarial loss: 0.435376\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017241; batch adversarial loss: 0.411162\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023584; batch adversarial loss: 0.408973\n",
      "epoch 148; iter: 0; batch classifier loss: 0.062687; batch adversarial loss: 0.447612\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037830; batch adversarial loss: 0.485141\n",
      "epoch 150; iter: 0; batch classifier loss: 0.047921; batch adversarial loss: 0.436328\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015101; batch adversarial loss: 0.440658\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027883; batch adversarial loss: 0.434734\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018847; batch adversarial loss: 0.393689\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032523; batch adversarial loss: 0.465051\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027959; batch adversarial loss: 0.409726\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017651; batch adversarial loss: 0.457807\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037461; batch adversarial loss: 0.386857\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008610; batch adversarial loss: 0.510534\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021424; batch adversarial loss: 0.390690\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021537; batch adversarial loss: 0.489622\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008869; batch adversarial loss: 0.440627\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037632; batch adversarial loss: 0.506653\n",
      "epoch 163; iter: 0; batch classifier loss: 0.008916; batch adversarial loss: 0.481641\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023411; batch adversarial loss: 0.469282\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015037; batch adversarial loss: 0.445766\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026822; batch adversarial loss: 0.395219\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022944; batch adversarial loss: 0.468048\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015189; batch adversarial loss: 0.410790\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013898; batch adversarial loss: 0.443605\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011103; batch adversarial loss: 0.389881\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028802; batch adversarial loss: 0.470599\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018595; batch adversarial loss: 0.474744\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011471; batch adversarial loss: 0.493425\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017213; batch adversarial loss: 0.345708\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009168; batch adversarial loss: 0.403936\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018720; batch adversarial loss: 0.411219\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022568; batch adversarial loss: 0.605272\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009032; batch adversarial loss: 0.359236\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018964; batch adversarial loss: 0.425138\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006966; batch adversarial loss: 0.426673\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007010; batch adversarial loss: 0.445267\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011853; batch adversarial loss: 0.406967\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022835; batch adversarial loss: 0.418888\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003091; batch adversarial loss: 0.465107\n",
      "epoch 185; iter: 0; batch classifier loss: 0.039355; batch adversarial loss: 0.490419\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006660; batch adversarial loss: 0.432612\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022659; batch adversarial loss: 0.415645\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017761; batch adversarial loss: 0.441290\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007059; batch adversarial loss: 0.451596\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007212; batch adversarial loss: 0.394425\n",
      "epoch 191; iter: 0; batch classifier loss: 0.042352; batch adversarial loss: 0.518044\n",
      "epoch 192; iter: 0; batch classifier loss: 0.061264; batch adversarial loss: 0.416358\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009859; batch adversarial loss: 0.390207\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005635; batch adversarial loss: 0.453134\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020114; batch adversarial loss: 0.365300\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007470; batch adversarial loss: 0.431255\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010477; batch adversarial loss: 0.436252\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004771; batch adversarial loss: 0.445171\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021019; batch adversarial loss: 0.468629\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708673; batch adversarial loss: 0.916216\n",
      "epoch 1; iter: 0; batch classifier loss: 0.643951; batch adversarial loss: 0.939573\n",
      "epoch 2; iter: 0; batch classifier loss: 0.772109; batch adversarial loss: 0.921317\n",
      "epoch 3; iter: 0; batch classifier loss: 0.992889; batch adversarial loss: 0.872086\n",
      "epoch 4; iter: 0; batch classifier loss: 0.971102; batch adversarial loss: 0.818270\n",
      "epoch 5; iter: 0; batch classifier loss: 0.779348; batch adversarial loss: 0.709052\n",
      "epoch 6; iter: 0; batch classifier loss: 0.763698; batch adversarial loss: 0.669455\n",
      "epoch 7; iter: 0; batch classifier loss: 0.612131; batch adversarial loss: 0.631185\n",
      "epoch 8; iter: 0; batch classifier loss: 0.433739; batch adversarial loss: 0.585736\n",
      "epoch 9; iter: 0; batch classifier loss: 0.357692; batch adversarial loss: 0.525068\n",
      "epoch 10; iter: 0; batch classifier loss: 0.302171; batch adversarial loss: 0.505584\n",
      "epoch 11; iter: 0; batch classifier loss: 0.334436; batch adversarial loss: 0.510630\n",
      "epoch 12; iter: 0; batch classifier loss: 0.355390; batch adversarial loss: 0.529142\n",
      "epoch 13; iter: 0; batch classifier loss: 0.293589; batch adversarial loss: 0.496457\n",
      "epoch 14; iter: 0; batch classifier loss: 0.265026; batch adversarial loss: 0.526652\n",
      "epoch 15; iter: 0; batch classifier loss: 0.287113; batch adversarial loss: 0.469736\n",
      "epoch 16; iter: 0; batch classifier loss: 0.262478; batch adversarial loss: 0.483711\n",
      "epoch 17; iter: 0; batch classifier loss: 0.309206; batch adversarial loss: 0.532187\n",
      "epoch 18; iter: 0; batch classifier loss: 0.281026; batch adversarial loss: 0.560986\n",
      "epoch 19; iter: 0; batch classifier loss: 0.213998; batch adversarial loss: 0.410620\n",
      "epoch 20; iter: 0; batch classifier loss: 0.269073; batch adversarial loss: 0.482592\n",
      "epoch 21; iter: 0; batch classifier loss: 0.255327; batch adversarial loss: 0.405585\n",
      "epoch 22; iter: 0; batch classifier loss: 0.255612; batch adversarial loss: 0.540468\n",
      "epoch 23; iter: 0; batch classifier loss: 0.192885; batch adversarial loss: 0.458025\n",
      "epoch 24; iter: 0; batch classifier loss: 0.270559; batch adversarial loss: 0.452724\n",
      "epoch 25; iter: 0; batch classifier loss: 0.204297; batch adversarial loss: 0.502819\n",
      "epoch 26; iter: 0; batch classifier loss: 0.189387; batch adversarial loss: 0.441086\n",
      "epoch 27; iter: 0; batch classifier loss: 0.202284; batch adversarial loss: 0.444950\n",
      "epoch 28; iter: 0; batch classifier loss: 0.189396; batch adversarial loss: 0.537164\n",
      "epoch 29; iter: 0; batch classifier loss: 0.214835; batch adversarial loss: 0.474053\n",
      "epoch 30; iter: 0; batch classifier loss: 0.162505; batch adversarial loss: 0.446484\n",
      "epoch 31; iter: 0; batch classifier loss: 0.102964; batch adversarial loss: 0.594110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.153755; batch adversarial loss: 0.440255\n",
      "epoch 33; iter: 0; batch classifier loss: 0.163612; batch adversarial loss: 0.533900\n",
      "epoch 34; iter: 0; batch classifier loss: 0.130976; batch adversarial loss: 0.529087\n",
      "epoch 35; iter: 0; batch classifier loss: 0.134356; batch adversarial loss: 0.501383\n",
      "epoch 36; iter: 0; batch classifier loss: 0.169280; batch adversarial loss: 0.495225\n",
      "epoch 37; iter: 0; batch classifier loss: 0.118856; batch adversarial loss: 0.580585\n",
      "epoch 38; iter: 0; batch classifier loss: 0.137493; batch adversarial loss: 0.447507\n",
      "epoch 39; iter: 0; batch classifier loss: 0.164110; batch adversarial loss: 0.466145\n",
      "epoch 40; iter: 0; batch classifier loss: 0.128124; batch adversarial loss: 0.500062\n",
      "epoch 41; iter: 0; batch classifier loss: 0.127732; batch adversarial loss: 0.385764\n",
      "epoch 42; iter: 0; batch classifier loss: 0.104509; batch adversarial loss: 0.457440\n",
      "epoch 43; iter: 0; batch classifier loss: 0.109579; batch adversarial loss: 0.509883\n",
      "epoch 44; iter: 0; batch classifier loss: 0.134880; batch adversarial loss: 0.353330\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089052; batch adversarial loss: 0.516468\n",
      "epoch 46; iter: 0; batch classifier loss: 0.165546; batch adversarial loss: 0.441329\n",
      "epoch 47; iter: 0; batch classifier loss: 0.152579; batch adversarial loss: 0.432766\n",
      "epoch 48; iter: 0; batch classifier loss: 0.117940; batch adversarial loss: 0.489638\n",
      "epoch 49; iter: 0; batch classifier loss: 0.134065; batch adversarial loss: 0.510377\n",
      "epoch 50; iter: 0; batch classifier loss: 0.084163; batch adversarial loss: 0.438552\n",
      "epoch 51; iter: 0; batch classifier loss: 0.126564; batch adversarial loss: 0.474934\n",
      "epoch 52; iter: 0; batch classifier loss: 0.146222; batch adversarial loss: 0.430057\n",
      "epoch 53; iter: 0; batch classifier loss: 0.081188; batch adversarial loss: 0.432751\n",
      "epoch 54; iter: 0; batch classifier loss: 0.082460; batch adversarial loss: 0.501433\n",
      "epoch 55; iter: 0; batch classifier loss: 0.063420; batch adversarial loss: 0.474249\n",
      "epoch 56; iter: 0; batch classifier loss: 0.077031; batch adversarial loss: 0.475573\n",
      "epoch 57; iter: 0; batch classifier loss: 0.144655; batch adversarial loss: 0.422046\n",
      "epoch 58; iter: 0; batch classifier loss: 0.040091; batch adversarial loss: 0.476009\n",
      "epoch 59; iter: 0; batch classifier loss: 0.123624; batch adversarial loss: 0.407374\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097099; batch adversarial loss: 0.449839\n",
      "epoch 61; iter: 0; batch classifier loss: 0.126831; batch adversarial loss: 0.447603\n",
      "epoch 62; iter: 0; batch classifier loss: 0.064340; batch adversarial loss: 0.492912\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070931; batch adversarial loss: 0.489427\n",
      "epoch 64; iter: 0; batch classifier loss: 0.103656; batch adversarial loss: 0.435625\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079642; batch adversarial loss: 0.381337\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091693; batch adversarial loss: 0.443734\n",
      "epoch 67; iter: 0; batch classifier loss: 0.065374; batch adversarial loss: 0.436409\n",
      "epoch 68; iter: 0; batch classifier loss: 0.080970; batch adversarial loss: 0.454296\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102240; batch adversarial loss: 0.465135\n",
      "epoch 70; iter: 0; batch classifier loss: 0.053403; batch adversarial loss: 0.526714\n",
      "epoch 71; iter: 0; batch classifier loss: 0.054740; batch adversarial loss: 0.427970\n",
      "epoch 72; iter: 0; batch classifier loss: 0.046235; batch adversarial loss: 0.463909\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069059; batch adversarial loss: 0.406753\n",
      "epoch 74; iter: 0; batch classifier loss: 0.047797; batch adversarial loss: 0.412398\n",
      "epoch 75; iter: 0; batch classifier loss: 0.068792; batch adversarial loss: 0.470853\n",
      "epoch 76; iter: 0; batch classifier loss: 0.091308; batch adversarial loss: 0.477843\n",
      "epoch 77; iter: 0; batch classifier loss: 0.060850; batch adversarial loss: 0.492326\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061591; batch adversarial loss: 0.400006\n",
      "epoch 79; iter: 0; batch classifier loss: 0.073722; batch adversarial loss: 0.462167\n",
      "epoch 80; iter: 0; batch classifier loss: 0.080136; batch adversarial loss: 0.461536\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096949; batch adversarial loss: 0.491955\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066917; batch adversarial loss: 0.413121\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071571; batch adversarial loss: 0.381496\n",
      "epoch 84; iter: 0; batch classifier loss: 0.096363; batch adversarial loss: 0.379881\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046742; batch adversarial loss: 0.399190\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076302; batch adversarial loss: 0.505823\n",
      "epoch 87; iter: 0; batch classifier loss: 0.030602; batch adversarial loss: 0.595622\n",
      "epoch 88; iter: 0; batch classifier loss: 0.044709; batch adversarial loss: 0.403226\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066815; batch adversarial loss: 0.370048\n",
      "epoch 90; iter: 0; batch classifier loss: 0.044635; batch adversarial loss: 0.410065\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048937; batch adversarial loss: 0.451350\n",
      "epoch 92; iter: 0; batch classifier loss: 0.054669; batch adversarial loss: 0.447587\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065532; batch adversarial loss: 0.395257\n",
      "epoch 94; iter: 0; batch classifier loss: 0.096188; batch adversarial loss: 0.438315\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048783; batch adversarial loss: 0.384939\n",
      "epoch 96; iter: 0; batch classifier loss: 0.088475; batch adversarial loss: 0.428342\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056428; batch adversarial loss: 0.484956\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047451; batch adversarial loss: 0.449175\n",
      "epoch 99; iter: 0; batch classifier loss: 0.024230; batch adversarial loss: 0.467493\n",
      "epoch 100; iter: 0; batch classifier loss: 0.031454; batch adversarial loss: 0.480284\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054572; batch adversarial loss: 0.499773\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047507; batch adversarial loss: 0.464992\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055739; batch adversarial loss: 0.480990\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061026; batch adversarial loss: 0.502922\n",
      "epoch 105; iter: 0; batch classifier loss: 0.036861; batch adversarial loss: 0.501855\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042207; batch adversarial loss: 0.461191\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035283; batch adversarial loss: 0.464587\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043520; batch adversarial loss: 0.452510\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047339; batch adversarial loss: 0.435617\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039034; batch adversarial loss: 0.388404\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035776; batch adversarial loss: 0.459066\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035423; batch adversarial loss: 0.510672\n",
      "epoch 113; iter: 0; batch classifier loss: 0.024061; batch adversarial loss: 0.447080\n",
      "epoch 114; iter: 0; batch classifier loss: 0.045616; batch adversarial loss: 0.441216\n",
      "epoch 115; iter: 0; batch classifier loss: 0.058461; batch adversarial loss: 0.403128\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038065; batch adversarial loss: 0.448255\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037893; batch adversarial loss: 0.445922\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028694; batch adversarial loss: 0.473915\n",
      "epoch 119; iter: 0; batch classifier loss: 0.016467; batch adversarial loss: 0.491017\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025004; batch adversarial loss: 0.347038\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038753; batch adversarial loss: 0.425622\n",
      "epoch 122; iter: 0; batch classifier loss: 0.061877; batch adversarial loss: 0.533731\n",
      "epoch 123; iter: 0; batch classifier loss: 0.077532; batch adversarial loss: 0.456137\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024785; batch adversarial loss: 0.437590\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026310; batch adversarial loss: 0.448171\n",
      "epoch 126; iter: 0; batch classifier loss: 0.056511; batch adversarial loss: 0.474581\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047205; batch adversarial loss: 0.466025\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039460; batch adversarial loss: 0.377639\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030128; batch adversarial loss: 0.441689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.021844; batch adversarial loss: 0.428739\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032844; batch adversarial loss: 0.482541\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047935; batch adversarial loss: 0.401203\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031330; batch adversarial loss: 0.417787\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032975; batch adversarial loss: 0.447139\n",
      "epoch 135; iter: 0; batch classifier loss: 0.078828; batch adversarial loss: 0.477839\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025926; batch adversarial loss: 0.426085\n",
      "epoch 137; iter: 0; batch classifier loss: 0.058462; batch adversarial loss: 0.393866\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030615; batch adversarial loss: 0.534067\n",
      "epoch 139; iter: 0; batch classifier loss: 0.047130; batch adversarial loss: 0.441957\n",
      "epoch 140; iter: 0; batch classifier loss: 0.039515; batch adversarial loss: 0.526059\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024718; batch adversarial loss: 0.426627\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035889; batch adversarial loss: 0.454023\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029689; batch adversarial loss: 0.588407\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017556; batch adversarial loss: 0.390039\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024873; batch adversarial loss: 0.472963\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032690; batch adversarial loss: 0.472954\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042581; batch adversarial loss: 0.405691\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024456; batch adversarial loss: 0.536699\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033645; batch adversarial loss: 0.441414\n",
      "epoch 150; iter: 0; batch classifier loss: 0.047784; batch adversarial loss: 0.475693\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020469; batch adversarial loss: 0.382212\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032755; batch adversarial loss: 0.431126\n",
      "epoch 153; iter: 0; batch classifier loss: 0.049926; batch adversarial loss: 0.383703\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024765; batch adversarial loss: 0.429164\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010239; batch adversarial loss: 0.453990\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015989; batch adversarial loss: 0.497768\n",
      "epoch 157; iter: 0; batch classifier loss: 0.050907; batch adversarial loss: 0.384063\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028497; batch adversarial loss: 0.535168\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014461; batch adversarial loss: 0.408223\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023536; batch adversarial loss: 0.429256\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013847; batch adversarial loss: 0.415462\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017072; batch adversarial loss: 0.406497\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024862; batch adversarial loss: 0.504627\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025363; batch adversarial loss: 0.460713\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029137; batch adversarial loss: 0.421358\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013670; batch adversarial loss: 0.472558\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028504; batch adversarial loss: 0.434724\n",
      "epoch 168; iter: 0; batch classifier loss: 0.059081; batch adversarial loss: 0.485112\n",
      "epoch 169; iter: 0; batch classifier loss: 0.002286; batch adversarial loss: 0.470025\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020014; batch adversarial loss: 0.476285\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023135; batch adversarial loss: 0.453770\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016416; batch adversarial loss: 0.448466\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019450; batch adversarial loss: 0.521128\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019539; batch adversarial loss: 0.362687\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027809; batch adversarial loss: 0.513049\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026008; batch adversarial loss: 0.452745\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037598; batch adversarial loss: 0.514175\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012978; batch adversarial loss: 0.437246\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014201; batch adversarial loss: 0.480594\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015349; batch adversarial loss: 0.444507\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035052; batch adversarial loss: 0.510080\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007135; batch adversarial loss: 0.442817\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007937; batch adversarial loss: 0.492364\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019750; batch adversarial loss: 0.482661\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015211; batch adversarial loss: 0.473478\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015801; batch adversarial loss: 0.469241\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010263; batch adversarial loss: 0.486507\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010192; batch adversarial loss: 0.404594\n",
      "epoch 189; iter: 0; batch classifier loss: 0.037882; batch adversarial loss: 0.445944\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027761; batch adversarial loss: 0.486344\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033252; batch adversarial loss: 0.428744\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019748; batch adversarial loss: 0.422148\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005298; batch adversarial loss: 0.520312\n",
      "epoch 194; iter: 0; batch classifier loss: 0.003810; batch adversarial loss: 0.575979\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026514; batch adversarial loss: 0.455772\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026769; batch adversarial loss: 0.363418\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045553; batch adversarial loss: 0.593503\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023245; batch adversarial loss: 0.518528\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028659; batch adversarial loss: 0.454602\n",
      "epoch 0; iter: 0; batch classifier loss: 0.784136; batch adversarial loss: 0.578390\n",
      "epoch 1; iter: 0; batch classifier loss: 0.440537; batch adversarial loss: 0.610547\n",
      "epoch 2; iter: 0; batch classifier loss: 0.427760; batch adversarial loss: 0.590243\n",
      "epoch 3; iter: 0; batch classifier loss: 0.407914; batch adversarial loss: 0.570033\n",
      "epoch 4; iter: 0; batch classifier loss: 0.321841; batch adversarial loss: 0.537474\n",
      "epoch 5; iter: 0; batch classifier loss: 0.282360; batch adversarial loss: 0.520319\n",
      "epoch 6; iter: 0; batch classifier loss: 0.376756; batch adversarial loss: 0.506072\n",
      "epoch 7; iter: 0; batch classifier loss: 0.231820; batch adversarial loss: 0.509806\n",
      "epoch 8; iter: 0; batch classifier loss: 0.324999; batch adversarial loss: 0.511915\n",
      "epoch 9; iter: 0; batch classifier loss: 0.311263; batch adversarial loss: 0.523457\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269404; batch adversarial loss: 0.552419\n",
      "epoch 11; iter: 0; batch classifier loss: 0.289505; batch adversarial loss: 0.459578\n",
      "epoch 12; iter: 0; batch classifier loss: 0.270155; batch adversarial loss: 0.496228\n",
      "epoch 13; iter: 0; batch classifier loss: 0.229154; batch adversarial loss: 0.436085\n",
      "epoch 14; iter: 0; batch classifier loss: 0.274673; batch adversarial loss: 0.567805\n",
      "epoch 15; iter: 0; batch classifier loss: 0.313343; batch adversarial loss: 0.496187\n",
      "epoch 16; iter: 0; batch classifier loss: 0.338236; batch adversarial loss: 0.570073\n",
      "epoch 17; iter: 0; batch classifier loss: 0.326332; batch adversarial loss: 0.505911\n",
      "epoch 18; iter: 0; batch classifier loss: 0.307241; batch adversarial loss: 0.441593\n",
      "epoch 19; iter: 0; batch classifier loss: 0.350262; batch adversarial loss: 0.488147\n",
      "epoch 20; iter: 0; batch classifier loss: 0.438390; batch adversarial loss: 0.516184\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509438; batch adversarial loss: 0.470796\n",
      "epoch 22; iter: 0; batch classifier loss: 0.403329; batch adversarial loss: 0.503133\n",
      "epoch 23; iter: 0; batch classifier loss: 0.209075; batch adversarial loss: 0.509932\n",
      "epoch 24; iter: 0; batch classifier loss: 0.237895; batch adversarial loss: 0.413277\n",
      "epoch 25; iter: 0; batch classifier loss: 0.168134; batch adversarial loss: 0.492808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.151336; batch adversarial loss: 0.478140\n",
      "epoch 27; iter: 0; batch classifier loss: 0.137179; batch adversarial loss: 0.438923\n",
      "epoch 28; iter: 0; batch classifier loss: 0.205457; batch adversarial loss: 0.452618\n",
      "epoch 29; iter: 0; batch classifier loss: 0.182421; batch adversarial loss: 0.439638\n",
      "epoch 30; iter: 0; batch classifier loss: 0.141958; batch adversarial loss: 0.432093\n",
      "epoch 31; iter: 0; batch classifier loss: 0.125213; batch adversarial loss: 0.514999\n",
      "epoch 32; iter: 0; batch classifier loss: 0.158055; batch adversarial loss: 0.460895\n",
      "epoch 33; iter: 0; batch classifier loss: 0.126302; batch adversarial loss: 0.424173\n",
      "epoch 34; iter: 0; batch classifier loss: 0.150032; batch adversarial loss: 0.477773\n",
      "epoch 35; iter: 0; batch classifier loss: 0.222786; batch adversarial loss: 0.426099\n",
      "epoch 36; iter: 0; batch classifier loss: 0.212437; batch adversarial loss: 0.430550\n",
      "epoch 37; iter: 0; batch classifier loss: 0.125493; batch adversarial loss: 0.537190\n",
      "epoch 38; iter: 0; batch classifier loss: 0.177120; batch adversarial loss: 0.456742\n",
      "epoch 39; iter: 0; batch classifier loss: 0.128999; batch adversarial loss: 0.441227\n",
      "epoch 40; iter: 0; batch classifier loss: 0.170513; batch adversarial loss: 0.464584\n",
      "epoch 41; iter: 0; batch classifier loss: 0.174196; batch adversarial loss: 0.380764\n",
      "epoch 42; iter: 0; batch classifier loss: 0.156905; batch adversarial loss: 0.486001\n",
      "epoch 43; iter: 0; batch classifier loss: 0.137845; batch adversarial loss: 0.406200\n",
      "epoch 44; iter: 0; batch classifier loss: 0.142990; batch adversarial loss: 0.547502\n",
      "epoch 45; iter: 0; batch classifier loss: 0.181216; batch adversarial loss: 0.540640\n",
      "epoch 46; iter: 0; batch classifier loss: 0.150979; batch adversarial loss: 0.467316\n",
      "epoch 47; iter: 0; batch classifier loss: 0.167231; batch adversarial loss: 0.398507\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125600; batch adversarial loss: 0.453256\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114433; batch adversarial loss: 0.437521\n",
      "epoch 50; iter: 0; batch classifier loss: 0.112722; batch adversarial loss: 0.469526\n",
      "epoch 51; iter: 0; batch classifier loss: 0.163040; batch adversarial loss: 0.474065\n",
      "epoch 52; iter: 0; batch classifier loss: 0.165148; batch adversarial loss: 0.453479\n",
      "epoch 53; iter: 0; batch classifier loss: 0.117633; batch adversarial loss: 0.406260\n",
      "epoch 54; iter: 0; batch classifier loss: 0.195676; batch adversarial loss: 0.525372\n",
      "epoch 55; iter: 0; batch classifier loss: 0.138948; batch adversarial loss: 0.438188\n",
      "epoch 56; iter: 0; batch classifier loss: 0.271005; batch adversarial loss: 0.391148\n",
      "epoch 57; iter: 0; batch classifier loss: 0.217209; batch adversarial loss: 0.423860\n",
      "epoch 58; iter: 0; batch classifier loss: 0.171140; batch adversarial loss: 0.400132\n",
      "epoch 59; iter: 0; batch classifier loss: 0.134665; batch adversarial loss: 0.476264\n",
      "epoch 60; iter: 0; batch classifier loss: 0.200864; batch adversarial loss: 0.414563\n",
      "epoch 61; iter: 0; batch classifier loss: 0.175614; batch adversarial loss: 0.415709\n",
      "epoch 62; iter: 0; batch classifier loss: 0.194572; batch adversarial loss: 0.466511\n",
      "epoch 63; iter: 0; batch classifier loss: 0.167640; batch adversarial loss: 0.419763\n",
      "epoch 64; iter: 0; batch classifier loss: 0.132231; batch adversarial loss: 0.439149\n",
      "epoch 65; iter: 0; batch classifier loss: 0.159904; batch adversarial loss: 0.451049\n",
      "epoch 66; iter: 0; batch classifier loss: 0.156228; batch adversarial loss: 0.559684\n",
      "epoch 67; iter: 0; batch classifier loss: 0.123400; batch adversarial loss: 0.392370\n",
      "epoch 68; iter: 0; batch classifier loss: 0.163697; batch adversarial loss: 0.402740\n",
      "epoch 69; iter: 0; batch classifier loss: 0.097262; batch adversarial loss: 0.485314\n",
      "epoch 70; iter: 0; batch classifier loss: 0.159946; batch adversarial loss: 0.518775\n",
      "epoch 71; iter: 0; batch classifier loss: 0.183897; batch adversarial loss: 0.381131\n",
      "epoch 72; iter: 0; batch classifier loss: 0.120796; batch adversarial loss: 0.472190\n",
      "epoch 73; iter: 0; batch classifier loss: 0.160096; batch adversarial loss: 0.535557\n",
      "epoch 74; iter: 0; batch classifier loss: 0.123429; batch adversarial loss: 0.462327\n",
      "epoch 75; iter: 0; batch classifier loss: 0.174216; batch adversarial loss: 0.494385\n",
      "epoch 76; iter: 0; batch classifier loss: 0.130754; batch adversarial loss: 0.418679\n",
      "epoch 77; iter: 0; batch classifier loss: 0.106920; batch adversarial loss: 0.358446\n",
      "epoch 78; iter: 0; batch classifier loss: 0.170081; batch adversarial loss: 0.472610\n",
      "epoch 79; iter: 0; batch classifier loss: 0.183408; batch adversarial loss: 0.408562\n",
      "epoch 80; iter: 0; batch classifier loss: 0.153039; batch adversarial loss: 0.371481\n",
      "epoch 81; iter: 0; batch classifier loss: 0.124805; batch adversarial loss: 0.409289\n",
      "epoch 82; iter: 0; batch classifier loss: 0.185822; batch adversarial loss: 0.346282\n",
      "epoch 83; iter: 0; batch classifier loss: 0.097818; batch adversarial loss: 0.479620\n",
      "epoch 84; iter: 0; batch classifier loss: 0.150978; batch adversarial loss: 0.469577\n",
      "epoch 85; iter: 0; batch classifier loss: 0.162667; batch adversarial loss: 0.474109\n",
      "epoch 86; iter: 0; batch classifier loss: 0.144181; batch adversarial loss: 0.318398\n",
      "epoch 87; iter: 0; batch classifier loss: 0.157373; batch adversarial loss: 0.486177\n",
      "epoch 88; iter: 0; batch classifier loss: 0.136862; batch adversarial loss: 0.561958\n",
      "epoch 89; iter: 0; batch classifier loss: 0.188860; batch adversarial loss: 0.471835\n",
      "epoch 90; iter: 0; batch classifier loss: 0.141656; batch adversarial loss: 0.545233\n",
      "epoch 91; iter: 0; batch classifier loss: 0.114240; batch adversarial loss: 0.432763\n",
      "epoch 92; iter: 0; batch classifier loss: 0.193995; batch adversarial loss: 0.422204\n",
      "epoch 93; iter: 0; batch classifier loss: 0.189833; batch adversarial loss: 0.480914\n",
      "epoch 94; iter: 0; batch classifier loss: 0.158703; batch adversarial loss: 0.450809\n",
      "epoch 95; iter: 0; batch classifier loss: 0.139107; batch adversarial loss: 0.553164\n",
      "epoch 96; iter: 0; batch classifier loss: 0.159809; batch adversarial loss: 0.382350\n",
      "epoch 97; iter: 0; batch classifier loss: 0.164255; batch adversarial loss: 0.463318\n",
      "epoch 98; iter: 0; batch classifier loss: 0.131646; batch adversarial loss: 0.467309\n",
      "epoch 99; iter: 0; batch classifier loss: 0.162877; batch adversarial loss: 0.434375\n",
      "epoch 100; iter: 0; batch classifier loss: 0.135243; batch adversarial loss: 0.429705\n",
      "epoch 101; iter: 0; batch classifier loss: 0.155997; batch adversarial loss: 0.446888\n",
      "epoch 102; iter: 0; batch classifier loss: 0.123083; batch adversarial loss: 0.397899\n",
      "epoch 103; iter: 0; batch classifier loss: 0.154772; batch adversarial loss: 0.443470\n",
      "epoch 104; iter: 0; batch classifier loss: 0.143609; batch adversarial loss: 0.412424\n",
      "epoch 105; iter: 0; batch classifier loss: 0.190503; batch adversarial loss: 0.513529\n",
      "epoch 106; iter: 0; batch classifier loss: 0.141937; batch adversarial loss: 0.464098\n",
      "epoch 107; iter: 0; batch classifier loss: 0.158306; batch adversarial loss: 0.432565\n",
      "epoch 108; iter: 0; batch classifier loss: 0.110023; batch adversarial loss: 0.392956\n",
      "epoch 109; iter: 0; batch classifier loss: 0.146227; batch adversarial loss: 0.418803\n",
      "epoch 110; iter: 0; batch classifier loss: 0.118259; batch adversarial loss: 0.477717\n",
      "epoch 111; iter: 0; batch classifier loss: 0.126585; batch adversarial loss: 0.440367\n",
      "epoch 112; iter: 0; batch classifier loss: 0.109162; batch adversarial loss: 0.351870\n",
      "epoch 113; iter: 0; batch classifier loss: 0.099851; batch adversarial loss: 0.391544\n",
      "epoch 114; iter: 0; batch classifier loss: 0.101661; batch adversarial loss: 0.417280\n",
      "epoch 115; iter: 0; batch classifier loss: 0.131364; batch adversarial loss: 0.480734\n",
      "epoch 116; iter: 0; batch classifier loss: 0.118542; batch adversarial loss: 0.428738\n",
      "epoch 117; iter: 0; batch classifier loss: 0.097344; batch adversarial loss: 0.441108\n",
      "epoch 118; iter: 0; batch classifier loss: 0.087083; batch adversarial loss: 0.439849\n",
      "epoch 119; iter: 0; batch classifier loss: 0.070253; batch adversarial loss: 0.459124\n",
      "epoch 120; iter: 0; batch classifier loss: 0.066210; batch adversarial loss: 0.362037\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046536; batch adversarial loss: 0.448935\n",
      "epoch 122; iter: 0; batch classifier loss: 0.087174; batch adversarial loss: 0.475069\n",
      "epoch 123; iter: 0; batch classifier loss: 0.063566; batch adversarial loss: 0.479569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.051944; batch adversarial loss: 0.587899\n",
      "epoch 125; iter: 0; batch classifier loss: 0.079820; batch adversarial loss: 0.480844\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057108; batch adversarial loss: 0.451125\n",
      "epoch 127; iter: 0; batch classifier loss: 0.055011; batch adversarial loss: 0.429682\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032520; batch adversarial loss: 0.431273\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046317; batch adversarial loss: 0.504490\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025959; batch adversarial loss: 0.396939\n",
      "epoch 131; iter: 0; batch classifier loss: 0.067404; batch adversarial loss: 0.515195\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035029; batch adversarial loss: 0.495173\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037864; batch adversarial loss: 0.461438\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032073; batch adversarial loss: 0.459222\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046693; batch adversarial loss: 0.476113\n",
      "epoch 136; iter: 0; batch classifier loss: 0.071485; batch adversarial loss: 0.385395\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052949; batch adversarial loss: 0.329708\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022036; batch adversarial loss: 0.427403\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020008; batch adversarial loss: 0.447041\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033506; batch adversarial loss: 0.462931\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035970; batch adversarial loss: 0.455399\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030800; batch adversarial loss: 0.357595\n",
      "epoch 143; iter: 0; batch classifier loss: 0.081205; batch adversarial loss: 0.469165\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013756; batch adversarial loss: 0.484496\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030429; batch adversarial loss: 0.508309\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041252; batch adversarial loss: 0.512670\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031063; batch adversarial loss: 0.412087\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040931; batch adversarial loss: 0.439406\n",
      "epoch 149; iter: 0; batch classifier loss: 0.043403; batch adversarial loss: 0.418415\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026172; batch adversarial loss: 0.554835\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031724; batch adversarial loss: 0.436642\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030354; batch adversarial loss: 0.380350\n",
      "epoch 153; iter: 0; batch classifier loss: 0.064142; batch adversarial loss: 0.498911\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041102; batch adversarial loss: 0.402428\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042718; batch adversarial loss: 0.387919\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040320; batch adversarial loss: 0.497705\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042038; batch adversarial loss: 0.566436\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027473; batch adversarial loss: 0.463262\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035821; batch adversarial loss: 0.452709\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016248; batch adversarial loss: 0.464051\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040116; batch adversarial loss: 0.443826\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016917; batch adversarial loss: 0.471704\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012289; batch adversarial loss: 0.451067\n",
      "epoch 164; iter: 0; batch classifier loss: 0.048458; batch adversarial loss: 0.481133\n",
      "epoch 165; iter: 0; batch classifier loss: 0.052785; batch adversarial loss: 0.460774\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016579; batch adversarial loss: 0.394703\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018245; batch adversarial loss: 0.375669\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026445; batch adversarial loss: 0.554354\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011683; batch adversarial loss: 0.478344\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015725; batch adversarial loss: 0.411617\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033885; batch adversarial loss: 0.450315\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027324; batch adversarial loss: 0.576195\n",
      "epoch 173; iter: 0; batch classifier loss: 0.065801; batch adversarial loss: 0.476251\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012530; batch adversarial loss: 0.417323\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027472; batch adversarial loss: 0.385945\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024045; batch adversarial loss: 0.407032\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032750; batch adversarial loss: 0.429786\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014372; batch adversarial loss: 0.540543\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026077; batch adversarial loss: 0.423142\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013608; batch adversarial loss: 0.416506\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021060; batch adversarial loss: 0.470747\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015446; batch adversarial loss: 0.489647\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026031; batch adversarial loss: 0.430538\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012826; batch adversarial loss: 0.487822\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022393; batch adversarial loss: 0.432344\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017925; batch adversarial loss: 0.467554\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011522; batch adversarial loss: 0.434181\n",
      "epoch 188; iter: 0; batch classifier loss: 0.047100; batch adversarial loss: 0.400908\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024129; batch adversarial loss: 0.378207\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014458; batch adversarial loss: 0.452891\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026261; batch adversarial loss: 0.449007\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037100; batch adversarial loss: 0.498754\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007820; batch adversarial loss: 0.531118\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024196; batch adversarial loss: 0.486137\n",
      "epoch 195; iter: 0; batch classifier loss: 0.055822; batch adversarial loss: 0.573922\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023005; batch adversarial loss: 0.435874\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021221; batch adversarial loss: 0.447678\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020072; batch adversarial loss: 0.446225\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009739; batch adversarial loss: 0.435645\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678027; batch adversarial loss: 0.808650\n",
      "epoch 1; iter: 0; batch classifier loss: 0.387976; batch adversarial loss: 0.830022\n",
      "epoch 2; iter: 0; batch classifier loss: 0.365535; batch adversarial loss: 0.797846\n",
      "epoch 3; iter: 0; batch classifier loss: 0.371890; batch adversarial loss: 0.781643\n",
      "epoch 4; iter: 0; batch classifier loss: 0.328326; batch adversarial loss: 0.764605\n",
      "epoch 5; iter: 0; batch classifier loss: 0.354166; batch adversarial loss: 0.673892\n",
      "epoch 6; iter: 0; batch classifier loss: 0.335173; batch adversarial loss: 0.659926\n",
      "epoch 7; iter: 0; batch classifier loss: 0.285028; batch adversarial loss: 0.610475\n",
      "epoch 8; iter: 0; batch classifier loss: 0.298137; batch adversarial loss: 0.606666\n",
      "epoch 9; iter: 0; batch classifier loss: 0.276043; batch adversarial loss: 0.591840\n",
      "epoch 10; iter: 0; batch classifier loss: 0.288177; batch adversarial loss: 0.576210\n",
      "epoch 11; iter: 0; batch classifier loss: 0.259764; batch adversarial loss: 0.569433\n",
      "epoch 12; iter: 0; batch classifier loss: 0.265780; batch adversarial loss: 0.551375\n",
      "epoch 13; iter: 0; batch classifier loss: 0.306921; batch adversarial loss: 0.495568\n",
      "epoch 14; iter: 0; batch classifier loss: 0.269985; batch adversarial loss: 0.459289\n",
      "epoch 15; iter: 0; batch classifier loss: 0.263179; batch adversarial loss: 0.484998\n",
      "epoch 16; iter: 0; batch classifier loss: 0.202674; batch adversarial loss: 0.509448\n",
      "epoch 17; iter: 0; batch classifier loss: 0.245274; batch adversarial loss: 0.485974\n",
      "epoch 18; iter: 0; batch classifier loss: 0.275650; batch adversarial loss: 0.459900\n",
      "epoch 19; iter: 0; batch classifier loss: 0.238819; batch adversarial loss: 0.498382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.263431; batch adversarial loss: 0.425284\n",
      "epoch 21; iter: 0; batch classifier loss: 0.225342; batch adversarial loss: 0.418316\n",
      "epoch 22; iter: 0; batch classifier loss: 0.172575; batch adversarial loss: 0.436143\n",
      "epoch 23; iter: 0; batch classifier loss: 0.197152; batch adversarial loss: 0.397452\n",
      "epoch 24; iter: 0; batch classifier loss: 0.181599; batch adversarial loss: 0.449382\n",
      "epoch 25; iter: 0; batch classifier loss: 0.130712; batch adversarial loss: 0.432575\n",
      "epoch 26; iter: 0; batch classifier loss: 0.179216; batch adversarial loss: 0.435389\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152381; batch adversarial loss: 0.386985\n",
      "epoch 28; iter: 0; batch classifier loss: 0.195751; batch adversarial loss: 0.391542\n",
      "epoch 29; iter: 0; batch classifier loss: 0.181447; batch adversarial loss: 0.402451\n",
      "epoch 30; iter: 0; batch classifier loss: 0.154857; batch adversarial loss: 0.386013\n",
      "epoch 31; iter: 0; batch classifier loss: 0.124804; batch adversarial loss: 0.523200\n",
      "epoch 32; iter: 0; batch classifier loss: 0.125875; batch adversarial loss: 0.453940\n",
      "epoch 33; iter: 0; batch classifier loss: 0.116409; batch adversarial loss: 0.431667\n",
      "epoch 34; iter: 0; batch classifier loss: 0.160142; batch adversarial loss: 0.336307\n",
      "epoch 35; iter: 0; batch classifier loss: 0.099929; batch adversarial loss: 0.406986\n",
      "epoch 36; iter: 0; batch classifier loss: 0.179365; batch adversarial loss: 0.519382\n",
      "epoch 37; iter: 0; batch classifier loss: 0.156000; batch adversarial loss: 0.436901\n",
      "epoch 38; iter: 0; batch classifier loss: 0.154778; batch adversarial loss: 0.485695\n",
      "epoch 39; iter: 0; batch classifier loss: 0.162653; batch adversarial loss: 0.357810\n",
      "epoch 40; iter: 0; batch classifier loss: 0.151715; batch adversarial loss: 0.437206\n",
      "epoch 41; iter: 0; batch classifier loss: 0.117792; batch adversarial loss: 0.444540\n",
      "epoch 42; iter: 0; batch classifier loss: 0.124722; batch adversarial loss: 0.387144\n",
      "epoch 43; iter: 0; batch classifier loss: 0.106548; batch adversarial loss: 0.499478\n",
      "epoch 44; iter: 0; batch classifier loss: 0.161449; batch adversarial loss: 0.398431\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103189; batch adversarial loss: 0.300773\n",
      "epoch 46; iter: 0; batch classifier loss: 0.106631; batch adversarial loss: 0.386364\n",
      "epoch 47; iter: 0; batch classifier loss: 0.145054; batch adversarial loss: 0.335560\n",
      "epoch 48; iter: 0; batch classifier loss: 0.105830; batch adversarial loss: 0.426044\n",
      "epoch 49; iter: 0; batch classifier loss: 0.083799; batch adversarial loss: 0.448912\n",
      "epoch 50; iter: 0; batch classifier loss: 0.103695; batch adversarial loss: 0.474778\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092842; batch adversarial loss: 0.360265\n",
      "epoch 52; iter: 0; batch classifier loss: 0.119427; batch adversarial loss: 0.386371\n",
      "epoch 53; iter: 0; batch classifier loss: 0.074656; batch adversarial loss: 0.471800\n",
      "epoch 54; iter: 0; batch classifier loss: 0.088778; batch adversarial loss: 0.440831\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087171; batch adversarial loss: 0.355258\n",
      "epoch 56; iter: 0; batch classifier loss: 0.096128; batch adversarial loss: 0.462166\n",
      "epoch 57; iter: 0; batch classifier loss: 0.067828; batch adversarial loss: 0.414101\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077556; batch adversarial loss: 0.405481\n",
      "epoch 59; iter: 0; batch classifier loss: 0.071112; batch adversarial loss: 0.490930\n",
      "epoch 60; iter: 0; batch classifier loss: 0.066222; batch adversarial loss: 0.383331\n",
      "epoch 61; iter: 0; batch classifier loss: 0.065275; batch adversarial loss: 0.463915\n",
      "epoch 62; iter: 0; batch classifier loss: 0.086133; batch adversarial loss: 0.468001\n",
      "epoch 63; iter: 0; batch classifier loss: 0.053686; batch adversarial loss: 0.405882\n",
      "epoch 64; iter: 0; batch classifier loss: 0.052618; batch adversarial loss: 0.382279\n",
      "epoch 65; iter: 0; batch classifier loss: 0.114240; batch adversarial loss: 0.373985\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073551; batch adversarial loss: 0.464357\n",
      "epoch 67; iter: 0; batch classifier loss: 0.089041; batch adversarial loss: 0.394368\n",
      "epoch 68; iter: 0; batch classifier loss: 0.085968; batch adversarial loss: 0.411404\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094652; batch adversarial loss: 0.441725\n",
      "epoch 70; iter: 0; batch classifier loss: 0.058064; batch adversarial loss: 0.504758\n",
      "epoch 71; iter: 0; batch classifier loss: 0.076176; batch adversarial loss: 0.317918\n",
      "epoch 72; iter: 0; batch classifier loss: 0.061860; batch adversarial loss: 0.433070\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067612; batch adversarial loss: 0.411012\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089831; batch adversarial loss: 0.401409\n",
      "epoch 75; iter: 0; batch classifier loss: 0.046179; batch adversarial loss: 0.287871\n",
      "epoch 76; iter: 0; batch classifier loss: 0.051294; batch adversarial loss: 0.449191\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045677; batch adversarial loss: 0.461957\n",
      "epoch 78; iter: 0; batch classifier loss: 0.069033; batch adversarial loss: 0.464162\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071740; batch adversarial loss: 0.500632\n",
      "epoch 80; iter: 0; batch classifier loss: 0.065468; batch adversarial loss: 0.384372\n",
      "epoch 81; iter: 0; batch classifier loss: 0.052799; batch adversarial loss: 0.473285\n",
      "epoch 82; iter: 0; batch classifier loss: 0.040577; batch adversarial loss: 0.449712\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054475; batch adversarial loss: 0.400847\n",
      "epoch 84; iter: 0; batch classifier loss: 0.050470; batch adversarial loss: 0.428535\n",
      "epoch 85; iter: 0; batch classifier loss: 0.037876; batch adversarial loss: 0.404624\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053288; batch adversarial loss: 0.468811\n",
      "epoch 87; iter: 0; batch classifier loss: 0.039862; batch adversarial loss: 0.494473\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042704; batch adversarial loss: 0.456823\n",
      "epoch 89; iter: 0; batch classifier loss: 0.067250; batch adversarial loss: 0.454064\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054595; batch adversarial loss: 0.375789\n",
      "epoch 91; iter: 0; batch classifier loss: 0.047359; batch adversarial loss: 0.413555\n",
      "epoch 92; iter: 0; batch classifier loss: 0.056625; batch adversarial loss: 0.462557\n",
      "epoch 93; iter: 0; batch classifier loss: 0.030205; batch adversarial loss: 0.422557\n",
      "epoch 94; iter: 0; batch classifier loss: 0.025566; batch adversarial loss: 0.540196\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048585; batch adversarial loss: 0.480440\n",
      "epoch 96; iter: 0; batch classifier loss: 0.032108; batch adversarial loss: 0.504264\n",
      "epoch 97; iter: 0; batch classifier loss: 0.040778; batch adversarial loss: 0.412324\n",
      "epoch 98; iter: 0; batch classifier loss: 0.037877; batch adversarial loss: 0.491526\n",
      "epoch 99; iter: 0; batch classifier loss: 0.021408; batch adversarial loss: 0.451932\n",
      "epoch 100; iter: 0; batch classifier loss: 0.041605; batch adversarial loss: 0.449908\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040608; batch adversarial loss: 0.372645\n",
      "epoch 102; iter: 0; batch classifier loss: 0.039089; batch adversarial loss: 0.431259\n",
      "epoch 103; iter: 0; batch classifier loss: 0.021824; batch adversarial loss: 0.415271\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038844; batch adversarial loss: 0.382075\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046829; batch adversarial loss: 0.426240\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049962; batch adversarial loss: 0.422803\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035080; batch adversarial loss: 0.450142\n",
      "epoch 108; iter: 0; batch classifier loss: 0.027521; batch adversarial loss: 0.477845\n",
      "epoch 109; iter: 0; batch classifier loss: 0.018989; batch adversarial loss: 0.447512\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038924; batch adversarial loss: 0.445909\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031279; batch adversarial loss: 0.400839\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059255; batch adversarial loss: 0.291148\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042450; batch adversarial loss: 0.503549\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057799; batch adversarial loss: 0.437257\n",
      "epoch 115; iter: 0; batch classifier loss: 0.016372; batch adversarial loss: 0.426807\n",
      "epoch 116; iter: 0; batch classifier loss: 0.025926; batch adversarial loss: 0.454498\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041724; batch adversarial loss: 0.404626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.025261; batch adversarial loss: 0.402631\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047572; batch adversarial loss: 0.491756\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049438; batch adversarial loss: 0.337488\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038756; batch adversarial loss: 0.440934\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040847; batch adversarial loss: 0.397182\n",
      "epoch 123; iter: 0; batch classifier loss: 0.022430; batch adversarial loss: 0.486646\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025942; batch adversarial loss: 0.459836\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029851; batch adversarial loss: 0.574541\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044915; batch adversarial loss: 0.576782\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037214; batch adversarial loss: 0.432415\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032605; batch adversarial loss: 0.506923\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042522; batch adversarial loss: 0.542720\n",
      "epoch 130; iter: 0; batch classifier loss: 0.105664; batch adversarial loss: 0.619749\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031065; batch adversarial loss: 0.441752\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050368; batch adversarial loss: 0.491924\n",
      "epoch 133; iter: 0; batch classifier loss: 0.079256; batch adversarial loss: 0.433182\n",
      "epoch 134; iter: 0; batch classifier loss: 0.078552; batch adversarial loss: 0.539485\n",
      "epoch 135; iter: 0; batch classifier loss: 0.067351; batch adversarial loss: 0.532550\n",
      "epoch 136; iter: 0; batch classifier loss: 0.076383; batch adversarial loss: 0.534246\n",
      "epoch 137; iter: 0; batch classifier loss: 0.108143; batch adversarial loss: 0.655589\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039743; batch adversarial loss: 0.456124\n",
      "epoch 139; iter: 0; batch classifier loss: 0.139235; batch adversarial loss: 0.663697\n",
      "epoch 140; iter: 0; batch classifier loss: 0.097887; batch adversarial loss: 0.498806\n",
      "epoch 141; iter: 0; batch classifier loss: 0.079929; batch adversarial loss: 0.580573\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037041; batch adversarial loss: 0.549010\n",
      "epoch 143; iter: 0; batch classifier loss: 0.138302; batch adversarial loss: 0.589739\n",
      "epoch 144; iter: 0; batch classifier loss: 0.088267; batch adversarial loss: 0.493851\n",
      "epoch 145; iter: 0; batch classifier loss: 0.060228; batch adversarial loss: 0.529523\n",
      "epoch 146; iter: 0; batch classifier loss: 0.136946; batch adversarial loss: 0.620651\n",
      "epoch 147; iter: 0; batch classifier loss: 0.132771; batch adversarial loss: 0.595832\n",
      "epoch 148; iter: 0; batch classifier loss: 0.153045; batch adversarial loss: 0.658534\n",
      "epoch 149; iter: 0; batch classifier loss: 0.197567; batch adversarial loss: 0.762268\n",
      "epoch 150; iter: 0; batch classifier loss: 0.132503; batch adversarial loss: 0.564012\n",
      "epoch 151; iter: 0; batch classifier loss: 0.114069; batch adversarial loss: 0.561169\n",
      "epoch 152; iter: 0; batch classifier loss: 0.084087; batch adversarial loss: 0.575903\n",
      "epoch 153; iter: 0; batch classifier loss: 0.170486; batch adversarial loss: 0.647454\n",
      "epoch 154; iter: 0; batch classifier loss: 0.177039; batch adversarial loss: 0.563882\n",
      "epoch 155; iter: 0; batch classifier loss: 0.122211; batch adversarial loss: 0.481352\n",
      "epoch 156; iter: 0; batch classifier loss: 0.128728; batch adversarial loss: 0.528481\n",
      "epoch 157; iter: 0; batch classifier loss: 0.126398; batch adversarial loss: 0.555824\n",
      "epoch 158; iter: 0; batch classifier loss: 0.226120; batch adversarial loss: 0.652602\n",
      "epoch 159; iter: 0; batch classifier loss: 0.112708; batch adversarial loss: 0.468729\n",
      "epoch 160; iter: 0; batch classifier loss: 0.122047; batch adversarial loss: 0.480338\n",
      "epoch 161; iter: 0; batch classifier loss: 0.202894; batch adversarial loss: 0.511267\n",
      "epoch 162; iter: 0; batch classifier loss: 0.105235; batch adversarial loss: 0.476753\n",
      "epoch 163; iter: 0; batch classifier loss: 0.125324; batch adversarial loss: 0.598164\n",
      "epoch 164; iter: 0; batch classifier loss: 0.100790; batch adversarial loss: 0.446050\n",
      "epoch 165; iter: 0; batch classifier loss: 0.100515; batch adversarial loss: 0.455241\n",
      "epoch 166; iter: 0; batch classifier loss: 0.086474; batch adversarial loss: 0.415225\n",
      "epoch 167; iter: 0; batch classifier loss: 0.124283; batch adversarial loss: 0.556249\n",
      "epoch 168; iter: 0; batch classifier loss: 0.101224; batch adversarial loss: 0.444920\n",
      "epoch 169; iter: 0; batch classifier loss: 0.072118; batch adversarial loss: 0.457659\n",
      "epoch 170; iter: 0; batch classifier loss: 0.103130; batch adversarial loss: 0.538127\n",
      "epoch 171; iter: 0; batch classifier loss: 0.041969; batch adversarial loss: 0.430766\n",
      "epoch 172; iter: 0; batch classifier loss: 0.075929; batch adversarial loss: 0.453649\n",
      "epoch 173; iter: 0; batch classifier loss: 0.092930; batch adversarial loss: 0.429358\n",
      "epoch 174; iter: 0; batch classifier loss: 0.099247; batch adversarial loss: 0.427665\n",
      "epoch 175; iter: 0; batch classifier loss: 0.084358; batch adversarial loss: 0.426736\n",
      "epoch 176; iter: 0; batch classifier loss: 0.104486; batch adversarial loss: 0.528441\n",
      "epoch 177; iter: 0; batch classifier loss: 0.110852; batch adversarial loss: 0.432489\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027329; batch adversarial loss: 0.419641\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044789; batch adversarial loss: 0.466145\n",
      "epoch 180; iter: 0; batch classifier loss: 0.036101; batch adversarial loss: 0.601277\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020377; batch adversarial loss: 0.455918\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019303; batch adversarial loss: 0.455984\n",
      "epoch 183; iter: 0; batch classifier loss: 0.040123; batch adversarial loss: 0.454007\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027908; batch adversarial loss: 0.487892\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040584; batch adversarial loss: 0.449896\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012180; batch adversarial loss: 0.431815\n",
      "epoch 187; iter: 0; batch classifier loss: 0.041240; batch adversarial loss: 0.474167\n",
      "epoch 188; iter: 0; batch classifier loss: 0.051863; batch adversarial loss: 0.447421\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023152; batch adversarial loss: 0.435565\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034426; batch adversarial loss: 0.496589\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033197; batch adversarial loss: 0.449496\n",
      "epoch 192; iter: 0; batch classifier loss: 0.065929; batch adversarial loss: 0.496276\n",
      "epoch 193; iter: 0; batch classifier loss: 0.058167; batch adversarial loss: 0.464441\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041603; batch adversarial loss: 0.477899\n",
      "epoch 195; iter: 0; batch classifier loss: 0.060324; batch adversarial loss: 0.514026\n",
      "epoch 196; iter: 0; batch classifier loss: 0.083366; batch adversarial loss: 0.410931\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032907; batch adversarial loss: 0.393637\n",
      "epoch 198; iter: 0; batch classifier loss: 0.071876; batch adversarial loss: 0.420189\n",
      "epoch 199; iter: 0; batch classifier loss: 0.049922; batch adversarial loss: 0.461121\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695101; batch adversarial loss: 0.640174\n",
      "epoch 1; iter: 0; batch classifier loss: 0.443649; batch adversarial loss: 0.636269\n",
      "epoch 2; iter: 0; batch classifier loss: 0.340687; batch adversarial loss: 0.604404\n",
      "epoch 3; iter: 0; batch classifier loss: 0.391980; batch adversarial loss: 0.572804\n",
      "epoch 4; iter: 0; batch classifier loss: 0.293102; batch adversarial loss: 0.538014\n",
      "epoch 5; iter: 0; batch classifier loss: 0.305218; batch adversarial loss: 0.561431\n",
      "epoch 6; iter: 0; batch classifier loss: 0.265231; batch adversarial loss: 0.514979\n",
      "epoch 7; iter: 0; batch classifier loss: 0.191742; batch adversarial loss: 0.477607\n",
      "epoch 8; iter: 0; batch classifier loss: 0.303239; batch adversarial loss: 0.513095\n",
      "epoch 9; iter: 0; batch classifier loss: 0.228271; batch adversarial loss: 0.533907\n",
      "epoch 10; iter: 0; batch classifier loss: 0.209460; batch adversarial loss: 0.509902\n",
      "epoch 11; iter: 0; batch classifier loss: 0.261471; batch adversarial loss: 0.500831\n",
      "epoch 12; iter: 0; batch classifier loss: 0.275898; batch adversarial loss: 0.452087\n",
      "epoch 13; iter: 0; batch classifier loss: 0.191647; batch adversarial loss: 0.518168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.248236; batch adversarial loss: 0.475134\n",
      "epoch 15; iter: 0; batch classifier loss: 0.146950; batch adversarial loss: 0.523433\n",
      "epoch 16; iter: 0; batch classifier loss: 0.261478; batch adversarial loss: 0.532277\n",
      "epoch 17; iter: 0; batch classifier loss: 0.248005; batch adversarial loss: 0.513620\n",
      "epoch 18; iter: 0; batch classifier loss: 0.260748; batch adversarial loss: 0.496423\n",
      "epoch 19; iter: 0; batch classifier loss: 0.317810; batch adversarial loss: 0.550357\n",
      "epoch 20; iter: 0; batch classifier loss: 0.290486; batch adversarial loss: 0.532471\n",
      "epoch 21; iter: 0; batch classifier loss: 0.288604; batch adversarial loss: 0.474594\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469989; batch adversarial loss: 0.518112\n",
      "epoch 23; iter: 0; batch classifier loss: 0.414467; batch adversarial loss: 0.441474\n",
      "epoch 24; iter: 0; batch classifier loss: 0.257051; batch adversarial loss: 0.457681\n",
      "epoch 25; iter: 0; batch classifier loss: 0.167278; batch adversarial loss: 0.421950\n",
      "epoch 26; iter: 0; batch classifier loss: 0.135281; batch adversarial loss: 0.485592\n",
      "epoch 27; iter: 0; batch classifier loss: 0.188159; batch adversarial loss: 0.503914\n",
      "epoch 28; iter: 0; batch classifier loss: 0.190448; batch adversarial loss: 0.418853\n",
      "epoch 29; iter: 0; batch classifier loss: 0.132574; batch adversarial loss: 0.524246\n",
      "epoch 30; iter: 0; batch classifier loss: 0.116635; batch adversarial loss: 0.428275\n",
      "epoch 31; iter: 0; batch classifier loss: 0.111567; batch adversarial loss: 0.420758\n",
      "epoch 32; iter: 0; batch classifier loss: 0.171976; batch adversarial loss: 0.366249\n",
      "epoch 33; iter: 0; batch classifier loss: 0.196058; batch adversarial loss: 0.468689\n",
      "epoch 34; iter: 0; batch classifier loss: 0.117840; batch adversarial loss: 0.416376\n",
      "epoch 35; iter: 0; batch classifier loss: 0.124795; batch adversarial loss: 0.393953\n",
      "epoch 36; iter: 0; batch classifier loss: 0.112061; batch adversarial loss: 0.458877\n",
      "epoch 37; iter: 0; batch classifier loss: 0.080617; batch adversarial loss: 0.417456\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126946; batch adversarial loss: 0.447250\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106774; batch adversarial loss: 0.475342\n",
      "epoch 40; iter: 0; batch classifier loss: 0.073886; batch adversarial loss: 0.460989\n",
      "epoch 41; iter: 0; batch classifier loss: 0.059094; batch adversarial loss: 0.467878\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110214; batch adversarial loss: 0.390214\n",
      "epoch 43; iter: 0; batch classifier loss: 0.097273; batch adversarial loss: 0.438944\n",
      "epoch 44; iter: 0; batch classifier loss: 0.113642; batch adversarial loss: 0.462296\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108190; batch adversarial loss: 0.384119\n",
      "epoch 46; iter: 0; batch classifier loss: 0.122293; batch adversarial loss: 0.541346\n",
      "epoch 47; iter: 0; batch classifier loss: 0.111630; batch adversarial loss: 0.547660\n",
      "epoch 48; iter: 0; batch classifier loss: 0.084065; batch adversarial loss: 0.486041\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107230; batch adversarial loss: 0.480764\n",
      "epoch 50; iter: 0; batch classifier loss: 0.075643; batch adversarial loss: 0.455488\n",
      "epoch 51; iter: 0; batch classifier loss: 0.107244; batch adversarial loss: 0.448399\n",
      "epoch 52; iter: 0; batch classifier loss: 0.069612; batch adversarial loss: 0.480749\n",
      "epoch 53; iter: 0; batch classifier loss: 0.063627; batch adversarial loss: 0.433258\n",
      "epoch 54; iter: 0; batch classifier loss: 0.063388; batch adversarial loss: 0.456100\n",
      "epoch 55; iter: 0; batch classifier loss: 0.095095; batch adversarial loss: 0.496566\n",
      "epoch 56; iter: 0; batch classifier loss: 0.110550; batch adversarial loss: 0.466800\n",
      "epoch 57; iter: 0; batch classifier loss: 0.088394; batch adversarial loss: 0.464698\n",
      "epoch 58; iter: 0; batch classifier loss: 0.118987; batch adversarial loss: 0.412158\n",
      "epoch 59; iter: 0; batch classifier loss: 0.098984; batch adversarial loss: 0.508140\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122457; batch adversarial loss: 0.541127\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103933; batch adversarial loss: 0.437169\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084533; batch adversarial loss: 0.421396\n",
      "epoch 63; iter: 0; batch classifier loss: 0.100905; batch adversarial loss: 0.453484\n",
      "epoch 64; iter: 0; batch classifier loss: 0.099009; batch adversarial loss: 0.439206\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088229; batch adversarial loss: 0.471901\n",
      "epoch 66; iter: 0; batch classifier loss: 0.071577; batch adversarial loss: 0.371947\n",
      "epoch 67; iter: 0; batch classifier loss: 0.086672; batch adversarial loss: 0.396705\n",
      "epoch 68; iter: 0; batch classifier loss: 0.110349; batch adversarial loss: 0.531476\n",
      "epoch 69; iter: 0; batch classifier loss: 0.100889; batch adversarial loss: 0.515802\n",
      "epoch 70; iter: 0; batch classifier loss: 0.110059; batch adversarial loss: 0.471893\n",
      "epoch 71; iter: 0; batch classifier loss: 0.053257; batch adversarial loss: 0.555072\n",
      "epoch 72; iter: 0; batch classifier loss: 0.102366; batch adversarial loss: 0.438181\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077110; batch adversarial loss: 0.475955\n",
      "epoch 74; iter: 0; batch classifier loss: 0.126381; batch adversarial loss: 0.418906\n",
      "epoch 75; iter: 0; batch classifier loss: 0.048255; batch adversarial loss: 0.520121\n",
      "epoch 76; iter: 0; batch classifier loss: 0.112586; batch adversarial loss: 0.447296\n",
      "epoch 77; iter: 0; batch classifier loss: 0.073819; batch adversarial loss: 0.439009\n",
      "epoch 78; iter: 0; batch classifier loss: 0.127334; batch adversarial loss: 0.489212\n",
      "epoch 79; iter: 0; batch classifier loss: 0.093389; batch adversarial loss: 0.419638\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090557; batch adversarial loss: 0.497797\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075731; batch adversarial loss: 0.479492\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083388; batch adversarial loss: 0.463496\n",
      "epoch 83; iter: 0; batch classifier loss: 0.066663; batch adversarial loss: 0.458530\n",
      "epoch 84; iter: 0; batch classifier loss: 0.107471; batch adversarial loss: 0.336517\n",
      "epoch 85; iter: 0; batch classifier loss: 0.106934; batch adversarial loss: 0.464378\n",
      "epoch 86; iter: 0; batch classifier loss: 0.078640; batch adversarial loss: 0.437318\n",
      "epoch 87; iter: 0; batch classifier loss: 0.069333; batch adversarial loss: 0.387037\n",
      "epoch 88; iter: 0; batch classifier loss: 0.044689; batch adversarial loss: 0.387186\n",
      "epoch 89; iter: 0; batch classifier loss: 0.110329; batch adversarial loss: 0.369630\n",
      "epoch 90; iter: 0; batch classifier loss: 0.079854; batch adversarial loss: 0.398508\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077877; batch adversarial loss: 0.418937\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070996; batch adversarial loss: 0.427863\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071643; batch adversarial loss: 0.444358\n",
      "epoch 94; iter: 0; batch classifier loss: 0.052464; batch adversarial loss: 0.478047\n",
      "epoch 95; iter: 0; batch classifier loss: 0.084118; batch adversarial loss: 0.508519\n",
      "epoch 96; iter: 0; batch classifier loss: 0.091775; batch adversarial loss: 0.450928\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055493; batch adversarial loss: 0.542922\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052069; batch adversarial loss: 0.413615\n",
      "epoch 99; iter: 0; batch classifier loss: 0.075231; batch adversarial loss: 0.478615\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044303; batch adversarial loss: 0.435779\n",
      "epoch 101; iter: 0; batch classifier loss: 0.052650; batch adversarial loss: 0.480875\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051707; batch adversarial loss: 0.454434\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055069; batch adversarial loss: 0.482340\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050243; batch adversarial loss: 0.513462\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066557; batch adversarial loss: 0.486281\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040914; batch adversarial loss: 0.459559\n",
      "epoch 107; iter: 0; batch classifier loss: 0.102459; batch adversarial loss: 0.440368\n",
      "epoch 108; iter: 0; batch classifier loss: 0.047898; batch adversarial loss: 0.454130\n",
      "epoch 109; iter: 0; batch classifier loss: 0.096325; batch adversarial loss: 0.444403\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035701; batch adversarial loss: 0.497529\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066021; batch adversarial loss: 0.451953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.023609; batch adversarial loss: 0.497922\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056592; batch adversarial loss: 0.351570\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039471; batch adversarial loss: 0.496166\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059435; batch adversarial loss: 0.480410\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048713; batch adversarial loss: 0.463249\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033250; batch adversarial loss: 0.524119\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049771; batch adversarial loss: 0.421456\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053538; batch adversarial loss: 0.470994\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037840; batch adversarial loss: 0.429879\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040223; batch adversarial loss: 0.465307\n",
      "epoch 122; iter: 0; batch classifier loss: 0.018962; batch adversarial loss: 0.441785\n",
      "epoch 123; iter: 0; batch classifier loss: 0.078317; batch adversarial loss: 0.572281\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020652; batch adversarial loss: 0.497908\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038819; batch adversarial loss: 0.479882\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047379; batch adversarial loss: 0.406306\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043653; batch adversarial loss: 0.541233\n",
      "epoch 128; iter: 0; batch classifier loss: 0.062052; batch adversarial loss: 0.416231\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022164; batch adversarial loss: 0.485878\n",
      "epoch 130; iter: 0; batch classifier loss: 0.058598; batch adversarial loss: 0.404198\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032304; batch adversarial loss: 0.504719\n",
      "epoch 132; iter: 0; batch classifier loss: 0.071625; batch adversarial loss: 0.425902\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023625; batch adversarial loss: 0.447391\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050094; batch adversarial loss: 0.444849\n",
      "epoch 135; iter: 0; batch classifier loss: 0.072344; batch adversarial loss: 0.348866\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032989; batch adversarial loss: 0.396864\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022997; batch adversarial loss: 0.590384\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014056; batch adversarial loss: 0.472296\n",
      "epoch 139; iter: 0; batch classifier loss: 0.073316; batch adversarial loss: 0.387455\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048468; batch adversarial loss: 0.444555\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026934; batch adversarial loss: 0.427209\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023591; batch adversarial loss: 0.468020\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051556; batch adversarial loss: 0.460668\n",
      "epoch 144; iter: 0; batch classifier loss: 0.038907; batch adversarial loss: 0.467360\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030078; batch adversarial loss: 0.504387\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039626; batch adversarial loss: 0.488891\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042200; batch adversarial loss: 0.589729\n",
      "epoch 148; iter: 0; batch classifier loss: 0.051342; batch adversarial loss: 0.414763\n",
      "epoch 149; iter: 0; batch classifier loss: 0.042513; batch adversarial loss: 0.468080\n",
      "epoch 150; iter: 0; batch classifier loss: 0.055382; batch adversarial loss: 0.539174\n",
      "epoch 151; iter: 0; batch classifier loss: 0.051995; batch adversarial loss: 0.370305\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017180; batch adversarial loss: 0.428065\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024130; batch adversarial loss: 0.496263\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025817; batch adversarial loss: 0.471206\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036119; batch adversarial loss: 0.476095\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026870; batch adversarial loss: 0.420070\n",
      "epoch 157; iter: 0; batch classifier loss: 0.128038; batch adversarial loss: 0.463986\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013208; batch adversarial loss: 0.498785\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021499; batch adversarial loss: 0.504271\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009647; batch adversarial loss: 0.461194\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040754; batch adversarial loss: 0.459119\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033958; batch adversarial loss: 0.555971\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021646; batch adversarial loss: 0.476100\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019804; batch adversarial loss: 0.411658\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014456; batch adversarial loss: 0.426899\n",
      "epoch 166; iter: 0; batch classifier loss: 0.006329; batch adversarial loss: 0.454644\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042311; batch adversarial loss: 0.480721\n",
      "epoch 168; iter: 0; batch classifier loss: 0.047741; batch adversarial loss: 0.494581\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040166; batch adversarial loss: 0.458195\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023878; batch adversarial loss: 0.480064\n",
      "epoch 171; iter: 0; batch classifier loss: 0.077518; batch adversarial loss: 0.399384\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019040; batch adversarial loss: 0.419376\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035328; batch adversarial loss: 0.423205\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014419; batch adversarial loss: 0.531532\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027302; batch adversarial loss: 0.423130\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032788; batch adversarial loss: 0.506050\n",
      "epoch 177; iter: 0; batch classifier loss: 0.047829; batch adversarial loss: 0.467713\n",
      "epoch 178; iter: 0; batch classifier loss: 0.046618; batch adversarial loss: 0.504465\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008509; batch adversarial loss: 0.388876\n",
      "epoch 180; iter: 0; batch classifier loss: 0.057252; batch adversarial loss: 0.469221\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011809; batch adversarial loss: 0.459981\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025228; batch adversarial loss: 0.438819\n",
      "epoch 183; iter: 0; batch classifier loss: 0.037933; batch adversarial loss: 0.434233\n",
      "epoch 184; iter: 0; batch classifier loss: 0.046424; batch adversarial loss: 0.475951\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035870; batch adversarial loss: 0.352420\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018948; batch adversarial loss: 0.519027\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026223; batch adversarial loss: 0.498085\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034941; batch adversarial loss: 0.522204\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021108; batch adversarial loss: 0.509617\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011146; batch adversarial loss: 0.348730\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020663; batch adversarial loss: 0.388186\n",
      "epoch 192; iter: 0; batch classifier loss: 0.055104; batch adversarial loss: 0.357443\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029268; batch adversarial loss: 0.415815\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017531; batch adversarial loss: 0.442764\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015015; batch adversarial loss: 0.488717\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025126; batch adversarial loss: 0.405081\n",
      "epoch 197; iter: 0; batch classifier loss: 0.068464; batch adversarial loss: 0.442768\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014428; batch adversarial loss: 0.519670\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019593; batch adversarial loss: 0.444211\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696866; batch adversarial loss: 1.002710\n",
      "epoch 1; iter: 0; batch classifier loss: 0.832174; batch adversarial loss: 1.204277\n",
      "epoch 2; iter: 0; batch classifier loss: 0.965364; batch adversarial loss: 1.204631\n",
      "epoch 3; iter: 0; batch classifier loss: 1.178745; batch adversarial loss: 1.111160\n",
      "epoch 4; iter: 0; batch classifier loss: 1.108253; batch adversarial loss: 0.983353\n",
      "epoch 5; iter: 0; batch classifier loss: 1.343487; batch adversarial loss: 0.933998\n",
      "epoch 6; iter: 0; batch classifier loss: 1.170227; batch adversarial loss: 0.830508\n",
      "epoch 7; iter: 0; batch classifier loss: 1.054610; batch adversarial loss: 0.769016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 1.145980; batch adversarial loss: 0.710710\n",
      "epoch 9; iter: 0; batch classifier loss: 1.088045; batch adversarial loss: 0.623595\n",
      "epoch 10; iter: 0; batch classifier loss: 0.821633; batch adversarial loss: 0.581674\n",
      "epoch 11; iter: 0; batch classifier loss: 0.664517; batch adversarial loss: 0.538649\n",
      "epoch 12; iter: 0; batch classifier loss: 0.490435; batch adversarial loss: 0.524115\n",
      "epoch 13; iter: 0; batch classifier loss: 0.380440; batch adversarial loss: 0.482296\n",
      "epoch 14; iter: 0; batch classifier loss: 0.356452; batch adversarial loss: 0.482603\n",
      "epoch 15; iter: 0; batch classifier loss: 0.265198; batch adversarial loss: 0.555269\n",
      "epoch 16; iter: 0; batch classifier loss: 0.310762; batch adversarial loss: 0.563314\n",
      "epoch 17; iter: 0; batch classifier loss: 0.298844; batch adversarial loss: 0.460687\n",
      "epoch 18; iter: 0; batch classifier loss: 0.280748; batch adversarial loss: 0.483758\n",
      "epoch 19; iter: 0; batch classifier loss: 0.274348; batch adversarial loss: 0.476351\n",
      "epoch 20; iter: 0; batch classifier loss: 0.240593; batch adversarial loss: 0.470659\n",
      "epoch 21; iter: 0; batch classifier loss: 0.289436; batch adversarial loss: 0.448409\n",
      "epoch 22; iter: 0; batch classifier loss: 0.214572; batch adversarial loss: 0.501634\n",
      "epoch 23; iter: 0; batch classifier loss: 0.198499; batch adversarial loss: 0.524519\n",
      "epoch 24; iter: 0; batch classifier loss: 0.179212; batch adversarial loss: 0.434926\n",
      "epoch 25; iter: 0; batch classifier loss: 0.224362; batch adversarial loss: 0.500015\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223137; batch adversarial loss: 0.475024\n",
      "epoch 27; iter: 0; batch classifier loss: 0.215404; batch adversarial loss: 0.470831\n",
      "epoch 28; iter: 0; batch classifier loss: 0.182726; batch adversarial loss: 0.517604\n",
      "epoch 29; iter: 0; batch classifier loss: 0.160251; batch adversarial loss: 0.491259\n",
      "epoch 30; iter: 0; batch classifier loss: 0.161631; batch adversarial loss: 0.484189\n",
      "epoch 31; iter: 0; batch classifier loss: 0.173994; batch adversarial loss: 0.442031\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154851; batch adversarial loss: 0.560929\n",
      "epoch 33; iter: 0; batch classifier loss: 0.112798; batch adversarial loss: 0.470368\n",
      "epoch 34; iter: 0; batch classifier loss: 0.136425; batch adversarial loss: 0.458518\n",
      "epoch 35; iter: 0; batch classifier loss: 0.164666; batch adversarial loss: 0.421751\n",
      "epoch 36; iter: 0; batch classifier loss: 0.175837; batch adversarial loss: 0.384125\n",
      "epoch 37; iter: 0; batch classifier loss: 0.125563; batch adversarial loss: 0.440504\n",
      "epoch 38; iter: 0; batch classifier loss: 0.120185; batch adversarial loss: 0.477921\n",
      "epoch 39; iter: 0; batch classifier loss: 0.193263; batch adversarial loss: 0.455293\n",
      "epoch 40; iter: 0; batch classifier loss: 0.121786; batch adversarial loss: 0.546983\n",
      "epoch 41; iter: 0; batch classifier loss: 0.143063; batch adversarial loss: 0.397362\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116308; batch adversarial loss: 0.530363\n",
      "epoch 43; iter: 0; batch classifier loss: 0.137278; batch adversarial loss: 0.410962\n",
      "epoch 44; iter: 0; batch classifier loss: 0.143967; batch adversarial loss: 0.355448\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102628; batch adversarial loss: 0.428248\n",
      "epoch 46; iter: 0; batch classifier loss: 0.118302; batch adversarial loss: 0.490271\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112571; batch adversarial loss: 0.442210\n",
      "epoch 48; iter: 0; batch classifier loss: 0.097179; batch adversarial loss: 0.427694\n",
      "epoch 49; iter: 0; batch classifier loss: 0.086740; batch adversarial loss: 0.552255\n",
      "epoch 50; iter: 0; batch classifier loss: 0.115912; batch adversarial loss: 0.451276\n",
      "epoch 51; iter: 0; batch classifier loss: 0.091685; batch adversarial loss: 0.409229\n",
      "epoch 52; iter: 0; batch classifier loss: 0.109651; batch adversarial loss: 0.469491\n",
      "epoch 53; iter: 0; batch classifier loss: 0.129055; batch adversarial loss: 0.436917\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122147; batch adversarial loss: 0.490694\n",
      "epoch 55; iter: 0; batch classifier loss: 0.095293; batch adversarial loss: 0.423762\n",
      "epoch 56; iter: 0; batch classifier loss: 0.110348; batch adversarial loss: 0.505793\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112903; batch adversarial loss: 0.410094\n",
      "epoch 58; iter: 0; batch classifier loss: 0.112474; batch adversarial loss: 0.485970\n",
      "epoch 59; iter: 0; batch classifier loss: 0.142723; batch adversarial loss: 0.413865\n",
      "epoch 60; iter: 0; batch classifier loss: 0.146626; batch adversarial loss: 0.466392\n",
      "epoch 61; iter: 0; batch classifier loss: 0.086616; batch adversarial loss: 0.374379\n",
      "epoch 62; iter: 0; batch classifier loss: 0.126439; batch adversarial loss: 0.485806\n",
      "epoch 63; iter: 0; batch classifier loss: 0.098342; batch adversarial loss: 0.432625\n",
      "epoch 64; iter: 0; batch classifier loss: 0.079758; batch adversarial loss: 0.429730\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122322; batch adversarial loss: 0.459518\n",
      "epoch 66; iter: 0; batch classifier loss: 0.133341; batch adversarial loss: 0.460802\n",
      "epoch 67; iter: 0; batch classifier loss: 0.127052; batch adversarial loss: 0.350295\n",
      "epoch 68; iter: 0; batch classifier loss: 0.075165; batch adversarial loss: 0.443982\n",
      "epoch 69; iter: 0; batch classifier loss: 0.097906; batch adversarial loss: 0.367202\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079491; batch adversarial loss: 0.537634\n",
      "epoch 71; iter: 0; batch classifier loss: 0.091489; batch adversarial loss: 0.456577\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082262; batch adversarial loss: 0.498236\n",
      "epoch 73; iter: 0; batch classifier loss: 0.074560; batch adversarial loss: 0.385330\n",
      "epoch 74; iter: 0; batch classifier loss: 0.098034; batch adversarial loss: 0.510117\n",
      "epoch 75; iter: 0; batch classifier loss: 0.124237; batch adversarial loss: 0.427637\n",
      "epoch 76; iter: 0; batch classifier loss: 0.046413; batch adversarial loss: 0.531107\n",
      "epoch 77; iter: 0; batch classifier loss: 0.075988; batch adversarial loss: 0.418565\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079531; batch adversarial loss: 0.501112\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044917; batch adversarial loss: 0.503918\n",
      "epoch 80; iter: 0; batch classifier loss: 0.043997; batch adversarial loss: 0.418895\n",
      "epoch 81; iter: 0; batch classifier loss: 0.080356; batch adversarial loss: 0.461290\n",
      "epoch 82; iter: 0; batch classifier loss: 0.056929; batch adversarial loss: 0.502240\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083807; batch adversarial loss: 0.370985\n",
      "epoch 84; iter: 0; batch classifier loss: 0.108951; batch adversarial loss: 0.500715\n",
      "epoch 85; iter: 0; batch classifier loss: 0.063007; batch adversarial loss: 0.567723\n",
      "epoch 86; iter: 0; batch classifier loss: 0.080933; batch adversarial loss: 0.497188\n",
      "epoch 87; iter: 0; batch classifier loss: 0.097493; batch adversarial loss: 0.437701\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058723; batch adversarial loss: 0.485073\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069188; batch adversarial loss: 0.404079\n",
      "epoch 90; iter: 0; batch classifier loss: 0.043265; batch adversarial loss: 0.496796\n",
      "epoch 91; iter: 0; batch classifier loss: 0.079047; batch adversarial loss: 0.379557\n",
      "epoch 92; iter: 0; batch classifier loss: 0.103238; batch adversarial loss: 0.480550\n",
      "epoch 93; iter: 0; batch classifier loss: 0.066705; batch adversarial loss: 0.489336\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041234; batch adversarial loss: 0.517052\n",
      "epoch 95; iter: 0; batch classifier loss: 0.093728; batch adversarial loss: 0.367607\n",
      "epoch 96; iter: 0; batch classifier loss: 0.086341; batch adversarial loss: 0.494991\n",
      "epoch 97; iter: 0; batch classifier loss: 0.076096; batch adversarial loss: 0.374650\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054427; batch adversarial loss: 0.429425\n",
      "epoch 99; iter: 0; batch classifier loss: 0.035568; batch adversarial loss: 0.485303\n",
      "epoch 100; iter: 0; batch classifier loss: 0.085342; batch adversarial loss: 0.421380\n",
      "epoch 101; iter: 0; batch classifier loss: 0.076797; batch adversarial loss: 0.458139\n",
      "epoch 102; iter: 0; batch classifier loss: 0.061529; batch adversarial loss: 0.418665\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044832; batch adversarial loss: 0.572157\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071588; batch adversarial loss: 0.437219\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058463; batch adversarial loss: 0.466984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.062369; batch adversarial loss: 0.452087\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037562; batch adversarial loss: 0.468437\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067347; batch adversarial loss: 0.518565\n",
      "epoch 109; iter: 0; batch classifier loss: 0.083840; batch adversarial loss: 0.424808\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051056; batch adversarial loss: 0.478592\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044292; batch adversarial loss: 0.393621\n",
      "epoch 112; iter: 0; batch classifier loss: 0.085789; batch adversarial loss: 0.543851\n",
      "epoch 113; iter: 0; batch classifier loss: 0.026821; batch adversarial loss: 0.485683\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041840; batch adversarial loss: 0.500335\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042373; batch adversarial loss: 0.516483\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045827; batch adversarial loss: 0.501995\n",
      "epoch 117; iter: 0; batch classifier loss: 0.072385; batch adversarial loss: 0.418262\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047803; batch adversarial loss: 0.499294\n",
      "epoch 119; iter: 0; batch classifier loss: 0.085810; batch adversarial loss: 0.512634\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033816; batch adversarial loss: 0.436482\n",
      "epoch 121; iter: 0; batch classifier loss: 0.022973; batch adversarial loss: 0.419419\n",
      "epoch 122; iter: 0; batch classifier loss: 0.068695; batch adversarial loss: 0.582592\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049335; batch adversarial loss: 0.545076\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044498; batch adversarial loss: 0.417051\n",
      "epoch 125; iter: 0; batch classifier loss: 0.024459; batch adversarial loss: 0.503744\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043295; batch adversarial loss: 0.380634\n",
      "epoch 127; iter: 0; batch classifier loss: 0.057275; batch adversarial loss: 0.418989\n",
      "epoch 128; iter: 0; batch classifier loss: 0.013865; batch adversarial loss: 0.501823\n",
      "epoch 129; iter: 0; batch classifier loss: 0.055963; batch adversarial loss: 0.486237\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041867; batch adversarial loss: 0.404775\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029146; batch adversarial loss: 0.338928\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038718; batch adversarial loss: 0.492538\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053589; batch adversarial loss: 0.449245\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024600; batch adversarial loss: 0.487158\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042255; batch adversarial loss: 0.370544\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041632; batch adversarial loss: 0.422749\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054941; batch adversarial loss: 0.488644\n",
      "epoch 138; iter: 0; batch classifier loss: 0.083660; batch adversarial loss: 0.501418\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018723; batch adversarial loss: 0.450479\n",
      "epoch 140; iter: 0; batch classifier loss: 0.057178; batch adversarial loss: 0.545538\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039216; batch adversarial loss: 0.472645\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049240; batch adversarial loss: 0.405897\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027877; batch adversarial loss: 0.458997\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017518; batch adversarial loss: 0.473279\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014394; batch adversarial loss: 0.505087\n",
      "epoch 146; iter: 0; batch classifier loss: 0.036091; batch adversarial loss: 0.518542\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034487; batch adversarial loss: 0.432834\n",
      "epoch 148; iter: 0; batch classifier loss: 0.057003; batch adversarial loss: 0.388184\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022458; batch adversarial loss: 0.423405\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035014; batch adversarial loss: 0.441160\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020703; batch adversarial loss: 0.371764\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024213; batch adversarial loss: 0.451835\n",
      "epoch 153; iter: 0; batch classifier loss: 0.006017; batch adversarial loss: 0.446173\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021289; batch adversarial loss: 0.438167\n",
      "epoch 155; iter: 0; batch classifier loss: 0.008709; batch adversarial loss: 0.385256\n",
      "epoch 156; iter: 0; batch classifier loss: 0.008948; batch adversarial loss: 0.519328\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032282; batch adversarial loss: 0.471638\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035476; batch adversarial loss: 0.456486\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012044; batch adversarial loss: 0.433755\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027442; batch adversarial loss: 0.444001\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019317; batch adversarial loss: 0.483432\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028725; batch adversarial loss: 0.461199\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015206; batch adversarial loss: 0.483672\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026703; batch adversarial loss: 0.466647\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031180; batch adversarial loss: 0.514018\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040816; batch adversarial loss: 0.520853\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029331; batch adversarial loss: 0.482037\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024506; batch adversarial loss: 0.479497\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035272; batch adversarial loss: 0.459784\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028886; batch adversarial loss: 0.409239\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027268; batch adversarial loss: 0.505256\n",
      "epoch 172; iter: 0; batch classifier loss: 0.035762; batch adversarial loss: 0.516563\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020332; batch adversarial loss: 0.528692\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016925; batch adversarial loss: 0.425363\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025951; batch adversarial loss: 0.549809\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026584; batch adversarial loss: 0.472558\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022987; batch adversarial loss: 0.371260\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010999; batch adversarial loss: 0.387418\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019324; batch adversarial loss: 0.434839\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012495; batch adversarial loss: 0.508559\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014714; batch adversarial loss: 0.393842\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014715; batch adversarial loss: 0.407816\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005824; batch adversarial loss: 0.462819\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027892; batch adversarial loss: 0.473297\n",
      "epoch 185; iter: 0; batch classifier loss: 0.066916; batch adversarial loss: 0.496665\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032676; batch adversarial loss: 0.390054\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011039; batch adversarial loss: 0.440566\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024158; batch adversarial loss: 0.400130\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021919; batch adversarial loss: 0.523526\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025060; batch adversarial loss: 0.417801\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014489; batch adversarial loss: 0.428325\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040363; batch adversarial loss: 0.378315\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026018; batch adversarial loss: 0.495356\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020872; batch adversarial loss: 0.397860\n",
      "epoch 195; iter: 0; batch classifier loss: 0.035526; batch adversarial loss: 0.383946\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027961; batch adversarial loss: 0.439962\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024311; batch adversarial loss: 0.541734\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008945; batch adversarial loss: 0.442932\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027139; batch adversarial loss: 0.448128\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705703; batch adversarial loss: 0.637105\n",
      "epoch 1; iter: 0; batch classifier loss: 0.343373; batch adversarial loss: 0.632427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.374835; batch adversarial loss: 0.624627\n",
      "epoch 3; iter: 0; batch classifier loss: 0.337171; batch adversarial loss: 0.597140\n",
      "epoch 4; iter: 0; batch classifier loss: 0.378413; batch adversarial loss: 0.595564\n",
      "epoch 5; iter: 0; batch classifier loss: 0.447844; batch adversarial loss: 0.637794\n",
      "epoch 6; iter: 0; batch classifier loss: 0.527715; batch adversarial loss: 0.589574\n",
      "epoch 7; iter: 0; batch classifier loss: 0.531639; batch adversarial loss: 0.557082\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547687; batch adversarial loss: 0.546650\n",
      "epoch 9; iter: 0; batch classifier loss: 0.418620; batch adversarial loss: 0.539814\n",
      "epoch 10; iter: 0; batch classifier loss: 0.382768; batch adversarial loss: 0.525569\n",
      "epoch 11; iter: 0; batch classifier loss: 0.389640; batch adversarial loss: 0.530041\n",
      "epoch 12; iter: 0; batch classifier loss: 0.355250; batch adversarial loss: 0.464707\n",
      "epoch 13; iter: 0; batch classifier loss: 0.389965; batch adversarial loss: 0.517750\n",
      "epoch 14; iter: 0; batch classifier loss: 0.309920; batch adversarial loss: 0.455030\n",
      "epoch 15; iter: 0; batch classifier loss: 0.374583; batch adversarial loss: 0.444801\n",
      "epoch 16; iter: 0; batch classifier loss: 0.354630; batch adversarial loss: 0.477169\n",
      "epoch 17; iter: 0; batch classifier loss: 0.366299; batch adversarial loss: 0.507627\n",
      "epoch 18; iter: 0; batch classifier loss: 0.238011; batch adversarial loss: 0.527299\n",
      "epoch 19; iter: 0; batch classifier loss: 0.271240; batch adversarial loss: 0.522353\n",
      "epoch 20; iter: 0; batch classifier loss: 0.334076; batch adversarial loss: 0.487770\n",
      "epoch 21; iter: 0; batch classifier loss: 0.277878; batch adversarial loss: 0.474046\n",
      "epoch 22; iter: 0; batch classifier loss: 0.255564; batch adversarial loss: 0.509938\n",
      "epoch 23; iter: 0; batch classifier loss: 0.243538; batch adversarial loss: 0.442327\n",
      "epoch 24; iter: 0; batch classifier loss: 0.303268; batch adversarial loss: 0.485763\n",
      "epoch 25; iter: 0; batch classifier loss: 0.286298; batch adversarial loss: 0.393558\n",
      "epoch 26; iter: 0; batch classifier loss: 0.337018; batch adversarial loss: 0.522538\n",
      "epoch 27; iter: 0; batch classifier loss: 0.225902; batch adversarial loss: 0.515965\n",
      "epoch 28; iter: 0; batch classifier loss: 0.275924; batch adversarial loss: 0.424476\n",
      "epoch 29; iter: 0; batch classifier loss: 0.286515; batch adversarial loss: 0.362666\n",
      "epoch 30; iter: 0; batch classifier loss: 0.238267; batch adversarial loss: 0.479523\n",
      "epoch 31; iter: 0; batch classifier loss: 0.237444; batch adversarial loss: 0.422284\n",
      "epoch 32; iter: 0; batch classifier loss: 0.257017; batch adversarial loss: 0.466181\n",
      "epoch 33; iter: 0; batch classifier loss: 0.229884; batch adversarial loss: 0.441523\n",
      "epoch 34; iter: 0; batch classifier loss: 0.281814; batch adversarial loss: 0.486585\n",
      "epoch 35; iter: 0; batch classifier loss: 0.373444; batch adversarial loss: 0.495254\n",
      "epoch 36; iter: 0; batch classifier loss: 0.282829; batch adversarial loss: 0.393570\n",
      "epoch 37; iter: 0; batch classifier loss: 0.156572; batch adversarial loss: 0.480600\n",
      "epoch 38; iter: 0; batch classifier loss: 0.211697; batch adversarial loss: 0.455108\n",
      "epoch 39; iter: 0; batch classifier loss: 0.195766; batch adversarial loss: 0.497510\n",
      "epoch 40; iter: 0; batch classifier loss: 0.229757; batch adversarial loss: 0.430569\n",
      "epoch 41; iter: 0; batch classifier loss: 0.280530; batch adversarial loss: 0.402731\n",
      "epoch 42; iter: 0; batch classifier loss: 0.200945; batch adversarial loss: 0.564889\n",
      "epoch 43; iter: 0; batch classifier loss: 0.279041; batch adversarial loss: 0.390546\n",
      "epoch 44; iter: 0; batch classifier loss: 0.207475; batch adversarial loss: 0.458695\n",
      "epoch 45; iter: 0; batch classifier loss: 0.253063; batch adversarial loss: 0.535458\n",
      "epoch 46; iter: 0; batch classifier loss: 0.247609; batch adversarial loss: 0.339990\n",
      "epoch 47; iter: 0; batch classifier loss: 0.243458; batch adversarial loss: 0.461024\n",
      "epoch 48; iter: 0; batch classifier loss: 0.251704; batch adversarial loss: 0.484367\n",
      "epoch 49; iter: 0; batch classifier loss: 0.274434; batch adversarial loss: 0.459003\n",
      "epoch 50; iter: 0; batch classifier loss: 0.228369; batch adversarial loss: 0.459845\n",
      "epoch 51; iter: 0; batch classifier loss: 0.250211; batch adversarial loss: 0.447741\n",
      "epoch 52; iter: 0; batch classifier loss: 0.234752; batch adversarial loss: 0.362913\n",
      "epoch 53; iter: 0; batch classifier loss: 0.241436; batch adversarial loss: 0.458641\n",
      "epoch 54; iter: 0; batch classifier loss: 0.300927; batch adversarial loss: 0.385884\n",
      "epoch 55; iter: 0; batch classifier loss: 0.136619; batch adversarial loss: 0.482742\n",
      "epoch 56; iter: 0; batch classifier loss: 0.100407; batch adversarial loss: 0.431398\n",
      "epoch 57; iter: 0; batch classifier loss: 0.088387; batch adversarial loss: 0.401209\n",
      "epoch 58; iter: 0; batch classifier loss: 0.075029; batch adversarial loss: 0.362600\n",
      "epoch 59; iter: 0; batch classifier loss: 0.073118; batch adversarial loss: 0.432779\n",
      "epoch 60; iter: 0; batch classifier loss: 0.103410; batch adversarial loss: 0.508286\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080825; batch adversarial loss: 0.436565\n",
      "epoch 62; iter: 0; batch classifier loss: 0.046296; batch adversarial loss: 0.410269\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076305; batch adversarial loss: 0.473559\n",
      "epoch 64; iter: 0; batch classifier loss: 0.059426; batch adversarial loss: 0.437102\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070670; batch adversarial loss: 0.454661\n",
      "epoch 66; iter: 0; batch classifier loss: 0.069211; batch adversarial loss: 0.394900\n",
      "epoch 67; iter: 0; batch classifier loss: 0.086070; batch adversarial loss: 0.402911\n",
      "epoch 68; iter: 0; batch classifier loss: 0.042406; batch adversarial loss: 0.381730\n",
      "epoch 69; iter: 0; batch classifier loss: 0.039110; batch adversarial loss: 0.437475\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067088; batch adversarial loss: 0.407009\n",
      "epoch 71; iter: 0; batch classifier loss: 0.046787; batch adversarial loss: 0.391722\n",
      "epoch 72; iter: 0; batch classifier loss: 0.041011; batch adversarial loss: 0.434081\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065941; batch adversarial loss: 0.460886\n",
      "epoch 74; iter: 0; batch classifier loss: 0.031838; batch adversarial loss: 0.501484\n",
      "epoch 75; iter: 0; batch classifier loss: 0.062032; batch adversarial loss: 0.426099\n",
      "epoch 76; iter: 0; batch classifier loss: 0.040592; batch adversarial loss: 0.432051\n",
      "epoch 77; iter: 0; batch classifier loss: 0.030782; batch adversarial loss: 0.472634\n",
      "epoch 78; iter: 0; batch classifier loss: 0.046598; batch adversarial loss: 0.444233\n",
      "epoch 79; iter: 0; batch classifier loss: 0.027683; batch adversarial loss: 0.528458\n",
      "epoch 80; iter: 0; batch classifier loss: 0.073281; batch adversarial loss: 0.374188\n",
      "epoch 81; iter: 0; batch classifier loss: 0.021863; batch adversarial loss: 0.445951\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052964; batch adversarial loss: 0.509913\n",
      "epoch 83; iter: 0; batch classifier loss: 0.040212; batch adversarial loss: 0.392991\n",
      "epoch 84; iter: 0; batch classifier loss: 0.039707; batch adversarial loss: 0.456135\n",
      "epoch 85; iter: 0; batch classifier loss: 0.042663; batch adversarial loss: 0.474695\n",
      "epoch 86; iter: 0; batch classifier loss: 0.024599; batch adversarial loss: 0.494153\n",
      "epoch 87; iter: 0; batch classifier loss: 0.022012; batch adversarial loss: 0.531724\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057007; batch adversarial loss: 0.345252\n",
      "epoch 89; iter: 0; batch classifier loss: 0.026265; batch adversarial loss: 0.441876\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067307; batch adversarial loss: 0.398789\n",
      "epoch 91; iter: 0; batch classifier loss: 0.028841; batch adversarial loss: 0.490096\n",
      "epoch 92; iter: 0; batch classifier loss: 0.035780; batch adversarial loss: 0.462161\n",
      "epoch 93; iter: 0; batch classifier loss: 0.018180; batch adversarial loss: 0.415510\n",
      "epoch 94; iter: 0; batch classifier loss: 0.016637; batch adversarial loss: 0.456318\n",
      "epoch 95; iter: 0; batch classifier loss: 0.027110; batch adversarial loss: 0.474587\n",
      "epoch 96; iter: 0; batch classifier loss: 0.017221; batch adversarial loss: 0.520931\n",
      "epoch 97; iter: 0; batch classifier loss: 0.020830; batch adversarial loss: 0.469922\n",
      "epoch 98; iter: 0; batch classifier loss: 0.040316; batch adversarial loss: 0.427028\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039297; batch adversarial loss: 0.363856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.026430; batch adversarial loss: 0.396400\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061290; batch adversarial loss: 0.428231\n",
      "epoch 102; iter: 0; batch classifier loss: 0.025010; batch adversarial loss: 0.573646\n",
      "epoch 103; iter: 0; batch classifier loss: 0.026070; batch adversarial loss: 0.434807\n",
      "epoch 104; iter: 0; batch classifier loss: 0.022177; batch adversarial loss: 0.436294\n",
      "epoch 105; iter: 0; batch classifier loss: 0.033393; batch adversarial loss: 0.526374\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045819; batch adversarial loss: 0.415998\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024555; batch adversarial loss: 0.362130\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049361; batch adversarial loss: 0.384453\n",
      "epoch 109; iter: 0; batch classifier loss: 0.022620; batch adversarial loss: 0.439960\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031961; batch adversarial loss: 0.402994\n",
      "epoch 111; iter: 0; batch classifier loss: 0.018340; batch adversarial loss: 0.420214\n",
      "epoch 112; iter: 0; batch classifier loss: 0.018243; batch adversarial loss: 0.408458\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042384; batch adversarial loss: 0.485204\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043239; batch adversarial loss: 0.454591\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032620; batch adversarial loss: 0.487541\n",
      "epoch 116; iter: 0; batch classifier loss: 0.012370; batch adversarial loss: 0.377304\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038058; batch adversarial loss: 0.528603\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045515; batch adversarial loss: 0.464133\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035236; batch adversarial loss: 0.362321\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025489; batch adversarial loss: 0.525700\n",
      "epoch 121; iter: 0; batch classifier loss: 0.014667; batch adversarial loss: 0.487067\n",
      "epoch 122; iter: 0; batch classifier loss: 0.009992; batch adversarial loss: 0.462375\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028257; batch adversarial loss: 0.525266\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025582; batch adversarial loss: 0.471585\n",
      "epoch 125; iter: 0; batch classifier loss: 0.016585; batch adversarial loss: 0.408319\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027188; batch adversarial loss: 0.454016\n",
      "epoch 127; iter: 0; batch classifier loss: 0.012814; batch adversarial loss: 0.438490\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034478; batch adversarial loss: 0.469091\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040762; batch adversarial loss: 0.454168\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026707; batch adversarial loss: 0.414426\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020455; batch adversarial loss: 0.398684\n",
      "epoch 132; iter: 0; batch classifier loss: 0.018701; batch adversarial loss: 0.459051\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023110; batch adversarial loss: 0.421492\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027860; batch adversarial loss: 0.400496\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029504; batch adversarial loss: 0.456332\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035572; batch adversarial loss: 0.482456\n",
      "epoch 137; iter: 0; batch classifier loss: 0.016467; batch adversarial loss: 0.493643\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026057; batch adversarial loss: 0.463138\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040241; batch adversarial loss: 0.436535\n",
      "epoch 140; iter: 0; batch classifier loss: 0.014038; batch adversarial loss: 0.426766\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031175; batch adversarial loss: 0.493405\n",
      "epoch 142; iter: 0; batch classifier loss: 0.055252; batch adversarial loss: 0.481889\n",
      "epoch 143; iter: 0; batch classifier loss: 0.007066; batch adversarial loss: 0.451789\n",
      "epoch 144; iter: 0; batch classifier loss: 0.006431; batch adversarial loss: 0.320836\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024668; batch adversarial loss: 0.456779\n",
      "epoch 146; iter: 0; batch classifier loss: 0.008069; batch adversarial loss: 0.445346\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033433; batch adversarial loss: 0.421183\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023692; batch adversarial loss: 0.547674\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017989; batch adversarial loss: 0.475253\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036066; batch adversarial loss: 0.425128\n",
      "epoch 151; iter: 0; batch classifier loss: 0.061975; batch adversarial loss: 0.420186\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028930; batch adversarial loss: 0.455764\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017302; batch adversarial loss: 0.430450\n",
      "epoch 154; iter: 0; batch classifier loss: 0.052924; batch adversarial loss: 0.352645\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010910; batch adversarial loss: 0.398644\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020165; batch adversarial loss: 0.401565\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023720; batch adversarial loss: 0.469928\n",
      "epoch 158; iter: 0; batch classifier loss: 0.007376; batch adversarial loss: 0.435590\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029738; batch adversarial loss: 0.397728\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034032; batch adversarial loss: 0.522415\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033461; batch adversarial loss: 0.478460\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010929; batch adversarial loss: 0.424053\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016755; batch adversarial loss: 0.448748\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016713; batch adversarial loss: 0.417549\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028273; batch adversarial loss: 0.445833\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015360; batch adversarial loss: 0.495164\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015283; batch adversarial loss: 0.448161\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010051; batch adversarial loss: 0.453776\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016997; batch adversarial loss: 0.459793\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009949; batch adversarial loss: 0.531802\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018123; batch adversarial loss: 0.508156\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028534; batch adversarial loss: 0.438182\n",
      "epoch 173; iter: 0; batch classifier loss: 0.046104; batch adversarial loss: 0.368150\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040115; batch adversarial loss: 0.420624\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009163; batch adversarial loss: 0.493438\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022469; batch adversarial loss: 0.468862\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011505; batch adversarial loss: 0.414057\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029348; batch adversarial loss: 0.388546\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015502; batch adversarial loss: 0.398202\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006600; batch adversarial loss: 0.456361\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028495; batch adversarial loss: 0.388519\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019094; batch adversarial loss: 0.406478\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034252; batch adversarial loss: 0.471665\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032681; batch adversarial loss: 0.400507\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026919; batch adversarial loss: 0.454720\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019450; batch adversarial loss: 0.403626\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027995; batch adversarial loss: 0.399644\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014619; batch adversarial loss: 0.484713\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021980; batch adversarial loss: 0.438553\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022209; batch adversarial loss: 0.471388\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029649; batch adversarial loss: 0.495334\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020258; batch adversarial loss: 0.415860\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010545; batch adversarial loss: 0.412133\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016193; batch adversarial loss: 0.439239\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024291; batch adversarial loss: 0.534034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.014175; batch adversarial loss: 0.380010\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018141; batch adversarial loss: 0.418810\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027773; batch adversarial loss: 0.546198\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010767; batch adversarial loss: 0.474673\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687425; batch adversarial loss: 0.822376\n",
      "epoch 1; iter: 0; batch classifier loss: 0.732672; batch adversarial loss: 0.900078\n",
      "epoch 2; iter: 0; batch classifier loss: 0.799240; batch adversarial loss: 0.858614\n",
      "epoch 3; iter: 0; batch classifier loss: 0.950456; batch adversarial loss: 0.884319\n",
      "epoch 4; iter: 0; batch classifier loss: 0.734553; batch adversarial loss: 0.726398\n",
      "epoch 5; iter: 0; batch classifier loss: 0.566240; batch adversarial loss: 0.641719\n",
      "epoch 6; iter: 0; batch classifier loss: 0.614896; batch adversarial loss: 0.647104\n",
      "epoch 7; iter: 0; batch classifier loss: 0.446143; batch adversarial loss: 0.557017\n",
      "epoch 8; iter: 0; batch classifier loss: 0.391051; batch adversarial loss: 0.568708\n",
      "epoch 9; iter: 0; batch classifier loss: 0.306955; batch adversarial loss: 0.518857\n",
      "epoch 10; iter: 0; batch classifier loss: 0.263601; batch adversarial loss: 0.510771\n",
      "epoch 11; iter: 0; batch classifier loss: 0.295067; batch adversarial loss: 0.486298\n",
      "epoch 12; iter: 0; batch classifier loss: 0.289725; batch adversarial loss: 0.612584\n",
      "epoch 13; iter: 0; batch classifier loss: 0.285803; batch adversarial loss: 0.538928\n",
      "epoch 14; iter: 0; batch classifier loss: 0.248259; batch adversarial loss: 0.515624\n",
      "epoch 15; iter: 0; batch classifier loss: 0.292615; batch adversarial loss: 0.499432\n",
      "epoch 16; iter: 0; batch classifier loss: 0.303025; batch adversarial loss: 0.512395\n",
      "epoch 17; iter: 0; batch classifier loss: 0.231979; batch adversarial loss: 0.515823\n",
      "epoch 18; iter: 0; batch classifier loss: 0.264643; batch adversarial loss: 0.597030\n",
      "epoch 19; iter: 0; batch classifier loss: 0.212232; batch adversarial loss: 0.523268\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220065; batch adversarial loss: 0.446340\n",
      "epoch 21; iter: 0; batch classifier loss: 0.195711; batch adversarial loss: 0.549443\n",
      "epoch 22; iter: 0; batch classifier loss: 0.168359; batch adversarial loss: 0.486089\n",
      "epoch 23; iter: 0; batch classifier loss: 0.188552; batch adversarial loss: 0.478593\n",
      "epoch 24; iter: 0; batch classifier loss: 0.167589; batch adversarial loss: 0.483565\n",
      "epoch 25; iter: 0; batch classifier loss: 0.186778; batch adversarial loss: 0.522569\n",
      "epoch 26; iter: 0; batch classifier loss: 0.158020; batch adversarial loss: 0.524731\n",
      "epoch 27; iter: 0; batch classifier loss: 0.210262; batch adversarial loss: 0.508287\n",
      "epoch 28; iter: 0; batch classifier loss: 0.136063; batch adversarial loss: 0.469313\n",
      "epoch 29; iter: 0; batch classifier loss: 0.182107; batch adversarial loss: 0.355991\n",
      "epoch 30; iter: 0; batch classifier loss: 0.152744; batch adversarial loss: 0.415889\n",
      "epoch 31; iter: 0; batch classifier loss: 0.111754; batch adversarial loss: 0.437497\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165068; batch adversarial loss: 0.435408\n",
      "epoch 33; iter: 0; batch classifier loss: 0.128516; batch adversarial loss: 0.454911\n",
      "epoch 34; iter: 0; batch classifier loss: 0.164117; batch adversarial loss: 0.461216\n",
      "epoch 35; iter: 0; batch classifier loss: 0.217927; batch adversarial loss: 0.339051\n",
      "epoch 36; iter: 0; batch classifier loss: 0.173093; batch adversarial loss: 0.435242\n",
      "epoch 37; iter: 0; batch classifier loss: 0.140964; batch adversarial loss: 0.542955\n",
      "epoch 38; iter: 0; batch classifier loss: 0.094191; batch adversarial loss: 0.485337\n",
      "epoch 39; iter: 0; batch classifier loss: 0.087823; batch adversarial loss: 0.429299\n",
      "epoch 40; iter: 0; batch classifier loss: 0.067947; batch adversarial loss: 0.579076\n",
      "epoch 41; iter: 0; batch classifier loss: 0.135934; batch adversarial loss: 0.457872\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116193; batch adversarial loss: 0.473841\n",
      "epoch 43; iter: 0; batch classifier loss: 0.103681; batch adversarial loss: 0.522112\n",
      "epoch 44; iter: 0; batch classifier loss: 0.078261; batch adversarial loss: 0.442477\n",
      "epoch 45; iter: 0; batch classifier loss: 0.111410; batch adversarial loss: 0.437482\n",
      "epoch 46; iter: 0; batch classifier loss: 0.149062; batch adversarial loss: 0.426194\n",
      "epoch 47; iter: 0; batch classifier loss: 0.086902; batch adversarial loss: 0.411070\n",
      "epoch 48; iter: 0; batch classifier loss: 0.140874; batch adversarial loss: 0.430324\n",
      "epoch 49; iter: 0; batch classifier loss: 0.096980; batch adversarial loss: 0.468070\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098647; batch adversarial loss: 0.329749\n",
      "epoch 51; iter: 0; batch classifier loss: 0.125291; batch adversarial loss: 0.437676\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103491; batch adversarial loss: 0.407246\n",
      "epoch 53; iter: 0; batch classifier loss: 0.102058; batch adversarial loss: 0.553044\n",
      "epoch 54; iter: 0; batch classifier loss: 0.033299; batch adversarial loss: 0.445459\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086554; batch adversarial loss: 0.405964\n",
      "epoch 56; iter: 0; batch classifier loss: 0.089845; batch adversarial loss: 0.529315\n",
      "epoch 57; iter: 0; batch classifier loss: 0.084231; batch adversarial loss: 0.460991\n",
      "epoch 58; iter: 0; batch classifier loss: 0.084187; batch adversarial loss: 0.517387\n",
      "epoch 59; iter: 0; batch classifier loss: 0.106276; batch adversarial loss: 0.364558\n",
      "epoch 60; iter: 0; batch classifier loss: 0.084313; batch adversarial loss: 0.483988\n",
      "epoch 61; iter: 0; batch classifier loss: 0.061497; batch adversarial loss: 0.410636\n",
      "epoch 62; iter: 0; batch classifier loss: 0.075192; batch adversarial loss: 0.559672\n",
      "epoch 63; iter: 0; batch classifier loss: 0.071202; batch adversarial loss: 0.399433\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106074; batch adversarial loss: 0.466324\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088796; batch adversarial loss: 0.504234\n",
      "epoch 66; iter: 0; batch classifier loss: 0.125986; batch adversarial loss: 0.389991\n",
      "epoch 67; iter: 0; batch classifier loss: 0.090579; batch adversarial loss: 0.435401\n",
      "epoch 68; iter: 0; batch classifier loss: 0.100622; batch adversarial loss: 0.421143\n",
      "epoch 69; iter: 0; batch classifier loss: 0.067066; batch adversarial loss: 0.500983\n",
      "epoch 70; iter: 0; batch classifier loss: 0.096523; batch adversarial loss: 0.438847\n",
      "epoch 71; iter: 0; batch classifier loss: 0.095729; batch adversarial loss: 0.538301\n",
      "epoch 72; iter: 0; batch classifier loss: 0.076310; batch adversarial loss: 0.539968\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085009; batch adversarial loss: 0.429307\n",
      "epoch 74; iter: 0; batch classifier loss: 0.058273; batch adversarial loss: 0.502375\n",
      "epoch 75; iter: 0; batch classifier loss: 0.072787; batch adversarial loss: 0.466191\n",
      "epoch 76; iter: 0; batch classifier loss: 0.106441; batch adversarial loss: 0.432366\n",
      "epoch 77; iter: 0; batch classifier loss: 0.089883; batch adversarial loss: 0.477687\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071429; batch adversarial loss: 0.486973\n",
      "epoch 79; iter: 0; batch classifier loss: 0.093734; batch adversarial loss: 0.441752\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068223; batch adversarial loss: 0.445677\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075077; batch adversarial loss: 0.455054\n",
      "epoch 82; iter: 0; batch classifier loss: 0.080204; batch adversarial loss: 0.431250\n",
      "epoch 83; iter: 0; batch classifier loss: 0.099314; batch adversarial loss: 0.492735\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062918; batch adversarial loss: 0.387159\n",
      "epoch 85; iter: 0; batch classifier loss: 0.060336; batch adversarial loss: 0.420925\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053039; batch adversarial loss: 0.539981\n",
      "epoch 87; iter: 0; batch classifier loss: 0.060649; batch adversarial loss: 0.423453\n",
      "epoch 88; iter: 0; batch classifier loss: 0.039273; batch adversarial loss: 0.403222\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050908; batch adversarial loss: 0.548139\n",
      "epoch 90; iter: 0; batch classifier loss: 0.058283; batch adversarial loss: 0.411131\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045389; batch adversarial loss: 0.411837\n",
      "epoch 92; iter: 0; batch classifier loss: 0.091801; batch adversarial loss: 0.455537\n",
      "epoch 93; iter: 0; batch classifier loss: 0.022645; batch adversarial loss: 0.400677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.069501; batch adversarial loss: 0.450500\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048239; batch adversarial loss: 0.533259\n",
      "epoch 96; iter: 0; batch classifier loss: 0.061861; batch adversarial loss: 0.545975\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051004; batch adversarial loss: 0.467035\n",
      "epoch 98; iter: 0; batch classifier loss: 0.028973; batch adversarial loss: 0.446614\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040869; batch adversarial loss: 0.438857\n",
      "epoch 100; iter: 0; batch classifier loss: 0.025917; batch adversarial loss: 0.527860\n",
      "epoch 101; iter: 0; batch classifier loss: 0.059659; batch adversarial loss: 0.410859\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038257; batch adversarial loss: 0.441934\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066648; batch adversarial loss: 0.461268\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038731; batch adversarial loss: 0.494283\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056829; batch adversarial loss: 0.476666\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058862; batch adversarial loss: 0.376986\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035774; batch adversarial loss: 0.392646\n",
      "epoch 108; iter: 0; batch classifier loss: 0.017595; batch adversarial loss: 0.480881\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039036; batch adversarial loss: 0.483438\n",
      "epoch 110; iter: 0; batch classifier loss: 0.016605; batch adversarial loss: 0.417047\n",
      "epoch 111; iter: 0; batch classifier loss: 0.018785; batch adversarial loss: 0.495542\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031054; batch adversarial loss: 0.437712\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029340; batch adversarial loss: 0.403043\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036997; batch adversarial loss: 0.489986\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042500; batch adversarial loss: 0.499248\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028110; batch adversarial loss: 0.472760\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038860; batch adversarial loss: 0.471682\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035119; batch adversarial loss: 0.356089\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073585; batch adversarial loss: 0.466638\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054624; batch adversarial loss: 0.484608\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029947; batch adversarial loss: 0.400629\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039711; batch adversarial loss: 0.464528\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049152; batch adversarial loss: 0.488253\n",
      "epoch 124; iter: 0; batch classifier loss: 0.028264; batch adversarial loss: 0.449575\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023609; batch adversarial loss: 0.462110\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028565; batch adversarial loss: 0.506139\n",
      "epoch 127; iter: 0; batch classifier loss: 0.017940; batch adversarial loss: 0.463373\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029640; batch adversarial loss: 0.535103\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051371; batch adversarial loss: 0.389076\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023101; batch adversarial loss: 0.454563\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023410; batch adversarial loss: 0.422580\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029886; batch adversarial loss: 0.419802\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019829; batch adversarial loss: 0.455107\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023596; batch adversarial loss: 0.479151\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030816; batch adversarial loss: 0.415877\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021110; batch adversarial loss: 0.435389\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029970; batch adversarial loss: 0.509603\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048039; batch adversarial loss: 0.464815\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026683; batch adversarial loss: 0.361790\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024460; batch adversarial loss: 0.526520\n",
      "epoch 141; iter: 0; batch classifier loss: 0.058786; batch adversarial loss: 0.451875\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013434; batch adversarial loss: 0.454556\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016231; batch adversarial loss: 0.450718\n",
      "epoch 144; iter: 0; batch classifier loss: 0.053995; batch adversarial loss: 0.465375\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021657; batch adversarial loss: 0.418574\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032009; batch adversarial loss: 0.544095\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036720; batch adversarial loss: 0.372199\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027966; batch adversarial loss: 0.532469\n",
      "epoch 149; iter: 0; batch classifier loss: 0.077837; batch adversarial loss: 0.401989\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054300; batch adversarial loss: 0.436568\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014556; batch adversarial loss: 0.521632\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016465; batch adversarial loss: 0.484701\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013639; batch adversarial loss: 0.501724\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028573; batch adversarial loss: 0.404453\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017818; batch adversarial loss: 0.387400\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036078; batch adversarial loss: 0.393026\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034070; batch adversarial loss: 0.462589\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029281; batch adversarial loss: 0.524482\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013008; batch adversarial loss: 0.486180\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030577; batch adversarial loss: 0.458530\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016352; batch adversarial loss: 0.476218\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012148; batch adversarial loss: 0.435248\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023023; batch adversarial loss: 0.414124\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012163; batch adversarial loss: 0.528398\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023649; batch adversarial loss: 0.539914\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020288; batch adversarial loss: 0.507198\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020053; batch adversarial loss: 0.455520\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017742; batch adversarial loss: 0.461299\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036891; batch adversarial loss: 0.424628\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025636; batch adversarial loss: 0.422501\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022835; batch adversarial loss: 0.467229\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013958; batch adversarial loss: 0.426085\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023040; batch adversarial loss: 0.484478\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008640; batch adversarial loss: 0.432396\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020697; batch adversarial loss: 0.489663\n",
      "epoch 176; iter: 0; batch classifier loss: 0.006779; batch adversarial loss: 0.442737\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019617; batch adversarial loss: 0.504004\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019844; batch adversarial loss: 0.360468\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020983; batch adversarial loss: 0.417645\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025593; batch adversarial loss: 0.439397\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018911; batch adversarial loss: 0.564565\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028090; batch adversarial loss: 0.599907\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023995; batch adversarial loss: 0.409359\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016209; batch adversarial loss: 0.493846\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010940; batch adversarial loss: 0.425068\n",
      "epoch 186; iter: 0; batch classifier loss: 0.003124; batch adversarial loss: 0.434767\n",
      "epoch 187; iter: 0; batch classifier loss: 0.047309; batch adversarial loss: 0.507242\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012675; batch adversarial loss: 0.446729\n",
      "epoch 189; iter: 0; batch classifier loss: 0.039981; batch adversarial loss: 0.426176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.021681; batch adversarial loss: 0.365947\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020579; batch adversarial loss: 0.478634\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016562; batch adversarial loss: 0.376394\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020253; batch adversarial loss: 0.382768\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018720; batch adversarial loss: 0.444843\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010084; batch adversarial loss: 0.412451\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013575; batch adversarial loss: 0.531959\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012243; batch adversarial loss: 0.452330\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020977; batch adversarial loss: 0.454251\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030036; batch adversarial loss: 0.406328\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710166; batch adversarial loss: 0.785138\n",
      "epoch 1; iter: 0; batch classifier loss: 0.474942; batch adversarial loss: 0.726659\n",
      "epoch 2; iter: 0; batch classifier loss: 0.462095; batch adversarial loss: 0.696819\n",
      "epoch 3; iter: 0; batch classifier loss: 0.431871; batch adversarial loss: 0.657809\n",
      "epoch 4; iter: 0; batch classifier loss: 0.386064; batch adversarial loss: 0.616158\n",
      "epoch 5; iter: 0; batch classifier loss: 0.352379; batch adversarial loss: 0.576059\n",
      "epoch 6; iter: 0; batch classifier loss: 0.378727; batch adversarial loss: 0.575518\n",
      "epoch 7; iter: 0; batch classifier loss: 0.312943; batch adversarial loss: 0.565720\n",
      "epoch 8; iter: 0; batch classifier loss: 0.294941; batch adversarial loss: 0.576991\n",
      "epoch 9; iter: 0; batch classifier loss: 0.323334; batch adversarial loss: 0.521316\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374729; batch adversarial loss: 0.531912\n",
      "epoch 11; iter: 0; batch classifier loss: 0.396679; batch adversarial loss: 0.534856\n",
      "epoch 12; iter: 0; batch classifier loss: 0.441682; batch adversarial loss: 0.501298\n",
      "epoch 13; iter: 0; batch classifier loss: 0.469129; batch adversarial loss: 0.520896\n",
      "epoch 14; iter: 0; batch classifier loss: 0.371139; batch adversarial loss: 0.530262\n",
      "epoch 15; iter: 0; batch classifier loss: 0.434959; batch adversarial loss: 0.491734\n",
      "epoch 16; iter: 0; batch classifier loss: 0.359483; batch adversarial loss: 0.567397\n",
      "epoch 17; iter: 0; batch classifier loss: 0.369689; batch adversarial loss: 0.498112\n",
      "epoch 18; iter: 0; batch classifier loss: 0.316064; batch adversarial loss: 0.504344\n",
      "epoch 19; iter: 0; batch classifier loss: 0.324567; batch adversarial loss: 0.480241\n",
      "epoch 20; iter: 0; batch classifier loss: 0.262903; batch adversarial loss: 0.484881\n",
      "epoch 21; iter: 0; batch classifier loss: 0.310414; batch adversarial loss: 0.462964\n",
      "epoch 22; iter: 0; batch classifier loss: 0.309726; batch adversarial loss: 0.502349\n",
      "epoch 23; iter: 0; batch classifier loss: 0.255602; batch adversarial loss: 0.461557\n",
      "epoch 24; iter: 0; batch classifier loss: 0.222424; batch adversarial loss: 0.500665\n",
      "epoch 25; iter: 0; batch classifier loss: 0.168049; batch adversarial loss: 0.415438\n",
      "epoch 26; iter: 0; batch classifier loss: 0.229045; batch adversarial loss: 0.464847\n",
      "epoch 27; iter: 0; batch classifier loss: 0.227857; batch adversarial loss: 0.543150\n",
      "epoch 28; iter: 0; batch classifier loss: 0.238677; batch adversarial loss: 0.437632\n",
      "epoch 29; iter: 0; batch classifier loss: 0.279690; batch adversarial loss: 0.448661\n",
      "epoch 30; iter: 0; batch classifier loss: 0.226994; batch adversarial loss: 0.456036\n",
      "epoch 31; iter: 0; batch classifier loss: 0.211951; batch adversarial loss: 0.425768\n",
      "epoch 32; iter: 0; batch classifier loss: 0.187765; batch adversarial loss: 0.421111\n",
      "epoch 33; iter: 0; batch classifier loss: 0.142694; batch adversarial loss: 0.396305\n",
      "epoch 34; iter: 0; batch classifier loss: 0.186696; batch adversarial loss: 0.480570\n",
      "epoch 35; iter: 0; batch classifier loss: 0.128309; batch adversarial loss: 0.447967\n",
      "epoch 36; iter: 0; batch classifier loss: 0.131512; batch adversarial loss: 0.427774\n",
      "epoch 37; iter: 0; batch classifier loss: 0.123353; batch adversarial loss: 0.513026\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127083; batch adversarial loss: 0.411801\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132818; batch adversarial loss: 0.523264\n",
      "epoch 40; iter: 0; batch classifier loss: 0.105854; batch adversarial loss: 0.409125\n",
      "epoch 41; iter: 0; batch classifier loss: 0.110402; batch adversarial loss: 0.445036\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116162; batch adversarial loss: 0.438393\n",
      "epoch 43; iter: 0; batch classifier loss: 0.068980; batch adversarial loss: 0.437080\n",
      "epoch 44; iter: 0; batch classifier loss: 0.095228; batch adversarial loss: 0.463748\n",
      "epoch 45; iter: 0; batch classifier loss: 0.123594; batch adversarial loss: 0.440329\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102256; batch adversarial loss: 0.465581\n",
      "epoch 47; iter: 0; batch classifier loss: 0.123246; batch adversarial loss: 0.541212\n",
      "epoch 48; iter: 0; batch classifier loss: 0.116199; batch adversarial loss: 0.472600\n",
      "epoch 49; iter: 0; batch classifier loss: 0.132809; batch adversarial loss: 0.435065\n",
      "epoch 50; iter: 0; batch classifier loss: 0.059330; batch adversarial loss: 0.431701\n",
      "epoch 51; iter: 0; batch classifier loss: 0.091886; batch adversarial loss: 0.513884\n",
      "epoch 52; iter: 0; batch classifier loss: 0.042852; batch adversarial loss: 0.525903\n",
      "epoch 53; iter: 0; batch classifier loss: 0.070373; batch adversarial loss: 0.479102\n",
      "epoch 54; iter: 0; batch classifier loss: 0.119528; batch adversarial loss: 0.519641\n",
      "epoch 55; iter: 0; batch classifier loss: 0.082463; batch adversarial loss: 0.485185\n",
      "epoch 56; iter: 0; batch classifier loss: 0.094264; batch adversarial loss: 0.464346\n",
      "epoch 57; iter: 0; batch classifier loss: 0.122263; batch adversarial loss: 0.493677\n",
      "epoch 58; iter: 0; batch classifier loss: 0.079343; batch adversarial loss: 0.380188\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070470; batch adversarial loss: 0.376571\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072848; batch adversarial loss: 0.452227\n",
      "epoch 61; iter: 0; batch classifier loss: 0.062606; batch adversarial loss: 0.427973\n",
      "epoch 62; iter: 0; batch classifier loss: 0.056971; batch adversarial loss: 0.378350\n",
      "epoch 63; iter: 0; batch classifier loss: 0.084089; batch adversarial loss: 0.465308\n",
      "epoch 64; iter: 0; batch classifier loss: 0.095805; batch adversarial loss: 0.376696\n",
      "epoch 65; iter: 0; batch classifier loss: 0.054818; batch adversarial loss: 0.406527\n",
      "epoch 66; iter: 0; batch classifier loss: 0.049815; batch adversarial loss: 0.478330\n",
      "epoch 67; iter: 0; batch classifier loss: 0.054851; batch adversarial loss: 0.485168\n",
      "epoch 68; iter: 0; batch classifier loss: 0.074797; batch adversarial loss: 0.452356\n",
      "epoch 69; iter: 0; batch classifier loss: 0.113114; batch adversarial loss: 0.434605\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078382; batch adversarial loss: 0.399881\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058555; batch adversarial loss: 0.364829\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080362; batch adversarial loss: 0.441562\n",
      "epoch 73; iter: 0; batch classifier loss: 0.052713; batch adversarial loss: 0.423012\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053800; batch adversarial loss: 0.419839\n",
      "epoch 75; iter: 0; batch classifier loss: 0.091151; batch adversarial loss: 0.341425\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060054; batch adversarial loss: 0.477023\n",
      "epoch 77; iter: 0; batch classifier loss: 0.059461; batch adversarial loss: 0.469254\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080756; batch adversarial loss: 0.462298\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063097; batch adversarial loss: 0.453025\n",
      "epoch 80; iter: 0; batch classifier loss: 0.044591; batch adversarial loss: 0.432715\n",
      "epoch 81; iter: 0; batch classifier loss: 0.077803; batch adversarial loss: 0.463093\n",
      "epoch 82; iter: 0; batch classifier loss: 0.042954; batch adversarial loss: 0.484404\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070037; batch adversarial loss: 0.415944\n",
      "epoch 84; iter: 0; batch classifier loss: 0.038139; batch adversarial loss: 0.433384\n",
      "epoch 85; iter: 0; batch classifier loss: 0.041873; batch adversarial loss: 0.495417\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076854; batch adversarial loss: 0.508174\n",
      "epoch 87; iter: 0; batch classifier loss: 0.034972; batch adversarial loss: 0.439741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.051729; batch adversarial loss: 0.404039\n",
      "epoch 89; iter: 0; batch classifier loss: 0.046395; batch adversarial loss: 0.462861\n",
      "epoch 90; iter: 0; batch classifier loss: 0.035234; batch adversarial loss: 0.526465\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062939; batch adversarial loss: 0.551294\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044658; batch adversarial loss: 0.372324\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044660; batch adversarial loss: 0.400936\n",
      "epoch 94; iter: 0; batch classifier loss: 0.045779; batch adversarial loss: 0.419239\n",
      "epoch 95; iter: 0; batch classifier loss: 0.041797; batch adversarial loss: 0.475472\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055813; batch adversarial loss: 0.489076\n",
      "epoch 97; iter: 0; batch classifier loss: 0.040864; batch adversarial loss: 0.417411\n",
      "epoch 98; iter: 0; batch classifier loss: 0.015458; batch adversarial loss: 0.502841\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049191; batch adversarial loss: 0.445277\n",
      "epoch 100; iter: 0; batch classifier loss: 0.052516; batch adversarial loss: 0.580241\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075890; batch adversarial loss: 0.388875\n",
      "epoch 102; iter: 0; batch classifier loss: 0.023926; batch adversarial loss: 0.530387\n",
      "epoch 103; iter: 0; batch classifier loss: 0.029115; batch adversarial loss: 0.438908\n",
      "epoch 104; iter: 0; batch classifier loss: 0.024980; batch adversarial loss: 0.529898\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034562; batch adversarial loss: 0.472427\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051190; batch adversarial loss: 0.518387\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041307; batch adversarial loss: 0.461688\n",
      "epoch 108; iter: 0; batch classifier loss: 0.032243; batch adversarial loss: 0.458113\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039765; batch adversarial loss: 0.448682\n",
      "epoch 110; iter: 0; batch classifier loss: 0.054436; batch adversarial loss: 0.398751\n",
      "epoch 111; iter: 0; batch classifier loss: 0.022627; batch adversarial loss: 0.561098\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037489; batch adversarial loss: 0.419505\n",
      "epoch 113; iter: 0; batch classifier loss: 0.031168; batch adversarial loss: 0.462290\n",
      "epoch 114; iter: 0; batch classifier loss: 0.018636; batch adversarial loss: 0.463254\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027938; batch adversarial loss: 0.495740\n",
      "epoch 116; iter: 0; batch classifier loss: 0.017998; batch adversarial loss: 0.434276\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037001; batch adversarial loss: 0.437819\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044051; batch adversarial loss: 0.433876\n",
      "epoch 119; iter: 0; batch classifier loss: 0.010269; batch adversarial loss: 0.437129\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038205; batch adversarial loss: 0.552950\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030179; batch adversarial loss: 0.443931\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045468; batch adversarial loss: 0.502257\n",
      "epoch 123; iter: 0; batch classifier loss: 0.011871; batch adversarial loss: 0.357163\n",
      "epoch 124; iter: 0; batch classifier loss: 0.015061; batch adversarial loss: 0.516923\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028223; batch adversarial loss: 0.488675\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034921; batch adversarial loss: 0.464502\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029961; batch adversarial loss: 0.489989\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034299; batch adversarial loss: 0.497870\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030292; batch adversarial loss: 0.533054\n",
      "epoch 130; iter: 0; batch classifier loss: 0.013414; batch adversarial loss: 0.410492\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029462; batch adversarial loss: 0.407188\n",
      "epoch 132; iter: 0; batch classifier loss: 0.010372; batch adversarial loss: 0.418225\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035985; batch adversarial loss: 0.399041\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019061; batch adversarial loss: 0.448255\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012099; batch adversarial loss: 0.376575\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020343; batch adversarial loss: 0.533135\n",
      "epoch 137; iter: 0; batch classifier loss: 0.019962; batch adversarial loss: 0.455878\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037741; batch adversarial loss: 0.484963\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014702; batch adversarial loss: 0.419219\n",
      "epoch 140; iter: 0; batch classifier loss: 0.015066; batch adversarial loss: 0.436750\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029254; batch adversarial loss: 0.472007\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043570; batch adversarial loss: 0.505541\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032322; batch adversarial loss: 0.428834\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026575; batch adversarial loss: 0.365081\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032311; batch adversarial loss: 0.439339\n",
      "epoch 146; iter: 0; batch classifier loss: 0.006690; batch adversarial loss: 0.394948\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015426; batch adversarial loss: 0.455703\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016978; batch adversarial loss: 0.450914\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013572; batch adversarial loss: 0.427615\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031669; batch adversarial loss: 0.552507\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048608; batch adversarial loss: 0.318478\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026427; batch adversarial loss: 0.471676\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013977; batch adversarial loss: 0.437762\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046545; batch adversarial loss: 0.394389\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017133; batch adversarial loss: 0.457057\n",
      "epoch 156; iter: 0; batch classifier loss: 0.065089; batch adversarial loss: 0.447338\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016257; batch adversarial loss: 0.437879\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023748; batch adversarial loss: 0.476461\n",
      "epoch 159; iter: 0; batch classifier loss: 0.041560; batch adversarial loss: 0.398051\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017641; batch adversarial loss: 0.468296\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022315; batch adversarial loss: 0.451540\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043896; batch adversarial loss: 0.574364\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025981; batch adversarial loss: 0.567080\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037696; batch adversarial loss: 0.418414\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011704; batch adversarial loss: 0.423114\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017639; batch adversarial loss: 0.484245\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006609; batch adversarial loss: 0.550818\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032561; batch adversarial loss: 0.418939\n",
      "epoch 169; iter: 0; batch classifier loss: 0.002657; batch adversarial loss: 0.482681\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027166; batch adversarial loss: 0.530106\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011467; batch adversarial loss: 0.394792\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016126; batch adversarial loss: 0.457980\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019813; batch adversarial loss: 0.485929\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013517; batch adversarial loss: 0.544167\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013420; batch adversarial loss: 0.428857\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012398; batch adversarial loss: 0.502589\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033624; batch adversarial loss: 0.402136\n",
      "epoch 178; iter: 0; batch classifier loss: 0.047584; batch adversarial loss: 0.427302\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027391; batch adversarial loss: 0.400233\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020103; batch adversarial loss: 0.477365\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014107; batch adversarial loss: 0.393685\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015941; batch adversarial loss: 0.390887\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025885; batch adversarial loss: 0.455831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.035091; batch adversarial loss: 0.428572\n",
      "epoch 185; iter: 0; batch classifier loss: 0.034548; batch adversarial loss: 0.514512\n",
      "epoch 186; iter: 0; batch classifier loss: 0.042188; batch adversarial loss: 0.422804\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011723; batch adversarial loss: 0.493011\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008199; batch adversarial loss: 0.422151\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027384; batch adversarial loss: 0.371215\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013168; batch adversarial loss: 0.528805\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025085; batch adversarial loss: 0.469125\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020701; batch adversarial loss: 0.407552\n",
      "epoch 193; iter: 0; batch classifier loss: 0.049891; batch adversarial loss: 0.418005\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027529; batch adversarial loss: 0.418765\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012330; batch adversarial loss: 0.439928\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012285; batch adversarial loss: 0.387699\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005629; batch adversarial loss: 0.463509\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007203; batch adversarial loss: 0.405914\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033512; batch adversarial loss: 0.383408\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673250; batch adversarial loss: 0.725894\n",
      "epoch 1; iter: 0; batch classifier loss: 0.479240; batch adversarial loss: 0.683448\n",
      "epoch 2; iter: 0; batch classifier loss: 0.466291; batch adversarial loss: 0.683913\n",
      "epoch 3; iter: 0; batch classifier loss: 0.405856; batch adversarial loss: 0.662219\n",
      "epoch 4; iter: 0; batch classifier loss: 0.374233; batch adversarial loss: 0.593697\n",
      "epoch 5; iter: 0; batch classifier loss: 0.310882; batch adversarial loss: 0.578596\n",
      "epoch 6; iter: 0; batch classifier loss: 0.321526; batch adversarial loss: 0.542201\n",
      "epoch 7; iter: 0; batch classifier loss: 0.339037; batch adversarial loss: 0.523201\n",
      "epoch 8; iter: 0; batch classifier loss: 0.222065; batch adversarial loss: 0.500014\n",
      "epoch 9; iter: 0; batch classifier loss: 0.247314; batch adversarial loss: 0.469108\n",
      "epoch 10; iter: 0; batch classifier loss: 0.213166; batch adversarial loss: 0.502032\n",
      "epoch 11; iter: 0; batch classifier loss: 0.195590; batch adversarial loss: 0.511721\n",
      "epoch 12; iter: 0; batch classifier loss: 0.239483; batch adversarial loss: 0.435477\n",
      "epoch 13; iter: 0; batch classifier loss: 0.203360; batch adversarial loss: 0.463710\n",
      "epoch 14; iter: 0; batch classifier loss: 0.140276; batch adversarial loss: 0.463281\n",
      "epoch 15; iter: 0; batch classifier loss: 0.241546; batch adversarial loss: 0.428631\n",
      "epoch 16; iter: 0; batch classifier loss: 0.195846; batch adversarial loss: 0.431475\n",
      "epoch 17; iter: 0; batch classifier loss: 0.140477; batch adversarial loss: 0.449260\n",
      "epoch 18; iter: 0; batch classifier loss: 0.242887; batch adversarial loss: 0.488749\n",
      "epoch 19; iter: 0; batch classifier loss: 0.210002; batch adversarial loss: 0.393072\n",
      "epoch 20; iter: 0; batch classifier loss: 0.147170; batch adversarial loss: 0.364668\n",
      "epoch 21; iter: 0; batch classifier loss: 0.118353; batch adversarial loss: 0.403610\n",
      "epoch 22; iter: 0; batch classifier loss: 0.133627; batch adversarial loss: 0.464455\n",
      "epoch 23; iter: 0; batch classifier loss: 0.150662; batch adversarial loss: 0.422259\n",
      "epoch 24; iter: 0; batch classifier loss: 0.189648; batch adversarial loss: 0.390072\n",
      "epoch 25; iter: 0; batch classifier loss: 0.125297; batch adversarial loss: 0.471641\n",
      "epoch 26; iter: 0; batch classifier loss: 0.158470; batch adversarial loss: 0.392670\n",
      "epoch 27; iter: 0; batch classifier loss: 0.161924; batch adversarial loss: 0.431014\n",
      "epoch 28; iter: 0; batch classifier loss: 0.165213; batch adversarial loss: 0.406282\n",
      "epoch 29; iter: 0; batch classifier loss: 0.154150; batch adversarial loss: 0.361528\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151052; batch adversarial loss: 0.403637\n",
      "epoch 31; iter: 0; batch classifier loss: 0.125816; batch adversarial loss: 0.376021\n",
      "epoch 32; iter: 0; batch classifier loss: 0.129577; batch adversarial loss: 0.437276\n",
      "epoch 33; iter: 0; batch classifier loss: 0.141666; batch adversarial loss: 0.451122\n",
      "epoch 34; iter: 0; batch classifier loss: 0.156165; batch adversarial loss: 0.474539\n",
      "epoch 35; iter: 0; batch classifier loss: 0.159141; batch adversarial loss: 0.480069\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109293; batch adversarial loss: 0.320844\n",
      "epoch 37; iter: 0; batch classifier loss: 0.108586; batch adversarial loss: 0.395714\n",
      "epoch 38; iter: 0; batch classifier loss: 0.108404; batch adversarial loss: 0.414045\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125517; batch adversarial loss: 0.468675\n",
      "epoch 40; iter: 0; batch classifier loss: 0.165724; batch adversarial loss: 0.358402\n",
      "epoch 41; iter: 0; batch classifier loss: 0.131172; batch adversarial loss: 0.433033\n",
      "epoch 42; iter: 0; batch classifier loss: 0.126834; batch adversarial loss: 0.383853\n",
      "epoch 43; iter: 0; batch classifier loss: 0.093108; batch adversarial loss: 0.514781\n",
      "epoch 44; iter: 0; batch classifier loss: 0.073633; batch adversarial loss: 0.430680\n",
      "epoch 45; iter: 0; batch classifier loss: 0.094278; batch adversarial loss: 0.468274\n",
      "epoch 46; iter: 0; batch classifier loss: 0.092629; batch adversarial loss: 0.365847\n",
      "epoch 47; iter: 0; batch classifier loss: 0.108015; batch adversarial loss: 0.368906\n",
      "epoch 48; iter: 0; batch classifier loss: 0.078094; batch adversarial loss: 0.413371\n",
      "epoch 49; iter: 0; batch classifier loss: 0.084138; batch adversarial loss: 0.367074\n",
      "epoch 50; iter: 0; batch classifier loss: 0.090379; batch adversarial loss: 0.445944\n",
      "epoch 51; iter: 0; batch classifier loss: 0.074376; batch adversarial loss: 0.396824\n",
      "epoch 52; iter: 0; batch classifier loss: 0.114415; batch adversarial loss: 0.500003\n",
      "epoch 53; iter: 0; batch classifier loss: 0.111050; batch adversarial loss: 0.460702\n",
      "epoch 54; iter: 0; batch classifier loss: 0.080956; batch adversarial loss: 0.313942\n",
      "epoch 55; iter: 0; batch classifier loss: 0.088867; batch adversarial loss: 0.431204\n",
      "epoch 56; iter: 0; batch classifier loss: 0.109274; batch adversarial loss: 0.395329\n",
      "epoch 57; iter: 0; batch classifier loss: 0.087438; batch adversarial loss: 0.374518\n",
      "epoch 58; iter: 0; batch classifier loss: 0.091623; batch adversarial loss: 0.401575\n",
      "epoch 59; iter: 0; batch classifier loss: 0.058717; batch adversarial loss: 0.367342\n",
      "epoch 60; iter: 0; batch classifier loss: 0.057424; batch adversarial loss: 0.459725\n",
      "epoch 61; iter: 0; batch classifier loss: 0.082902; batch adversarial loss: 0.461506\n",
      "epoch 62; iter: 0; batch classifier loss: 0.065578; batch adversarial loss: 0.385564\n",
      "epoch 63; iter: 0; batch classifier loss: 0.051851; batch adversarial loss: 0.407828\n",
      "epoch 64; iter: 0; batch classifier loss: 0.099057; batch adversarial loss: 0.498490\n",
      "epoch 65; iter: 0; batch classifier loss: 0.093960; batch adversarial loss: 0.443274\n",
      "epoch 66; iter: 0; batch classifier loss: 0.115249; batch adversarial loss: 0.442750\n",
      "epoch 67; iter: 0; batch classifier loss: 0.046006; batch adversarial loss: 0.403376\n",
      "epoch 68; iter: 0; batch classifier loss: 0.058064; batch adversarial loss: 0.470083\n",
      "epoch 69; iter: 0; batch classifier loss: 0.063813; batch adversarial loss: 0.360476\n",
      "epoch 70; iter: 0; batch classifier loss: 0.070600; batch adversarial loss: 0.420464\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071366; batch adversarial loss: 0.379112\n",
      "epoch 72; iter: 0; batch classifier loss: 0.083896; batch adversarial loss: 0.359089\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084330; batch adversarial loss: 0.371951\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079091; batch adversarial loss: 0.418604\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076222; batch adversarial loss: 0.427452\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083049; batch adversarial loss: 0.402538\n",
      "epoch 77; iter: 0; batch classifier loss: 0.085354; batch adversarial loss: 0.415437\n",
      "epoch 78; iter: 0; batch classifier loss: 0.077191; batch adversarial loss: 0.367577\n",
      "epoch 79; iter: 0; batch classifier loss: 0.086470; batch adversarial loss: 0.427090\n",
      "epoch 80; iter: 0; batch classifier loss: 0.087662; batch adversarial loss: 0.458859\n",
      "epoch 81; iter: 0; batch classifier loss: 0.047092; batch adversarial loss: 0.378778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.041771; batch adversarial loss: 0.425969\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068834; batch adversarial loss: 0.470421\n",
      "epoch 84; iter: 0; batch classifier loss: 0.066709; batch adversarial loss: 0.385088\n",
      "epoch 85; iter: 0; batch classifier loss: 0.058926; batch adversarial loss: 0.430646\n",
      "epoch 86; iter: 0; batch classifier loss: 0.094292; batch adversarial loss: 0.365368\n",
      "epoch 87; iter: 0; batch classifier loss: 0.075719; batch adversarial loss: 0.429409\n",
      "epoch 88; iter: 0; batch classifier loss: 0.074765; batch adversarial loss: 0.396730\n",
      "epoch 89; iter: 0; batch classifier loss: 0.047183; batch adversarial loss: 0.458107\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073156; batch adversarial loss: 0.349946\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045908; batch adversarial loss: 0.429614\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082157; batch adversarial loss: 0.352792\n",
      "epoch 93; iter: 0; batch classifier loss: 0.029214; batch adversarial loss: 0.398556\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072194; batch adversarial loss: 0.489118\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054573; batch adversarial loss: 0.433905\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057276; batch adversarial loss: 0.382154\n",
      "epoch 97; iter: 0; batch classifier loss: 0.058161; batch adversarial loss: 0.432374\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053206; batch adversarial loss: 0.434529\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055082; batch adversarial loss: 0.339208\n",
      "epoch 100; iter: 0; batch classifier loss: 0.029933; batch adversarial loss: 0.366561\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039315; batch adversarial loss: 0.398636\n",
      "epoch 102; iter: 0; batch classifier loss: 0.028285; batch adversarial loss: 0.460767\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049164; batch adversarial loss: 0.417199\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027303; batch adversarial loss: 0.624893\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038988; batch adversarial loss: 0.408429\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036908; batch adversarial loss: 0.558942\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036665; batch adversarial loss: 0.461403\n",
      "epoch 108; iter: 0; batch classifier loss: 0.019913; batch adversarial loss: 0.451866\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046645; batch adversarial loss: 0.387670\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045650; batch adversarial loss: 0.482169\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030159; batch adversarial loss: 0.424306\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042095; batch adversarial loss: 0.413713\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048098; batch adversarial loss: 0.531199\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037214; batch adversarial loss: 0.443865\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034392; batch adversarial loss: 0.476778\n",
      "epoch 116; iter: 0; batch classifier loss: 0.020561; batch adversarial loss: 0.411324\n",
      "epoch 117; iter: 0; batch classifier loss: 0.088334; batch adversarial loss: 0.580847\n",
      "epoch 118; iter: 0; batch classifier loss: 0.067989; batch adversarial loss: 0.460720\n",
      "epoch 119; iter: 0; batch classifier loss: 0.020203; batch adversarial loss: 0.454970\n",
      "epoch 120; iter: 0; batch classifier loss: 0.080024; batch adversarial loss: 0.541485\n",
      "epoch 121; iter: 0; batch classifier loss: 0.089032; batch adversarial loss: 0.640095\n",
      "epoch 122; iter: 0; batch classifier loss: 0.057378; batch adversarial loss: 0.418025\n",
      "epoch 123; iter: 0; batch classifier loss: 0.066046; batch adversarial loss: 0.606885\n",
      "epoch 124; iter: 0; batch classifier loss: 0.129317; batch adversarial loss: 0.745266\n",
      "epoch 125; iter: 0; batch classifier loss: 0.209923; batch adversarial loss: 0.856920\n",
      "epoch 126; iter: 0; batch classifier loss: 0.059486; batch adversarial loss: 0.635049\n",
      "epoch 127; iter: 0; batch classifier loss: 0.055347; batch adversarial loss: 0.523340\n",
      "epoch 128; iter: 0; batch classifier loss: 0.079783; batch adversarial loss: 0.534710\n",
      "epoch 129; iter: 0; batch classifier loss: 0.161704; batch adversarial loss: 0.624284\n",
      "epoch 130; iter: 0; batch classifier loss: 0.223342; batch adversarial loss: 0.726341\n",
      "epoch 131; iter: 0; batch classifier loss: 0.140923; batch adversarial loss: 0.644803\n",
      "epoch 132; iter: 0; batch classifier loss: 0.161034; batch adversarial loss: 0.643126\n",
      "epoch 133; iter: 0; batch classifier loss: 0.174030; batch adversarial loss: 0.636081\n",
      "epoch 134; iter: 0; batch classifier loss: 0.139107; batch adversarial loss: 0.613108\n",
      "epoch 135; iter: 0; batch classifier loss: 0.221441; batch adversarial loss: 0.717530\n",
      "epoch 136; iter: 0; batch classifier loss: 0.128606; batch adversarial loss: 0.554935\n",
      "epoch 137; iter: 0; batch classifier loss: 0.136966; batch adversarial loss: 0.558991\n",
      "epoch 138; iter: 0; batch classifier loss: 0.160096; batch adversarial loss: 0.532479\n",
      "epoch 139; iter: 0; batch classifier loss: 0.134006; batch adversarial loss: 0.570706\n",
      "epoch 140; iter: 0; batch classifier loss: 0.164591; batch adversarial loss: 0.685477\n",
      "epoch 141; iter: 0; batch classifier loss: 0.162454; batch adversarial loss: 0.677793\n",
      "epoch 142; iter: 0; batch classifier loss: 0.159096; batch adversarial loss: 0.493962\n",
      "epoch 143; iter: 0; batch classifier loss: 0.101320; batch adversarial loss: 0.495751\n",
      "epoch 144; iter: 0; batch classifier loss: 0.162691; batch adversarial loss: 0.533066\n",
      "epoch 145; iter: 0; batch classifier loss: 0.192830; batch adversarial loss: 0.607234\n",
      "epoch 146; iter: 0; batch classifier loss: 0.110532; batch adversarial loss: 0.502843\n",
      "epoch 147; iter: 0; batch classifier loss: 0.162585; batch adversarial loss: 0.546832\n",
      "epoch 148; iter: 0; batch classifier loss: 0.109036; batch adversarial loss: 0.507194\n",
      "epoch 149; iter: 0; batch classifier loss: 0.114578; batch adversarial loss: 0.513830\n",
      "epoch 150; iter: 0; batch classifier loss: 0.155319; batch adversarial loss: 0.536933\n",
      "epoch 151; iter: 0; batch classifier loss: 0.182323; batch adversarial loss: 0.552162\n",
      "epoch 152; iter: 0; batch classifier loss: 0.114412; batch adversarial loss: 0.488694\n",
      "epoch 153; iter: 0; batch classifier loss: 0.115429; batch adversarial loss: 0.499978\n",
      "epoch 154; iter: 0; batch classifier loss: 0.144091; batch adversarial loss: 0.656661\n",
      "epoch 155; iter: 0; batch classifier loss: 0.121972; batch adversarial loss: 0.568055\n",
      "epoch 156; iter: 0; batch classifier loss: 0.173685; batch adversarial loss: 0.626518\n",
      "epoch 157; iter: 0; batch classifier loss: 0.127686; batch adversarial loss: 0.483100\n",
      "epoch 158; iter: 0; batch classifier loss: 0.087211; batch adversarial loss: 0.397359\n",
      "epoch 159; iter: 0; batch classifier loss: 0.100305; batch adversarial loss: 0.456407\n",
      "epoch 160; iter: 0; batch classifier loss: 0.128314; batch adversarial loss: 0.471551\n",
      "epoch 161; iter: 0; batch classifier loss: 0.144767; batch adversarial loss: 0.466839\n",
      "epoch 162; iter: 0; batch classifier loss: 0.098728; batch adversarial loss: 0.449636\n",
      "epoch 163; iter: 0; batch classifier loss: 0.092979; batch adversarial loss: 0.433816\n",
      "epoch 164; iter: 0; batch classifier loss: 0.108279; batch adversarial loss: 0.445507\n",
      "epoch 165; iter: 0; batch classifier loss: 0.050983; batch adversarial loss: 0.400993\n",
      "epoch 166; iter: 0; batch classifier loss: 0.099661; batch adversarial loss: 0.412057\n",
      "epoch 167; iter: 0; batch classifier loss: 0.133272; batch adversarial loss: 0.556780\n",
      "epoch 168; iter: 0; batch classifier loss: 0.062586; batch adversarial loss: 0.518677\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031386; batch adversarial loss: 0.383814\n",
      "epoch 170; iter: 0; batch classifier loss: 0.047139; batch adversarial loss: 0.530179\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021389; batch adversarial loss: 0.416739\n",
      "epoch 172; iter: 0; batch classifier loss: 0.064314; batch adversarial loss: 0.526751\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036029; batch adversarial loss: 0.506703\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019766; batch adversarial loss: 0.515345\n",
      "epoch 175; iter: 0; batch classifier loss: 0.052625; batch adversarial loss: 0.421920\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023506; batch adversarial loss: 0.525110\n",
      "epoch 177; iter: 0; batch classifier loss: 0.074939; batch adversarial loss: 0.502026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.029529; batch adversarial loss: 0.537039\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023674; batch adversarial loss: 0.391919\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011081; batch adversarial loss: 0.460005\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039083; batch adversarial loss: 0.526623\n",
      "epoch 182; iter: 0; batch classifier loss: 0.043693; batch adversarial loss: 0.464407\n",
      "epoch 183; iter: 0; batch classifier loss: 0.045960; batch adversarial loss: 0.560819\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038689; batch adversarial loss: 0.460285\n",
      "epoch 185; iter: 0; batch classifier loss: 0.049408; batch adversarial loss: 0.510603\n",
      "epoch 186; iter: 0; batch classifier loss: 0.062720; batch adversarial loss: 0.525134\n",
      "epoch 187; iter: 0; batch classifier loss: 0.043190; batch adversarial loss: 0.526466\n",
      "epoch 188; iter: 0; batch classifier loss: 0.112639; batch adversarial loss: 0.460501\n",
      "epoch 189; iter: 0; batch classifier loss: 0.098245; batch adversarial loss: 0.472074\n",
      "epoch 190; iter: 0; batch classifier loss: 0.051149; batch adversarial loss: 0.394093\n",
      "epoch 191; iter: 0; batch classifier loss: 0.071437; batch adversarial loss: 0.408355\n",
      "epoch 192; iter: 0; batch classifier loss: 0.079433; batch adversarial loss: 0.463105\n",
      "epoch 193; iter: 0; batch classifier loss: 0.077842; batch adversarial loss: 0.468491\n",
      "epoch 194; iter: 0; batch classifier loss: 0.093789; batch adversarial loss: 0.407508\n",
      "epoch 195; iter: 0; batch classifier loss: 0.136761; batch adversarial loss: 0.408656\n",
      "epoch 196; iter: 0; batch classifier loss: 0.054027; batch adversarial loss: 0.396866\n",
      "epoch 197; iter: 0; batch classifier loss: 0.050130; batch adversarial loss: 0.392821\n",
      "epoch 198; iter: 0; batch classifier loss: 0.090855; batch adversarial loss: 0.412605\n",
      "epoch 199; iter: 0; batch classifier loss: 0.062247; batch adversarial loss: 0.444831\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695770; batch adversarial loss: 0.951419\n",
      "epoch 1; iter: 0; batch classifier loss: 0.866616; batch adversarial loss: 1.157752\n",
      "epoch 2; iter: 0; batch classifier loss: 1.000769; batch adversarial loss: 1.110581\n",
      "epoch 3; iter: 0; batch classifier loss: 1.131449; batch adversarial loss: 1.012385\n",
      "epoch 4; iter: 0; batch classifier loss: 1.048993; batch adversarial loss: 0.891957\n",
      "epoch 5; iter: 0; batch classifier loss: 0.875796; batch adversarial loss: 0.801652\n",
      "epoch 6; iter: 0; batch classifier loss: 0.863421; batch adversarial loss: 0.739351\n",
      "epoch 7; iter: 0; batch classifier loss: 0.851014; batch adversarial loss: 0.684920\n",
      "epoch 8; iter: 0; batch classifier loss: 0.691997; batch adversarial loss: 0.648320\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578026; batch adversarial loss: 0.607049\n",
      "epoch 10; iter: 0; batch classifier loss: 0.492258; batch adversarial loss: 0.546631\n",
      "epoch 11; iter: 0; batch classifier loss: 0.327942; batch adversarial loss: 0.496653\n",
      "epoch 12; iter: 0; batch classifier loss: 0.270016; batch adversarial loss: 0.554163\n",
      "epoch 13; iter: 0; batch classifier loss: 0.279706; batch adversarial loss: 0.521278\n",
      "epoch 14; iter: 0; batch classifier loss: 0.266570; batch adversarial loss: 0.463575\n",
      "epoch 15; iter: 0; batch classifier loss: 0.301875; batch adversarial loss: 0.446925\n",
      "epoch 16; iter: 0; batch classifier loss: 0.282473; batch adversarial loss: 0.471735\n",
      "epoch 17; iter: 0; batch classifier loss: 0.270099; batch adversarial loss: 0.486541\n",
      "epoch 18; iter: 0; batch classifier loss: 0.265739; batch adversarial loss: 0.480677\n",
      "epoch 19; iter: 0; batch classifier loss: 0.222070; batch adversarial loss: 0.500220\n",
      "epoch 20; iter: 0; batch classifier loss: 0.227591; batch adversarial loss: 0.483518\n",
      "epoch 21; iter: 0; batch classifier loss: 0.235719; batch adversarial loss: 0.394542\n",
      "epoch 22; iter: 0; batch classifier loss: 0.225735; batch adversarial loss: 0.463918\n",
      "epoch 23; iter: 0; batch classifier loss: 0.129407; batch adversarial loss: 0.541110\n",
      "epoch 24; iter: 0; batch classifier loss: 0.246020; batch adversarial loss: 0.406748\n",
      "epoch 25; iter: 0; batch classifier loss: 0.185262; batch adversarial loss: 0.398412\n",
      "epoch 26; iter: 0; batch classifier loss: 0.224274; batch adversarial loss: 0.407175\n",
      "epoch 27; iter: 0; batch classifier loss: 0.224584; batch adversarial loss: 0.496644\n",
      "epoch 28; iter: 0; batch classifier loss: 0.214700; batch adversarial loss: 0.477905\n",
      "epoch 29; iter: 0; batch classifier loss: 0.097049; batch adversarial loss: 0.557215\n",
      "epoch 30; iter: 0; batch classifier loss: 0.125121; batch adversarial loss: 0.482368\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178285; batch adversarial loss: 0.441066\n",
      "epoch 32; iter: 0; batch classifier loss: 0.106222; batch adversarial loss: 0.518173\n",
      "epoch 33; iter: 0; batch classifier loss: 0.123836; batch adversarial loss: 0.441309\n",
      "epoch 34; iter: 0; batch classifier loss: 0.157322; batch adversarial loss: 0.392182\n",
      "epoch 35; iter: 0; batch classifier loss: 0.138408; batch adversarial loss: 0.581819\n",
      "epoch 36; iter: 0; batch classifier loss: 0.082869; batch adversarial loss: 0.450676\n",
      "epoch 37; iter: 0; batch classifier loss: 0.081630; batch adversarial loss: 0.408939\n",
      "epoch 38; iter: 0; batch classifier loss: 0.071970; batch adversarial loss: 0.479017\n",
      "epoch 39; iter: 0; batch classifier loss: 0.117871; batch adversarial loss: 0.489406\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095450; batch adversarial loss: 0.536526\n",
      "epoch 41; iter: 0; batch classifier loss: 0.113533; batch adversarial loss: 0.463933\n",
      "epoch 42; iter: 0; batch classifier loss: 0.113730; batch adversarial loss: 0.480324\n",
      "epoch 43; iter: 0; batch classifier loss: 0.152572; batch adversarial loss: 0.468017\n",
      "epoch 44; iter: 0; batch classifier loss: 0.107917; batch adversarial loss: 0.469965\n",
      "epoch 45; iter: 0; batch classifier loss: 0.121266; batch adversarial loss: 0.465636\n",
      "epoch 46; iter: 0; batch classifier loss: 0.097977; batch adversarial loss: 0.419897\n",
      "epoch 47; iter: 0; batch classifier loss: 0.123610; batch adversarial loss: 0.445815\n",
      "epoch 48; iter: 0; batch classifier loss: 0.093697; batch adversarial loss: 0.523312\n",
      "epoch 49; iter: 0; batch classifier loss: 0.120630; batch adversarial loss: 0.387154\n",
      "epoch 50; iter: 0; batch classifier loss: 0.117211; batch adversarial loss: 0.430932\n",
      "epoch 51; iter: 0; batch classifier loss: 0.137343; batch adversarial loss: 0.421805\n",
      "epoch 52; iter: 0; batch classifier loss: 0.093565; batch adversarial loss: 0.410779\n",
      "epoch 53; iter: 0; batch classifier loss: 0.074199; batch adversarial loss: 0.492749\n",
      "epoch 54; iter: 0; batch classifier loss: 0.135257; batch adversarial loss: 0.397435\n",
      "epoch 55; iter: 0; batch classifier loss: 0.123647; batch adversarial loss: 0.496748\n",
      "epoch 56; iter: 0; batch classifier loss: 0.108828; batch adversarial loss: 0.380360\n",
      "epoch 57; iter: 0; batch classifier loss: 0.098987; batch adversarial loss: 0.489335\n",
      "epoch 58; iter: 0; batch classifier loss: 0.138730; batch adversarial loss: 0.429004\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099487; batch adversarial loss: 0.455642\n",
      "epoch 60; iter: 0; batch classifier loss: 0.048335; batch adversarial loss: 0.349208\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087189; batch adversarial loss: 0.538887\n",
      "epoch 62; iter: 0; batch classifier loss: 0.099708; batch adversarial loss: 0.478091\n",
      "epoch 63; iter: 0; batch classifier loss: 0.096936; batch adversarial loss: 0.531676\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076633; batch adversarial loss: 0.484629\n",
      "epoch 65; iter: 0; batch classifier loss: 0.094438; batch adversarial loss: 0.446209\n",
      "epoch 66; iter: 0; batch classifier loss: 0.056697; batch adversarial loss: 0.450952\n",
      "epoch 67; iter: 0; batch classifier loss: 0.097016; batch adversarial loss: 0.458422\n",
      "epoch 68; iter: 0; batch classifier loss: 0.050819; batch adversarial loss: 0.426317\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081339; batch adversarial loss: 0.383235\n",
      "epoch 70; iter: 0; batch classifier loss: 0.085097; batch adversarial loss: 0.492045\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104910; batch adversarial loss: 0.446143\n",
      "epoch 72; iter: 0; batch classifier loss: 0.038797; batch adversarial loss: 0.463473\n",
      "epoch 73; iter: 0; batch classifier loss: 0.066889; batch adversarial loss: 0.469243\n",
      "epoch 74; iter: 0; batch classifier loss: 0.122966; batch adversarial loss: 0.460324\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061983; batch adversarial loss: 0.415958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.070513; batch adversarial loss: 0.430878\n",
      "epoch 77; iter: 0; batch classifier loss: 0.071273; batch adversarial loss: 0.559558\n",
      "epoch 78; iter: 0; batch classifier loss: 0.076676; batch adversarial loss: 0.462256\n",
      "epoch 79; iter: 0; batch classifier loss: 0.038697; batch adversarial loss: 0.411083\n",
      "epoch 80; iter: 0; batch classifier loss: 0.097711; batch adversarial loss: 0.466195\n",
      "epoch 81; iter: 0; batch classifier loss: 0.054320; batch adversarial loss: 0.442607\n",
      "epoch 82; iter: 0; batch classifier loss: 0.036476; batch adversarial loss: 0.440267\n",
      "epoch 83; iter: 0; batch classifier loss: 0.053085; batch adversarial loss: 0.442995\n",
      "epoch 84; iter: 0; batch classifier loss: 0.061210; batch adversarial loss: 0.462272\n",
      "epoch 85; iter: 0; batch classifier loss: 0.024224; batch adversarial loss: 0.523707\n",
      "epoch 86; iter: 0; batch classifier loss: 0.029984; batch adversarial loss: 0.483255\n",
      "epoch 87; iter: 0; batch classifier loss: 0.051632; batch adversarial loss: 0.448900\n",
      "epoch 88; iter: 0; batch classifier loss: 0.056981; batch adversarial loss: 0.448087\n",
      "epoch 89; iter: 0; batch classifier loss: 0.030601; batch adversarial loss: 0.463481\n",
      "epoch 90; iter: 0; batch classifier loss: 0.071893; batch adversarial loss: 0.355592\n",
      "epoch 91; iter: 0; batch classifier loss: 0.047567; batch adversarial loss: 0.488967\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082304; batch adversarial loss: 0.430623\n",
      "epoch 93; iter: 0; batch classifier loss: 0.049755; batch adversarial loss: 0.472643\n",
      "epoch 94; iter: 0; batch classifier loss: 0.036697; batch adversarial loss: 0.451941\n",
      "epoch 95; iter: 0; batch classifier loss: 0.046460; batch adversarial loss: 0.376050\n",
      "epoch 96; iter: 0; batch classifier loss: 0.061075; batch adversarial loss: 0.570407\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050183; batch adversarial loss: 0.395095\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039494; batch adversarial loss: 0.513630\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078464; batch adversarial loss: 0.380661\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037809; batch adversarial loss: 0.381245\n",
      "epoch 101; iter: 0; batch classifier loss: 0.028290; batch adversarial loss: 0.538137\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042800; batch adversarial loss: 0.448864\n",
      "epoch 103; iter: 0; batch classifier loss: 0.067235; batch adversarial loss: 0.425587\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034570; batch adversarial loss: 0.389479\n",
      "epoch 105; iter: 0; batch classifier loss: 0.024173; batch adversarial loss: 0.436009\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030657; batch adversarial loss: 0.434231\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027775; batch adversarial loss: 0.411219\n",
      "epoch 108; iter: 0; batch classifier loss: 0.015476; batch adversarial loss: 0.464948\n",
      "epoch 109; iter: 0; batch classifier loss: 0.065446; batch adversarial loss: 0.583318\n",
      "epoch 110; iter: 0; batch classifier loss: 0.021184; batch adversarial loss: 0.483638\n",
      "epoch 111; iter: 0; batch classifier loss: 0.022885; batch adversarial loss: 0.450918\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053986; batch adversarial loss: 0.512089\n",
      "epoch 113; iter: 0; batch classifier loss: 0.023928; batch adversarial loss: 0.461188\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029453; batch adversarial loss: 0.621639\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042961; batch adversarial loss: 0.443879\n",
      "epoch 116; iter: 0; batch classifier loss: 0.071656; batch adversarial loss: 0.459050\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045934; batch adversarial loss: 0.363826\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024484; batch adversarial loss: 0.478544\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031461; batch adversarial loss: 0.498337\n",
      "epoch 120; iter: 0; batch classifier loss: 0.072144; batch adversarial loss: 0.466061\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037813; batch adversarial loss: 0.471278\n",
      "epoch 122; iter: 0; batch classifier loss: 0.016005; batch adversarial loss: 0.470585\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055601; batch adversarial loss: 0.450043\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043278; batch adversarial loss: 0.360910\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022278; batch adversarial loss: 0.474678\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043771; batch adversarial loss: 0.422908\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033349; batch adversarial loss: 0.374640\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037886; batch adversarial loss: 0.387839\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022679; batch adversarial loss: 0.405062\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050083; batch adversarial loss: 0.482494\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017901; batch adversarial loss: 0.492314\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023754; batch adversarial loss: 0.429672\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021877; batch adversarial loss: 0.481073\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027824; batch adversarial loss: 0.435861\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026972; batch adversarial loss: 0.464481\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030418; batch adversarial loss: 0.367209\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024413; batch adversarial loss: 0.411722\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022228; batch adversarial loss: 0.452806\n",
      "epoch 139; iter: 0; batch classifier loss: 0.047153; batch adversarial loss: 0.402178\n",
      "epoch 140; iter: 0; batch classifier loss: 0.014249; batch adversarial loss: 0.462164\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029955; batch adversarial loss: 0.459397\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021204; batch adversarial loss: 0.460641\n",
      "epoch 143; iter: 0; batch classifier loss: 0.010003; batch adversarial loss: 0.417444\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029231; batch adversarial loss: 0.451220\n",
      "epoch 145; iter: 0; batch classifier loss: 0.047627; batch adversarial loss: 0.431113\n",
      "epoch 146; iter: 0; batch classifier loss: 0.033125; batch adversarial loss: 0.439289\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013553; batch adversarial loss: 0.480392\n",
      "epoch 148; iter: 0; batch classifier loss: 0.003281; batch adversarial loss: 0.507279\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020241; batch adversarial loss: 0.464327\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023911; batch adversarial loss: 0.456326\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028295; batch adversarial loss: 0.395920\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011067; batch adversarial loss: 0.472979\n",
      "epoch 153; iter: 0; batch classifier loss: 0.004655; batch adversarial loss: 0.492543\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023178; batch adversarial loss: 0.434173\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041809; batch adversarial loss: 0.483389\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040995; batch adversarial loss: 0.413141\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015250; batch adversarial loss: 0.447237\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015707; batch adversarial loss: 0.457869\n",
      "epoch 159; iter: 0; batch classifier loss: 0.004848; batch adversarial loss: 0.503168\n",
      "epoch 160; iter: 0; batch classifier loss: 0.006882; batch adversarial loss: 0.526152\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014822; batch adversarial loss: 0.468760\n",
      "epoch 162; iter: 0; batch classifier loss: 0.006549; batch adversarial loss: 0.426519\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024570; batch adversarial loss: 0.551734\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010658; batch adversarial loss: 0.402784\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018877; batch adversarial loss: 0.509574\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032147; batch adversarial loss: 0.568561\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013436; batch adversarial loss: 0.367862\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005048; batch adversarial loss: 0.482997\n",
      "epoch 169; iter: 0; batch classifier loss: 0.004698; batch adversarial loss: 0.456378\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013981; batch adversarial loss: 0.409464\n",
      "epoch 171; iter: 0; batch classifier loss: 0.006189; batch adversarial loss: 0.488488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.047469; batch adversarial loss: 0.392297\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029141; batch adversarial loss: 0.430883\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020785; batch adversarial loss: 0.505149\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025887; batch adversarial loss: 0.531501\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026645; batch adversarial loss: 0.376239\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016209; batch adversarial loss: 0.444854\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007870; batch adversarial loss: 0.378167\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015188; batch adversarial loss: 0.440375\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015003; batch adversarial loss: 0.401098\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018018; batch adversarial loss: 0.328544\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012486; batch adversarial loss: 0.521966\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011477; batch adversarial loss: 0.417734\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006958; batch adversarial loss: 0.382406\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009852; batch adversarial loss: 0.467042\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016943; batch adversarial loss: 0.470936\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015496; batch adversarial loss: 0.385400\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040090; batch adversarial loss: 0.506979\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010168; batch adversarial loss: 0.427411\n",
      "epoch 190; iter: 0; batch classifier loss: 0.002903; batch adversarial loss: 0.453416\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025242; batch adversarial loss: 0.433161\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017746; batch adversarial loss: 0.440969\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006408; batch adversarial loss: 0.427678\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012759; batch adversarial loss: 0.383062\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019496; batch adversarial loss: 0.447219\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027844; batch adversarial loss: 0.440251\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027802; batch adversarial loss: 0.414301\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011925; batch adversarial loss: 0.468390\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008256; batch adversarial loss: 0.536513\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682303; batch adversarial loss: 0.635693\n",
      "epoch 1; iter: 0; batch classifier loss: 0.380422; batch adversarial loss: 0.619133\n",
      "epoch 2; iter: 0; batch classifier loss: 0.353717; batch adversarial loss: 0.617297\n",
      "epoch 3; iter: 0; batch classifier loss: 0.343535; batch adversarial loss: 0.553633\n",
      "epoch 4; iter: 0; batch classifier loss: 0.308058; batch adversarial loss: 0.552351\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343512; batch adversarial loss: 0.530643\n",
      "epoch 6; iter: 0; batch classifier loss: 0.359714; batch adversarial loss: 0.529056\n",
      "epoch 7; iter: 0; batch classifier loss: 0.271250; batch adversarial loss: 0.532652\n",
      "epoch 8; iter: 0; batch classifier loss: 0.292463; batch adversarial loss: 0.536594\n",
      "epoch 9; iter: 0; batch classifier loss: 0.356183; batch adversarial loss: 0.497624\n",
      "epoch 10; iter: 0; batch classifier loss: 0.321096; batch adversarial loss: 0.510755\n",
      "epoch 11; iter: 0; batch classifier loss: 0.352917; batch adversarial loss: 0.607031\n",
      "epoch 12; iter: 0; batch classifier loss: 0.401915; batch adversarial loss: 0.580351\n",
      "epoch 13; iter: 0; batch classifier loss: 0.607382; batch adversarial loss: 0.509393\n",
      "epoch 14; iter: 0; batch classifier loss: 0.436703; batch adversarial loss: 0.528862\n",
      "epoch 15; iter: 0; batch classifier loss: 0.384498; batch adversarial loss: 0.479614\n",
      "epoch 16; iter: 0; batch classifier loss: 0.190768; batch adversarial loss: 0.508796\n",
      "epoch 17; iter: 0; batch classifier loss: 0.207197; batch adversarial loss: 0.450658\n",
      "epoch 18; iter: 0; batch classifier loss: 0.235095; batch adversarial loss: 0.439165\n",
      "epoch 19; iter: 0; batch classifier loss: 0.167108; batch adversarial loss: 0.463330\n",
      "epoch 20; iter: 0; batch classifier loss: 0.225963; batch adversarial loss: 0.397617\n",
      "epoch 21; iter: 0; batch classifier loss: 0.188224; batch adversarial loss: 0.410556\n",
      "epoch 22; iter: 0; batch classifier loss: 0.178650; batch adversarial loss: 0.519499\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168989; batch adversarial loss: 0.442859\n",
      "epoch 24; iter: 0; batch classifier loss: 0.227313; batch adversarial loss: 0.445444\n",
      "epoch 25; iter: 0; batch classifier loss: 0.152913; batch adversarial loss: 0.431005\n",
      "epoch 26; iter: 0; batch classifier loss: 0.202203; batch adversarial loss: 0.472729\n",
      "epoch 27; iter: 0; batch classifier loss: 0.172726; batch adversarial loss: 0.600212\n",
      "epoch 28; iter: 0; batch classifier loss: 0.208715; batch adversarial loss: 0.477979\n",
      "epoch 29; iter: 0; batch classifier loss: 0.127162; batch adversarial loss: 0.531833\n",
      "epoch 30; iter: 0; batch classifier loss: 0.158679; batch adversarial loss: 0.434700\n",
      "epoch 31; iter: 0; batch classifier loss: 0.141229; batch adversarial loss: 0.436488\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154561; batch adversarial loss: 0.462176\n",
      "epoch 33; iter: 0; batch classifier loss: 0.148703; batch adversarial loss: 0.524285\n",
      "epoch 34; iter: 0; batch classifier loss: 0.187341; batch adversarial loss: 0.427814\n",
      "epoch 35; iter: 0; batch classifier loss: 0.119980; batch adversarial loss: 0.487106\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150388; batch adversarial loss: 0.406417\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111824; batch adversarial loss: 0.425507\n",
      "epoch 38; iter: 0; batch classifier loss: 0.093342; batch adversarial loss: 0.516906\n",
      "epoch 39; iter: 0; batch classifier loss: 0.110892; batch adversarial loss: 0.451428\n",
      "epoch 40; iter: 0; batch classifier loss: 0.094649; batch adversarial loss: 0.429872\n",
      "epoch 41; iter: 0; batch classifier loss: 0.099295; batch adversarial loss: 0.531389\n",
      "epoch 42; iter: 0; batch classifier loss: 0.149976; batch adversarial loss: 0.414064\n",
      "epoch 43; iter: 0; batch classifier loss: 0.109818; batch adversarial loss: 0.461160\n",
      "epoch 44; iter: 0; batch classifier loss: 0.088692; batch adversarial loss: 0.437895\n",
      "epoch 45; iter: 0; batch classifier loss: 0.088838; batch adversarial loss: 0.435402\n",
      "epoch 46; iter: 0; batch classifier loss: 0.113551; batch adversarial loss: 0.395419\n",
      "epoch 47; iter: 0; batch classifier loss: 0.128664; batch adversarial loss: 0.473278\n",
      "epoch 48; iter: 0; batch classifier loss: 0.112685; batch adversarial loss: 0.449215\n",
      "epoch 49; iter: 0; batch classifier loss: 0.090941; batch adversarial loss: 0.384228\n",
      "epoch 50; iter: 0; batch classifier loss: 0.093415; batch adversarial loss: 0.452822\n",
      "epoch 51; iter: 0; batch classifier loss: 0.195264; batch adversarial loss: 0.422465\n",
      "epoch 52; iter: 0; batch classifier loss: 0.114043; batch adversarial loss: 0.407757\n",
      "epoch 53; iter: 0; batch classifier loss: 0.079167; batch adversarial loss: 0.524642\n",
      "epoch 54; iter: 0; batch classifier loss: 0.084995; batch adversarial loss: 0.523175\n",
      "epoch 55; iter: 0; batch classifier loss: 0.066212; batch adversarial loss: 0.533346\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098258; batch adversarial loss: 0.402203\n",
      "epoch 57; iter: 0; batch classifier loss: 0.090847; batch adversarial loss: 0.473636\n",
      "epoch 58; iter: 0; batch classifier loss: 0.135980; batch adversarial loss: 0.392580\n",
      "epoch 59; iter: 0; batch classifier loss: 0.115026; batch adversarial loss: 0.422195\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079388; batch adversarial loss: 0.447473\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087744; batch adversarial loss: 0.393495\n",
      "epoch 62; iter: 0; batch classifier loss: 0.070183; batch adversarial loss: 0.458241\n",
      "epoch 63; iter: 0; batch classifier loss: 0.078001; batch adversarial loss: 0.493786\n",
      "epoch 64; iter: 0; batch classifier loss: 0.099406; batch adversarial loss: 0.374418\n",
      "epoch 65; iter: 0; batch classifier loss: 0.073914; batch adversarial loss: 0.592061\n",
      "epoch 66; iter: 0; batch classifier loss: 0.109109; batch adversarial loss: 0.426498\n",
      "epoch 67; iter: 0; batch classifier loss: 0.057009; batch adversarial loss: 0.442090\n",
      "epoch 68; iter: 0; batch classifier loss: 0.100270; batch adversarial loss: 0.488598\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103107; batch adversarial loss: 0.452519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.158695; batch adversarial loss: 0.484304\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115637; batch adversarial loss: 0.398834\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071732; batch adversarial loss: 0.358790\n",
      "epoch 73; iter: 0; batch classifier loss: 0.048841; batch adversarial loss: 0.594986\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067117; batch adversarial loss: 0.467302\n",
      "epoch 75; iter: 0; batch classifier loss: 0.090277; batch adversarial loss: 0.485363\n",
      "epoch 76; iter: 0; batch classifier loss: 0.027890; batch adversarial loss: 0.489130\n",
      "epoch 77; iter: 0; batch classifier loss: 0.110846; batch adversarial loss: 0.446943\n",
      "epoch 78; iter: 0; batch classifier loss: 0.088054; batch adversarial loss: 0.405271\n",
      "epoch 79; iter: 0; batch classifier loss: 0.124918; batch adversarial loss: 0.521147\n",
      "epoch 80; iter: 0; batch classifier loss: 0.049258; batch adversarial loss: 0.523850\n",
      "epoch 81; iter: 0; batch classifier loss: 0.058296; batch adversarial loss: 0.436354\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065400; batch adversarial loss: 0.383648\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083344; batch adversarial loss: 0.417158\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079103; batch adversarial loss: 0.487781\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064098; batch adversarial loss: 0.468589\n",
      "epoch 86; iter: 0; batch classifier loss: 0.099003; batch adversarial loss: 0.462392\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053332; batch adversarial loss: 0.425497\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062896; batch adversarial loss: 0.410635\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065718; batch adversarial loss: 0.486096\n",
      "epoch 90; iter: 0; batch classifier loss: 0.043416; batch adversarial loss: 0.533248\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057451; batch adversarial loss: 0.466147\n",
      "epoch 92; iter: 0; batch classifier loss: 0.031345; batch adversarial loss: 0.454282\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064584; batch adversarial loss: 0.534410\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077453; batch adversarial loss: 0.376682\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052849; batch adversarial loss: 0.387500\n",
      "epoch 96; iter: 0; batch classifier loss: 0.026992; batch adversarial loss: 0.431518\n",
      "epoch 97; iter: 0; batch classifier loss: 0.061106; batch adversarial loss: 0.374905\n",
      "epoch 98; iter: 0; batch classifier loss: 0.089733; batch adversarial loss: 0.461661\n",
      "epoch 99; iter: 0; batch classifier loss: 0.077604; batch adversarial loss: 0.435631\n",
      "epoch 100; iter: 0; batch classifier loss: 0.052446; batch adversarial loss: 0.505231\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068154; batch adversarial loss: 0.459074\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041295; batch adversarial loss: 0.444622\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050861; batch adversarial loss: 0.508997\n",
      "epoch 104; iter: 0; batch classifier loss: 0.022236; batch adversarial loss: 0.430441\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037964; batch adversarial loss: 0.548944\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058833; batch adversarial loss: 0.447987\n",
      "epoch 107; iter: 0; batch classifier loss: 0.021090; batch adversarial loss: 0.352949\n",
      "epoch 108; iter: 0; batch classifier loss: 0.027604; batch adversarial loss: 0.515881\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038081; batch adversarial loss: 0.487527\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026412; batch adversarial loss: 0.540714\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069476; batch adversarial loss: 0.403975\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034129; batch adversarial loss: 0.491090\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035900; batch adversarial loss: 0.423038\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041337; batch adversarial loss: 0.487360\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032582; batch adversarial loss: 0.505058\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032949; batch adversarial loss: 0.568790\n",
      "epoch 117; iter: 0; batch classifier loss: 0.064315; batch adversarial loss: 0.360857\n",
      "epoch 118; iter: 0; batch classifier loss: 0.055959; batch adversarial loss: 0.482629\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025113; batch adversarial loss: 0.474391\n",
      "epoch 120; iter: 0; batch classifier loss: 0.056230; batch adversarial loss: 0.443618\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033992; batch adversarial loss: 0.437027\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040761; batch adversarial loss: 0.527209\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028338; batch adversarial loss: 0.501229\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039386; batch adversarial loss: 0.396094\n",
      "epoch 125; iter: 0; batch classifier loss: 0.013467; batch adversarial loss: 0.443563\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051778; batch adversarial loss: 0.474430\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019704; batch adversarial loss: 0.419752\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036113; batch adversarial loss: 0.473116\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038084; batch adversarial loss: 0.469649\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031123; batch adversarial loss: 0.532252\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021933; batch adversarial loss: 0.493029\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024269; batch adversarial loss: 0.357397\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034183; batch adversarial loss: 0.409598\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023044; batch adversarial loss: 0.517095\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029868; batch adversarial loss: 0.391618\n",
      "epoch 136; iter: 0; batch classifier loss: 0.053084; batch adversarial loss: 0.501425\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032815; batch adversarial loss: 0.488107\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018983; batch adversarial loss: 0.419857\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034154; batch adversarial loss: 0.475766\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020220; batch adversarial loss: 0.459720\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028517; batch adversarial loss: 0.423029\n",
      "epoch 142; iter: 0; batch classifier loss: 0.052628; batch adversarial loss: 0.573606\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037095; batch adversarial loss: 0.509689\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017285; batch adversarial loss: 0.412854\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029191; batch adversarial loss: 0.447721\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027044; batch adversarial loss: 0.424552\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033903; batch adversarial loss: 0.411376\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034706; batch adversarial loss: 0.581823\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026898; batch adversarial loss: 0.425604\n",
      "epoch 150; iter: 0; batch classifier loss: 0.048420; batch adversarial loss: 0.449679\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041690; batch adversarial loss: 0.325484\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030990; batch adversarial loss: 0.466873\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034539; batch adversarial loss: 0.485410\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027371; batch adversarial loss: 0.445554\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011447; batch adversarial loss: 0.468859\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050553; batch adversarial loss: 0.426187\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019355; batch adversarial loss: 0.396486\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008437; batch adversarial loss: 0.495913\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034190; batch adversarial loss: 0.411014\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031528; batch adversarial loss: 0.358621\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029907; batch adversarial loss: 0.515636\n",
      "epoch 162; iter: 0; batch classifier loss: 0.053103; batch adversarial loss: 0.454762\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017583; batch adversarial loss: 0.487301\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020449; batch adversarial loss: 0.372230\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022741; batch adversarial loss: 0.452799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.017400; batch adversarial loss: 0.482161\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035015; batch adversarial loss: 0.450275\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032505; batch adversarial loss: 0.471517\n",
      "epoch 169; iter: 0; batch classifier loss: 0.004873; batch adversarial loss: 0.313891\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014635; batch adversarial loss: 0.411587\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031011; batch adversarial loss: 0.457837\n",
      "epoch 172; iter: 0; batch classifier loss: 0.038569; batch adversarial loss: 0.406707\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015839; batch adversarial loss: 0.511814\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009584; batch adversarial loss: 0.419561\n",
      "epoch 175; iter: 0; batch classifier loss: 0.073810; batch adversarial loss: 0.491611\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025087; batch adversarial loss: 0.461164\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021478; batch adversarial loss: 0.425620\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020669; batch adversarial loss: 0.472311\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008061; batch adversarial loss: 0.381100\n",
      "epoch 180; iter: 0; batch classifier loss: 0.005988; batch adversarial loss: 0.488211\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009595; batch adversarial loss: 0.437705\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020826; batch adversarial loss: 0.507495\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030791; batch adversarial loss: 0.397548\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023150; batch adversarial loss: 0.431540\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031624; batch adversarial loss: 0.457635\n",
      "epoch 186; iter: 0; batch classifier loss: 0.089667; batch adversarial loss: 0.381305\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021314; batch adversarial loss: 0.479905\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017465; batch adversarial loss: 0.420356\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012888; batch adversarial loss: 0.404613\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031836; batch adversarial loss: 0.495293\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007299; batch adversarial loss: 0.496887\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035741; batch adversarial loss: 0.472772\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009909; batch adversarial loss: 0.422636\n",
      "epoch 194; iter: 0; batch classifier loss: 0.051705; batch adversarial loss: 0.414795\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017195; batch adversarial loss: 0.397178\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006328; batch adversarial loss: 0.431644\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009364; batch adversarial loss: 0.474130\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010824; batch adversarial loss: 0.419054\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027102; batch adversarial loss: 0.463657\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674589; batch adversarial loss: 0.540846\n",
      "epoch 1; iter: 0; batch classifier loss: 0.429096; batch adversarial loss: 0.595236\n",
      "epoch 2; iter: 0; batch classifier loss: 0.434511; batch adversarial loss: 0.605132\n",
      "epoch 3; iter: 0; batch classifier loss: 0.414988; batch adversarial loss: 0.633138\n",
      "epoch 4; iter: 0; batch classifier loss: 0.402332; batch adversarial loss: 0.625471\n",
      "epoch 5; iter: 0; batch classifier loss: 0.390224; batch adversarial loss: 0.574848\n",
      "epoch 6; iter: 0; batch classifier loss: 0.402559; batch adversarial loss: 0.567282\n",
      "epoch 7; iter: 0; batch classifier loss: 0.448018; batch adversarial loss: 0.637358\n",
      "epoch 8; iter: 0; batch classifier loss: 0.510711; batch adversarial loss: 0.595493\n",
      "epoch 9; iter: 0; batch classifier loss: 0.627878; batch adversarial loss: 0.557126\n",
      "epoch 10; iter: 0; batch classifier loss: 0.640797; batch adversarial loss: 0.556480\n",
      "epoch 11; iter: 0; batch classifier loss: 0.607570; batch adversarial loss: 0.531581\n",
      "epoch 12; iter: 0; batch classifier loss: 0.447204; batch adversarial loss: 0.457900\n",
      "epoch 13; iter: 0; batch classifier loss: 0.369948; batch adversarial loss: 0.469338\n",
      "epoch 14; iter: 0; batch classifier loss: 0.293406; batch adversarial loss: 0.426656\n",
      "epoch 15; iter: 0; batch classifier loss: 0.337906; batch adversarial loss: 0.416061\n",
      "epoch 16; iter: 0; batch classifier loss: 0.245084; batch adversarial loss: 0.486167\n",
      "epoch 17; iter: 0; batch classifier loss: 0.246814; batch adversarial loss: 0.524186\n",
      "epoch 18; iter: 0; batch classifier loss: 0.298412; batch adversarial loss: 0.449529\n",
      "epoch 19; iter: 0; batch classifier loss: 0.214411; batch adversarial loss: 0.448992\n",
      "epoch 20; iter: 0; batch classifier loss: 0.249123; batch adversarial loss: 0.488290\n",
      "epoch 21; iter: 0; batch classifier loss: 0.217431; batch adversarial loss: 0.427618\n",
      "epoch 22; iter: 0; batch classifier loss: 0.285803; batch adversarial loss: 0.391389\n",
      "epoch 23; iter: 0; batch classifier loss: 0.201525; batch adversarial loss: 0.437740\n",
      "epoch 24; iter: 0; batch classifier loss: 0.165945; batch adversarial loss: 0.436822\n",
      "epoch 25; iter: 0; batch classifier loss: 0.228220; batch adversarial loss: 0.539845\n",
      "epoch 26; iter: 0; batch classifier loss: 0.188917; batch adversarial loss: 0.508904\n",
      "epoch 27; iter: 0; batch classifier loss: 0.145220; batch adversarial loss: 0.460687\n",
      "epoch 28; iter: 0; batch classifier loss: 0.223339; batch adversarial loss: 0.470277\n",
      "epoch 29; iter: 0; batch classifier loss: 0.209953; batch adversarial loss: 0.398680\n",
      "epoch 30; iter: 0; batch classifier loss: 0.229109; batch adversarial loss: 0.448251\n",
      "epoch 31; iter: 0; batch classifier loss: 0.138752; batch adversarial loss: 0.520806\n",
      "epoch 32; iter: 0; batch classifier loss: 0.133906; batch adversarial loss: 0.500527\n",
      "epoch 33; iter: 0; batch classifier loss: 0.154620; batch adversarial loss: 0.454247\n",
      "epoch 34; iter: 0; batch classifier loss: 0.199089; batch adversarial loss: 0.376961\n",
      "epoch 35; iter: 0; batch classifier loss: 0.147620; batch adversarial loss: 0.420198\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150407; batch adversarial loss: 0.345873\n",
      "epoch 37; iter: 0; batch classifier loss: 0.144909; batch adversarial loss: 0.469296\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148169; batch adversarial loss: 0.537042\n",
      "epoch 39; iter: 0; batch classifier loss: 0.222868; batch adversarial loss: 0.373693\n",
      "epoch 40; iter: 0; batch classifier loss: 0.152118; batch adversarial loss: 0.412319\n",
      "epoch 41; iter: 0; batch classifier loss: 0.104110; batch adversarial loss: 0.486351\n",
      "epoch 42; iter: 0; batch classifier loss: 0.187216; batch adversarial loss: 0.482740\n",
      "epoch 43; iter: 0; batch classifier loss: 0.120114; batch adversarial loss: 0.429666\n",
      "epoch 44; iter: 0; batch classifier loss: 0.167659; batch adversarial loss: 0.455644\n",
      "epoch 45; iter: 0; batch classifier loss: 0.161401; batch adversarial loss: 0.405573\n",
      "epoch 46; iter: 0; batch classifier loss: 0.168644; batch adversarial loss: 0.442268\n",
      "epoch 47; iter: 0; batch classifier loss: 0.145324; batch adversarial loss: 0.447928\n",
      "epoch 48; iter: 0; batch classifier loss: 0.159056; batch adversarial loss: 0.378855\n",
      "epoch 49; iter: 0; batch classifier loss: 0.131800; batch adversarial loss: 0.415804\n",
      "epoch 50; iter: 0; batch classifier loss: 0.147575; batch adversarial loss: 0.488177\n",
      "epoch 51; iter: 0; batch classifier loss: 0.209585; batch adversarial loss: 0.446029\n",
      "epoch 52; iter: 0; batch classifier loss: 0.175501; batch adversarial loss: 0.458559\n",
      "epoch 53; iter: 0; batch classifier loss: 0.127368; batch adversarial loss: 0.492205\n",
      "epoch 54; iter: 0; batch classifier loss: 0.117851; batch adversarial loss: 0.441030\n",
      "epoch 55; iter: 0; batch classifier loss: 0.149774; batch adversarial loss: 0.463300\n",
      "epoch 56; iter: 0; batch classifier loss: 0.121307; batch adversarial loss: 0.377580\n",
      "epoch 57; iter: 0; batch classifier loss: 0.144960; batch adversarial loss: 0.454066\n",
      "epoch 58; iter: 0; batch classifier loss: 0.102301; batch adversarial loss: 0.434464\n",
      "epoch 59; iter: 0; batch classifier loss: 0.106026; batch adversarial loss: 0.453326\n",
      "epoch 60; iter: 0; batch classifier loss: 0.144326; batch adversarial loss: 0.521803\n",
      "epoch 61; iter: 0; batch classifier loss: 0.105064; batch adversarial loss: 0.455030\n",
      "epoch 62; iter: 0; batch classifier loss: 0.136850; batch adversarial loss: 0.382173\n",
      "epoch 63; iter: 0; batch classifier loss: 0.156562; batch adversarial loss: 0.451839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.127170; batch adversarial loss: 0.491253\n",
      "epoch 65; iter: 0; batch classifier loss: 0.168206; batch adversarial loss: 0.358446\n",
      "epoch 66; iter: 0; batch classifier loss: 0.118607; batch adversarial loss: 0.420699\n",
      "epoch 67; iter: 0; batch classifier loss: 0.162711; batch adversarial loss: 0.511533\n",
      "epoch 68; iter: 0; batch classifier loss: 0.108795; batch adversarial loss: 0.424364\n",
      "epoch 69; iter: 0; batch classifier loss: 0.077529; batch adversarial loss: 0.484858\n",
      "epoch 70; iter: 0; batch classifier loss: 0.098546; batch adversarial loss: 0.526873\n",
      "epoch 71; iter: 0; batch classifier loss: 0.155880; batch adversarial loss: 0.471284\n",
      "epoch 72; iter: 0; batch classifier loss: 0.084439; batch adversarial loss: 0.386237\n",
      "epoch 73; iter: 0; batch classifier loss: 0.124668; batch adversarial loss: 0.535879\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069821; batch adversarial loss: 0.441514\n",
      "epoch 75; iter: 0; batch classifier loss: 0.093493; batch adversarial loss: 0.495298\n",
      "epoch 76; iter: 0; batch classifier loss: 0.087116; batch adversarial loss: 0.525851\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064423; batch adversarial loss: 0.427581\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074463; batch adversarial loss: 0.491866\n",
      "epoch 79; iter: 0; batch classifier loss: 0.079708; batch adversarial loss: 0.444491\n",
      "epoch 80; iter: 0; batch classifier loss: 0.046880; batch adversarial loss: 0.489140\n",
      "epoch 81; iter: 0; batch classifier loss: 0.115321; batch adversarial loss: 0.449053\n",
      "epoch 82; iter: 0; batch classifier loss: 0.098245; batch adversarial loss: 0.385418\n",
      "epoch 83; iter: 0; batch classifier loss: 0.103244; batch adversarial loss: 0.427050\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080436; batch adversarial loss: 0.489415\n",
      "epoch 85; iter: 0; batch classifier loss: 0.096527; batch adversarial loss: 0.416481\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073047; batch adversarial loss: 0.397005\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062433; batch adversarial loss: 0.326263\n",
      "epoch 88; iter: 0; batch classifier loss: 0.068725; batch adversarial loss: 0.490002\n",
      "epoch 89; iter: 0; batch classifier loss: 0.085332; batch adversarial loss: 0.363950\n",
      "epoch 90; iter: 0; batch classifier loss: 0.070442; batch adversarial loss: 0.435803\n",
      "epoch 91; iter: 0; batch classifier loss: 0.114308; batch adversarial loss: 0.477164\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071507; batch adversarial loss: 0.539606\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056034; batch adversarial loss: 0.452882\n",
      "epoch 94; iter: 0; batch classifier loss: 0.076677; batch adversarial loss: 0.477090\n",
      "epoch 95; iter: 0; batch classifier loss: 0.089609; batch adversarial loss: 0.424127\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057539; batch adversarial loss: 0.440797\n",
      "epoch 97; iter: 0; batch classifier loss: 0.058465; batch adversarial loss: 0.547650\n",
      "epoch 98; iter: 0; batch classifier loss: 0.069356; batch adversarial loss: 0.390233\n",
      "epoch 99; iter: 0; batch classifier loss: 0.035756; batch adversarial loss: 0.466358\n",
      "epoch 100; iter: 0; batch classifier loss: 0.143859; batch adversarial loss: 0.362968\n",
      "epoch 101; iter: 0; batch classifier loss: 0.079388; batch adversarial loss: 0.433814\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046940; batch adversarial loss: 0.446587\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064126; batch adversarial loss: 0.438714\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063323; batch adversarial loss: 0.451880\n",
      "epoch 105; iter: 0; batch classifier loss: 0.070369; batch adversarial loss: 0.332665\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039223; batch adversarial loss: 0.416987\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041557; batch adversarial loss: 0.381995\n",
      "epoch 108; iter: 0; batch classifier loss: 0.061998; batch adversarial loss: 0.442389\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047513; batch adversarial loss: 0.430695\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060862; batch adversarial loss: 0.403948\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062970; batch adversarial loss: 0.456383\n",
      "epoch 112; iter: 0; batch classifier loss: 0.087208; batch adversarial loss: 0.447106\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058255; batch adversarial loss: 0.432511\n",
      "epoch 114; iter: 0; batch classifier loss: 0.074915; batch adversarial loss: 0.474668\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054571; batch adversarial loss: 0.480544\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026537; batch adversarial loss: 0.403144\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045563; batch adversarial loss: 0.412091\n",
      "epoch 118; iter: 0; batch classifier loss: 0.015927; batch adversarial loss: 0.539230\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032024; batch adversarial loss: 0.436638\n",
      "epoch 120; iter: 0; batch classifier loss: 0.029974; batch adversarial loss: 0.366239\n",
      "epoch 121; iter: 0; batch classifier loss: 0.061880; batch adversarial loss: 0.442056\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033501; batch adversarial loss: 0.429063\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021718; batch adversarial loss: 0.428226\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048257; batch adversarial loss: 0.535567\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042769; batch adversarial loss: 0.388606\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055503; batch adversarial loss: 0.523916\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036031; batch adversarial loss: 0.396955\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039005; batch adversarial loss: 0.377803\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046257; batch adversarial loss: 0.373484\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050951; batch adversarial loss: 0.464950\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047441; batch adversarial loss: 0.496951\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029717; batch adversarial loss: 0.449695\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035562; batch adversarial loss: 0.360452\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038652; batch adversarial loss: 0.459428\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020395; batch adversarial loss: 0.361946\n",
      "epoch 136; iter: 0; batch classifier loss: 0.059410; batch adversarial loss: 0.475314\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031114; batch adversarial loss: 0.531276\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045363; batch adversarial loss: 0.450396\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029463; batch adversarial loss: 0.514003\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032060; batch adversarial loss: 0.432221\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039085; batch adversarial loss: 0.457395\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027196; batch adversarial loss: 0.457184\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023627; batch adversarial loss: 0.454766\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039516; batch adversarial loss: 0.427019\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019081; batch adversarial loss: 0.488614\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044080; batch adversarial loss: 0.413134\n",
      "epoch 147; iter: 0; batch classifier loss: 0.050724; batch adversarial loss: 0.490778\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023876; batch adversarial loss: 0.362168\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023422; batch adversarial loss: 0.466438\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023864; batch adversarial loss: 0.366647\n",
      "epoch 151; iter: 0; batch classifier loss: 0.005648; batch adversarial loss: 0.523145\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021094; batch adversarial loss: 0.521659\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022315; batch adversarial loss: 0.567638\n",
      "epoch 154; iter: 0; batch classifier loss: 0.053292; batch adversarial loss: 0.339647\n",
      "epoch 155; iter: 0; batch classifier loss: 0.039624; batch adversarial loss: 0.509524\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019001; batch adversarial loss: 0.480537\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031721; batch adversarial loss: 0.414279\n",
      "epoch 158; iter: 0; batch classifier loss: 0.046966; batch adversarial loss: 0.478387\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035038; batch adversarial loss: 0.428307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.018513; batch adversarial loss: 0.356416\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038025; batch adversarial loss: 0.423633\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022774; batch adversarial loss: 0.436045\n",
      "epoch 163; iter: 0; batch classifier loss: 0.050166; batch adversarial loss: 0.517036\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013506; batch adversarial loss: 0.447702\n",
      "epoch 165; iter: 0; batch classifier loss: 0.048692; batch adversarial loss: 0.405170\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018977; batch adversarial loss: 0.378288\n",
      "epoch 167; iter: 0; batch classifier loss: 0.070402; batch adversarial loss: 0.447803\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010707; batch adversarial loss: 0.446782\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024499; batch adversarial loss: 0.533187\n",
      "epoch 170; iter: 0; batch classifier loss: 0.046324; batch adversarial loss: 0.434036\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032939; batch adversarial loss: 0.363748\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009350; batch adversarial loss: 0.490889\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036944; batch adversarial loss: 0.415891\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017282; batch adversarial loss: 0.468046\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016838; batch adversarial loss: 0.424538\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022994; batch adversarial loss: 0.363830\n",
      "epoch 177; iter: 0; batch classifier loss: 0.048200; batch adversarial loss: 0.447200\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022085; batch adversarial loss: 0.491614\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043512; batch adversarial loss: 0.489325\n",
      "epoch 180; iter: 0; batch classifier loss: 0.046359; batch adversarial loss: 0.417432\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025583; batch adversarial loss: 0.358636\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008320; batch adversarial loss: 0.431185\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012451; batch adversarial loss: 0.353957\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015772; batch adversarial loss: 0.488189\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020116; batch adversarial loss: 0.499797\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009671; batch adversarial loss: 0.524647\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013502; batch adversarial loss: 0.359842\n",
      "epoch 188; iter: 0; batch classifier loss: 0.001818; batch adversarial loss: 0.471247\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035731; batch adversarial loss: 0.501348\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023259; batch adversarial loss: 0.485048\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016687; batch adversarial loss: 0.544171\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012235; batch adversarial loss: 0.432165\n",
      "epoch 193; iter: 0; batch classifier loss: 0.034053; batch adversarial loss: 0.439380\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024664; batch adversarial loss: 0.460580\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036882; batch adversarial loss: 0.629136\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030959; batch adversarial loss: 0.449803\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021847; batch adversarial loss: 0.513416\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032130; batch adversarial loss: 0.488126\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031656; batch adversarial loss: 0.539620\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696653; batch adversarial loss: 0.695497\n",
      "epoch 1; iter: 0; batch classifier loss: 0.498428; batch adversarial loss: 0.649807\n",
      "epoch 2; iter: 0; batch classifier loss: 0.466041; batch adversarial loss: 0.646703\n",
      "epoch 3; iter: 0; batch classifier loss: 0.379762; batch adversarial loss: 0.630174\n",
      "epoch 4; iter: 0; batch classifier loss: 0.443070; batch adversarial loss: 0.593194\n",
      "epoch 5; iter: 0; batch classifier loss: 0.491330; batch adversarial loss: 0.587316\n",
      "epoch 6; iter: 0; batch classifier loss: 0.400470; batch adversarial loss: 0.606095\n",
      "epoch 7; iter: 0; batch classifier loss: 0.485386; batch adversarial loss: 0.569472\n",
      "epoch 8; iter: 0; batch classifier loss: 0.445451; batch adversarial loss: 0.573273\n",
      "epoch 9; iter: 0; batch classifier loss: 0.426411; batch adversarial loss: 0.548102\n",
      "epoch 10; iter: 0; batch classifier loss: 0.364143; batch adversarial loss: 0.542721\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403307; batch adversarial loss: 0.509787\n",
      "epoch 12; iter: 0; batch classifier loss: 0.295353; batch adversarial loss: 0.561200\n",
      "epoch 13; iter: 0; batch classifier loss: 0.400744; batch adversarial loss: 0.577013\n",
      "epoch 14; iter: 0; batch classifier loss: 0.410758; batch adversarial loss: 0.487969\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307682; batch adversarial loss: 0.487457\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311538; batch adversarial loss: 0.489454\n",
      "epoch 17; iter: 0; batch classifier loss: 0.349864; batch adversarial loss: 0.506643\n",
      "epoch 18; iter: 0; batch classifier loss: 0.399487; batch adversarial loss: 0.528846\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338906; batch adversarial loss: 0.515865\n",
      "epoch 20; iter: 0; batch classifier loss: 0.339152; batch adversarial loss: 0.421945\n",
      "epoch 21; iter: 0; batch classifier loss: 0.219618; batch adversarial loss: 0.465891\n",
      "epoch 22; iter: 0; batch classifier loss: 0.264477; batch adversarial loss: 0.456241\n",
      "epoch 23; iter: 0; batch classifier loss: 0.197403; batch adversarial loss: 0.502304\n",
      "epoch 24; iter: 0; batch classifier loss: 0.234275; batch adversarial loss: 0.534927\n",
      "epoch 25; iter: 0; batch classifier loss: 0.279450; batch adversarial loss: 0.502336\n",
      "epoch 26; iter: 0; batch classifier loss: 0.243888; batch adversarial loss: 0.566448\n",
      "epoch 27; iter: 0; batch classifier loss: 0.217655; batch adversarial loss: 0.505331\n",
      "epoch 28; iter: 0; batch classifier loss: 0.230297; batch adversarial loss: 0.530115\n",
      "epoch 29; iter: 0; batch classifier loss: 0.319329; batch adversarial loss: 0.429245\n",
      "epoch 30; iter: 0; batch classifier loss: 0.226071; batch adversarial loss: 0.513598\n",
      "epoch 31; iter: 0; batch classifier loss: 0.269177; batch adversarial loss: 0.517310\n",
      "epoch 32; iter: 0; batch classifier loss: 0.196176; batch adversarial loss: 0.494643\n",
      "epoch 33; iter: 0; batch classifier loss: 0.275375; batch adversarial loss: 0.425566\n",
      "epoch 34; iter: 0; batch classifier loss: 0.311273; batch adversarial loss: 0.470847\n",
      "epoch 35; iter: 0; batch classifier loss: 0.221872; batch adversarial loss: 0.497011\n",
      "epoch 36; iter: 0; batch classifier loss: 0.230476; batch adversarial loss: 0.549459\n",
      "epoch 37; iter: 0; batch classifier loss: 0.275053; batch adversarial loss: 0.530817\n",
      "epoch 38; iter: 0; batch classifier loss: 0.187570; batch adversarial loss: 0.491855\n",
      "epoch 39; iter: 0; batch classifier loss: 0.315934; batch adversarial loss: 0.404374\n",
      "epoch 40; iter: 0; batch classifier loss: 0.233567; batch adversarial loss: 0.412721\n",
      "epoch 41; iter: 0; batch classifier loss: 0.186845; batch adversarial loss: 0.483024\n",
      "epoch 42; iter: 0; batch classifier loss: 0.240089; batch adversarial loss: 0.438870\n",
      "epoch 43; iter: 0; batch classifier loss: 0.205020; batch adversarial loss: 0.496602\n",
      "epoch 44; iter: 0; batch classifier loss: 0.174036; batch adversarial loss: 0.505577\n",
      "epoch 45; iter: 0; batch classifier loss: 0.221103; batch adversarial loss: 0.423072\n",
      "epoch 46; iter: 0; batch classifier loss: 0.230151; batch adversarial loss: 0.413610\n",
      "epoch 47; iter: 0; batch classifier loss: 0.201948; batch adversarial loss: 0.494380\n",
      "epoch 48; iter: 0; batch classifier loss: 0.193790; batch adversarial loss: 0.506108\n",
      "epoch 49; iter: 0; batch classifier loss: 0.235904; batch adversarial loss: 0.457458\n",
      "epoch 50; iter: 0; batch classifier loss: 0.152568; batch adversarial loss: 0.482576\n",
      "epoch 51; iter: 0; batch classifier loss: 0.165422; batch adversarial loss: 0.433576\n",
      "epoch 52; iter: 0; batch classifier loss: 0.247742; batch adversarial loss: 0.494448\n",
      "epoch 53; iter: 0; batch classifier loss: 0.219178; batch adversarial loss: 0.507243\n",
      "epoch 54; iter: 0; batch classifier loss: 0.171005; batch adversarial loss: 0.363018\n",
      "epoch 55; iter: 0; batch classifier loss: 0.149751; batch adversarial loss: 0.458132\n",
      "epoch 56; iter: 0; batch classifier loss: 0.164123; batch adversarial loss: 0.374583\n",
      "epoch 57; iter: 0; batch classifier loss: 0.179802; batch adversarial loss: 0.483366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.310822; batch adversarial loss: 0.446637\n",
      "epoch 59; iter: 0; batch classifier loss: 0.151455; batch adversarial loss: 0.422522\n",
      "epoch 60; iter: 0; batch classifier loss: 0.107232; batch adversarial loss: 0.467930\n",
      "epoch 61; iter: 0; batch classifier loss: 0.089958; batch adversarial loss: 0.461087\n",
      "epoch 62; iter: 0; batch classifier loss: 0.193956; batch adversarial loss: 0.399111\n",
      "epoch 63; iter: 0; batch classifier loss: 0.234220; batch adversarial loss: 0.484423\n",
      "epoch 64; iter: 0; batch classifier loss: 0.232445; batch adversarial loss: 0.481641\n",
      "epoch 65; iter: 0; batch classifier loss: 0.156944; batch adversarial loss: 0.471089\n",
      "epoch 66; iter: 0; batch classifier loss: 0.194630; batch adversarial loss: 0.505400\n",
      "epoch 67; iter: 0; batch classifier loss: 0.174217; batch adversarial loss: 0.545485\n",
      "epoch 68; iter: 0; batch classifier loss: 0.183622; batch adversarial loss: 0.459107\n",
      "epoch 69; iter: 0; batch classifier loss: 0.211604; batch adversarial loss: 0.482532\n",
      "epoch 70; iter: 0; batch classifier loss: 0.355942; batch adversarial loss: 0.423362\n",
      "epoch 71; iter: 0; batch classifier loss: 0.143733; batch adversarial loss: 0.396908\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054065; batch adversarial loss: 0.529573\n",
      "epoch 73; iter: 0; batch classifier loss: 0.094703; batch adversarial loss: 0.467991\n",
      "epoch 74; iter: 0; batch classifier loss: 0.149740; batch adversarial loss: 0.408916\n",
      "epoch 75; iter: 0; batch classifier loss: 0.188468; batch adversarial loss: 0.445023\n",
      "epoch 76; iter: 0; batch classifier loss: 0.175696; batch adversarial loss: 0.326185\n",
      "epoch 77; iter: 0; batch classifier loss: 0.234397; batch adversarial loss: 0.518787\n",
      "epoch 78; iter: 0; batch classifier loss: 0.216189; batch adversarial loss: 0.504792\n",
      "epoch 79; iter: 0; batch classifier loss: 0.109426; batch adversarial loss: 0.556729\n",
      "epoch 80; iter: 0; batch classifier loss: 0.189380; batch adversarial loss: 0.436020\n",
      "epoch 81; iter: 0; batch classifier loss: 0.227999; batch adversarial loss: 0.374904\n",
      "epoch 82; iter: 0; batch classifier loss: 0.187090; batch adversarial loss: 0.533789\n",
      "epoch 83; iter: 0; batch classifier loss: 0.181411; batch adversarial loss: 0.386454\n",
      "epoch 84; iter: 0; batch classifier loss: 0.142949; batch adversarial loss: 0.531979\n",
      "epoch 85; iter: 0; batch classifier loss: 0.220417; batch adversarial loss: 0.447707\n",
      "epoch 86; iter: 0; batch classifier loss: 0.181952; batch adversarial loss: 0.482536\n",
      "epoch 87; iter: 0; batch classifier loss: 0.136129; batch adversarial loss: 0.422342\n",
      "epoch 88; iter: 0; batch classifier loss: 0.085845; batch adversarial loss: 0.508348\n",
      "epoch 89; iter: 0; batch classifier loss: 0.186423; batch adversarial loss: 0.461677\n",
      "epoch 90; iter: 0; batch classifier loss: 0.215347; batch adversarial loss: 0.469599\n",
      "epoch 91; iter: 0; batch classifier loss: 0.187238; batch adversarial loss: 0.410293\n",
      "epoch 92; iter: 0; batch classifier loss: 0.159409; batch adversarial loss: 0.493878\n",
      "epoch 93; iter: 0; batch classifier loss: 0.135605; batch adversarial loss: 0.483187\n",
      "epoch 94; iter: 0; batch classifier loss: 0.258313; batch adversarial loss: 0.446857\n",
      "epoch 95; iter: 0; batch classifier loss: 0.221746; batch adversarial loss: 0.495245\n",
      "epoch 96; iter: 0; batch classifier loss: 0.135911; batch adversarial loss: 0.482951\n",
      "epoch 97; iter: 0; batch classifier loss: 0.175649; batch adversarial loss: 0.361344\n",
      "epoch 98; iter: 0; batch classifier loss: 0.186866; batch adversarial loss: 0.445367\n",
      "epoch 99; iter: 0; batch classifier loss: 0.177670; batch adversarial loss: 0.484487\n",
      "epoch 100; iter: 0; batch classifier loss: 0.161586; batch adversarial loss: 0.469491\n",
      "epoch 101; iter: 0; batch classifier loss: 0.196379; batch adversarial loss: 0.443393\n",
      "epoch 102; iter: 0; batch classifier loss: 0.150557; batch adversarial loss: 0.432145\n",
      "epoch 103; iter: 0; batch classifier loss: 0.134891; batch adversarial loss: 0.410737\n",
      "epoch 104; iter: 0; batch classifier loss: 0.151281; batch adversarial loss: 0.384203\n",
      "epoch 105; iter: 0; batch classifier loss: 0.134172; batch adversarial loss: 0.458594\n",
      "epoch 106; iter: 0; batch classifier loss: 0.104700; batch adversarial loss: 0.519216\n",
      "epoch 107; iter: 0; batch classifier loss: 0.111947; batch adversarial loss: 0.452476\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064523; batch adversarial loss: 0.374033\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053552; batch adversarial loss: 0.387886\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068003; batch adversarial loss: 0.474338\n",
      "epoch 111; iter: 0; batch classifier loss: 0.078666; batch adversarial loss: 0.448535\n",
      "epoch 112; iter: 0; batch classifier loss: 0.049969; batch adversarial loss: 0.371349\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040318; batch adversarial loss: 0.427480\n",
      "epoch 114; iter: 0; batch classifier loss: 0.081325; batch adversarial loss: 0.400134\n",
      "epoch 115; iter: 0; batch classifier loss: 0.047355; batch adversarial loss: 0.456952\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037357; batch adversarial loss: 0.384028\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038356; batch adversarial loss: 0.468965\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050802; batch adversarial loss: 0.418980\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022369; batch adversarial loss: 0.517432\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040384; batch adversarial loss: 0.491661\n",
      "epoch 121; iter: 0; batch classifier loss: 0.072379; batch adversarial loss: 0.423072\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015536; batch adversarial loss: 0.497197\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014338; batch adversarial loss: 0.388622\n",
      "epoch 124; iter: 0; batch classifier loss: 0.073845; batch adversarial loss: 0.542952\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023473; batch adversarial loss: 0.442260\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050686; batch adversarial loss: 0.505748\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040400; batch adversarial loss: 0.460760\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041891; batch adversarial loss: 0.448847\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022093; batch adversarial loss: 0.467522\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035369; batch adversarial loss: 0.393541\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043792; batch adversarial loss: 0.394997\n",
      "epoch 132; iter: 0; batch classifier loss: 0.069166; batch adversarial loss: 0.584413\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022508; batch adversarial loss: 0.429283\n",
      "epoch 134; iter: 0; batch classifier loss: 0.072588; batch adversarial loss: 0.440454\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027813; batch adversarial loss: 0.487063\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017476; batch adversarial loss: 0.397731\n",
      "epoch 137; iter: 0; batch classifier loss: 0.077436; batch adversarial loss: 0.439074\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019415; batch adversarial loss: 0.465522\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014836; batch adversarial loss: 0.472610\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032587; batch adversarial loss: 0.399776\n",
      "epoch 141; iter: 0; batch classifier loss: 0.047701; batch adversarial loss: 0.455186\n",
      "epoch 142; iter: 0; batch classifier loss: 0.051747; batch adversarial loss: 0.438058\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024621; batch adversarial loss: 0.467546\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027801; batch adversarial loss: 0.454286\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043861; batch adversarial loss: 0.435484\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020214; batch adversarial loss: 0.357731\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043973; batch adversarial loss: 0.547840\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021183; batch adversarial loss: 0.419301\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033933; batch adversarial loss: 0.389782\n",
      "epoch 150; iter: 0; batch classifier loss: 0.010869; batch adversarial loss: 0.504979\n",
      "epoch 151; iter: 0; batch classifier loss: 0.006085; batch adversarial loss: 0.383378\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035395; batch adversarial loss: 0.437746\n",
      "epoch 153; iter: 0; batch classifier loss: 0.005955; batch adversarial loss: 0.392137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.029916; batch adversarial loss: 0.476681\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014940; batch adversarial loss: 0.565180\n",
      "epoch 156; iter: 0; batch classifier loss: 0.051269; batch adversarial loss: 0.496750\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016780; batch adversarial loss: 0.506718\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019865; batch adversarial loss: 0.393127\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015539; batch adversarial loss: 0.476658\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010498; batch adversarial loss: 0.440474\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023867; batch adversarial loss: 0.487791\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014490; batch adversarial loss: 0.481619\n",
      "epoch 163; iter: 0; batch classifier loss: 0.008231; batch adversarial loss: 0.517789\n",
      "epoch 164; iter: 0; batch classifier loss: 0.045564; batch adversarial loss: 0.433468\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013859; batch adversarial loss: 0.461701\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010123; batch adversarial loss: 0.485103\n",
      "epoch 167; iter: 0; batch classifier loss: 0.049826; batch adversarial loss: 0.446041\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019665; batch adversarial loss: 0.456946\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038368; batch adversarial loss: 0.405316\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025429; batch adversarial loss: 0.422891\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015442; batch adversarial loss: 0.400136\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034571; batch adversarial loss: 0.436463\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007264; batch adversarial loss: 0.372970\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022355; batch adversarial loss: 0.483363\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020622; batch adversarial loss: 0.579151\n",
      "epoch 176; iter: 0; batch classifier loss: 0.003490; batch adversarial loss: 0.487833\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024224; batch adversarial loss: 0.499079\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011458; batch adversarial loss: 0.437549\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020662; batch adversarial loss: 0.481900\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019023; batch adversarial loss: 0.463437\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022532; batch adversarial loss: 0.448178\n",
      "epoch 182; iter: 0; batch classifier loss: 0.005549; batch adversarial loss: 0.418835\n",
      "epoch 183; iter: 0; batch classifier loss: 0.035961; batch adversarial loss: 0.450260\n",
      "epoch 184; iter: 0; batch classifier loss: 0.002938; batch adversarial loss: 0.514534\n",
      "epoch 185; iter: 0; batch classifier loss: 0.047427; batch adversarial loss: 0.550213\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024622; batch adversarial loss: 0.383814\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025972; batch adversarial loss: 0.446160\n",
      "epoch 188; iter: 0; batch classifier loss: 0.002486; batch adversarial loss: 0.489078\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009057; batch adversarial loss: 0.434204\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011181; batch adversarial loss: 0.397021\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013094; batch adversarial loss: 0.481849\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015126; batch adversarial loss: 0.433958\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019147; batch adversarial loss: 0.520360\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011080; batch adversarial loss: 0.413976\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014227; batch adversarial loss: 0.517649\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006751; batch adversarial loss: 0.437151\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010279; batch adversarial loss: 0.384727\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019193; batch adversarial loss: 0.446482\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008987; batch adversarial loss: 0.379083\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683630; batch adversarial loss: 0.529712\n",
      "epoch 1; iter: 0; batch classifier loss: 0.486975; batch adversarial loss: 0.550168\n",
      "epoch 2; iter: 0; batch classifier loss: 0.347610; batch adversarial loss: 0.609445\n",
      "epoch 3; iter: 0; batch classifier loss: 0.356176; batch adversarial loss: 0.600629\n",
      "epoch 4; iter: 0; batch classifier loss: 0.311070; batch adversarial loss: 0.550374\n",
      "epoch 5; iter: 0; batch classifier loss: 0.386101; batch adversarial loss: 0.596182\n",
      "epoch 6; iter: 0; batch classifier loss: 0.334737; batch adversarial loss: 0.594334\n",
      "epoch 7; iter: 0; batch classifier loss: 0.412811; batch adversarial loss: 0.610521\n",
      "epoch 8; iter: 0; batch classifier loss: 0.446136; batch adversarial loss: 0.541206\n",
      "epoch 9; iter: 0; batch classifier loss: 0.442530; batch adversarial loss: 0.583915\n",
      "epoch 10; iter: 0; batch classifier loss: 0.386223; batch adversarial loss: 0.532654\n",
      "epoch 11; iter: 0; batch classifier loss: 0.354132; batch adversarial loss: 0.478247\n",
      "epoch 12; iter: 0; batch classifier loss: 0.294127; batch adversarial loss: 0.517902\n",
      "epoch 13; iter: 0; batch classifier loss: 0.314215; batch adversarial loss: 0.504025\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236715; batch adversarial loss: 0.462762\n",
      "epoch 15; iter: 0; batch classifier loss: 0.243900; batch adversarial loss: 0.446278\n",
      "epoch 16; iter: 0; batch classifier loss: 0.274196; batch adversarial loss: 0.373112\n",
      "epoch 17; iter: 0; batch classifier loss: 0.178882; batch adversarial loss: 0.575185\n",
      "epoch 18; iter: 0; batch classifier loss: 0.235585; batch adversarial loss: 0.508102\n",
      "epoch 19; iter: 0; batch classifier loss: 0.256335; batch adversarial loss: 0.553684\n",
      "epoch 20; iter: 0; batch classifier loss: 0.225833; batch adversarial loss: 0.467913\n",
      "epoch 21; iter: 0; batch classifier loss: 0.145546; batch adversarial loss: 0.425610\n",
      "epoch 22; iter: 0; batch classifier loss: 0.153402; batch adversarial loss: 0.507035\n",
      "epoch 23; iter: 0; batch classifier loss: 0.181246; batch adversarial loss: 0.444399\n",
      "epoch 24; iter: 0; batch classifier loss: 0.228460; batch adversarial loss: 0.448794\n",
      "epoch 25; iter: 0; batch classifier loss: 0.208474; batch adversarial loss: 0.550987\n",
      "epoch 26; iter: 0; batch classifier loss: 0.198783; batch adversarial loss: 0.446102\n",
      "epoch 27; iter: 0; batch classifier loss: 0.179458; batch adversarial loss: 0.477941\n",
      "epoch 28; iter: 0; batch classifier loss: 0.178357; batch adversarial loss: 0.509953\n",
      "epoch 29; iter: 0; batch classifier loss: 0.186901; batch adversarial loss: 0.375551\n",
      "epoch 30; iter: 0; batch classifier loss: 0.196133; batch adversarial loss: 0.499431\n",
      "epoch 31; iter: 0; batch classifier loss: 0.123267; batch adversarial loss: 0.381097\n",
      "epoch 32; iter: 0; batch classifier loss: 0.133778; batch adversarial loss: 0.480960\n",
      "epoch 33; iter: 0; batch classifier loss: 0.168255; batch adversarial loss: 0.446556\n",
      "epoch 34; iter: 0; batch classifier loss: 0.133768; batch adversarial loss: 0.419058\n",
      "epoch 35; iter: 0; batch classifier loss: 0.207550; batch adversarial loss: 0.423451\n",
      "epoch 36; iter: 0; batch classifier loss: 0.127883; batch adversarial loss: 0.566388\n",
      "epoch 37; iter: 0; batch classifier loss: 0.154328; batch adversarial loss: 0.488117\n",
      "epoch 38; iter: 0; batch classifier loss: 0.141189; batch adversarial loss: 0.456793\n",
      "epoch 39; iter: 0; batch classifier loss: 0.184312; batch adversarial loss: 0.370073\n",
      "epoch 40; iter: 0; batch classifier loss: 0.163068; batch adversarial loss: 0.395272\n",
      "epoch 41; iter: 0; batch classifier loss: 0.152559; batch adversarial loss: 0.469705\n",
      "epoch 42; iter: 0; batch classifier loss: 0.115743; batch adversarial loss: 0.399637\n",
      "epoch 43; iter: 0; batch classifier loss: 0.094586; batch adversarial loss: 0.423157\n",
      "epoch 44; iter: 0; batch classifier loss: 0.174930; batch adversarial loss: 0.520612\n",
      "epoch 45; iter: 0; batch classifier loss: 0.152099; batch adversarial loss: 0.496986\n",
      "epoch 46; iter: 0; batch classifier loss: 0.165569; batch adversarial loss: 0.423003\n",
      "epoch 47; iter: 0; batch classifier loss: 0.103935; batch adversarial loss: 0.512886\n",
      "epoch 48; iter: 0; batch classifier loss: 0.178680; batch adversarial loss: 0.476894\n",
      "epoch 49; iter: 0; batch classifier loss: 0.155915; batch adversarial loss: 0.389254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.131876; batch adversarial loss: 0.532710\n",
      "epoch 51; iter: 0; batch classifier loss: 0.156850; batch adversarial loss: 0.436792\n",
      "epoch 52; iter: 0; batch classifier loss: 0.184964; batch adversarial loss: 0.433566\n",
      "epoch 53; iter: 0; batch classifier loss: 0.080237; batch adversarial loss: 0.496071\n",
      "epoch 54; iter: 0; batch classifier loss: 0.113401; batch adversarial loss: 0.496134\n",
      "epoch 55; iter: 0; batch classifier loss: 0.100098; batch adversarial loss: 0.498507\n",
      "epoch 56; iter: 0; batch classifier loss: 0.200197; batch adversarial loss: 0.404908\n",
      "epoch 57; iter: 0; batch classifier loss: 0.134294; batch adversarial loss: 0.532061\n",
      "epoch 58; iter: 0; batch classifier loss: 0.160741; batch adversarial loss: 0.444501\n",
      "epoch 59; iter: 0; batch classifier loss: 0.143720; batch adversarial loss: 0.391906\n",
      "epoch 60; iter: 0; batch classifier loss: 0.104448; batch adversarial loss: 0.498250\n",
      "epoch 61; iter: 0; batch classifier loss: 0.142269; batch adversarial loss: 0.503959\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092338; batch adversarial loss: 0.566220\n",
      "epoch 63; iter: 0; batch classifier loss: 0.100118; batch adversarial loss: 0.484522\n",
      "epoch 64; iter: 0; batch classifier loss: 0.145045; batch adversarial loss: 0.477590\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077496; batch adversarial loss: 0.491478\n",
      "epoch 66; iter: 0; batch classifier loss: 0.123198; batch adversarial loss: 0.423993\n",
      "epoch 67; iter: 0; batch classifier loss: 0.117767; batch adversarial loss: 0.433080\n",
      "epoch 68; iter: 0; batch classifier loss: 0.107256; batch adversarial loss: 0.457532\n",
      "epoch 69; iter: 0; batch classifier loss: 0.200279; batch adversarial loss: 0.515870\n",
      "epoch 70; iter: 0; batch classifier loss: 0.132985; batch adversarial loss: 0.389152\n",
      "epoch 71; iter: 0; batch classifier loss: 0.172012; batch adversarial loss: 0.511350\n",
      "epoch 72; iter: 0; batch classifier loss: 0.169038; batch adversarial loss: 0.376594\n",
      "epoch 73; iter: 0; batch classifier loss: 0.121594; batch adversarial loss: 0.465051\n",
      "epoch 74; iter: 0; batch classifier loss: 0.104322; batch adversarial loss: 0.374832\n",
      "epoch 75; iter: 0; batch classifier loss: 0.138259; batch adversarial loss: 0.402634\n",
      "epoch 76; iter: 0; batch classifier loss: 0.124368; batch adversarial loss: 0.525353\n",
      "epoch 77; iter: 0; batch classifier loss: 0.115446; batch adversarial loss: 0.554043\n",
      "epoch 78; iter: 0; batch classifier loss: 0.149246; batch adversarial loss: 0.454528\n",
      "epoch 79; iter: 0; batch classifier loss: 0.114292; batch adversarial loss: 0.430563\n",
      "epoch 80; iter: 0; batch classifier loss: 0.157252; batch adversarial loss: 0.493781\n",
      "epoch 81; iter: 0; batch classifier loss: 0.119021; batch adversarial loss: 0.543880\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073031; batch adversarial loss: 0.536848\n",
      "epoch 83; iter: 0; batch classifier loss: 0.126335; batch adversarial loss: 0.489155\n",
      "epoch 84; iter: 0; batch classifier loss: 0.139429; batch adversarial loss: 0.489279\n",
      "epoch 85; iter: 0; batch classifier loss: 0.071453; batch adversarial loss: 0.546259\n",
      "epoch 86; iter: 0; batch classifier loss: 0.110259; batch adversarial loss: 0.426547\n",
      "epoch 87; iter: 0; batch classifier loss: 0.133435; batch adversarial loss: 0.359547\n",
      "epoch 88; iter: 0; batch classifier loss: 0.127073; batch adversarial loss: 0.377677\n",
      "epoch 89; iter: 0; batch classifier loss: 0.155199; batch adversarial loss: 0.443228\n",
      "epoch 90; iter: 0; batch classifier loss: 0.145301; batch adversarial loss: 0.405851\n",
      "epoch 91; iter: 0; batch classifier loss: 0.100175; batch adversarial loss: 0.491535\n",
      "epoch 92; iter: 0; batch classifier loss: 0.111168; batch adversarial loss: 0.515464\n",
      "epoch 93; iter: 0; batch classifier loss: 0.120134; batch adversarial loss: 0.434093\n",
      "epoch 94; iter: 0; batch classifier loss: 0.108096; batch adversarial loss: 0.401173\n",
      "epoch 95; iter: 0; batch classifier loss: 0.065915; batch adversarial loss: 0.451519\n",
      "epoch 96; iter: 0; batch classifier loss: 0.086917; batch adversarial loss: 0.536536\n",
      "epoch 97; iter: 0; batch classifier loss: 0.110151; batch adversarial loss: 0.488436\n",
      "epoch 98; iter: 0; batch classifier loss: 0.144469; batch adversarial loss: 0.414815\n",
      "epoch 99; iter: 0; batch classifier loss: 0.076474; batch adversarial loss: 0.515419\n",
      "epoch 100; iter: 0; batch classifier loss: 0.102546; batch adversarial loss: 0.392312\n",
      "epoch 101; iter: 0; batch classifier loss: 0.093271; batch adversarial loss: 0.424429\n",
      "epoch 102; iter: 0; batch classifier loss: 0.085216; batch adversarial loss: 0.401279\n",
      "epoch 103; iter: 0; batch classifier loss: 0.103794; batch adversarial loss: 0.378661\n",
      "epoch 104; iter: 0; batch classifier loss: 0.091477; batch adversarial loss: 0.448903\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058588; batch adversarial loss: 0.426177\n",
      "epoch 106; iter: 0; batch classifier loss: 0.102583; batch adversarial loss: 0.545014\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066446; batch adversarial loss: 0.345681\n",
      "epoch 108; iter: 0; batch classifier loss: 0.076012; batch adversarial loss: 0.506286\n",
      "epoch 109; iter: 0; batch classifier loss: 0.080656; batch adversarial loss: 0.418390\n",
      "epoch 110; iter: 0; batch classifier loss: 0.107996; batch adversarial loss: 0.491109\n",
      "epoch 111; iter: 0; batch classifier loss: 0.082210; batch adversarial loss: 0.358171\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055805; batch adversarial loss: 0.430371\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045699; batch adversarial loss: 0.475372\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056193; batch adversarial loss: 0.408448\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049968; batch adversarial loss: 0.479804\n",
      "epoch 116; iter: 0; batch classifier loss: 0.059509; batch adversarial loss: 0.354616\n",
      "epoch 117; iter: 0; batch classifier loss: 0.068145; batch adversarial loss: 0.447276\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045253; batch adversarial loss: 0.419418\n",
      "epoch 119; iter: 0; batch classifier loss: 0.062426; batch adversarial loss: 0.509074\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042295; batch adversarial loss: 0.480645\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028486; batch adversarial loss: 0.467877\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042321; batch adversarial loss: 0.438980\n",
      "epoch 123; iter: 0; batch classifier loss: 0.082587; batch adversarial loss: 0.502710\n",
      "epoch 124; iter: 0; batch classifier loss: 0.058639; batch adversarial loss: 0.427758\n",
      "epoch 125; iter: 0; batch classifier loss: 0.014367; batch adversarial loss: 0.385463\n",
      "epoch 126; iter: 0; batch classifier loss: 0.018332; batch adversarial loss: 0.475864\n",
      "epoch 127; iter: 0; batch classifier loss: 0.068976; batch adversarial loss: 0.455133\n",
      "epoch 128; iter: 0; batch classifier loss: 0.059713; batch adversarial loss: 0.499368\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021609; batch adversarial loss: 0.401097\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046627; batch adversarial loss: 0.462393\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041772; batch adversarial loss: 0.495946\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032148; batch adversarial loss: 0.503691\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038423; batch adversarial loss: 0.538008\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034616; batch adversarial loss: 0.528779\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032836; batch adversarial loss: 0.486601\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039531; batch adversarial loss: 0.500316\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017394; batch adversarial loss: 0.447749\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035684; batch adversarial loss: 0.547065\n",
      "epoch 139; iter: 0; batch classifier loss: 0.058227; batch adversarial loss: 0.498658\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022058; batch adversarial loss: 0.457259\n",
      "epoch 141; iter: 0; batch classifier loss: 0.041112; batch adversarial loss: 0.500625\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031644; batch adversarial loss: 0.515167\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030623; batch adversarial loss: 0.436396\n",
      "epoch 144; iter: 0; batch classifier loss: 0.060624; batch adversarial loss: 0.423806\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048029; batch adversarial loss: 0.477707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.029756; batch adversarial loss: 0.495625\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027858; batch adversarial loss: 0.520175\n",
      "epoch 148; iter: 0; batch classifier loss: 0.057308; batch adversarial loss: 0.503683\n",
      "epoch 149; iter: 0; batch classifier loss: 0.054220; batch adversarial loss: 0.414376\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021674; batch adversarial loss: 0.520036\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031921; batch adversarial loss: 0.490346\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025088; batch adversarial loss: 0.488941\n",
      "epoch 153; iter: 0; batch classifier loss: 0.044023; batch adversarial loss: 0.529197\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028552; batch adversarial loss: 0.421760\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022091; batch adversarial loss: 0.448601\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034531; batch adversarial loss: 0.426219\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015378; batch adversarial loss: 0.497399\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019717; batch adversarial loss: 0.576728\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019792; batch adversarial loss: 0.467124\n",
      "epoch 160; iter: 0; batch classifier loss: 0.011229; batch adversarial loss: 0.465382\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036252; batch adversarial loss: 0.514227\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022256; batch adversarial loss: 0.431042\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018905; batch adversarial loss: 0.405996\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032360; batch adversarial loss: 0.456828\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029180; batch adversarial loss: 0.575126\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021450; batch adversarial loss: 0.383325\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018130; batch adversarial loss: 0.467628\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009202; batch adversarial loss: 0.402406\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017344; batch adversarial loss: 0.418719\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025761; batch adversarial loss: 0.354536\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024997; batch adversarial loss: 0.385427\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010032; batch adversarial loss: 0.426888\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010119; batch adversarial loss: 0.386282\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038377; batch adversarial loss: 0.464074\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021848; batch adversarial loss: 0.493029\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029668; batch adversarial loss: 0.385253\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046443; batch adversarial loss: 0.554816\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018755; batch adversarial loss: 0.461389\n",
      "epoch 179; iter: 0; batch classifier loss: 0.050102; batch adversarial loss: 0.531075\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025348; batch adversarial loss: 0.493862\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026832; batch adversarial loss: 0.391767\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026251; batch adversarial loss: 0.516998\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017250; batch adversarial loss: 0.581445\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014052; batch adversarial loss: 0.349361\n",
      "epoch 185; iter: 0; batch classifier loss: 0.050151; batch adversarial loss: 0.448148\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025544; batch adversarial loss: 0.421656\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011095; batch adversarial loss: 0.442255\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013781; batch adversarial loss: 0.400950\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026713; batch adversarial loss: 0.446435\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022742; batch adversarial loss: 0.472381\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013758; batch adversarial loss: 0.427408\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020347; batch adversarial loss: 0.505621\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016508; batch adversarial loss: 0.492922\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024850; batch adversarial loss: 0.445865\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031623; batch adversarial loss: 0.410627\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008471; batch adversarial loss: 0.500353\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006785; batch adversarial loss: 0.482070\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016113; batch adversarial loss: 0.313890\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020354; batch adversarial loss: 0.430627\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705934; batch adversarial loss: 0.742203\n",
      "epoch 1; iter: 0; batch classifier loss: 0.472786; batch adversarial loss: 0.686475\n",
      "epoch 2; iter: 0; batch classifier loss: 0.460025; batch adversarial loss: 0.642768\n",
      "epoch 3; iter: 0; batch classifier loss: 0.379669; batch adversarial loss: 0.627116\n",
      "epoch 4; iter: 0; batch classifier loss: 0.424764; batch adversarial loss: 0.607795\n",
      "epoch 5; iter: 0; batch classifier loss: 0.391253; batch adversarial loss: 0.542835\n",
      "epoch 6; iter: 0; batch classifier loss: 0.345111; batch adversarial loss: 0.563485\n",
      "epoch 7; iter: 0; batch classifier loss: 0.391823; batch adversarial loss: 0.544383\n",
      "epoch 8; iter: 0; batch classifier loss: 0.400991; batch adversarial loss: 0.552157\n",
      "epoch 9; iter: 0; batch classifier loss: 0.401528; batch adversarial loss: 0.537410\n",
      "epoch 10; iter: 0; batch classifier loss: 0.339679; batch adversarial loss: 0.519096\n",
      "epoch 11; iter: 0; batch classifier loss: 0.371352; batch adversarial loss: 0.546576\n",
      "epoch 12; iter: 0; batch classifier loss: 0.463619; batch adversarial loss: 0.524230\n",
      "epoch 13; iter: 0; batch classifier loss: 0.391757; batch adversarial loss: 0.502313\n",
      "epoch 14; iter: 0; batch classifier loss: 0.356399; batch adversarial loss: 0.580059\n",
      "epoch 15; iter: 0; batch classifier loss: 0.323463; batch adversarial loss: 0.506080\n",
      "epoch 16; iter: 0; batch classifier loss: 0.351812; batch adversarial loss: 0.448413\n",
      "epoch 17; iter: 0; batch classifier loss: 0.300260; batch adversarial loss: 0.475595\n",
      "epoch 18; iter: 0; batch classifier loss: 0.336144; batch adversarial loss: 0.493749\n",
      "epoch 19; iter: 0; batch classifier loss: 0.315954; batch adversarial loss: 0.528858\n",
      "epoch 20; iter: 0; batch classifier loss: 0.344507; batch adversarial loss: 0.494287\n",
      "epoch 21; iter: 0; batch classifier loss: 0.305668; batch adversarial loss: 0.521576\n",
      "epoch 22; iter: 0; batch classifier loss: 0.305531; batch adversarial loss: 0.475764\n",
      "epoch 23; iter: 0; batch classifier loss: 0.287268; batch adversarial loss: 0.505528\n",
      "epoch 24; iter: 0; batch classifier loss: 0.245208; batch adversarial loss: 0.446006\n",
      "epoch 25; iter: 0; batch classifier loss: 0.333203; batch adversarial loss: 0.517377\n",
      "epoch 26; iter: 0; batch classifier loss: 0.257774; batch adversarial loss: 0.485982\n",
      "epoch 27; iter: 0; batch classifier loss: 0.320496; batch adversarial loss: 0.407261\n",
      "epoch 28; iter: 0; batch classifier loss: 0.305670; batch adversarial loss: 0.464767\n",
      "epoch 29; iter: 0; batch classifier loss: 0.311597; batch adversarial loss: 0.454591\n",
      "epoch 30; iter: 0; batch classifier loss: 0.236720; batch adversarial loss: 0.434427\n",
      "epoch 31; iter: 0; batch classifier loss: 0.218652; batch adversarial loss: 0.526077\n",
      "epoch 32; iter: 0; batch classifier loss: 0.185350; batch adversarial loss: 0.549219\n",
      "epoch 33; iter: 0; batch classifier loss: 0.211373; batch adversarial loss: 0.567083\n",
      "epoch 34; iter: 0; batch classifier loss: 0.252189; batch adversarial loss: 0.483012\n",
      "epoch 35; iter: 0; batch classifier loss: 0.254274; batch adversarial loss: 0.429851\n",
      "epoch 36; iter: 0; batch classifier loss: 0.174419; batch adversarial loss: 0.504264\n",
      "epoch 37; iter: 0; batch classifier loss: 0.271572; batch adversarial loss: 0.438807\n",
      "epoch 38; iter: 0; batch classifier loss: 0.249886; batch adversarial loss: 0.468922\n",
      "epoch 39; iter: 0; batch classifier loss: 0.255087; batch adversarial loss: 0.444082\n",
      "epoch 40; iter: 0; batch classifier loss: 0.203053; batch adversarial loss: 0.422162\n",
      "epoch 41; iter: 0; batch classifier loss: 0.222067; batch adversarial loss: 0.417162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.219598; batch adversarial loss: 0.379818\n",
      "epoch 43; iter: 0; batch classifier loss: 0.188996; batch adversarial loss: 0.519946\n",
      "epoch 44; iter: 0; batch classifier loss: 0.183274; batch adversarial loss: 0.426546\n",
      "epoch 45; iter: 0; batch classifier loss: 0.176625; batch adversarial loss: 0.519105\n",
      "epoch 46; iter: 0; batch classifier loss: 0.209044; batch adversarial loss: 0.475338\n",
      "epoch 47; iter: 0; batch classifier loss: 0.231621; batch adversarial loss: 0.460774\n",
      "epoch 48; iter: 0; batch classifier loss: 0.148434; batch adversarial loss: 0.457499\n",
      "epoch 49; iter: 0; batch classifier loss: 0.265043; batch adversarial loss: 0.517604\n",
      "epoch 50; iter: 0; batch classifier loss: 0.205158; batch adversarial loss: 0.478689\n",
      "epoch 51; iter: 0; batch classifier loss: 0.230232; batch adversarial loss: 0.399671\n",
      "epoch 52; iter: 0; batch classifier loss: 0.198534; batch adversarial loss: 0.470006\n",
      "epoch 53; iter: 0; batch classifier loss: 0.180638; batch adversarial loss: 0.461343\n",
      "epoch 54; iter: 0; batch classifier loss: 0.186093; batch adversarial loss: 0.508377\n",
      "epoch 55; iter: 0; batch classifier loss: 0.190473; batch adversarial loss: 0.506476\n",
      "epoch 56; iter: 0; batch classifier loss: 0.217714; batch adversarial loss: 0.541779\n",
      "epoch 57; iter: 0; batch classifier loss: 0.209285; batch adversarial loss: 0.365121\n",
      "epoch 58; iter: 0; batch classifier loss: 0.262271; batch adversarial loss: 0.399179\n",
      "epoch 59; iter: 0; batch classifier loss: 0.224457; batch adversarial loss: 0.435249\n",
      "epoch 60; iter: 0; batch classifier loss: 0.158720; batch adversarial loss: 0.495024\n",
      "epoch 61; iter: 0; batch classifier loss: 0.201313; batch adversarial loss: 0.565307\n",
      "epoch 62; iter: 0; batch classifier loss: 0.221847; batch adversarial loss: 0.482683\n",
      "epoch 63; iter: 0; batch classifier loss: 0.239342; batch adversarial loss: 0.411390\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098041; batch adversarial loss: 0.518075\n",
      "epoch 65; iter: 0; batch classifier loss: 0.102051; batch adversarial loss: 0.483611\n",
      "epoch 66; iter: 0; batch classifier loss: 0.087233; batch adversarial loss: 0.431011\n",
      "epoch 67; iter: 0; batch classifier loss: 0.066380; batch adversarial loss: 0.404897\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070387; batch adversarial loss: 0.565652\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094319; batch adversarial loss: 0.411456\n",
      "epoch 70; iter: 0; batch classifier loss: 0.063569; batch adversarial loss: 0.435977\n",
      "epoch 71; iter: 0; batch classifier loss: 0.052938; batch adversarial loss: 0.538956\n",
      "epoch 72; iter: 0; batch classifier loss: 0.049358; batch adversarial loss: 0.416834\n",
      "epoch 73; iter: 0; batch classifier loss: 0.106207; batch adversarial loss: 0.376316\n",
      "epoch 74; iter: 0; batch classifier loss: 0.025852; batch adversarial loss: 0.456607\n",
      "epoch 75; iter: 0; batch classifier loss: 0.035788; batch adversarial loss: 0.502407\n",
      "epoch 76; iter: 0; batch classifier loss: 0.056938; batch adversarial loss: 0.402434\n",
      "epoch 77; iter: 0; batch classifier loss: 0.036625; batch adversarial loss: 0.390520\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061612; batch adversarial loss: 0.564981\n",
      "epoch 79; iter: 0; batch classifier loss: 0.077209; batch adversarial loss: 0.466782\n",
      "epoch 80; iter: 0; batch classifier loss: 0.031717; batch adversarial loss: 0.436996\n",
      "epoch 81; iter: 0; batch classifier loss: 0.051992; batch adversarial loss: 0.412630\n",
      "epoch 82; iter: 0; batch classifier loss: 0.027536; batch adversarial loss: 0.403268\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083597; batch adversarial loss: 0.388172\n",
      "epoch 84; iter: 0; batch classifier loss: 0.030862; batch adversarial loss: 0.506805\n",
      "epoch 85; iter: 0; batch classifier loss: 0.117304; batch adversarial loss: 0.456644\n",
      "epoch 86; iter: 0; batch classifier loss: 0.100371; batch adversarial loss: 0.533518\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054359; batch adversarial loss: 0.359693\n",
      "epoch 88; iter: 0; batch classifier loss: 0.028891; batch adversarial loss: 0.328702\n",
      "epoch 89; iter: 0; batch classifier loss: 0.087974; batch adversarial loss: 0.356909\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057219; batch adversarial loss: 0.403677\n",
      "epoch 91; iter: 0; batch classifier loss: 0.116434; batch adversarial loss: 0.424395\n",
      "epoch 92; iter: 0; batch classifier loss: 0.042364; batch adversarial loss: 0.408387\n",
      "epoch 93; iter: 0; batch classifier loss: 0.057994; batch adversarial loss: 0.454396\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038545; batch adversarial loss: 0.436492\n",
      "epoch 95; iter: 0; batch classifier loss: 0.074681; batch adversarial loss: 0.365872\n",
      "epoch 96; iter: 0; batch classifier loss: 0.028481; batch adversarial loss: 0.402799\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073857; batch adversarial loss: 0.395135\n",
      "epoch 98; iter: 0; batch classifier loss: 0.037173; batch adversarial loss: 0.435744\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065336; batch adversarial loss: 0.430579\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037569; batch adversarial loss: 0.333871\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039848; batch adversarial loss: 0.486032\n",
      "epoch 102; iter: 0; batch classifier loss: 0.027546; batch adversarial loss: 0.422488\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061151; batch adversarial loss: 0.510831\n",
      "epoch 104; iter: 0; batch classifier loss: 0.055159; batch adversarial loss: 0.458589\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029756; batch adversarial loss: 0.477966\n",
      "epoch 106; iter: 0; batch classifier loss: 0.023171; batch adversarial loss: 0.416441\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034879; batch adversarial loss: 0.354444\n",
      "epoch 108; iter: 0; batch classifier loss: 0.031535; batch adversarial loss: 0.419361\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060975; batch adversarial loss: 0.553842\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067350; batch adversarial loss: 0.476228\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053277; batch adversarial loss: 0.435057\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075782; batch adversarial loss: 0.549842\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048101; batch adversarial loss: 0.436152\n",
      "epoch 114; iter: 0; batch classifier loss: 0.038581; batch adversarial loss: 0.436304\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063619; batch adversarial loss: 0.448496\n",
      "epoch 116; iter: 0; batch classifier loss: 0.074421; batch adversarial loss: 0.422726\n",
      "epoch 117; iter: 0; batch classifier loss: 0.087801; batch adversarial loss: 0.449363\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046712; batch adversarial loss: 0.418260\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050882; batch adversarial loss: 0.419375\n",
      "epoch 120; iter: 0; batch classifier loss: 0.110164; batch adversarial loss: 0.412973\n",
      "epoch 121; iter: 0; batch classifier loss: 0.078647; batch adversarial loss: 0.442719\n",
      "epoch 122; iter: 0; batch classifier loss: 0.053280; batch adversarial loss: 0.470413\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049740; batch adversarial loss: 0.419124\n",
      "epoch 124; iter: 0; batch classifier loss: 0.085213; batch adversarial loss: 0.428836\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035314; batch adversarial loss: 0.472575\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048335; batch adversarial loss: 0.431412\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028570; batch adversarial loss: 0.448225\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056550; batch adversarial loss: 0.386406\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059273; batch adversarial loss: 0.371423\n",
      "epoch 130; iter: 0; batch classifier loss: 0.075052; batch adversarial loss: 0.466900\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038317; batch adversarial loss: 0.472217\n",
      "epoch 132; iter: 0; batch classifier loss: 0.052638; batch adversarial loss: 0.389003\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043777; batch adversarial loss: 0.477953\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038534; batch adversarial loss: 0.422840\n",
      "epoch 135; iter: 0; batch classifier loss: 0.058284; batch adversarial loss: 0.456838\n",
      "epoch 136; iter: 0; batch classifier loss: 0.052311; batch adversarial loss: 0.431047\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041507; batch adversarial loss: 0.399772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.033983; batch adversarial loss: 0.354863\n",
      "epoch 139; iter: 0; batch classifier loss: 0.069989; batch adversarial loss: 0.453784\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047067; batch adversarial loss: 0.439277\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049817; batch adversarial loss: 0.389650\n",
      "epoch 142; iter: 0; batch classifier loss: 0.085606; batch adversarial loss: 0.472770\n",
      "epoch 143; iter: 0; batch classifier loss: 0.057320; batch adversarial loss: 0.487337\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033134; batch adversarial loss: 0.420520\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033681; batch adversarial loss: 0.455240\n",
      "epoch 146; iter: 0; batch classifier loss: 0.093204; batch adversarial loss: 0.341195\n",
      "epoch 147; iter: 0; batch classifier loss: 0.050175; batch adversarial loss: 0.439694\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030566; batch adversarial loss: 0.479705\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032473; batch adversarial loss: 0.445132\n",
      "epoch 150; iter: 0; batch classifier loss: 0.055506; batch adversarial loss: 0.550471\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037661; batch adversarial loss: 0.431476\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024030; batch adversarial loss: 0.340694\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031471; batch adversarial loss: 0.397302\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034423; batch adversarial loss: 0.424478\n",
      "epoch 155; iter: 0; batch classifier loss: 0.067921; batch adversarial loss: 0.436481\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023163; batch adversarial loss: 0.437902\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035748; batch adversarial loss: 0.451942\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035468; batch adversarial loss: 0.441323\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026896; batch adversarial loss: 0.423639\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026587; batch adversarial loss: 0.432641\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033900; batch adversarial loss: 0.431818\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037001; batch adversarial loss: 0.477874\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018516; batch adversarial loss: 0.446468\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032622; batch adversarial loss: 0.498244\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032079; batch adversarial loss: 0.395458\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019939; batch adversarial loss: 0.509081\n",
      "epoch 167; iter: 0; batch classifier loss: 0.060981; batch adversarial loss: 0.343479\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031862; batch adversarial loss: 0.394155\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011884; batch adversarial loss: 0.461562\n",
      "epoch 170; iter: 0; batch classifier loss: 0.048008; batch adversarial loss: 0.411672\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028690; batch adversarial loss: 0.568081\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011437; batch adversarial loss: 0.468306\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036251; batch adversarial loss: 0.587760\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035210; batch adversarial loss: 0.483766\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034596; batch adversarial loss: 0.360121\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023785; batch adversarial loss: 0.492132\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031174; batch adversarial loss: 0.413686\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018345; batch adversarial loss: 0.513873\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021559; batch adversarial loss: 0.476498\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026620; batch adversarial loss: 0.373427\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016504; batch adversarial loss: 0.324439\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015821; batch adversarial loss: 0.452616\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019749; batch adversarial loss: 0.481838\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016886; batch adversarial loss: 0.434483\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021170; batch adversarial loss: 0.531194\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025566; batch adversarial loss: 0.394133\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020710; batch adversarial loss: 0.479255\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009310; batch adversarial loss: 0.420253\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034220; batch adversarial loss: 0.396108\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032430; batch adversarial loss: 0.468744\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023214; batch adversarial loss: 0.503340\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028082; batch adversarial loss: 0.389964\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027144; batch adversarial loss: 0.494954\n",
      "epoch 194; iter: 0; batch classifier loss: 0.046755; batch adversarial loss: 0.475831\n",
      "epoch 195; iter: 0; batch classifier loss: 0.032962; batch adversarial loss: 0.498746\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013329; batch adversarial loss: 0.491976\n",
      "epoch 197; iter: 0; batch classifier loss: 0.062535; batch adversarial loss: 0.554399\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024245; batch adversarial loss: 0.451739\n",
      "epoch 199; iter: 0; batch classifier loss: 0.051126; batch adversarial loss: 0.522547\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695964; batch adversarial loss: 0.585176\n",
      "epoch 1; iter: 0; batch classifier loss: 0.356979; batch adversarial loss: 0.618323\n",
      "epoch 2; iter: 0; batch classifier loss: 0.377090; batch adversarial loss: 0.609046\n",
      "epoch 3; iter: 0; batch classifier loss: 0.324610; batch adversarial loss: 0.546080\n",
      "epoch 4; iter: 0; batch classifier loss: 0.392799; batch adversarial loss: 0.587504\n",
      "epoch 5; iter: 0; batch classifier loss: 0.490726; batch adversarial loss: 0.625638\n",
      "epoch 6; iter: 0; batch classifier loss: 0.438863; batch adversarial loss: 0.602109\n",
      "epoch 7; iter: 0; batch classifier loss: 0.519489; batch adversarial loss: 0.651389\n",
      "epoch 8; iter: 0; batch classifier loss: 0.510838; batch adversarial loss: 0.613652\n",
      "epoch 9; iter: 0; batch classifier loss: 0.559847; batch adversarial loss: 0.588982\n",
      "epoch 10; iter: 0; batch classifier loss: 0.414487; batch adversarial loss: 0.478832\n",
      "epoch 11; iter: 0; batch classifier loss: 0.332330; batch adversarial loss: 0.501930\n",
      "epoch 12; iter: 0; batch classifier loss: 0.314328; batch adversarial loss: 0.513435\n",
      "epoch 13; iter: 0; batch classifier loss: 0.368246; batch adversarial loss: 0.472114\n",
      "epoch 14; iter: 0; batch classifier loss: 0.311414; batch adversarial loss: 0.420981\n",
      "epoch 15; iter: 0; batch classifier loss: 0.276741; batch adversarial loss: 0.426435\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281311; batch adversarial loss: 0.438779\n",
      "epoch 17; iter: 0; batch classifier loss: 0.238189; batch adversarial loss: 0.526453\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243174; batch adversarial loss: 0.588421\n",
      "epoch 19; iter: 0; batch classifier loss: 0.324157; batch adversarial loss: 0.455105\n",
      "epoch 20; iter: 0; batch classifier loss: 0.244631; batch adversarial loss: 0.499068\n",
      "epoch 21; iter: 0; batch classifier loss: 0.214825; batch adversarial loss: 0.495280\n",
      "epoch 22; iter: 0; batch classifier loss: 0.255948; batch adversarial loss: 0.470721\n",
      "epoch 23; iter: 0; batch classifier loss: 0.235548; batch adversarial loss: 0.495996\n",
      "epoch 24; iter: 0; batch classifier loss: 0.239668; batch adversarial loss: 0.457526\n",
      "epoch 25; iter: 0; batch classifier loss: 0.210360; batch adversarial loss: 0.442322\n",
      "epoch 26; iter: 0; batch classifier loss: 0.197401; batch adversarial loss: 0.488156\n",
      "epoch 27; iter: 0; batch classifier loss: 0.187308; batch adversarial loss: 0.505867\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184582; batch adversarial loss: 0.482012\n",
      "epoch 29; iter: 0; batch classifier loss: 0.227773; batch adversarial loss: 0.426959\n",
      "epoch 30; iter: 0; batch classifier loss: 0.182359; batch adversarial loss: 0.439801\n",
      "epoch 31; iter: 0; batch classifier loss: 0.141721; batch adversarial loss: 0.418248\n",
      "epoch 32; iter: 0; batch classifier loss: 0.179729; batch adversarial loss: 0.432356\n",
      "epoch 33; iter: 0; batch classifier loss: 0.180138; batch adversarial loss: 0.466811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.159231; batch adversarial loss: 0.401663\n",
      "epoch 35; iter: 0; batch classifier loss: 0.177320; batch adversarial loss: 0.494603\n",
      "epoch 36; iter: 0; batch classifier loss: 0.161083; batch adversarial loss: 0.402991\n",
      "epoch 37; iter: 0; batch classifier loss: 0.213146; batch adversarial loss: 0.518376\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107896; batch adversarial loss: 0.518049\n",
      "epoch 39; iter: 0; batch classifier loss: 0.151619; batch adversarial loss: 0.471230\n",
      "epoch 40; iter: 0; batch classifier loss: 0.096030; batch adversarial loss: 0.423370\n",
      "epoch 41; iter: 0; batch classifier loss: 0.177299; batch adversarial loss: 0.522675\n",
      "epoch 42; iter: 0; batch classifier loss: 0.144514; batch adversarial loss: 0.455574\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150791; batch adversarial loss: 0.398978\n",
      "epoch 44; iter: 0; batch classifier loss: 0.169396; batch adversarial loss: 0.482957\n",
      "epoch 45; iter: 0; batch classifier loss: 0.141394; batch adversarial loss: 0.511308\n",
      "epoch 46; iter: 0; batch classifier loss: 0.167082; batch adversarial loss: 0.378767\n",
      "epoch 47; iter: 0; batch classifier loss: 0.120078; batch adversarial loss: 0.485868\n",
      "epoch 48; iter: 0; batch classifier loss: 0.135998; batch adversarial loss: 0.433176\n",
      "epoch 49; iter: 0; batch classifier loss: 0.116387; batch adversarial loss: 0.494028\n",
      "epoch 50; iter: 0; batch classifier loss: 0.130436; batch adversarial loss: 0.473356\n",
      "epoch 51; iter: 0; batch classifier loss: 0.115213; batch adversarial loss: 0.431751\n",
      "epoch 52; iter: 0; batch classifier loss: 0.149390; batch adversarial loss: 0.414110\n",
      "epoch 53; iter: 0; batch classifier loss: 0.130954; batch adversarial loss: 0.442801\n",
      "epoch 54; iter: 0; batch classifier loss: 0.134305; batch adversarial loss: 0.470789\n",
      "epoch 55; iter: 0; batch classifier loss: 0.112706; batch adversarial loss: 0.467692\n",
      "epoch 56; iter: 0; batch classifier loss: 0.171659; batch adversarial loss: 0.469839\n",
      "epoch 57; iter: 0; batch classifier loss: 0.154400; batch adversarial loss: 0.502756\n",
      "epoch 58; iter: 0; batch classifier loss: 0.107341; batch adversarial loss: 0.508250\n",
      "epoch 59; iter: 0; batch classifier loss: 0.143416; batch adversarial loss: 0.404635\n",
      "epoch 60; iter: 0; batch classifier loss: 0.112155; batch adversarial loss: 0.383992\n",
      "epoch 61; iter: 0; batch classifier loss: 0.152150; batch adversarial loss: 0.527532\n",
      "epoch 62; iter: 0; batch classifier loss: 0.157694; batch adversarial loss: 0.475383\n",
      "epoch 63; iter: 0; batch classifier loss: 0.128846; batch adversarial loss: 0.393696\n",
      "epoch 64; iter: 0; batch classifier loss: 0.099667; batch adversarial loss: 0.405453\n",
      "epoch 65; iter: 0; batch classifier loss: 0.081598; batch adversarial loss: 0.475897\n",
      "epoch 66; iter: 0; batch classifier loss: 0.121353; batch adversarial loss: 0.497061\n",
      "epoch 67; iter: 0; batch classifier loss: 0.084043; batch adversarial loss: 0.415210\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096499; batch adversarial loss: 0.531377\n",
      "epoch 69; iter: 0; batch classifier loss: 0.173906; batch adversarial loss: 0.408848\n",
      "epoch 70; iter: 0; batch classifier loss: 0.140373; batch adversarial loss: 0.396560\n",
      "epoch 71; iter: 0; batch classifier loss: 0.107284; batch adversarial loss: 0.449536\n",
      "epoch 72; iter: 0; batch classifier loss: 0.110244; batch adversarial loss: 0.515776\n",
      "epoch 73; iter: 0; batch classifier loss: 0.110908; batch adversarial loss: 0.473738\n",
      "epoch 74; iter: 0; batch classifier loss: 0.116466; batch adversarial loss: 0.473819\n",
      "epoch 75; iter: 0; batch classifier loss: 0.114538; batch adversarial loss: 0.468510\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081485; batch adversarial loss: 0.630908\n",
      "epoch 77; iter: 0; batch classifier loss: 0.093127; batch adversarial loss: 0.428893\n",
      "epoch 78; iter: 0; batch classifier loss: 0.048833; batch adversarial loss: 0.436649\n",
      "epoch 79; iter: 0; batch classifier loss: 0.069595; batch adversarial loss: 0.439700\n",
      "epoch 80; iter: 0; batch classifier loss: 0.124925; batch adversarial loss: 0.537998\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065671; batch adversarial loss: 0.500101\n",
      "epoch 82; iter: 0; batch classifier loss: 0.056487; batch adversarial loss: 0.411951\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074720; batch adversarial loss: 0.455090\n",
      "epoch 84; iter: 0; batch classifier loss: 0.114117; batch adversarial loss: 0.473247\n",
      "epoch 85; iter: 0; batch classifier loss: 0.054391; batch adversarial loss: 0.470347\n",
      "epoch 86; iter: 0; batch classifier loss: 0.075245; batch adversarial loss: 0.394042\n",
      "epoch 87; iter: 0; batch classifier loss: 0.077742; batch adversarial loss: 0.466781\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064251; batch adversarial loss: 0.470953\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059588; batch adversarial loss: 0.485293\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053564; batch adversarial loss: 0.425679\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056427; batch adversarial loss: 0.505271\n",
      "epoch 92; iter: 0; batch classifier loss: 0.043406; batch adversarial loss: 0.546715\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043469; batch adversarial loss: 0.424703\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079859; batch adversarial loss: 0.511464\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064326; batch adversarial loss: 0.473928\n",
      "epoch 96; iter: 0; batch classifier loss: 0.061856; batch adversarial loss: 0.503913\n",
      "epoch 97; iter: 0; batch classifier loss: 0.091012; batch adversarial loss: 0.353029\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054931; batch adversarial loss: 0.484697\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055856; batch adversarial loss: 0.431927\n",
      "epoch 100; iter: 0; batch classifier loss: 0.070721; batch adversarial loss: 0.407281\n",
      "epoch 101; iter: 0; batch classifier loss: 0.045118; batch adversarial loss: 0.421206\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042555; batch adversarial loss: 0.503439\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040398; batch adversarial loss: 0.446942\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034686; batch adversarial loss: 0.473306\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054895; batch adversarial loss: 0.473961\n",
      "epoch 106; iter: 0; batch classifier loss: 0.029097; batch adversarial loss: 0.442426\n",
      "epoch 107; iter: 0; batch classifier loss: 0.026762; batch adversarial loss: 0.448065\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042554; batch adversarial loss: 0.475658\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033945; batch adversarial loss: 0.464415\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045340; batch adversarial loss: 0.512863\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069052; batch adversarial loss: 0.383018\n",
      "epoch 112; iter: 0; batch classifier loss: 0.074361; batch adversarial loss: 0.509269\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029574; batch adversarial loss: 0.493407\n",
      "epoch 114; iter: 0; batch classifier loss: 0.045004; batch adversarial loss: 0.434015\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036842; batch adversarial loss: 0.411891\n",
      "epoch 116; iter: 0; batch classifier loss: 0.019103; batch adversarial loss: 0.529551\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042087; batch adversarial loss: 0.355468\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025035; batch adversarial loss: 0.494576\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022405; batch adversarial loss: 0.483959\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025409; batch adversarial loss: 0.526429\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018667; batch adversarial loss: 0.381732\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039896; batch adversarial loss: 0.456143\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030905; batch adversarial loss: 0.352428\n",
      "epoch 124; iter: 0; batch classifier loss: 0.018639; batch adversarial loss: 0.374224\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027885; batch adversarial loss: 0.401632\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027873; batch adversarial loss: 0.481375\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060157; batch adversarial loss: 0.484371\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036738; batch adversarial loss: 0.452861\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021959; batch adversarial loss: 0.509758\n",
      "epoch 130; iter: 0; batch classifier loss: 0.020136; batch adversarial loss: 0.438536\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033498; batch adversarial loss: 0.396005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.050398; batch adversarial loss: 0.537066\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044368; batch adversarial loss: 0.491921\n",
      "epoch 134; iter: 0; batch classifier loss: 0.046985; batch adversarial loss: 0.421869\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033613; batch adversarial loss: 0.502498\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023827; batch adversarial loss: 0.434699\n",
      "epoch 137; iter: 0; batch classifier loss: 0.013314; batch adversarial loss: 0.426898\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040128; batch adversarial loss: 0.533312\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018709; batch adversarial loss: 0.501790\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035820; batch adversarial loss: 0.387788\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037891; batch adversarial loss: 0.391245\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022554; batch adversarial loss: 0.459444\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022095; batch adversarial loss: 0.493792\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022223; batch adversarial loss: 0.493485\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028476; batch adversarial loss: 0.568908\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029271; batch adversarial loss: 0.516221\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016813; batch adversarial loss: 0.445831\n",
      "epoch 148; iter: 0; batch classifier loss: 0.055435; batch adversarial loss: 0.456708\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016374; batch adversarial loss: 0.430239\n",
      "epoch 150; iter: 0; batch classifier loss: 0.009483; batch adversarial loss: 0.433409\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015583; batch adversarial loss: 0.514317\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030589; batch adversarial loss: 0.405390\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017429; batch adversarial loss: 0.536238\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023405; batch adversarial loss: 0.487263\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014900; batch adversarial loss: 0.534006\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018469; batch adversarial loss: 0.452680\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020802; batch adversarial loss: 0.423439\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032220; batch adversarial loss: 0.495677\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011132; batch adversarial loss: 0.380327\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020745; batch adversarial loss: 0.489308\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009607; batch adversarial loss: 0.441514\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019645; batch adversarial loss: 0.510229\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018057; batch adversarial loss: 0.521117\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037318; batch adversarial loss: 0.498198\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009970; batch adversarial loss: 0.458510\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013950; batch adversarial loss: 0.452829\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007952; batch adversarial loss: 0.381184\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015552; batch adversarial loss: 0.353575\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028512; batch adversarial loss: 0.363593\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014442; batch adversarial loss: 0.532512\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032895; batch adversarial loss: 0.470839\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010868; batch adversarial loss: 0.405404\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018745; batch adversarial loss: 0.459207\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020218; batch adversarial loss: 0.544643\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023341; batch adversarial loss: 0.394422\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017959; batch adversarial loss: 0.500841\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010432; batch adversarial loss: 0.465021\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012963; batch adversarial loss: 0.488580\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019556; batch adversarial loss: 0.390598\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020701; batch adversarial loss: 0.547856\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026634; batch adversarial loss: 0.452717\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012044; batch adversarial loss: 0.424964\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020739; batch adversarial loss: 0.449643\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004524; batch adversarial loss: 0.431271\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008559; batch adversarial loss: 0.457531\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030382; batch adversarial loss: 0.404493\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013363; batch adversarial loss: 0.464292\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007485; batch adversarial loss: 0.393025\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018857; batch adversarial loss: 0.478628\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009549; batch adversarial loss: 0.486193\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019489; batch adversarial loss: 0.477779\n",
      "epoch 192; iter: 0; batch classifier loss: 0.043178; batch adversarial loss: 0.611653\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009118; batch adversarial loss: 0.388312\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008521; batch adversarial loss: 0.408281\n",
      "epoch 195; iter: 0; batch classifier loss: 0.040331; batch adversarial loss: 0.443077\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007677; batch adversarial loss: 0.432244\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039190; batch adversarial loss: 0.365038\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006695; batch adversarial loss: 0.450316\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035880; batch adversarial loss: 0.490460\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685011; batch adversarial loss: 0.888927\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433044; batch adversarial loss: 0.871888\n",
      "epoch 2; iter: 0; batch classifier loss: 0.451991; batch adversarial loss: 0.909402\n",
      "epoch 3; iter: 0; batch classifier loss: 0.486322; batch adversarial loss: 0.843036\n",
      "epoch 4; iter: 0; batch classifier loss: 0.399092; batch adversarial loss: 0.766884\n",
      "epoch 5; iter: 0; batch classifier loss: 0.311764; batch adversarial loss: 0.691935\n",
      "epoch 6; iter: 0; batch classifier loss: 0.343027; batch adversarial loss: 0.661771\n",
      "epoch 7; iter: 0; batch classifier loss: 0.376031; batch adversarial loss: 0.622976\n",
      "epoch 8; iter: 0; batch classifier loss: 0.294978; batch adversarial loss: 0.614927\n",
      "epoch 9; iter: 0; batch classifier loss: 0.322088; batch adversarial loss: 0.564383\n",
      "epoch 10; iter: 0; batch classifier loss: 0.298062; batch adversarial loss: 0.573015\n",
      "epoch 11; iter: 0; batch classifier loss: 0.290075; batch adversarial loss: 0.490551\n",
      "epoch 12; iter: 0; batch classifier loss: 0.264430; batch adversarial loss: 0.534139\n",
      "epoch 13; iter: 0; batch classifier loss: 0.272009; batch adversarial loss: 0.523684\n",
      "epoch 14; iter: 0; batch classifier loss: 0.213123; batch adversarial loss: 0.535310\n",
      "epoch 15; iter: 0; batch classifier loss: 0.276339; batch adversarial loss: 0.474988\n",
      "epoch 16; iter: 0; batch classifier loss: 0.189612; batch adversarial loss: 0.472187\n",
      "epoch 17; iter: 0; batch classifier loss: 0.274911; batch adversarial loss: 0.458775\n",
      "epoch 18; iter: 0; batch classifier loss: 0.232532; batch adversarial loss: 0.470001\n",
      "epoch 19; iter: 0; batch classifier loss: 0.219543; batch adversarial loss: 0.450622\n",
      "epoch 20; iter: 0; batch classifier loss: 0.231242; batch adversarial loss: 0.421648\n",
      "epoch 21; iter: 0; batch classifier loss: 0.141785; batch adversarial loss: 0.480750\n",
      "epoch 22; iter: 0; batch classifier loss: 0.192811; batch adversarial loss: 0.412685\n",
      "epoch 23; iter: 0; batch classifier loss: 0.184520; batch adversarial loss: 0.421194\n",
      "epoch 24; iter: 0; batch classifier loss: 0.147821; batch adversarial loss: 0.406879\n",
      "epoch 25; iter: 0; batch classifier loss: 0.199190; batch adversarial loss: 0.476310\n",
      "epoch 26; iter: 0; batch classifier loss: 0.142330; batch adversarial loss: 0.478901\n",
      "epoch 27; iter: 0; batch classifier loss: 0.151745; batch adversarial loss: 0.441967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.126123; batch adversarial loss: 0.483640\n",
      "epoch 29; iter: 0; batch classifier loss: 0.113147; batch adversarial loss: 0.439600\n",
      "epoch 30; iter: 0; batch classifier loss: 0.152248; batch adversarial loss: 0.485902\n",
      "epoch 31; iter: 0; batch classifier loss: 0.128518; batch adversarial loss: 0.435989\n",
      "epoch 32; iter: 0; batch classifier loss: 0.106044; batch adversarial loss: 0.454168\n",
      "epoch 33; iter: 0; batch classifier loss: 0.124638; batch adversarial loss: 0.428319\n",
      "epoch 34; iter: 0; batch classifier loss: 0.088963; batch adversarial loss: 0.453085\n",
      "epoch 35; iter: 0; batch classifier loss: 0.172280; batch adversarial loss: 0.443124\n",
      "epoch 36; iter: 0; batch classifier loss: 0.151895; batch adversarial loss: 0.549539\n",
      "epoch 37; iter: 0; batch classifier loss: 0.126611; batch adversarial loss: 0.397878\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127506; batch adversarial loss: 0.523136\n",
      "epoch 39; iter: 0; batch classifier loss: 0.108758; batch adversarial loss: 0.367346\n",
      "epoch 40; iter: 0; batch classifier loss: 0.081236; batch adversarial loss: 0.418728\n",
      "epoch 41; iter: 0; batch classifier loss: 0.114937; batch adversarial loss: 0.394430\n",
      "epoch 42; iter: 0; batch classifier loss: 0.136419; batch adversarial loss: 0.395357\n",
      "epoch 43; iter: 0; batch classifier loss: 0.140732; batch adversarial loss: 0.477770\n",
      "epoch 44; iter: 0; batch classifier loss: 0.097364; batch adversarial loss: 0.490258\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089550; batch adversarial loss: 0.431370\n",
      "epoch 46; iter: 0; batch classifier loss: 0.093377; batch adversarial loss: 0.428717\n",
      "epoch 47; iter: 0; batch classifier loss: 0.093372; batch adversarial loss: 0.463669\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104954; batch adversarial loss: 0.484572\n",
      "epoch 49; iter: 0; batch classifier loss: 0.076346; batch adversarial loss: 0.434779\n",
      "epoch 50; iter: 0; batch classifier loss: 0.083368; batch adversarial loss: 0.410700\n",
      "epoch 51; iter: 0; batch classifier loss: 0.071624; batch adversarial loss: 0.403119\n",
      "epoch 52; iter: 0; batch classifier loss: 0.135230; batch adversarial loss: 0.523860\n",
      "epoch 53; iter: 0; batch classifier loss: 0.073277; batch adversarial loss: 0.381344\n",
      "epoch 54; iter: 0; batch classifier loss: 0.081173; batch adversarial loss: 0.406959\n",
      "epoch 55; iter: 0; batch classifier loss: 0.100544; batch adversarial loss: 0.365009\n",
      "epoch 56; iter: 0; batch classifier loss: 0.097933; batch adversarial loss: 0.578823\n",
      "epoch 57; iter: 0; batch classifier loss: 0.063976; batch adversarial loss: 0.411529\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090233; batch adversarial loss: 0.370827\n",
      "epoch 59; iter: 0; batch classifier loss: 0.097837; batch adversarial loss: 0.470434\n",
      "epoch 60; iter: 0; batch classifier loss: 0.049882; batch adversarial loss: 0.456802\n",
      "epoch 61; iter: 0; batch classifier loss: 0.099624; batch adversarial loss: 0.399919\n",
      "epoch 62; iter: 0; batch classifier loss: 0.109779; batch adversarial loss: 0.415441\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076484; batch adversarial loss: 0.356683\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090659; batch adversarial loss: 0.440883\n",
      "epoch 65; iter: 0; batch classifier loss: 0.073299; batch adversarial loss: 0.392083\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060877; batch adversarial loss: 0.544425\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059149; batch adversarial loss: 0.527625\n",
      "epoch 68; iter: 0; batch classifier loss: 0.093874; batch adversarial loss: 0.466382\n",
      "epoch 69; iter: 0; batch classifier loss: 0.089236; batch adversarial loss: 0.489766\n",
      "epoch 70; iter: 0; batch classifier loss: 0.095268; batch adversarial loss: 0.498718\n",
      "epoch 71; iter: 0; batch classifier loss: 0.052381; batch adversarial loss: 0.469049\n",
      "epoch 72; iter: 0; batch classifier loss: 0.050777; batch adversarial loss: 0.448529\n",
      "epoch 73; iter: 0; batch classifier loss: 0.049020; batch adversarial loss: 0.464287\n",
      "epoch 74; iter: 0; batch classifier loss: 0.078914; batch adversarial loss: 0.429288\n",
      "epoch 75; iter: 0; batch classifier loss: 0.047494; batch adversarial loss: 0.361268\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076002; batch adversarial loss: 0.420625\n",
      "epoch 77; iter: 0; batch classifier loss: 0.052833; batch adversarial loss: 0.464578\n",
      "epoch 78; iter: 0; batch classifier loss: 0.055785; batch adversarial loss: 0.416662\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076322; batch adversarial loss: 0.492468\n",
      "epoch 80; iter: 0; batch classifier loss: 0.049596; batch adversarial loss: 0.339410\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055192; batch adversarial loss: 0.438073\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071995; batch adversarial loss: 0.478056\n",
      "epoch 83; iter: 0; batch classifier loss: 0.049799; batch adversarial loss: 0.402021\n",
      "epoch 84; iter: 0; batch classifier loss: 0.044267; batch adversarial loss: 0.402338\n",
      "epoch 85; iter: 0; batch classifier loss: 0.050584; batch adversarial loss: 0.474865\n",
      "epoch 86; iter: 0; batch classifier loss: 0.099353; batch adversarial loss: 0.504424\n",
      "epoch 87; iter: 0; batch classifier loss: 0.090731; batch adversarial loss: 0.424391\n",
      "epoch 88; iter: 0; batch classifier loss: 0.065929; batch adversarial loss: 0.351032\n",
      "epoch 89; iter: 0; batch classifier loss: 0.071507; batch adversarial loss: 0.411166\n",
      "epoch 90; iter: 0; batch classifier loss: 0.044957; batch adversarial loss: 0.435299\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055222; batch adversarial loss: 0.508290\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064600; batch adversarial loss: 0.461133\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055744; batch adversarial loss: 0.409266\n",
      "epoch 94; iter: 0; batch classifier loss: 0.092234; batch adversarial loss: 0.479311\n",
      "epoch 95; iter: 0; batch classifier loss: 0.086897; batch adversarial loss: 0.491869\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062352; batch adversarial loss: 0.493018\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054945; batch adversarial loss: 0.394731\n",
      "epoch 98; iter: 0; batch classifier loss: 0.071452; batch adversarial loss: 0.489300\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038106; batch adversarial loss: 0.494313\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044507; batch adversarial loss: 0.497406\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043559; batch adversarial loss: 0.392357\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049221; batch adversarial loss: 0.438238\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039000; batch adversarial loss: 0.440256\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034162; batch adversarial loss: 0.401461\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050021; batch adversarial loss: 0.503471\n",
      "epoch 106; iter: 0; batch classifier loss: 0.066597; batch adversarial loss: 0.488955\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056104; batch adversarial loss: 0.427319\n",
      "epoch 108; iter: 0; batch classifier loss: 0.084171; batch adversarial loss: 0.466292\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037278; batch adversarial loss: 0.429180\n",
      "epoch 110; iter: 0; batch classifier loss: 0.018064; batch adversarial loss: 0.373218\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031070; batch adversarial loss: 0.425240\n",
      "epoch 112; iter: 0; batch classifier loss: 0.089945; batch adversarial loss: 0.378067\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063205; batch adversarial loss: 0.503164\n",
      "epoch 114; iter: 0; batch classifier loss: 0.077616; batch adversarial loss: 0.492511\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045941; batch adversarial loss: 0.404300\n",
      "epoch 116; iter: 0; batch classifier loss: 0.064894; batch adversarial loss: 0.405520\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034758; batch adversarial loss: 0.390368\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043115; batch adversarial loss: 0.423096\n",
      "epoch 119; iter: 0; batch classifier loss: 0.063345; batch adversarial loss: 0.478368\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046672; batch adversarial loss: 0.410378\n",
      "epoch 121; iter: 0; batch classifier loss: 0.092550; batch adversarial loss: 0.415151\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048174; batch adversarial loss: 0.447293\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051511; batch adversarial loss: 0.458967\n",
      "epoch 124; iter: 0; batch classifier loss: 0.064048; batch adversarial loss: 0.444775\n",
      "epoch 125; iter: 0; batch classifier loss: 0.071524; batch adversarial loss: 0.520728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.050449; batch adversarial loss: 0.557925\n",
      "epoch 127; iter: 0; batch classifier loss: 0.077047; batch adversarial loss: 0.418341\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024148; batch adversarial loss: 0.361764\n",
      "epoch 129; iter: 0; batch classifier loss: 0.054809; batch adversarial loss: 0.530499\n",
      "epoch 130; iter: 0; batch classifier loss: 0.058424; batch adversarial loss: 0.414092\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049490; batch adversarial loss: 0.512347\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046546; batch adversarial loss: 0.453433\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044477; batch adversarial loss: 0.342571\n",
      "epoch 134; iter: 0; batch classifier loss: 0.067548; batch adversarial loss: 0.464889\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039965; batch adversarial loss: 0.475306\n",
      "epoch 136; iter: 0; batch classifier loss: 0.077793; batch adversarial loss: 0.454726\n",
      "epoch 137; iter: 0; batch classifier loss: 0.067796; batch adversarial loss: 0.418367\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028422; batch adversarial loss: 0.421636\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039768; batch adversarial loss: 0.349483\n",
      "epoch 140; iter: 0; batch classifier loss: 0.074086; batch adversarial loss: 0.436226\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048496; batch adversarial loss: 0.405617\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043118; batch adversarial loss: 0.392705\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037738; batch adversarial loss: 0.370573\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052957; batch adversarial loss: 0.415173\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036609; batch adversarial loss: 0.378434\n",
      "epoch 146; iter: 0; batch classifier loss: 0.080141; batch adversarial loss: 0.549486\n",
      "epoch 147; iter: 0; batch classifier loss: 0.048908; batch adversarial loss: 0.491730\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034413; batch adversarial loss: 0.433443\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053882; batch adversarial loss: 0.382471\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042537; batch adversarial loss: 0.356895\n",
      "epoch 151; iter: 0; batch classifier loss: 0.080214; batch adversarial loss: 0.493725\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033806; batch adversarial loss: 0.415117\n",
      "epoch 153; iter: 0; batch classifier loss: 0.047570; batch adversarial loss: 0.469060\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046291; batch adversarial loss: 0.493692\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036463; batch adversarial loss: 0.481251\n",
      "epoch 156; iter: 0; batch classifier loss: 0.060852; batch adversarial loss: 0.485348\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034555; batch adversarial loss: 0.356888\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048887; batch adversarial loss: 0.466304\n",
      "epoch 159; iter: 0; batch classifier loss: 0.062580; batch adversarial loss: 0.387395\n",
      "epoch 160; iter: 0; batch classifier loss: 0.074267; batch adversarial loss: 0.474610\n",
      "epoch 161; iter: 0; batch classifier loss: 0.046148; batch adversarial loss: 0.396712\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039788; batch adversarial loss: 0.410969\n",
      "epoch 163; iter: 0; batch classifier loss: 0.047018; batch adversarial loss: 0.435160\n",
      "epoch 164; iter: 0; batch classifier loss: 0.075990; batch adversarial loss: 0.409697\n",
      "epoch 165; iter: 0; batch classifier loss: 0.060499; batch adversarial loss: 0.365922\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046104; batch adversarial loss: 0.404336\n",
      "epoch 167; iter: 0; batch classifier loss: 0.049226; batch adversarial loss: 0.367467\n",
      "epoch 168; iter: 0; batch classifier loss: 0.055255; batch adversarial loss: 0.470238\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038333; batch adversarial loss: 0.382670\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040140; batch adversarial loss: 0.436694\n",
      "epoch 171; iter: 0; batch classifier loss: 0.085200; batch adversarial loss: 0.416367\n",
      "epoch 172; iter: 0; batch classifier loss: 0.043863; batch adversarial loss: 0.371566\n",
      "epoch 173; iter: 0; batch classifier loss: 0.048058; batch adversarial loss: 0.474188\n",
      "epoch 174; iter: 0; batch classifier loss: 0.057912; batch adversarial loss: 0.463560\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030445; batch adversarial loss: 0.433774\n",
      "epoch 176; iter: 0; batch classifier loss: 0.044975; batch adversarial loss: 0.537155\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029532; batch adversarial loss: 0.486156\n",
      "epoch 178; iter: 0; batch classifier loss: 0.041370; batch adversarial loss: 0.475733\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040965; batch adversarial loss: 0.326741\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023792; batch adversarial loss: 0.451727\n",
      "epoch 181; iter: 0; batch classifier loss: 0.049441; batch adversarial loss: 0.419963\n",
      "epoch 182; iter: 0; batch classifier loss: 0.041610; batch adversarial loss: 0.430945\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019327; batch adversarial loss: 0.434502\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033186; batch adversarial loss: 0.319182\n",
      "epoch 185; iter: 0; batch classifier loss: 0.043511; batch adversarial loss: 0.320000\n",
      "epoch 186; iter: 0; batch classifier loss: 0.066478; batch adversarial loss: 0.461992\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032923; batch adversarial loss: 0.411265\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031960; batch adversarial loss: 0.419479\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025274; batch adversarial loss: 0.406936\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030106; batch adversarial loss: 0.506359\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037093; batch adversarial loss: 0.361096\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026782; batch adversarial loss: 0.365173\n",
      "epoch 193; iter: 0; batch classifier loss: 0.048699; batch adversarial loss: 0.385776\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030758; batch adversarial loss: 0.372896\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025720; batch adversarial loss: 0.414468\n",
      "epoch 196; iter: 0; batch classifier loss: 0.035325; batch adversarial loss: 0.320857\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026787; batch adversarial loss: 0.467484\n",
      "epoch 198; iter: 0; batch classifier loss: 0.033043; batch adversarial loss: 0.393382\n",
      "epoch 199; iter: 0; batch classifier loss: 0.045793; batch adversarial loss: 0.442806\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715713; batch adversarial loss: 0.675425\n",
      "epoch 1; iter: 0; batch classifier loss: 0.536910; batch adversarial loss: 0.638273\n",
      "epoch 2; iter: 0; batch classifier loss: 0.395436; batch adversarial loss: 0.612178\n",
      "epoch 3; iter: 0; batch classifier loss: 0.317314; batch adversarial loss: 0.580301\n",
      "epoch 4; iter: 0; batch classifier loss: 0.310630; batch adversarial loss: 0.563296\n",
      "epoch 5; iter: 0; batch classifier loss: 0.338925; batch adversarial loss: 0.521330\n",
      "epoch 6; iter: 0; batch classifier loss: 0.339379; batch adversarial loss: 0.505529\n",
      "epoch 7; iter: 0; batch classifier loss: 0.291598; batch adversarial loss: 0.491204\n",
      "epoch 8; iter: 0; batch classifier loss: 0.324769; batch adversarial loss: 0.499312\n",
      "epoch 9; iter: 0; batch classifier loss: 0.269414; batch adversarial loss: 0.462364\n",
      "epoch 10; iter: 0; batch classifier loss: 0.272284; batch adversarial loss: 0.475582\n",
      "epoch 11; iter: 0; batch classifier loss: 0.225448; batch adversarial loss: 0.556486\n",
      "epoch 12; iter: 0; batch classifier loss: 0.249916; batch adversarial loss: 0.520180\n",
      "epoch 13; iter: 0; batch classifier loss: 0.197597; batch adversarial loss: 0.461736\n",
      "epoch 14; iter: 0; batch classifier loss: 0.181216; batch adversarial loss: 0.542173\n",
      "epoch 15; iter: 0; batch classifier loss: 0.253410; batch adversarial loss: 0.545828\n",
      "epoch 16; iter: 0; batch classifier loss: 0.158465; batch adversarial loss: 0.535714\n",
      "epoch 17; iter: 0; batch classifier loss: 0.220731; batch adversarial loss: 0.472089\n",
      "epoch 18; iter: 0; batch classifier loss: 0.209820; batch adversarial loss: 0.478961\n",
      "epoch 19; iter: 0; batch classifier loss: 0.244887; batch adversarial loss: 0.566209\n",
      "epoch 20; iter: 0; batch classifier loss: 0.176635; batch adversarial loss: 0.446528\n",
      "epoch 21; iter: 0; batch classifier loss: 0.196589; batch adversarial loss: 0.458948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.222007; batch adversarial loss: 0.481888\n",
      "epoch 23; iter: 0; batch classifier loss: 0.282460; batch adversarial loss: 0.422074\n",
      "epoch 24; iter: 0; batch classifier loss: 0.326073; batch adversarial loss: 0.473493\n",
      "epoch 25; iter: 0; batch classifier loss: 0.277558; batch adversarial loss: 0.496366\n",
      "epoch 26; iter: 0; batch classifier loss: 0.401228; batch adversarial loss: 0.480079\n",
      "epoch 27; iter: 0; batch classifier loss: 0.246730; batch adversarial loss: 0.565163\n",
      "epoch 28; iter: 0; batch classifier loss: 0.177820; batch adversarial loss: 0.440917\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178548; batch adversarial loss: 0.480649\n",
      "epoch 30; iter: 0; batch classifier loss: 0.126047; batch adversarial loss: 0.474334\n",
      "epoch 31; iter: 0; batch classifier loss: 0.140697; batch adversarial loss: 0.394967\n",
      "epoch 32; iter: 0; batch classifier loss: 0.137702; batch adversarial loss: 0.425225\n",
      "epoch 33; iter: 0; batch classifier loss: 0.098440; batch adversarial loss: 0.390601\n",
      "epoch 34; iter: 0; batch classifier loss: 0.138269; batch adversarial loss: 0.563488\n",
      "epoch 35; iter: 0; batch classifier loss: 0.152527; batch adversarial loss: 0.415732\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102382; batch adversarial loss: 0.429925\n",
      "epoch 37; iter: 0; batch classifier loss: 0.143029; batch adversarial loss: 0.456453\n",
      "epoch 38; iter: 0; batch classifier loss: 0.100047; batch adversarial loss: 0.455219\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131002; batch adversarial loss: 0.454520\n",
      "epoch 40; iter: 0; batch classifier loss: 0.130195; batch adversarial loss: 0.463369\n",
      "epoch 41; iter: 0; batch classifier loss: 0.061785; batch adversarial loss: 0.427722\n",
      "epoch 42; iter: 0; batch classifier loss: 0.111452; batch adversarial loss: 0.519741\n",
      "epoch 43; iter: 0; batch classifier loss: 0.092061; batch adversarial loss: 0.438807\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123829; batch adversarial loss: 0.475989\n",
      "epoch 45; iter: 0; batch classifier loss: 0.135517; batch adversarial loss: 0.504838\n",
      "epoch 46; iter: 0; batch classifier loss: 0.073658; batch adversarial loss: 0.533061\n",
      "epoch 47; iter: 0; batch classifier loss: 0.066693; batch adversarial loss: 0.439910\n",
      "epoch 48; iter: 0; batch classifier loss: 0.089990; batch adversarial loss: 0.522895\n",
      "epoch 49; iter: 0; batch classifier loss: 0.096740; batch adversarial loss: 0.495235\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091141; batch adversarial loss: 0.442088\n",
      "epoch 51; iter: 0; batch classifier loss: 0.057577; batch adversarial loss: 0.490558\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071858; batch adversarial loss: 0.461321\n",
      "epoch 53; iter: 0; batch classifier loss: 0.069162; batch adversarial loss: 0.463082\n",
      "epoch 54; iter: 0; batch classifier loss: 0.129792; batch adversarial loss: 0.468356\n",
      "epoch 55; iter: 0; batch classifier loss: 0.063055; batch adversarial loss: 0.443538\n",
      "epoch 56; iter: 0; batch classifier loss: 0.077794; batch adversarial loss: 0.463351\n",
      "epoch 57; iter: 0; batch classifier loss: 0.055278; batch adversarial loss: 0.416947\n",
      "epoch 58; iter: 0; batch classifier loss: 0.111145; batch adversarial loss: 0.472680\n",
      "epoch 59; iter: 0; batch classifier loss: 0.119341; batch adversarial loss: 0.440167\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086740; batch adversarial loss: 0.484794\n",
      "epoch 61; iter: 0; batch classifier loss: 0.085348; batch adversarial loss: 0.441400\n",
      "epoch 62; iter: 0; batch classifier loss: 0.050754; batch adversarial loss: 0.468850\n",
      "epoch 63; iter: 0; batch classifier loss: 0.059264; batch adversarial loss: 0.488367\n",
      "epoch 64; iter: 0; batch classifier loss: 0.120242; batch adversarial loss: 0.383215\n",
      "epoch 65; iter: 0; batch classifier loss: 0.105317; batch adversarial loss: 0.411158\n",
      "epoch 66; iter: 0; batch classifier loss: 0.081741; batch adversarial loss: 0.375913\n",
      "epoch 67; iter: 0; batch classifier loss: 0.089787; batch adversarial loss: 0.438257\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096248; batch adversarial loss: 0.389510\n",
      "epoch 69; iter: 0; batch classifier loss: 0.110457; batch adversarial loss: 0.507950\n",
      "epoch 70; iter: 0; batch classifier loss: 0.092015; batch adversarial loss: 0.429624\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064560; batch adversarial loss: 0.444640\n",
      "epoch 72; iter: 0; batch classifier loss: 0.088586; batch adversarial loss: 0.432562\n",
      "epoch 73; iter: 0; batch classifier loss: 0.059923; batch adversarial loss: 0.413989\n",
      "epoch 74; iter: 0; batch classifier loss: 0.055840; batch adversarial loss: 0.513749\n",
      "epoch 75; iter: 0; batch classifier loss: 0.089773; batch adversarial loss: 0.394626\n",
      "epoch 76; iter: 0; batch classifier loss: 0.056999; batch adversarial loss: 0.391134\n",
      "epoch 77; iter: 0; batch classifier loss: 0.104100; batch adversarial loss: 0.480262\n",
      "epoch 78; iter: 0; batch classifier loss: 0.128865; batch adversarial loss: 0.465490\n",
      "epoch 79; iter: 0; batch classifier loss: 0.098140; batch adversarial loss: 0.522278\n",
      "epoch 80; iter: 0; batch classifier loss: 0.057568; batch adversarial loss: 0.408856\n",
      "epoch 81; iter: 0; batch classifier loss: 0.052567; batch adversarial loss: 0.410514\n",
      "epoch 82; iter: 0; batch classifier loss: 0.086125; batch adversarial loss: 0.379453\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065325; batch adversarial loss: 0.444211\n",
      "epoch 84; iter: 0; batch classifier loss: 0.072633; batch adversarial loss: 0.503487\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052827; batch adversarial loss: 0.444316\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062595; batch adversarial loss: 0.548891\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066293; batch adversarial loss: 0.497234\n",
      "epoch 88; iter: 0; batch classifier loss: 0.094834; batch adversarial loss: 0.462296\n",
      "epoch 89; iter: 0; batch classifier loss: 0.040745; batch adversarial loss: 0.516613\n",
      "epoch 90; iter: 0; batch classifier loss: 0.049227; batch adversarial loss: 0.437524\n",
      "epoch 91; iter: 0; batch classifier loss: 0.051652; batch adversarial loss: 0.381036\n",
      "epoch 92; iter: 0; batch classifier loss: 0.098603; batch adversarial loss: 0.457940\n",
      "epoch 93; iter: 0; batch classifier loss: 0.083041; batch adversarial loss: 0.389166\n",
      "epoch 94; iter: 0; batch classifier loss: 0.156177; batch adversarial loss: 0.451769\n",
      "epoch 95; iter: 0; batch classifier loss: 0.072570; batch adversarial loss: 0.393452\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064591; batch adversarial loss: 0.422790\n",
      "epoch 97; iter: 0; batch classifier loss: 0.035754; batch adversarial loss: 0.399373\n",
      "epoch 98; iter: 0; batch classifier loss: 0.091871; batch adversarial loss: 0.449815\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061700; batch adversarial loss: 0.430323\n",
      "epoch 100; iter: 0; batch classifier loss: 0.042387; batch adversarial loss: 0.435439\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061911; batch adversarial loss: 0.393709\n",
      "epoch 102; iter: 0; batch classifier loss: 0.154345; batch adversarial loss: 0.342381\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045906; batch adversarial loss: 0.534092\n",
      "epoch 104; iter: 0; batch classifier loss: 0.078804; batch adversarial loss: 0.426570\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051581; batch adversarial loss: 0.454576\n",
      "epoch 106; iter: 0; batch classifier loss: 0.082390; batch adversarial loss: 0.495531\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048112; batch adversarial loss: 0.431591\n",
      "epoch 108; iter: 0; batch classifier loss: 0.084014; batch adversarial loss: 0.427617\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039545; batch adversarial loss: 0.531429\n",
      "epoch 110; iter: 0; batch classifier loss: 0.034662; batch adversarial loss: 0.422719\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055457; batch adversarial loss: 0.466500\n",
      "epoch 112; iter: 0; batch classifier loss: 0.068010; batch adversarial loss: 0.504577\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044584; batch adversarial loss: 0.564611\n",
      "epoch 114; iter: 0; batch classifier loss: 0.064290; batch adversarial loss: 0.532493\n",
      "epoch 115; iter: 0; batch classifier loss: 0.077620; batch adversarial loss: 0.466866\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041402; batch adversarial loss: 0.398561\n",
      "epoch 117; iter: 0; batch classifier loss: 0.071036; batch adversarial loss: 0.438315\n",
      "epoch 118; iter: 0; batch classifier loss: 0.034734; batch adversarial loss: 0.362415\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037337; batch adversarial loss: 0.502652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.068197; batch adversarial loss: 0.418020\n",
      "epoch 121; iter: 0; batch classifier loss: 0.069299; batch adversarial loss: 0.399464\n",
      "epoch 122; iter: 0; batch classifier loss: 0.071962; batch adversarial loss: 0.434602\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033150; batch adversarial loss: 0.403216\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023030; batch adversarial loss: 0.464325\n",
      "epoch 125; iter: 0; batch classifier loss: 0.060947; batch adversarial loss: 0.401414\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026031; batch adversarial loss: 0.514947\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024842; batch adversarial loss: 0.315467\n",
      "epoch 128; iter: 0; batch classifier loss: 0.060320; batch adversarial loss: 0.530083\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020794; batch adversarial loss: 0.447185\n",
      "epoch 130; iter: 0; batch classifier loss: 0.063661; batch adversarial loss: 0.369502\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047353; batch adversarial loss: 0.538089\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028249; batch adversarial loss: 0.380957\n",
      "epoch 133; iter: 0; batch classifier loss: 0.055475; batch adversarial loss: 0.401424\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038461; batch adversarial loss: 0.353787\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032766; batch adversarial loss: 0.484623\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043505; batch adversarial loss: 0.530858\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032645; batch adversarial loss: 0.488319\n",
      "epoch 138; iter: 0; batch classifier loss: 0.042922; batch adversarial loss: 0.471321\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016424; batch adversarial loss: 0.464305\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030217; batch adversarial loss: 0.512881\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052775; batch adversarial loss: 0.475643\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023113; batch adversarial loss: 0.524261\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037842; batch adversarial loss: 0.497892\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030084; batch adversarial loss: 0.461665\n",
      "epoch 145; iter: 0; batch classifier loss: 0.068486; batch adversarial loss: 0.467835\n",
      "epoch 146; iter: 0; batch classifier loss: 0.008793; batch adversarial loss: 0.551843\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026026; batch adversarial loss: 0.471569\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016019; batch adversarial loss: 0.480297\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035961; batch adversarial loss: 0.444271\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018063; batch adversarial loss: 0.494023\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040098; batch adversarial loss: 0.422907\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018548; batch adversarial loss: 0.537134\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039424; batch adversarial loss: 0.401300\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035949; batch adversarial loss: 0.436210\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022692; batch adversarial loss: 0.481224\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021684; batch adversarial loss: 0.420700\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028182; batch adversarial loss: 0.535463\n",
      "epoch 158; iter: 0; batch classifier loss: 0.031661; batch adversarial loss: 0.446804\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015375; batch adversarial loss: 0.394851\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018443; batch adversarial loss: 0.500581\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027479; batch adversarial loss: 0.444952\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038109; batch adversarial loss: 0.533845\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035736; batch adversarial loss: 0.444395\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032293; batch adversarial loss: 0.433495\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040177; batch adversarial loss: 0.506072\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022018; batch adversarial loss: 0.448581\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032543; batch adversarial loss: 0.438072\n",
      "epoch 168; iter: 0; batch classifier loss: 0.061545; batch adversarial loss: 0.455196\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010651; batch adversarial loss: 0.380612\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020747; batch adversarial loss: 0.378345\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010136; batch adversarial loss: 0.417716\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018656; batch adversarial loss: 0.536489\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032867; batch adversarial loss: 0.422257\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020422; batch adversarial loss: 0.530315\n",
      "epoch 175; iter: 0; batch classifier loss: 0.044562; batch adversarial loss: 0.365698\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022300; batch adversarial loss: 0.505450\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036429; batch adversarial loss: 0.547162\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018329; batch adversarial loss: 0.413483\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018290; batch adversarial loss: 0.555885\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025473; batch adversarial loss: 0.391101\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009443; batch adversarial loss: 0.579129\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025373; batch adversarial loss: 0.466379\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024757; batch adversarial loss: 0.454058\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014663; batch adversarial loss: 0.471141\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020905; batch adversarial loss: 0.523961\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010740; batch adversarial loss: 0.473556\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019584; batch adversarial loss: 0.488076\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016375; batch adversarial loss: 0.539840\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022695; batch adversarial loss: 0.416561\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020936; batch adversarial loss: 0.368392\n",
      "epoch 191; iter: 0; batch classifier loss: 0.044292; batch adversarial loss: 0.526484\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020251; batch adversarial loss: 0.547312\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021653; batch adversarial loss: 0.449278\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020189; batch adversarial loss: 0.403813\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034981; batch adversarial loss: 0.486594\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028107; batch adversarial loss: 0.504257\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019015; batch adversarial loss: 0.466760\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009979; batch adversarial loss: 0.485238\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031852; batch adversarial loss: 0.423213\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687890; batch adversarial loss: 1.003292\n",
      "epoch 1; iter: 0; batch classifier loss: 0.489455; batch adversarial loss: 1.039670\n",
      "epoch 2; iter: 0; batch classifier loss: 0.543014; batch adversarial loss: 1.046488\n",
      "epoch 3; iter: 0; batch classifier loss: 0.332276; batch adversarial loss: 0.886550\n",
      "epoch 4; iter: 0; batch classifier loss: 0.353549; batch adversarial loss: 0.839939\n",
      "epoch 5; iter: 0; batch classifier loss: 0.346231; batch adversarial loss: 0.735813\n",
      "epoch 6; iter: 0; batch classifier loss: 0.307917; batch adversarial loss: 0.737972\n",
      "epoch 7; iter: 0; batch classifier loss: 0.350567; batch adversarial loss: 0.682812\n",
      "epoch 8; iter: 0; batch classifier loss: 0.289123; batch adversarial loss: 0.634781\n",
      "epoch 9; iter: 0; batch classifier loss: 0.305383; batch adversarial loss: 0.645600\n",
      "epoch 10; iter: 0; batch classifier loss: 0.334329; batch adversarial loss: 0.613905\n",
      "epoch 11; iter: 0; batch classifier loss: 0.300094; batch adversarial loss: 0.591953\n",
      "epoch 12; iter: 0; batch classifier loss: 0.306719; batch adversarial loss: 0.577554\n",
      "epoch 13; iter: 0; batch classifier loss: 0.193675; batch adversarial loss: 0.581660\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263247; batch adversarial loss: 0.548092\n",
      "epoch 15; iter: 0; batch classifier loss: 0.264932; batch adversarial loss: 0.517105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.241290; batch adversarial loss: 0.493528\n",
      "epoch 17; iter: 0; batch classifier loss: 0.180194; batch adversarial loss: 0.505616\n",
      "epoch 18; iter: 0; batch classifier loss: 0.224256; batch adversarial loss: 0.486583\n",
      "epoch 19; iter: 0; batch classifier loss: 0.230756; batch adversarial loss: 0.471757\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222879; batch adversarial loss: 0.448276\n",
      "epoch 21; iter: 0; batch classifier loss: 0.211228; batch adversarial loss: 0.459205\n",
      "epoch 22; iter: 0; batch classifier loss: 0.174788; batch adversarial loss: 0.444611\n",
      "epoch 23; iter: 0; batch classifier loss: 0.220090; batch adversarial loss: 0.457610\n",
      "epoch 24; iter: 0; batch classifier loss: 0.242698; batch adversarial loss: 0.465541\n",
      "epoch 25; iter: 0; batch classifier loss: 0.241310; batch adversarial loss: 0.432490\n",
      "epoch 26; iter: 0; batch classifier loss: 0.211895; batch adversarial loss: 0.414795\n",
      "epoch 27; iter: 0; batch classifier loss: 0.243893; batch adversarial loss: 0.462506\n",
      "epoch 28; iter: 0; batch classifier loss: 0.200330; batch adversarial loss: 0.468640\n",
      "epoch 29; iter: 0; batch classifier loss: 0.266781; batch adversarial loss: 0.449681\n",
      "epoch 30; iter: 0; batch classifier loss: 0.209921; batch adversarial loss: 0.482921\n",
      "epoch 31; iter: 0; batch classifier loss: 0.179601; batch adversarial loss: 0.442424\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165914; batch adversarial loss: 0.425355\n",
      "epoch 33; iter: 0; batch classifier loss: 0.182213; batch adversarial loss: 0.449478\n",
      "epoch 34; iter: 0; batch classifier loss: 0.199888; batch adversarial loss: 0.454896\n",
      "epoch 35; iter: 0; batch classifier loss: 0.197135; batch adversarial loss: 0.362035\n",
      "epoch 36; iter: 0; batch classifier loss: 0.215039; batch adversarial loss: 0.393794\n",
      "epoch 37; iter: 0; batch classifier loss: 0.157906; batch adversarial loss: 0.473301\n",
      "epoch 38; iter: 0; batch classifier loss: 0.152395; batch adversarial loss: 0.458049\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125801; batch adversarial loss: 0.313669\n",
      "epoch 40; iter: 0; batch classifier loss: 0.203817; batch adversarial loss: 0.421482\n",
      "epoch 41; iter: 0; batch classifier loss: 0.205802; batch adversarial loss: 0.389899\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116692; batch adversarial loss: 0.379020\n",
      "epoch 43; iter: 0; batch classifier loss: 0.140746; batch adversarial loss: 0.372026\n",
      "epoch 44; iter: 0; batch classifier loss: 0.128567; batch adversarial loss: 0.449591\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117401; batch adversarial loss: 0.417955\n",
      "epoch 46; iter: 0; batch classifier loss: 0.151003; batch adversarial loss: 0.374979\n",
      "epoch 47; iter: 0; batch classifier loss: 0.127969; batch adversarial loss: 0.467767\n",
      "epoch 48; iter: 0; batch classifier loss: 0.114486; batch adversarial loss: 0.426575\n",
      "epoch 49; iter: 0; batch classifier loss: 0.127096; batch adversarial loss: 0.432768\n",
      "epoch 50; iter: 0; batch classifier loss: 0.129853; batch adversarial loss: 0.356589\n",
      "epoch 51; iter: 0; batch classifier loss: 0.108122; batch adversarial loss: 0.383427\n",
      "epoch 52; iter: 0; batch classifier loss: 0.118027; batch adversarial loss: 0.412610\n",
      "epoch 53; iter: 0; batch classifier loss: 0.109150; batch adversarial loss: 0.373166\n",
      "epoch 54; iter: 0; batch classifier loss: 0.124993; batch adversarial loss: 0.401648\n",
      "epoch 55; iter: 0; batch classifier loss: 0.104818; batch adversarial loss: 0.422438\n",
      "epoch 56; iter: 0; batch classifier loss: 0.114179; batch adversarial loss: 0.354608\n",
      "epoch 57; iter: 0; batch classifier loss: 0.125373; batch adversarial loss: 0.406207\n",
      "epoch 58; iter: 0; batch classifier loss: 0.105180; batch adversarial loss: 0.384469\n",
      "epoch 59; iter: 0; batch classifier loss: 0.118981; batch adversarial loss: 0.451945\n",
      "epoch 60; iter: 0; batch classifier loss: 0.117346; batch adversarial loss: 0.408213\n",
      "epoch 61; iter: 0; batch classifier loss: 0.102104; batch adversarial loss: 0.414553\n",
      "epoch 62; iter: 0; batch classifier loss: 0.149332; batch adversarial loss: 0.439071\n",
      "epoch 63; iter: 0; batch classifier loss: 0.074570; batch adversarial loss: 0.482715\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082120; batch adversarial loss: 0.434368\n",
      "epoch 65; iter: 0; batch classifier loss: 0.085880; batch adversarial loss: 0.392124\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072949; batch adversarial loss: 0.341626\n",
      "epoch 67; iter: 0; batch classifier loss: 0.078778; batch adversarial loss: 0.391338\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081879; batch adversarial loss: 0.370442\n",
      "epoch 69; iter: 0; batch classifier loss: 0.091662; batch adversarial loss: 0.529156\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065448; batch adversarial loss: 0.418507\n",
      "epoch 71; iter: 0; batch classifier loss: 0.076090; batch adversarial loss: 0.436125\n",
      "epoch 72; iter: 0; batch classifier loss: 0.089794; batch adversarial loss: 0.340029\n",
      "epoch 73; iter: 0; batch classifier loss: 0.092401; batch adversarial loss: 0.394449\n",
      "epoch 74; iter: 0; batch classifier loss: 0.086192; batch adversarial loss: 0.408764\n",
      "epoch 75; iter: 0; batch classifier loss: 0.057464; batch adversarial loss: 0.372999\n",
      "epoch 76; iter: 0; batch classifier loss: 0.087519; batch adversarial loss: 0.420472\n",
      "epoch 77; iter: 0; batch classifier loss: 0.078309; batch adversarial loss: 0.413504\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079142; batch adversarial loss: 0.461729\n",
      "epoch 79; iter: 0; batch classifier loss: 0.093022; batch adversarial loss: 0.362423\n",
      "epoch 80; iter: 0; batch classifier loss: 0.044394; batch adversarial loss: 0.436101\n",
      "epoch 81; iter: 0; batch classifier loss: 0.107243; batch adversarial loss: 0.438506\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066737; batch adversarial loss: 0.489245\n",
      "epoch 83; iter: 0; batch classifier loss: 0.107630; batch adversarial loss: 0.405637\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085630; batch adversarial loss: 0.522309\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073057; batch adversarial loss: 0.409534\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057931; batch adversarial loss: 0.451657\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062900; batch adversarial loss: 0.409463\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040949; batch adversarial loss: 0.404514\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057097; batch adversarial loss: 0.423396\n",
      "epoch 90; iter: 0; batch classifier loss: 0.099786; batch adversarial loss: 0.393189\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056706; batch adversarial loss: 0.437064\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070587; batch adversarial loss: 0.495863\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048121; batch adversarial loss: 0.450990\n",
      "epoch 94; iter: 0; batch classifier loss: 0.060354; batch adversarial loss: 0.320730\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070922; batch adversarial loss: 0.349502\n",
      "epoch 96; iter: 0; batch classifier loss: 0.081959; batch adversarial loss: 0.367309\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069760; batch adversarial loss: 0.403204\n",
      "epoch 98; iter: 0; batch classifier loss: 0.104297; batch adversarial loss: 0.413822\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067035; batch adversarial loss: 0.340155\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064445; batch adversarial loss: 0.504686\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044224; batch adversarial loss: 0.371841\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054032; batch adversarial loss: 0.362218\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056665; batch adversarial loss: 0.466397\n",
      "epoch 104; iter: 0; batch classifier loss: 0.074371; batch adversarial loss: 0.439052\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044030; batch adversarial loss: 0.437713\n",
      "epoch 106; iter: 0; batch classifier loss: 0.061490; batch adversarial loss: 0.385374\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063915; batch adversarial loss: 0.481188\n",
      "epoch 108; iter: 0; batch classifier loss: 0.073610; batch adversarial loss: 0.422682\n",
      "epoch 109; iter: 0; batch classifier loss: 0.063865; batch adversarial loss: 0.414759\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068970; batch adversarial loss: 0.370836\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044057; batch adversarial loss: 0.396721\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030185; batch adversarial loss: 0.341966\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047783; batch adversarial loss: 0.450432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.070297; batch adversarial loss: 0.495189\n",
      "epoch 115; iter: 0; batch classifier loss: 0.080715; batch adversarial loss: 0.514878\n",
      "epoch 116; iter: 0; batch classifier loss: 0.082047; batch adversarial loss: 0.474716\n",
      "epoch 117; iter: 0; batch classifier loss: 0.090301; batch adversarial loss: 0.372940\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036084; batch adversarial loss: 0.426675\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038130; batch adversarial loss: 0.350631\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048600; batch adversarial loss: 0.497260\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049623; batch adversarial loss: 0.379273\n",
      "epoch 122; iter: 0; batch classifier loss: 0.068950; batch adversarial loss: 0.326947\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053230; batch adversarial loss: 0.443395\n",
      "epoch 124; iter: 0; batch classifier loss: 0.068247; batch adversarial loss: 0.417233\n",
      "epoch 125; iter: 0; batch classifier loss: 0.060771; batch adversarial loss: 0.434257\n",
      "epoch 126; iter: 0; batch classifier loss: 0.076597; batch adversarial loss: 0.408121\n",
      "epoch 127; iter: 0; batch classifier loss: 0.068551; batch adversarial loss: 0.480558\n",
      "epoch 128; iter: 0; batch classifier loss: 0.068184; batch adversarial loss: 0.460986\n",
      "epoch 129; iter: 0; batch classifier loss: 0.060353; batch adversarial loss: 0.358020\n",
      "epoch 130; iter: 0; batch classifier loss: 0.070548; batch adversarial loss: 0.479130\n",
      "epoch 131; iter: 0; batch classifier loss: 0.054070; batch adversarial loss: 0.365224\n",
      "epoch 132; iter: 0; batch classifier loss: 0.091406; batch adversarial loss: 0.456738\n",
      "epoch 133; iter: 0; batch classifier loss: 0.054301; batch adversarial loss: 0.429996\n",
      "epoch 134; iter: 0; batch classifier loss: 0.063575; batch adversarial loss: 0.473914\n",
      "epoch 135; iter: 0; batch classifier loss: 0.054504; batch adversarial loss: 0.447429\n",
      "epoch 136; iter: 0; batch classifier loss: 0.076817; batch adversarial loss: 0.382953\n",
      "epoch 137; iter: 0; batch classifier loss: 0.057346; batch adversarial loss: 0.496903\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044204; batch adversarial loss: 0.478086\n",
      "epoch 139; iter: 0; batch classifier loss: 0.056818; batch adversarial loss: 0.440182\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050629; batch adversarial loss: 0.417871\n",
      "epoch 141; iter: 0; batch classifier loss: 0.051939; batch adversarial loss: 0.465608\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042566; batch adversarial loss: 0.366163\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031242; batch adversarial loss: 0.430522\n",
      "epoch 144; iter: 0; batch classifier loss: 0.053436; batch adversarial loss: 0.453524\n",
      "epoch 145; iter: 0; batch classifier loss: 0.060747; batch adversarial loss: 0.432849\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025475; batch adversarial loss: 0.477378\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041855; batch adversarial loss: 0.367003\n",
      "epoch 148; iter: 0; batch classifier loss: 0.064363; batch adversarial loss: 0.544221\n",
      "epoch 149; iter: 0; batch classifier loss: 0.071072; batch adversarial loss: 0.564467\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030686; batch adversarial loss: 0.541592\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025114; batch adversarial loss: 0.408541\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038469; batch adversarial loss: 0.438373\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030966; batch adversarial loss: 0.438755\n",
      "epoch 154; iter: 0; batch classifier loss: 0.048586; batch adversarial loss: 0.426097\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031976; batch adversarial loss: 0.500403\n",
      "epoch 156; iter: 0; batch classifier loss: 0.068284; batch adversarial loss: 0.468025\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036472; batch adversarial loss: 0.378045\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037802; batch adversarial loss: 0.338737\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022192; batch adversarial loss: 0.391528\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036363; batch adversarial loss: 0.420973\n",
      "epoch 161; iter: 0; batch classifier loss: 0.051603; batch adversarial loss: 0.364074\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037515; batch adversarial loss: 0.408006\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039885; batch adversarial loss: 0.356710\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011929; batch adversarial loss: 0.573708\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025872; batch adversarial loss: 0.491077\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019949; batch adversarial loss: 0.401965\n",
      "epoch 167; iter: 0; batch classifier loss: 0.037057; batch adversarial loss: 0.450860\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037537; batch adversarial loss: 0.490204\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029886; batch adversarial loss: 0.377296\n",
      "epoch 170; iter: 0; batch classifier loss: 0.054951; batch adversarial loss: 0.436554\n",
      "epoch 171; iter: 0; batch classifier loss: 0.052536; batch adversarial loss: 0.364077\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008820; batch adversarial loss: 0.417574\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020730; batch adversarial loss: 0.533054\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026969; batch adversarial loss: 0.449171\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025715; batch adversarial loss: 0.443960\n",
      "epoch 176; iter: 0; batch classifier loss: 0.046450; batch adversarial loss: 0.410873\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032612; batch adversarial loss: 0.425481\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031953; batch adversarial loss: 0.381121\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017140; batch adversarial loss: 0.415600\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030761; batch adversarial loss: 0.448467\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018193; batch adversarial loss: 0.430218\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021151; batch adversarial loss: 0.434733\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025662; batch adversarial loss: 0.406266\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030456; batch adversarial loss: 0.407686\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012653; batch adversarial loss: 0.476799\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026333; batch adversarial loss: 0.551105\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040524; batch adversarial loss: 0.430211\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015769; batch adversarial loss: 0.471360\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020731; batch adversarial loss: 0.499305\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016194; batch adversarial loss: 0.587042\n",
      "epoch 191; iter: 0; batch classifier loss: 0.042207; batch adversarial loss: 0.431945\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027883; batch adversarial loss: 0.388698\n",
      "epoch 193; iter: 0; batch classifier loss: 0.044089; batch adversarial loss: 0.540014\n",
      "epoch 194; iter: 0; batch classifier loss: 0.061031; batch adversarial loss: 0.509511\n",
      "epoch 195; iter: 0; batch classifier loss: 0.062302; batch adversarial loss: 0.555100\n",
      "epoch 196; iter: 0; batch classifier loss: 0.047977; batch adversarial loss: 0.577497\n",
      "epoch 197; iter: 0; batch classifier loss: 0.069313; batch adversarial loss: 0.633687\n",
      "epoch 198; iter: 0; batch classifier loss: 0.071651; batch adversarial loss: 0.535658\n",
      "epoch 199; iter: 0; batch classifier loss: 0.100759; batch adversarial loss: 0.643230\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682351; batch adversarial loss: 0.930332\n",
      "epoch 1; iter: 0; batch classifier loss: 0.646140; batch adversarial loss: 1.004168\n",
      "epoch 2; iter: 0; batch classifier loss: 0.901131; batch adversarial loss: 1.064834\n",
      "epoch 3; iter: 0; batch classifier loss: 1.028379; batch adversarial loss: 0.970312\n",
      "epoch 4; iter: 0; batch classifier loss: 1.075873; batch adversarial loss: 0.874712\n",
      "epoch 5; iter: 0; batch classifier loss: 1.144158; batch adversarial loss: 0.810745\n",
      "epoch 6; iter: 0; batch classifier loss: 0.895995; batch adversarial loss: 0.708801\n",
      "epoch 7; iter: 0; batch classifier loss: 0.746109; batch adversarial loss: 0.666076\n",
      "epoch 8; iter: 0; batch classifier loss: 0.716901; batch adversarial loss: 0.622337\n",
      "epoch 9; iter: 0; batch classifier loss: 0.529898; batch adversarial loss: 0.583075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.395253; batch adversarial loss: 0.529225\n",
      "epoch 11; iter: 0; batch classifier loss: 0.317136; batch adversarial loss: 0.512633\n",
      "epoch 12; iter: 0; batch classifier loss: 0.312700; batch adversarial loss: 0.511853\n",
      "epoch 13; iter: 0; batch classifier loss: 0.315987; batch adversarial loss: 0.527711\n",
      "epoch 14; iter: 0; batch classifier loss: 0.292348; batch adversarial loss: 0.498663\n",
      "epoch 15; iter: 0; batch classifier loss: 0.218661; batch adversarial loss: 0.559008\n",
      "epoch 16; iter: 0; batch classifier loss: 0.304687; batch adversarial loss: 0.552027\n",
      "epoch 17; iter: 0; batch classifier loss: 0.281258; batch adversarial loss: 0.540101\n",
      "epoch 18; iter: 0; batch classifier loss: 0.260817; batch adversarial loss: 0.513392\n",
      "epoch 19; iter: 0; batch classifier loss: 0.271974; batch adversarial loss: 0.496880\n",
      "epoch 20; iter: 0; batch classifier loss: 0.221789; batch adversarial loss: 0.515660\n",
      "epoch 21; iter: 0; batch classifier loss: 0.259167; batch adversarial loss: 0.473768\n",
      "epoch 22; iter: 0; batch classifier loss: 0.254307; batch adversarial loss: 0.439851\n",
      "epoch 23; iter: 0; batch classifier loss: 0.212329; batch adversarial loss: 0.488734\n",
      "epoch 24; iter: 0; batch classifier loss: 0.191718; batch adversarial loss: 0.528432\n",
      "epoch 25; iter: 0; batch classifier loss: 0.288895; batch adversarial loss: 0.418181\n",
      "epoch 26; iter: 0; batch classifier loss: 0.198786; batch adversarial loss: 0.467794\n",
      "epoch 27; iter: 0; batch classifier loss: 0.185564; batch adversarial loss: 0.399945\n",
      "epoch 28; iter: 0; batch classifier loss: 0.160358; batch adversarial loss: 0.409174\n",
      "epoch 29; iter: 0; batch classifier loss: 0.168533; batch adversarial loss: 0.512737\n",
      "epoch 30; iter: 0; batch classifier loss: 0.215866; batch adversarial loss: 0.406634\n",
      "epoch 31; iter: 0; batch classifier loss: 0.164072; batch adversarial loss: 0.410473\n",
      "epoch 32; iter: 0; batch classifier loss: 0.206937; batch adversarial loss: 0.422395\n",
      "epoch 33; iter: 0; batch classifier loss: 0.120694; batch adversarial loss: 0.466343\n",
      "epoch 34; iter: 0; batch classifier loss: 0.120224; batch adversarial loss: 0.502916\n",
      "epoch 35; iter: 0; batch classifier loss: 0.117021; batch adversarial loss: 0.526017\n",
      "epoch 36; iter: 0; batch classifier loss: 0.157633; batch adversarial loss: 0.383539\n",
      "epoch 37; iter: 0; batch classifier loss: 0.119724; batch adversarial loss: 0.503056\n",
      "epoch 38; iter: 0; batch classifier loss: 0.142617; batch adversarial loss: 0.460627\n",
      "epoch 39; iter: 0; batch classifier loss: 0.136559; batch adversarial loss: 0.381605\n",
      "epoch 40; iter: 0; batch classifier loss: 0.123680; batch adversarial loss: 0.439502\n",
      "epoch 41; iter: 0; batch classifier loss: 0.102547; batch adversarial loss: 0.468830\n",
      "epoch 42; iter: 0; batch classifier loss: 0.132474; batch adversarial loss: 0.425695\n",
      "epoch 43; iter: 0; batch classifier loss: 0.097305; batch adversarial loss: 0.515134\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118482; batch adversarial loss: 0.471301\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086198; batch adversarial loss: 0.461776\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086830; batch adversarial loss: 0.488542\n",
      "epoch 47; iter: 0; batch classifier loss: 0.193566; batch adversarial loss: 0.359445\n",
      "epoch 48; iter: 0; batch classifier loss: 0.106097; batch adversarial loss: 0.460441\n",
      "epoch 49; iter: 0; batch classifier loss: 0.082667; batch adversarial loss: 0.565836\n",
      "epoch 50; iter: 0; batch classifier loss: 0.077699; batch adversarial loss: 0.550215\n",
      "epoch 51; iter: 0; batch classifier loss: 0.053566; batch adversarial loss: 0.458595\n",
      "epoch 52; iter: 0; batch classifier loss: 0.063475; batch adversarial loss: 0.432505\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076433; batch adversarial loss: 0.601203\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103911; batch adversarial loss: 0.533303\n",
      "epoch 55; iter: 0; batch classifier loss: 0.114447; batch adversarial loss: 0.501037\n",
      "epoch 56; iter: 0; batch classifier loss: 0.113005; batch adversarial loss: 0.397819\n",
      "epoch 57; iter: 0; batch classifier loss: 0.118718; batch adversarial loss: 0.448821\n",
      "epoch 58; iter: 0; batch classifier loss: 0.059742; batch adversarial loss: 0.425137\n",
      "epoch 59; iter: 0; batch classifier loss: 0.086369; batch adversarial loss: 0.415317\n",
      "epoch 60; iter: 0; batch classifier loss: 0.060042; batch adversarial loss: 0.473713\n",
      "epoch 61; iter: 0; batch classifier loss: 0.051417; batch adversarial loss: 0.429047\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089108; batch adversarial loss: 0.424889\n",
      "epoch 63; iter: 0; batch classifier loss: 0.084253; batch adversarial loss: 0.443776\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080266; batch adversarial loss: 0.365364\n",
      "epoch 65; iter: 0; batch classifier loss: 0.071421; batch adversarial loss: 0.474212\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075132; batch adversarial loss: 0.459346\n",
      "epoch 67; iter: 0; batch classifier loss: 0.051628; batch adversarial loss: 0.468176\n",
      "epoch 68; iter: 0; batch classifier loss: 0.039478; batch adversarial loss: 0.476995\n",
      "epoch 69; iter: 0; batch classifier loss: 0.069712; batch adversarial loss: 0.439702\n",
      "epoch 70; iter: 0; batch classifier loss: 0.060063; batch adversarial loss: 0.394803\n",
      "epoch 71; iter: 0; batch classifier loss: 0.040203; batch adversarial loss: 0.480459\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054446; batch adversarial loss: 0.506046\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065109; batch adversarial loss: 0.429394\n",
      "epoch 74; iter: 0; batch classifier loss: 0.070870; batch adversarial loss: 0.456036\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063268; batch adversarial loss: 0.418938\n",
      "epoch 76; iter: 0; batch classifier loss: 0.056290; batch adversarial loss: 0.413236\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056117; batch adversarial loss: 0.485382\n",
      "epoch 78; iter: 0; batch classifier loss: 0.076113; batch adversarial loss: 0.469102\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057079; batch adversarial loss: 0.446057\n",
      "epoch 80; iter: 0; batch classifier loss: 0.092799; batch adversarial loss: 0.425494\n",
      "epoch 81; iter: 0; batch classifier loss: 0.039250; batch adversarial loss: 0.446449\n",
      "epoch 82; iter: 0; batch classifier loss: 0.049389; batch adversarial loss: 0.486806\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059956; batch adversarial loss: 0.482287\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055184; batch adversarial loss: 0.464195\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055533; batch adversarial loss: 0.402565\n",
      "epoch 86; iter: 0; batch classifier loss: 0.044754; batch adversarial loss: 0.450464\n",
      "epoch 87; iter: 0; batch classifier loss: 0.106914; batch adversarial loss: 0.427640\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054356; batch adversarial loss: 0.421034\n",
      "epoch 89; iter: 0; batch classifier loss: 0.032952; batch adversarial loss: 0.462616\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056150; batch adversarial loss: 0.414823\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062063; batch adversarial loss: 0.385555\n",
      "epoch 92; iter: 0; batch classifier loss: 0.020933; batch adversarial loss: 0.419998\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051953; batch adversarial loss: 0.411671\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062116; batch adversarial loss: 0.456914\n",
      "epoch 95; iter: 0; batch classifier loss: 0.040373; batch adversarial loss: 0.465787\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048055; batch adversarial loss: 0.399416\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054597; batch adversarial loss: 0.422761\n",
      "epoch 98; iter: 0; batch classifier loss: 0.060469; batch adversarial loss: 0.465660\n",
      "epoch 99; iter: 0; batch classifier loss: 0.018300; batch adversarial loss: 0.435379\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045117; batch adversarial loss: 0.484045\n",
      "epoch 101; iter: 0; batch classifier loss: 0.030371; batch adversarial loss: 0.518066\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046116; batch adversarial loss: 0.400852\n",
      "epoch 103; iter: 0; batch classifier loss: 0.020337; batch adversarial loss: 0.436675\n",
      "epoch 104; iter: 0; batch classifier loss: 0.028171; batch adversarial loss: 0.580414\n",
      "epoch 105; iter: 0; batch classifier loss: 0.024807; batch adversarial loss: 0.439868\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046515; batch adversarial loss: 0.407670\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055420; batch adversarial loss: 0.474927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.033130; batch adversarial loss: 0.419693\n",
      "epoch 109; iter: 0; batch classifier loss: 0.022645; batch adversarial loss: 0.445977\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031068; batch adversarial loss: 0.391034\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064862; batch adversarial loss: 0.414907\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046866; batch adversarial loss: 0.508248\n",
      "epoch 113; iter: 0; batch classifier loss: 0.013760; batch adversarial loss: 0.446256\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047975; batch adversarial loss: 0.440351\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063992; batch adversarial loss: 0.352416\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052271; batch adversarial loss: 0.480852\n",
      "epoch 117; iter: 0; batch classifier loss: 0.019853; batch adversarial loss: 0.411424\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056485; batch adversarial loss: 0.442492\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026690; batch adversarial loss: 0.465955\n",
      "epoch 120; iter: 0; batch classifier loss: 0.019065; batch adversarial loss: 0.418297\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039710; batch adversarial loss: 0.597169\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028411; batch adversarial loss: 0.363322\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042011; batch adversarial loss: 0.438178\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022326; batch adversarial loss: 0.463887\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022138; batch adversarial loss: 0.507666\n",
      "epoch 126; iter: 0; batch classifier loss: 0.072239; batch adversarial loss: 0.361952\n",
      "epoch 127; iter: 0; batch classifier loss: 0.017338; batch adversarial loss: 0.439831\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019522; batch adversarial loss: 0.530170\n",
      "epoch 129; iter: 0; batch classifier loss: 0.011757; batch adversarial loss: 0.337779\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032842; batch adversarial loss: 0.445442\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019297; batch adversarial loss: 0.586172\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015143; batch adversarial loss: 0.426076\n",
      "epoch 133; iter: 0; batch classifier loss: 0.055227; batch adversarial loss: 0.434694\n",
      "epoch 134; iter: 0; batch classifier loss: 0.005486; batch adversarial loss: 0.375744\n",
      "epoch 135; iter: 0; batch classifier loss: 0.053774; batch adversarial loss: 0.467021\n",
      "epoch 136; iter: 0; batch classifier loss: 0.015366; batch adversarial loss: 0.449260\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020113; batch adversarial loss: 0.432564\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022533; batch adversarial loss: 0.394414\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015368; batch adversarial loss: 0.450269\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036240; batch adversarial loss: 0.511787\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038378; batch adversarial loss: 0.426645\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016575; batch adversarial loss: 0.453446\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031246; batch adversarial loss: 0.431584\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021780; batch adversarial loss: 0.556005\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031041; batch adversarial loss: 0.467371\n",
      "epoch 146; iter: 0; batch classifier loss: 0.046652; batch adversarial loss: 0.436508\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052888; batch adversarial loss: 0.426619\n",
      "epoch 148; iter: 0; batch classifier loss: 0.080357; batch adversarial loss: 0.400780\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011192; batch adversarial loss: 0.440075\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015473; batch adversarial loss: 0.521775\n",
      "epoch 151; iter: 0; batch classifier loss: 0.010347; batch adversarial loss: 0.447777\n",
      "epoch 152; iter: 0; batch classifier loss: 0.012930; batch adversarial loss: 0.460690\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016782; batch adversarial loss: 0.412398\n",
      "epoch 154; iter: 0; batch classifier loss: 0.009517; batch adversarial loss: 0.457132\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021195; batch adversarial loss: 0.465976\n",
      "epoch 156; iter: 0; batch classifier loss: 0.005346; batch adversarial loss: 0.430366\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021405; batch adversarial loss: 0.388713\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008330; batch adversarial loss: 0.436852\n",
      "epoch 159; iter: 0; batch classifier loss: 0.008586; batch adversarial loss: 0.542881\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007542; batch adversarial loss: 0.423082\n",
      "epoch 161; iter: 0; batch classifier loss: 0.006648; batch adversarial loss: 0.516076\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022466; batch adversarial loss: 0.522784\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006307; batch adversarial loss: 0.424974\n",
      "epoch 164; iter: 0; batch classifier loss: 0.065445; batch adversarial loss: 0.473886\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024739; batch adversarial loss: 0.404940\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040091; batch adversarial loss: 0.453722\n",
      "epoch 167; iter: 0; batch classifier loss: 0.004793; batch adversarial loss: 0.358336\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011651; batch adversarial loss: 0.375434\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009087; batch adversarial loss: 0.498441\n",
      "epoch 170; iter: 0; batch classifier loss: 0.004615; batch adversarial loss: 0.477680\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015881; batch adversarial loss: 0.382529\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034385; batch adversarial loss: 0.406398\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007212; batch adversarial loss: 0.484806\n",
      "epoch 174; iter: 0; batch classifier loss: 0.003450; batch adversarial loss: 0.484349\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011062; batch adversarial loss: 0.420629\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014325; batch adversarial loss: 0.400162\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018521; batch adversarial loss: 0.331912\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015734; batch adversarial loss: 0.353856\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017443; batch adversarial loss: 0.528566\n",
      "epoch 180; iter: 0; batch classifier loss: 0.047933; batch adversarial loss: 0.460360\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008161; batch adversarial loss: 0.517753\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014673; batch adversarial loss: 0.530612\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015953; batch adversarial loss: 0.457115\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019834; batch adversarial loss: 0.428432\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026027; batch adversarial loss: 0.504837\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012553; batch adversarial loss: 0.452995\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011017; batch adversarial loss: 0.472584\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008287; batch adversarial loss: 0.452546\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017641; batch adversarial loss: 0.383036\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026650; batch adversarial loss: 0.436889\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005484; batch adversarial loss: 0.430041\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018870; batch adversarial loss: 0.438526\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007206; batch adversarial loss: 0.461445\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024417; batch adversarial loss: 0.409857\n",
      "epoch 195; iter: 0; batch classifier loss: 0.003648; batch adversarial loss: 0.418445\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022559; batch adversarial loss: 0.372393\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015897; batch adversarial loss: 0.398127\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005843; batch adversarial loss: 0.459788\n",
      "epoch 199; iter: 0; batch classifier loss: 0.040044; batch adversarial loss: 0.413559\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687397; batch adversarial loss: 0.718907\n",
      "epoch 1; iter: 0; batch classifier loss: 0.445126; batch adversarial loss: 0.679117\n",
      "epoch 2; iter: 0; batch classifier loss: 0.406080; batch adversarial loss: 0.651537\n",
      "epoch 3; iter: 0; batch classifier loss: 0.405667; batch adversarial loss: 0.615135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.329061; batch adversarial loss: 0.592544\n",
      "epoch 5; iter: 0; batch classifier loss: 0.308527; batch adversarial loss: 0.540526\n",
      "epoch 6; iter: 0; batch classifier loss: 0.300057; batch adversarial loss: 0.516447\n",
      "epoch 7; iter: 0; batch classifier loss: 0.289583; batch adversarial loss: 0.513192\n",
      "epoch 8; iter: 0; batch classifier loss: 0.243354; batch adversarial loss: 0.532473\n",
      "epoch 9; iter: 0; batch classifier loss: 0.254613; batch adversarial loss: 0.501232\n",
      "epoch 10; iter: 0; batch classifier loss: 0.191074; batch adversarial loss: 0.464452\n",
      "epoch 11; iter: 0; batch classifier loss: 0.119089; batch adversarial loss: 0.541481\n",
      "epoch 12; iter: 0; batch classifier loss: 0.231425; batch adversarial loss: 0.499215\n",
      "epoch 13; iter: 0; batch classifier loss: 0.204038; batch adversarial loss: 0.504652\n",
      "epoch 14; iter: 0; batch classifier loss: 0.177249; batch adversarial loss: 0.449617\n",
      "epoch 15; iter: 0; batch classifier loss: 0.132504; batch adversarial loss: 0.481504\n",
      "epoch 16; iter: 0; batch classifier loss: 0.202075; batch adversarial loss: 0.441337\n",
      "epoch 17; iter: 0; batch classifier loss: 0.137466; batch adversarial loss: 0.442909\n",
      "epoch 18; iter: 0; batch classifier loss: 0.144784; batch adversarial loss: 0.494407\n",
      "epoch 19; iter: 0; batch classifier loss: 0.132463; batch adversarial loss: 0.408279\n",
      "epoch 20; iter: 0; batch classifier loss: 0.135615; batch adversarial loss: 0.535258\n",
      "epoch 21; iter: 0; batch classifier loss: 0.177363; batch adversarial loss: 0.431637\n",
      "epoch 22; iter: 0; batch classifier loss: 0.129664; batch adversarial loss: 0.487674\n",
      "epoch 23; iter: 0; batch classifier loss: 0.079403; batch adversarial loss: 0.479255\n",
      "epoch 24; iter: 0; batch classifier loss: 0.173914; batch adversarial loss: 0.478860\n",
      "epoch 25; iter: 0; batch classifier loss: 0.138682; batch adversarial loss: 0.565399\n",
      "epoch 26; iter: 0; batch classifier loss: 0.122107; batch adversarial loss: 0.444673\n",
      "epoch 27; iter: 0; batch classifier loss: 0.120230; batch adversarial loss: 0.473185\n",
      "epoch 28; iter: 0; batch classifier loss: 0.160642; batch adversarial loss: 0.517672\n",
      "epoch 29; iter: 0; batch classifier loss: 0.164415; batch adversarial loss: 0.515595\n",
      "epoch 30; iter: 0; batch classifier loss: 0.215754; batch adversarial loss: 0.558595\n",
      "epoch 31; iter: 0; batch classifier loss: 0.210610; batch adversarial loss: 0.523513\n",
      "epoch 32; iter: 0; batch classifier loss: 0.227350; batch adversarial loss: 0.520695\n",
      "epoch 33; iter: 0; batch classifier loss: 0.203561; batch adversarial loss: 0.566893\n",
      "epoch 34; iter: 0; batch classifier loss: 0.200549; batch adversarial loss: 0.630240\n",
      "epoch 35; iter: 0; batch classifier loss: 0.241251; batch adversarial loss: 0.559253\n",
      "epoch 36; iter: 0; batch classifier loss: 0.194502; batch adversarial loss: 0.510926\n",
      "epoch 37; iter: 0; batch classifier loss: 0.225639; batch adversarial loss: 0.480476\n",
      "epoch 38; iter: 0; batch classifier loss: 0.212561; batch adversarial loss: 0.475266\n",
      "epoch 39; iter: 0; batch classifier loss: 0.225256; batch adversarial loss: 0.413584\n",
      "epoch 40; iter: 0; batch classifier loss: 0.216200; batch adversarial loss: 0.415999\n",
      "epoch 41; iter: 0; batch classifier loss: 0.209087; batch adversarial loss: 0.384738\n",
      "epoch 42; iter: 0; batch classifier loss: 0.130142; batch adversarial loss: 0.521540\n",
      "epoch 43; iter: 0; batch classifier loss: 0.078312; batch adversarial loss: 0.450029\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085167; batch adversarial loss: 0.472250\n",
      "epoch 45; iter: 0; batch classifier loss: 0.054789; batch adversarial loss: 0.488302\n",
      "epoch 46; iter: 0; batch classifier loss: 0.089881; batch adversarial loss: 0.417573\n",
      "epoch 47; iter: 0; batch classifier loss: 0.084913; batch adversarial loss: 0.449513\n",
      "epoch 48; iter: 0; batch classifier loss: 0.070352; batch adversarial loss: 0.464465\n",
      "epoch 49; iter: 0; batch classifier loss: 0.069369; batch adversarial loss: 0.401084\n",
      "epoch 50; iter: 0; batch classifier loss: 0.061653; batch adversarial loss: 0.403491\n",
      "epoch 51; iter: 0; batch classifier loss: 0.077571; batch adversarial loss: 0.445516\n",
      "epoch 52; iter: 0; batch classifier loss: 0.054866; batch adversarial loss: 0.365553\n",
      "epoch 53; iter: 0; batch classifier loss: 0.107257; batch adversarial loss: 0.448265\n",
      "epoch 54; iter: 0; batch classifier loss: 0.068114; batch adversarial loss: 0.516251\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084213; batch adversarial loss: 0.476744\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102303; batch adversarial loss: 0.473093\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072640; batch adversarial loss: 0.474666\n",
      "epoch 58; iter: 0; batch classifier loss: 0.059521; batch adversarial loss: 0.490467\n",
      "epoch 59; iter: 0; batch classifier loss: 0.066130; batch adversarial loss: 0.546225\n",
      "epoch 60; iter: 0; batch classifier loss: 0.112687; batch adversarial loss: 0.410729\n",
      "epoch 61; iter: 0; batch classifier loss: 0.051455; batch adversarial loss: 0.539384\n",
      "epoch 62; iter: 0; batch classifier loss: 0.079909; batch adversarial loss: 0.413217\n",
      "epoch 63; iter: 0; batch classifier loss: 0.109388; batch adversarial loss: 0.459229\n",
      "epoch 64; iter: 0; batch classifier loss: 0.111149; batch adversarial loss: 0.486045\n",
      "epoch 65; iter: 0; batch classifier loss: 0.121489; batch adversarial loss: 0.401390\n",
      "epoch 66; iter: 0; batch classifier loss: 0.053264; batch adversarial loss: 0.398233\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080519; batch adversarial loss: 0.520320\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082364; batch adversarial loss: 0.410354\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087136; batch adversarial loss: 0.433660\n",
      "epoch 70; iter: 0; batch classifier loss: 0.108108; batch adversarial loss: 0.403850\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079693; batch adversarial loss: 0.447797\n",
      "epoch 72; iter: 0; batch classifier loss: 0.085712; batch adversarial loss: 0.415024\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083025; batch adversarial loss: 0.445421\n",
      "epoch 74; iter: 0; batch classifier loss: 0.074704; batch adversarial loss: 0.467650\n",
      "epoch 75; iter: 0; batch classifier loss: 0.066771; batch adversarial loss: 0.432534\n",
      "epoch 76; iter: 0; batch classifier loss: 0.102028; batch adversarial loss: 0.497415\n",
      "epoch 77; iter: 0; batch classifier loss: 0.066774; batch adversarial loss: 0.389012\n",
      "epoch 78; iter: 0; batch classifier loss: 0.104737; batch adversarial loss: 0.546305\n",
      "epoch 79; iter: 0; batch classifier loss: 0.134301; batch adversarial loss: 0.463335\n",
      "epoch 80; iter: 0; batch classifier loss: 0.114279; batch adversarial loss: 0.504736\n",
      "epoch 81; iter: 0; batch classifier loss: 0.063309; batch adversarial loss: 0.430978\n",
      "epoch 82; iter: 0; batch classifier loss: 0.119345; batch adversarial loss: 0.427054\n",
      "epoch 83; iter: 0; batch classifier loss: 0.049746; batch adversarial loss: 0.485857\n",
      "epoch 84; iter: 0; batch classifier loss: 0.106264; batch adversarial loss: 0.482886\n",
      "epoch 85; iter: 0; batch classifier loss: 0.106731; batch adversarial loss: 0.410143\n",
      "epoch 86; iter: 0; batch classifier loss: 0.080484; batch adversarial loss: 0.412176\n",
      "epoch 87; iter: 0; batch classifier loss: 0.036668; batch adversarial loss: 0.431069\n",
      "epoch 88; iter: 0; batch classifier loss: 0.084201; batch adversarial loss: 0.521923\n",
      "epoch 89; iter: 0; batch classifier loss: 0.100085; batch adversarial loss: 0.501878\n",
      "epoch 90; iter: 0; batch classifier loss: 0.098361; batch adversarial loss: 0.460677\n",
      "epoch 91; iter: 0; batch classifier loss: 0.102022; batch adversarial loss: 0.444260\n",
      "epoch 92; iter: 0; batch classifier loss: 0.084415; batch adversarial loss: 0.436321\n",
      "epoch 93; iter: 0; batch classifier loss: 0.090167; batch adversarial loss: 0.447646\n",
      "epoch 94; iter: 0; batch classifier loss: 0.096553; batch adversarial loss: 0.407946\n",
      "epoch 95; iter: 0; batch classifier loss: 0.096512; batch adversarial loss: 0.459688\n",
      "epoch 96; iter: 0; batch classifier loss: 0.074242; batch adversarial loss: 0.427393\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049897; batch adversarial loss: 0.442357\n",
      "epoch 98; iter: 0; batch classifier loss: 0.098873; batch adversarial loss: 0.341878\n",
      "epoch 99; iter: 0; batch classifier loss: 0.149011; batch adversarial loss: 0.429314\n",
      "epoch 100; iter: 0; batch classifier loss: 0.119220; batch adversarial loss: 0.450294\n",
      "epoch 101; iter: 0; batch classifier loss: 0.059328; batch adversarial loss: 0.446130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.051962; batch adversarial loss: 0.524318\n",
      "epoch 103; iter: 0; batch classifier loss: 0.096286; batch adversarial loss: 0.499846\n",
      "epoch 104; iter: 0; batch classifier loss: 0.077420; batch adversarial loss: 0.563372\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066052; batch adversarial loss: 0.563402\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051844; batch adversarial loss: 0.516935\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037704; batch adversarial loss: 0.478778\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039453; batch adversarial loss: 0.444764\n",
      "epoch 109; iter: 0; batch classifier loss: 0.072870; batch adversarial loss: 0.533673\n",
      "epoch 110; iter: 0; batch classifier loss: 0.133783; batch adversarial loss: 0.492134\n",
      "epoch 111; iter: 0; batch classifier loss: 0.078492; batch adversarial loss: 0.467089\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063564; batch adversarial loss: 0.416772\n",
      "epoch 113; iter: 0; batch classifier loss: 0.073790; batch adversarial loss: 0.396136\n",
      "epoch 114; iter: 0; batch classifier loss: 0.101415; batch adversarial loss: 0.439608\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059267; batch adversarial loss: 0.499256\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038946; batch adversarial loss: 0.426431\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061639; batch adversarial loss: 0.428589\n",
      "epoch 118; iter: 0; batch classifier loss: 0.077377; batch adversarial loss: 0.492320\n",
      "epoch 119; iter: 0; batch classifier loss: 0.068351; batch adversarial loss: 0.523603\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042806; batch adversarial loss: 0.470709\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053162; batch adversarial loss: 0.481114\n",
      "epoch 122; iter: 0; batch classifier loss: 0.089333; batch adversarial loss: 0.531554\n",
      "epoch 123; iter: 0; batch classifier loss: 0.072131; batch adversarial loss: 0.440349\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051428; batch adversarial loss: 0.425804\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046469; batch adversarial loss: 0.482745\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057127; batch adversarial loss: 0.367020\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027971; batch adversarial loss: 0.503042\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056480; batch adversarial loss: 0.525827\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026584; batch adversarial loss: 0.452617\n",
      "epoch 130; iter: 0; batch classifier loss: 0.071266; batch adversarial loss: 0.400854\n",
      "epoch 131; iter: 0; batch classifier loss: 0.056719; batch adversarial loss: 0.385349\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051993; batch adversarial loss: 0.576814\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025857; batch adversarial loss: 0.403156\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045636; batch adversarial loss: 0.467676\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022940; batch adversarial loss: 0.533761\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026629; batch adversarial loss: 0.450662\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024045; batch adversarial loss: 0.474365\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049096; batch adversarial loss: 0.417135\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037678; batch adversarial loss: 0.530280\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027439; batch adversarial loss: 0.460399\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021927; batch adversarial loss: 0.422053\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023442; batch adversarial loss: 0.393870\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040835; batch adversarial loss: 0.535265\n",
      "epoch 144; iter: 0; batch classifier loss: 0.047720; batch adversarial loss: 0.447882\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026671; batch adversarial loss: 0.451520\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052423; batch adversarial loss: 0.389908\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021300; batch adversarial loss: 0.479593\n",
      "epoch 148; iter: 0; batch classifier loss: 0.063888; batch adversarial loss: 0.445670\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040570; batch adversarial loss: 0.530489\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044847; batch adversarial loss: 0.538544\n",
      "epoch 151; iter: 0; batch classifier loss: 0.084397; batch adversarial loss: 0.391169\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019341; batch adversarial loss: 0.431953\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034033; batch adversarial loss: 0.355585\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021045; batch adversarial loss: 0.532005\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023871; batch adversarial loss: 0.441946\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022477; batch adversarial loss: 0.417974\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013774; batch adversarial loss: 0.583712\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024722; batch adversarial loss: 0.392321\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011893; batch adversarial loss: 0.462915\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030258; batch adversarial loss: 0.519939\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035694; batch adversarial loss: 0.456231\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024748; batch adversarial loss: 0.525953\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026369; batch adversarial loss: 0.503223\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022022; batch adversarial loss: 0.525602\n",
      "epoch 165; iter: 0; batch classifier loss: 0.066238; batch adversarial loss: 0.491768\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013629; batch adversarial loss: 0.404807\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006799; batch adversarial loss: 0.494574\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034769; batch adversarial loss: 0.441687\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040455; batch adversarial loss: 0.411280\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019093; batch adversarial loss: 0.557193\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015097; batch adversarial loss: 0.456533\n",
      "epoch 172; iter: 0; batch classifier loss: 0.035589; batch adversarial loss: 0.457620\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019494; batch adversarial loss: 0.530196\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014921; batch adversarial loss: 0.415940\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016597; batch adversarial loss: 0.370553\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017829; batch adversarial loss: 0.449507\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014632; batch adversarial loss: 0.378884\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013305; batch adversarial loss: 0.478452\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032425; batch adversarial loss: 0.458837\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017651; batch adversarial loss: 0.466351\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023435; batch adversarial loss: 0.483568\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014813; batch adversarial loss: 0.452937\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030068; batch adversarial loss: 0.518178\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024014; batch adversarial loss: 0.438042\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021003; batch adversarial loss: 0.401480\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025333; batch adversarial loss: 0.436272\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029717; batch adversarial loss: 0.468149\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013859; batch adversarial loss: 0.309034\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016228; batch adversarial loss: 0.411020\n",
      "epoch 190; iter: 0; batch classifier loss: 0.050263; batch adversarial loss: 0.529198\n",
      "epoch 191; iter: 0; batch classifier loss: 0.040060; batch adversarial loss: 0.463020\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028908; batch adversarial loss: 0.484362\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019851; batch adversarial loss: 0.509660\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011403; batch adversarial loss: 0.452738\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026281; batch adversarial loss: 0.469394\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028335; batch adversarial loss: 0.486842\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016435; batch adversarial loss: 0.573881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.034309; batch adversarial loss: 0.519255\n",
      "epoch 199; iter: 0; batch classifier loss: 0.002762; batch adversarial loss: 0.386261\n",
      "epoch 0; iter: 0; batch classifier loss: 0.658868; batch adversarial loss: 0.713612\n",
      "epoch 1; iter: 0; batch classifier loss: 0.450181; batch adversarial loss: 0.703745\n",
      "epoch 2; iter: 0; batch classifier loss: 0.466023; batch adversarial loss: 0.664445\n",
      "epoch 3; iter: 0; batch classifier loss: 0.417725; batch adversarial loss: 0.624602\n",
      "epoch 4; iter: 0; batch classifier loss: 0.327890; batch adversarial loss: 0.598387\n",
      "epoch 5; iter: 0; batch classifier loss: 0.368532; batch adversarial loss: 0.529069\n",
      "epoch 6; iter: 0; batch classifier loss: 0.379081; batch adversarial loss: 0.525651\n",
      "epoch 7; iter: 0; batch classifier loss: 0.371287; batch adversarial loss: 0.511858\n",
      "epoch 8; iter: 0; batch classifier loss: 0.273338; batch adversarial loss: 0.541458\n",
      "epoch 9; iter: 0; batch classifier loss: 0.274769; batch adversarial loss: 0.464236\n",
      "epoch 10; iter: 0; batch classifier loss: 0.256789; batch adversarial loss: 0.476486\n",
      "epoch 11; iter: 0; batch classifier loss: 0.205820; batch adversarial loss: 0.463142\n",
      "epoch 12; iter: 0; batch classifier loss: 0.253163; batch adversarial loss: 0.406758\n",
      "epoch 13; iter: 0; batch classifier loss: 0.257229; batch adversarial loss: 0.459516\n",
      "epoch 14; iter: 0; batch classifier loss: 0.146653; batch adversarial loss: 0.540219\n",
      "epoch 15; iter: 0; batch classifier loss: 0.221226; batch adversarial loss: 0.426046\n",
      "epoch 16; iter: 0; batch classifier loss: 0.150068; batch adversarial loss: 0.487187\n",
      "epoch 17; iter: 0; batch classifier loss: 0.126525; batch adversarial loss: 0.525718\n",
      "epoch 18; iter: 0; batch classifier loss: 0.149731; batch adversarial loss: 0.427895\n",
      "epoch 19; iter: 0; batch classifier loss: 0.174222; batch adversarial loss: 0.474483\n",
      "epoch 20; iter: 0; batch classifier loss: 0.107904; batch adversarial loss: 0.567564\n",
      "epoch 21; iter: 0; batch classifier loss: 0.140253; batch adversarial loss: 0.464020\n",
      "epoch 22; iter: 0; batch classifier loss: 0.104579; batch adversarial loss: 0.402390\n",
      "epoch 23; iter: 0; batch classifier loss: 0.121046; batch adversarial loss: 0.458062\n",
      "epoch 24; iter: 0; batch classifier loss: 0.083921; batch adversarial loss: 0.531670\n",
      "epoch 25; iter: 0; batch classifier loss: 0.137089; batch adversarial loss: 0.468973\n",
      "epoch 26; iter: 0; batch classifier loss: 0.189085; batch adversarial loss: 0.408560\n",
      "epoch 27; iter: 0; batch classifier loss: 0.148545; batch adversarial loss: 0.399787\n",
      "epoch 28; iter: 0; batch classifier loss: 0.119108; batch adversarial loss: 0.428906\n",
      "epoch 29; iter: 0; batch classifier loss: 0.126706; batch adversarial loss: 0.520685\n",
      "epoch 30; iter: 0; batch classifier loss: 0.105796; batch adversarial loss: 0.514335\n",
      "epoch 31; iter: 0; batch classifier loss: 0.134414; batch adversarial loss: 0.505923\n",
      "epoch 32; iter: 0; batch classifier loss: 0.115777; batch adversarial loss: 0.489754\n",
      "epoch 33; iter: 0; batch classifier loss: 0.147971; batch adversarial loss: 0.466814\n",
      "epoch 34; iter: 0; batch classifier loss: 0.152999; batch adversarial loss: 0.553829\n",
      "epoch 35; iter: 0; batch classifier loss: 0.153052; batch adversarial loss: 0.421502\n",
      "epoch 36; iter: 0; batch classifier loss: 0.200835; batch adversarial loss: 0.500947\n",
      "epoch 37; iter: 0; batch classifier loss: 0.210080; batch adversarial loss: 0.574856\n",
      "epoch 38; iter: 0; batch classifier loss: 0.137741; batch adversarial loss: 0.477467\n",
      "epoch 39; iter: 0; batch classifier loss: 0.202587; batch adversarial loss: 0.520670\n",
      "epoch 40; iter: 0; batch classifier loss: 0.135645; batch adversarial loss: 0.434864\n",
      "epoch 41; iter: 0; batch classifier loss: 0.176499; batch adversarial loss: 0.492623\n",
      "epoch 42; iter: 0; batch classifier loss: 0.143891; batch adversarial loss: 0.373923\n",
      "epoch 43; iter: 0; batch classifier loss: 0.138014; batch adversarial loss: 0.445026\n",
      "epoch 44; iter: 0; batch classifier loss: 0.141937; batch adversarial loss: 0.551117\n",
      "epoch 45; iter: 0; batch classifier loss: 0.157214; batch adversarial loss: 0.477403\n",
      "epoch 46; iter: 0; batch classifier loss: 0.152686; batch adversarial loss: 0.429114\n",
      "epoch 47; iter: 0; batch classifier loss: 0.127394; batch adversarial loss: 0.396852\n",
      "epoch 48; iter: 0; batch classifier loss: 0.077239; batch adversarial loss: 0.484702\n",
      "epoch 49; iter: 0; batch classifier loss: 0.075558; batch adversarial loss: 0.501961\n",
      "epoch 50; iter: 0; batch classifier loss: 0.076416; batch adversarial loss: 0.473401\n",
      "epoch 51; iter: 0; batch classifier loss: 0.059744; batch adversarial loss: 0.504322\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071533; batch adversarial loss: 0.433913\n",
      "epoch 53; iter: 0; batch classifier loss: 0.089389; batch adversarial loss: 0.533827\n",
      "epoch 54; iter: 0; batch classifier loss: 0.057339; batch adversarial loss: 0.407614\n",
      "epoch 55; iter: 0; batch classifier loss: 0.059640; batch adversarial loss: 0.527099\n",
      "epoch 56; iter: 0; batch classifier loss: 0.051095; batch adversarial loss: 0.464068\n",
      "epoch 57; iter: 0; batch classifier loss: 0.053617; batch adversarial loss: 0.454324\n",
      "epoch 58; iter: 0; batch classifier loss: 0.085715; batch adversarial loss: 0.494775\n",
      "epoch 59; iter: 0; batch classifier loss: 0.078210; batch adversarial loss: 0.535658\n",
      "epoch 60; iter: 0; batch classifier loss: 0.046478; batch adversarial loss: 0.373870\n",
      "epoch 61; iter: 0; batch classifier loss: 0.068938; batch adversarial loss: 0.424155\n",
      "epoch 62; iter: 0; batch classifier loss: 0.071727; batch adversarial loss: 0.463446\n",
      "epoch 63; iter: 0; batch classifier loss: 0.062372; batch adversarial loss: 0.446715\n",
      "epoch 64; iter: 0; batch classifier loss: 0.041255; batch adversarial loss: 0.409369\n",
      "epoch 65; iter: 0; batch classifier loss: 0.101137; batch adversarial loss: 0.384901\n",
      "epoch 66; iter: 0; batch classifier loss: 0.095054; batch adversarial loss: 0.434493\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094298; batch adversarial loss: 0.464006\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082907; batch adversarial loss: 0.387914\n",
      "epoch 69; iter: 0; batch classifier loss: 0.070830; batch adversarial loss: 0.385831\n",
      "epoch 70; iter: 0; batch classifier loss: 0.107741; batch adversarial loss: 0.433567\n",
      "epoch 71; iter: 0; batch classifier loss: 0.084008; batch adversarial loss: 0.388529\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080189; batch adversarial loss: 0.560172\n",
      "epoch 73; iter: 0; batch classifier loss: 0.054734; batch adversarial loss: 0.487314\n",
      "epoch 74; iter: 0; batch classifier loss: 0.113064; batch adversarial loss: 0.417556\n",
      "epoch 75; iter: 0; batch classifier loss: 0.106984; batch adversarial loss: 0.449903\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072284; batch adversarial loss: 0.399620\n",
      "epoch 77; iter: 0; batch classifier loss: 0.072173; batch adversarial loss: 0.436470\n",
      "epoch 78; iter: 0; batch classifier loss: 0.101904; batch adversarial loss: 0.438331\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065997; batch adversarial loss: 0.446928\n",
      "epoch 80; iter: 0; batch classifier loss: 0.081595; batch adversarial loss: 0.395801\n",
      "epoch 81; iter: 0; batch classifier loss: 0.134232; batch adversarial loss: 0.481707\n",
      "epoch 82; iter: 0; batch classifier loss: 0.061108; batch adversarial loss: 0.484658\n",
      "epoch 83; iter: 0; batch classifier loss: 0.076131; batch adversarial loss: 0.423842\n",
      "epoch 84; iter: 0; batch classifier loss: 0.090688; batch adversarial loss: 0.404163\n",
      "epoch 85; iter: 0; batch classifier loss: 0.108116; batch adversarial loss: 0.478005\n",
      "epoch 86; iter: 0; batch classifier loss: 0.110246; batch adversarial loss: 0.281735\n",
      "epoch 87; iter: 0; batch classifier loss: 0.058963; batch adversarial loss: 0.472482\n",
      "epoch 88; iter: 0; batch classifier loss: 0.125032; batch adversarial loss: 0.473844\n",
      "epoch 89; iter: 0; batch classifier loss: 0.121078; batch adversarial loss: 0.382210\n",
      "epoch 90; iter: 0; batch classifier loss: 0.092309; batch adversarial loss: 0.398847\n",
      "epoch 91; iter: 0; batch classifier loss: 0.040470; batch adversarial loss: 0.457436\n",
      "epoch 92; iter: 0; batch classifier loss: 0.076957; batch adversarial loss: 0.407367\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061924; batch adversarial loss: 0.420605\n",
      "epoch 94; iter: 0; batch classifier loss: 0.096086; batch adversarial loss: 0.422943\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063880; batch adversarial loss: 0.454369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.071774; batch adversarial loss: 0.477066\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051207; batch adversarial loss: 0.428348\n",
      "epoch 98; iter: 0; batch classifier loss: 0.091769; batch adversarial loss: 0.488766\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064995; batch adversarial loss: 0.433139\n",
      "epoch 100; iter: 0; batch classifier loss: 0.089683; batch adversarial loss: 0.494494\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063657; batch adversarial loss: 0.530178\n",
      "epoch 102; iter: 0; batch classifier loss: 0.098524; batch adversarial loss: 0.458974\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076261; batch adversarial loss: 0.512936\n",
      "epoch 104; iter: 0; batch classifier loss: 0.075294; batch adversarial loss: 0.442803\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066801; batch adversarial loss: 0.405628\n",
      "epoch 106; iter: 0; batch classifier loss: 0.056978; batch adversarial loss: 0.412257\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049812; batch adversarial loss: 0.443123\n",
      "epoch 108; iter: 0; batch classifier loss: 0.091366; batch adversarial loss: 0.444095\n",
      "epoch 109; iter: 0; batch classifier loss: 0.073123; batch adversarial loss: 0.382162\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064492; batch adversarial loss: 0.393725\n",
      "epoch 111; iter: 0; batch classifier loss: 0.075510; batch adversarial loss: 0.429338\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031442; batch adversarial loss: 0.440045\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059600; batch adversarial loss: 0.443396\n",
      "epoch 114; iter: 0; batch classifier loss: 0.065854; batch adversarial loss: 0.412924\n",
      "epoch 115; iter: 0; batch classifier loss: 0.069346; batch adversarial loss: 0.529712\n",
      "epoch 116; iter: 0; batch classifier loss: 0.077633; batch adversarial loss: 0.412691\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051205; batch adversarial loss: 0.437991\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031529; batch adversarial loss: 0.390976\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035975; batch adversarial loss: 0.413960\n",
      "epoch 120; iter: 0; batch classifier loss: 0.112318; batch adversarial loss: 0.520107\n",
      "epoch 121; iter: 0; batch classifier loss: 0.110352; batch adversarial loss: 0.506140\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039585; batch adversarial loss: 0.494171\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039818; batch adversarial loss: 0.485777\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019392; batch adversarial loss: 0.471394\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062206; batch adversarial loss: 0.406285\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034555; batch adversarial loss: 0.417453\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028038; batch adversarial loss: 0.437986\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038018; batch adversarial loss: 0.442523\n",
      "epoch 129; iter: 0; batch classifier loss: 0.052472; batch adversarial loss: 0.416140\n",
      "epoch 130; iter: 0; batch classifier loss: 0.054685; batch adversarial loss: 0.500867\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046348; batch adversarial loss: 0.448377\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019818; batch adversarial loss: 0.540269\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046861; batch adversarial loss: 0.414973\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034137; batch adversarial loss: 0.457293\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022593; batch adversarial loss: 0.378851\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028211; batch adversarial loss: 0.414883\n",
      "epoch 137; iter: 0; batch classifier loss: 0.047814; batch adversarial loss: 0.303104\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032556; batch adversarial loss: 0.446173\n",
      "epoch 139; iter: 0; batch classifier loss: 0.051840; batch adversarial loss: 0.410320\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031090; batch adversarial loss: 0.542296\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035677; batch adversarial loss: 0.504537\n",
      "epoch 142; iter: 0; batch classifier loss: 0.051690; batch adversarial loss: 0.503799\n",
      "epoch 143; iter: 0; batch classifier loss: 0.061205; batch adversarial loss: 0.347892\n",
      "epoch 144; iter: 0; batch classifier loss: 0.047488; batch adversarial loss: 0.398046\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030873; batch adversarial loss: 0.367003\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042122; batch adversarial loss: 0.466553\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018535; batch adversarial loss: 0.527149\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032734; batch adversarial loss: 0.468663\n",
      "epoch 149; iter: 0; batch classifier loss: 0.050147; batch adversarial loss: 0.477383\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038189; batch adversarial loss: 0.481731\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019173; batch adversarial loss: 0.439797\n",
      "epoch 152; iter: 0; batch classifier loss: 0.054427; batch adversarial loss: 0.369981\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012579; batch adversarial loss: 0.489793\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046533; batch adversarial loss: 0.443567\n",
      "epoch 155; iter: 0; batch classifier loss: 0.043056; batch adversarial loss: 0.394572\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023227; batch adversarial loss: 0.484762\n",
      "epoch 157; iter: 0; batch classifier loss: 0.044271; batch adversarial loss: 0.504249\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016179; batch adversarial loss: 0.509520\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049158; batch adversarial loss: 0.406433\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033317; batch adversarial loss: 0.391302\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042384; batch adversarial loss: 0.408277\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024501; batch adversarial loss: 0.473358\n",
      "epoch 163; iter: 0; batch classifier loss: 0.061613; batch adversarial loss: 0.549757\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028453; batch adversarial loss: 0.393517\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013113; batch adversarial loss: 0.479478\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019429; batch adversarial loss: 0.454552\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030839; batch adversarial loss: 0.518192\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021957; batch adversarial loss: 0.516126\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024350; batch adversarial loss: 0.550521\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038636; batch adversarial loss: 0.322038\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027664; batch adversarial loss: 0.457904\n",
      "epoch 172; iter: 0; batch classifier loss: 0.072712; batch adversarial loss: 0.462615\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010327; batch adversarial loss: 0.530019\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030836; batch adversarial loss: 0.473123\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011015; batch adversarial loss: 0.383595\n",
      "epoch 176; iter: 0; batch classifier loss: 0.059527; batch adversarial loss: 0.460816\n",
      "epoch 177; iter: 0; batch classifier loss: 0.045669; batch adversarial loss: 0.480680\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034739; batch adversarial loss: 0.351526\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018780; batch adversarial loss: 0.474942\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020378; batch adversarial loss: 0.482309\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027083; batch adversarial loss: 0.463229\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027676; batch adversarial loss: 0.485965\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014661; batch adversarial loss: 0.570939\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016625; batch adversarial loss: 0.680644\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012251; batch adversarial loss: 0.476321\n",
      "epoch 186; iter: 0; batch classifier loss: 0.054742; batch adversarial loss: 0.456262\n",
      "epoch 187; iter: 0; batch classifier loss: 0.046561; batch adversarial loss: 0.496112\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016363; batch adversarial loss: 0.435555\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014035; batch adversarial loss: 0.362823\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018620; batch adversarial loss: 0.409772\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005263; batch adversarial loss: 0.422407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.017575; batch adversarial loss: 0.491911\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006846; batch adversarial loss: 0.392998\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021741; batch adversarial loss: 0.560899\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004933; batch adversarial loss: 0.448621\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018982; batch adversarial loss: 0.479409\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028757; batch adversarial loss: 0.428229\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014264; batch adversarial loss: 0.469767\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008327; batch adversarial loss: 0.485069\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682409; batch adversarial loss: 0.862444\n",
      "epoch 1; iter: 0; batch classifier loss: 0.508115; batch adversarial loss: 0.938112\n",
      "epoch 2; iter: 0; batch classifier loss: 0.638986; batch adversarial loss: 0.920537\n",
      "epoch 3; iter: 0; batch classifier loss: 0.828514; batch adversarial loss: 0.878646\n",
      "epoch 4; iter: 0; batch classifier loss: 0.844017; batch adversarial loss: 0.792298\n",
      "epoch 5; iter: 0; batch classifier loss: 0.866813; batch adversarial loss: 0.725216\n",
      "epoch 6; iter: 0; batch classifier loss: 0.981694; batch adversarial loss: 0.672596\n",
      "epoch 7; iter: 0; batch classifier loss: 0.895848; batch adversarial loss: 0.606833\n",
      "epoch 8; iter: 0; batch classifier loss: 0.531890; batch adversarial loss: 0.581191\n",
      "epoch 9; iter: 0; batch classifier loss: 0.388904; batch adversarial loss: 0.530320\n",
      "epoch 10; iter: 0; batch classifier loss: 0.328041; batch adversarial loss: 0.560963\n",
      "epoch 11; iter: 0; batch classifier loss: 0.381003; batch adversarial loss: 0.523539\n",
      "epoch 12; iter: 0; batch classifier loss: 0.352775; batch adversarial loss: 0.500552\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331941; batch adversarial loss: 0.520972\n",
      "epoch 14; iter: 0; batch classifier loss: 0.345429; batch adversarial loss: 0.509569\n",
      "epoch 15; iter: 0; batch classifier loss: 0.308159; batch adversarial loss: 0.536686\n",
      "epoch 16; iter: 0; batch classifier loss: 0.350554; batch adversarial loss: 0.482239\n",
      "epoch 17; iter: 0; batch classifier loss: 0.278344; batch adversarial loss: 0.523584\n",
      "epoch 18; iter: 0; batch classifier loss: 0.309295; batch adversarial loss: 0.525827\n",
      "epoch 19; iter: 0; batch classifier loss: 0.397216; batch adversarial loss: 0.484654\n",
      "epoch 20; iter: 0; batch classifier loss: 0.326188; batch adversarial loss: 0.503158\n",
      "epoch 21; iter: 0; batch classifier loss: 0.388219; batch adversarial loss: 0.402022\n",
      "epoch 22; iter: 0; batch classifier loss: 0.331975; batch adversarial loss: 0.455590\n",
      "epoch 23; iter: 0; batch classifier loss: 0.311850; batch adversarial loss: 0.501201\n",
      "epoch 24; iter: 0; batch classifier loss: 0.384757; batch adversarial loss: 0.469687\n",
      "epoch 25; iter: 0; batch classifier loss: 0.294063; batch adversarial loss: 0.455534\n",
      "epoch 26; iter: 0; batch classifier loss: 0.248947; batch adversarial loss: 0.470972\n",
      "epoch 27; iter: 0; batch classifier loss: 0.252614; batch adversarial loss: 0.449293\n",
      "epoch 28; iter: 0; batch classifier loss: 0.227516; batch adversarial loss: 0.433374\n",
      "epoch 29; iter: 0; batch classifier loss: 0.361976; batch adversarial loss: 0.494888\n",
      "epoch 30; iter: 0; batch classifier loss: 0.173029; batch adversarial loss: 0.494020\n",
      "epoch 31; iter: 0; batch classifier loss: 0.262336; batch adversarial loss: 0.472029\n",
      "epoch 32; iter: 0; batch classifier loss: 0.211353; batch adversarial loss: 0.491364\n",
      "epoch 33; iter: 0; batch classifier loss: 0.140261; batch adversarial loss: 0.465898\n",
      "epoch 34; iter: 0; batch classifier loss: 0.179996; batch adversarial loss: 0.430553\n",
      "epoch 35; iter: 0; batch classifier loss: 0.284089; batch adversarial loss: 0.494120\n",
      "epoch 36; iter: 0; batch classifier loss: 0.163414; batch adversarial loss: 0.440041\n",
      "epoch 37; iter: 0; batch classifier loss: 0.215456; batch adversarial loss: 0.359036\n",
      "epoch 38; iter: 0; batch classifier loss: 0.155228; batch adversarial loss: 0.492437\n",
      "epoch 39; iter: 0; batch classifier loss: 0.177723; batch adversarial loss: 0.517601\n",
      "epoch 40; iter: 0; batch classifier loss: 0.103441; batch adversarial loss: 0.573657\n",
      "epoch 41; iter: 0; batch classifier loss: 0.111182; batch adversarial loss: 0.446407\n",
      "epoch 42; iter: 0; batch classifier loss: 0.167353; batch adversarial loss: 0.455856\n",
      "epoch 43; iter: 0; batch classifier loss: 0.136872; batch adversarial loss: 0.397492\n",
      "epoch 44; iter: 0; batch classifier loss: 0.168405; batch adversarial loss: 0.371955\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117944; batch adversarial loss: 0.426514\n",
      "epoch 46; iter: 0; batch classifier loss: 0.108504; batch adversarial loss: 0.433707\n",
      "epoch 47; iter: 0; batch classifier loss: 0.129201; batch adversarial loss: 0.470800\n",
      "epoch 48; iter: 0; batch classifier loss: 0.108655; batch adversarial loss: 0.499827\n",
      "epoch 49; iter: 0; batch classifier loss: 0.124693; batch adversarial loss: 0.393973\n",
      "epoch 50; iter: 0; batch classifier loss: 0.101944; batch adversarial loss: 0.409743\n",
      "epoch 51; iter: 0; batch classifier loss: 0.094633; batch adversarial loss: 0.376132\n",
      "epoch 52; iter: 0; batch classifier loss: 0.095436; batch adversarial loss: 0.475748\n",
      "epoch 53; iter: 0; batch classifier loss: 0.087753; batch adversarial loss: 0.433151\n",
      "epoch 54; iter: 0; batch classifier loss: 0.120005; batch adversarial loss: 0.429922\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077710; batch adversarial loss: 0.514819\n",
      "epoch 56; iter: 0; batch classifier loss: 0.086946; batch adversarial loss: 0.487587\n",
      "epoch 57; iter: 0; batch classifier loss: 0.093470; batch adversarial loss: 0.391164\n",
      "epoch 58; iter: 0; batch classifier loss: 0.065664; batch adversarial loss: 0.351711\n",
      "epoch 59; iter: 0; batch classifier loss: 0.126953; batch adversarial loss: 0.484024\n",
      "epoch 60; iter: 0; batch classifier loss: 0.075458; batch adversarial loss: 0.438551\n",
      "epoch 61; iter: 0; batch classifier loss: 0.091705; batch adversarial loss: 0.455646\n",
      "epoch 62; iter: 0; batch classifier loss: 0.065124; batch adversarial loss: 0.424654\n",
      "epoch 63; iter: 0; batch classifier loss: 0.048764; batch adversarial loss: 0.457595\n",
      "epoch 64; iter: 0; batch classifier loss: 0.056559; batch adversarial loss: 0.544635\n",
      "epoch 65; iter: 0; batch classifier loss: 0.093549; batch adversarial loss: 0.427698\n",
      "epoch 66; iter: 0; batch classifier loss: 0.079648; batch adversarial loss: 0.472076\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079635; batch adversarial loss: 0.398096\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070374; batch adversarial loss: 0.387175\n",
      "epoch 69; iter: 0; batch classifier loss: 0.084865; batch adversarial loss: 0.461949\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079771; batch adversarial loss: 0.447094\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063974; batch adversarial loss: 0.427275\n",
      "epoch 72; iter: 0; batch classifier loss: 0.065023; batch adversarial loss: 0.422244\n",
      "epoch 73; iter: 0; batch classifier loss: 0.058936; batch adversarial loss: 0.449418\n",
      "epoch 74; iter: 0; batch classifier loss: 0.084912; batch adversarial loss: 0.476822\n",
      "epoch 75; iter: 0; batch classifier loss: 0.085128; batch adversarial loss: 0.477886\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060799; batch adversarial loss: 0.437080\n",
      "epoch 77; iter: 0; batch classifier loss: 0.052240; batch adversarial loss: 0.454139\n",
      "epoch 78; iter: 0; batch classifier loss: 0.044277; batch adversarial loss: 0.490416\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076609; batch adversarial loss: 0.433643\n",
      "epoch 80; iter: 0; batch classifier loss: 0.045469; batch adversarial loss: 0.546987\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079683; batch adversarial loss: 0.413667\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060411; batch adversarial loss: 0.423247\n",
      "epoch 83; iter: 0; batch classifier loss: 0.031306; batch adversarial loss: 0.446409\n",
      "epoch 84; iter: 0; batch classifier loss: 0.047534; batch adversarial loss: 0.478586\n",
      "epoch 85; iter: 0; batch classifier loss: 0.044465; batch adversarial loss: 0.473535\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052191; batch adversarial loss: 0.482344\n",
      "epoch 87; iter: 0; batch classifier loss: 0.025763; batch adversarial loss: 0.430999\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055207; batch adversarial loss: 0.485419\n",
      "epoch 89; iter: 0; batch classifier loss: 0.024604; batch adversarial loss: 0.467470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.032509; batch adversarial loss: 0.498895\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046372; batch adversarial loss: 0.407411\n",
      "epoch 92; iter: 0; batch classifier loss: 0.033611; batch adversarial loss: 0.584053\n",
      "epoch 93; iter: 0; batch classifier loss: 0.023891; batch adversarial loss: 0.443546\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038832; batch adversarial loss: 0.471531\n",
      "epoch 95; iter: 0; batch classifier loss: 0.055091; batch adversarial loss: 0.435551\n",
      "epoch 96; iter: 0; batch classifier loss: 0.022435; batch adversarial loss: 0.498095\n",
      "epoch 97; iter: 0; batch classifier loss: 0.036489; batch adversarial loss: 0.452970\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046964; batch adversarial loss: 0.551746\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053410; batch adversarial loss: 0.387891\n",
      "epoch 100; iter: 0; batch classifier loss: 0.024660; batch adversarial loss: 0.398134\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070007; batch adversarial loss: 0.449050\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033390; batch adversarial loss: 0.490942\n",
      "epoch 103; iter: 0; batch classifier loss: 0.071899; batch adversarial loss: 0.653859\n",
      "epoch 104; iter: 0; batch classifier loss: 0.028031; batch adversarial loss: 0.543708\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042888; batch adversarial loss: 0.423736\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054279; batch adversarial loss: 0.395870\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049897; batch adversarial loss: 0.397797\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058459; batch adversarial loss: 0.385536\n",
      "epoch 109; iter: 0; batch classifier loss: 0.023260; batch adversarial loss: 0.461243\n",
      "epoch 110; iter: 0; batch classifier loss: 0.024194; batch adversarial loss: 0.423001\n",
      "epoch 111; iter: 0; batch classifier loss: 0.024743; batch adversarial loss: 0.418171\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041504; batch adversarial loss: 0.338748\n",
      "epoch 113; iter: 0; batch classifier loss: 0.026849; batch adversarial loss: 0.370870\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040542; batch adversarial loss: 0.436753\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045449; batch adversarial loss: 0.424407\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036179; batch adversarial loss: 0.339554\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027117; batch adversarial loss: 0.371270\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045408; batch adversarial loss: 0.546003\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045425; batch adversarial loss: 0.413062\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030682; batch adversarial loss: 0.494653\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032439; batch adversarial loss: 0.476957\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043033; batch adversarial loss: 0.381985\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014807; batch adversarial loss: 0.467920\n",
      "epoch 124; iter: 0; batch classifier loss: 0.045075; batch adversarial loss: 0.437824\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043298; batch adversarial loss: 0.543489\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031455; batch adversarial loss: 0.533698\n",
      "epoch 127; iter: 0; batch classifier loss: 0.016971; batch adversarial loss: 0.337051\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044624; batch adversarial loss: 0.485267\n",
      "epoch 129; iter: 0; batch classifier loss: 0.063208; batch adversarial loss: 0.472613\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042094; batch adversarial loss: 0.460458\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027018; batch adversarial loss: 0.446212\n",
      "epoch 132; iter: 0; batch classifier loss: 0.008348; batch adversarial loss: 0.407854\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029440; batch adversarial loss: 0.520927\n",
      "epoch 134; iter: 0; batch classifier loss: 0.010237; batch adversarial loss: 0.459758\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026738; batch adversarial loss: 0.438193\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037334; batch adversarial loss: 0.496827\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030063; batch adversarial loss: 0.543654\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032261; batch adversarial loss: 0.381561\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025251; batch adversarial loss: 0.500953\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037279; batch adversarial loss: 0.447472\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023533; batch adversarial loss: 0.359999\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024148; batch adversarial loss: 0.467496\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014965; batch adversarial loss: 0.447756\n",
      "epoch 144; iter: 0; batch classifier loss: 0.053606; batch adversarial loss: 0.391457\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032989; batch adversarial loss: 0.444302\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028694; batch adversarial loss: 0.434095\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022505; batch adversarial loss: 0.523586\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014713; batch adversarial loss: 0.542250\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023457; batch adversarial loss: 0.409127\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027408; batch adversarial loss: 0.389041\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037751; batch adversarial loss: 0.501060\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028036; batch adversarial loss: 0.474916\n",
      "epoch 153; iter: 0; batch classifier loss: 0.009667; batch adversarial loss: 0.464695\n",
      "epoch 154; iter: 0; batch classifier loss: 0.006087; batch adversarial loss: 0.445597\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025708; batch adversarial loss: 0.356130\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042028; batch adversarial loss: 0.482210\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017595; batch adversarial loss: 0.417238\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016344; batch adversarial loss: 0.531996\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020266; batch adversarial loss: 0.436997\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017913; batch adversarial loss: 0.431718\n",
      "epoch 161; iter: 0; batch classifier loss: 0.059555; batch adversarial loss: 0.522541\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024016; batch adversarial loss: 0.317946\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016655; batch adversarial loss: 0.436114\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034019; batch adversarial loss: 0.390895\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023077; batch adversarial loss: 0.418105\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007560; batch adversarial loss: 0.443161\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029518; batch adversarial loss: 0.392887\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035008; batch adversarial loss: 0.474901\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012799; batch adversarial loss: 0.482336\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015840; batch adversarial loss: 0.391710\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013548; batch adversarial loss: 0.459534\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019664; batch adversarial loss: 0.499485\n",
      "epoch 173; iter: 0; batch classifier loss: 0.061157; batch adversarial loss: 0.458843\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031250; batch adversarial loss: 0.427653\n",
      "epoch 175; iter: 0; batch classifier loss: 0.042529; batch adversarial loss: 0.426568\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013317; batch adversarial loss: 0.462333\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033071; batch adversarial loss: 0.422108\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020417; batch adversarial loss: 0.479731\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015226; batch adversarial loss: 0.465811\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020005; batch adversarial loss: 0.378981\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025380; batch adversarial loss: 0.367377\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011513; batch adversarial loss: 0.453948\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011602; batch adversarial loss: 0.435313\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029812; batch adversarial loss: 0.444177\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029266; batch adversarial loss: 0.462666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.005456; batch adversarial loss: 0.422974\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011934; batch adversarial loss: 0.421870\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015723; batch adversarial loss: 0.436725\n",
      "epoch 189; iter: 0; batch classifier loss: 0.047501; batch adversarial loss: 0.369320\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019969; batch adversarial loss: 0.397542\n",
      "epoch 191; iter: 0; batch classifier loss: 0.053483; batch adversarial loss: 0.518645\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032338; batch adversarial loss: 0.441579\n",
      "epoch 193; iter: 0; batch classifier loss: 0.036821; batch adversarial loss: 0.472767\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004874; batch adversarial loss: 0.418561\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017831; batch adversarial loss: 0.410336\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015579; batch adversarial loss: 0.493583\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025244; batch adversarial loss: 0.380432\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012106; batch adversarial loss: 0.416495\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010991; batch adversarial loss: 0.504363\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674201; batch adversarial loss: 0.649866\n",
      "epoch 1; iter: 0; batch classifier loss: 0.496785; batch adversarial loss: 0.639011\n",
      "epoch 2; iter: 0; batch classifier loss: 0.474048; batch adversarial loss: 0.636677\n",
      "epoch 3; iter: 0; batch classifier loss: 0.526379; batch adversarial loss: 0.620422\n",
      "epoch 4; iter: 0; batch classifier loss: 0.488837; batch adversarial loss: 0.603510\n",
      "epoch 5; iter: 0; batch classifier loss: 0.479234; batch adversarial loss: 0.599710\n",
      "epoch 6; iter: 0; batch classifier loss: 0.427296; batch adversarial loss: 0.604089\n",
      "epoch 7; iter: 0; batch classifier loss: 0.445843; batch adversarial loss: 0.576720\n",
      "epoch 8; iter: 0; batch classifier loss: 0.484364; batch adversarial loss: 0.545340\n",
      "epoch 9; iter: 0; batch classifier loss: 0.369219; batch adversarial loss: 0.583177\n",
      "epoch 10; iter: 0; batch classifier loss: 0.370776; batch adversarial loss: 0.542595\n",
      "epoch 11; iter: 0; batch classifier loss: 0.375610; batch adversarial loss: 0.523830\n",
      "epoch 12; iter: 0; batch classifier loss: 0.329667; batch adversarial loss: 0.481733\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340995; batch adversarial loss: 0.512778\n",
      "epoch 14; iter: 0; batch classifier loss: 0.324253; batch adversarial loss: 0.521555\n",
      "epoch 15; iter: 0; batch classifier loss: 0.378952; batch adversarial loss: 0.518206\n",
      "epoch 16; iter: 0; batch classifier loss: 0.355339; batch adversarial loss: 0.437219\n",
      "epoch 17; iter: 0; batch classifier loss: 0.322791; batch adversarial loss: 0.480333\n",
      "epoch 18; iter: 0; batch classifier loss: 0.286298; batch adversarial loss: 0.461120\n",
      "epoch 19; iter: 0; batch classifier loss: 0.295548; batch adversarial loss: 0.482581\n",
      "epoch 20; iter: 0; batch classifier loss: 0.286917; batch adversarial loss: 0.412453\n",
      "epoch 21; iter: 0; batch classifier loss: 0.241612; batch adversarial loss: 0.515351\n",
      "epoch 22; iter: 0; batch classifier loss: 0.254325; batch adversarial loss: 0.526931\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285039; batch adversarial loss: 0.503876\n",
      "epoch 24; iter: 0; batch classifier loss: 0.231749; batch adversarial loss: 0.512051\n",
      "epoch 25; iter: 0; batch classifier loss: 0.218724; batch adversarial loss: 0.496145\n",
      "epoch 26; iter: 0; batch classifier loss: 0.203214; batch adversarial loss: 0.499223\n",
      "epoch 27; iter: 0; batch classifier loss: 0.206615; batch adversarial loss: 0.500651\n",
      "epoch 28; iter: 0; batch classifier loss: 0.206684; batch adversarial loss: 0.486395\n",
      "epoch 29; iter: 0; batch classifier loss: 0.265149; batch adversarial loss: 0.426031\n",
      "epoch 30; iter: 0; batch classifier loss: 0.217463; batch adversarial loss: 0.509072\n",
      "epoch 31; iter: 0; batch classifier loss: 0.209723; batch adversarial loss: 0.423239\n",
      "epoch 32; iter: 0; batch classifier loss: 0.188564; batch adversarial loss: 0.542323\n",
      "epoch 33; iter: 0; batch classifier loss: 0.199980; batch adversarial loss: 0.408940\n",
      "epoch 34; iter: 0; batch classifier loss: 0.193604; batch adversarial loss: 0.415028\n",
      "epoch 35; iter: 0; batch classifier loss: 0.217677; batch adversarial loss: 0.387682\n",
      "epoch 36; iter: 0; batch classifier loss: 0.158221; batch adversarial loss: 0.467789\n",
      "epoch 37; iter: 0; batch classifier loss: 0.173363; batch adversarial loss: 0.508634\n",
      "epoch 38; iter: 0; batch classifier loss: 0.179646; batch adversarial loss: 0.422659\n",
      "epoch 39; iter: 0; batch classifier loss: 0.155056; batch adversarial loss: 0.421235\n",
      "epoch 40; iter: 0; batch classifier loss: 0.221164; batch adversarial loss: 0.454118\n",
      "epoch 41; iter: 0; batch classifier loss: 0.211843; batch adversarial loss: 0.500908\n",
      "epoch 42; iter: 0; batch classifier loss: 0.231558; batch adversarial loss: 0.463658\n",
      "epoch 43; iter: 0; batch classifier loss: 0.179916; batch adversarial loss: 0.388083\n",
      "epoch 44; iter: 0; batch classifier loss: 0.148107; batch adversarial loss: 0.444075\n",
      "epoch 45; iter: 0; batch classifier loss: 0.151680; batch adversarial loss: 0.499034\n",
      "epoch 46; iter: 0; batch classifier loss: 0.142709; batch adversarial loss: 0.530667\n",
      "epoch 47; iter: 0; batch classifier loss: 0.125341; batch adversarial loss: 0.541654\n",
      "epoch 48; iter: 0; batch classifier loss: 0.227890; batch adversarial loss: 0.510240\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114388; batch adversarial loss: 0.511740\n",
      "epoch 50; iter: 0; batch classifier loss: 0.178668; batch adversarial loss: 0.384935\n",
      "epoch 51; iter: 0; batch classifier loss: 0.184678; batch adversarial loss: 0.397452\n",
      "epoch 52; iter: 0; batch classifier loss: 0.088582; batch adversarial loss: 0.515523\n",
      "epoch 53; iter: 0; batch classifier loss: 0.176594; batch adversarial loss: 0.504104\n",
      "epoch 54; iter: 0; batch classifier loss: 0.191898; batch adversarial loss: 0.531111\n",
      "epoch 55; iter: 0; batch classifier loss: 0.163397; batch adversarial loss: 0.453983\n",
      "epoch 56; iter: 0; batch classifier loss: 0.188604; batch adversarial loss: 0.459229\n",
      "epoch 57; iter: 0; batch classifier loss: 0.122210; batch adversarial loss: 0.393892\n",
      "epoch 58; iter: 0; batch classifier loss: 0.141850; batch adversarial loss: 0.399559\n",
      "epoch 59; iter: 0; batch classifier loss: 0.144254; batch adversarial loss: 0.468364\n",
      "epoch 60; iter: 0; batch classifier loss: 0.113345; batch adversarial loss: 0.443552\n",
      "epoch 61; iter: 0; batch classifier loss: 0.206780; batch adversarial loss: 0.447871\n",
      "epoch 62; iter: 0; batch classifier loss: 0.141570; batch adversarial loss: 0.434444\n",
      "epoch 63; iter: 0; batch classifier loss: 0.159372; batch adversarial loss: 0.469642\n",
      "epoch 64; iter: 0; batch classifier loss: 0.129450; batch adversarial loss: 0.362138\n",
      "epoch 65; iter: 0; batch classifier loss: 0.135265; batch adversarial loss: 0.436126\n",
      "epoch 66; iter: 0; batch classifier loss: 0.141370; batch adversarial loss: 0.523187\n",
      "epoch 67; iter: 0; batch classifier loss: 0.148432; batch adversarial loss: 0.473194\n",
      "epoch 68; iter: 0; batch classifier loss: 0.130502; batch adversarial loss: 0.405953\n",
      "epoch 69; iter: 0; batch classifier loss: 0.130674; batch adversarial loss: 0.346230\n",
      "epoch 70; iter: 0; batch classifier loss: 0.130928; batch adversarial loss: 0.521952\n",
      "epoch 71; iter: 0; batch classifier loss: 0.183787; batch adversarial loss: 0.482727\n",
      "epoch 72; iter: 0; batch classifier loss: 0.134225; batch adversarial loss: 0.447852\n",
      "epoch 73; iter: 0; batch classifier loss: 0.135221; batch adversarial loss: 0.461876\n",
      "epoch 74; iter: 0; batch classifier loss: 0.122638; batch adversarial loss: 0.432525\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071116; batch adversarial loss: 0.435587\n",
      "epoch 76; iter: 0; batch classifier loss: 0.096199; batch adversarial loss: 0.430841\n",
      "epoch 77; iter: 0; batch classifier loss: 0.106700; batch adversarial loss: 0.418576\n",
      "epoch 78; iter: 0; batch classifier loss: 0.163319; batch adversarial loss: 0.443325\n",
      "epoch 79; iter: 0; batch classifier loss: 0.100094; batch adversarial loss: 0.403406\n",
      "epoch 80; iter: 0; batch classifier loss: 0.116297; batch adversarial loss: 0.429678\n",
      "epoch 81; iter: 0; batch classifier loss: 0.090436; batch adversarial loss: 0.533925\n",
      "epoch 82; iter: 0; batch classifier loss: 0.102253; batch adversarial loss: 0.447559\n",
      "epoch 83; iter: 0; batch classifier loss: 0.082263; batch adversarial loss: 0.446478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.117839; batch adversarial loss: 0.487892\n",
      "epoch 85; iter: 0; batch classifier loss: 0.081307; batch adversarial loss: 0.427915\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089755; batch adversarial loss: 0.485357\n",
      "epoch 87; iter: 0; batch classifier loss: 0.065960; batch adversarial loss: 0.443242\n",
      "epoch 88; iter: 0; batch classifier loss: 0.084641; batch adversarial loss: 0.442834\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056669; batch adversarial loss: 0.483425\n",
      "epoch 90; iter: 0; batch classifier loss: 0.055247; batch adversarial loss: 0.535223\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060708; batch adversarial loss: 0.517331\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064021; batch adversarial loss: 0.377312\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071362; batch adversarial loss: 0.458445\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056078; batch adversarial loss: 0.372963\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077370; batch adversarial loss: 0.444954\n",
      "epoch 96; iter: 0; batch classifier loss: 0.084693; batch adversarial loss: 0.503634\n",
      "epoch 97; iter: 0; batch classifier loss: 0.104063; batch adversarial loss: 0.416136\n",
      "epoch 98; iter: 0; batch classifier loss: 0.066288; batch adversarial loss: 0.400168\n",
      "epoch 99; iter: 0; batch classifier loss: 0.051425; batch adversarial loss: 0.485478\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066957; batch adversarial loss: 0.419019\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050039; batch adversarial loss: 0.586156\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057065; batch adversarial loss: 0.384779\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046462; batch adversarial loss: 0.478704\n",
      "epoch 104; iter: 0; batch classifier loss: 0.078336; batch adversarial loss: 0.407047\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034012; batch adversarial loss: 0.520291\n",
      "epoch 106; iter: 0; batch classifier loss: 0.028472; batch adversarial loss: 0.420290\n",
      "epoch 107; iter: 0; batch classifier loss: 0.060862; batch adversarial loss: 0.434046\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053332; batch adversarial loss: 0.407116\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061855; batch adversarial loss: 0.444535\n",
      "epoch 110; iter: 0; batch classifier loss: 0.055242; batch adversarial loss: 0.430772\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035185; batch adversarial loss: 0.449871\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045154; batch adversarial loss: 0.314192\n",
      "epoch 113; iter: 0; batch classifier loss: 0.036288; batch adversarial loss: 0.427891\n",
      "epoch 114; iter: 0; batch classifier loss: 0.070336; batch adversarial loss: 0.401079\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038994; batch adversarial loss: 0.509066\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021581; batch adversarial loss: 0.555444\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028611; batch adversarial loss: 0.506883\n",
      "epoch 118; iter: 0; batch classifier loss: 0.019819; batch adversarial loss: 0.384752\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031684; batch adversarial loss: 0.434355\n",
      "epoch 120; iter: 0; batch classifier loss: 0.076653; batch adversarial loss: 0.470443\n",
      "epoch 121; iter: 0; batch classifier loss: 0.019635; batch adversarial loss: 0.463626\n",
      "epoch 122; iter: 0; batch classifier loss: 0.021142; batch adversarial loss: 0.455681\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033028; batch adversarial loss: 0.400210\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030712; batch adversarial loss: 0.507582\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025766; batch adversarial loss: 0.598675\n",
      "epoch 126; iter: 0; batch classifier loss: 0.018949; batch adversarial loss: 0.462946\n",
      "epoch 127; iter: 0; batch classifier loss: 0.038661; batch adversarial loss: 0.391016\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031995; batch adversarial loss: 0.426617\n",
      "epoch 129; iter: 0; batch classifier loss: 0.052255; batch adversarial loss: 0.376109\n",
      "epoch 130; iter: 0; batch classifier loss: 0.058772; batch adversarial loss: 0.477124\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029831; batch adversarial loss: 0.544257\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030168; batch adversarial loss: 0.385695\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040575; batch adversarial loss: 0.518900\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029099; batch adversarial loss: 0.380886\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018215; batch adversarial loss: 0.417773\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042093; batch adversarial loss: 0.483191\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029874; batch adversarial loss: 0.416529\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028400; batch adversarial loss: 0.552556\n",
      "epoch 139; iter: 0; batch classifier loss: 0.073177; batch adversarial loss: 0.378505\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022044; batch adversarial loss: 0.479795\n",
      "epoch 141; iter: 0; batch classifier loss: 0.012724; batch adversarial loss: 0.488358\n",
      "epoch 142; iter: 0; batch classifier loss: 0.015193; batch adversarial loss: 0.474866\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035195; batch adversarial loss: 0.417064\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048875; batch adversarial loss: 0.428993\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041507; batch adversarial loss: 0.438627\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038947; batch adversarial loss: 0.418121\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020208; batch adversarial loss: 0.371792\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021733; batch adversarial loss: 0.453698\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021663; batch adversarial loss: 0.430184\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012925; batch adversarial loss: 0.442773\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033496; batch adversarial loss: 0.343465\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027175; batch adversarial loss: 0.557442\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015878; batch adversarial loss: 0.371550\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035952; batch adversarial loss: 0.508990\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020415; batch adversarial loss: 0.528667\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029003; batch adversarial loss: 0.414052\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020175; batch adversarial loss: 0.513867\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009364; batch adversarial loss: 0.460186\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028789; batch adversarial loss: 0.398321\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033203; batch adversarial loss: 0.552812\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016436; batch adversarial loss: 0.457466\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014534; batch adversarial loss: 0.470423\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019927; batch adversarial loss: 0.520525\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018094; batch adversarial loss: 0.417647\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009586; batch adversarial loss: 0.409074\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013914; batch adversarial loss: 0.384988\n",
      "epoch 167; iter: 0; batch classifier loss: 0.005957; batch adversarial loss: 0.471083\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024208; batch adversarial loss: 0.456639\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010981; batch adversarial loss: 0.362962\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017345; batch adversarial loss: 0.497344\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010317; batch adversarial loss: 0.438865\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027495; batch adversarial loss: 0.432670\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024813; batch adversarial loss: 0.489869\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030788; batch adversarial loss: 0.440417\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009018; batch adversarial loss: 0.421592\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011884; batch adversarial loss: 0.469023\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019650; batch adversarial loss: 0.501549\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010426; batch adversarial loss: 0.386363\n",
      "epoch 179; iter: 0; batch classifier loss: 0.046894; batch adversarial loss: 0.395786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.012648; batch adversarial loss: 0.437334\n",
      "epoch 181; iter: 0; batch classifier loss: 0.046146; batch adversarial loss: 0.495267\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023000; batch adversarial loss: 0.545205\n",
      "epoch 183; iter: 0; batch classifier loss: 0.060546; batch adversarial loss: 0.503214\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018320; batch adversarial loss: 0.488659\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020207; batch adversarial loss: 0.471564\n",
      "epoch 186; iter: 0; batch classifier loss: 0.003085; batch adversarial loss: 0.366158\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015168; batch adversarial loss: 0.392507\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015492; batch adversarial loss: 0.390334\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018583; batch adversarial loss: 0.306057\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010749; batch adversarial loss: 0.481758\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008448; batch adversarial loss: 0.302158\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019429; batch adversarial loss: 0.403342\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008000; batch adversarial loss: 0.493347\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005083; batch adversarial loss: 0.321421\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010848; batch adversarial loss: 0.341984\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007915; batch adversarial loss: 0.421141\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016965; batch adversarial loss: 0.410017\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010449; batch adversarial loss: 0.472222\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007577; batch adversarial loss: 0.405769\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676149; batch adversarial loss: 0.564797\n",
      "epoch 1; iter: 0; batch classifier loss: 0.480059; batch adversarial loss: 0.617674\n",
      "epoch 2; iter: 0; batch classifier loss: 0.401024; batch adversarial loss: 0.636089\n",
      "epoch 3; iter: 0; batch classifier loss: 0.383324; batch adversarial loss: 0.629233\n",
      "epoch 4; iter: 0; batch classifier loss: 0.390362; batch adversarial loss: 0.543414\n",
      "epoch 5; iter: 0; batch classifier loss: 0.490888; batch adversarial loss: 0.567834\n",
      "epoch 6; iter: 0; batch classifier loss: 0.516214; batch adversarial loss: 0.570399\n",
      "epoch 7; iter: 0; batch classifier loss: 0.541391; batch adversarial loss: 0.568428\n",
      "epoch 8; iter: 0; batch classifier loss: 0.690040; batch adversarial loss: 0.569791\n",
      "epoch 9; iter: 0; batch classifier loss: 0.453703; batch adversarial loss: 0.483076\n",
      "epoch 10; iter: 0; batch classifier loss: 0.419131; batch adversarial loss: 0.498312\n",
      "epoch 11; iter: 0; batch classifier loss: 0.362251; batch adversarial loss: 0.540635\n",
      "epoch 12; iter: 0; batch classifier loss: 0.303217; batch adversarial loss: 0.491847\n",
      "epoch 13; iter: 0; batch classifier loss: 0.382840; batch adversarial loss: 0.510862\n",
      "epoch 14; iter: 0; batch classifier loss: 0.340042; batch adversarial loss: 0.428315\n",
      "epoch 15; iter: 0; batch classifier loss: 0.264944; batch adversarial loss: 0.440175\n",
      "epoch 16; iter: 0; batch classifier loss: 0.285311; batch adversarial loss: 0.488357\n",
      "epoch 17; iter: 0; batch classifier loss: 0.281541; batch adversarial loss: 0.466970\n",
      "epoch 18; iter: 0; batch classifier loss: 0.242797; batch adversarial loss: 0.515257\n",
      "epoch 19; iter: 0; batch classifier loss: 0.295142; batch adversarial loss: 0.473301\n",
      "epoch 20; iter: 0; batch classifier loss: 0.212432; batch adversarial loss: 0.449801\n",
      "epoch 21; iter: 0; batch classifier loss: 0.203906; batch adversarial loss: 0.520560\n",
      "epoch 22; iter: 0; batch classifier loss: 0.182720; batch adversarial loss: 0.489679\n",
      "epoch 23; iter: 0; batch classifier loss: 0.159274; batch adversarial loss: 0.483944\n",
      "epoch 24; iter: 0; batch classifier loss: 0.255684; batch adversarial loss: 0.417890\n",
      "epoch 25; iter: 0; batch classifier loss: 0.185780; batch adversarial loss: 0.442741\n",
      "epoch 26; iter: 0; batch classifier loss: 0.199072; batch adversarial loss: 0.451238\n",
      "epoch 27; iter: 0; batch classifier loss: 0.183357; batch adversarial loss: 0.416241\n",
      "epoch 28; iter: 0; batch classifier loss: 0.209428; batch adversarial loss: 0.499923\n",
      "epoch 29; iter: 0; batch classifier loss: 0.164124; batch adversarial loss: 0.411056\n",
      "epoch 30; iter: 0; batch classifier loss: 0.198805; batch adversarial loss: 0.490726\n",
      "epoch 31; iter: 0; batch classifier loss: 0.174489; batch adversarial loss: 0.500016\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126283; batch adversarial loss: 0.441235\n",
      "epoch 33; iter: 0; batch classifier loss: 0.168524; batch adversarial loss: 0.451812\n",
      "epoch 34; iter: 0; batch classifier loss: 0.244804; batch adversarial loss: 0.378374\n",
      "epoch 35; iter: 0; batch classifier loss: 0.164329; batch adversarial loss: 0.471476\n",
      "epoch 36; iter: 0; batch classifier loss: 0.193401; batch adversarial loss: 0.539990\n",
      "epoch 37; iter: 0; batch classifier loss: 0.174310; batch adversarial loss: 0.469016\n",
      "epoch 38; iter: 0; batch classifier loss: 0.191854; batch adversarial loss: 0.436216\n",
      "epoch 39; iter: 0; batch classifier loss: 0.183877; batch adversarial loss: 0.383321\n",
      "epoch 40; iter: 0; batch classifier loss: 0.134402; batch adversarial loss: 0.385587\n",
      "epoch 41; iter: 0; batch classifier loss: 0.148970; batch adversarial loss: 0.532661\n",
      "epoch 42; iter: 0; batch classifier loss: 0.148339; batch adversarial loss: 0.482345\n",
      "epoch 43; iter: 0; batch classifier loss: 0.163625; batch adversarial loss: 0.421326\n",
      "epoch 44; iter: 0; batch classifier loss: 0.139761; batch adversarial loss: 0.438005\n",
      "epoch 45; iter: 0; batch classifier loss: 0.150385; batch adversarial loss: 0.353125\n",
      "epoch 46; iter: 0; batch classifier loss: 0.164439; batch adversarial loss: 0.424991\n",
      "epoch 47; iter: 0; batch classifier loss: 0.140898; batch adversarial loss: 0.393309\n",
      "epoch 48; iter: 0; batch classifier loss: 0.174448; batch adversarial loss: 0.540382\n",
      "epoch 49; iter: 0; batch classifier loss: 0.135067; batch adversarial loss: 0.460817\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098880; batch adversarial loss: 0.463556\n",
      "epoch 51; iter: 0; batch classifier loss: 0.140594; batch adversarial loss: 0.428445\n",
      "epoch 52; iter: 0; batch classifier loss: 0.123075; batch adversarial loss: 0.483411\n",
      "epoch 53; iter: 0; batch classifier loss: 0.166924; batch adversarial loss: 0.454683\n",
      "epoch 54; iter: 0; batch classifier loss: 0.080269; batch adversarial loss: 0.496356\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117164; batch adversarial loss: 0.391735\n",
      "epoch 56; iter: 0; batch classifier loss: 0.123886; batch adversarial loss: 0.530514\n",
      "epoch 57; iter: 0; batch classifier loss: 0.106361; batch adversarial loss: 0.328321\n",
      "epoch 58; iter: 0; batch classifier loss: 0.117567; batch adversarial loss: 0.475145\n",
      "epoch 59; iter: 0; batch classifier loss: 0.101283; batch adversarial loss: 0.471188\n",
      "epoch 60; iter: 0; batch classifier loss: 0.094866; batch adversarial loss: 0.377662\n",
      "epoch 61; iter: 0; batch classifier loss: 0.105798; batch adversarial loss: 0.393300\n",
      "epoch 62; iter: 0; batch classifier loss: 0.145072; batch adversarial loss: 0.370574\n",
      "epoch 63; iter: 0; batch classifier loss: 0.122394; batch adversarial loss: 0.464213\n",
      "epoch 64; iter: 0; batch classifier loss: 0.055609; batch adversarial loss: 0.485427\n",
      "epoch 65; iter: 0; batch classifier loss: 0.190261; batch adversarial loss: 0.394888\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085978; batch adversarial loss: 0.478966\n",
      "epoch 67; iter: 0; batch classifier loss: 0.177701; batch adversarial loss: 0.381841\n",
      "epoch 68; iter: 0; batch classifier loss: 0.156355; batch adversarial loss: 0.381356\n",
      "epoch 69; iter: 0; batch classifier loss: 0.107481; batch adversarial loss: 0.507836\n",
      "epoch 70; iter: 0; batch classifier loss: 0.149884; batch adversarial loss: 0.400407\n",
      "epoch 71; iter: 0; batch classifier loss: 0.094923; batch adversarial loss: 0.492412\n",
      "epoch 72; iter: 0; batch classifier loss: 0.119868; batch adversarial loss: 0.320210\n",
      "epoch 73; iter: 0; batch classifier loss: 0.092604; batch adversarial loss: 0.519129\n",
      "epoch 74; iter: 0; batch classifier loss: 0.084032; batch adversarial loss: 0.423706\n",
      "epoch 75; iter: 0; batch classifier loss: 0.113507; batch adversarial loss: 0.354602\n",
      "epoch 76; iter: 0; batch classifier loss: 0.118377; batch adversarial loss: 0.492797\n",
      "epoch 77; iter: 0; batch classifier loss: 0.070680; batch adversarial loss: 0.456775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.068619; batch adversarial loss: 0.458491\n",
      "epoch 79; iter: 0; batch classifier loss: 0.051769; batch adversarial loss: 0.552351\n",
      "epoch 80; iter: 0; batch classifier loss: 0.099195; batch adversarial loss: 0.501157\n",
      "epoch 81; iter: 0; batch classifier loss: 0.132410; batch adversarial loss: 0.404816\n",
      "epoch 82; iter: 0; batch classifier loss: 0.111636; batch adversarial loss: 0.474239\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078373; batch adversarial loss: 0.507890\n",
      "epoch 84; iter: 0; batch classifier loss: 0.131532; batch adversarial loss: 0.399148\n",
      "epoch 85; iter: 0; batch classifier loss: 0.081710; batch adversarial loss: 0.378843\n",
      "epoch 86; iter: 0; batch classifier loss: 0.112733; batch adversarial loss: 0.383428\n",
      "epoch 87; iter: 0; batch classifier loss: 0.106559; batch adversarial loss: 0.441245\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063435; batch adversarial loss: 0.378857\n",
      "epoch 89; iter: 0; batch classifier loss: 0.072013; batch adversarial loss: 0.392086\n",
      "epoch 90; iter: 0; batch classifier loss: 0.080407; batch adversarial loss: 0.441339\n",
      "epoch 91; iter: 0; batch classifier loss: 0.089583; batch adversarial loss: 0.428323\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070557; batch adversarial loss: 0.411557\n",
      "epoch 93; iter: 0; batch classifier loss: 0.084149; batch adversarial loss: 0.574116\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058479; batch adversarial loss: 0.493848\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073500; batch adversarial loss: 0.514452\n",
      "epoch 96; iter: 0; batch classifier loss: 0.105276; batch adversarial loss: 0.455311\n",
      "epoch 97; iter: 0; batch classifier loss: 0.098832; batch adversarial loss: 0.508662\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047291; batch adversarial loss: 0.418838\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042066; batch adversarial loss: 0.478572\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056701; batch adversarial loss: 0.458950\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058095; batch adversarial loss: 0.391906\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053541; batch adversarial loss: 0.497217\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066948; batch adversarial loss: 0.474438\n",
      "epoch 104; iter: 0; batch classifier loss: 0.096238; batch adversarial loss: 0.461344\n",
      "epoch 105; iter: 0; batch classifier loss: 0.070065; batch adversarial loss: 0.318482\n",
      "epoch 106; iter: 0; batch classifier loss: 0.081767; batch adversarial loss: 0.412576\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045917; batch adversarial loss: 0.473212\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056561; batch adversarial loss: 0.566056\n",
      "epoch 109; iter: 0; batch classifier loss: 0.024280; batch adversarial loss: 0.440111\n",
      "epoch 110; iter: 0; batch classifier loss: 0.055448; batch adversarial loss: 0.358587\n",
      "epoch 111; iter: 0; batch classifier loss: 0.080145; batch adversarial loss: 0.382211\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047302; batch adversarial loss: 0.502092\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069907; batch adversarial loss: 0.439345\n",
      "epoch 114; iter: 0; batch classifier loss: 0.086960; batch adversarial loss: 0.403541\n",
      "epoch 115; iter: 0; batch classifier loss: 0.090367; batch adversarial loss: 0.411142\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045632; batch adversarial loss: 0.393456\n",
      "epoch 117; iter: 0; batch classifier loss: 0.087131; batch adversarial loss: 0.486757\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052585; batch adversarial loss: 0.354283\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050344; batch adversarial loss: 0.401857\n",
      "epoch 120; iter: 0; batch classifier loss: 0.056838; batch adversarial loss: 0.534030\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044566; batch adversarial loss: 0.441866\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039690; batch adversarial loss: 0.410662\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051522; batch adversarial loss: 0.394034\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048957; batch adversarial loss: 0.403989\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030215; batch adversarial loss: 0.432258\n",
      "epoch 126; iter: 0; batch classifier loss: 0.054528; batch adversarial loss: 0.333057\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043763; batch adversarial loss: 0.525462\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017959; batch adversarial loss: 0.354062\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040108; batch adversarial loss: 0.391767\n",
      "epoch 130; iter: 0; batch classifier loss: 0.071214; batch adversarial loss: 0.429971\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040621; batch adversarial loss: 0.411588\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037046; batch adversarial loss: 0.461479\n",
      "epoch 133; iter: 0; batch classifier loss: 0.064273; batch adversarial loss: 0.438754\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019591; batch adversarial loss: 0.448595\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047775; batch adversarial loss: 0.472403\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017663; batch adversarial loss: 0.459282\n",
      "epoch 137; iter: 0; batch classifier loss: 0.053711; batch adversarial loss: 0.425629\n",
      "epoch 138; iter: 0; batch classifier loss: 0.012953; batch adversarial loss: 0.438944\n",
      "epoch 139; iter: 0; batch classifier loss: 0.054880; batch adversarial loss: 0.426932\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019736; batch adversarial loss: 0.459020\n",
      "epoch 141; iter: 0; batch classifier loss: 0.041712; batch adversarial loss: 0.507415\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044823; batch adversarial loss: 0.516192\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043300; batch adversarial loss: 0.434481\n",
      "epoch 144; iter: 0; batch classifier loss: 0.047491; batch adversarial loss: 0.392847\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032126; batch adversarial loss: 0.510839\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048771; batch adversarial loss: 0.505312\n",
      "epoch 147; iter: 0; batch classifier loss: 0.012456; batch adversarial loss: 0.451235\n",
      "epoch 148; iter: 0; batch classifier loss: 0.058496; batch adversarial loss: 0.367258\n",
      "epoch 149; iter: 0; batch classifier loss: 0.007730; batch adversarial loss: 0.436679\n",
      "epoch 150; iter: 0; batch classifier loss: 0.048247; batch adversarial loss: 0.418015\n",
      "epoch 151; iter: 0; batch classifier loss: 0.052886; batch adversarial loss: 0.412836\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025057; batch adversarial loss: 0.417958\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015515; batch adversarial loss: 0.369814\n",
      "epoch 154; iter: 0; batch classifier loss: 0.048359; batch adversarial loss: 0.446158\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024225; batch adversarial loss: 0.463018\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026987; batch adversarial loss: 0.499781\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029480; batch adversarial loss: 0.410463\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036076; batch adversarial loss: 0.458583\n",
      "epoch 159; iter: 0; batch classifier loss: 0.061507; batch adversarial loss: 0.515172\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030205; batch adversarial loss: 0.466148\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022958; batch adversarial loss: 0.477948\n",
      "epoch 162; iter: 0; batch classifier loss: 0.045714; batch adversarial loss: 0.534418\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019466; batch adversarial loss: 0.571392\n",
      "epoch 164; iter: 0; batch classifier loss: 0.005663; batch adversarial loss: 0.393407\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020628; batch adversarial loss: 0.350302\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040528; batch adversarial loss: 0.361410\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024997; batch adversarial loss: 0.412826\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005371; batch adversarial loss: 0.450296\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017236; batch adversarial loss: 0.484355\n",
      "epoch 170; iter: 0; batch classifier loss: 0.007928; batch adversarial loss: 0.533107\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023545; batch adversarial loss: 0.422868\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013233; batch adversarial loss: 0.484402\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020827; batch adversarial loss: 0.393440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.024537; batch adversarial loss: 0.476171\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028459; batch adversarial loss: 0.513164\n",
      "epoch 176; iter: 0; batch classifier loss: 0.038780; batch adversarial loss: 0.395965\n",
      "epoch 177; iter: 0; batch classifier loss: 0.063262; batch adversarial loss: 0.416887\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011526; batch adversarial loss: 0.364644\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020026; batch adversarial loss: 0.474401\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016370; batch adversarial loss: 0.370179\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009436; batch adversarial loss: 0.360348\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009993; batch adversarial loss: 0.494051\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029503; batch adversarial loss: 0.433649\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026553; batch adversarial loss: 0.494258\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042785; batch adversarial loss: 0.421526\n",
      "epoch 186; iter: 0; batch classifier loss: 0.052993; batch adversarial loss: 0.399582\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014038; batch adversarial loss: 0.432301\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014179; batch adversarial loss: 0.401307\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007794; batch adversarial loss: 0.358817\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028997; batch adversarial loss: 0.340743\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021208; batch adversarial loss: 0.467867\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011108; batch adversarial loss: 0.344526\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032899; batch adversarial loss: 0.506308\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010970; batch adversarial loss: 0.515705\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006634; batch adversarial loss: 0.588730\n",
      "epoch 196; iter: 0; batch classifier loss: 0.041912; batch adversarial loss: 0.392076\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021728; batch adversarial loss: 0.430969\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025182; batch adversarial loss: 0.411454\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024108; batch adversarial loss: 0.456169\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680874; batch adversarial loss: 0.840672\n",
      "epoch 1; iter: 0; batch classifier loss: 0.498191; batch adversarial loss: 0.862939\n",
      "epoch 2; iter: 0; batch classifier loss: 0.376183; batch adversarial loss: 0.810476\n",
      "epoch 3; iter: 0; batch classifier loss: 0.442235; batch adversarial loss: 0.764822\n",
      "epoch 4; iter: 0; batch classifier loss: 0.396362; batch adversarial loss: 0.685906\n",
      "epoch 5; iter: 0; batch classifier loss: 0.318918; batch adversarial loss: 0.659212\n",
      "epoch 6; iter: 0; batch classifier loss: 0.307062; batch adversarial loss: 0.619935\n",
      "epoch 7; iter: 0; batch classifier loss: 0.335020; batch adversarial loss: 0.616041\n",
      "epoch 8; iter: 0; batch classifier loss: 0.379305; batch adversarial loss: 0.576096\n",
      "epoch 9; iter: 0; batch classifier loss: 0.260458; batch adversarial loss: 0.563787\n",
      "epoch 10; iter: 0; batch classifier loss: 0.314382; batch adversarial loss: 0.542591\n",
      "epoch 11; iter: 0; batch classifier loss: 0.276674; batch adversarial loss: 0.593109\n",
      "epoch 12; iter: 0; batch classifier loss: 0.260719; batch adversarial loss: 0.579617\n",
      "epoch 13; iter: 0; batch classifier loss: 0.251010; batch adversarial loss: 0.535111\n",
      "epoch 14; iter: 0; batch classifier loss: 0.221654; batch adversarial loss: 0.508795\n",
      "epoch 15; iter: 0; batch classifier loss: 0.161880; batch adversarial loss: 0.528867\n",
      "epoch 16; iter: 0; batch classifier loss: 0.270014; batch adversarial loss: 0.391080\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217860; batch adversarial loss: 0.470515\n",
      "epoch 18; iter: 0; batch classifier loss: 0.253546; batch adversarial loss: 0.528554\n",
      "epoch 19; iter: 0; batch classifier loss: 0.203585; batch adversarial loss: 0.512421\n",
      "epoch 20; iter: 0; batch classifier loss: 0.209107; batch adversarial loss: 0.433241\n",
      "epoch 21; iter: 0; batch classifier loss: 0.217867; batch adversarial loss: 0.412160\n",
      "epoch 22; iter: 0; batch classifier loss: 0.120908; batch adversarial loss: 0.509001\n",
      "epoch 23; iter: 0; batch classifier loss: 0.140433; batch adversarial loss: 0.436285\n",
      "epoch 24; iter: 0; batch classifier loss: 0.159916; batch adversarial loss: 0.372910\n",
      "epoch 25; iter: 0; batch classifier loss: 0.161049; batch adversarial loss: 0.479594\n",
      "epoch 26; iter: 0; batch classifier loss: 0.140546; batch adversarial loss: 0.430067\n",
      "epoch 27; iter: 0; batch classifier loss: 0.123631; batch adversarial loss: 0.405172\n",
      "epoch 28; iter: 0; batch classifier loss: 0.104168; batch adversarial loss: 0.491077\n",
      "epoch 29; iter: 0; batch classifier loss: 0.209156; batch adversarial loss: 0.475545\n",
      "epoch 30; iter: 0; batch classifier loss: 0.181715; batch adversarial loss: 0.553681\n",
      "epoch 31; iter: 0; batch classifier loss: 0.136837; batch adversarial loss: 0.525995\n",
      "epoch 32; iter: 0; batch classifier loss: 0.122717; batch adversarial loss: 0.536946\n",
      "epoch 33; iter: 0; batch classifier loss: 0.104725; batch adversarial loss: 0.435933\n",
      "epoch 34; iter: 0; batch classifier loss: 0.133925; batch adversarial loss: 0.433586\n",
      "epoch 35; iter: 0; batch classifier loss: 0.170953; batch adversarial loss: 0.466826\n",
      "epoch 36; iter: 0; batch classifier loss: 0.083580; batch adversarial loss: 0.462220\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110665; batch adversarial loss: 0.399393\n",
      "epoch 38; iter: 0; batch classifier loss: 0.128166; batch adversarial loss: 0.379879\n",
      "epoch 39; iter: 0; batch classifier loss: 0.119243; batch adversarial loss: 0.391084\n",
      "epoch 40; iter: 0; batch classifier loss: 0.125084; batch adversarial loss: 0.361298\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125240; batch adversarial loss: 0.516841\n",
      "epoch 42; iter: 0; batch classifier loss: 0.094202; batch adversarial loss: 0.495727\n",
      "epoch 43; iter: 0; batch classifier loss: 0.153181; batch adversarial loss: 0.442312\n",
      "epoch 44; iter: 0; batch classifier loss: 0.111138; batch adversarial loss: 0.442027\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091441; batch adversarial loss: 0.369443\n",
      "epoch 46; iter: 0; batch classifier loss: 0.098993; batch adversarial loss: 0.412738\n",
      "epoch 47; iter: 0; batch classifier loss: 0.101983; batch adversarial loss: 0.386878\n",
      "epoch 48; iter: 0; batch classifier loss: 0.147730; batch adversarial loss: 0.415726\n",
      "epoch 49; iter: 0; batch classifier loss: 0.111389; batch adversarial loss: 0.443751\n",
      "epoch 50; iter: 0; batch classifier loss: 0.136096; batch adversarial loss: 0.461611\n",
      "epoch 51; iter: 0; batch classifier loss: 0.051256; batch adversarial loss: 0.398455\n",
      "epoch 52; iter: 0; batch classifier loss: 0.171168; batch adversarial loss: 0.437732\n",
      "epoch 53; iter: 0; batch classifier loss: 0.126524; batch adversarial loss: 0.453074\n",
      "epoch 54; iter: 0; batch classifier loss: 0.148872; batch adversarial loss: 0.478371\n",
      "epoch 55; iter: 0; batch classifier loss: 0.094267; batch adversarial loss: 0.477776\n",
      "epoch 56; iter: 0; batch classifier loss: 0.080469; batch adversarial loss: 0.414356\n",
      "epoch 57; iter: 0; batch classifier loss: 0.080522; batch adversarial loss: 0.431279\n",
      "epoch 58; iter: 0; batch classifier loss: 0.100411; batch adversarial loss: 0.475680\n",
      "epoch 59; iter: 0; batch classifier loss: 0.119081; batch adversarial loss: 0.432181\n",
      "epoch 60; iter: 0; batch classifier loss: 0.057786; batch adversarial loss: 0.430198\n",
      "epoch 61; iter: 0; batch classifier loss: 0.112981; batch adversarial loss: 0.412636\n",
      "epoch 62; iter: 0; batch classifier loss: 0.105734; batch adversarial loss: 0.422788\n",
      "epoch 63; iter: 0; batch classifier loss: 0.084359; batch adversarial loss: 0.407804\n",
      "epoch 64; iter: 0; batch classifier loss: 0.096829; batch adversarial loss: 0.369941\n",
      "epoch 65; iter: 0; batch classifier loss: 0.096929; batch adversarial loss: 0.444093\n",
      "epoch 66; iter: 0; batch classifier loss: 0.056435; batch adversarial loss: 0.491841\n",
      "epoch 67; iter: 0; batch classifier loss: 0.074679; batch adversarial loss: 0.489375\n",
      "epoch 68; iter: 0; batch classifier loss: 0.089520; batch adversarial loss: 0.473988\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072850; batch adversarial loss: 0.485930\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079833; batch adversarial loss: 0.421941\n",
      "epoch 71; iter: 0; batch classifier loss: 0.082418; batch adversarial loss: 0.456054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.076006; batch adversarial loss: 0.536112\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079485; batch adversarial loss: 0.450228\n",
      "epoch 74; iter: 0; batch classifier loss: 0.085224; batch adversarial loss: 0.406817\n",
      "epoch 75; iter: 0; batch classifier loss: 0.079757; batch adversarial loss: 0.533059\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082408; batch adversarial loss: 0.334323\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084072; batch adversarial loss: 0.447668\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090630; batch adversarial loss: 0.532679\n",
      "epoch 79; iter: 0; batch classifier loss: 0.171836; batch adversarial loss: 0.559155\n",
      "epoch 80; iter: 0; batch classifier loss: 0.098764; batch adversarial loss: 0.436543\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073934; batch adversarial loss: 0.443624\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060816; batch adversarial loss: 0.384272\n",
      "epoch 83; iter: 0; batch classifier loss: 0.088670; batch adversarial loss: 0.440653\n",
      "epoch 84; iter: 0; batch classifier loss: 0.059357; batch adversarial loss: 0.447473\n",
      "epoch 85; iter: 0; batch classifier loss: 0.089387; batch adversarial loss: 0.506824\n",
      "epoch 86; iter: 0; batch classifier loss: 0.118428; batch adversarial loss: 0.394665\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072173; batch adversarial loss: 0.391385\n",
      "epoch 88; iter: 0; batch classifier loss: 0.081912; batch adversarial loss: 0.367244\n",
      "epoch 89; iter: 0; batch classifier loss: 0.117178; batch adversarial loss: 0.533878\n",
      "epoch 90; iter: 0; batch classifier loss: 0.111214; batch adversarial loss: 0.516797\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043644; batch adversarial loss: 0.393716\n",
      "epoch 92; iter: 0; batch classifier loss: 0.047651; batch adversarial loss: 0.426549\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078026; batch adversarial loss: 0.498201\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079846; batch adversarial loss: 0.496242\n",
      "epoch 95; iter: 0; batch classifier loss: 0.098803; batch adversarial loss: 0.420143\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057657; batch adversarial loss: 0.499360\n",
      "epoch 97; iter: 0; batch classifier loss: 0.105300; batch adversarial loss: 0.411914\n",
      "epoch 98; iter: 0; batch classifier loss: 0.083789; batch adversarial loss: 0.463033\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063524; batch adversarial loss: 0.442797\n",
      "epoch 100; iter: 0; batch classifier loss: 0.097052; batch adversarial loss: 0.490772\n",
      "epoch 101; iter: 0; batch classifier loss: 0.082138; batch adversarial loss: 0.390636\n",
      "epoch 102; iter: 0; batch classifier loss: 0.080853; batch adversarial loss: 0.395008\n",
      "epoch 103; iter: 0; batch classifier loss: 0.101185; batch adversarial loss: 0.464730\n",
      "epoch 104; iter: 0; batch classifier loss: 0.052860; batch adversarial loss: 0.450002\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061759; batch adversarial loss: 0.462164\n",
      "epoch 106; iter: 0; batch classifier loss: 0.070357; batch adversarial loss: 0.430779\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052624; batch adversarial loss: 0.366968\n",
      "epoch 108; iter: 0; batch classifier loss: 0.086895; batch adversarial loss: 0.428579\n",
      "epoch 109; iter: 0; batch classifier loss: 0.071594; batch adversarial loss: 0.380851\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053919; batch adversarial loss: 0.444189\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064253; batch adversarial loss: 0.342234\n",
      "epoch 112; iter: 0; batch classifier loss: 0.048175; batch adversarial loss: 0.459865\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069286; batch adversarial loss: 0.450076\n",
      "epoch 114; iter: 0; batch classifier loss: 0.075797; batch adversarial loss: 0.404118\n",
      "epoch 115; iter: 0; batch classifier loss: 0.061986; batch adversarial loss: 0.406294\n",
      "epoch 116; iter: 0; batch classifier loss: 0.115790; batch adversarial loss: 0.458368\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055942; batch adversarial loss: 0.440539\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041254; batch adversarial loss: 0.416096\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046654; batch adversarial loss: 0.405830\n",
      "epoch 120; iter: 0; batch classifier loss: 0.070634; batch adversarial loss: 0.530309\n",
      "epoch 121; iter: 0; batch classifier loss: 0.076981; batch adversarial loss: 0.380478\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062910; batch adversarial loss: 0.425808\n",
      "epoch 123; iter: 0; batch classifier loss: 0.076774; batch adversarial loss: 0.487030\n",
      "epoch 124; iter: 0; batch classifier loss: 0.077738; batch adversarial loss: 0.417937\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045100; batch adversarial loss: 0.460507\n",
      "epoch 126; iter: 0; batch classifier loss: 0.056133; batch adversarial loss: 0.426895\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044121; batch adversarial loss: 0.368826\n",
      "epoch 128; iter: 0; batch classifier loss: 0.059233; batch adversarial loss: 0.486285\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050603; batch adversarial loss: 0.396120\n",
      "epoch 130; iter: 0; batch classifier loss: 0.065024; batch adversarial loss: 0.488698\n",
      "epoch 131; iter: 0; batch classifier loss: 0.089520; batch adversarial loss: 0.408876\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042839; batch adversarial loss: 0.376286\n",
      "epoch 133; iter: 0; batch classifier loss: 0.066118; batch adversarial loss: 0.448559\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050850; batch adversarial loss: 0.376346\n",
      "epoch 135; iter: 0; batch classifier loss: 0.072550; batch adversarial loss: 0.441932\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036223; batch adversarial loss: 0.432646\n",
      "epoch 137; iter: 0; batch classifier loss: 0.079573; batch adversarial loss: 0.401383\n",
      "epoch 138; iter: 0; batch classifier loss: 0.060099; batch adversarial loss: 0.385697\n",
      "epoch 139; iter: 0; batch classifier loss: 0.074298; batch adversarial loss: 0.449992\n",
      "epoch 140; iter: 0; batch classifier loss: 0.059240; batch adversarial loss: 0.440395\n",
      "epoch 141; iter: 0; batch classifier loss: 0.062075; batch adversarial loss: 0.412431\n",
      "epoch 142; iter: 0; batch classifier loss: 0.086747; batch adversarial loss: 0.469195\n",
      "epoch 143; iter: 0; batch classifier loss: 0.074161; batch adversarial loss: 0.454495\n",
      "epoch 144; iter: 0; batch classifier loss: 0.056440; batch adversarial loss: 0.476809\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048313; batch adversarial loss: 0.516202\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052449; batch adversarial loss: 0.512699\n",
      "epoch 147; iter: 0; batch classifier loss: 0.053349; batch adversarial loss: 0.348566\n",
      "epoch 148; iter: 0; batch classifier loss: 0.041699; batch adversarial loss: 0.455729\n",
      "epoch 149; iter: 0; batch classifier loss: 0.077673; batch adversarial loss: 0.474698\n",
      "epoch 150; iter: 0; batch classifier loss: 0.053420; batch adversarial loss: 0.491721\n",
      "epoch 151; iter: 0; batch classifier loss: 0.057230; batch adversarial loss: 0.433908\n",
      "epoch 152; iter: 0; batch classifier loss: 0.056898; batch adversarial loss: 0.492856\n",
      "epoch 153; iter: 0; batch classifier loss: 0.062123; batch adversarial loss: 0.424101\n",
      "epoch 154; iter: 0; batch classifier loss: 0.057623; batch adversarial loss: 0.383154\n",
      "epoch 155; iter: 0; batch classifier loss: 0.057474; batch adversarial loss: 0.426688\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037497; batch adversarial loss: 0.478940\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041152; batch adversarial loss: 0.447278\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026790; batch adversarial loss: 0.448034\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039237; batch adversarial loss: 0.480974\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046533; batch adversarial loss: 0.569404\n",
      "epoch 161; iter: 0; batch classifier loss: 0.056939; batch adversarial loss: 0.480313\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039308; batch adversarial loss: 0.527260\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037867; batch adversarial loss: 0.503709\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035292; batch adversarial loss: 0.463966\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032279; batch adversarial loss: 0.483758\n",
      "epoch 166; iter: 0; batch classifier loss: 0.064255; batch adversarial loss: 0.511994\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022931; batch adversarial loss: 0.521189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.039783; batch adversarial loss: 0.488851\n",
      "epoch 169; iter: 0; batch classifier loss: 0.041127; batch adversarial loss: 0.532517\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026289; batch adversarial loss: 0.469570\n",
      "epoch 171; iter: 0; batch classifier loss: 0.051936; batch adversarial loss: 0.505781\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028922; batch adversarial loss: 0.414620\n",
      "epoch 173; iter: 0; batch classifier loss: 0.056452; batch adversarial loss: 0.438208\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026133; batch adversarial loss: 0.522033\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040964; batch adversarial loss: 0.491454\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016911; batch adversarial loss: 0.544411\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026624; batch adversarial loss: 0.476647\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014035; batch adversarial loss: 0.423209\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039475; batch adversarial loss: 0.476446\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028601; batch adversarial loss: 0.494866\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022452; batch adversarial loss: 0.478751\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016502; batch adversarial loss: 0.466776\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016918; batch adversarial loss: 0.410458\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036634; batch adversarial loss: 0.500119\n",
      "epoch 185; iter: 0; batch classifier loss: 0.091867; batch adversarial loss: 0.535028\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028127; batch adversarial loss: 0.505625\n",
      "epoch 187; iter: 0; batch classifier loss: 0.088260; batch adversarial loss: 0.666960\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031569; batch adversarial loss: 0.442215\n",
      "epoch 189; iter: 0; batch classifier loss: 0.049639; batch adversarial loss: 0.443944\n",
      "epoch 190; iter: 0; batch classifier loss: 0.159675; batch adversarial loss: 0.669613\n",
      "epoch 191; iter: 0; batch classifier loss: 0.137468; batch adversarial loss: 0.646134\n",
      "epoch 192; iter: 0; batch classifier loss: 0.104909; batch adversarial loss: 0.758443\n",
      "epoch 193; iter: 0; batch classifier loss: 0.214077; batch adversarial loss: 0.767476\n",
      "epoch 194; iter: 0; batch classifier loss: 0.115190; batch adversarial loss: 0.618521\n",
      "epoch 195; iter: 0; batch classifier loss: 0.209872; batch adversarial loss: 0.748710\n",
      "epoch 196; iter: 0; batch classifier loss: 0.122877; batch adversarial loss: 0.624036\n",
      "epoch 197; iter: 0; batch classifier loss: 0.162868; batch adversarial loss: 0.688550\n",
      "epoch 198; iter: 0; batch classifier loss: 0.190536; batch adversarial loss: 0.762395\n",
      "epoch 199; iter: 0; batch classifier loss: 0.157099; batch adversarial loss: 0.724908\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680708; batch adversarial loss: 0.688815\n",
      "epoch 1; iter: 0; batch classifier loss: 0.515339; batch adversarial loss: 0.660357\n",
      "epoch 2; iter: 0; batch classifier loss: 0.505191; batch adversarial loss: 0.645755\n",
      "epoch 3; iter: 0; batch classifier loss: 0.495464; batch adversarial loss: 0.638762\n",
      "epoch 4; iter: 0; batch classifier loss: 0.522738; batch adversarial loss: 0.589125\n",
      "epoch 5; iter: 0; batch classifier loss: 0.528885; batch adversarial loss: 0.567298\n",
      "epoch 6; iter: 0; batch classifier loss: 0.439351; batch adversarial loss: 0.611427\n",
      "epoch 7; iter: 0; batch classifier loss: 0.386820; batch adversarial loss: 0.576466\n",
      "epoch 8; iter: 0; batch classifier loss: 0.446555; batch adversarial loss: 0.544758\n",
      "epoch 9; iter: 0; batch classifier loss: 0.356636; batch adversarial loss: 0.530386\n",
      "epoch 10; iter: 0; batch classifier loss: 0.362476; batch adversarial loss: 0.536356\n",
      "epoch 11; iter: 0; batch classifier loss: 0.397066; batch adversarial loss: 0.533222\n",
      "epoch 12; iter: 0; batch classifier loss: 0.333147; batch adversarial loss: 0.488315\n",
      "epoch 13; iter: 0; batch classifier loss: 0.346802; batch adversarial loss: 0.494465\n",
      "epoch 14; iter: 0; batch classifier loss: 0.385746; batch adversarial loss: 0.473388\n",
      "epoch 15; iter: 0; batch classifier loss: 0.310301; batch adversarial loss: 0.498425\n",
      "epoch 16; iter: 0; batch classifier loss: 0.357099; batch adversarial loss: 0.549862\n",
      "epoch 17; iter: 0; batch classifier loss: 0.394311; batch adversarial loss: 0.441316\n",
      "epoch 18; iter: 0; batch classifier loss: 0.288169; batch adversarial loss: 0.465438\n",
      "epoch 19; iter: 0; batch classifier loss: 0.318158; batch adversarial loss: 0.408011\n",
      "epoch 20; iter: 0; batch classifier loss: 0.248707; batch adversarial loss: 0.532199\n",
      "epoch 21; iter: 0; batch classifier loss: 0.307229; batch adversarial loss: 0.408457\n",
      "epoch 22; iter: 0; batch classifier loss: 0.306876; batch adversarial loss: 0.513363\n",
      "epoch 23; iter: 0; batch classifier loss: 0.310980; batch adversarial loss: 0.456765\n",
      "epoch 24; iter: 0; batch classifier loss: 0.370865; batch adversarial loss: 0.460916\n",
      "epoch 25; iter: 0; batch classifier loss: 0.332324; batch adversarial loss: 0.494355\n",
      "epoch 26; iter: 0; batch classifier loss: 0.230157; batch adversarial loss: 0.461972\n",
      "epoch 27; iter: 0; batch classifier loss: 0.258623; batch adversarial loss: 0.532878\n",
      "epoch 28; iter: 0; batch classifier loss: 0.266676; batch adversarial loss: 0.464511\n",
      "epoch 29; iter: 0; batch classifier loss: 0.261689; batch adversarial loss: 0.434274\n",
      "epoch 30; iter: 0; batch classifier loss: 0.263157; batch adversarial loss: 0.471721\n",
      "epoch 31; iter: 0; batch classifier loss: 0.223175; batch adversarial loss: 0.421155\n",
      "epoch 32; iter: 0; batch classifier loss: 0.192029; batch adversarial loss: 0.465688\n",
      "epoch 33; iter: 0; batch classifier loss: 0.223732; batch adversarial loss: 0.537884\n",
      "epoch 34; iter: 0; batch classifier loss: 0.206009; batch adversarial loss: 0.363443\n",
      "epoch 35; iter: 0; batch classifier loss: 0.216198; batch adversarial loss: 0.397294\n",
      "epoch 36; iter: 0; batch classifier loss: 0.298882; batch adversarial loss: 0.460438\n",
      "epoch 37; iter: 0; batch classifier loss: 0.202773; batch adversarial loss: 0.380737\n",
      "epoch 38; iter: 0; batch classifier loss: 0.192182; batch adversarial loss: 0.412146\n",
      "epoch 39; iter: 0; batch classifier loss: 0.247375; batch adversarial loss: 0.436934\n",
      "epoch 40; iter: 0; batch classifier loss: 0.215072; batch adversarial loss: 0.389416\n",
      "epoch 41; iter: 0; batch classifier loss: 0.216343; batch adversarial loss: 0.434215\n",
      "epoch 42; iter: 0; batch classifier loss: 0.236591; batch adversarial loss: 0.459204\n",
      "epoch 43; iter: 0; batch classifier loss: 0.229571; batch adversarial loss: 0.493747\n",
      "epoch 44; iter: 0; batch classifier loss: 0.202021; batch adversarial loss: 0.411820\n",
      "epoch 45; iter: 0; batch classifier loss: 0.247058; batch adversarial loss: 0.471219\n",
      "epoch 46; iter: 0; batch classifier loss: 0.128006; batch adversarial loss: 0.483023\n",
      "epoch 47; iter: 0; batch classifier loss: 0.097465; batch adversarial loss: 0.485020\n",
      "epoch 48; iter: 0; batch classifier loss: 0.162269; batch adversarial loss: 0.484158\n",
      "epoch 49; iter: 0; batch classifier loss: 0.279249; batch adversarial loss: 0.446220\n",
      "epoch 50; iter: 0; batch classifier loss: 0.145545; batch adversarial loss: 0.493091\n",
      "epoch 51; iter: 0; batch classifier loss: 0.165090; batch adversarial loss: 0.407466\n",
      "epoch 52; iter: 0; batch classifier loss: 0.195168; batch adversarial loss: 0.496472\n",
      "epoch 53; iter: 0; batch classifier loss: 0.190471; batch adversarial loss: 0.408970\n",
      "epoch 54; iter: 0; batch classifier loss: 0.172560; batch adversarial loss: 0.445509\n",
      "epoch 55; iter: 0; batch classifier loss: 0.159372; batch adversarial loss: 0.573150\n",
      "epoch 56; iter: 0; batch classifier loss: 0.153510; batch adversarial loss: 0.471202\n",
      "epoch 57; iter: 0; batch classifier loss: 0.238876; batch adversarial loss: 0.496235\n",
      "epoch 58; iter: 0; batch classifier loss: 0.149035; batch adversarial loss: 0.496300\n",
      "epoch 59; iter: 0; batch classifier loss: 0.129074; batch adversarial loss: 0.608801\n",
      "epoch 60; iter: 0; batch classifier loss: 0.199399; batch adversarial loss: 0.408062\n",
      "epoch 61; iter: 0; batch classifier loss: 0.105329; batch adversarial loss: 0.408660\n",
      "epoch 62; iter: 0; batch classifier loss: 0.076506; batch adversarial loss: 0.483137\n",
      "epoch 63; iter: 0; batch classifier loss: 0.078603; batch adversarial loss: 0.433748\n",
      "epoch 64; iter: 0; batch classifier loss: 0.093477; batch adversarial loss: 0.416695\n",
      "epoch 65; iter: 0; batch classifier loss: 0.185825; batch adversarial loss: 0.394841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.188028; batch adversarial loss: 0.426218\n",
      "epoch 67; iter: 0; batch classifier loss: 0.141037; batch adversarial loss: 0.551939\n",
      "epoch 68; iter: 0; batch classifier loss: 0.155670; batch adversarial loss: 0.431287\n",
      "epoch 69; iter: 0; batch classifier loss: 0.104073; batch adversarial loss: 0.431003\n",
      "epoch 70; iter: 0; batch classifier loss: 0.192811; batch adversarial loss: 0.433373\n",
      "epoch 71; iter: 0; batch classifier loss: 0.160247; batch adversarial loss: 0.368995\n",
      "epoch 72; iter: 0; batch classifier loss: 0.111961; batch adversarial loss: 0.372233\n",
      "epoch 73; iter: 0; batch classifier loss: 0.181625; batch adversarial loss: 0.460439\n",
      "epoch 74; iter: 0; batch classifier loss: 0.098912; batch adversarial loss: 0.442985\n",
      "epoch 75; iter: 0; batch classifier loss: 0.174116; batch adversarial loss: 0.499093\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076928; batch adversarial loss: 0.445648\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056041; batch adversarial loss: 0.452480\n",
      "epoch 78; iter: 0; batch classifier loss: 0.119260; batch adversarial loss: 0.435401\n",
      "epoch 79; iter: 0; batch classifier loss: 0.088529; batch adversarial loss: 0.371204\n",
      "epoch 80; iter: 0; batch classifier loss: 0.089739; batch adversarial loss: 0.482888\n",
      "epoch 81; iter: 0; batch classifier loss: 0.060202; batch adversarial loss: 0.456671\n",
      "epoch 82; iter: 0; batch classifier loss: 0.049965; batch adversarial loss: 0.527228\n",
      "epoch 83; iter: 0; batch classifier loss: 0.092866; batch adversarial loss: 0.402163\n",
      "epoch 84; iter: 0; batch classifier loss: 0.092437; batch adversarial loss: 0.433112\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074923; batch adversarial loss: 0.468250\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062917; batch adversarial loss: 0.345480\n",
      "epoch 87; iter: 0; batch classifier loss: 0.127106; batch adversarial loss: 0.463416\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057200; batch adversarial loss: 0.464100\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048519; batch adversarial loss: 0.514020\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063149; batch adversarial loss: 0.440785\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060897; batch adversarial loss: 0.429940\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068602; batch adversarial loss: 0.362276\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046966; batch adversarial loss: 0.444116\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048765; batch adversarial loss: 0.478508\n",
      "epoch 95; iter: 0; batch classifier loss: 0.034717; batch adversarial loss: 0.516841\n",
      "epoch 96; iter: 0; batch classifier loss: 0.020765; batch adversarial loss: 0.375652\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042977; batch adversarial loss: 0.388343\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072884; batch adversarial loss: 0.458436\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061828; batch adversarial loss: 0.417221\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039392; batch adversarial loss: 0.420934\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056619; batch adversarial loss: 0.429300\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032316; batch adversarial loss: 0.287658\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040199; batch adversarial loss: 0.489215\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044237; batch adversarial loss: 0.433657\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043555; batch adversarial loss: 0.490338\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050140; batch adversarial loss: 0.487806\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040161; batch adversarial loss: 0.507178\n",
      "epoch 108; iter: 0; batch classifier loss: 0.066761; batch adversarial loss: 0.455928\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064583; batch adversarial loss: 0.389113\n",
      "epoch 110; iter: 0; batch classifier loss: 0.029173; batch adversarial loss: 0.522384\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037825; batch adversarial loss: 0.490166\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036775; batch adversarial loss: 0.482096\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048417; batch adversarial loss: 0.418038\n",
      "epoch 114; iter: 0; batch classifier loss: 0.017430; batch adversarial loss: 0.474164\n",
      "epoch 115; iter: 0; batch classifier loss: 0.020666; batch adversarial loss: 0.427377\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035006; batch adversarial loss: 0.369926\n",
      "epoch 117; iter: 0; batch classifier loss: 0.011192; batch adversarial loss: 0.413691\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035822; batch adversarial loss: 0.419516\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047287; batch adversarial loss: 0.486012\n",
      "epoch 120; iter: 0; batch classifier loss: 0.067150; batch adversarial loss: 0.537548\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035308; batch adversarial loss: 0.453037\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029124; batch adversarial loss: 0.496958\n",
      "epoch 123; iter: 0; batch classifier loss: 0.012591; batch adversarial loss: 0.449508\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020902; batch adversarial loss: 0.540084\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017617; batch adversarial loss: 0.480484\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027087; batch adversarial loss: 0.368137\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034480; batch adversarial loss: 0.473390\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038605; batch adversarial loss: 0.452631\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047068; batch adversarial loss: 0.427278\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045248; batch adversarial loss: 0.437036\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027667; batch adversarial loss: 0.531035\n",
      "epoch 132; iter: 0; batch classifier loss: 0.009907; batch adversarial loss: 0.443021\n",
      "epoch 133; iter: 0; batch classifier loss: 0.012930; batch adversarial loss: 0.496878\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020399; batch adversarial loss: 0.396707\n",
      "epoch 135; iter: 0; batch classifier loss: 0.013979; batch adversarial loss: 0.441855\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018676; batch adversarial loss: 0.468175\n",
      "epoch 137; iter: 0; batch classifier loss: 0.010793; batch adversarial loss: 0.511292\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019702; batch adversarial loss: 0.490149\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024770; batch adversarial loss: 0.396337\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038737; batch adversarial loss: 0.420368\n",
      "epoch 141; iter: 0; batch classifier loss: 0.057807; batch adversarial loss: 0.425918\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043850; batch adversarial loss: 0.441070\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032278; batch adversarial loss: 0.563572\n",
      "epoch 144; iter: 0; batch classifier loss: 0.064705; batch adversarial loss: 0.359172\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022575; batch adversarial loss: 0.481788\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026424; batch adversarial loss: 0.497102\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010773; batch adversarial loss: 0.358187\n",
      "epoch 148; iter: 0; batch classifier loss: 0.008520; batch adversarial loss: 0.417945\n",
      "epoch 149; iter: 0; batch classifier loss: 0.008151; batch adversarial loss: 0.451421\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024286; batch adversarial loss: 0.415236\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022229; batch adversarial loss: 0.422903\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028389; batch adversarial loss: 0.449869\n",
      "epoch 153; iter: 0; batch classifier loss: 0.045338; batch adversarial loss: 0.397295\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022998; batch adversarial loss: 0.450620\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022261; batch adversarial loss: 0.445673\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017297; batch adversarial loss: 0.379438\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020101; batch adversarial loss: 0.484783\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019531; batch adversarial loss: 0.422191\n",
      "epoch 159; iter: 0; batch classifier loss: 0.008692; batch adversarial loss: 0.477434\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009216; batch adversarial loss: 0.399669\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020924; batch adversarial loss: 0.385377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.009892; batch adversarial loss: 0.568200\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036331; batch adversarial loss: 0.413067\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010149; batch adversarial loss: 0.479999\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024737; batch adversarial loss: 0.450966\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033588; batch adversarial loss: 0.420560\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023091; batch adversarial loss: 0.412261\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027872; batch adversarial loss: 0.428665\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009179; batch adversarial loss: 0.443898\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012805; batch adversarial loss: 0.486829\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015229; batch adversarial loss: 0.369781\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016027; batch adversarial loss: 0.534930\n",
      "epoch 173; iter: 0; batch classifier loss: 0.005956; batch adversarial loss: 0.450101\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011177; batch adversarial loss: 0.492166\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009025; batch adversarial loss: 0.496965\n",
      "epoch 176; iter: 0; batch classifier loss: 0.004667; batch adversarial loss: 0.471605\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012925; batch adversarial loss: 0.422090\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015804; batch adversarial loss: 0.408602\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013056; batch adversarial loss: 0.480011\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013786; batch adversarial loss: 0.408655\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007586; batch adversarial loss: 0.455113\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012028; batch adversarial loss: 0.374847\n",
      "epoch 183; iter: 0; batch classifier loss: 0.004249; batch adversarial loss: 0.431087\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031973; batch adversarial loss: 0.405626\n",
      "epoch 185; iter: 0; batch classifier loss: 0.003156; batch adversarial loss: 0.360144\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020270; batch adversarial loss: 0.398942\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011802; batch adversarial loss: 0.496306\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008378; batch adversarial loss: 0.578466\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025780; batch adversarial loss: 0.373974\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010389; batch adversarial loss: 0.541492\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006815; batch adversarial loss: 0.466092\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022628; batch adversarial loss: 0.391670\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005008; batch adversarial loss: 0.510605\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035492; batch adversarial loss: 0.418012\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019024; batch adversarial loss: 0.449125\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018443; batch adversarial loss: 0.480783\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014343; batch adversarial loss: 0.409310\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004821; batch adversarial loss: 0.408720\n",
      "epoch 199; iter: 0; batch classifier loss: 0.043492; batch adversarial loss: 0.422284\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705683; batch adversarial loss: 0.730710\n",
      "epoch 1; iter: 0; batch classifier loss: 0.561972; batch adversarial loss: 0.680919\n",
      "epoch 2; iter: 0; batch classifier loss: 0.393764; batch adversarial loss: 0.663142\n",
      "epoch 3; iter: 0; batch classifier loss: 0.362960; batch adversarial loss: 0.622489\n",
      "epoch 4; iter: 0; batch classifier loss: 0.337739; batch adversarial loss: 0.595234\n",
      "epoch 5; iter: 0; batch classifier loss: 0.346023; batch adversarial loss: 0.575523\n",
      "epoch 6; iter: 0; batch classifier loss: 0.360958; batch adversarial loss: 0.506939\n",
      "epoch 7; iter: 0; batch classifier loss: 0.279141; batch adversarial loss: 0.545084\n",
      "epoch 8; iter: 0; batch classifier loss: 0.341023; batch adversarial loss: 0.519239\n",
      "epoch 9; iter: 0; batch classifier loss: 0.245494; batch adversarial loss: 0.522449\n",
      "epoch 10; iter: 0; batch classifier loss: 0.202013; batch adversarial loss: 0.524826\n",
      "epoch 11; iter: 0; batch classifier loss: 0.230045; batch adversarial loss: 0.478537\n",
      "epoch 12; iter: 0; batch classifier loss: 0.262497; batch adversarial loss: 0.520856\n",
      "epoch 13; iter: 0; batch classifier loss: 0.202212; batch adversarial loss: 0.424598\n",
      "epoch 14; iter: 0; batch classifier loss: 0.226297; batch adversarial loss: 0.496889\n",
      "epoch 15; iter: 0; batch classifier loss: 0.242336; batch adversarial loss: 0.570552\n",
      "epoch 16; iter: 0; batch classifier loss: 0.218081; batch adversarial loss: 0.510636\n",
      "epoch 17; iter: 0; batch classifier loss: 0.231268; batch adversarial loss: 0.488158\n",
      "epoch 18; iter: 0; batch classifier loss: 0.226653; batch adversarial loss: 0.571899\n",
      "epoch 19; iter: 0; batch classifier loss: 0.270706; batch adversarial loss: 0.493092\n",
      "epoch 20; iter: 0; batch classifier loss: 0.223080; batch adversarial loss: 0.431430\n",
      "epoch 21; iter: 0; batch classifier loss: 0.285041; batch adversarial loss: 0.451422\n",
      "epoch 22; iter: 0; batch classifier loss: 0.453177; batch adversarial loss: 0.449832\n",
      "epoch 23; iter: 0; batch classifier loss: 0.475991; batch adversarial loss: 0.543509\n",
      "epoch 24; iter: 0; batch classifier loss: 0.266016; batch adversarial loss: 0.547180\n",
      "epoch 25; iter: 0; batch classifier loss: 0.139189; batch adversarial loss: 0.475950\n",
      "epoch 26; iter: 0; batch classifier loss: 0.157393; batch adversarial loss: 0.433981\n",
      "epoch 27; iter: 0; batch classifier loss: 0.128904; batch adversarial loss: 0.414833\n",
      "epoch 28; iter: 0; batch classifier loss: 0.171130; batch adversarial loss: 0.489874\n",
      "epoch 29; iter: 0; batch classifier loss: 0.180770; batch adversarial loss: 0.398835\n",
      "epoch 30; iter: 0; batch classifier loss: 0.128516; batch adversarial loss: 0.460469\n",
      "epoch 31; iter: 0; batch classifier loss: 0.159440; batch adversarial loss: 0.489249\n",
      "epoch 32; iter: 0; batch classifier loss: 0.118526; batch adversarial loss: 0.577608\n",
      "epoch 33; iter: 0; batch classifier loss: 0.097106; batch adversarial loss: 0.517527\n",
      "epoch 34; iter: 0; batch classifier loss: 0.146230; batch adversarial loss: 0.348089\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129855; batch adversarial loss: 0.444581\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102653; batch adversarial loss: 0.416935\n",
      "epoch 37; iter: 0; batch classifier loss: 0.090105; batch adversarial loss: 0.582959\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115274; batch adversarial loss: 0.443183\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126575; batch adversarial loss: 0.456897\n",
      "epoch 40; iter: 0; batch classifier loss: 0.109395; batch adversarial loss: 0.534794\n",
      "epoch 41; iter: 0; batch classifier loss: 0.118964; batch adversarial loss: 0.402398\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117081; batch adversarial loss: 0.460588\n",
      "epoch 43; iter: 0; batch classifier loss: 0.149122; batch adversarial loss: 0.463874\n",
      "epoch 44; iter: 0; batch classifier loss: 0.106278; batch adversarial loss: 0.440427\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099715; batch adversarial loss: 0.489976\n",
      "epoch 46; iter: 0; batch classifier loss: 0.155359; batch adversarial loss: 0.457778\n",
      "epoch 47; iter: 0; batch classifier loss: 0.103254; batch adversarial loss: 0.334144\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081231; batch adversarial loss: 0.428080\n",
      "epoch 49; iter: 0; batch classifier loss: 0.097501; batch adversarial loss: 0.444908\n",
      "epoch 50; iter: 0; batch classifier loss: 0.086249; batch adversarial loss: 0.489112\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081463; batch adversarial loss: 0.454604\n",
      "epoch 52; iter: 0; batch classifier loss: 0.091181; batch adversarial loss: 0.385576\n",
      "epoch 53; iter: 0; batch classifier loss: 0.056719; batch adversarial loss: 0.493469\n",
      "epoch 54; iter: 0; batch classifier loss: 0.070901; batch adversarial loss: 0.437538\n",
      "epoch 55; iter: 0; batch classifier loss: 0.149135; batch adversarial loss: 0.352029\n",
      "epoch 56; iter: 0; batch classifier loss: 0.077460; batch adversarial loss: 0.502309\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086874; batch adversarial loss: 0.390522\n",
      "epoch 58; iter: 0; batch classifier loss: 0.130877; batch adversarial loss: 0.422358\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087131; batch adversarial loss: 0.447904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.070617; batch adversarial loss: 0.532870\n",
      "epoch 61; iter: 0; batch classifier loss: 0.066654; batch adversarial loss: 0.436727\n",
      "epoch 62; iter: 0; batch classifier loss: 0.079446; batch adversarial loss: 0.369499\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103325; batch adversarial loss: 0.440973\n",
      "epoch 64; iter: 0; batch classifier loss: 0.060829; batch adversarial loss: 0.413663\n",
      "epoch 65; iter: 0; batch classifier loss: 0.124885; batch adversarial loss: 0.393181\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092794; batch adversarial loss: 0.328855\n",
      "epoch 67; iter: 0; batch classifier loss: 0.075456; batch adversarial loss: 0.504799\n",
      "epoch 68; iter: 0; batch classifier loss: 0.065265; batch adversarial loss: 0.431188\n",
      "epoch 69; iter: 0; batch classifier loss: 0.117127; batch adversarial loss: 0.380105\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067906; batch adversarial loss: 0.399884\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071211; batch adversarial loss: 0.405962\n",
      "epoch 72; iter: 0; batch classifier loss: 0.052038; batch adversarial loss: 0.407700\n",
      "epoch 73; iter: 0; batch classifier loss: 0.057295; batch adversarial loss: 0.457538\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067550; batch adversarial loss: 0.468756\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096497; batch adversarial loss: 0.420311\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076604; batch adversarial loss: 0.453445\n",
      "epoch 77; iter: 0; batch classifier loss: 0.088547; batch adversarial loss: 0.401682\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073856; batch adversarial loss: 0.328736\n",
      "epoch 79; iter: 0; batch classifier loss: 0.093261; batch adversarial loss: 0.486173\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067802; batch adversarial loss: 0.394978\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074091; batch adversarial loss: 0.396550\n",
      "epoch 82; iter: 0; batch classifier loss: 0.096516; batch adversarial loss: 0.497544\n",
      "epoch 83; iter: 0; batch classifier loss: 0.076700; batch adversarial loss: 0.431676\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048819; batch adversarial loss: 0.482460\n",
      "epoch 85; iter: 0; batch classifier loss: 0.072774; batch adversarial loss: 0.389154\n",
      "epoch 86; iter: 0; batch classifier loss: 0.042103; batch adversarial loss: 0.549765\n",
      "epoch 87; iter: 0; batch classifier loss: 0.039756; batch adversarial loss: 0.402086\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062420; batch adversarial loss: 0.493143\n",
      "epoch 89; iter: 0; batch classifier loss: 0.038710; batch adversarial loss: 0.523340\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061282; batch adversarial loss: 0.419629\n",
      "epoch 91; iter: 0; batch classifier loss: 0.047782; batch adversarial loss: 0.499381\n",
      "epoch 92; iter: 0; batch classifier loss: 0.089586; batch adversarial loss: 0.413136\n",
      "epoch 93; iter: 0; batch classifier loss: 0.030119; batch adversarial loss: 0.373335\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050657; batch adversarial loss: 0.388835\n",
      "epoch 95; iter: 0; batch classifier loss: 0.030629; batch adversarial loss: 0.380756\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066210; batch adversarial loss: 0.399609\n",
      "epoch 97; iter: 0; batch classifier loss: 0.030754; batch adversarial loss: 0.381085\n",
      "epoch 98; iter: 0; batch classifier loss: 0.069040; batch adversarial loss: 0.426181\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071200; batch adversarial loss: 0.464648\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060334; batch adversarial loss: 0.469972\n",
      "epoch 101; iter: 0; batch classifier loss: 0.069264; batch adversarial loss: 0.462776\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031712; batch adversarial loss: 0.540347\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052768; batch adversarial loss: 0.516058\n",
      "epoch 104; iter: 0; batch classifier loss: 0.040326; batch adversarial loss: 0.434932\n",
      "epoch 105; iter: 0; batch classifier loss: 0.069569; batch adversarial loss: 0.461816\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055005; batch adversarial loss: 0.523334\n",
      "epoch 107; iter: 0; batch classifier loss: 0.077811; batch adversarial loss: 0.499151\n",
      "epoch 108; iter: 0; batch classifier loss: 0.083816; batch adversarial loss: 0.438461\n",
      "epoch 109; iter: 0; batch classifier loss: 0.028235; batch adversarial loss: 0.427509\n",
      "epoch 110; iter: 0; batch classifier loss: 0.034453; batch adversarial loss: 0.420689\n",
      "epoch 111; iter: 0; batch classifier loss: 0.083996; batch adversarial loss: 0.423003\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034181; batch adversarial loss: 0.444168\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057256; batch adversarial loss: 0.434611\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039204; batch adversarial loss: 0.451302\n",
      "epoch 115; iter: 0; batch classifier loss: 0.056917; batch adversarial loss: 0.512661\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026238; batch adversarial loss: 0.354484\n",
      "epoch 117; iter: 0; batch classifier loss: 0.072472; batch adversarial loss: 0.449640\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050988; batch adversarial loss: 0.478785\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055370; batch adversarial loss: 0.358475\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042136; batch adversarial loss: 0.456543\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060031; batch adversarial loss: 0.353282\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042361; batch adversarial loss: 0.496906\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050152; batch adversarial loss: 0.418054\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029591; batch adversarial loss: 0.474088\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029099; batch adversarial loss: 0.476840\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036143; batch adversarial loss: 0.405566\n",
      "epoch 127; iter: 0; batch classifier loss: 0.056073; batch adversarial loss: 0.444489\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025964; batch adversarial loss: 0.444172\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051486; batch adversarial loss: 0.369352\n",
      "epoch 130; iter: 0; batch classifier loss: 0.068903; batch adversarial loss: 0.433359\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036105; batch adversarial loss: 0.350693\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028952; batch adversarial loss: 0.371403\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037124; batch adversarial loss: 0.513301\n",
      "epoch 134; iter: 0; batch classifier loss: 0.013041; batch adversarial loss: 0.453608\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041275; batch adversarial loss: 0.429391\n",
      "epoch 136; iter: 0; batch classifier loss: 0.015443; batch adversarial loss: 0.391860\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025523; batch adversarial loss: 0.421239\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027580; batch adversarial loss: 0.441559\n",
      "epoch 139; iter: 0; batch classifier loss: 0.047198; batch adversarial loss: 0.453585\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024404; batch adversarial loss: 0.426428\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021098; batch adversarial loss: 0.469870\n",
      "epoch 142; iter: 0; batch classifier loss: 0.055977; batch adversarial loss: 0.471714\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024340; batch adversarial loss: 0.439871\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045618; batch adversarial loss: 0.387828\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037542; batch adversarial loss: 0.518806\n",
      "epoch 146; iter: 0; batch classifier loss: 0.049549; batch adversarial loss: 0.519753\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032755; batch adversarial loss: 0.462826\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045016; batch adversarial loss: 0.346073\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012158; batch adversarial loss: 0.493101\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033708; batch adversarial loss: 0.372977\n",
      "epoch 151; iter: 0; batch classifier loss: 0.056871; batch adversarial loss: 0.483511\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021811; batch adversarial loss: 0.435546\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018222; batch adversarial loss: 0.501348\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013575; batch adversarial loss: 0.572237\n",
      "epoch 155; iter: 0; batch classifier loss: 0.074401; batch adversarial loss: 0.432401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.031455; batch adversarial loss: 0.378597\n",
      "epoch 157; iter: 0; batch classifier loss: 0.058744; batch adversarial loss: 0.477649\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012868; batch adversarial loss: 0.437186\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037625; batch adversarial loss: 0.436437\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041244; batch adversarial loss: 0.409246\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018690; batch adversarial loss: 0.595755\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015397; batch adversarial loss: 0.430985\n",
      "epoch 163; iter: 0; batch classifier loss: 0.043065; batch adversarial loss: 0.386851\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019930; batch adversarial loss: 0.486859\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009147; batch adversarial loss: 0.404469\n",
      "epoch 166; iter: 0; batch classifier loss: 0.004660; batch adversarial loss: 0.533929\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014653; batch adversarial loss: 0.383912\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010274; batch adversarial loss: 0.405266\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015594; batch adversarial loss: 0.411386\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011723; batch adversarial loss: 0.458816\n",
      "epoch 171; iter: 0; batch classifier loss: 0.060214; batch adversarial loss: 0.453446\n",
      "epoch 172; iter: 0; batch classifier loss: 0.006843; batch adversarial loss: 0.451855\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006586; batch adversarial loss: 0.459177\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018833; batch adversarial loss: 0.470932\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016839; batch adversarial loss: 0.467620\n",
      "epoch 176; iter: 0; batch classifier loss: 0.036586; batch adversarial loss: 0.435488\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024057; batch adversarial loss: 0.486295\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017553; batch adversarial loss: 0.404348\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035806; batch adversarial loss: 0.437740\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021458; batch adversarial loss: 0.516999\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019420; batch adversarial loss: 0.392913\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010495; batch adversarial loss: 0.489502\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022934; batch adversarial loss: 0.450090\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033854; batch adversarial loss: 0.426194\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024209; batch adversarial loss: 0.418649\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007721; batch adversarial loss: 0.417826\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014819; batch adversarial loss: 0.496826\n",
      "epoch 188; iter: 0; batch classifier loss: 0.057517; batch adversarial loss: 0.469073\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017945; batch adversarial loss: 0.424152\n",
      "epoch 190; iter: 0; batch classifier loss: 0.043612; batch adversarial loss: 0.418153\n",
      "epoch 191; iter: 0; batch classifier loss: 0.036735; batch adversarial loss: 0.397510\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029375; batch adversarial loss: 0.476568\n",
      "epoch 193; iter: 0; batch classifier loss: 0.042751; batch adversarial loss: 0.373996\n",
      "epoch 194; iter: 0; batch classifier loss: 0.040646; batch adversarial loss: 0.496363\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030358; batch adversarial loss: 0.440897\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007782; batch adversarial loss: 0.386716\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012281; batch adversarial loss: 0.474990\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021639; batch adversarial loss: 0.390529\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028802; batch adversarial loss: 0.419458\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698590; batch adversarial loss: 0.679580\n",
      "epoch 1; iter: 0; batch classifier loss: 0.467252; batch adversarial loss: 0.635649\n",
      "epoch 2; iter: 0; batch classifier loss: 0.383284; batch adversarial loss: 0.622236\n",
      "epoch 3; iter: 0; batch classifier loss: 0.306538; batch adversarial loss: 0.570062\n",
      "epoch 4; iter: 0; batch classifier loss: 0.356974; batch adversarial loss: 0.554990\n",
      "epoch 5; iter: 0; batch classifier loss: 0.345016; batch adversarial loss: 0.573291\n",
      "epoch 6; iter: 0; batch classifier loss: 0.237830; batch adversarial loss: 0.514887\n",
      "epoch 7; iter: 0; batch classifier loss: 0.259486; batch adversarial loss: 0.539365\n",
      "epoch 8; iter: 0; batch classifier loss: 0.236226; batch adversarial loss: 0.521187\n",
      "epoch 9; iter: 0; batch classifier loss: 0.185001; batch adversarial loss: 0.523837\n",
      "epoch 10; iter: 0; batch classifier loss: 0.222664; batch adversarial loss: 0.515059\n",
      "epoch 11; iter: 0; batch classifier loss: 0.227377; batch adversarial loss: 0.479976\n",
      "epoch 12; iter: 0; batch classifier loss: 0.237845; batch adversarial loss: 0.534210\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232399; batch adversarial loss: 0.506382\n",
      "epoch 14; iter: 0; batch classifier loss: 0.246540; batch adversarial loss: 0.526910\n",
      "epoch 15; iter: 0; batch classifier loss: 0.223027; batch adversarial loss: 0.515177\n",
      "epoch 16; iter: 0; batch classifier loss: 0.226241; batch adversarial loss: 0.454976\n",
      "epoch 17; iter: 0; batch classifier loss: 0.234031; batch adversarial loss: 0.493137\n",
      "epoch 18; iter: 0; batch classifier loss: 0.260622; batch adversarial loss: 0.519866\n",
      "epoch 19; iter: 0; batch classifier loss: 0.356189; batch adversarial loss: 0.533307\n",
      "epoch 20; iter: 0; batch classifier loss: 0.450258; batch adversarial loss: 0.479084\n",
      "epoch 21; iter: 0; batch classifier loss: 0.448871; batch adversarial loss: 0.531156\n",
      "epoch 22; iter: 0; batch classifier loss: 0.314961; batch adversarial loss: 0.560122\n",
      "epoch 23; iter: 0; batch classifier loss: 0.245854; batch adversarial loss: 0.447498\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194795; batch adversarial loss: 0.504916\n",
      "epoch 25; iter: 0; batch classifier loss: 0.147216; batch adversarial loss: 0.408547\n",
      "epoch 26; iter: 0; batch classifier loss: 0.100687; batch adversarial loss: 0.459638\n",
      "epoch 27; iter: 0; batch classifier loss: 0.128203; batch adversarial loss: 0.416017\n",
      "epoch 28; iter: 0; batch classifier loss: 0.165650; batch adversarial loss: 0.427090\n",
      "epoch 29; iter: 0; batch classifier loss: 0.151952; batch adversarial loss: 0.397172\n",
      "epoch 30; iter: 0; batch classifier loss: 0.149785; batch adversarial loss: 0.410809\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178318; batch adversarial loss: 0.440298\n",
      "epoch 32; iter: 0; batch classifier loss: 0.108891; batch adversarial loss: 0.469236\n",
      "epoch 33; iter: 0; batch classifier loss: 0.099915; batch adversarial loss: 0.448349\n",
      "epoch 34; iter: 0; batch classifier loss: 0.080737; batch adversarial loss: 0.394939\n",
      "epoch 35; iter: 0; batch classifier loss: 0.144082; batch adversarial loss: 0.437894\n",
      "epoch 36; iter: 0; batch classifier loss: 0.105566; batch adversarial loss: 0.425164\n",
      "epoch 37; iter: 0; batch classifier loss: 0.103872; batch adversarial loss: 0.483304\n",
      "epoch 38; iter: 0; batch classifier loss: 0.116686; batch adversarial loss: 0.446094\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125361; batch adversarial loss: 0.521071\n",
      "epoch 40; iter: 0; batch classifier loss: 0.066020; batch adversarial loss: 0.448041\n",
      "epoch 41; iter: 0; batch classifier loss: 0.102146; batch adversarial loss: 0.466915\n",
      "epoch 42; iter: 0; batch classifier loss: 0.085072; batch adversarial loss: 0.489193\n",
      "epoch 43; iter: 0; batch classifier loss: 0.091983; batch adversarial loss: 0.582225\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127460; batch adversarial loss: 0.468138\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086820; batch adversarial loss: 0.380806\n",
      "epoch 46; iter: 0; batch classifier loss: 0.091227; batch adversarial loss: 0.423104\n",
      "epoch 47; iter: 0; batch classifier loss: 0.086424; batch adversarial loss: 0.379285\n",
      "epoch 48; iter: 0; batch classifier loss: 0.084384; batch adversarial loss: 0.524616\n",
      "epoch 49; iter: 0; batch classifier loss: 0.132512; batch adversarial loss: 0.445049\n",
      "epoch 50; iter: 0; batch classifier loss: 0.132459; batch adversarial loss: 0.374933\n",
      "epoch 51; iter: 0; batch classifier loss: 0.067982; batch adversarial loss: 0.496145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.111089; batch adversarial loss: 0.366801\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098855; batch adversarial loss: 0.444722\n",
      "epoch 54; iter: 0; batch classifier loss: 0.115879; batch adversarial loss: 0.472255\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086765; batch adversarial loss: 0.477303\n",
      "epoch 56; iter: 0; batch classifier loss: 0.064103; batch adversarial loss: 0.425585\n",
      "epoch 57; iter: 0; batch classifier loss: 0.077628; batch adversarial loss: 0.449582\n",
      "epoch 58; iter: 0; batch classifier loss: 0.087106; batch adversarial loss: 0.450696\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084774; batch adversarial loss: 0.418525\n",
      "epoch 60; iter: 0; batch classifier loss: 0.100772; batch adversarial loss: 0.478951\n",
      "epoch 61; iter: 0; batch classifier loss: 0.143129; batch adversarial loss: 0.502884\n",
      "epoch 62; iter: 0; batch classifier loss: 0.079692; batch adversarial loss: 0.392143\n",
      "epoch 63; iter: 0; batch classifier loss: 0.048612; batch adversarial loss: 0.449898\n",
      "epoch 64; iter: 0; batch classifier loss: 0.045214; batch adversarial loss: 0.452384\n",
      "epoch 65; iter: 0; batch classifier loss: 0.152955; batch adversarial loss: 0.479152\n",
      "epoch 66; iter: 0; batch classifier loss: 0.046900; batch adversarial loss: 0.355632\n",
      "epoch 67; iter: 0; batch classifier loss: 0.119300; batch adversarial loss: 0.413290\n",
      "epoch 68; iter: 0; batch classifier loss: 0.059891; batch adversarial loss: 0.453674\n",
      "epoch 69; iter: 0; batch classifier loss: 0.129034; batch adversarial loss: 0.410030\n",
      "epoch 70; iter: 0; batch classifier loss: 0.075357; batch adversarial loss: 0.453393\n",
      "epoch 71; iter: 0; batch classifier loss: 0.053845; batch adversarial loss: 0.427578\n",
      "epoch 72; iter: 0; batch classifier loss: 0.073878; batch adversarial loss: 0.512017\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077565; batch adversarial loss: 0.385577\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054428; batch adversarial loss: 0.521974\n",
      "epoch 75; iter: 0; batch classifier loss: 0.121225; batch adversarial loss: 0.487445\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060912; batch adversarial loss: 0.395311\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056552; batch adversarial loss: 0.436427\n",
      "epoch 78; iter: 0; batch classifier loss: 0.056500; batch adversarial loss: 0.543993\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082450; batch adversarial loss: 0.444656\n",
      "epoch 80; iter: 0; batch classifier loss: 0.085485; batch adversarial loss: 0.383326\n",
      "epoch 81; iter: 0; batch classifier loss: 0.041164; batch adversarial loss: 0.431400\n",
      "epoch 82; iter: 0; batch classifier loss: 0.049478; batch adversarial loss: 0.504290\n",
      "epoch 83; iter: 0; batch classifier loss: 0.076174; batch adversarial loss: 0.507281\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052613; batch adversarial loss: 0.489057\n",
      "epoch 85; iter: 0; batch classifier loss: 0.063728; batch adversarial loss: 0.428401\n",
      "epoch 86; iter: 0; batch classifier loss: 0.059266; batch adversarial loss: 0.347571\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067651; batch adversarial loss: 0.400278\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073325; batch adversarial loss: 0.448186\n",
      "epoch 89; iter: 0; batch classifier loss: 0.111285; batch adversarial loss: 0.414533\n",
      "epoch 90; iter: 0; batch classifier loss: 0.089775; batch adversarial loss: 0.461635\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083304; batch adversarial loss: 0.456432\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055183; batch adversarial loss: 0.449433\n",
      "epoch 93; iter: 0; batch classifier loss: 0.066174; batch adversarial loss: 0.415146\n",
      "epoch 94; iter: 0; batch classifier loss: 0.080072; batch adversarial loss: 0.516901\n",
      "epoch 95; iter: 0; batch classifier loss: 0.076367; batch adversarial loss: 0.443909\n",
      "epoch 96; iter: 0; batch classifier loss: 0.067589; batch adversarial loss: 0.462621\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046168; batch adversarial loss: 0.482493\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055477; batch adversarial loss: 0.448307\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059662; batch adversarial loss: 0.467433\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053649; batch adversarial loss: 0.444748\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051505; batch adversarial loss: 0.404238\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047996; batch adversarial loss: 0.449245\n",
      "epoch 103; iter: 0; batch classifier loss: 0.073979; batch adversarial loss: 0.396805\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050296; batch adversarial loss: 0.435505\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062336; batch adversarial loss: 0.464966\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035092; batch adversarial loss: 0.407290\n",
      "epoch 107; iter: 0; batch classifier loss: 0.074448; batch adversarial loss: 0.450136\n",
      "epoch 108; iter: 0; batch classifier loss: 0.034429; batch adversarial loss: 0.355564\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039114; batch adversarial loss: 0.426026\n",
      "epoch 110; iter: 0; batch classifier loss: 0.096255; batch adversarial loss: 0.415998\n",
      "epoch 111; iter: 0; batch classifier loss: 0.021715; batch adversarial loss: 0.403128\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040001; batch adversarial loss: 0.425254\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037535; batch adversarial loss: 0.368078\n",
      "epoch 114; iter: 0; batch classifier loss: 0.045991; batch adversarial loss: 0.406517\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053192; batch adversarial loss: 0.433984\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028801; batch adversarial loss: 0.417342\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027560; batch adversarial loss: 0.461694\n",
      "epoch 118; iter: 0; batch classifier loss: 0.077794; batch adversarial loss: 0.432818\n",
      "epoch 119; iter: 0; batch classifier loss: 0.027628; batch adversarial loss: 0.400019\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022610; batch adversarial loss: 0.402717\n",
      "epoch 121; iter: 0; batch classifier loss: 0.061123; batch adversarial loss: 0.430325\n",
      "epoch 122; iter: 0; batch classifier loss: 0.081833; batch adversarial loss: 0.385257\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031888; batch adversarial loss: 0.386987\n",
      "epoch 124; iter: 0; batch classifier loss: 0.065614; batch adversarial loss: 0.440649\n",
      "epoch 125; iter: 0; batch classifier loss: 0.071805; batch adversarial loss: 0.481061\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042714; batch adversarial loss: 0.395215\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022853; batch adversarial loss: 0.330181\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035399; batch adversarial loss: 0.450552\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036735; batch adversarial loss: 0.463364\n",
      "epoch 130; iter: 0; batch classifier loss: 0.063603; batch adversarial loss: 0.461946\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015246; batch adversarial loss: 0.430682\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026077; batch adversarial loss: 0.381969\n",
      "epoch 133; iter: 0; batch classifier loss: 0.075309; batch adversarial loss: 0.346276\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033266; batch adversarial loss: 0.450472\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038600; batch adversarial loss: 0.517677\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025400; batch adversarial loss: 0.397601\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037759; batch adversarial loss: 0.404198\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021507; batch adversarial loss: 0.521139\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040370; batch adversarial loss: 0.438455\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032661; batch adversarial loss: 0.499759\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025169; batch adversarial loss: 0.489658\n",
      "epoch 142; iter: 0; batch classifier loss: 0.062357; batch adversarial loss: 0.461368\n",
      "epoch 143; iter: 0; batch classifier loss: 0.056122; batch adversarial loss: 0.364616\n",
      "epoch 144; iter: 0; batch classifier loss: 0.070285; batch adversarial loss: 0.404424\n",
      "epoch 145; iter: 0; batch classifier loss: 0.071042; batch adversarial loss: 0.418574\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018831; batch adversarial loss: 0.404559\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028776; batch adversarial loss: 0.466956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.012871; batch adversarial loss: 0.560311\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039935; batch adversarial loss: 0.465839\n",
      "epoch 150; iter: 0; batch classifier loss: 0.046934; batch adversarial loss: 0.437889\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022452; batch adversarial loss: 0.421738\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030580; batch adversarial loss: 0.271912\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029650; batch adversarial loss: 0.415870\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032919; batch adversarial loss: 0.444693\n",
      "epoch 155; iter: 0; batch classifier loss: 0.039678; batch adversarial loss: 0.430179\n",
      "epoch 156; iter: 0; batch classifier loss: 0.071390; batch adversarial loss: 0.402921\n",
      "epoch 157; iter: 0; batch classifier loss: 0.006461; batch adversarial loss: 0.427095\n",
      "epoch 158; iter: 0; batch classifier loss: 0.041652; batch adversarial loss: 0.445521\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023559; batch adversarial loss: 0.409113\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015887; batch adversarial loss: 0.469421\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013549; batch adversarial loss: 0.525905\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030742; batch adversarial loss: 0.402639\n",
      "epoch 163; iter: 0; batch classifier loss: 0.051584; batch adversarial loss: 0.421695\n",
      "epoch 164; iter: 0; batch classifier loss: 0.058071; batch adversarial loss: 0.509181\n",
      "epoch 165; iter: 0; batch classifier loss: 0.106091; batch adversarial loss: 0.352568\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028900; batch adversarial loss: 0.474555\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019931; batch adversarial loss: 0.444089\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016393; batch adversarial loss: 0.446655\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013075; batch adversarial loss: 0.438776\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027142; batch adversarial loss: 0.519281\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017902; batch adversarial loss: 0.324992\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036366; batch adversarial loss: 0.421577\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027156; batch adversarial loss: 0.446385\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028484; batch adversarial loss: 0.473924\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018972; batch adversarial loss: 0.422871\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016384; batch adversarial loss: 0.415323\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024511; batch adversarial loss: 0.401478\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017520; batch adversarial loss: 0.503957\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043467; batch adversarial loss: 0.455765\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014485; batch adversarial loss: 0.431714\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011025; batch adversarial loss: 0.413208\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028597; batch adversarial loss: 0.452838\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012040; batch adversarial loss: 0.440251\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008303; batch adversarial loss: 0.417924\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036542; batch adversarial loss: 0.500233\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030175; batch adversarial loss: 0.440059\n",
      "epoch 187; iter: 0; batch classifier loss: 0.060834; batch adversarial loss: 0.344121\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023639; batch adversarial loss: 0.469517\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023182; batch adversarial loss: 0.425196\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037796; batch adversarial loss: 0.407725\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007859; batch adversarial loss: 0.428779\n",
      "epoch 192; iter: 0; batch classifier loss: 0.046342; batch adversarial loss: 0.425102\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023188; batch adversarial loss: 0.519409\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015678; batch adversarial loss: 0.381773\n",
      "epoch 195; iter: 0; batch classifier loss: 0.040485; batch adversarial loss: 0.423937\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012706; batch adversarial loss: 0.547793\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018676; batch adversarial loss: 0.512359\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014741; batch adversarial loss: 0.473504\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020291; batch adversarial loss: 0.476656\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710374; batch adversarial loss: 0.961885\n",
      "epoch 1; iter: 0; batch classifier loss: 0.639203; batch adversarial loss: 1.051397\n",
      "epoch 2; iter: 0; batch classifier loss: 0.915408; batch adversarial loss: 1.130206\n",
      "epoch 3; iter: 0; batch classifier loss: 1.005932; batch adversarial loss: 1.024538\n",
      "epoch 4; iter: 0; batch classifier loss: 1.053102; batch adversarial loss: 0.929164\n",
      "epoch 5; iter: 0; batch classifier loss: 1.194167; batch adversarial loss: 0.870834\n",
      "epoch 6; iter: 0; batch classifier loss: 1.072257; batch adversarial loss: 0.770621\n",
      "epoch 7; iter: 0; batch classifier loss: 0.984284; batch adversarial loss: 0.691274\n",
      "epoch 8; iter: 0; batch classifier loss: 0.842409; batch adversarial loss: 0.681798\n",
      "epoch 9; iter: 0; batch classifier loss: 0.694962; batch adversarial loss: 0.590249\n",
      "epoch 10; iter: 0; batch classifier loss: 0.554136; batch adversarial loss: 0.546044\n",
      "epoch 11; iter: 0; batch classifier loss: 0.416880; batch adversarial loss: 0.524179\n",
      "epoch 12; iter: 0; batch classifier loss: 0.326674; batch adversarial loss: 0.506034\n",
      "epoch 13; iter: 0; batch classifier loss: 0.336473; batch adversarial loss: 0.472978\n",
      "epoch 14; iter: 0; batch classifier loss: 0.330541; batch adversarial loss: 0.483944\n",
      "epoch 15; iter: 0; batch classifier loss: 0.244780; batch adversarial loss: 0.503671\n",
      "epoch 16; iter: 0; batch classifier loss: 0.254850; batch adversarial loss: 0.502825\n",
      "epoch 17; iter: 0; batch classifier loss: 0.296955; batch adversarial loss: 0.520149\n",
      "epoch 18; iter: 0; batch classifier loss: 0.273363; batch adversarial loss: 0.479814\n",
      "epoch 19; iter: 0; batch classifier loss: 0.224355; batch adversarial loss: 0.481836\n",
      "epoch 20; iter: 0; batch classifier loss: 0.194982; batch adversarial loss: 0.590236\n",
      "epoch 21; iter: 0; batch classifier loss: 0.190016; batch adversarial loss: 0.511034\n",
      "epoch 22; iter: 0; batch classifier loss: 0.241241; batch adversarial loss: 0.496790\n",
      "epoch 23; iter: 0; batch classifier loss: 0.181963; batch adversarial loss: 0.449468\n",
      "epoch 24; iter: 0; batch classifier loss: 0.178268; batch adversarial loss: 0.457581\n",
      "epoch 25; iter: 0; batch classifier loss: 0.209942; batch adversarial loss: 0.523168\n",
      "epoch 26; iter: 0; batch classifier loss: 0.233866; batch adversarial loss: 0.447272\n",
      "epoch 27; iter: 0; batch classifier loss: 0.244023; batch adversarial loss: 0.471219\n",
      "epoch 28; iter: 0; batch classifier loss: 0.227241; batch adversarial loss: 0.472547\n",
      "epoch 29; iter: 0; batch classifier loss: 0.186836; batch adversarial loss: 0.465175\n",
      "epoch 30; iter: 0; batch classifier loss: 0.231385; batch adversarial loss: 0.529968\n",
      "epoch 31; iter: 0; batch classifier loss: 0.186554; batch adversarial loss: 0.400810\n",
      "epoch 32; iter: 0; batch classifier loss: 0.182955; batch adversarial loss: 0.426787\n",
      "epoch 33; iter: 0; batch classifier loss: 0.235186; batch adversarial loss: 0.493695\n",
      "epoch 34; iter: 0; batch classifier loss: 0.191152; batch adversarial loss: 0.436825\n",
      "epoch 35; iter: 0; batch classifier loss: 0.151932; batch adversarial loss: 0.543680\n",
      "epoch 36; iter: 0; batch classifier loss: 0.176897; batch adversarial loss: 0.439264\n",
      "epoch 37; iter: 0; batch classifier loss: 0.128820; batch adversarial loss: 0.413561\n",
      "epoch 38; iter: 0; batch classifier loss: 0.152219; batch adversarial loss: 0.411059\n",
      "epoch 39; iter: 0; batch classifier loss: 0.182243; batch adversarial loss: 0.465871\n",
      "epoch 40; iter: 0; batch classifier loss: 0.123915; batch adversarial loss: 0.443201\n",
      "epoch 41; iter: 0; batch classifier loss: 0.146928; batch adversarial loss: 0.410161\n",
      "epoch 42; iter: 0; batch classifier loss: 0.144145; batch adversarial loss: 0.481598\n",
      "epoch 43; iter: 0; batch classifier loss: 0.102256; batch adversarial loss: 0.502977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.137080; batch adversarial loss: 0.451145\n",
      "epoch 45; iter: 0; batch classifier loss: 0.188784; batch adversarial loss: 0.398516\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117137; batch adversarial loss: 0.430235\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112318; batch adversarial loss: 0.439224\n",
      "epoch 48; iter: 0; batch classifier loss: 0.112587; batch adversarial loss: 0.552536\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113990; batch adversarial loss: 0.413812\n",
      "epoch 50; iter: 0; batch classifier loss: 0.134763; batch adversarial loss: 0.424654\n",
      "epoch 51; iter: 0; batch classifier loss: 0.074344; batch adversarial loss: 0.476052\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100441; batch adversarial loss: 0.509699\n",
      "epoch 53; iter: 0; batch classifier loss: 0.083449; batch adversarial loss: 0.431224\n",
      "epoch 54; iter: 0; batch classifier loss: 0.093919; batch adversarial loss: 0.501677\n",
      "epoch 55; iter: 0; batch classifier loss: 0.146596; batch adversarial loss: 0.487769\n",
      "epoch 56; iter: 0; batch classifier loss: 0.141230; batch adversarial loss: 0.427884\n",
      "epoch 57; iter: 0; batch classifier loss: 0.115131; batch adversarial loss: 0.449709\n",
      "epoch 58; iter: 0; batch classifier loss: 0.053355; batch adversarial loss: 0.516830\n",
      "epoch 59; iter: 0; batch classifier loss: 0.111213; batch adversarial loss: 0.408072\n",
      "epoch 60; iter: 0; batch classifier loss: 0.078303; batch adversarial loss: 0.476015\n",
      "epoch 61; iter: 0; batch classifier loss: 0.128263; batch adversarial loss: 0.381241\n",
      "epoch 62; iter: 0; batch classifier loss: 0.091148; batch adversarial loss: 0.557979\n",
      "epoch 63; iter: 0; batch classifier loss: 0.063224; batch adversarial loss: 0.437660\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090583; batch adversarial loss: 0.434779\n",
      "epoch 65; iter: 0; batch classifier loss: 0.032440; batch adversarial loss: 0.562378\n",
      "epoch 66; iter: 0; batch classifier loss: 0.042629; batch adversarial loss: 0.508720\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061909; batch adversarial loss: 0.457238\n",
      "epoch 68; iter: 0; batch classifier loss: 0.114908; batch adversarial loss: 0.378267\n",
      "epoch 69; iter: 0; batch classifier loss: 0.069862; batch adversarial loss: 0.402957\n",
      "epoch 70; iter: 0; batch classifier loss: 0.075969; batch adversarial loss: 0.389535\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078748; batch adversarial loss: 0.487169\n",
      "epoch 72; iter: 0; batch classifier loss: 0.065454; batch adversarial loss: 0.474894\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101365; batch adversarial loss: 0.491733\n",
      "epoch 74; iter: 0; batch classifier loss: 0.084586; batch adversarial loss: 0.496473\n",
      "epoch 75; iter: 0; batch classifier loss: 0.056400; batch adversarial loss: 0.432920\n",
      "epoch 76; iter: 0; batch classifier loss: 0.048172; batch adversarial loss: 0.406390\n",
      "epoch 77; iter: 0; batch classifier loss: 0.078312; batch adversarial loss: 0.551031\n",
      "epoch 78; iter: 0; batch classifier loss: 0.114264; batch adversarial loss: 0.445299\n",
      "epoch 79; iter: 0; batch classifier loss: 0.041262; batch adversarial loss: 0.467507\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068102; batch adversarial loss: 0.459230\n",
      "epoch 81; iter: 0; batch classifier loss: 0.047556; batch adversarial loss: 0.457929\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059164; batch adversarial loss: 0.465470\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035174; batch adversarial loss: 0.390535\n",
      "epoch 84; iter: 0; batch classifier loss: 0.036695; batch adversarial loss: 0.446105\n",
      "epoch 85; iter: 0; batch classifier loss: 0.044261; batch adversarial loss: 0.460921\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068032; batch adversarial loss: 0.508384\n",
      "epoch 87; iter: 0; batch classifier loss: 0.061069; batch adversarial loss: 0.434518\n",
      "epoch 88; iter: 0; batch classifier loss: 0.046733; batch adversarial loss: 0.451102\n",
      "epoch 89; iter: 0; batch classifier loss: 0.078646; batch adversarial loss: 0.470879\n",
      "epoch 90; iter: 0; batch classifier loss: 0.049270; batch adversarial loss: 0.455329\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045294; batch adversarial loss: 0.406374\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058553; batch adversarial loss: 0.528520\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036339; batch adversarial loss: 0.455810\n",
      "epoch 94; iter: 0; batch classifier loss: 0.028546; batch adversarial loss: 0.418236\n",
      "epoch 95; iter: 0; batch classifier loss: 0.039413; batch adversarial loss: 0.568081\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037023; batch adversarial loss: 0.476587\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056705; batch adversarial loss: 0.440687\n",
      "epoch 98; iter: 0; batch classifier loss: 0.017533; batch adversarial loss: 0.485224\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040668; batch adversarial loss: 0.541709\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050445; batch adversarial loss: 0.412540\n",
      "epoch 101; iter: 0; batch classifier loss: 0.028029; batch adversarial loss: 0.379454\n",
      "epoch 102; iter: 0; batch classifier loss: 0.027161; batch adversarial loss: 0.406001\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036682; batch adversarial loss: 0.395881\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039626; batch adversarial loss: 0.486177\n",
      "epoch 105; iter: 0; batch classifier loss: 0.026374; batch adversarial loss: 0.494559\n",
      "epoch 106; iter: 0; batch classifier loss: 0.015702; batch adversarial loss: 0.392135\n",
      "epoch 107; iter: 0; batch classifier loss: 0.020876; batch adversarial loss: 0.479205\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045638; batch adversarial loss: 0.485792\n",
      "epoch 109; iter: 0; batch classifier loss: 0.020310; batch adversarial loss: 0.484154\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045561; batch adversarial loss: 0.417088\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042672; batch adversarial loss: 0.369130\n",
      "epoch 112; iter: 0; batch classifier loss: 0.010452; batch adversarial loss: 0.455779\n",
      "epoch 113; iter: 0; batch classifier loss: 0.016954; batch adversarial loss: 0.409480\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054593; batch adversarial loss: 0.468241\n",
      "epoch 115; iter: 0; batch classifier loss: 0.011677; batch adversarial loss: 0.436760\n",
      "epoch 116; iter: 0; batch classifier loss: 0.019985; batch adversarial loss: 0.361889\n",
      "epoch 117; iter: 0; batch classifier loss: 0.019014; batch adversarial loss: 0.410055\n",
      "epoch 118; iter: 0; batch classifier loss: 0.021367; batch adversarial loss: 0.334571\n",
      "epoch 119; iter: 0; batch classifier loss: 0.058008; batch adversarial loss: 0.473055\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037110; batch adversarial loss: 0.384723\n",
      "epoch 121; iter: 0; batch classifier loss: 0.019972; batch adversarial loss: 0.410705\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041773; batch adversarial loss: 0.410632\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029573; batch adversarial loss: 0.475352\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052409; batch adversarial loss: 0.386566\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018906; batch adversarial loss: 0.474963\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035017; batch adversarial loss: 0.453791\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026881; batch adversarial loss: 0.380016\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017265; batch adversarial loss: 0.488767\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026214; batch adversarial loss: 0.379999\n",
      "epoch 130; iter: 0; batch classifier loss: 0.015265; batch adversarial loss: 0.479736\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042550; batch adversarial loss: 0.374619\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038617; batch adversarial loss: 0.322726\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027424; batch adversarial loss: 0.411258\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016963; batch adversarial loss: 0.458180\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047169; batch adversarial loss: 0.450210\n",
      "epoch 136; iter: 0; batch classifier loss: 0.014275; batch adversarial loss: 0.368267\n",
      "epoch 137; iter: 0; batch classifier loss: 0.071208; batch adversarial loss: 0.483838\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017441; batch adversarial loss: 0.404666\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020381; batch adversarial loss: 0.476772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.036352; batch adversarial loss: 0.447625\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026889; batch adversarial loss: 0.386252\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033160; batch adversarial loss: 0.493396\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024657; batch adversarial loss: 0.462487\n",
      "epoch 144; iter: 0; batch classifier loss: 0.015977; batch adversarial loss: 0.415194\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022264; batch adversarial loss: 0.410192\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051594; batch adversarial loss: 0.524435\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017013; batch adversarial loss: 0.469440\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021431; batch adversarial loss: 0.459227\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014378; batch adversarial loss: 0.406998\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028540; batch adversarial loss: 0.405681\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014829; batch adversarial loss: 0.484824\n",
      "epoch 152; iter: 0; batch classifier loss: 0.007325; batch adversarial loss: 0.487799\n",
      "epoch 153; iter: 0; batch classifier loss: 0.003746; batch adversarial loss: 0.412228\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031611; batch adversarial loss: 0.413178\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011111; batch adversarial loss: 0.451242\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032395; batch adversarial loss: 0.451746\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033063; batch adversarial loss: 0.438143\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013179; batch adversarial loss: 0.489243\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029046; batch adversarial loss: 0.373859\n",
      "epoch 160; iter: 0; batch classifier loss: 0.048536; batch adversarial loss: 0.490035\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027668; batch adversarial loss: 0.357353\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038662; batch adversarial loss: 0.419650\n",
      "epoch 163; iter: 0; batch classifier loss: 0.005611; batch adversarial loss: 0.401808\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013991; batch adversarial loss: 0.430214\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010353; batch adversarial loss: 0.400395\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024878; batch adversarial loss: 0.471197\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022723; batch adversarial loss: 0.452820\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010313; batch adversarial loss: 0.412581\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031371; batch adversarial loss: 0.477502\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022668; batch adversarial loss: 0.461158\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029005; batch adversarial loss: 0.449360\n",
      "epoch 172; iter: 0; batch classifier loss: 0.053521; batch adversarial loss: 0.487971\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014802; batch adversarial loss: 0.448071\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007560; batch adversarial loss: 0.532738\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011628; batch adversarial loss: 0.345164\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020397; batch adversarial loss: 0.423045\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012289; batch adversarial loss: 0.417636\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031389; batch adversarial loss: 0.433086\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020852; batch adversarial loss: 0.377665\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024427; batch adversarial loss: 0.432789\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008715; batch adversarial loss: 0.431367\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023620; batch adversarial loss: 0.371250\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013477; batch adversarial loss: 0.454292\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004717; batch adversarial loss: 0.430535\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006891; batch adversarial loss: 0.415332\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030408; batch adversarial loss: 0.430989\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019144; batch adversarial loss: 0.435841\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007130; batch adversarial loss: 0.411085\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016762; batch adversarial loss: 0.513735\n",
      "epoch 190; iter: 0; batch classifier loss: 0.003299; batch adversarial loss: 0.349553\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011799; batch adversarial loss: 0.342457\n",
      "epoch 192; iter: 0; batch classifier loss: 0.034949; batch adversarial loss: 0.491900\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007983; batch adversarial loss: 0.523245\n",
      "epoch 194; iter: 0; batch classifier loss: 0.003894; batch adversarial loss: 0.508160\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021301; batch adversarial loss: 0.556490\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008504; batch adversarial loss: 0.388109\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013571; batch adversarial loss: 0.472875\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026493; batch adversarial loss: 0.496223\n",
      "epoch 199; iter: 0; batch classifier loss: 0.056330; batch adversarial loss: 0.543567\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678800; batch adversarial loss: 0.542160\n",
      "epoch 1; iter: 0; batch classifier loss: 0.472402; batch adversarial loss: 0.560485\n",
      "epoch 2; iter: 0; batch classifier loss: 0.367869; batch adversarial loss: 0.627825\n",
      "epoch 3; iter: 0; batch classifier loss: 0.336583; batch adversarial loss: 0.618656\n",
      "epoch 4; iter: 0; batch classifier loss: 0.390982; batch adversarial loss: 0.524055\n",
      "epoch 5; iter: 0; batch classifier loss: 0.344732; batch adversarial loss: 0.489994\n",
      "epoch 6; iter: 0; batch classifier loss: 0.385601; batch adversarial loss: 0.522710\n",
      "epoch 7; iter: 0; batch classifier loss: 0.322656; batch adversarial loss: 0.530034\n",
      "epoch 8; iter: 0; batch classifier loss: 0.305246; batch adversarial loss: 0.564427\n",
      "epoch 9; iter: 0; batch classifier loss: 0.324174; batch adversarial loss: 0.584679\n",
      "epoch 10; iter: 0; batch classifier loss: 0.291845; batch adversarial loss: 0.503051\n",
      "epoch 11; iter: 0; batch classifier loss: 0.388931; batch adversarial loss: 0.548956\n",
      "epoch 12; iter: 0; batch classifier loss: 0.308550; batch adversarial loss: 0.453695\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448647; batch adversarial loss: 0.611819\n",
      "epoch 14; iter: 0; batch classifier loss: 0.448070; batch adversarial loss: 0.484200\n",
      "epoch 15; iter: 0; batch classifier loss: 0.546739; batch adversarial loss: 0.500822\n",
      "epoch 16; iter: 0; batch classifier loss: 0.473123; batch adversarial loss: 0.471326\n",
      "epoch 17; iter: 0; batch classifier loss: 0.352930; batch adversarial loss: 0.476821\n",
      "epoch 18; iter: 0; batch classifier loss: 0.271618; batch adversarial loss: 0.501398\n",
      "epoch 19; iter: 0; batch classifier loss: 0.226162; batch adversarial loss: 0.453960\n",
      "epoch 20; iter: 0; batch classifier loss: 0.215044; batch adversarial loss: 0.384339\n",
      "epoch 21; iter: 0; batch classifier loss: 0.290589; batch adversarial loss: 0.387752\n",
      "epoch 22; iter: 0; batch classifier loss: 0.213860; batch adversarial loss: 0.525440\n",
      "epoch 23; iter: 0; batch classifier loss: 0.186456; batch adversarial loss: 0.431455\n",
      "epoch 24; iter: 0; batch classifier loss: 0.168910; batch adversarial loss: 0.513456\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215317; batch adversarial loss: 0.458392\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208410; batch adversarial loss: 0.383180\n",
      "epoch 27; iter: 0; batch classifier loss: 0.202470; batch adversarial loss: 0.416464\n",
      "epoch 28; iter: 0; batch classifier loss: 0.135687; batch adversarial loss: 0.454649\n",
      "epoch 29; iter: 0; batch classifier loss: 0.198237; batch adversarial loss: 0.456472\n",
      "epoch 30; iter: 0; batch classifier loss: 0.152079; batch adversarial loss: 0.478698\n",
      "epoch 31; iter: 0; batch classifier loss: 0.200035; batch adversarial loss: 0.512328\n",
      "epoch 32; iter: 0; batch classifier loss: 0.168716; batch adversarial loss: 0.458956\n",
      "epoch 33; iter: 0; batch classifier loss: 0.191433; batch adversarial loss: 0.488576\n",
      "epoch 34; iter: 0; batch classifier loss: 0.167630; batch adversarial loss: 0.410193\n",
      "epoch 35; iter: 0; batch classifier loss: 0.120005; batch adversarial loss: 0.424523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.203568; batch adversarial loss: 0.428960\n",
      "epoch 37; iter: 0; batch classifier loss: 0.133033; batch adversarial loss: 0.561125\n",
      "epoch 38; iter: 0; batch classifier loss: 0.162988; batch adversarial loss: 0.470633\n",
      "epoch 39; iter: 0; batch classifier loss: 0.129927; batch adversarial loss: 0.405729\n",
      "epoch 40; iter: 0; batch classifier loss: 0.167766; batch adversarial loss: 0.506668\n",
      "epoch 41; iter: 0; batch classifier loss: 0.128625; batch adversarial loss: 0.395530\n",
      "epoch 42; iter: 0; batch classifier loss: 0.133278; batch adversarial loss: 0.449265\n",
      "epoch 43; iter: 0; batch classifier loss: 0.145435; batch adversarial loss: 0.460884\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098338; batch adversarial loss: 0.490893\n",
      "epoch 45; iter: 0; batch classifier loss: 0.151015; batch adversarial loss: 0.414733\n",
      "epoch 46; iter: 0; batch classifier loss: 0.161368; batch adversarial loss: 0.416907\n",
      "epoch 47; iter: 0; batch classifier loss: 0.202889; batch adversarial loss: 0.456213\n",
      "epoch 48; iter: 0; batch classifier loss: 0.102362; batch adversarial loss: 0.404111\n",
      "epoch 49; iter: 0; batch classifier loss: 0.155146; batch adversarial loss: 0.475583\n",
      "epoch 50; iter: 0; batch classifier loss: 0.146629; batch adversarial loss: 0.464315\n",
      "epoch 51; iter: 0; batch classifier loss: 0.183560; batch adversarial loss: 0.439119\n",
      "epoch 52; iter: 0; batch classifier loss: 0.172220; batch adversarial loss: 0.367742\n",
      "epoch 53; iter: 0; batch classifier loss: 0.147369; batch adversarial loss: 0.445787\n",
      "epoch 54; iter: 0; batch classifier loss: 0.221271; batch adversarial loss: 0.426423\n",
      "epoch 55; iter: 0; batch classifier loss: 0.189487; batch adversarial loss: 0.440907\n",
      "epoch 56; iter: 0; batch classifier loss: 0.142424; batch adversarial loss: 0.434813\n",
      "epoch 57; iter: 0; batch classifier loss: 0.165287; batch adversarial loss: 0.455446\n",
      "epoch 58; iter: 0; batch classifier loss: 0.197962; batch adversarial loss: 0.433465\n",
      "epoch 59; iter: 0; batch classifier loss: 0.157778; batch adversarial loss: 0.481393\n",
      "epoch 60; iter: 0; batch classifier loss: 0.193279; batch adversarial loss: 0.434526\n",
      "epoch 61; iter: 0; batch classifier loss: 0.174435; batch adversarial loss: 0.459098\n",
      "epoch 62; iter: 0; batch classifier loss: 0.146892; batch adversarial loss: 0.397250\n",
      "epoch 63; iter: 0; batch classifier loss: 0.129336; batch adversarial loss: 0.434226\n",
      "epoch 64; iter: 0; batch classifier loss: 0.227141; batch adversarial loss: 0.452171\n",
      "epoch 65; iter: 0; batch classifier loss: 0.139676; batch adversarial loss: 0.454290\n",
      "epoch 66; iter: 0; batch classifier loss: 0.187242; batch adversarial loss: 0.547182\n",
      "epoch 67; iter: 0; batch classifier loss: 0.184467; batch adversarial loss: 0.374669\n",
      "epoch 68; iter: 0; batch classifier loss: 0.147574; batch adversarial loss: 0.421156\n",
      "epoch 69; iter: 0; batch classifier loss: 0.204568; batch adversarial loss: 0.447407\n",
      "epoch 70; iter: 0; batch classifier loss: 0.180982; batch adversarial loss: 0.413688\n",
      "epoch 71; iter: 0; batch classifier loss: 0.267200; batch adversarial loss: 0.440307\n",
      "epoch 72; iter: 0; batch classifier loss: 0.243008; batch adversarial loss: 0.479188\n",
      "epoch 73; iter: 0; batch classifier loss: 0.220945; batch adversarial loss: 0.396925\n",
      "epoch 74; iter: 0; batch classifier loss: 0.218958; batch adversarial loss: 0.458578\n",
      "epoch 75; iter: 0; batch classifier loss: 0.165884; batch adversarial loss: 0.520412\n",
      "epoch 76; iter: 0; batch classifier loss: 0.196803; batch adversarial loss: 0.412179\n",
      "epoch 77; iter: 0; batch classifier loss: 0.185789; batch adversarial loss: 0.483091\n",
      "epoch 78; iter: 0; batch classifier loss: 0.152034; batch adversarial loss: 0.450331\n",
      "epoch 79; iter: 0; batch classifier loss: 0.226885; batch adversarial loss: 0.420120\n",
      "epoch 80; iter: 0; batch classifier loss: 0.200715; batch adversarial loss: 0.520659\n",
      "epoch 81; iter: 0; batch classifier loss: 0.246253; batch adversarial loss: 0.394713\n",
      "epoch 82; iter: 0; batch classifier loss: 0.207508; batch adversarial loss: 0.383891\n",
      "epoch 83; iter: 0; batch classifier loss: 0.223723; batch adversarial loss: 0.399096\n",
      "epoch 84; iter: 0; batch classifier loss: 0.192645; batch adversarial loss: 0.398735\n",
      "epoch 85; iter: 0; batch classifier loss: 0.175940; batch adversarial loss: 0.458371\n",
      "epoch 86; iter: 0; batch classifier loss: 0.228745; batch adversarial loss: 0.409218\n",
      "epoch 87; iter: 0; batch classifier loss: 0.163532; batch adversarial loss: 0.483457\n",
      "epoch 88; iter: 0; batch classifier loss: 0.275661; batch adversarial loss: 0.521206\n",
      "epoch 89; iter: 0; batch classifier loss: 0.288772; batch adversarial loss: 0.361203\n",
      "epoch 90; iter: 0; batch classifier loss: 0.192738; batch adversarial loss: 0.507568\n",
      "epoch 91; iter: 0; batch classifier loss: 0.252080; batch adversarial loss: 0.372929\n",
      "epoch 92; iter: 0; batch classifier loss: 0.215333; batch adversarial loss: 0.409321\n",
      "epoch 93; iter: 0; batch classifier loss: 0.174448; batch adversarial loss: 0.483413\n",
      "epoch 94; iter: 0; batch classifier loss: 0.154551; batch adversarial loss: 0.508241\n",
      "epoch 95; iter: 0; batch classifier loss: 0.222158; batch adversarial loss: 0.508743\n",
      "epoch 96; iter: 0; batch classifier loss: 0.231837; batch adversarial loss: 0.372074\n",
      "epoch 97; iter: 0; batch classifier loss: 0.202871; batch adversarial loss: 0.557832\n",
      "epoch 98; iter: 0; batch classifier loss: 0.226095; batch adversarial loss: 0.483027\n",
      "epoch 99; iter: 0; batch classifier loss: 0.254096; batch adversarial loss: 0.421744\n",
      "epoch 100; iter: 0; batch classifier loss: 0.193836; batch adversarial loss: 0.446443\n",
      "epoch 101; iter: 0; batch classifier loss: 0.114767; batch adversarial loss: 0.520689\n",
      "epoch 102; iter: 0; batch classifier loss: 0.099254; batch adversarial loss: 0.505660\n",
      "epoch 103; iter: 0; batch classifier loss: 0.093158; batch adversarial loss: 0.417291\n",
      "epoch 104; iter: 0; batch classifier loss: 0.205602; batch adversarial loss: 0.380669\n",
      "epoch 105; iter: 0; batch classifier loss: 0.142970; batch adversarial loss: 0.459810\n",
      "epoch 106; iter: 0; batch classifier loss: 0.207177; batch adversarial loss: 0.530789\n",
      "epoch 107; iter: 0; batch classifier loss: 0.204406; batch adversarial loss: 0.384769\n",
      "epoch 108; iter: 0; batch classifier loss: 0.221220; batch adversarial loss: 0.518966\n",
      "epoch 109; iter: 0; batch classifier loss: 0.232748; batch adversarial loss: 0.371060\n",
      "epoch 110; iter: 0; batch classifier loss: 0.242575; batch adversarial loss: 0.423657\n",
      "epoch 111; iter: 0; batch classifier loss: 0.208372; batch adversarial loss: 0.371173\n",
      "epoch 112; iter: 0; batch classifier loss: 0.188678; batch adversarial loss: 0.491187\n",
      "epoch 113; iter: 0; batch classifier loss: 0.164975; batch adversarial loss: 0.482781\n",
      "epoch 114; iter: 0; batch classifier loss: 0.201442; batch adversarial loss: 0.364137\n",
      "epoch 115; iter: 0; batch classifier loss: 0.196615; batch adversarial loss: 0.361474\n",
      "epoch 116; iter: 0; batch classifier loss: 0.186564; batch adversarial loss: 0.436380\n",
      "epoch 117; iter: 0; batch classifier loss: 0.236837; batch adversarial loss: 0.433635\n",
      "epoch 118; iter: 0; batch classifier loss: 0.220303; batch adversarial loss: 0.508990\n",
      "epoch 119; iter: 0; batch classifier loss: 0.204644; batch adversarial loss: 0.445327\n",
      "epoch 120; iter: 0; batch classifier loss: 0.202299; batch adversarial loss: 0.471467\n",
      "epoch 121; iter: 0; batch classifier loss: 0.218803; batch adversarial loss: 0.484128\n",
      "epoch 122; iter: 0; batch classifier loss: 0.180380; batch adversarial loss: 0.517988\n",
      "epoch 123; iter: 0; batch classifier loss: 0.141785; batch adversarial loss: 0.520578\n",
      "epoch 124; iter: 0; batch classifier loss: 0.205579; batch adversarial loss: 0.459042\n",
      "epoch 125; iter: 0; batch classifier loss: 0.221564; batch adversarial loss: 0.508419\n",
      "epoch 126; iter: 0; batch classifier loss: 0.200777; batch adversarial loss: 0.496675\n",
      "epoch 127; iter: 0; batch classifier loss: 0.162906; batch adversarial loss: 0.435000\n",
      "epoch 128; iter: 0; batch classifier loss: 0.169036; batch adversarial loss: 0.384742\n",
      "epoch 129; iter: 0; batch classifier loss: 0.240833; batch adversarial loss: 0.544564\n",
      "epoch 130; iter: 0; batch classifier loss: 0.184590; batch adversarial loss: 0.434522\n",
      "epoch 131; iter: 0; batch classifier loss: 0.192197; batch adversarial loss: 0.422256\n",
      "epoch 132; iter: 0; batch classifier loss: 0.274815; batch adversarial loss: 0.335681\n",
      "epoch 133; iter: 0; batch classifier loss: 0.191943; batch adversarial loss: 0.397119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.180340; batch adversarial loss: 0.496219\n",
      "epoch 135; iter: 0; batch classifier loss: 0.220944; batch adversarial loss: 0.446724\n",
      "epoch 136; iter: 0; batch classifier loss: 0.227568; batch adversarial loss: 0.434426\n",
      "epoch 137; iter: 0; batch classifier loss: 0.187698; batch adversarial loss: 0.446573\n",
      "epoch 138; iter: 0; batch classifier loss: 0.218750; batch adversarial loss: 0.470667\n",
      "epoch 139; iter: 0; batch classifier loss: 0.170691; batch adversarial loss: 0.433541\n",
      "epoch 140; iter: 0; batch classifier loss: 0.231676; batch adversarial loss: 0.470954\n",
      "epoch 141; iter: 0; batch classifier loss: 0.296022; batch adversarial loss: 0.508004\n",
      "epoch 142; iter: 0; batch classifier loss: 0.192547; batch adversarial loss: 0.482583\n",
      "epoch 143; iter: 0; batch classifier loss: 0.171200; batch adversarial loss: 0.459010\n",
      "epoch 144; iter: 0; batch classifier loss: 0.155698; batch adversarial loss: 0.408994\n",
      "epoch 145; iter: 0; batch classifier loss: 0.190286; batch adversarial loss: 0.472069\n",
      "epoch 146; iter: 0; batch classifier loss: 0.156339; batch adversarial loss: 0.434057\n",
      "epoch 147; iter: 0; batch classifier loss: 0.187167; batch adversarial loss: 0.458752\n",
      "epoch 148; iter: 0; batch classifier loss: 0.180940; batch adversarial loss: 0.445717\n",
      "epoch 149; iter: 0; batch classifier loss: 0.189682; batch adversarial loss: 0.470936\n",
      "epoch 150; iter: 0; batch classifier loss: 0.192925; batch adversarial loss: 0.421659\n",
      "epoch 151; iter: 0; batch classifier loss: 0.169305; batch adversarial loss: 0.508350\n",
      "epoch 152; iter: 0; batch classifier loss: 0.150979; batch adversarial loss: 0.496088\n",
      "epoch 153; iter: 0; batch classifier loss: 0.190952; batch adversarial loss: 0.409623\n",
      "epoch 154; iter: 0; batch classifier loss: 0.191252; batch adversarial loss: 0.546354\n",
      "epoch 155; iter: 0; batch classifier loss: 0.204811; batch adversarial loss: 0.447131\n",
      "epoch 156; iter: 0; batch classifier loss: 0.149160; batch adversarial loss: 0.521157\n",
      "epoch 157; iter: 0; batch classifier loss: 0.124713; batch adversarial loss: 0.459116\n",
      "epoch 158; iter: 0; batch classifier loss: 0.191754; batch adversarial loss: 0.384192\n",
      "epoch 159; iter: 0; batch classifier loss: 0.191181; batch adversarial loss: 0.458780\n",
      "epoch 160; iter: 0; batch classifier loss: 0.209892; batch adversarial loss: 0.469568\n",
      "epoch 161; iter: 0; batch classifier loss: 0.194693; batch adversarial loss: 0.384578\n",
      "epoch 162; iter: 0; batch classifier loss: 0.153374; batch adversarial loss: 0.383542\n",
      "epoch 163; iter: 0; batch classifier loss: 0.193889; batch adversarial loss: 0.495996\n",
      "epoch 164; iter: 0; batch classifier loss: 0.123661; batch adversarial loss: 0.406169\n",
      "epoch 165; iter: 0; batch classifier loss: 0.115225; batch adversarial loss: 0.417966\n",
      "epoch 166; iter: 0; batch classifier loss: 0.106321; batch adversarial loss: 0.407043\n",
      "epoch 167; iter: 0; batch classifier loss: 0.086485; batch adversarial loss: 0.478782\n",
      "epoch 168; iter: 0; batch classifier loss: 0.071187; batch adversarial loss: 0.491313\n",
      "epoch 169; iter: 0; batch classifier loss: 0.062192; batch adversarial loss: 0.473917\n",
      "epoch 170; iter: 0; batch classifier loss: 0.043179; batch adversarial loss: 0.497241\n",
      "epoch 171; iter: 0; batch classifier loss: 0.063891; batch adversarial loss: 0.435922\n",
      "epoch 172; iter: 0; batch classifier loss: 0.079492; batch adversarial loss: 0.466062\n",
      "epoch 173; iter: 0; batch classifier loss: 0.060695; batch adversarial loss: 0.418096\n",
      "epoch 174; iter: 0; batch classifier loss: 0.057454; batch adversarial loss: 0.504448\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040008; batch adversarial loss: 0.390704\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030024; batch adversarial loss: 0.524983\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030286; batch adversarial loss: 0.508352\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025263; batch adversarial loss: 0.501948\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035881; batch adversarial loss: 0.395284\n",
      "epoch 180; iter: 0; batch classifier loss: 0.048930; batch adversarial loss: 0.434262\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027506; batch adversarial loss: 0.370967\n",
      "epoch 182; iter: 0; batch classifier loss: 0.046957; batch adversarial loss: 0.425637\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033545; batch adversarial loss: 0.455540\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023029; batch adversarial loss: 0.443425\n",
      "epoch 185; iter: 0; batch classifier loss: 0.053141; batch adversarial loss: 0.447409\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019725; batch adversarial loss: 0.426559\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022589; batch adversarial loss: 0.455143\n",
      "epoch 188; iter: 0; batch classifier loss: 0.061743; batch adversarial loss: 0.508421\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034874; batch adversarial loss: 0.590424\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028816; batch adversarial loss: 0.492155\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025947; batch adversarial loss: 0.475407\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035335; batch adversarial loss: 0.501540\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026586; batch adversarial loss: 0.567846\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031539; batch adversarial loss: 0.429983\n",
      "epoch 195; iter: 0; batch classifier loss: 0.046459; batch adversarial loss: 0.487724\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016272; batch adversarial loss: 0.463311\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014323; batch adversarial loss: 0.556045\n",
      "epoch 198; iter: 0; batch classifier loss: 0.033065; batch adversarial loss: 0.401876\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021317; batch adversarial loss: 0.436560\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692660; batch adversarial loss: 0.863978\n",
      "epoch 1; iter: 0; batch classifier loss: 0.770835; batch adversarial loss: 1.035744\n",
      "epoch 2; iter: 0; batch classifier loss: 0.881915; batch adversarial loss: 0.970392\n",
      "epoch 3; iter: 0; batch classifier loss: 0.811034; batch adversarial loss: 0.831203\n",
      "epoch 4; iter: 0; batch classifier loss: 0.849670; batch adversarial loss: 0.796100\n",
      "epoch 5; iter: 0; batch classifier loss: 0.658662; batch adversarial loss: 0.696080\n",
      "epoch 6; iter: 0; batch classifier loss: 0.691402; batch adversarial loss: 0.673642\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559906; batch adversarial loss: 0.646385\n",
      "epoch 8; iter: 0; batch classifier loss: 0.432579; batch adversarial loss: 0.559204\n",
      "epoch 9; iter: 0; batch classifier loss: 0.383481; batch adversarial loss: 0.538336\n",
      "epoch 10; iter: 0; batch classifier loss: 0.262140; batch adversarial loss: 0.499348\n",
      "epoch 11; iter: 0; batch classifier loss: 0.362393; batch adversarial loss: 0.526413\n",
      "epoch 12; iter: 0; batch classifier loss: 0.278422; batch adversarial loss: 0.495042\n",
      "epoch 13; iter: 0; batch classifier loss: 0.258074; batch adversarial loss: 0.489344\n",
      "epoch 14; iter: 0; batch classifier loss: 0.199585; batch adversarial loss: 0.513318\n",
      "epoch 15; iter: 0; batch classifier loss: 0.240314; batch adversarial loss: 0.517572\n",
      "epoch 16; iter: 0; batch classifier loss: 0.232460; batch adversarial loss: 0.492995\n",
      "epoch 17; iter: 0; batch classifier loss: 0.245502; batch adversarial loss: 0.495131\n",
      "epoch 18; iter: 0; batch classifier loss: 0.224975; batch adversarial loss: 0.454119\n",
      "epoch 19; iter: 0; batch classifier loss: 0.204723; batch adversarial loss: 0.522484\n",
      "epoch 20; iter: 0; batch classifier loss: 0.164237; batch adversarial loss: 0.489473\n",
      "epoch 21; iter: 0; batch classifier loss: 0.193409; batch adversarial loss: 0.504393\n",
      "epoch 22; iter: 0; batch classifier loss: 0.142740; batch adversarial loss: 0.478853\n",
      "epoch 23; iter: 0; batch classifier loss: 0.201359; batch adversarial loss: 0.488073\n",
      "epoch 24; iter: 0; batch classifier loss: 0.186451; batch adversarial loss: 0.415708\n",
      "epoch 25; iter: 0; batch classifier loss: 0.156594; batch adversarial loss: 0.481853\n",
      "epoch 26; iter: 0; batch classifier loss: 0.243273; batch adversarial loss: 0.507385\n",
      "epoch 27; iter: 0; batch classifier loss: 0.147234; batch adversarial loss: 0.447791\n",
      "epoch 28; iter: 0; batch classifier loss: 0.156809; batch adversarial loss: 0.505977\n",
      "epoch 29; iter: 0; batch classifier loss: 0.187057; batch adversarial loss: 0.494867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.163420; batch adversarial loss: 0.412129\n",
      "epoch 31; iter: 0; batch classifier loss: 0.154620; batch adversarial loss: 0.448045\n",
      "epoch 32; iter: 0; batch classifier loss: 0.174357; batch adversarial loss: 0.517814\n",
      "epoch 33; iter: 0; batch classifier loss: 0.169048; batch adversarial loss: 0.487709\n",
      "epoch 34; iter: 0; batch classifier loss: 0.121178; batch adversarial loss: 0.480281\n",
      "epoch 35; iter: 0; batch classifier loss: 0.182345; batch adversarial loss: 0.470535\n",
      "epoch 36; iter: 0; batch classifier loss: 0.125801; batch adversarial loss: 0.532978\n",
      "epoch 37; iter: 0; batch classifier loss: 0.141426; batch adversarial loss: 0.512068\n",
      "epoch 38; iter: 0; batch classifier loss: 0.090359; batch adversarial loss: 0.466265\n",
      "epoch 39; iter: 0; batch classifier loss: 0.170474; batch adversarial loss: 0.381559\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095448; batch adversarial loss: 0.396038\n",
      "epoch 41; iter: 0; batch classifier loss: 0.141370; batch adversarial loss: 0.386211\n",
      "epoch 42; iter: 0; batch classifier loss: 0.090301; batch adversarial loss: 0.370198\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117569; batch adversarial loss: 0.431898\n",
      "epoch 44; iter: 0; batch classifier loss: 0.111982; batch adversarial loss: 0.560476\n",
      "epoch 45; iter: 0; batch classifier loss: 0.107274; batch adversarial loss: 0.530442\n",
      "epoch 46; iter: 0; batch classifier loss: 0.123076; batch adversarial loss: 0.469215\n",
      "epoch 47; iter: 0; batch classifier loss: 0.147937; batch adversarial loss: 0.432925\n",
      "epoch 48; iter: 0; batch classifier loss: 0.127359; batch adversarial loss: 0.412078\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098488; batch adversarial loss: 0.420148\n",
      "epoch 50; iter: 0; batch classifier loss: 0.115135; batch adversarial loss: 0.427567\n",
      "epoch 51; iter: 0; batch classifier loss: 0.103807; batch adversarial loss: 0.535297\n",
      "epoch 52; iter: 0; batch classifier loss: 0.119565; batch adversarial loss: 0.525550\n",
      "epoch 53; iter: 0; batch classifier loss: 0.070602; batch adversarial loss: 0.473905\n",
      "epoch 54; iter: 0; batch classifier loss: 0.060598; batch adversarial loss: 0.470289\n",
      "epoch 55; iter: 0; batch classifier loss: 0.080052; batch adversarial loss: 0.566089\n",
      "epoch 56; iter: 0; batch classifier loss: 0.100159; batch adversarial loss: 0.448239\n",
      "epoch 57; iter: 0; batch classifier loss: 0.104103; batch adversarial loss: 0.471751\n",
      "epoch 58; iter: 0; batch classifier loss: 0.138778; batch adversarial loss: 0.526130\n",
      "epoch 59; iter: 0; batch classifier loss: 0.121809; batch adversarial loss: 0.546403\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086465; batch adversarial loss: 0.403732\n",
      "epoch 61; iter: 0; batch classifier loss: 0.109499; batch adversarial loss: 0.537376\n",
      "epoch 62; iter: 0; batch classifier loss: 0.075169; batch adversarial loss: 0.500130\n",
      "epoch 63; iter: 0; batch classifier loss: 0.106169; batch adversarial loss: 0.485384\n",
      "epoch 64; iter: 0; batch classifier loss: 0.089899; batch adversarial loss: 0.470089\n",
      "epoch 65; iter: 0; batch classifier loss: 0.044017; batch adversarial loss: 0.516917\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072471; batch adversarial loss: 0.379862\n",
      "epoch 67; iter: 0; batch classifier loss: 0.042652; batch adversarial loss: 0.498139\n",
      "epoch 68; iter: 0; batch classifier loss: 0.091486; batch adversarial loss: 0.415049\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094888; batch adversarial loss: 0.480143\n",
      "epoch 70; iter: 0; batch classifier loss: 0.074745; batch adversarial loss: 0.452802\n",
      "epoch 71; iter: 0; batch classifier loss: 0.121344; batch adversarial loss: 0.325151\n",
      "epoch 72; iter: 0; batch classifier loss: 0.078966; batch adversarial loss: 0.431952\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085679; batch adversarial loss: 0.437881\n",
      "epoch 74; iter: 0; batch classifier loss: 0.092412; batch adversarial loss: 0.456094\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059116; batch adversarial loss: 0.561234\n",
      "epoch 76; iter: 0; batch classifier loss: 0.049209; batch adversarial loss: 0.447501\n",
      "epoch 77; iter: 0; batch classifier loss: 0.080153; batch adversarial loss: 0.398562\n",
      "epoch 78; iter: 0; batch classifier loss: 0.052058; batch adversarial loss: 0.439328\n",
      "epoch 79; iter: 0; batch classifier loss: 0.115320; batch adversarial loss: 0.372093\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068840; batch adversarial loss: 0.459052\n",
      "epoch 81; iter: 0; batch classifier loss: 0.086927; batch adversarial loss: 0.563459\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046579; batch adversarial loss: 0.426536\n",
      "epoch 83; iter: 0; batch classifier loss: 0.036596; batch adversarial loss: 0.524351\n",
      "epoch 84; iter: 0; batch classifier loss: 0.101660; batch adversarial loss: 0.421263\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065610; batch adversarial loss: 0.425352\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074508; batch adversarial loss: 0.373661\n",
      "epoch 87; iter: 0; batch classifier loss: 0.101277; batch adversarial loss: 0.549307\n",
      "epoch 88; iter: 0; batch classifier loss: 0.053959; batch adversarial loss: 0.445896\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068208; batch adversarial loss: 0.512359\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048775; batch adversarial loss: 0.356055\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063065; batch adversarial loss: 0.445742\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058460; batch adversarial loss: 0.392876\n",
      "epoch 93; iter: 0; batch classifier loss: 0.059425; batch adversarial loss: 0.441929\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079988; batch adversarial loss: 0.482216\n",
      "epoch 95; iter: 0; batch classifier loss: 0.094402; batch adversarial loss: 0.452188\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036105; batch adversarial loss: 0.548774\n",
      "epoch 97; iter: 0; batch classifier loss: 0.053249; batch adversarial loss: 0.536627\n",
      "epoch 98; iter: 0; batch classifier loss: 0.071187; batch adversarial loss: 0.433172\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064925; batch adversarial loss: 0.495880\n",
      "epoch 100; iter: 0; batch classifier loss: 0.086703; batch adversarial loss: 0.410509\n",
      "epoch 101; iter: 0; batch classifier loss: 0.031488; batch adversarial loss: 0.461602\n",
      "epoch 102; iter: 0; batch classifier loss: 0.028012; batch adversarial loss: 0.474605\n",
      "epoch 103; iter: 0; batch classifier loss: 0.089444; batch adversarial loss: 0.524233\n",
      "epoch 104; iter: 0; batch classifier loss: 0.030813; batch adversarial loss: 0.453985\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057837; batch adversarial loss: 0.474176\n",
      "epoch 106; iter: 0; batch classifier loss: 0.083043; batch adversarial loss: 0.441860\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035578; batch adversarial loss: 0.469949\n",
      "epoch 108; iter: 0; batch classifier loss: 0.054445; batch adversarial loss: 0.373260\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058619; batch adversarial loss: 0.401909\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030334; batch adversarial loss: 0.496365\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039694; batch adversarial loss: 0.459767\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053634; batch adversarial loss: 0.491542\n",
      "epoch 113; iter: 0; batch classifier loss: 0.021810; batch adversarial loss: 0.480355\n",
      "epoch 114; iter: 0; batch classifier loss: 0.022201; batch adversarial loss: 0.435636\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036830; batch adversarial loss: 0.469802\n",
      "epoch 116; iter: 0; batch classifier loss: 0.014969; batch adversarial loss: 0.434958\n",
      "epoch 117; iter: 0; batch classifier loss: 0.065575; batch adversarial loss: 0.421502\n",
      "epoch 118; iter: 0; batch classifier loss: 0.070866; batch adversarial loss: 0.366574\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022472; batch adversarial loss: 0.549698\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034852; batch adversarial loss: 0.424546\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051250; batch adversarial loss: 0.372370\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040267; batch adversarial loss: 0.450364\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064946; batch adversarial loss: 0.457376\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044835; batch adversarial loss: 0.605356\n",
      "epoch 125; iter: 0; batch classifier loss: 0.019417; batch adversarial loss: 0.486340\n",
      "epoch 126; iter: 0; batch classifier loss: 0.101816; batch adversarial loss: 0.477550\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048388; batch adversarial loss: 0.498472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.024538; batch adversarial loss: 0.483397\n",
      "epoch 129; iter: 0; batch classifier loss: 0.053377; batch adversarial loss: 0.418674\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048410; batch adversarial loss: 0.392488\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015286; batch adversarial loss: 0.494749\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041159; batch adversarial loss: 0.464408\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027907; batch adversarial loss: 0.484314\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037917; batch adversarial loss: 0.400437\n",
      "epoch 135; iter: 0; batch classifier loss: 0.013577; batch adversarial loss: 0.489692\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031889; batch adversarial loss: 0.392927\n",
      "epoch 137; iter: 0; batch classifier loss: 0.012070; batch adversarial loss: 0.442182\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038933; batch adversarial loss: 0.446490\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021163; batch adversarial loss: 0.453562\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041827; batch adversarial loss: 0.367688\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036086; batch adversarial loss: 0.418966\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027501; batch adversarial loss: 0.460890\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026200; batch adversarial loss: 0.467904\n",
      "epoch 144; iter: 0; batch classifier loss: 0.008290; batch adversarial loss: 0.425453\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032142; batch adversarial loss: 0.437409\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023776; batch adversarial loss: 0.467381\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014869; batch adversarial loss: 0.486260\n",
      "epoch 148; iter: 0; batch classifier loss: 0.010688; batch adversarial loss: 0.480163\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011770; batch adversarial loss: 0.413158\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025422; batch adversarial loss: 0.448410\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016961; batch adversarial loss: 0.460286\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015936; batch adversarial loss: 0.501323\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024873; batch adversarial loss: 0.443138\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025777; batch adversarial loss: 0.382035\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041620; batch adversarial loss: 0.431954\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035211; batch adversarial loss: 0.485227\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046445; batch adversarial loss: 0.418506\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009423; batch adversarial loss: 0.503210\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016508; batch adversarial loss: 0.421888\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035697; batch adversarial loss: 0.364027\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018384; batch adversarial loss: 0.399559\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014267; batch adversarial loss: 0.491159\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017383; batch adversarial loss: 0.486171\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017631; batch adversarial loss: 0.412978\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014500; batch adversarial loss: 0.451484\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025398; batch adversarial loss: 0.475909\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017984; batch adversarial loss: 0.383669\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019158; batch adversarial loss: 0.376269\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018555; batch adversarial loss: 0.439838\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027604; batch adversarial loss: 0.321200\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031131; batch adversarial loss: 0.442130\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017239; batch adversarial loss: 0.423768\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034556; batch adversarial loss: 0.482377\n",
      "epoch 174; iter: 0; batch classifier loss: 0.057168; batch adversarial loss: 0.515422\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008500; batch adversarial loss: 0.491391\n",
      "epoch 176; iter: 0; batch classifier loss: 0.039975; batch adversarial loss: 0.449170\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013940; batch adversarial loss: 0.406481\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038308; batch adversarial loss: 0.438079\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039769; batch adversarial loss: 0.353315\n",
      "epoch 180; iter: 0; batch classifier loss: 0.003241; batch adversarial loss: 0.453106\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016620; batch adversarial loss: 0.499547\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006522; batch adversarial loss: 0.366880\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026595; batch adversarial loss: 0.493374\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021551; batch adversarial loss: 0.423278\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015025; batch adversarial loss: 0.541514\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024171; batch adversarial loss: 0.480994\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027348; batch adversarial loss: 0.360311\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018408; batch adversarial loss: 0.458107\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011978; batch adversarial loss: 0.526559\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032556; batch adversarial loss: 0.519141\n",
      "epoch 191; iter: 0; batch classifier loss: 0.045486; batch adversarial loss: 0.453357\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023747; batch adversarial loss: 0.468547\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022910; batch adversarial loss: 0.502464\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035710; batch adversarial loss: 0.484594\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011252; batch adversarial loss: 0.403943\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025528; batch adversarial loss: 0.470703\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004188; batch adversarial loss: 0.441545\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022588; batch adversarial loss: 0.410712\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014123; batch adversarial loss: 0.371351\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723204; batch adversarial loss: 0.972717\n",
      "epoch 1; iter: 0; batch classifier loss: 0.539159; batch adversarial loss: 1.027601\n",
      "epoch 2; iter: 0; batch classifier loss: 0.857396; batch adversarial loss: 1.043375\n",
      "epoch 3; iter: 0; batch classifier loss: 0.903616; batch adversarial loss: 0.970186\n",
      "epoch 4; iter: 0; batch classifier loss: 0.856510; batch adversarial loss: 0.871468\n",
      "epoch 5; iter: 0; batch classifier loss: 0.880892; batch adversarial loss: 0.785858\n",
      "epoch 6; iter: 0; batch classifier loss: 0.894881; batch adversarial loss: 0.722192\n",
      "epoch 7; iter: 0; batch classifier loss: 0.799518; batch adversarial loss: 0.656782\n",
      "epoch 8; iter: 0; batch classifier loss: 0.751580; batch adversarial loss: 0.604286\n",
      "epoch 9; iter: 0; batch classifier loss: 0.404169; batch adversarial loss: 0.556085\n",
      "epoch 10; iter: 0; batch classifier loss: 0.255682; batch adversarial loss: 0.528864\n",
      "epoch 11; iter: 0; batch classifier loss: 0.245720; batch adversarial loss: 0.560438\n",
      "epoch 12; iter: 0; batch classifier loss: 0.280596; batch adversarial loss: 0.525601\n",
      "epoch 13; iter: 0; batch classifier loss: 0.292464; batch adversarial loss: 0.492488\n",
      "epoch 14; iter: 0; batch classifier loss: 0.284982; batch adversarial loss: 0.493082\n",
      "epoch 15; iter: 0; batch classifier loss: 0.252395; batch adversarial loss: 0.477715\n",
      "epoch 16; iter: 0; batch classifier loss: 0.267424; batch adversarial loss: 0.475501\n",
      "epoch 17; iter: 0; batch classifier loss: 0.251890; batch adversarial loss: 0.493872\n",
      "epoch 18; iter: 0; batch classifier loss: 0.205101; batch adversarial loss: 0.471760\n",
      "epoch 19; iter: 0; batch classifier loss: 0.160891; batch adversarial loss: 0.454655\n",
      "epoch 20; iter: 0; batch classifier loss: 0.165812; batch adversarial loss: 0.415305\n",
      "epoch 21; iter: 0; batch classifier loss: 0.219253; batch adversarial loss: 0.450050\n",
      "epoch 22; iter: 0; batch classifier loss: 0.127512; batch adversarial loss: 0.417826\n",
      "epoch 23; iter: 0; batch classifier loss: 0.112154; batch adversarial loss: 0.492733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.123649; batch adversarial loss: 0.410058\n",
      "epoch 25; iter: 0; batch classifier loss: 0.116605; batch adversarial loss: 0.334749\n",
      "epoch 26; iter: 0; batch classifier loss: 0.136727; batch adversarial loss: 0.478114\n",
      "epoch 27; iter: 0; batch classifier loss: 0.109404; batch adversarial loss: 0.449850\n",
      "epoch 28; iter: 0; batch classifier loss: 0.098881; batch adversarial loss: 0.496360\n",
      "epoch 29; iter: 0; batch classifier loss: 0.074116; batch adversarial loss: 0.367847\n",
      "epoch 30; iter: 0; batch classifier loss: 0.093957; batch adversarial loss: 0.435537\n",
      "epoch 31; iter: 0; batch classifier loss: 0.149342; batch adversarial loss: 0.414167\n",
      "epoch 32; iter: 0; batch classifier loss: 0.068480; batch adversarial loss: 0.411041\n",
      "epoch 33; iter: 0; batch classifier loss: 0.108393; batch adversarial loss: 0.406214\n",
      "epoch 34; iter: 0; batch classifier loss: 0.099903; batch adversarial loss: 0.505185\n",
      "epoch 35; iter: 0; batch classifier loss: 0.123947; batch adversarial loss: 0.534328\n",
      "epoch 36; iter: 0; batch classifier loss: 0.079174; batch adversarial loss: 0.421868\n",
      "epoch 37; iter: 0; batch classifier loss: 0.095320; batch adversarial loss: 0.343804\n",
      "epoch 38; iter: 0; batch classifier loss: 0.095601; batch adversarial loss: 0.360267\n",
      "epoch 39; iter: 0; batch classifier loss: 0.097203; batch adversarial loss: 0.527757\n",
      "epoch 40; iter: 0; batch classifier loss: 0.064249; batch adversarial loss: 0.445949\n",
      "epoch 41; iter: 0; batch classifier loss: 0.079633; batch adversarial loss: 0.428509\n",
      "epoch 42; iter: 0; batch classifier loss: 0.097330; batch adversarial loss: 0.410344\n",
      "epoch 43; iter: 0; batch classifier loss: 0.095579; batch adversarial loss: 0.472925\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098660; batch adversarial loss: 0.532744\n",
      "epoch 45; iter: 0; batch classifier loss: 0.065899; batch adversarial loss: 0.448840\n",
      "epoch 46; iter: 0; batch classifier loss: 0.080882; batch adversarial loss: 0.485973\n",
      "epoch 47; iter: 0; batch classifier loss: 0.080875; batch adversarial loss: 0.454245\n",
      "epoch 48; iter: 0; batch classifier loss: 0.085934; batch adversarial loss: 0.449011\n",
      "epoch 49; iter: 0; batch classifier loss: 0.078568; batch adversarial loss: 0.380363\n",
      "epoch 50; iter: 0; batch classifier loss: 0.059748; batch adversarial loss: 0.351224\n",
      "epoch 51; iter: 0; batch classifier loss: 0.104315; batch adversarial loss: 0.489615\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103058; batch adversarial loss: 0.460549\n",
      "epoch 53; iter: 0; batch classifier loss: 0.075969; batch adversarial loss: 0.426429\n",
      "epoch 54; iter: 0; batch classifier loss: 0.054841; batch adversarial loss: 0.493437\n",
      "epoch 55; iter: 0; batch classifier loss: 0.066325; batch adversarial loss: 0.476683\n",
      "epoch 56; iter: 0; batch classifier loss: 0.058054; batch adversarial loss: 0.443104\n",
      "epoch 57; iter: 0; batch classifier loss: 0.068224; batch adversarial loss: 0.363309\n",
      "epoch 58; iter: 0; batch classifier loss: 0.075139; batch adversarial loss: 0.566152\n",
      "epoch 59; iter: 0; batch classifier loss: 0.098305; batch adversarial loss: 0.436182\n",
      "epoch 60; iter: 0; batch classifier loss: 0.047674; batch adversarial loss: 0.479671\n",
      "epoch 61; iter: 0; batch classifier loss: 0.076151; batch adversarial loss: 0.537432\n",
      "epoch 62; iter: 0; batch classifier loss: 0.083321; batch adversarial loss: 0.430161\n",
      "epoch 63; iter: 0; batch classifier loss: 0.037154; batch adversarial loss: 0.427556\n",
      "epoch 64; iter: 0; batch classifier loss: 0.045682; batch adversarial loss: 0.501200\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087730; batch adversarial loss: 0.394051\n",
      "epoch 66; iter: 0; batch classifier loss: 0.045219; batch adversarial loss: 0.446432\n",
      "epoch 67; iter: 0; batch classifier loss: 0.055372; batch adversarial loss: 0.468214\n",
      "epoch 68; iter: 0; batch classifier loss: 0.031557; batch adversarial loss: 0.452920\n",
      "epoch 69; iter: 0; batch classifier loss: 0.053446; batch adversarial loss: 0.499172\n",
      "epoch 70; iter: 0; batch classifier loss: 0.050913; batch adversarial loss: 0.389233\n",
      "epoch 71; iter: 0; batch classifier loss: 0.051263; batch adversarial loss: 0.449576\n",
      "epoch 72; iter: 0; batch classifier loss: 0.026309; batch adversarial loss: 0.382289\n",
      "epoch 73; iter: 0; batch classifier loss: 0.074223; batch adversarial loss: 0.422843\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067713; batch adversarial loss: 0.528017\n",
      "epoch 75; iter: 0; batch classifier loss: 0.039752; batch adversarial loss: 0.406272\n",
      "epoch 76; iter: 0; batch classifier loss: 0.043268; batch adversarial loss: 0.410215\n",
      "epoch 77; iter: 0; batch classifier loss: 0.074658; batch adversarial loss: 0.520959\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061008; batch adversarial loss: 0.495623\n",
      "epoch 79; iter: 0; batch classifier loss: 0.048958; batch adversarial loss: 0.539381\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061981; batch adversarial loss: 0.472427\n",
      "epoch 81; iter: 0; batch classifier loss: 0.024574; batch adversarial loss: 0.493454\n",
      "epoch 82; iter: 0; batch classifier loss: 0.054012; batch adversarial loss: 0.395035\n",
      "epoch 83; iter: 0; batch classifier loss: 0.072292; batch adversarial loss: 0.452131\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051668; batch adversarial loss: 0.467857\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052532; batch adversarial loss: 0.512843\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068358; batch adversarial loss: 0.517447\n",
      "epoch 87; iter: 0; batch classifier loss: 0.038489; batch adversarial loss: 0.492871\n",
      "epoch 88; iter: 0; batch classifier loss: 0.029763; batch adversarial loss: 0.433364\n",
      "epoch 89; iter: 0; batch classifier loss: 0.037258; batch adversarial loss: 0.526055\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073293; batch adversarial loss: 0.409602\n",
      "epoch 91; iter: 0; batch classifier loss: 0.029927; batch adversarial loss: 0.404014\n",
      "epoch 92; iter: 0; batch classifier loss: 0.013741; batch adversarial loss: 0.472693\n",
      "epoch 93; iter: 0; batch classifier loss: 0.034410; batch adversarial loss: 0.451272\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079624; batch adversarial loss: 0.449343\n",
      "epoch 95; iter: 0; batch classifier loss: 0.041696; batch adversarial loss: 0.483431\n",
      "epoch 96; iter: 0; batch classifier loss: 0.029164; batch adversarial loss: 0.438224\n",
      "epoch 97; iter: 0; batch classifier loss: 0.036132; batch adversarial loss: 0.440692\n",
      "epoch 98; iter: 0; batch classifier loss: 0.041583; batch adversarial loss: 0.518077\n",
      "epoch 99; iter: 0; batch classifier loss: 0.086536; batch adversarial loss: 0.388230\n",
      "epoch 100; iter: 0; batch classifier loss: 0.017888; batch adversarial loss: 0.380220\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040735; batch adversarial loss: 0.371932\n",
      "epoch 102; iter: 0; batch classifier loss: 0.024941; batch adversarial loss: 0.521363\n",
      "epoch 103; iter: 0; batch classifier loss: 0.078190; batch adversarial loss: 0.475456\n",
      "epoch 104; iter: 0; batch classifier loss: 0.023389; batch adversarial loss: 0.475189\n",
      "epoch 105; iter: 0; batch classifier loss: 0.021154; batch adversarial loss: 0.513262\n",
      "epoch 106; iter: 0; batch classifier loss: 0.038599; batch adversarial loss: 0.516237\n",
      "epoch 107; iter: 0; batch classifier loss: 0.022145; batch adversarial loss: 0.440541\n",
      "epoch 108; iter: 0; batch classifier loss: 0.014461; batch adversarial loss: 0.541778\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033240; batch adversarial loss: 0.430667\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044855; batch adversarial loss: 0.462214\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055333; batch adversarial loss: 0.435984\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031011; batch adversarial loss: 0.444493\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034864; batch adversarial loss: 0.459593\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027276; batch adversarial loss: 0.415931\n",
      "epoch 115; iter: 0; batch classifier loss: 0.030479; batch adversarial loss: 0.504521\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027478; batch adversarial loss: 0.450241\n",
      "epoch 117; iter: 0; batch classifier loss: 0.022903; batch adversarial loss: 0.464742\n",
      "epoch 118; iter: 0; batch classifier loss: 0.019370; batch adversarial loss: 0.318615\n",
      "epoch 119; iter: 0; batch classifier loss: 0.018373; batch adversarial loss: 0.377445\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050820; batch adversarial loss: 0.455461\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036738; batch adversarial loss: 0.494281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.033605; batch adversarial loss: 0.494620\n",
      "epoch 123; iter: 0; batch classifier loss: 0.013607; batch adversarial loss: 0.497532\n",
      "epoch 124; iter: 0; batch classifier loss: 0.028869; batch adversarial loss: 0.499416\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022846; batch adversarial loss: 0.493706\n",
      "epoch 126; iter: 0; batch classifier loss: 0.018257; batch adversarial loss: 0.385019\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024334; batch adversarial loss: 0.394615\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023302; batch adversarial loss: 0.485955\n",
      "epoch 129; iter: 0; batch classifier loss: 0.067086; batch adversarial loss: 0.499698\n",
      "epoch 130; iter: 0; batch classifier loss: 0.015811; batch adversarial loss: 0.430168\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023507; batch adversarial loss: 0.412833\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039003; batch adversarial loss: 0.413300\n",
      "epoch 133; iter: 0; batch classifier loss: 0.064163; batch adversarial loss: 0.492740\n",
      "epoch 134; iter: 0; batch classifier loss: 0.044722; batch adversarial loss: 0.447843\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026279; batch adversarial loss: 0.411914\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033692; batch adversarial loss: 0.550715\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015873; batch adversarial loss: 0.439024\n",
      "epoch 138; iter: 0; batch classifier loss: 0.010220; batch adversarial loss: 0.527233\n",
      "epoch 139; iter: 0; batch classifier loss: 0.052343; batch adversarial loss: 0.440712\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044340; batch adversarial loss: 0.475287\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016716; batch adversarial loss: 0.406846\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039867; batch adversarial loss: 0.427909\n",
      "epoch 143; iter: 0; batch classifier loss: 0.010458; batch adversarial loss: 0.453243\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026082; batch adversarial loss: 0.451858\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028412; batch adversarial loss: 0.424691\n",
      "epoch 146; iter: 0; batch classifier loss: 0.012127; batch adversarial loss: 0.428393\n",
      "epoch 147; iter: 0; batch classifier loss: 0.012652; batch adversarial loss: 0.401182\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026127; batch adversarial loss: 0.465962\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013238; batch adversarial loss: 0.429719\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030983; batch adversarial loss: 0.478266\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014567; batch adversarial loss: 0.527170\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015185; batch adversarial loss: 0.541764\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011316; batch adversarial loss: 0.478280\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012269; batch adversarial loss: 0.483274\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009604; batch adversarial loss: 0.474148\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025437; batch adversarial loss: 0.350147\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015047; batch adversarial loss: 0.471010\n",
      "epoch 158; iter: 0; batch classifier loss: 0.040334; batch adversarial loss: 0.454816\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038552; batch adversarial loss: 0.447844\n",
      "epoch 160; iter: 0; batch classifier loss: 0.011230; batch adversarial loss: 0.352757\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009689; batch adversarial loss: 0.518400\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039125; batch adversarial loss: 0.345711\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028919; batch adversarial loss: 0.427625\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021588; batch adversarial loss: 0.347047\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022535; batch adversarial loss: 0.520597\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010195; batch adversarial loss: 0.479214\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010147; batch adversarial loss: 0.449480\n",
      "epoch 168; iter: 0; batch classifier loss: 0.049771; batch adversarial loss: 0.387440\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019647; batch adversarial loss: 0.449804\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031920; batch adversarial loss: 0.491612\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017032; batch adversarial loss: 0.409231\n",
      "epoch 172; iter: 0; batch classifier loss: 0.057269; batch adversarial loss: 0.463022\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019878; batch adversarial loss: 0.448801\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019339; batch adversarial loss: 0.552415\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021887; batch adversarial loss: 0.424871\n",
      "epoch 176; iter: 0; batch classifier loss: 0.006332; batch adversarial loss: 0.569166\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016098; batch adversarial loss: 0.395218\n",
      "epoch 178; iter: 0; batch classifier loss: 0.005832; batch adversarial loss: 0.396116\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015602; batch adversarial loss: 0.419441\n",
      "epoch 180; iter: 0; batch classifier loss: 0.042408; batch adversarial loss: 0.423856\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012058; batch adversarial loss: 0.506518\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021697; batch adversarial loss: 0.455019\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009986; batch adversarial loss: 0.537115\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016672; batch adversarial loss: 0.432753\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009369; batch adversarial loss: 0.524127\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024382; batch adversarial loss: 0.427653\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034209; batch adversarial loss: 0.443010\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031730; batch adversarial loss: 0.521292\n",
      "epoch 189; iter: 0; batch classifier loss: 0.005418; batch adversarial loss: 0.367028\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037960; batch adversarial loss: 0.397902\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018834; batch adversarial loss: 0.420567\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013880; batch adversarial loss: 0.468280\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010126; batch adversarial loss: 0.375214\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025620; batch adversarial loss: 0.456323\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013739; batch adversarial loss: 0.426129\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012675; batch adversarial loss: 0.515806\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024156; batch adversarial loss: 0.413949\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013301; batch adversarial loss: 0.448031\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028356; batch adversarial loss: 0.520409\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694792; batch adversarial loss: 0.752280\n",
      "epoch 1; iter: 0; batch classifier loss: 0.470611; batch adversarial loss: 0.721267\n",
      "epoch 2; iter: 0; batch classifier loss: 0.408731; batch adversarial loss: 0.714191\n",
      "epoch 3; iter: 0; batch classifier loss: 0.404308; batch adversarial loss: 0.677831\n",
      "epoch 4; iter: 0; batch classifier loss: 0.369129; batch adversarial loss: 0.643917\n",
      "epoch 5; iter: 0; batch classifier loss: 0.263294; batch adversarial loss: 0.598948\n",
      "epoch 6; iter: 0; batch classifier loss: 0.395305; batch adversarial loss: 0.554224\n",
      "epoch 7; iter: 0; batch classifier loss: 0.368495; batch adversarial loss: 0.527254\n",
      "epoch 8; iter: 0; batch classifier loss: 0.305398; batch adversarial loss: 0.511531\n",
      "epoch 9; iter: 0; batch classifier loss: 0.263090; batch adversarial loss: 0.486845\n",
      "epoch 10; iter: 0; batch classifier loss: 0.225982; batch adversarial loss: 0.486594\n",
      "epoch 11; iter: 0; batch classifier loss: 0.212558; batch adversarial loss: 0.442166\n",
      "epoch 12; iter: 0; batch classifier loss: 0.215733; batch adversarial loss: 0.452574\n",
      "epoch 13; iter: 0; batch classifier loss: 0.205554; batch adversarial loss: 0.483829\n",
      "epoch 14; iter: 0; batch classifier loss: 0.224416; batch adversarial loss: 0.416533\n",
      "epoch 15; iter: 0; batch classifier loss: 0.172179; batch adversarial loss: 0.484554\n",
      "epoch 16; iter: 0; batch classifier loss: 0.157164; batch adversarial loss: 0.435992\n",
      "epoch 17; iter: 0; batch classifier loss: 0.176499; batch adversarial loss: 0.458423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.139692; batch adversarial loss: 0.469497\n",
      "epoch 19; iter: 0; batch classifier loss: 0.153142; batch adversarial loss: 0.491530\n",
      "epoch 20; iter: 0; batch classifier loss: 0.218343; batch adversarial loss: 0.439733\n",
      "epoch 21; iter: 0; batch classifier loss: 0.150613; batch adversarial loss: 0.484748\n",
      "epoch 22; iter: 0; batch classifier loss: 0.173797; batch adversarial loss: 0.407132\n",
      "epoch 23; iter: 0; batch classifier loss: 0.169776; batch adversarial loss: 0.399327\n",
      "epoch 24; iter: 0; batch classifier loss: 0.133645; batch adversarial loss: 0.406457\n",
      "epoch 25; iter: 0; batch classifier loss: 0.135659; batch adversarial loss: 0.406395\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194663; batch adversarial loss: 0.424119\n",
      "epoch 27; iter: 0; batch classifier loss: 0.153155; batch adversarial loss: 0.476198\n",
      "epoch 28; iter: 0; batch classifier loss: 0.172836; batch adversarial loss: 0.396787\n",
      "epoch 29; iter: 0; batch classifier loss: 0.130214; batch adversarial loss: 0.353479\n",
      "epoch 30; iter: 0; batch classifier loss: 0.102286; batch adversarial loss: 0.354534\n",
      "epoch 31; iter: 0; batch classifier loss: 0.109733; batch adversarial loss: 0.371478\n",
      "epoch 32; iter: 0; batch classifier loss: 0.110880; batch adversarial loss: 0.517464\n",
      "epoch 33; iter: 0; batch classifier loss: 0.124264; batch adversarial loss: 0.414499\n",
      "epoch 34; iter: 0; batch classifier loss: 0.129240; batch adversarial loss: 0.320290\n",
      "epoch 35; iter: 0; batch classifier loss: 0.106806; batch adversarial loss: 0.468500\n",
      "epoch 36; iter: 0; batch classifier loss: 0.132141; batch adversarial loss: 0.321010\n",
      "epoch 37; iter: 0; batch classifier loss: 0.172310; batch adversarial loss: 0.476209\n",
      "epoch 38; iter: 0; batch classifier loss: 0.138564; batch adversarial loss: 0.477581\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125290; batch adversarial loss: 0.482569\n",
      "epoch 40; iter: 0; batch classifier loss: 0.105716; batch adversarial loss: 0.469188\n",
      "epoch 41; iter: 0; batch classifier loss: 0.116261; batch adversarial loss: 0.374284\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103858; batch adversarial loss: 0.486769\n",
      "epoch 43; iter: 0; batch classifier loss: 0.068245; batch adversarial loss: 0.406745\n",
      "epoch 44; iter: 0; batch classifier loss: 0.107636; batch adversarial loss: 0.411236\n",
      "epoch 45; iter: 0; batch classifier loss: 0.107909; batch adversarial loss: 0.354689\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126329; batch adversarial loss: 0.474085\n",
      "epoch 47; iter: 0; batch classifier loss: 0.147899; batch adversarial loss: 0.325405\n",
      "epoch 48; iter: 0; batch classifier loss: 0.163047; batch adversarial loss: 0.399489\n",
      "epoch 49; iter: 0; batch classifier loss: 0.085980; batch adversarial loss: 0.394845\n",
      "epoch 50; iter: 0; batch classifier loss: 0.082221; batch adversarial loss: 0.359781\n",
      "epoch 51; iter: 0; batch classifier loss: 0.090575; batch adversarial loss: 0.371260\n",
      "epoch 52; iter: 0; batch classifier loss: 0.051210; batch adversarial loss: 0.336990\n",
      "epoch 53; iter: 0; batch classifier loss: 0.072553; batch adversarial loss: 0.397300\n",
      "epoch 54; iter: 0; batch classifier loss: 0.072574; batch adversarial loss: 0.376613\n",
      "epoch 55; iter: 0; batch classifier loss: 0.090115; batch adversarial loss: 0.382474\n",
      "epoch 56; iter: 0; batch classifier loss: 0.097762; batch adversarial loss: 0.483673\n",
      "epoch 57; iter: 0; batch classifier loss: 0.081989; batch adversarial loss: 0.406828\n",
      "epoch 58; iter: 0; batch classifier loss: 0.061746; batch adversarial loss: 0.419642\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081295; batch adversarial loss: 0.473859\n",
      "epoch 60; iter: 0; batch classifier loss: 0.073251; batch adversarial loss: 0.414308\n",
      "epoch 61; iter: 0; batch classifier loss: 0.075861; batch adversarial loss: 0.362655\n",
      "epoch 62; iter: 0; batch classifier loss: 0.098561; batch adversarial loss: 0.537058\n",
      "epoch 63; iter: 0; batch classifier loss: 0.060016; batch adversarial loss: 0.374383\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082365; batch adversarial loss: 0.491600\n",
      "epoch 65; iter: 0; batch classifier loss: 0.109894; batch adversarial loss: 0.384385\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088451; batch adversarial loss: 0.416190\n",
      "epoch 67; iter: 0; batch classifier loss: 0.098661; batch adversarial loss: 0.436666\n",
      "epoch 68; iter: 0; batch classifier loss: 0.112073; batch adversarial loss: 0.392167\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076338; batch adversarial loss: 0.419417\n",
      "epoch 70; iter: 0; batch classifier loss: 0.063262; batch adversarial loss: 0.474717\n",
      "epoch 71; iter: 0; batch classifier loss: 0.084244; batch adversarial loss: 0.538657\n",
      "epoch 72; iter: 0; batch classifier loss: 0.081521; batch adversarial loss: 0.500262\n",
      "epoch 73; iter: 0; batch classifier loss: 0.058383; batch adversarial loss: 0.432192\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069309; batch adversarial loss: 0.341979\n",
      "epoch 75; iter: 0; batch classifier loss: 0.078005; batch adversarial loss: 0.360031\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060317; batch adversarial loss: 0.456280\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065934; batch adversarial loss: 0.417905\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071322; batch adversarial loss: 0.381664\n",
      "epoch 79; iter: 0; batch classifier loss: 0.055449; batch adversarial loss: 0.371819\n",
      "epoch 80; iter: 0; batch classifier loss: 0.066618; batch adversarial loss: 0.430524\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071891; batch adversarial loss: 0.421847\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075326; batch adversarial loss: 0.457644\n",
      "epoch 83; iter: 0; batch classifier loss: 0.084840; batch adversarial loss: 0.431791\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062233; batch adversarial loss: 0.324089\n",
      "epoch 85; iter: 0; batch classifier loss: 0.044275; batch adversarial loss: 0.393722\n",
      "epoch 86; iter: 0; batch classifier loss: 0.071914; batch adversarial loss: 0.350628\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047076; batch adversarial loss: 0.483944\n",
      "epoch 88; iter: 0; batch classifier loss: 0.046043; batch adversarial loss: 0.279349\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068231; batch adversarial loss: 0.451503\n",
      "epoch 90; iter: 0; batch classifier loss: 0.031034; batch adversarial loss: 0.406387\n",
      "epoch 91; iter: 0; batch classifier loss: 0.065491; batch adversarial loss: 0.367641\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041490; batch adversarial loss: 0.411804\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048552; batch adversarial loss: 0.329958\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042456; batch adversarial loss: 0.403099\n",
      "epoch 95; iter: 0; batch classifier loss: 0.078669; batch adversarial loss: 0.508312\n",
      "epoch 96; iter: 0; batch classifier loss: 0.050130; batch adversarial loss: 0.502423\n",
      "epoch 97; iter: 0; batch classifier loss: 0.045960; batch adversarial loss: 0.408079\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050278; batch adversarial loss: 0.405971\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063437; batch adversarial loss: 0.436010\n",
      "epoch 100; iter: 0; batch classifier loss: 0.033494; batch adversarial loss: 0.454102\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056612; batch adversarial loss: 0.431870\n",
      "epoch 102; iter: 0; batch classifier loss: 0.040446; batch adversarial loss: 0.436683\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045376; batch adversarial loss: 0.505486\n",
      "epoch 104; iter: 0; batch classifier loss: 0.017794; batch adversarial loss: 0.430424\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041922; batch adversarial loss: 0.399762\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031351; batch adversarial loss: 0.431587\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037042; batch adversarial loss: 0.428645\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044999; batch adversarial loss: 0.500698\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049470; batch adversarial loss: 0.450697\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048838; batch adversarial loss: 0.379979\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064495; batch adversarial loss: 0.518417\n",
      "epoch 112; iter: 0; batch classifier loss: 0.023319; batch adversarial loss: 0.439250\n",
      "epoch 113; iter: 0; batch classifier loss: 0.036757; batch adversarial loss: 0.446062\n",
      "epoch 114; iter: 0; batch classifier loss: 0.023200; batch adversarial loss: 0.520393\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033904; batch adversarial loss: 0.500201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.023964; batch adversarial loss: 0.393779\n",
      "epoch 117; iter: 0; batch classifier loss: 0.018335; batch adversarial loss: 0.397034\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040619; batch adversarial loss: 0.401063\n",
      "epoch 119; iter: 0; batch classifier loss: 0.020552; batch adversarial loss: 0.417990\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034088; batch adversarial loss: 0.438769\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046475; batch adversarial loss: 0.349990\n",
      "epoch 122; iter: 0; batch classifier loss: 0.027207; batch adversarial loss: 0.526240\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026996; batch adversarial loss: 0.445299\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020007; batch adversarial loss: 0.388021\n",
      "epoch 125; iter: 0; batch classifier loss: 0.067042; batch adversarial loss: 0.512294\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028170; batch adversarial loss: 0.492533\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043296; batch adversarial loss: 0.517275\n",
      "epoch 128; iter: 0; batch classifier loss: 0.061037; batch adversarial loss: 0.561407\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050177; batch adversarial loss: 0.475132\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024175; batch adversarial loss: 0.494457\n",
      "epoch 131; iter: 0; batch classifier loss: 0.074957; batch adversarial loss: 0.552231\n",
      "epoch 132; iter: 0; batch classifier loss: 0.090857; batch adversarial loss: 0.548892\n",
      "epoch 133; iter: 0; batch classifier loss: 0.090097; batch adversarial loss: 0.552453\n",
      "epoch 134; iter: 0; batch classifier loss: 0.108056; batch adversarial loss: 0.637052\n",
      "epoch 135; iter: 0; batch classifier loss: 0.085890; batch adversarial loss: 0.617628\n",
      "epoch 136; iter: 0; batch classifier loss: 0.125896; batch adversarial loss: 0.571743\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041962; batch adversarial loss: 0.384361\n",
      "epoch 138; iter: 0; batch classifier loss: 0.106556; batch adversarial loss: 0.682203\n",
      "epoch 139; iter: 0; batch classifier loss: 0.124343; batch adversarial loss: 0.546148\n",
      "epoch 140; iter: 0; batch classifier loss: 0.174739; batch adversarial loss: 0.699220\n",
      "epoch 141; iter: 0; batch classifier loss: 0.287544; batch adversarial loss: 0.842363\n",
      "epoch 142; iter: 0; batch classifier loss: 0.145197; batch adversarial loss: 0.634492\n",
      "epoch 143; iter: 0; batch classifier loss: 0.192654; batch adversarial loss: 0.735804\n",
      "epoch 144; iter: 0; batch classifier loss: 0.147149; batch adversarial loss: 0.487579\n",
      "epoch 145; iter: 0; batch classifier loss: 0.084231; batch adversarial loss: 0.469071\n",
      "epoch 146; iter: 0; batch classifier loss: 0.133657; batch adversarial loss: 0.608002\n",
      "epoch 147; iter: 0; batch classifier loss: 0.106892; batch adversarial loss: 0.545610\n",
      "epoch 148; iter: 0; batch classifier loss: 0.073691; batch adversarial loss: 0.464990\n",
      "epoch 149; iter: 0; batch classifier loss: 0.073223; batch adversarial loss: 0.419149\n",
      "epoch 150; iter: 0; batch classifier loss: 0.103196; batch adversarial loss: 0.590089\n",
      "epoch 151; iter: 0; batch classifier loss: 0.180502; batch adversarial loss: 0.628148\n",
      "epoch 152; iter: 0; batch classifier loss: 0.103236; batch adversarial loss: 0.475900\n",
      "epoch 153; iter: 0; batch classifier loss: 0.090531; batch adversarial loss: 0.410952\n",
      "epoch 154; iter: 0; batch classifier loss: 0.131546; batch adversarial loss: 0.550587\n",
      "epoch 155; iter: 0; batch classifier loss: 0.154937; batch adversarial loss: 0.624590\n",
      "epoch 156; iter: 0; batch classifier loss: 0.089985; batch adversarial loss: 0.523209\n",
      "epoch 157; iter: 0; batch classifier loss: 0.117620; batch adversarial loss: 0.473291\n",
      "epoch 158; iter: 0; batch classifier loss: 0.154023; batch adversarial loss: 0.467220\n",
      "epoch 159; iter: 0; batch classifier loss: 0.119587; batch adversarial loss: 0.520949\n",
      "epoch 160; iter: 0; batch classifier loss: 0.130434; batch adversarial loss: 0.517240\n",
      "epoch 161; iter: 0; batch classifier loss: 0.087561; batch adversarial loss: 0.376529\n",
      "epoch 162; iter: 0; batch classifier loss: 0.098656; batch adversarial loss: 0.478193\n",
      "epoch 163; iter: 0; batch classifier loss: 0.087000; batch adversarial loss: 0.425356\n",
      "epoch 164; iter: 0; batch classifier loss: 0.114671; batch adversarial loss: 0.410177\n",
      "epoch 165; iter: 0; batch classifier loss: 0.077612; batch adversarial loss: 0.444494\n",
      "epoch 166; iter: 0; batch classifier loss: 0.132342; batch adversarial loss: 0.448447\n",
      "epoch 167; iter: 0; batch classifier loss: 0.068790; batch adversarial loss: 0.404782\n",
      "epoch 168; iter: 0; batch classifier loss: 0.066425; batch adversarial loss: 0.435053\n",
      "epoch 169; iter: 0; batch classifier loss: 0.089125; batch adversarial loss: 0.477293\n",
      "epoch 170; iter: 0; batch classifier loss: 0.060686; batch adversarial loss: 0.421904\n",
      "epoch 171; iter: 0; batch classifier loss: 0.080047; batch adversarial loss: 0.458838\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032081; batch adversarial loss: 0.415569\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026104; batch adversarial loss: 0.409277\n",
      "epoch 174; iter: 0; batch classifier loss: 0.053781; batch adversarial loss: 0.470303\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017353; batch adversarial loss: 0.451400\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033199; batch adversarial loss: 0.378589\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025084; batch adversarial loss: 0.494540\n",
      "epoch 178; iter: 0; batch classifier loss: 0.047953; batch adversarial loss: 0.360450\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009675; batch adversarial loss: 0.582815\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017032; batch adversarial loss: 0.501634\n",
      "epoch 181; iter: 0; batch classifier loss: 0.051104; batch adversarial loss: 0.413675\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026268; batch adversarial loss: 0.424538\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026566; batch adversarial loss: 0.534832\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035701; batch adversarial loss: 0.465337\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037052; batch adversarial loss: 0.428426\n",
      "epoch 186; iter: 0; batch classifier loss: 0.062219; batch adversarial loss: 0.527720\n",
      "epoch 187; iter: 0; batch classifier loss: 0.045860; batch adversarial loss: 0.470503\n",
      "epoch 188; iter: 0; batch classifier loss: 0.043121; batch adversarial loss: 0.361349\n",
      "epoch 189; iter: 0; batch classifier loss: 0.040503; batch adversarial loss: 0.426651\n",
      "epoch 190; iter: 0; batch classifier loss: 0.041327; batch adversarial loss: 0.539833\n",
      "epoch 191; iter: 0; batch classifier loss: 0.046230; batch adversarial loss: 0.467918\n",
      "epoch 192; iter: 0; batch classifier loss: 0.065208; batch adversarial loss: 0.391013\n",
      "epoch 193; iter: 0; batch classifier loss: 0.042443; batch adversarial loss: 0.461891\n",
      "epoch 194; iter: 0; batch classifier loss: 0.058330; batch adversarial loss: 0.473106\n",
      "epoch 195; iter: 0; batch classifier loss: 0.055782; batch adversarial loss: 0.444019\n",
      "epoch 196; iter: 0; batch classifier loss: 0.082976; batch adversarial loss: 0.357101\n",
      "epoch 197; iter: 0; batch classifier loss: 0.038548; batch adversarial loss: 0.602040\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037023; batch adversarial loss: 0.482648\n",
      "epoch 199; iter: 0; batch classifier loss: 0.052396; batch adversarial loss: 0.381353\n",
      "epoch 0; iter: 0; batch classifier loss: 0.665227; batch adversarial loss: 0.500334\n",
      "epoch 1; iter: 0; batch classifier loss: 0.428883; batch adversarial loss: 0.583435\n",
      "epoch 2; iter: 0; batch classifier loss: 0.369637; batch adversarial loss: 0.585398\n",
      "epoch 3; iter: 0; batch classifier loss: 0.370190; batch adversarial loss: 0.568359\n",
      "epoch 4; iter: 0; batch classifier loss: 0.332505; batch adversarial loss: 0.561010\n",
      "epoch 5; iter: 0; batch classifier loss: 0.427409; batch adversarial loss: 0.534324\n",
      "epoch 6; iter: 0; batch classifier loss: 0.357863; batch adversarial loss: 0.583485\n",
      "epoch 7; iter: 0; batch classifier loss: 0.289103; batch adversarial loss: 0.519372\n",
      "epoch 8; iter: 0; batch classifier loss: 0.375789; batch adversarial loss: 0.568696\n",
      "epoch 9; iter: 0; batch classifier loss: 0.338306; batch adversarial loss: 0.656178\n",
      "epoch 10; iter: 0; batch classifier loss: 0.244781; batch adversarial loss: 0.578331\n",
      "epoch 11; iter: 0; batch classifier loss: 0.291672; batch adversarial loss: 0.533769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.337880; batch adversarial loss: 0.564011\n",
      "epoch 13; iter: 0; batch classifier loss: 0.287644; batch adversarial loss: 0.575841\n",
      "epoch 14; iter: 0; batch classifier loss: 0.341767; batch adversarial loss: 0.478386\n",
      "epoch 15; iter: 0; batch classifier loss: 0.416009; batch adversarial loss: 0.612086\n",
      "epoch 16; iter: 0; batch classifier loss: 0.328215; batch adversarial loss: 0.500323\n",
      "epoch 17; iter: 0; batch classifier loss: 0.503514; batch adversarial loss: 0.525635\n",
      "epoch 18; iter: 0; batch classifier loss: 0.582797; batch adversarial loss: 0.545059\n",
      "epoch 19; iter: 0; batch classifier loss: 0.322840; batch adversarial loss: 0.515453\n",
      "epoch 20; iter: 0; batch classifier loss: 0.270196; batch adversarial loss: 0.459843\n",
      "epoch 21; iter: 0; batch classifier loss: 0.210143; batch adversarial loss: 0.479594\n",
      "epoch 22; iter: 0; batch classifier loss: 0.197469; batch adversarial loss: 0.471344\n",
      "epoch 23; iter: 0; batch classifier loss: 0.190004; batch adversarial loss: 0.477915\n",
      "epoch 24; iter: 0; batch classifier loss: 0.155572; batch adversarial loss: 0.475213\n",
      "epoch 25; iter: 0; batch classifier loss: 0.125759; batch adversarial loss: 0.443447\n",
      "epoch 26; iter: 0; batch classifier loss: 0.173695; batch adversarial loss: 0.535964\n",
      "epoch 27; iter: 0; batch classifier loss: 0.148990; batch adversarial loss: 0.450658\n",
      "epoch 28; iter: 0; batch classifier loss: 0.146799; batch adversarial loss: 0.394028\n",
      "epoch 29; iter: 0; batch classifier loss: 0.189485; batch adversarial loss: 0.440102\n",
      "epoch 30; iter: 0; batch classifier loss: 0.140755; batch adversarial loss: 0.489673\n",
      "epoch 31; iter: 0; batch classifier loss: 0.133266; batch adversarial loss: 0.535770\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146508; batch adversarial loss: 0.387901\n",
      "epoch 33; iter: 0; batch classifier loss: 0.144307; batch adversarial loss: 0.394647\n",
      "epoch 34; iter: 0; batch classifier loss: 0.145595; batch adversarial loss: 0.511341\n",
      "epoch 35; iter: 0; batch classifier loss: 0.084488; batch adversarial loss: 0.398531\n",
      "epoch 36; iter: 0; batch classifier loss: 0.108706; batch adversarial loss: 0.469556\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110327; batch adversarial loss: 0.405384\n",
      "epoch 38; iter: 0; batch classifier loss: 0.118928; batch adversarial loss: 0.404726\n",
      "epoch 39; iter: 0; batch classifier loss: 0.081515; batch adversarial loss: 0.448553\n",
      "epoch 40; iter: 0; batch classifier loss: 0.085394; batch adversarial loss: 0.436224\n",
      "epoch 41; iter: 0; batch classifier loss: 0.069330; batch adversarial loss: 0.442353\n",
      "epoch 42; iter: 0; batch classifier loss: 0.073847; batch adversarial loss: 0.457050\n",
      "epoch 43; iter: 0; batch classifier loss: 0.103492; batch adversarial loss: 0.431724\n",
      "epoch 44; iter: 0; batch classifier loss: 0.082839; batch adversarial loss: 0.558386\n",
      "epoch 45; iter: 0; batch classifier loss: 0.155185; batch adversarial loss: 0.511527\n",
      "epoch 46; iter: 0; batch classifier loss: 0.113260; batch adversarial loss: 0.430583\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113433; batch adversarial loss: 0.344112\n",
      "epoch 48; iter: 0; batch classifier loss: 0.129299; batch adversarial loss: 0.404817\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101345; batch adversarial loss: 0.455769\n",
      "epoch 50; iter: 0; batch classifier loss: 0.063353; batch adversarial loss: 0.439989\n",
      "epoch 51; iter: 0; batch classifier loss: 0.100785; batch adversarial loss: 0.417055\n",
      "epoch 52; iter: 0; batch classifier loss: 0.079551; batch adversarial loss: 0.494653\n",
      "epoch 53; iter: 0; batch classifier loss: 0.104892; batch adversarial loss: 0.422215\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108741; batch adversarial loss: 0.470611\n",
      "epoch 55; iter: 0; batch classifier loss: 0.120094; batch adversarial loss: 0.395494\n",
      "epoch 56; iter: 0; batch classifier loss: 0.075002; batch adversarial loss: 0.358217\n",
      "epoch 57; iter: 0; batch classifier loss: 0.105327; batch adversarial loss: 0.442957\n",
      "epoch 58; iter: 0; batch classifier loss: 0.104325; batch adversarial loss: 0.515084\n",
      "epoch 59; iter: 0; batch classifier loss: 0.046847; batch adversarial loss: 0.512137\n",
      "epoch 60; iter: 0; batch classifier loss: 0.096134; batch adversarial loss: 0.487152\n",
      "epoch 61; iter: 0; batch classifier loss: 0.084271; batch adversarial loss: 0.429470\n",
      "epoch 62; iter: 0; batch classifier loss: 0.141543; batch adversarial loss: 0.459068\n",
      "epoch 63; iter: 0; batch classifier loss: 0.151821; batch adversarial loss: 0.475956\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078385; batch adversarial loss: 0.421439\n",
      "epoch 65; iter: 0; batch classifier loss: 0.113188; batch adversarial loss: 0.471301\n",
      "epoch 66; iter: 0; batch classifier loss: 0.103174; batch adversarial loss: 0.485324\n",
      "epoch 67; iter: 0; batch classifier loss: 0.109295; batch adversarial loss: 0.555271\n",
      "epoch 68; iter: 0; batch classifier loss: 0.109782; batch adversarial loss: 0.408019\n",
      "epoch 69; iter: 0; batch classifier loss: 0.108500; batch adversarial loss: 0.366400\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090016; batch adversarial loss: 0.433584\n",
      "epoch 71; iter: 0; batch classifier loss: 0.126760; batch adversarial loss: 0.589640\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077240; batch adversarial loss: 0.473668\n",
      "epoch 73; iter: 0; batch classifier loss: 0.130775; batch adversarial loss: 0.452264\n",
      "epoch 74; iter: 0; batch classifier loss: 0.091541; batch adversarial loss: 0.462644\n",
      "epoch 75; iter: 0; batch classifier loss: 0.093173; batch adversarial loss: 0.422199\n",
      "epoch 76; iter: 0; batch classifier loss: 0.132248; batch adversarial loss: 0.448544\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063778; batch adversarial loss: 0.385339\n",
      "epoch 78; iter: 0; batch classifier loss: 0.089457; batch adversarial loss: 0.408867\n",
      "epoch 79; iter: 0; batch classifier loss: 0.077802; batch adversarial loss: 0.500381\n",
      "epoch 80; iter: 0; batch classifier loss: 0.050979; batch adversarial loss: 0.486944\n",
      "epoch 81; iter: 0; batch classifier loss: 0.110098; batch adversarial loss: 0.485797\n",
      "epoch 82; iter: 0; batch classifier loss: 0.127643; batch adversarial loss: 0.462027\n",
      "epoch 83; iter: 0; batch classifier loss: 0.153393; batch adversarial loss: 0.543558\n",
      "epoch 84; iter: 0; batch classifier loss: 0.148438; batch adversarial loss: 0.383446\n",
      "epoch 85; iter: 0; batch classifier loss: 0.098058; batch adversarial loss: 0.440670\n",
      "epoch 86; iter: 0; batch classifier loss: 0.075537; batch adversarial loss: 0.533651\n",
      "epoch 87; iter: 0; batch classifier loss: 0.108869; batch adversarial loss: 0.411982\n",
      "epoch 88; iter: 0; batch classifier loss: 0.118949; batch adversarial loss: 0.447326\n",
      "epoch 89; iter: 0; batch classifier loss: 0.090752; batch adversarial loss: 0.378181\n",
      "epoch 90; iter: 0; batch classifier loss: 0.137478; batch adversarial loss: 0.393690\n",
      "epoch 91; iter: 0; batch classifier loss: 0.109701; batch adversarial loss: 0.410374\n",
      "epoch 92; iter: 0; batch classifier loss: 0.102051; batch adversarial loss: 0.466843\n",
      "epoch 93; iter: 0; batch classifier loss: 0.095669; batch adversarial loss: 0.421507\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053662; batch adversarial loss: 0.436224\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087544; batch adversarial loss: 0.484724\n",
      "epoch 96; iter: 0; batch classifier loss: 0.060369; batch adversarial loss: 0.482044\n",
      "epoch 97; iter: 0; batch classifier loss: 0.068698; batch adversarial loss: 0.461662\n",
      "epoch 98; iter: 0; batch classifier loss: 0.120600; batch adversarial loss: 0.497282\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064082; batch adversarial loss: 0.510306\n",
      "epoch 100; iter: 0; batch classifier loss: 0.071267; batch adversarial loss: 0.440140\n",
      "epoch 101; iter: 0; batch classifier loss: 0.082586; batch adversarial loss: 0.481178\n",
      "epoch 102; iter: 0; batch classifier loss: 0.077705; batch adversarial loss: 0.461090\n",
      "epoch 103; iter: 0; batch classifier loss: 0.075087; batch adversarial loss: 0.506952\n",
      "epoch 104; iter: 0; batch classifier loss: 0.084559; batch adversarial loss: 0.427546\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055519; batch adversarial loss: 0.547215\n",
      "epoch 106; iter: 0; batch classifier loss: 0.099742; batch adversarial loss: 0.401392\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047806; batch adversarial loss: 0.525576\n",
      "epoch 108; iter: 0; batch classifier loss: 0.098070; batch adversarial loss: 0.509255\n",
      "epoch 109; iter: 0; batch classifier loss: 0.095225; batch adversarial loss: 0.421065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.066475; batch adversarial loss: 0.489901\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058068; batch adversarial loss: 0.441620\n",
      "epoch 112; iter: 0; batch classifier loss: 0.060742; batch adversarial loss: 0.389495\n",
      "epoch 113; iter: 0; batch classifier loss: 0.086793; batch adversarial loss: 0.374767\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035058; batch adversarial loss: 0.555027\n",
      "epoch 115; iter: 0; batch classifier loss: 0.079409; batch adversarial loss: 0.532164\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039956; batch adversarial loss: 0.449612\n",
      "epoch 117; iter: 0; batch classifier loss: 0.022841; batch adversarial loss: 0.517583\n",
      "epoch 118; iter: 0; batch classifier loss: 0.062902; batch adversarial loss: 0.392646\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023216; batch adversarial loss: 0.485516\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039555; batch adversarial loss: 0.530114\n",
      "epoch 121; iter: 0; batch classifier loss: 0.068169; batch adversarial loss: 0.461398\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049430; batch adversarial loss: 0.539628\n",
      "epoch 123; iter: 0; batch classifier loss: 0.087642; batch adversarial loss: 0.471398\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046964; batch adversarial loss: 0.335406\n",
      "epoch 125; iter: 0; batch classifier loss: 0.067832; batch adversarial loss: 0.432622\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022422; batch adversarial loss: 0.479176\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050584; batch adversarial loss: 0.469196\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041746; batch adversarial loss: 0.489948\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023204; batch adversarial loss: 0.534087\n",
      "epoch 130; iter: 0; batch classifier loss: 0.089768; batch adversarial loss: 0.444891\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031358; batch adversarial loss: 0.456011\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045087; batch adversarial loss: 0.451288\n",
      "epoch 133; iter: 0; batch classifier loss: 0.061048; batch adversarial loss: 0.387114\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036809; batch adversarial loss: 0.382534\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050503; batch adversarial loss: 0.479217\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038785; batch adversarial loss: 0.448024\n",
      "epoch 137; iter: 0; batch classifier loss: 0.055124; batch adversarial loss: 0.418929\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022344; batch adversarial loss: 0.400081\n",
      "epoch 139; iter: 0; batch classifier loss: 0.069481; batch adversarial loss: 0.488003\n",
      "epoch 140; iter: 0; batch classifier loss: 0.058049; batch adversarial loss: 0.465352\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020564; batch adversarial loss: 0.338506\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020465; batch adversarial loss: 0.471291\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023443; batch adversarial loss: 0.470339\n",
      "epoch 144; iter: 0; batch classifier loss: 0.050829; batch adversarial loss: 0.474197\n",
      "epoch 145; iter: 0; batch classifier loss: 0.068019; batch adversarial loss: 0.416548\n",
      "epoch 146; iter: 0; batch classifier loss: 0.005369; batch adversarial loss: 0.434686\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034573; batch adversarial loss: 0.474352\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027227; batch adversarial loss: 0.431802\n",
      "epoch 149; iter: 0; batch classifier loss: 0.062402; batch adversarial loss: 0.336981\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022131; batch adversarial loss: 0.437395\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015758; batch adversarial loss: 0.468744\n",
      "epoch 152; iter: 0; batch classifier loss: 0.066611; batch adversarial loss: 0.431808\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040321; batch adversarial loss: 0.410417\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029465; batch adversarial loss: 0.601212\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018908; batch adversarial loss: 0.512553\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020766; batch adversarial loss: 0.548103\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023828; batch adversarial loss: 0.460660\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024758; batch adversarial loss: 0.435341\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017164; batch adversarial loss: 0.445873\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029644; batch adversarial loss: 0.476908\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034756; batch adversarial loss: 0.519986\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007248; batch adversarial loss: 0.454960\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022298; batch adversarial loss: 0.465882\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032512; batch adversarial loss: 0.476046\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023314; batch adversarial loss: 0.487624\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023193; batch adversarial loss: 0.390281\n",
      "epoch 167; iter: 0; batch classifier loss: 0.053155; batch adversarial loss: 0.419477\n",
      "epoch 168; iter: 0; batch classifier loss: 0.059003; batch adversarial loss: 0.443189\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021519; batch adversarial loss: 0.445445\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026666; batch adversarial loss: 0.345189\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018809; batch adversarial loss: 0.394021\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025415; batch adversarial loss: 0.460828\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020801; batch adversarial loss: 0.383524\n",
      "epoch 174; iter: 0; batch classifier loss: 0.085045; batch adversarial loss: 0.438829\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007253; batch adversarial loss: 0.442752\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016084; batch adversarial loss: 0.501976\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030471; batch adversarial loss: 0.457142\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015637; batch adversarial loss: 0.391582\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031654; batch adversarial loss: 0.417789\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012137; batch adversarial loss: 0.496928\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036925; batch adversarial loss: 0.464572\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030604; batch adversarial loss: 0.397426\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032507; batch adversarial loss: 0.488289\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026063; batch adversarial loss: 0.451837\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028573; batch adversarial loss: 0.441957\n",
      "epoch 186; iter: 0; batch classifier loss: 0.046057; batch adversarial loss: 0.438619\n",
      "epoch 187; iter: 0; batch classifier loss: 0.055293; batch adversarial loss: 0.426497\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007049; batch adversarial loss: 0.540461\n",
      "epoch 189; iter: 0; batch classifier loss: 0.059016; batch adversarial loss: 0.409083\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018848; batch adversarial loss: 0.485474\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027234; batch adversarial loss: 0.583394\n",
      "epoch 192; iter: 0; batch classifier loss: 0.061876; batch adversarial loss: 0.445554\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024362; batch adversarial loss: 0.454261\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027466; batch adversarial loss: 0.412838\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018366; batch adversarial loss: 0.578379\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015578; batch adversarial loss: 0.484383\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023014; batch adversarial loss: 0.516639\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027045; batch adversarial loss: 0.428199\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006334; batch adversarial loss: 0.438799\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711755; batch adversarial loss: 0.741957\n",
      "epoch 1; iter: 0; batch classifier loss: 0.504026; batch adversarial loss: 0.695995\n",
      "epoch 2; iter: 0; batch classifier loss: 0.357500; batch adversarial loss: 0.660478\n",
      "epoch 3; iter: 0; batch classifier loss: 0.319675; batch adversarial loss: 0.638034\n",
      "epoch 4; iter: 0; batch classifier loss: 0.433608; batch adversarial loss: 0.586671\n",
      "epoch 5; iter: 0; batch classifier loss: 0.327559; batch adversarial loss: 0.590524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.390668; batch adversarial loss: 0.548174\n",
      "epoch 7; iter: 0; batch classifier loss: 0.316992; batch adversarial loss: 0.567426\n",
      "epoch 8; iter: 0; batch classifier loss: 0.252629; batch adversarial loss: 0.531165\n",
      "epoch 9; iter: 0; batch classifier loss: 0.223139; batch adversarial loss: 0.511108\n",
      "epoch 10; iter: 0; batch classifier loss: 0.227891; batch adversarial loss: 0.455861\n",
      "epoch 11; iter: 0; batch classifier loss: 0.249246; batch adversarial loss: 0.501714\n",
      "epoch 12; iter: 0; batch classifier loss: 0.238933; batch adversarial loss: 0.472051\n",
      "epoch 13; iter: 0; batch classifier loss: 0.215303; batch adversarial loss: 0.509055\n",
      "epoch 14; iter: 0; batch classifier loss: 0.242484; batch adversarial loss: 0.499729\n",
      "epoch 15; iter: 0; batch classifier loss: 0.245222; batch adversarial loss: 0.526150\n",
      "epoch 16; iter: 0; batch classifier loss: 0.159704; batch adversarial loss: 0.534055\n",
      "epoch 17; iter: 0; batch classifier loss: 0.213566; batch adversarial loss: 0.494928\n",
      "epoch 18; iter: 0; batch classifier loss: 0.216804; batch adversarial loss: 0.468621\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223275; batch adversarial loss: 0.476448\n",
      "epoch 20; iter: 0; batch classifier loss: 0.201032; batch adversarial loss: 0.428677\n",
      "epoch 21; iter: 0; batch classifier loss: 0.253594; batch adversarial loss: 0.500441\n",
      "epoch 22; iter: 0; batch classifier loss: 0.389689; batch adversarial loss: 0.513145\n",
      "epoch 23; iter: 0; batch classifier loss: 0.330674; batch adversarial loss: 0.491061\n",
      "epoch 24; iter: 0; batch classifier loss: 0.438413; batch adversarial loss: 0.499707\n",
      "epoch 25; iter: 0; batch classifier loss: 0.278484; batch adversarial loss: 0.386367\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165939; batch adversarial loss: 0.398169\n",
      "epoch 27; iter: 0; batch classifier loss: 0.169013; batch adversarial loss: 0.501160\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184399; batch adversarial loss: 0.513757\n",
      "epoch 29; iter: 0; batch classifier loss: 0.139823; batch adversarial loss: 0.435527\n",
      "epoch 30; iter: 0; batch classifier loss: 0.132569; batch adversarial loss: 0.456606\n",
      "epoch 31; iter: 0; batch classifier loss: 0.134082; batch adversarial loss: 0.422500\n",
      "epoch 32; iter: 0; batch classifier loss: 0.186458; batch adversarial loss: 0.525863\n",
      "epoch 33; iter: 0; batch classifier loss: 0.123408; batch adversarial loss: 0.448004\n",
      "epoch 34; iter: 0; batch classifier loss: 0.080580; batch adversarial loss: 0.455042\n",
      "epoch 35; iter: 0; batch classifier loss: 0.145467; batch adversarial loss: 0.448433\n",
      "epoch 36; iter: 0; batch classifier loss: 0.081538; batch adversarial loss: 0.435481\n",
      "epoch 37; iter: 0; batch classifier loss: 0.088882; batch adversarial loss: 0.419632\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107435; batch adversarial loss: 0.441377\n",
      "epoch 39; iter: 0; batch classifier loss: 0.150209; batch adversarial loss: 0.463199\n",
      "epoch 40; iter: 0; batch classifier loss: 0.062228; batch adversarial loss: 0.411245\n",
      "epoch 41; iter: 0; batch classifier loss: 0.096000; batch adversarial loss: 0.440195\n",
      "epoch 42; iter: 0; batch classifier loss: 0.133935; batch adversarial loss: 0.386280\n",
      "epoch 43; iter: 0; batch classifier loss: 0.093409; batch adversarial loss: 0.553496\n",
      "epoch 44; iter: 0; batch classifier loss: 0.087041; batch adversarial loss: 0.448145\n",
      "epoch 45; iter: 0; batch classifier loss: 0.125476; batch adversarial loss: 0.483246\n",
      "epoch 46; iter: 0; batch classifier loss: 0.051239; batch adversarial loss: 0.551222\n",
      "epoch 47; iter: 0; batch classifier loss: 0.149285; batch adversarial loss: 0.407657\n",
      "epoch 48; iter: 0; batch classifier loss: 0.123438; batch adversarial loss: 0.484472\n",
      "epoch 49; iter: 0; batch classifier loss: 0.069176; batch adversarial loss: 0.391679\n",
      "epoch 50; iter: 0; batch classifier loss: 0.070487; batch adversarial loss: 0.461731\n",
      "epoch 51; iter: 0; batch classifier loss: 0.100279; batch adversarial loss: 0.421917\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096249; batch adversarial loss: 0.441819\n",
      "epoch 53; iter: 0; batch classifier loss: 0.108378; batch adversarial loss: 0.460326\n",
      "epoch 54; iter: 0; batch classifier loss: 0.083647; batch adversarial loss: 0.407446\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077934; batch adversarial loss: 0.412353\n",
      "epoch 56; iter: 0; batch classifier loss: 0.108287; batch adversarial loss: 0.374903\n",
      "epoch 57; iter: 0; batch classifier loss: 0.056721; batch adversarial loss: 0.536599\n",
      "epoch 58; iter: 0; batch classifier loss: 0.051734; batch adversarial loss: 0.433344\n",
      "epoch 59; iter: 0; batch classifier loss: 0.091935; batch adversarial loss: 0.475970\n",
      "epoch 60; iter: 0; batch classifier loss: 0.050277; batch adversarial loss: 0.415295\n",
      "epoch 61; iter: 0; batch classifier loss: 0.094896; batch adversarial loss: 0.531047\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101416; batch adversarial loss: 0.416398\n",
      "epoch 63; iter: 0; batch classifier loss: 0.060129; batch adversarial loss: 0.473253\n",
      "epoch 64; iter: 0; batch classifier loss: 0.059791; batch adversarial loss: 0.452274\n",
      "epoch 65; iter: 0; batch classifier loss: 0.048534; batch adversarial loss: 0.415446\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066539; batch adversarial loss: 0.402339\n",
      "epoch 67; iter: 0; batch classifier loss: 0.052313; batch adversarial loss: 0.491833\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096136; batch adversarial loss: 0.447909\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073810; batch adversarial loss: 0.418107\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065530; batch adversarial loss: 0.422055\n",
      "epoch 71; iter: 0; batch classifier loss: 0.075889; batch adversarial loss: 0.353113\n",
      "epoch 72; iter: 0; batch classifier loss: 0.059534; batch adversarial loss: 0.436963\n",
      "epoch 73; iter: 0; batch classifier loss: 0.045946; batch adversarial loss: 0.492363\n",
      "epoch 74; iter: 0; batch classifier loss: 0.048650; batch adversarial loss: 0.429726\n",
      "epoch 75; iter: 0; batch classifier loss: 0.056567; batch adversarial loss: 0.456074\n",
      "epoch 76; iter: 0; batch classifier loss: 0.097833; batch adversarial loss: 0.510987\n",
      "epoch 77; iter: 0; batch classifier loss: 0.083173; batch adversarial loss: 0.523179\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062830; batch adversarial loss: 0.491901\n",
      "epoch 79; iter: 0; batch classifier loss: 0.089203; batch adversarial loss: 0.402920\n",
      "epoch 80; iter: 0; batch classifier loss: 0.142187; batch adversarial loss: 0.399146\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069666; batch adversarial loss: 0.455318\n",
      "epoch 82; iter: 0; batch classifier loss: 0.079613; batch adversarial loss: 0.400363\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064880; batch adversarial loss: 0.412766\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065960; batch adversarial loss: 0.390834\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077081; batch adversarial loss: 0.387631\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070828; batch adversarial loss: 0.441266\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056772; batch adversarial loss: 0.394368\n",
      "epoch 88; iter: 0; batch classifier loss: 0.053900; batch adversarial loss: 0.403107\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051729; batch adversarial loss: 0.354964\n",
      "epoch 90; iter: 0; batch classifier loss: 0.035185; batch adversarial loss: 0.392974\n",
      "epoch 91; iter: 0; batch classifier loss: 0.042726; batch adversarial loss: 0.406563\n",
      "epoch 92; iter: 0; batch classifier loss: 0.072784; batch adversarial loss: 0.409827\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046235; batch adversarial loss: 0.478759\n",
      "epoch 94; iter: 0; batch classifier loss: 0.040319; batch adversarial loss: 0.518052\n",
      "epoch 95; iter: 0; batch classifier loss: 0.067670; batch adversarial loss: 0.445576\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048513; batch adversarial loss: 0.503180\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073615; batch adversarial loss: 0.476159\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048432; batch adversarial loss: 0.455109\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047859; batch adversarial loss: 0.444835\n",
      "epoch 100; iter: 0; batch classifier loss: 0.032949; batch adversarial loss: 0.418842\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057118; batch adversarial loss: 0.508529\n",
      "epoch 102; iter: 0; batch classifier loss: 0.077470; batch adversarial loss: 0.464679\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035993; batch adversarial loss: 0.409416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.067889; batch adversarial loss: 0.354939\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037687; batch adversarial loss: 0.407181\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033816; batch adversarial loss: 0.408415\n",
      "epoch 107; iter: 0; batch classifier loss: 0.020697; batch adversarial loss: 0.447655\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048877; batch adversarial loss: 0.411563\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032318; batch adversarial loss: 0.528677\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059959; batch adversarial loss: 0.449581\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036230; batch adversarial loss: 0.503770\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053926; batch adversarial loss: 0.614545\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053855; batch adversarial loss: 0.498164\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037027; batch adversarial loss: 0.445407\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033996; batch adversarial loss: 0.471441\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038097; batch adversarial loss: 0.500773\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027266; batch adversarial loss: 0.459769\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039531; batch adversarial loss: 0.386283\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059659; batch adversarial loss: 0.409905\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037638; batch adversarial loss: 0.418929\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027266; batch adversarial loss: 0.432811\n",
      "epoch 122; iter: 0; batch classifier loss: 0.102884; batch adversarial loss: 0.430919\n",
      "epoch 123; iter: 0; batch classifier loss: 0.062100; batch adversarial loss: 0.380921\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032077; batch adversarial loss: 0.525868\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027200; batch adversarial loss: 0.490949\n",
      "epoch 126; iter: 0; batch classifier loss: 0.059657; batch adversarial loss: 0.519890\n",
      "epoch 127; iter: 0; batch classifier loss: 0.062420; batch adversarial loss: 0.417595\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052934; batch adversarial loss: 0.465121\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018995; batch adversarial loss: 0.595911\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026357; batch adversarial loss: 0.448274\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042441; batch adversarial loss: 0.519680\n",
      "epoch 132; iter: 0; batch classifier loss: 0.052886; batch adversarial loss: 0.387969\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021631; batch adversarial loss: 0.372695\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033813; batch adversarial loss: 0.472796\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024336; batch adversarial loss: 0.501646\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056086; batch adversarial loss: 0.370712\n",
      "epoch 137; iter: 0; batch classifier loss: 0.012915; batch adversarial loss: 0.556351\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011482; batch adversarial loss: 0.510352\n",
      "epoch 139; iter: 0; batch classifier loss: 0.071630; batch adversarial loss: 0.386372\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045719; batch adversarial loss: 0.394273\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023259; batch adversarial loss: 0.462329\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028116; batch adversarial loss: 0.499070\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018411; batch adversarial loss: 0.422888\n",
      "epoch 144; iter: 0; batch classifier loss: 0.060374; batch adversarial loss: 0.444943\n",
      "epoch 145; iter: 0; batch classifier loss: 0.051775; batch adversarial loss: 0.575278\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025400; batch adversarial loss: 0.416032\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013714; batch adversarial loss: 0.546064\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017174; batch adversarial loss: 0.563807\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029848; batch adversarial loss: 0.431034\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036107; batch adversarial loss: 0.365205\n",
      "epoch 151; iter: 0; batch classifier loss: 0.077012; batch adversarial loss: 0.436907\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032186; batch adversarial loss: 0.430953\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027768; batch adversarial loss: 0.412238\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010256; batch adversarial loss: 0.489067\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016780; batch adversarial loss: 0.401685\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029193; batch adversarial loss: 0.426957\n",
      "epoch 157; iter: 0; batch classifier loss: 0.052693; batch adversarial loss: 0.336701\n",
      "epoch 158; iter: 0; batch classifier loss: 0.031018; batch adversarial loss: 0.444358\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010599; batch adversarial loss: 0.433865\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022286; batch adversarial loss: 0.497305\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026301; batch adversarial loss: 0.473205\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014307; batch adversarial loss: 0.430104\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014714; batch adversarial loss: 0.459227\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011835; batch adversarial loss: 0.460176\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041451; batch adversarial loss: 0.384968\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020319; batch adversarial loss: 0.333022\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035030; batch adversarial loss: 0.422626\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035835; batch adversarial loss: 0.435179\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020142; batch adversarial loss: 0.513809\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030950; batch adversarial loss: 0.466876\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033159; batch adversarial loss: 0.432336\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019685; batch adversarial loss: 0.403486\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020632; batch adversarial loss: 0.507134\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037018; batch adversarial loss: 0.485143\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009850; batch adversarial loss: 0.408058\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012775; batch adversarial loss: 0.450593\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009706; batch adversarial loss: 0.510430\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026312; batch adversarial loss: 0.398025\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025352; batch adversarial loss: 0.414426\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014180; batch adversarial loss: 0.400244\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037880; batch adversarial loss: 0.421222\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016602; batch adversarial loss: 0.450740\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011847; batch adversarial loss: 0.459170\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020762; batch adversarial loss: 0.483305\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023518; batch adversarial loss: 0.437383\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009963; batch adversarial loss: 0.379674\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028838; batch adversarial loss: 0.333131\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024826; batch adversarial loss: 0.367565\n",
      "epoch 189; iter: 0; batch classifier loss: 0.066682; batch adversarial loss: 0.475031\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017263; batch adversarial loss: 0.439162\n",
      "epoch 191; iter: 0; batch classifier loss: 0.039889; batch adversarial loss: 0.391102\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012704; batch adversarial loss: 0.459315\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023082; batch adversarial loss: 0.365211\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015048; batch adversarial loss: 0.476014\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029423; batch adversarial loss: 0.425001\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022666; batch adversarial loss: 0.474667\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010547; batch adversarial loss: 0.477440\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021940; batch adversarial loss: 0.379722\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020084; batch adversarial loss: 0.356304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.697313; batch adversarial loss: 0.658886\n",
      "epoch 1; iter: 0; batch classifier loss: 0.411884; batch adversarial loss: 0.650782\n",
      "epoch 2; iter: 0; batch classifier loss: 0.381537; batch adversarial loss: 0.637436\n",
      "epoch 3; iter: 0; batch classifier loss: 0.329703; batch adversarial loss: 0.581575\n",
      "epoch 4; iter: 0; batch classifier loss: 0.382977; batch adversarial loss: 0.556146\n",
      "epoch 5; iter: 0; batch classifier loss: 0.357405; batch adversarial loss: 0.529151\n",
      "epoch 6; iter: 0; batch classifier loss: 0.333133; batch adversarial loss: 0.561137\n",
      "epoch 7; iter: 0; batch classifier loss: 0.251083; batch adversarial loss: 0.520578\n",
      "epoch 8; iter: 0; batch classifier loss: 0.318649; batch adversarial loss: 0.495709\n",
      "epoch 9; iter: 0; batch classifier loss: 0.254800; batch adversarial loss: 0.536619\n",
      "epoch 10; iter: 0; batch classifier loss: 0.274867; batch adversarial loss: 0.448039\n",
      "epoch 11; iter: 0; batch classifier loss: 0.247944; batch adversarial loss: 0.441695\n",
      "epoch 12; iter: 0; batch classifier loss: 0.122019; batch adversarial loss: 0.518832\n",
      "epoch 13; iter: 0; batch classifier loss: 0.188790; batch adversarial loss: 0.496296\n",
      "epoch 14; iter: 0; batch classifier loss: 0.164489; batch adversarial loss: 0.417296\n",
      "epoch 15; iter: 0; batch classifier loss: 0.210565; batch adversarial loss: 0.502548\n",
      "epoch 16; iter: 0; batch classifier loss: 0.247248; batch adversarial loss: 0.490886\n",
      "epoch 17; iter: 0; batch classifier loss: 0.185949; batch adversarial loss: 0.435066\n",
      "epoch 18; iter: 0; batch classifier loss: 0.168160; batch adversarial loss: 0.469040\n",
      "epoch 19; iter: 0; batch classifier loss: 0.160521; batch adversarial loss: 0.442627\n",
      "epoch 20; iter: 0; batch classifier loss: 0.105159; batch adversarial loss: 0.429224\n",
      "epoch 21; iter: 0; batch classifier loss: 0.150684; batch adversarial loss: 0.488453\n",
      "epoch 22; iter: 0; batch classifier loss: 0.163473; batch adversarial loss: 0.433307\n",
      "epoch 23; iter: 0; batch classifier loss: 0.146248; batch adversarial loss: 0.562441\n",
      "epoch 24; iter: 0; batch classifier loss: 0.137559; batch adversarial loss: 0.533479\n",
      "epoch 25; iter: 0; batch classifier loss: 0.154949; batch adversarial loss: 0.445314\n",
      "epoch 26; iter: 0; batch classifier loss: 0.130202; batch adversarial loss: 0.528050\n",
      "epoch 27; iter: 0; batch classifier loss: 0.157907; batch adversarial loss: 0.509846\n",
      "epoch 28; iter: 0; batch classifier loss: 0.134787; batch adversarial loss: 0.548556\n",
      "epoch 29; iter: 0; batch classifier loss: 0.248555; batch adversarial loss: 0.420774\n",
      "epoch 30; iter: 0; batch classifier loss: 0.267755; batch adversarial loss: 0.460521\n",
      "epoch 31; iter: 0; batch classifier loss: 0.238866; batch adversarial loss: 0.407619\n",
      "epoch 32; iter: 0; batch classifier loss: 0.258843; batch adversarial loss: 0.468686\n",
      "epoch 33; iter: 0; batch classifier loss: 0.183566; batch adversarial loss: 0.481565\n",
      "epoch 34; iter: 0; batch classifier loss: 0.293697; batch adversarial loss: 0.516789\n",
      "epoch 35; iter: 0; batch classifier loss: 0.266925; batch adversarial loss: 0.453549\n",
      "epoch 36; iter: 0; batch classifier loss: 0.189026; batch adversarial loss: 0.482427\n",
      "epoch 37; iter: 0; batch classifier loss: 0.107727; batch adversarial loss: 0.520108\n",
      "epoch 38; iter: 0; batch classifier loss: 0.100728; batch adversarial loss: 0.397497\n",
      "epoch 39; iter: 0; batch classifier loss: 0.095138; batch adversarial loss: 0.430273\n",
      "epoch 40; iter: 0; batch classifier loss: 0.073444; batch adversarial loss: 0.403214\n",
      "epoch 41; iter: 0; batch classifier loss: 0.065975; batch adversarial loss: 0.490735\n",
      "epoch 42; iter: 0; batch classifier loss: 0.062307; batch adversarial loss: 0.492357\n",
      "epoch 43; iter: 0; batch classifier loss: 0.090312; batch adversarial loss: 0.472067\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123737; batch adversarial loss: 0.470308\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104406; batch adversarial loss: 0.390925\n",
      "epoch 46; iter: 0; batch classifier loss: 0.084955; batch adversarial loss: 0.551933\n",
      "epoch 47; iter: 0; batch classifier loss: 0.060557; batch adversarial loss: 0.408821\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082853; batch adversarial loss: 0.449501\n",
      "epoch 49; iter: 0; batch classifier loss: 0.060461; batch adversarial loss: 0.521309\n",
      "epoch 50; iter: 0; batch classifier loss: 0.113986; batch adversarial loss: 0.455190\n",
      "epoch 51; iter: 0; batch classifier loss: 0.108664; batch adversarial loss: 0.507704\n",
      "epoch 52; iter: 0; batch classifier loss: 0.120151; batch adversarial loss: 0.491129\n",
      "epoch 53; iter: 0; batch classifier loss: 0.081697; batch adversarial loss: 0.496174\n",
      "epoch 54; iter: 0; batch classifier loss: 0.102644; batch adversarial loss: 0.459053\n",
      "epoch 55; iter: 0; batch classifier loss: 0.075888; batch adversarial loss: 0.506673\n",
      "epoch 56; iter: 0; batch classifier loss: 0.074527; batch adversarial loss: 0.412503\n",
      "epoch 57; iter: 0; batch classifier loss: 0.063774; batch adversarial loss: 0.467042\n",
      "epoch 58; iter: 0; batch classifier loss: 0.079317; batch adversarial loss: 0.378422\n",
      "epoch 59; iter: 0; batch classifier loss: 0.120720; batch adversarial loss: 0.386572\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079801; batch adversarial loss: 0.482319\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090733; batch adversarial loss: 0.359362\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090390; batch adversarial loss: 0.502025\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088064; batch adversarial loss: 0.494516\n",
      "epoch 64; iter: 0; batch classifier loss: 0.057953; batch adversarial loss: 0.477307\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074946; batch adversarial loss: 0.389609\n",
      "epoch 66; iter: 0; batch classifier loss: 0.121889; batch adversarial loss: 0.475325\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107349; batch adversarial loss: 0.511816\n",
      "epoch 68; iter: 0; batch classifier loss: 0.137615; batch adversarial loss: 0.464963\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103798; batch adversarial loss: 0.366559\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065526; batch adversarial loss: 0.567019\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078732; batch adversarial loss: 0.465137\n",
      "epoch 72; iter: 0; batch classifier loss: 0.073370; batch adversarial loss: 0.562312\n",
      "epoch 73; iter: 0; batch classifier loss: 0.130774; batch adversarial loss: 0.393587\n",
      "epoch 74; iter: 0; batch classifier loss: 0.098514; batch adversarial loss: 0.496157\n",
      "epoch 75; iter: 0; batch classifier loss: 0.116135; batch adversarial loss: 0.455002\n",
      "epoch 76; iter: 0; batch classifier loss: 0.153555; batch adversarial loss: 0.438416\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063203; batch adversarial loss: 0.452813\n",
      "epoch 78; iter: 0; batch classifier loss: 0.076756; batch adversarial loss: 0.424608\n",
      "epoch 79; iter: 0; batch classifier loss: 0.058603; batch adversarial loss: 0.365191\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056347; batch adversarial loss: 0.462963\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074784; batch adversarial loss: 0.494504\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091333; batch adversarial loss: 0.472802\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079716; batch adversarial loss: 0.509884\n",
      "epoch 84; iter: 0; batch classifier loss: 0.099579; batch adversarial loss: 0.433101\n",
      "epoch 85; iter: 0; batch classifier loss: 0.089797; batch adversarial loss: 0.503595\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046689; batch adversarial loss: 0.551748\n",
      "epoch 87; iter: 0; batch classifier loss: 0.104224; batch adversarial loss: 0.343377\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064949; batch adversarial loss: 0.358398\n",
      "epoch 89; iter: 0; batch classifier loss: 0.044810; batch adversarial loss: 0.579883\n",
      "epoch 90; iter: 0; batch classifier loss: 0.096628; batch adversarial loss: 0.445608\n",
      "epoch 91; iter: 0; batch classifier loss: 0.031455; batch adversarial loss: 0.479637\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064434; batch adversarial loss: 0.469487\n",
      "epoch 93; iter: 0; batch classifier loss: 0.070648; batch adversarial loss: 0.432264\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041494; batch adversarial loss: 0.473552\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054378; batch adversarial loss: 0.471774\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044607; batch adversarial loss: 0.506740\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056198; batch adversarial loss: 0.350165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.079240; batch adversarial loss: 0.471830\n",
      "epoch 99; iter: 0; batch classifier loss: 0.036542; batch adversarial loss: 0.510100\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036819; batch adversarial loss: 0.446129\n",
      "epoch 101; iter: 0; batch classifier loss: 0.060330; batch adversarial loss: 0.438691\n",
      "epoch 102; iter: 0; batch classifier loss: 0.077093; batch adversarial loss: 0.471133\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052730; batch adversarial loss: 0.451185\n",
      "epoch 104; iter: 0; batch classifier loss: 0.076669; batch adversarial loss: 0.436408\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064706; batch adversarial loss: 0.511593\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040924; batch adversarial loss: 0.429693\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049446; batch adversarial loss: 0.449251\n",
      "epoch 108; iter: 0; batch classifier loss: 0.073608; batch adversarial loss: 0.415202\n",
      "epoch 109; iter: 0; batch classifier loss: 0.086273; batch adversarial loss: 0.501920\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053321; batch adversarial loss: 0.473280\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049573; batch adversarial loss: 0.422673\n",
      "epoch 112; iter: 0; batch classifier loss: 0.020728; batch adversarial loss: 0.465932\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057384; batch adversarial loss: 0.531361\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060609; batch adversarial loss: 0.443147\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050230; batch adversarial loss: 0.441308\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053757; batch adversarial loss: 0.524291\n",
      "epoch 117; iter: 0; batch classifier loss: 0.075540; batch adversarial loss: 0.377940\n",
      "epoch 118; iter: 0; batch classifier loss: 0.055509; batch adversarial loss: 0.361870\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044145; batch adversarial loss: 0.446553\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074204; batch adversarial loss: 0.407804\n",
      "epoch 121; iter: 0; batch classifier loss: 0.055595; batch adversarial loss: 0.403612\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028522; batch adversarial loss: 0.493880\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043255; batch adversarial loss: 0.410527\n",
      "epoch 124; iter: 0; batch classifier loss: 0.097297; batch adversarial loss: 0.534440\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030146; batch adversarial loss: 0.505725\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027878; batch adversarial loss: 0.478731\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032895; batch adversarial loss: 0.425033\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032128; batch adversarial loss: 0.477661\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048505; batch adversarial loss: 0.495260\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042613; batch adversarial loss: 0.487249\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023546; batch adversarial loss: 0.516895\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025266; batch adversarial loss: 0.440983\n",
      "epoch 133; iter: 0; batch classifier loss: 0.064249; batch adversarial loss: 0.474512\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030619; batch adversarial loss: 0.465281\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046800; batch adversarial loss: 0.494608\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029548; batch adversarial loss: 0.419637\n",
      "epoch 137; iter: 0; batch classifier loss: 0.047920; batch adversarial loss: 0.385186\n",
      "epoch 138; iter: 0; batch classifier loss: 0.057528; batch adversarial loss: 0.366076\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038979; batch adversarial loss: 0.506166\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024740; batch adversarial loss: 0.500391\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040770; batch adversarial loss: 0.449148\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022413; batch adversarial loss: 0.422694\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021419; batch adversarial loss: 0.494908\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036509; batch adversarial loss: 0.478813\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032557; batch adversarial loss: 0.428071\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024093; batch adversarial loss: 0.374109\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020240; batch adversarial loss: 0.454333\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015620; batch adversarial loss: 0.423483\n",
      "epoch 149; iter: 0; batch classifier loss: 0.046030; batch adversarial loss: 0.445763\n",
      "epoch 150; iter: 0; batch classifier loss: 0.063917; batch adversarial loss: 0.458666\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043125; batch adversarial loss: 0.461739\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020853; batch adversarial loss: 0.446816\n",
      "epoch 153; iter: 0; batch classifier loss: 0.058173; batch adversarial loss: 0.370839\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030574; batch adversarial loss: 0.498923\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031462; batch adversarial loss: 0.490735\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012258; batch adversarial loss: 0.464400\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023013; batch adversarial loss: 0.412444\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027326; batch adversarial loss: 0.445435\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021001; batch adversarial loss: 0.440088\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015078; batch adversarial loss: 0.344162\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022822; batch adversarial loss: 0.452697\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034476; batch adversarial loss: 0.518312\n",
      "epoch 163; iter: 0; batch classifier loss: 0.053081; batch adversarial loss: 0.426830\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009750; batch adversarial loss: 0.426933\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018365; batch adversarial loss: 0.424535\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029327; batch adversarial loss: 0.382711\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030904; batch adversarial loss: 0.372782\n",
      "epoch 168; iter: 0; batch classifier loss: 0.041096; batch adversarial loss: 0.348435\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029351; batch adversarial loss: 0.509452\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038325; batch adversarial loss: 0.435679\n",
      "epoch 171; iter: 0; batch classifier loss: 0.061693; batch adversarial loss: 0.398725\n",
      "epoch 172; iter: 0; batch classifier loss: 0.037036; batch adversarial loss: 0.474866\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034017; batch adversarial loss: 0.543381\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023876; batch adversarial loss: 0.556994\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028265; batch adversarial loss: 0.444733\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027602; batch adversarial loss: 0.317104\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030631; batch adversarial loss: 0.416219\n",
      "epoch 178; iter: 0; batch classifier loss: 0.041600; batch adversarial loss: 0.492282\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010504; batch adversarial loss: 0.374816\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013464; batch adversarial loss: 0.441672\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012970; batch adversarial loss: 0.455167\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026812; batch adversarial loss: 0.482494\n",
      "epoch 183; iter: 0; batch classifier loss: 0.004812; batch adversarial loss: 0.482143\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015695; batch adversarial loss: 0.414537\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031673; batch adversarial loss: 0.506476\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008994; batch adversarial loss: 0.354253\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026060; batch adversarial loss: 0.485997\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030617; batch adversarial loss: 0.487130\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016929; batch adversarial loss: 0.519136\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025480; batch adversarial loss: 0.563288\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020024; batch adversarial loss: 0.450817\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006730; batch adversarial loss: 0.476026\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011503; batch adversarial loss: 0.458817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.014870; batch adversarial loss: 0.450854\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019539; batch adversarial loss: 0.477457\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018400; batch adversarial loss: 0.425276\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022356; batch adversarial loss: 0.389952\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013037; batch adversarial loss: 0.417229\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022837; batch adversarial loss: 0.513287\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717136; batch adversarial loss: 0.665612\n",
      "epoch 1; iter: 0; batch classifier loss: 0.453835; batch adversarial loss: 0.636456\n",
      "epoch 2; iter: 0; batch classifier loss: 0.394624; batch adversarial loss: 0.604336\n",
      "epoch 3; iter: 0; batch classifier loss: 0.454989; batch adversarial loss: 0.568058\n",
      "epoch 4; iter: 0; batch classifier loss: 0.376891; batch adversarial loss: 0.565023\n",
      "epoch 5; iter: 0; batch classifier loss: 0.360025; batch adversarial loss: 0.530030\n",
      "epoch 6; iter: 0; batch classifier loss: 0.289217; batch adversarial loss: 0.523562\n",
      "epoch 7; iter: 0; batch classifier loss: 0.301320; batch adversarial loss: 0.541818\n",
      "epoch 8; iter: 0; batch classifier loss: 0.236337; batch adversarial loss: 0.549019\n",
      "epoch 9; iter: 0; batch classifier loss: 0.280272; batch adversarial loss: 0.427203\n",
      "epoch 10; iter: 0; batch classifier loss: 0.202790; batch adversarial loss: 0.451050\n",
      "epoch 11; iter: 0; batch classifier loss: 0.206430; batch adversarial loss: 0.457226\n",
      "epoch 12; iter: 0; batch classifier loss: 0.229586; batch adversarial loss: 0.497368\n",
      "epoch 13; iter: 0; batch classifier loss: 0.264918; batch adversarial loss: 0.457138\n",
      "epoch 14; iter: 0; batch classifier loss: 0.184435; batch adversarial loss: 0.457110\n",
      "epoch 15; iter: 0; batch classifier loss: 0.336691; batch adversarial loss: 0.488099\n",
      "epoch 16; iter: 0; batch classifier loss: 0.187666; batch adversarial loss: 0.550168\n",
      "epoch 17; iter: 0; batch classifier loss: 0.166107; batch adversarial loss: 0.510774\n",
      "epoch 18; iter: 0; batch classifier loss: 0.262946; batch adversarial loss: 0.530370\n",
      "epoch 19; iter: 0; batch classifier loss: 0.226534; batch adversarial loss: 0.427739\n",
      "epoch 20; iter: 0; batch classifier loss: 0.195292; batch adversarial loss: 0.457044\n",
      "epoch 21; iter: 0; batch classifier loss: 0.251113; batch adversarial loss: 0.518017\n",
      "epoch 22; iter: 0; batch classifier loss: 0.199415; batch adversarial loss: 0.457915\n",
      "epoch 23; iter: 0; batch classifier loss: 0.230213; batch adversarial loss: 0.497256\n",
      "epoch 24; iter: 0; batch classifier loss: 0.308609; batch adversarial loss: 0.478474\n",
      "epoch 25; iter: 0; batch classifier loss: 0.453631; batch adversarial loss: 0.550163\n",
      "epoch 26; iter: 0; batch classifier loss: 0.379716; batch adversarial loss: 0.475144\n",
      "epoch 27; iter: 0; batch classifier loss: 0.212937; batch adversarial loss: 0.430065\n",
      "epoch 28; iter: 0; batch classifier loss: 0.148837; batch adversarial loss: 0.452689\n",
      "epoch 29; iter: 0; batch classifier loss: 0.139705; batch adversarial loss: 0.443844\n",
      "epoch 30; iter: 0; batch classifier loss: 0.126636; batch adversarial loss: 0.448539\n",
      "epoch 31; iter: 0; batch classifier loss: 0.142805; batch adversarial loss: 0.484569\n",
      "epoch 32; iter: 0; batch classifier loss: 0.101086; batch adversarial loss: 0.468316\n",
      "epoch 33; iter: 0; batch classifier loss: 0.134937; batch adversarial loss: 0.411570\n",
      "epoch 34; iter: 0; batch classifier loss: 0.098338; batch adversarial loss: 0.423922\n",
      "epoch 35; iter: 0; batch classifier loss: 0.103399; batch adversarial loss: 0.453153\n",
      "epoch 36; iter: 0; batch classifier loss: 0.092786; batch adversarial loss: 0.405223\n",
      "epoch 37; iter: 0; batch classifier loss: 0.094625; batch adversarial loss: 0.471480\n",
      "epoch 38; iter: 0; batch classifier loss: 0.091792; batch adversarial loss: 0.461756\n",
      "epoch 39; iter: 0; batch classifier loss: 0.090314; batch adversarial loss: 0.449641\n",
      "epoch 40; iter: 0; batch classifier loss: 0.089693; batch adversarial loss: 0.464744\n",
      "epoch 41; iter: 0; batch classifier loss: 0.085835; batch adversarial loss: 0.410968\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110985; batch adversarial loss: 0.471049\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104277; batch adversarial loss: 0.477619\n",
      "epoch 44; iter: 0; batch classifier loss: 0.116900; batch adversarial loss: 0.447156\n",
      "epoch 45; iter: 0; batch classifier loss: 0.101097; batch adversarial loss: 0.455595\n",
      "epoch 46; iter: 0; batch classifier loss: 0.101304; batch adversarial loss: 0.427404\n",
      "epoch 47; iter: 0; batch classifier loss: 0.083670; batch adversarial loss: 0.430647\n",
      "epoch 48; iter: 0; batch classifier loss: 0.059429; batch adversarial loss: 0.587874\n",
      "epoch 49; iter: 0; batch classifier loss: 0.081283; batch adversarial loss: 0.439315\n",
      "epoch 50; iter: 0; batch classifier loss: 0.060456; batch adversarial loss: 0.474171\n",
      "epoch 51; iter: 0; batch classifier loss: 0.110537; batch adversarial loss: 0.546258\n",
      "epoch 52; iter: 0; batch classifier loss: 0.087682; batch adversarial loss: 0.477735\n",
      "epoch 53; iter: 0; batch classifier loss: 0.119492; batch adversarial loss: 0.458477\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103869; batch adversarial loss: 0.478275\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087590; batch adversarial loss: 0.441879\n",
      "epoch 56; iter: 0; batch classifier loss: 0.076984; batch adversarial loss: 0.499431\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061467; batch adversarial loss: 0.604844\n",
      "epoch 58; iter: 0; batch classifier loss: 0.127093; batch adversarial loss: 0.401366\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105044; batch adversarial loss: 0.499663\n",
      "epoch 60; iter: 0; batch classifier loss: 0.107366; batch adversarial loss: 0.483822\n",
      "epoch 61; iter: 0; batch classifier loss: 0.106193; batch adversarial loss: 0.440182\n",
      "epoch 62; iter: 0; batch classifier loss: 0.098425; batch adversarial loss: 0.425891\n",
      "epoch 63; iter: 0; batch classifier loss: 0.123210; batch adversarial loss: 0.329135\n",
      "epoch 64; iter: 0; batch classifier loss: 0.048085; batch adversarial loss: 0.488058\n",
      "epoch 65; iter: 0; batch classifier loss: 0.047341; batch adversarial loss: 0.435649\n",
      "epoch 66; iter: 0; batch classifier loss: 0.104602; batch adversarial loss: 0.552365\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069518; batch adversarial loss: 0.453888\n",
      "epoch 68; iter: 0; batch classifier loss: 0.072424; batch adversarial loss: 0.527896\n",
      "epoch 69; iter: 0; batch classifier loss: 0.106619; batch adversarial loss: 0.399953\n",
      "epoch 70; iter: 0; batch classifier loss: 0.115406; batch adversarial loss: 0.452042\n",
      "epoch 71; iter: 0; batch classifier loss: 0.048896; batch adversarial loss: 0.441069\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100294; batch adversarial loss: 0.424026\n",
      "epoch 73; iter: 0; batch classifier loss: 0.086249; batch adversarial loss: 0.395019\n",
      "epoch 74; iter: 0; batch classifier loss: 0.078533; batch adversarial loss: 0.378584\n",
      "epoch 75; iter: 0; batch classifier loss: 0.046056; batch adversarial loss: 0.563568\n",
      "epoch 76; iter: 0; batch classifier loss: 0.099360; batch adversarial loss: 0.374286\n",
      "epoch 77; iter: 0; batch classifier loss: 0.049804; batch adversarial loss: 0.414893\n",
      "epoch 78; iter: 0; batch classifier loss: 0.099656; batch adversarial loss: 0.536944\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070633; batch adversarial loss: 0.454220\n",
      "epoch 80; iter: 0; batch classifier loss: 0.047878; batch adversarial loss: 0.504130\n",
      "epoch 81; iter: 0; batch classifier loss: 0.070735; batch adversarial loss: 0.386776\n",
      "epoch 82; iter: 0; batch classifier loss: 0.076055; batch adversarial loss: 0.446490\n",
      "epoch 83; iter: 0; batch classifier loss: 0.113353; batch adversarial loss: 0.535962\n",
      "epoch 84; iter: 0; batch classifier loss: 0.083549; batch adversarial loss: 0.395768\n",
      "epoch 85; iter: 0; batch classifier loss: 0.079285; batch adversarial loss: 0.533194\n",
      "epoch 86; iter: 0; batch classifier loss: 0.111781; batch adversarial loss: 0.474430\n",
      "epoch 87; iter: 0; batch classifier loss: 0.085352; batch adversarial loss: 0.490203\n",
      "epoch 88; iter: 0; batch classifier loss: 0.100017; batch adversarial loss: 0.444403\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058435; batch adversarial loss: 0.423164\n",
      "epoch 90; iter: 0; batch classifier loss: 0.037469; batch adversarial loss: 0.546707\n",
      "epoch 91; iter: 0; batch classifier loss: 0.078355; batch adversarial loss: 0.514852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.074192; batch adversarial loss: 0.439408\n",
      "epoch 93; iter: 0; batch classifier loss: 0.049992; batch adversarial loss: 0.419183\n",
      "epoch 94; iter: 0; batch classifier loss: 0.071948; batch adversarial loss: 0.387541\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057801; batch adversarial loss: 0.426110\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068754; batch adversarial loss: 0.483427\n",
      "epoch 97; iter: 0; batch classifier loss: 0.085805; batch adversarial loss: 0.514140\n",
      "epoch 98; iter: 0; batch classifier loss: 0.032248; batch adversarial loss: 0.437942\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037791; batch adversarial loss: 0.348237\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066886; batch adversarial loss: 0.514637\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051590; batch adversarial loss: 0.349369\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057034; batch adversarial loss: 0.400923\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060651; batch adversarial loss: 0.405254\n",
      "epoch 104; iter: 0; batch classifier loss: 0.029081; batch adversarial loss: 0.500019\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046136; batch adversarial loss: 0.393947\n",
      "epoch 106; iter: 0; batch classifier loss: 0.028583; batch adversarial loss: 0.521827\n",
      "epoch 107; iter: 0; batch classifier loss: 0.075912; batch adversarial loss: 0.450345\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048720; batch adversarial loss: 0.480025\n",
      "epoch 109; iter: 0; batch classifier loss: 0.028420; batch adversarial loss: 0.438904\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068829; batch adversarial loss: 0.462412\n",
      "epoch 111; iter: 0; batch classifier loss: 0.089631; batch adversarial loss: 0.498127\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047430; batch adversarial loss: 0.430499\n",
      "epoch 113; iter: 0; batch classifier loss: 0.013146; batch adversarial loss: 0.537009\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046563; batch adversarial loss: 0.475743\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038151; batch adversarial loss: 0.480884\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050973; batch adversarial loss: 0.409604\n",
      "epoch 117; iter: 0; batch classifier loss: 0.083461; batch adversarial loss: 0.498544\n",
      "epoch 118; iter: 0; batch classifier loss: 0.096217; batch adversarial loss: 0.409297\n",
      "epoch 119; iter: 0; batch classifier loss: 0.020751; batch adversarial loss: 0.488384\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047331; batch adversarial loss: 0.381957\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048376; batch adversarial loss: 0.443816\n",
      "epoch 122; iter: 0; batch classifier loss: 0.019299; batch adversarial loss: 0.379207\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043429; batch adversarial loss: 0.416165\n",
      "epoch 124; iter: 0; batch classifier loss: 0.034356; batch adversarial loss: 0.504584\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032325; batch adversarial loss: 0.458837\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032773; batch adversarial loss: 0.390390\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051230; batch adversarial loss: 0.456748\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037490; batch adversarial loss: 0.424427\n",
      "epoch 129; iter: 0; batch classifier loss: 0.074029; batch adversarial loss: 0.469415\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027241; batch adversarial loss: 0.543083\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047369; batch adversarial loss: 0.455889\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046529; batch adversarial loss: 0.425594\n",
      "epoch 133; iter: 0; batch classifier loss: 0.059522; batch adversarial loss: 0.425012\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026529; batch adversarial loss: 0.437525\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029270; batch adversarial loss: 0.440467\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034005; batch adversarial loss: 0.520664\n",
      "epoch 137; iter: 0; batch classifier loss: 0.019719; batch adversarial loss: 0.470617\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033104; batch adversarial loss: 0.435662\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030996; batch adversarial loss: 0.413586\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021765; batch adversarial loss: 0.551872\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028049; batch adversarial loss: 0.465075\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027359; batch adversarial loss: 0.563345\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018658; batch adversarial loss: 0.375142\n",
      "epoch 144; iter: 0; batch classifier loss: 0.057502; batch adversarial loss: 0.505844\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026102; batch adversarial loss: 0.417725\n",
      "epoch 146; iter: 0; batch classifier loss: 0.049959; batch adversarial loss: 0.411478\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035369; batch adversarial loss: 0.433336\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023506; batch adversarial loss: 0.519812\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039156; batch adversarial loss: 0.451002\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052540; batch adversarial loss: 0.398353\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034930; batch adversarial loss: 0.519448\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038768; batch adversarial loss: 0.449087\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016575; batch adversarial loss: 0.404401\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016328; batch adversarial loss: 0.436031\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012774; batch adversarial loss: 0.451922\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033591; batch adversarial loss: 0.413773\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014914; batch adversarial loss: 0.545337\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021478; batch adversarial loss: 0.420299\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033757; batch adversarial loss: 0.465177\n",
      "epoch 160; iter: 0; batch classifier loss: 0.042248; batch adversarial loss: 0.433698\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035139; batch adversarial loss: 0.502003\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037114; batch adversarial loss: 0.406284\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023783; batch adversarial loss: 0.450390\n",
      "epoch 164; iter: 0; batch classifier loss: 0.046693; batch adversarial loss: 0.445471\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026058; batch adversarial loss: 0.467795\n",
      "epoch 166; iter: 0; batch classifier loss: 0.044719; batch adversarial loss: 0.344281\n",
      "epoch 167; iter: 0; batch classifier loss: 0.046246; batch adversarial loss: 0.459583\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018777; batch adversarial loss: 0.410829\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008143; batch adversarial loss: 0.453217\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024058; batch adversarial loss: 0.559482\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023801; batch adversarial loss: 0.474726\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011071; batch adversarial loss: 0.408334\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009940; batch adversarial loss: 0.357060\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023665; batch adversarial loss: 0.544710\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012308; batch adversarial loss: 0.450303\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017687; batch adversarial loss: 0.449074\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013987; batch adversarial loss: 0.496629\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035092; batch adversarial loss: 0.414042\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036360; batch adversarial loss: 0.556610\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012885; batch adversarial loss: 0.418108\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024933; batch adversarial loss: 0.372426\n",
      "epoch 182; iter: 0; batch classifier loss: 0.039419; batch adversarial loss: 0.464876\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020509; batch adversarial loss: 0.448395\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003141; batch adversarial loss: 0.448754\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010876; batch adversarial loss: 0.497940\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008927; batch adversarial loss: 0.623628\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021716; batch adversarial loss: 0.421722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.028360; batch adversarial loss: 0.489337\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035880; batch adversarial loss: 0.451722\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009330; batch adversarial loss: 0.513334\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029957; batch adversarial loss: 0.459804\n",
      "epoch 192; iter: 0; batch classifier loss: 0.050290; batch adversarial loss: 0.583997\n",
      "epoch 193; iter: 0; batch classifier loss: 0.058110; batch adversarial loss: 0.469642\n",
      "epoch 194; iter: 0; batch classifier loss: 0.040341; batch adversarial loss: 0.470981\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022796; batch adversarial loss: 0.418190\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009967; batch adversarial loss: 0.529940\n",
      "epoch 197; iter: 0; batch classifier loss: 0.036802; batch adversarial loss: 0.431054\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019222; batch adversarial loss: 0.522434\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012399; batch adversarial loss: 0.442520\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708759; batch adversarial loss: 1.031949\n",
      "epoch 1; iter: 0; batch classifier loss: 0.738969; batch adversarial loss: 1.097251\n",
      "epoch 2; iter: 0; batch classifier loss: 0.950950; batch adversarial loss: 1.106856\n",
      "epoch 3; iter: 0; batch classifier loss: 1.036958; batch adversarial loss: 1.004264\n",
      "epoch 4; iter: 0; batch classifier loss: 1.087122; batch adversarial loss: 0.912868\n",
      "epoch 5; iter: 0; batch classifier loss: 1.110181; batch adversarial loss: 0.827609\n",
      "epoch 6; iter: 0; batch classifier loss: 0.993954; batch adversarial loss: 0.760446\n",
      "epoch 7; iter: 0; batch classifier loss: 0.885061; batch adversarial loss: 0.668597\n",
      "epoch 8; iter: 0; batch classifier loss: 0.720169; batch adversarial loss: 0.662879\n",
      "epoch 9; iter: 0; batch classifier loss: 0.595078; batch adversarial loss: 0.597845\n",
      "epoch 10; iter: 0; batch classifier loss: 0.493762; batch adversarial loss: 0.569194\n",
      "epoch 11; iter: 0; batch classifier loss: 0.344346; batch adversarial loss: 0.485452\n",
      "epoch 12; iter: 0; batch classifier loss: 0.370944; batch adversarial loss: 0.537591\n",
      "epoch 13; iter: 0; batch classifier loss: 0.311185; batch adversarial loss: 0.494850\n",
      "epoch 14; iter: 0; batch classifier loss: 0.227790; batch adversarial loss: 0.506616\n",
      "epoch 15; iter: 0; batch classifier loss: 0.269618; batch adversarial loss: 0.513299\n",
      "epoch 16; iter: 0; batch classifier loss: 0.207889; batch adversarial loss: 0.518491\n",
      "epoch 17; iter: 0; batch classifier loss: 0.254969; batch adversarial loss: 0.465045\n",
      "epoch 18; iter: 0; batch classifier loss: 0.225783; batch adversarial loss: 0.428888\n",
      "epoch 19; iter: 0; batch classifier loss: 0.238930; batch adversarial loss: 0.561251\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220785; batch adversarial loss: 0.522064\n",
      "epoch 21; iter: 0; batch classifier loss: 0.253627; batch adversarial loss: 0.465307\n",
      "epoch 22; iter: 0; batch classifier loss: 0.219268; batch adversarial loss: 0.472523\n",
      "epoch 23; iter: 0; batch classifier loss: 0.172413; batch adversarial loss: 0.506954\n",
      "epoch 24; iter: 0; batch classifier loss: 0.221734; batch adversarial loss: 0.467478\n",
      "epoch 25; iter: 0; batch classifier loss: 0.229928; batch adversarial loss: 0.443720\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181058; batch adversarial loss: 0.517306\n",
      "epoch 27; iter: 0; batch classifier loss: 0.179374; batch adversarial loss: 0.529795\n",
      "epoch 28; iter: 0; batch classifier loss: 0.188783; batch adversarial loss: 0.525889\n",
      "epoch 29; iter: 0; batch classifier loss: 0.160907; batch adversarial loss: 0.480740\n",
      "epoch 30; iter: 0; batch classifier loss: 0.275982; batch adversarial loss: 0.446046\n",
      "epoch 31; iter: 0; batch classifier loss: 0.186501; batch adversarial loss: 0.478999\n",
      "epoch 32; iter: 0; batch classifier loss: 0.175010; batch adversarial loss: 0.465359\n",
      "epoch 33; iter: 0; batch classifier loss: 0.169474; batch adversarial loss: 0.436577\n",
      "epoch 34; iter: 0; batch classifier loss: 0.139779; batch adversarial loss: 0.455517\n",
      "epoch 35; iter: 0; batch classifier loss: 0.196586; batch adversarial loss: 0.404044\n",
      "epoch 36; iter: 0; batch classifier loss: 0.186455; batch adversarial loss: 0.471233\n",
      "epoch 37; iter: 0; batch classifier loss: 0.136711; batch adversarial loss: 0.522959\n",
      "epoch 38; iter: 0; batch classifier loss: 0.163649; batch adversarial loss: 0.476933\n",
      "epoch 39; iter: 0; batch classifier loss: 0.155614; batch adversarial loss: 0.432302\n",
      "epoch 40; iter: 0; batch classifier loss: 0.115428; batch adversarial loss: 0.427488\n",
      "epoch 41; iter: 0; batch classifier loss: 0.173393; batch adversarial loss: 0.399281\n",
      "epoch 42; iter: 0; batch classifier loss: 0.112533; batch adversarial loss: 0.562781\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104261; batch adversarial loss: 0.414773\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101389; batch adversarial loss: 0.450494\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108047; batch adversarial loss: 0.533013\n",
      "epoch 46; iter: 0; batch classifier loss: 0.134977; batch adversarial loss: 0.398318\n",
      "epoch 47; iter: 0; batch classifier loss: 0.109178; batch adversarial loss: 0.527313\n",
      "epoch 48; iter: 0; batch classifier loss: 0.151947; batch adversarial loss: 0.404489\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099528; batch adversarial loss: 0.464600\n",
      "epoch 50; iter: 0; batch classifier loss: 0.111322; batch adversarial loss: 0.395984\n",
      "epoch 51; iter: 0; batch classifier loss: 0.079122; batch adversarial loss: 0.478452\n",
      "epoch 52; iter: 0; batch classifier loss: 0.066109; batch adversarial loss: 0.340219\n",
      "epoch 53; iter: 0; batch classifier loss: 0.078625; batch adversarial loss: 0.508023\n",
      "epoch 54; iter: 0; batch classifier loss: 0.079247; batch adversarial loss: 0.475552\n",
      "epoch 55; iter: 0; batch classifier loss: 0.116629; batch adversarial loss: 0.437657\n",
      "epoch 56; iter: 0; batch classifier loss: 0.073257; batch adversarial loss: 0.451723\n",
      "epoch 57; iter: 0; batch classifier loss: 0.093305; batch adversarial loss: 0.470006\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080920; batch adversarial loss: 0.395352\n",
      "epoch 59; iter: 0; batch classifier loss: 0.095722; batch adversarial loss: 0.430365\n",
      "epoch 60; iter: 0; batch classifier loss: 0.082735; batch adversarial loss: 0.478587\n",
      "epoch 61; iter: 0; batch classifier loss: 0.068517; batch adversarial loss: 0.471279\n",
      "epoch 62; iter: 0; batch classifier loss: 0.137290; batch adversarial loss: 0.485697\n",
      "epoch 63; iter: 0; batch classifier loss: 0.086299; batch adversarial loss: 0.495829\n",
      "epoch 64; iter: 0; batch classifier loss: 0.060712; batch adversarial loss: 0.419625\n",
      "epoch 65; iter: 0; batch classifier loss: 0.091658; batch adversarial loss: 0.490584\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072993; batch adversarial loss: 0.477200\n",
      "epoch 67; iter: 0; batch classifier loss: 0.041389; batch adversarial loss: 0.403706\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096394; batch adversarial loss: 0.504874\n",
      "epoch 69; iter: 0; batch classifier loss: 0.068240; batch adversarial loss: 0.446790\n",
      "epoch 70; iter: 0; batch classifier loss: 0.049871; batch adversarial loss: 0.409303\n",
      "epoch 71; iter: 0; batch classifier loss: 0.061666; batch adversarial loss: 0.454229\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087313; batch adversarial loss: 0.441417\n",
      "epoch 73; iter: 0; batch classifier loss: 0.053163; batch adversarial loss: 0.432415\n",
      "epoch 74; iter: 0; batch classifier loss: 0.038508; batch adversarial loss: 0.450739\n",
      "epoch 75; iter: 0; batch classifier loss: 0.056299; batch adversarial loss: 0.502101\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058769; batch adversarial loss: 0.404807\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050098; batch adversarial loss: 0.454831\n",
      "epoch 78; iter: 0; batch classifier loss: 0.118714; batch adversarial loss: 0.454105\n",
      "epoch 79; iter: 0; batch classifier loss: 0.058079; batch adversarial loss: 0.479167\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076155; batch adversarial loss: 0.431326\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057850; batch adversarial loss: 0.508960\n",
      "epoch 82; iter: 0; batch classifier loss: 0.042005; batch adversarial loss: 0.498872\n",
      "epoch 83; iter: 0; batch classifier loss: 0.069676; batch adversarial loss: 0.474725\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062378; batch adversarial loss: 0.435395\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076545; batch adversarial loss: 0.524113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.047798; batch adversarial loss: 0.482328\n",
      "epoch 87; iter: 0; batch classifier loss: 0.031845; batch adversarial loss: 0.487766\n",
      "epoch 88; iter: 0; batch classifier loss: 0.044698; batch adversarial loss: 0.499922\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056227; batch adversarial loss: 0.395208\n",
      "epoch 90; iter: 0; batch classifier loss: 0.024185; batch adversarial loss: 0.400273\n",
      "epoch 91; iter: 0; batch classifier loss: 0.051862; batch adversarial loss: 0.491263\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048749; batch adversarial loss: 0.467045\n",
      "epoch 93; iter: 0; batch classifier loss: 0.024558; batch adversarial loss: 0.452162\n",
      "epoch 94; iter: 0; batch classifier loss: 0.035096; batch adversarial loss: 0.432015\n",
      "epoch 95; iter: 0; batch classifier loss: 0.017609; batch adversarial loss: 0.558297\n",
      "epoch 96; iter: 0; batch classifier loss: 0.028702; batch adversarial loss: 0.433534\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043825; batch adversarial loss: 0.455020\n",
      "epoch 98; iter: 0; batch classifier loss: 0.040845; batch adversarial loss: 0.459021\n",
      "epoch 99; iter: 0; batch classifier loss: 0.088995; batch adversarial loss: 0.377534\n",
      "epoch 100; iter: 0; batch classifier loss: 0.076034; batch adversarial loss: 0.362190\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046225; batch adversarial loss: 0.471480\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029797; batch adversarial loss: 0.466249\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055314; batch adversarial loss: 0.473453\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041858; batch adversarial loss: 0.366051\n",
      "epoch 105; iter: 0; batch classifier loss: 0.036926; batch adversarial loss: 0.542880\n",
      "epoch 106; iter: 0; batch classifier loss: 0.021102; batch adversarial loss: 0.472559\n",
      "epoch 107; iter: 0; batch classifier loss: 0.029353; batch adversarial loss: 0.422800\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058848; batch adversarial loss: 0.476112\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061185; batch adversarial loss: 0.438526\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049878; batch adversarial loss: 0.437492\n",
      "epoch 111; iter: 0; batch classifier loss: 0.038088; batch adversarial loss: 0.475467\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024293; batch adversarial loss: 0.495058\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038015; batch adversarial loss: 0.437617\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051203; batch adversarial loss: 0.383108\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035149; batch adversarial loss: 0.396773\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043591; batch adversarial loss: 0.467439\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034809; batch adversarial loss: 0.519673\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039619; batch adversarial loss: 0.456683\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041249; batch adversarial loss: 0.384891\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050581; batch adversarial loss: 0.453406\n",
      "epoch 121; iter: 0; batch classifier loss: 0.015370; batch adversarial loss: 0.392776\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048659; batch adversarial loss: 0.487067\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035097; batch adversarial loss: 0.454791\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035760; batch adversarial loss: 0.411255\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020221; batch adversarial loss: 0.435874\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028995; batch adversarial loss: 0.479132\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025164; batch adversarial loss: 0.411922\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028630; batch adversarial loss: 0.375800\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034297; batch adversarial loss: 0.531237\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029960; batch adversarial loss: 0.447328\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017390; batch adversarial loss: 0.457818\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022388; batch adversarial loss: 0.419752\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015810; batch adversarial loss: 0.543431\n",
      "epoch 134; iter: 0; batch classifier loss: 0.046840; batch adversarial loss: 0.490329\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034442; batch adversarial loss: 0.443656\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026336; batch adversarial loss: 0.515021\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017672; batch adversarial loss: 0.396510\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029126; batch adversarial loss: 0.404588\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038965; batch adversarial loss: 0.498062\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050648; batch adversarial loss: 0.482748\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022144; batch adversarial loss: 0.488175\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037678; batch adversarial loss: 0.505544\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033017; batch adversarial loss: 0.499603\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036787; batch adversarial loss: 0.475036\n",
      "epoch 145; iter: 0; batch classifier loss: 0.050859; batch adversarial loss: 0.586658\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035535; batch adversarial loss: 0.433911\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040768; batch adversarial loss: 0.434894\n",
      "epoch 148; iter: 0; batch classifier loss: 0.062640; batch adversarial loss: 0.443787\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012198; batch adversarial loss: 0.477094\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031132; batch adversarial loss: 0.440556\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042412; batch adversarial loss: 0.441392\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019913; batch adversarial loss: 0.473726\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020524; batch adversarial loss: 0.415189\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040592; batch adversarial loss: 0.450954\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028600; batch adversarial loss: 0.469077\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030904; batch adversarial loss: 0.349401\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028821; batch adversarial loss: 0.535029\n",
      "epoch 158; iter: 0; batch classifier loss: 0.043633; batch adversarial loss: 0.512438\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018656; batch adversarial loss: 0.444161\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033201; batch adversarial loss: 0.479981\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026037; batch adversarial loss: 0.441024\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041445; batch adversarial loss: 0.440859\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023375; batch adversarial loss: 0.399657\n",
      "epoch 164; iter: 0; batch classifier loss: 0.076112; batch adversarial loss: 0.492065\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023751; batch adversarial loss: 0.433264\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025413; batch adversarial loss: 0.492425\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016115; batch adversarial loss: 0.501387\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031284; batch adversarial loss: 0.385292\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028531; batch adversarial loss: 0.505064\n",
      "epoch 170; iter: 0; batch classifier loss: 0.002043; batch adversarial loss: 0.468112\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009800; batch adversarial loss: 0.508683\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025044; batch adversarial loss: 0.389526\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025787; batch adversarial loss: 0.484438\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010336; batch adversarial loss: 0.400689\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007090; batch adversarial loss: 0.492842\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015433; batch adversarial loss: 0.400536\n",
      "epoch 177; iter: 0; batch classifier loss: 0.007629; batch adversarial loss: 0.461062\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016522; batch adversarial loss: 0.520764\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020072; batch adversarial loss: 0.442996\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020918; batch adversarial loss: 0.369404\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010702; batch adversarial loss: 0.435196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.010436; batch adversarial loss: 0.481907\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014621; batch adversarial loss: 0.355639\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020074; batch adversarial loss: 0.459095\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011101; batch adversarial loss: 0.439973\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015413; batch adversarial loss: 0.433970\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018928; batch adversarial loss: 0.475413\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026263; batch adversarial loss: 0.529109\n",
      "epoch 189; iter: 0; batch classifier loss: 0.038153; batch adversarial loss: 0.430533\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034513; batch adversarial loss: 0.502122\n",
      "epoch 191; iter: 0; batch classifier loss: 0.036614; batch adversarial loss: 0.523386\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017945; batch adversarial loss: 0.513335\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012278; batch adversarial loss: 0.455711\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010469; batch adversarial loss: 0.479451\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014227; batch adversarial loss: 0.427166\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012937; batch adversarial loss: 0.339283\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034885; batch adversarial loss: 0.521428\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005803; batch adversarial loss: 0.448641\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024093; batch adversarial loss: 0.401101\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709076; batch adversarial loss: 0.748805\n",
      "epoch 1; iter: 0; batch classifier loss: 0.508029; batch adversarial loss: 0.701714\n",
      "epoch 2; iter: 0; batch classifier loss: 0.446530; batch adversarial loss: 0.650989\n",
      "epoch 3; iter: 0; batch classifier loss: 0.401297; batch adversarial loss: 0.628110\n",
      "epoch 4; iter: 0; batch classifier loss: 0.430309; batch adversarial loss: 0.585990\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343962; batch adversarial loss: 0.574393\n",
      "epoch 6; iter: 0; batch classifier loss: 0.428562; batch adversarial loss: 0.549053\n",
      "epoch 7; iter: 0; batch classifier loss: 0.362347; batch adversarial loss: 0.547042\n",
      "epoch 8; iter: 0; batch classifier loss: 0.361882; batch adversarial loss: 0.565893\n",
      "epoch 9; iter: 0; batch classifier loss: 0.348764; batch adversarial loss: 0.551448\n",
      "epoch 10; iter: 0; batch classifier loss: 0.393367; batch adversarial loss: 0.602636\n",
      "epoch 11; iter: 0; batch classifier loss: 0.377963; batch adversarial loss: 0.474549\n",
      "epoch 12; iter: 0; batch classifier loss: 0.405322; batch adversarial loss: 0.505035\n",
      "epoch 13; iter: 0; batch classifier loss: 0.390311; batch adversarial loss: 0.514456\n",
      "epoch 14; iter: 0; batch classifier loss: 0.354726; batch adversarial loss: 0.478015\n",
      "epoch 15; iter: 0; batch classifier loss: 0.368576; batch adversarial loss: 0.487446\n",
      "epoch 16; iter: 0; batch classifier loss: 0.450595; batch adversarial loss: 0.468277\n",
      "epoch 17; iter: 0; batch classifier loss: 0.381611; batch adversarial loss: 0.493773\n",
      "epoch 18; iter: 0; batch classifier loss: 0.311691; batch adversarial loss: 0.532214\n",
      "epoch 19; iter: 0; batch classifier loss: 0.312899; batch adversarial loss: 0.456717\n",
      "epoch 20; iter: 0; batch classifier loss: 0.290282; batch adversarial loss: 0.458509\n",
      "epoch 21; iter: 0; batch classifier loss: 0.280563; batch adversarial loss: 0.499550\n",
      "epoch 22; iter: 0; batch classifier loss: 0.370057; batch adversarial loss: 0.443585\n",
      "epoch 23; iter: 0; batch classifier loss: 0.262536; batch adversarial loss: 0.494806\n",
      "epoch 24; iter: 0; batch classifier loss: 0.268845; batch adversarial loss: 0.447289\n",
      "epoch 25; iter: 0; batch classifier loss: 0.188740; batch adversarial loss: 0.538041\n",
      "epoch 26; iter: 0; batch classifier loss: 0.196737; batch adversarial loss: 0.479650\n",
      "epoch 27; iter: 0; batch classifier loss: 0.235427; batch adversarial loss: 0.497035\n",
      "epoch 28; iter: 0; batch classifier loss: 0.231377; batch adversarial loss: 0.499580\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210308; batch adversarial loss: 0.449748\n",
      "epoch 30; iter: 0; batch classifier loss: 0.228085; batch adversarial loss: 0.447563\n",
      "epoch 31; iter: 0; batch classifier loss: 0.197459; batch adversarial loss: 0.506954\n",
      "epoch 32; iter: 0; batch classifier loss: 0.232338; batch adversarial loss: 0.504244\n",
      "epoch 33; iter: 0; batch classifier loss: 0.198416; batch adversarial loss: 0.491572\n",
      "epoch 34; iter: 0; batch classifier loss: 0.249848; batch adversarial loss: 0.397815\n",
      "epoch 35; iter: 0; batch classifier loss: 0.213210; batch adversarial loss: 0.469618\n",
      "epoch 36; iter: 0; batch classifier loss: 0.241810; batch adversarial loss: 0.440106\n",
      "epoch 37; iter: 0; batch classifier loss: 0.220318; batch adversarial loss: 0.405540\n",
      "epoch 38; iter: 0; batch classifier loss: 0.190591; batch adversarial loss: 0.468743\n",
      "epoch 39; iter: 0; batch classifier loss: 0.200786; batch adversarial loss: 0.508737\n",
      "epoch 40; iter: 0; batch classifier loss: 0.218468; batch adversarial loss: 0.369750\n",
      "epoch 41; iter: 0; batch classifier loss: 0.170296; batch adversarial loss: 0.330791\n",
      "epoch 42; iter: 0; batch classifier loss: 0.140379; batch adversarial loss: 0.439328\n",
      "epoch 43; iter: 0; batch classifier loss: 0.162007; batch adversarial loss: 0.412474\n",
      "epoch 44; iter: 0; batch classifier loss: 0.182226; batch adversarial loss: 0.401056\n",
      "epoch 45; iter: 0; batch classifier loss: 0.109889; batch adversarial loss: 0.446262\n",
      "epoch 46; iter: 0; batch classifier loss: 0.204231; batch adversarial loss: 0.498130\n",
      "epoch 47; iter: 0; batch classifier loss: 0.166640; batch adversarial loss: 0.419532\n",
      "epoch 48; iter: 0; batch classifier loss: 0.145054; batch adversarial loss: 0.513045\n",
      "epoch 49; iter: 0; batch classifier loss: 0.186609; batch adversarial loss: 0.385211\n",
      "epoch 50; iter: 0; batch classifier loss: 0.138999; batch adversarial loss: 0.430750\n",
      "epoch 51; iter: 0; batch classifier loss: 0.180134; batch adversarial loss: 0.350093\n",
      "epoch 52; iter: 0; batch classifier loss: 0.094855; batch adversarial loss: 0.445468\n",
      "epoch 53; iter: 0; batch classifier loss: 0.129989; batch adversarial loss: 0.436675\n",
      "epoch 54; iter: 0; batch classifier loss: 0.101287; batch adversarial loss: 0.349249\n",
      "epoch 55; iter: 0; batch classifier loss: 0.142659; batch adversarial loss: 0.584905\n",
      "epoch 56; iter: 0; batch classifier loss: 0.211614; batch adversarial loss: 0.383310\n",
      "epoch 57; iter: 0; batch classifier loss: 0.203907; batch adversarial loss: 0.499086\n",
      "epoch 58; iter: 0; batch classifier loss: 0.171600; batch adversarial loss: 0.446885\n",
      "epoch 59; iter: 0; batch classifier loss: 0.126557; batch adversarial loss: 0.510564\n",
      "epoch 60; iter: 0; batch classifier loss: 0.134214; batch adversarial loss: 0.432080\n",
      "epoch 61; iter: 0; batch classifier loss: 0.115305; batch adversarial loss: 0.457066\n",
      "epoch 62; iter: 0; batch classifier loss: 0.128141; batch adversarial loss: 0.424274\n",
      "epoch 63; iter: 0; batch classifier loss: 0.059883; batch adversarial loss: 0.438195\n",
      "epoch 64; iter: 0; batch classifier loss: 0.107401; batch adversarial loss: 0.392121\n",
      "epoch 65; iter: 0; batch classifier loss: 0.132445; batch adversarial loss: 0.550092\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096532; batch adversarial loss: 0.432092\n",
      "epoch 67; iter: 0; batch classifier loss: 0.112600; batch adversarial loss: 0.392684\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096418; batch adversarial loss: 0.479293\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103072; batch adversarial loss: 0.437822\n",
      "epoch 70; iter: 0; batch classifier loss: 0.081679; batch adversarial loss: 0.406700\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078946; batch adversarial loss: 0.429057\n",
      "epoch 72; iter: 0; batch classifier loss: 0.084990; batch adversarial loss: 0.417073\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068169; batch adversarial loss: 0.536181\n",
      "epoch 74; iter: 0; batch classifier loss: 0.095181; batch adversarial loss: 0.416876\n",
      "epoch 75; iter: 0; batch classifier loss: 0.114367; batch adversarial loss: 0.464858\n",
      "epoch 76; iter: 0; batch classifier loss: 0.066348; batch adversarial loss: 0.351987\n",
      "epoch 77; iter: 0; batch classifier loss: 0.088563; batch adversarial loss: 0.432674\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075433; batch adversarial loss: 0.394848\n",
      "epoch 79; iter: 0; batch classifier loss: 0.069773; batch adversarial loss: 0.371730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.062708; batch adversarial loss: 0.341832\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066632; batch adversarial loss: 0.475308\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046405; batch adversarial loss: 0.368502\n",
      "epoch 83; iter: 0; batch classifier loss: 0.098667; batch adversarial loss: 0.515308\n",
      "epoch 84; iter: 0; batch classifier loss: 0.059058; batch adversarial loss: 0.444181\n",
      "epoch 85; iter: 0; batch classifier loss: 0.035938; batch adversarial loss: 0.389636\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061396; batch adversarial loss: 0.423948\n",
      "epoch 87; iter: 0; batch classifier loss: 0.045356; batch adversarial loss: 0.360817\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058618; batch adversarial loss: 0.405468\n",
      "epoch 89; iter: 0; batch classifier loss: 0.115871; batch adversarial loss: 0.422326\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065485; batch adversarial loss: 0.437238\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055035; batch adversarial loss: 0.442176\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058026; batch adversarial loss: 0.442479\n",
      "epoch 93; iter: 0; batch classifier loss: 0.107640; batch adversarial loss: 0.362332\n",
      "epoch 94; iter: 0; batch classifier loss: 0.015826; batch adversarial loss: 0.505121\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066811; batch adversarial loss: 0.438221\n",
      "epoch 96; iter: 0; batch classifier loss: 0.038289; batch adversarial loss: 0.429871\n",
      "epoch 97; iter: 0; batch classifier loss: 0.053420; batch adversarial loss: 0.419617\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036796; batch adversarial loss: 0.448358\n",
      "epoch 99; iter: 0; batch classifier loss: 0.027767; batch adversarial loss: 0.578726\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039475; batch adversarial loss: 0.514989\n",
      "epoch 101; iter: 0; batch classifier loss: 0.059779; batch adversarial loss: 0.446016\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033698; batch adversarial loss: 0.484310\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033907; batch adversarial loss: 0.501098\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056637; batch adversarial loss: 0.426466\n",
      "epoch 105; iter: 0; batch classifier loss: 0.031036; batch adversarial loss: 0.445333\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031664; batch adversarial loss: 0.493715\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034848; batch adversarial loss: 0.472679\n",
      "epoch 108; iter: 0; batch classifier loss: 0.081804; batch adversarial loss: 0.389171\n",
      "epoch 109; iter: 0; batch classifier loss: 0.071408; batch adversarial loss: 0.482139\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051816; batch adversarial loss: 0.400418\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041238; batch adversarial loss: 0.492267\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037794; batch adversarial loss: 0.428909\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035814; batch adversarial loss: 0.450312\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028403; batch adversarial loss: 0.452413\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051532; batch adversarial loss: 0.430704\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024651; batch adversarial loss: 0.466466\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049886; batch adversarial loss: 0.374848\n",
      "epoch 118; iter: 0; batch classifier loss: 0.022827; batch adversarial loss: 0.595138\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041557; batch adversarial loss: 0.518378\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036528; batch adversarial loss: 0.520954\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057518; batch adversarial loss: 0.396877\n",
      "epoch 122; iter: 0; batch classifier loss: 0.013525; batch adversarial loss: 0.407906\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028558; batch adversarial loss: 0.434114\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020149; batch adversarial loss: 0.494627\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050276; batch adversarial loss: 0.428941\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034209; batch adversarial loss: 0.441707\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032802; batch adversarial loss: 0.356871\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022042; batch adversarial loss: 0.441850\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022900; batch adversarial loss: 0.437175\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016463; batch adversarial loss: 0.526118\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024306; batch adversarial loss: 0.457728\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038069; batch adversarial loss: 0.382457\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022403; batch adversarial loss: 0.596735\n",
      "epoch 134; iter: 0; batch classifier loss: 0.022839; batch adversarial loss: 0.469661\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026738; batch adversarial loss: 0.405354\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021624; batch adversarial loss: 0.401433\n",
      "epoch 137; iter: 0; batch classifier loss: 0.064176; batch adversarial loss: 0.397831\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036046; batch adversarial loss: 0.366093\n",
      "epoch 139; iter: 0; batch classifier loss: 0.011813; batch adversarial loss: 0.459763\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030361; batch adversarial loss: 0.619120\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034327; batch adversarial loss: 0.392696\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030247; batch adversarial loss: 0.456231\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051228; batch adversarial loss: 0.408221\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026211; batch adversarial loss: 0.502146\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032215; batch adversarial loss: 0.472195\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019743; batch adversarial loss: 0.466862\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033383; batch adversarial loss: 0.381374\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021918; batch adversarial loss: 0.472350\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027204; batch adversarial loss: 0.391586\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023236; batch adversarial loss: 0.475889\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024910; batch adversarial loss: 0.492651\n",
      "epoch 152; iter: 0; batch classifier loss: 0.003520; batch adversarial loss: 0.432289\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013877; batch adversarial loss: 0.439042\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034425; batch adversarial loss: 0.385981\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010505; batch adversarial loss: 0.407618\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041802; batch adversarial loss: 0.392348\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015416; batch adversarial loss: 0.329744\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025322; batch adversarial loss: 0.495148\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024939; batch adversarial loss: 0.434563\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022612; batch adversarial loss: 0.478844\n",
      "epoch 161; iter: 0; batch classifier loss: 0.049831; batch adversarial loss: 0.433286\n",
      "epoch 162; iter: 0; batch classifier loss: 0.053430; batch adversarial loss: 0.423233\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027027; batch adversarial loss: 0.473731\n",
      "epoch 164; iter: 0; batch classifier loss: 0.052188; batch adversarial loss: 0.413296\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017319; batch adversarial loss: 0.425661\n",
      "epoch 166; iter: 0; batch classifier loss: 0.005220; batch adversarial loss: 0.419221\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025877; batch adversarial loss: 0.477496\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028434; batch adversarial loss: 0.409778\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016300; batch adversarial loss: 0.498443\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015343; batch adversarial loss: 0.385205\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015522; batch adversarial loss: 0.380082\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021943; batch adversarial loss: 0.429588\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026178; batch adversarial loss: 0.383443\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011265; batch adversarial loss: 0.475161\n",
      "epoch 175; iter: 0; batch classifier loss: 0.057406; batch adversarial loss: 0.473446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.023364; batch adversarial loss: 0.538101\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024725; batch adversarial loss: 0.303087\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010985; batch adversarial loss: 0.526086\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025210; batch adversarial loss: 0.400290\n",
      "epoch 180; iter: 0; batch classifier loss: 0.047386; batch adversarial loss: 0.419102\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021442; batch adversarial loss: 0.351208\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017842; batch adversarial loss: 0.430901\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007001; batch adversarial loss: 0.494545\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020626; batch adversarial loss: 0.412615\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040436; batch adversarial loss: 0.376978\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018222; batch adversarial loss: 0.506938\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010863; batch adversarial loss: 0.442678\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018824; batch adversarial loss: 0.431963\n",
      "epoch 189; iter: 0; batch classifier loss: 0.005661; batch adversarial loss: 0.511601\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012139; batch adversarial loss: 0.476929\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031959; batch adversarial loss: 0.439958\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016759; batch adversarial loss: 0.461143\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016595; batch adversarial loss: 0.510213\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005443; batch adversarial loss: 0.416040\n",
      "epoch 195; iter: 0; batch classifier loss: 0.032280; batch adversarial loss: 0.409129\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004942; batch adversarial loss: 0.558645\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006295; batch adversarial loss: 0.403271\n",
      "epoch 198; iter: 0; batch classifier loss: 0.034816; batch adversarial loss: 0.578340\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017168; batch adversarial loss: 0.367784\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694777; batch adversarial loss: 0.956998\n",
      "epoch 1; iter: 0; batch classifier loss: 0.381532; batch adversarial loss: 0.933058\n",
      "epoch 2; iter: 0; batch classifier loss: 0.597308; batch adversarial loss: 0.880573\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576830; batch adversarial loss: 0.801291\n",
      "epoch 4; iter: 0; batch classifier loss: 0.500668; batch adversarial loss: 0.758890\n",
      "epoch 5; iter: 0; batch classifier loss: 0.341275; batch adversarial loss: 0.708377\n",
      "epoch 6; iter: 0; batch classifier loss: 0.258630; batch adversarial loss: 0.637473\n",
      "epoch 7; iter: 0; batch classifier loss: 0.278096; batch adversarial loss: 0.595414\n",
      "epoch 8; iter: 0; batch classifier loss: 0.240362; batch adversarial loss: 0.585600\n",
      "epoch 9; iter: 0; batch classifier loss: 0.300836; batch adversarial loss: 0.577608\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269830; batch adversarial loss: 0.550876\n",
      "epoch 11; iter: 0; batch classifier loss: 0.272352; batch adversarial loss: 0.531407\n",
      "epoch 12; iter: 0; batch classifier loss: 0.247499; batch adversarial loss: 0.555101\n",
      "epoch 13; iter: 0; batch classifier loss: 0.205555; batch adversarial loss: 0.514490\n",
      "epoch 14; iter: 0; batch classifier loss: 0.223003; batch adversarial loss: 0.554204\n",
      "epoch 15; iter: 0; batch classifier loss: 0.138743; batch adversarial loss: 0.515447\n",
      "epoch 16; iter: 0; batch classifier loss: 0.260239; batch adversarial loss: 0.549316\n",
      "epoch 17; iter: 0; batch classifier loss: 0.181770; batch adversarial loss: 0.463595\n",
      "epoch 18; iter: 0; batch classifier loss: 0.232124; batch adversarial loss: 0.496829\n",
      "epoch 19; iter: 0; batch classifier loss: 0.205520; batch adversarial loss: 0.514134\n",
      "epoch 20; iter: 0; batch classifier loss: 0.226936; batch adversarial loss: 0.468216\n",
      "epoch 21; iter: 0; batch classifier loss: 0.226815; batch adversarial loss: 0.473156\n",
      "epoch 22; iter: 0; batch classifier loss: 0.207164; batch adversarial loss: 0.482001\n",
      "epoch 23; iter: 0; batch classifier loss: 0.212480; batch adversarial loss: 0.430524\n",
      "epoch 24; iter: 0; batch classifier loss: 0.232858; batch adversarial loss: 0.504166\n",
      "epoch 25; iter: 0; batch classifier loss: 0.146495; batch adversarial loss: 0.480607\n",
      "epoch 26; iter: 0; batch classifier loss: 0.126105; batch adversarial loss: 0.419820\n",
      "epoch 27; iter: 0; batch classifier loss: 0.166064; batch adversarial loss: 0.430319\n",
      "epoch 28; iter: 0; batch classifier loss: 0.196203; batch adversarial loss: 0.484199\n",
      "epoch 29; iter: 0; batch classifier loss: 0.146875; batch adversarial loss: 0.434749\n",
      "epoch 30; iter: 0; batch classifier loss: 0.114354; batch adversarial loss: 0.448975\n",
      "epoch 31; iter: 0; batch classifier loss: 0.111981; batch adversarial loss: 0.463829\n",
      "epoch 32; iter: 0; batch classifier loss: 0.153220; batch adversarial loss: 0.443488\n",
      "epoch 33; iter: 0; batch classifier loss: 0.156081; batch adversarial loss: 0.418951\n",
      "epoch 34; iter: 0; batch classifier loss: 0.124143; batch adversarial loss: 0.414490\n",
      "epoch 35; iter: 0; batch classifier loss: 0.116159; batch adversarial loss: 0.471522\n",
      "epoch 36; iter: 0; batch classifier loss: 0.161703; batch adversarial loss: 0.416392\n",
      "epoch 37; iter: 0; batch classifier loss: 0.095078; batch adversarial loss: 0.458072\n",
      "epoch 38; iter: 0; batch classifier loss: 0.161541; batch adversarial loss: 0.425539\n",
      "epoch 39; iter: 0; batch classifier loss: 0.144905; batch adversarial loss: 0.519760\n",
      "epoch 40; iter: 0; batch classifier loss: 0.107273; batch adversarial loss: 0.493903\n",
      "epoch 41; iter: 0; batch classifier loss: 0.170294; batch adversarial loss: 0.399963\n",
      "epoch 42; iter: 0; batch classifier loss: 0.073232; batch adversarial loss: 0.445949\n",
      "epoch 43; iter: 0; batch classifier loss: 0.092676; batch adversarial loss: 0.449985\n",
      "epoch 44; iter: 0; batch classifier loss: 0.103884; batch adversarial loss: 0.375997\n",
      "epoch 45; iter: 0; batch classifier loss: 0.080659; batch adversarial loss: 0.475622\n",
      "epoch 46; iter: 0; batch classifier loss: 0.147588; batch adversarial loss: 0.433241\n",
      "epoch 47; iter: 0; batch classifier loss: 0.156418; batch adversarial loss: 0.509815\n",
      "epoch 48; iter: 0; batch classifier loss: 0.089376; batch adversarial loss: 0.438791\n",
      "epoch 49; iter: 0; batch classifier loss: 0.087303; batch adversarial loss: 0.433186\n",
      "epoch 50; iter: 0; batch classifier loss: 0.065300; batch adversarial loss: 0.396874\n",
      "epoch 51; iter: 0; batch classifier loss: 0.069616; batch adversarial loss: 0.482215\n",
      "epoch 52; iter: 0; batch classifier loss: 0.094496; batch adversarial loss: 0.454463\n",
      "epoch 53; iter: 0; batch classifier loss: 0.149030; batch adversarial loss: 0.425009\n",
      "epoch 54; iter: 0; batch classifier loss: 0.150068; batch adversarial loss: 0.451621\n",
      "epoch 55; iter: 0; batch classifier loss: 0.088703; batch adversarial loss: 0.519133\n",
      "epoch 56; iter: 0; batch classifier loss: 0.107019; batch adversarial loss: 0.416603\n",
      "epoch 57; iter: 0; batch classifier loss: 0.075338; batch adversarial loss: 0.438350\n",
      "epoch 58; iter: 0; batch classifier loss: 0.058417; batch adversarial loss: 0.358443\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072714; batch adversarial loss: 0.525624\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079129; batch adversarial loss: 0.381892\n",
      "epoch 61; iter: 0; batch classifier loss: 0.072333; batch adversarial loss: 0.370944\n",
      "epoch 62; iter: 0; batch classifier loss: 0.036715; batch adversarial loss: 0.498581\n",
      "epoch 63; iter: 0; batch classifier loss: 0.056292; batch adversarial loss: 0.430483\n",
      "epoch 64; iter: 0; batch classifier loss: 0.104887; batch adversarial loss: 0.475185\n",
      "epoch 65; iter: 0; batch classifier loss: 0.142528; batch adversarial loss: 0.464068\n",
      "epoch 66; iter: 0; batch classifier loss: 0.065347; batch adversarial loss: 0.446928\n",
      "epoch 67; iter: 0; batch classifier loss: 0.066036; batch adversarial loss: 0.411354\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094065; batch adversarial loss: 0.423272\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061598; batch adversarial loss: 0.500530\n",
      "epoch 70; iter: 0; batch classifier loss: 0.068732; batch adversarial loss: 0.333970\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063402; batch adversarial loss: 0.379218\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077827; batch adversarial loss: 0.449257\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069252; batch adversarial loss: 0.478481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.045294; batch adversarial loss: 0.426536\n",
      "epoch 75; iter: 0; batch classifier loss: 0.074006; batch adversarial loss: 0.449773\n",
      "epoch 76; iter: 0; batch classifier loss: 0.059201; batch adversarial loss: 0.367369\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084586; batch adversarial loss: 0.440352\n",
      "epoch 78; iter: 0; batch classifier loss: 0.044033; batch adversarial loss: 0.437980\n",
      "epoch 79; iter: 0; batch classifier loss: 0.035175; batch adversarial loss: 0.373298\n",
      "epoch 80; iter: 0; batch classifier loss: 0.058208; batch adversarial loss: 0.517611\n",
      "epoch 81; iter: 0; batch classifier loss: 0.098374; batch adversarial loss: 0.468686\n",
      "epoch 82; iter: 0; batch classifier loss: 0.045151; batch adversarial loss: 0.440234\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064529; batch adversarial loss: 0.299935\n",
      "epoch 84; iter: 0; batch classifier loss: 0.069353; batch adversarial loss: 0.458119\n",
      "epoch 85; iter: 0; batch classifier loss: 0.072200; batch adversarial loss: 0.424758\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065441; batch adversarial loss: 0.366305\n",
      "epoch 87; iter: 0; batch classifier loss: 0.094229; batch adversarial loss: 0.484772\n",
      "epoch 88; iter: 0; batch classifier loss: 0.056368; batch adversarial loss: 0.404998\n",
      "epoch 89; iter: 0; batch classifier loss: 0.095438; batch adversarial loss: 0.486714\n",
      "epoch 90; iter: 0; batch classifier loss: 0.049295; batch adversarial loss: 0.407560\n",
      "epoch 91; iter: 0; batch classifier loss: 0.051395; batch adversarial loss: 0.350111\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069453; batch adversarial loss: 0.421463\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054309; batch adversarial loss: 0.382872\n",
      "epoch 94; iter: 0; batch classifier loss: 0.059824; batch adversarial loss: 0.387787\n",
      "epoch 95; iter: 0; batch classifier loss: 0.082858; batch adversarial loss: 0.483839\n",
      "epoch 96; iter: 0; batch classifier loss: 0.042496; batch adversarial loss: 0.413158\n",
      "epoch 97; iter: 0; batch classifier loss: 0.061602; batch adversarial loss: 0.579324\n",
      "epoch 98; iter: 0; batch classifier loss: 0.040552; batch adversarial loss: 0.432682\n",
      "epoch 99; iter: 0; batch classifier loss: 0.077712; batch adversarial loss: 0.502492\n",
      "epoch 100; iter: 0; batch classifier loss: 0.029564; batch adversarial loss: 0.372936\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046039; batch adversarial loss: 0.393291\n",
      "epoch 102; iter: 0; batch classifier loss: 0.118225; batch adversarial loss: 0.481430\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044627; batch adversarial loss: 0.464041\n",
      "epoch 104; iter: 0; batch classifier loss: 0.067678; batch adversarial loss: 0.365849\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053329; batch adversarial loss: 0.409303\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037484; batch adversarial loss: 0.403367\n",
      "epoch 107; iter: 0; batch classifier loss: 0.080929; batch adversarial loss: 0.365026\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041202; batch adversarial loss: 0.476462\n",
      "epoch 109; iter: 0; batch classifier loss: 0.063080; batch adversarial loss: 0.487042\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068635; batch adversarial loss: 0.392296\n",
      "epoch 111; iter: 0; batch classifier loss: 0.093309; batch adversarial loss: 0.409572\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045167; batch adversarial loss: 0.433793\n",
      "epoch 113; iter: 0; batch classifier loss: 0.091042; batch adversarial loss: 0.486905\n",
      "epoch 114; iter: 0; batch classifier loss: 0.074063; batch adversarial loss: 0.420951\n",
      "epoch 115; iter: 0; batch classifier loss: 0.068442; batch adversarial loss: 0.424133\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051543; batch adversarial loss: 0.376626\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049462; batch adversarial loss: 0.335130\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035316; batch adversarial loss: 0.473185\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049676; batch adversarial loss: 0.504833\n",
      "epoch 120; iter: 0; batch classifier loss: 0.078485; batch adversarial loss: 0.463533\n",
      "epoch 121; iter: 0; batch classifier loss: 0.090957; batch adversarial loss: 0.551414\n",
      "epoch 122; iter: 0; batch classifier loss: 0.078690; batch adversarial loss: 0.291397\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055314; batch adversarial loss: 0.504299\n",
      "epoch 124; iter: 0; batch classifier loss: 0.045603; batch adversarial loss: 0.476477\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056081; batch adversarial loss: 0.454720\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045320; batch adversarial loss: 0.370686\n",
      "epoch 127; iter: 0; batch classifier loss: 0.063147; batch adversarial loss: 0.388809\n",
      "epoch 128; iter: 0; batch classifier loss: 0.089716; batch adversarial loss: 0.393748\n",
      "epoch 129; iter: 0; batch classifier loss: 0.069556; batch adversarial loss: 0.406646\n",
      "epoch 130; iter: 0; batch classifier loss: 0.062715; batch adversarial loss: 0.395830\n",
      "epoch 131; iter: 0; batch classifier loss: 0.088231; batch adversarial loss: 0.429952\n",
      "epoch 132; iter: 0; batch classifier loss: 0.055866; batch adversarial loss: 0.424710\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044338; batch adversarial loss: 0.405959\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050183; batch adversarial loss: 0.501772\n",
      "epoch 135; iter: 0; batch classifier loss: 0.056692; batch adversarial loss: 0.370719\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056002; batch adversarial loss: 0.521190\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052291; batch adversarial loss: 0.498944\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030032; batch adversarial loss: 0.378733\n",
      "epoch 139; iter: 0; batch classifier loss: 0.088277; batch adversarial loss: 0.440060\n",
      "epoch 140; iter: 0; batch classifier loss: 0.068948; batch adversarial loss: 0.436148\n",
      "epoch 141; iter: 0; batch classifier loss: 0.110902; batch adversarial loss: 0.384377\n",
      "epoch 142; iter: 0; batch classifier loss: 0.055801; batch adversarial loss: 0.498416\n",
      "epoch 143; iter: 0; batch classifier loss: 0.074945; batch adversarial loss: 0.459125\n",
      "epoch 144; iter: 0; batch classifier loss: 0.053810; batch adversarial loss: 0.411062\n",
      "epoch 145; iter: 0; batch classifier loss: 0.101044; batch adversarial loss: 0.467797\n",
      "epoch 146; iter: 0; batch classifier loss: 0.067502; batch adversarial loss: 0.468369\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044506; batch adversarial loss: 0.375943\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042738; batch adversarial loss: 0.344886\n",
      "epoch 149; iter: 0; batch classifier loss: 0.055552; batch adversarial loss: 0.417881\n",
      "epoch 150; iter: 0; batch classifier loss: 0.061869; batch adversarial loss: 0.355783\n",
      "epoch 151; iter: 0; batch classifier loss: 0.077125; batch adversarial loss: 0.446356\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035157; batch adversarial loss: 0.450819\n",
      "epoch 153; iter: 0; batch classifier loss: 0.060626; batch adversarial loss: 0.435422\n",
      "epoch 154; iter: 0; batch classifier loss: 0.054760; batch adversarial loss: 0.421607\n",
      "epoch 155; iter: 0; batch classifier loss: 0.053775; batch adversarial loss: 0.444770\n",
      "epoch 156; iter: 0; batch classifier loss: 0.058125; batch adversarial loss: 0.477751\n",
      "epoch 157; iter: 0; batch classifier loss: 0.064958; batch adversarial loss: 0.449223\n",
      "epoch 158; iter: 0; batch classifier loss: 0.089928; batch adversarial loss: 0.442323\n",
      "epoch 159; iter: 0; batch classifier loss: 0.043744; batch adversarial loss: 0.464000\n",
      "epoch 160; iter: 0; batch classifier loss: 0.077206; batch adversarial loss: 0.363557\n",
      "epoch 161; iter: 0; batch classifier loss: 0.056760; batch adversarial loss: 0.495826\n",
      "epoch 162; iter: 0; batch classifier loss: 0.051961; batch adversarial loss: 0.569859\n",
      "epoch 163; iter: 0; batch classifier loss: 0.059056; batch adversarial loss: 0.444905\n",
      "epoch 164; iter: 0; batch classifier loss: 0.057818; batch adversarial loss: 0.512641\n",
      "epoch 165; iter: 0; batch classifier loss: 0.045860; batch adversarial loss: 0.406342\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040189; batch adversarial loss: 0.474151\n",
      "epoch 167; iter: 0; batch classifier loss: 0.044863; batch adversarial loss: 0.387204\n",
      "epoch 168; iter: 0; batch classifier loss: 0.041709; batch adversarial loss: 0.499946\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036380; batch adversarial loss: 0.476291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.047187; batch adversarial loss: 0.428718\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038319; batch adversarial loss: 0.389821\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040518; batch adversarial loss: 0.388130\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027263; batch adversarial loss: 0.396745\n",
      "epoch 174; iter: 0; batch classifier loss: 0.050371; batch adversarial loss: 0.415642\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029983; batch adversarial loss: 0.472061\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032645; batch adversarial loss: 0.409778\n",
      "epoch 177; iter: 0; batch classifier loss: 0.039528; batch adversarial loss: 0.446479\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030722; batch adversarial loss: 0.427630\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035389; batch adversarial loss: 0.481169\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016252; batch adversarial loss: 0.505828\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020107; batch adversarial loss: 0.404969\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036150; batch adversarial loss: 0.439228\n",
      "epoch 183; iter: 0; batch classifier loss: 0.044090; batch adversarial loss: 0.541070\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035514; batch adversarial loss: 0.450065\n",
      "epoch 185; iter: 0; batch classifier loss: 0.072789; batch adversarial loss: 0.450381\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022855; batch adversarial loss: 0.532149\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024422; batch adversarial loss: 0.484852\n",
      "epoch 188; iter: 0; batch classifier loss: 0.053744; batch adversarial loss: 0.417978\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031889; batch adversarial loss: 0.406063\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018880; batch adversarial loss: 0.530446\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025877; batch adversarial loss: 0.438560\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029966; batch adversarial loss: 0.516280\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029083; batch adversarial loss: 0.430648\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017244; batch adversarial loss: 0.455324\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017839; batch adversarial loss: 0.525540\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031651; batch adversarial loss: 0.474380\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021897; batch adversarial loss: 0.438038\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023479; batch adversarial loss: 0.450150\n",
      "epoch 199; iter: 0; batch classifier loss: 0.040719; batch adversarial loss: 0.522816\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671188; batch adversarial loss: 0.585018\n",
      "epoch 1; iter: 0; batch classifier loss: 0.426139; batch adversarial loss: 0.597131\n",
      "epoch 2; iter: 0; batch classifier loss: 0.346766; batch adversarial loss: 0.609951\n",
      "epoch 3; iter: 0; batch classifier loss: 0.300674; batch adversarial loss: 0.607341\n",
      "epoch 4; iter: 0; batch classifier loss: 0.307567; batch adversarial loss: 0.539967\n",
      "epoch 5; iter: 0; batch classifier loss: 0.264993; batch adversarial loss: 0.559538\n",
      "epoch 6; iter: 0; batch classifier loss: 0.298144; batch adversarial loss: 0.575885\n",
      "epoch 7; iter: 0; batch classifier loss: 0.270725; batch adversarial loss: 0.506067\n",
      "epoch 8; iter: 0; batch classifier loss: 0.274190; batch adversarial loss: 0.517234\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363071; batch adversarial loss: 0.507465\n",
      "epoch 10; iter: 0; batch classifier loss: 0.310609; batch adversarial loss: 0.638794\n",
      "epoch 11; iter: 0; batch classifier loss: 0.407203; batch adversarial loss: 0.627396\n",
      "epoch 12; iter: 0; batch classifier loss: 0.564951; batch adversarial loss: 0.544527\n",
      "epoch 13; iter: 0; batch classifier loss: 0.621789; batch adversarial loss: 0.551174\n",
      "epoch 14; iter: 0; batch classifier loss: 0.570779; batch adversarial loss: 0.563456\n",
      "epoch 15; iter: 0; batch classifier loss: 0.315255; batch adversarial loss: 0.508879\n",
      "epoch 16; iter: 0; batch classifier loss: 0.294963; batch adversarial loss: 0.561226\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192686; batch adversarial loss: 0.508486\n",
      "epoch 18; iter: 0; batch classifier loss: 0.247210; batch adversarial loss: 0.450144\n",
      "epoch 19; iter: 0; batch classifier loss: 0.266114; batch adversarial loss: 0.458542\n",
      "epoch 20; iter: 0; batch classifier loss: 0.217431; batch adversarial loss: 0.457723\n",
      "epoch 21; iter: 0; batch classifier loss: 0.179164; batch adversarial loss: 0.526433\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206920; batch adversarial loss: 0.464676\n",
      "epoch 23; iter: 0; batch classifier loss: 0.161677; batch adversarial loss: 0.438222\n",
      "epoch 24; iter: 0; batch classifier loss: 0.165806; batch adversarial loss: 0.534326\n",
      "epoch 25; iter: 0; batch classifier loss: 0.216470; batch adversarial loss: 0.484184\n",
      "epoch 26; iter: 0; batch classifier loss: 0.172827; batch adversarial loss: 0.396231\n",
      "epoch 27; iter: 0; batch classifier loss: 0.134794; batch adversarial loss: 0.484748\n",
      "epoch 28; iter: 0; batch classifier loss: 0.179976; batch adversarial loss: 0.474306\n",
      "epoch 29; iter: 0; batch classifier loss: 0.217139; batch adversarial loss: 0.422429\n",
      "epoch 30; iter: 0; batch classifier loss: 0.093090; batch adversarial loss: 0.473502\n",
      "epoch 31; iter: 0; batch classifier loss: 0.153188; batch adversarial loss: 0.453436\n",
      "epoch 32; iter: 0; batch classifier loss: 0.214546; batch adversarial loss: 0.439198\n",
      "epoch 33; iter: 0; batch classifier loss: 0.181528; batch adversarial loss: 0.473030\n",
      "epoch 34; iter: 0; batch classifier loss: 0.123320; batch adversarial loss: 0.519896\n",
      "epoch 35; iter: 0; batch classifier loss: 0.179499; batch adversarial loss: 0.417400\n",
      "epoch 36; iter: 0; batch classifier loss: 0.155497; batch adversarial loss: 0.473528\n",
      "epoch 37; iter: 0; batch classifier loss: 0.209273; batch adversarial loss: 0.442769\n",
      "epoch 38; iter: 0; batch classifier loss: 0.167346; batch adversarial loss: 0.534044\n",
      "epoch 39; iter: 0; batch classifier loss: 0.130569; batch adversarial loss: 0.436459\n",
      "epoch 40; iter: 0; batch classifier loss: 0.129785; batch adversarial loss: 0.499446\n",
      "epoch 41; iter: 0; batch classifier loss: 0.203742; batch adversarial loss: 0.483549\n",
      "epoch 42; iter: 0; batch classifier loss: 0.136927; batch adversarial loss: 0.430247\n",
      "epoch 43; iter: 0; batch classifier loss: 0.106726; batch adversarial loss: 0.585774\n",
      "epoch 44; iter: 0; batch classifier loss: 0.153627; batch adversarial loss: 0.509830\n",
      "epoch 45; iter: 0; batch classifier loss: 0.194822; batch adversarial loss: 0.437376\n",
      "epoch 46; iter: 0; batch classifier loss: 0.169300; batch adversarial loss: 0.426626\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112215; batch adversarial loss: 0.471497\n",
      "epoch 48; iter: 0; batch classifier loss: 0.124213; batch adversarial loss: 0.449417\n",
      "epoch 49; iter: 0; batch classifier loss: 0.198990; batch adversarial loss: 0.519582\n",
      "epoch 50; iter: 0; batch classifier loss: 0.195897; batch adversarial loss: 0.506059\n",
      "epoch 51; iter: 0; batch classifier loss: 0.203211; batch adversarial loss: 0.403976\n",
      "epoch 52; iter: 0; batch classifier loss: 0.170218; batch adversarial loss: 0.545617\n",
      "epoch 53; iter: 0; batch classifier loss: 0.158302; batch adversarial loss: 0.546710\n",
      "epoch 54; iter: 0; batch classifier loss: 0.193914; batch adversarial loss: 0.483619\n",
      "epoch 55; iter: 0; batch classifier loss: 0.175902; batch adversarial loss: 0.524078\n",
      "epoch 56; iter: 0; batch classifier loss: 0.206779; batch adversarial loss: 0.473799\n",
      "epoch 57; iter: 0; batch classifier loss: 0.129456; batch adversarial loss: 0.485941\n",
      "epoch 58; iter: 0; batch classifier loss: 0.183688; batch adversarial loss: 0.401505\n",
      "epoch 59; iter: 0; batch classifier loss: 0.177764; batch adversarial loss: 0.498195\n",
      "epoch 60; iter: 0; batch classifier loss: 0.234421; batch adversarial loss: 0.444686\n",
      "epoch 61; iter: 0; batch classifier loss: 0.188157; batch adversarial loss: 0.531277\n",
      "epoch 62; iter: 0; batch classifier loss: 0.211683; batch adversarial loss: 0.504609\n",
      "epoch 63; iter: 0; batch classifier loss: 0.241624; batch adversarial loss: 0.395976\n",
      "epoch 64; iter: 0; batch classifier loss: 0.233434; batch adversarial loss: 0.480952\n",
      "epoch 65; iter: 0; batch classifier loss: 0.240782; batch adversarial loss: 0.483105\n",
      "epoch 66; iter: 0; batch classifier loss: 0.218715; batch adversarial loss: 0.408548\n",
      "epoch 67; iter: 0; batch classifier loss: 0.149911; batch adversarial loss: 0.482467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.149687; batch adversarial loss: 0.471956\n",
      "epoch 69; iter: 0; batch classifier loss: 0.279855; batch adversarial loss: 0.458563\n",
      "epoch 70; iter: 0; batch classifier loss: 0.217111; batch adversarial loss: 0.387562\n",
      "epoch 71; iter: 0; batch classifier loss: 0.198642; batch adversarial loss: 0.494766\n",
      "epoch 72; iter: 0; batch classifier loss: 0.198039; batch adversarial loss: 0.471517\n",
      "epoch 73; iter: 0; batch classifier loss: 0.137617; batch adversarial loss: 0.422994\n",
      "epoch 74; iter: 0; batch classifier loss: 0.170067; batch adversarial loss: 0.494923\n",
      "epoch 75; iter: 0; batch classifier loss: 0.144146; batch adversarial loss: 0.471114\n",
      "epoch 76; iter: 0; batch classifier loss: 0.199984; batch adversarial loss: 0.483519\n",
      "epoch 77; iter: 0; batch classifier loss: 0.199566; batch adversarial loss: 0.434968\n",
      "epoch 78; iter: 0; batch classifier loss: 0.157013; batch adversarial loss: 0.482793\n",
      "epoch 79; iter: 0; batch classifier loss: 0.161633; batch adversarial loss: 0.470867\n",
      "epoch 80; iter: 0; batch classifier loss: 0.231789; batch adversarial loss: 0.337110\n",
      "epoch 81; iter: 0; batch classifier loss: 0.194500; batch adversarial loss: 0.362026\n",
      "epoch 82; iter: 0; batch classifier loss: 0.271984; batch adversarial loss: 0.531654\n",
      "epoch 83; iter: 0; batch classifier loss: 0.227815; batch adversarial loss: 0.423031\n",
      "epoch 84; iter: 0; batch classifier loss: 0.176817; batch adversarial loss: 0.471060\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073211; batch adversarial loss: 0.385949\n",
      "epoch 86; iter: 0; batch classifier loss: 0.100689; batch adversarial loss: 0.466627\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059328; batch adversarial loss: 0.495977\n",
      "epoch 88; iter: 0; batch classifier loss: 0.065620; batch adversarial loss: 0.515393\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042735; batch adversarial loss: 0.536104\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064141; batch adversarial loss: 0.452701\n",
      "epoch 91; iter: 0; batch classifier loss: 0.086535; batch adversarial loss: 0.496830\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074474; batch adversarial loss: 0.436917\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071330; batch adversarial loss: 0.532535\n",
      "epoch 94; iter: 0; batch classifier loss: 0.112894; batch adversarial loss: 0.480208\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052067; batch adversarial loss: 0.463670\n",
      "epoch 96; iter: 0; batch classifier loss: 0.111824; batch adversarial loss: 0.538740\n",
      "epoch 97; iter: 0; batch classifier loss: 0.083656; batch adversarial loss: 0.350291\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063951; batch adversarial loss: 0.507010\n",
      "epoch 99; iter: 0; batch classifier loss: 0.089329; batch adversarial loss: 0.485317\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048152; batch adversarial loss: 0.469038\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041038; batch adversarial loss: 0.512518\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049030; batch adversarial loss: 0.475369\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049669; batch adversarial loss: 0.541044\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065624; batch adversarial loss: 0.438013\n",
      "epoch 105; iter: 0; batch classifier loss: 0.129713; batch adversarial loss: 0.411947\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068786; batch adversarial loss: 0.415468\n",
      "epoch 107; iter: 0; batch classifier loss: 0.093508; batch adversarial loss: 0.513271\n",
      "epoch 108; iter: 0; batch classifier loss: 0.081865; batch adversarial loss: 0.466820\n",
      "epoch 109; iter: 0; batch classifier loss: 0.085964; batch adversarial loss: 0.563541\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068361; batch adversarial loss: 0.467659\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060126; batch adversarial loss: 0.413264\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052869; batch adversarial loss: 0.401593\n",
      "epoch 113; iter: 0; batch classifier loss: 0.019879; batch adversarial loss: 0.525525\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057145; batch adversarial loss: 0.455516\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024607; batch adversarial loss: 0.505358\n",
      "epoch 116; iter: 0; batch classifier loss: 0.066721; batch adversarial loss: 0.451531\n",
      "epoch 117; iter: 0; batch classifier loss: 0.089279; batch adversarial loss: 0.390816\n",
      "epoch 118; iter: 0; batch classifier loss: 0.068372; batch adversarial loss: 0.408401\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031796; batch adversarial loss: 0.488848\n",
      "epoch 120; iter: 0; batch classifier loss: 0.064565; batch adversarial loss: 0.341939\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027989; batch adversarial loss: 0.518734\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046930; batch adversarial loss: 0.446016\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033783; batch adversarial loss: 0.479847\n",
      "epoch 124; iter: 0; batch classifier loss: 0.075815; batch adversarial loss: 0.445228\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026690; batch adversarial loss: 0.427992\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042068; batch adversarial loss: 0.476581\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045135; batch adversarial loss: 0.419511\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040633; batch adversarial loss: 0.399829\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017292; batch adversarial loss: 0.458823\n",
      "epoch 130; iter: 0; batch classifier loss: 0.064142; batch adversarial loss: 0.409909\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034038; batch adversarial loss: 0.494624\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019467; batch adversarial loss: 0.415679\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034596; batch adversarial loss: 0.497404\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020300; batch adversarial loss: 0.478028\n",
      "epoch 135; iter: 0; batch classifier loss: 0.017541; batch adversarial loss: 0.463604\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039304; batch adversarial loss: 0.437780\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043737; batch adversarial loss: 0.415877\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033652; batch adversarial loss: 0.435061\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016135; batch adversarial loss: 0.491172\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017231; batch adversarial loss: 0.424983\n",
      "epoch 141; iter: 0; batch classifier loss: 0.060126; batch adversarial loss: 0.495804\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018970; batch adversarial loss: 0.511460\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019471; batch adversarial loss: 0.507687\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028716; batch adversarial loss: 0.469517\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030795; batch adversarial loss: 0.542671\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017973; batch adversarial loss: 0.368396\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046473; batch adversarial loss: 0.320386\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021782; batch adversarial loss: 0.507882\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011535; batch adversarial loss: 0.477575\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011068; batch adversarial loss: 0.492015\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038522; batch adversarial loss: 0.467718\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014735; batch adversarial loss: 0.395771\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023166; batch adversarial loss: 0.429049\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018676; batch adversarial loss: 0.437685\n",
      "epoch 155; iter: 0; batch classifier loss: 0.053369; batch adversarial loss: 0.467279\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023436; batch adversarial loss: 0.456123\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039611; batch adversarial loss: 0.401767\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014643; batch adversarial loss: 0.547993\n",
      "epoch 159; iter: 0; batch classifier loss: 0.008745; batch adversarial loss: 0.401584\n",
      "epoch 160; iter: 0; batch classifier loss: 0.047402; batch adversarial loss: 0.373950\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017568; batch adversarial loss: 0.441581\n",
      "epoch 162; iter: 0; batch classifier loss: 0.008271; batch adversarial loss: 0.432766\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018606; batch adversarial loss: 0.392441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.024713; batch adversarial loss: 0.433583\n",
      "epoch 165; iter: 0; batch classifier loss: 0.062043; batch adversarial loss: 0.467557\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030948; batch adversarial loss: 0.523650\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020906; batch adversarial loss: 0.423121\n",
      "epoch 168; iter: 0; batch classifier loss: 0.046269; batch adversarial loss: 0.430310\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006938; batch adversarial loss: 0.418500\n",
      "epoch 170; iter: 0; batch classifier loss: 0.049582; batch adversarial loss: 0.465551\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036466; batch adversarial loss: 0.385622\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010489; batch adversarial loss: 0.474485\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006770; batch adversarial loss: 0.555502\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033726; batch adversarial loss: 0.434643\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018640; batch adversarial loss: 0.576253\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012448; batch adversarial loss: 0.418250\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012055; batch adversarial loss: 0.466715\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010092; batch adversarial loss: 0.488712\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026532; batch adversarial loss: 0.389896\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020629; batch adversarial loss: 0.441656\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015471; batch adversarial loss: 0.418527\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023049; batch adversarial loss: 0.444072\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011546; batch adversarial loss: 0.445138\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014343; batch adversarial loss: 0.476586\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013194; batch adversarial loss: 0.477243\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028856; batch adversarial loss: 0.476273\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017418; batch adversarial loss: 0.386351\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011320; batch adversarial loss: 0.443358\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016445; batch adversarial loss: 0.440669\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021561; batch adversarial loss: 0.438101\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034578; batch adversarial loss: 0.436373\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033783; batch adversarial loss: 0.467891\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024536; batch adversarial loss: 0.488814\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005071; batch adversarial loss: 0.359862\n",
      "epoch 195; iter: 0; batch classifier loss: 0.049068; batch adversarial loss: 0.444536\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020993; batch adversarial loss: 0.512871\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012998; batch adversarial loss: 0.502149\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008016; batch adversarial loss: 0.473080\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027499; batch adversarial loss: 0.379378\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685398; batch adversarial loss: 0.645824\n",
      "epoch 1; iter: 0; batch classifier loss: 0.442106; batch adversarial loss: 0.630263\n",
      "epoch 2; iter: 0; batch classifier loss: 0.336671; batch adversarial loss: 0.597616\n",
      "epoch 3; iter: 0; batch classifier loss: 0.283302; batch adversarial loss: 0.578670\n",
      "epoch 4; iter: 0; batch classifier loss: 0.269234; batch adversarial loss: 0.599384\n",
      "epoch 5; iter: 0; batch classifier loss: 0.294134; batch adversarial loss: 0.536384\n",
      "epoch 6; iter: 0; batch classifier loss: 0.313201; batch adversarial loss: 0.519931\n",
      "epoch 7; iter: 0; batch classifier loss: 0.297930; batch adversarial loss: 0.519708\n",
      "epoch 8; iter: 0; batch classifier loss: 0.208132; batch adversarial loss: 0.517102\n",
      "epoch 9; iter: 0; batch classifier loss: 0.333585; batch adversarial loss: 0.491297\n",
      "epoch 10; iter: 0; batch classifier loss: 0.259588; batch adversarial loss: 0.509134\n",
      "epoch 11; iter: 0; batch classifier loss: 0.323431; batch adversarial loss: 0.498937\n",
      "epoch 12; iter: 0; batch classifier loss: 0.315805; batch adversarial loss: 0.457869\n",
      "epoch 13; iter: 0; batch classifier loss: 0.261762; batch adversarial loss: 0.484234\n",
      "epoch 14; iter: 0; batch classifier loss: 0.302692; batch adversarial loss: 0.486672\n",
      "epoch 15; iter: 0; batch classifier loss: 0.309752; batch adversarial loss: 0.516582\n",
      "epoch 16; iter: 0; batch classifier loss: 0.482400; batch adversarial loss: 0.552525\n",
      "epoch 17; iter: 0; batch classifier loss: 0.578627; batch adversarial loss: 0.470272\n",
      "epoch 18; iter: 0; batch classifier loss: 0.386948; batch adversarial loss: 0.502401\n",
      "epoch 19; iter: 0; batch classifier loss: 0.274028; batch adversarial loss: 0.463400\n",
      "epoch 20; iter: 0; batch classifier loss: 0.226010; batch adversarial loss: 0.491281\n",
      "epoch 21; iter: 0; batch classifier loss: 0.201956; batch adversarial loss: 0.411748\n",
      "epoch 22; iter: 0; batch classifier loss: 0.160819; batch adversarial loss: 0.444151\n",
      "epoch 23; iter: 0; batch classifier loss: 0.146262; batch adversarial loss: 0.501495\n",
      "epoch 24; iter: 0; batch classifier loss: 0.204146; batch adversarial loss: 0.488796\n",
      "epoch 25; iter: 0; batch classifier loss: 0.164293; batch adversarial loss: 0.526584\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165818; batch adversarial loss: 0.469482\n",
      "epoch 27; iter: 0; batch classifier loss: 0.212964; batch adversarial loss: 0.487040\n",
      "epoch 28; iter: 0; batch classifier loss: 0.183644; batch adversarial loss: 0.441532\n",
      "epoch 29; iter: 0; batch classifier loss: 0.174798; batch adversarial loss: 0.464367\n",
      "epoch 30; iter: 0; batch classifier loss: 0.111910; batch adversarial loss: 0.493762\n",
      "epoch 31; iter: 0; batch classifier loss: 0.155827; batch adversarial loss: 0.422701\n",
      "epoch 32; iter: 0; batch classifier loss: 0.153309; batch adversarial loss: 0.458802\n",
      "epoch 33; iter: 0; batch classifier loss: 0.155867; batch adversarial loss: 0.436061\n",
      "epoch 34; iter: 0; batch classifier loss: 0.144433; batch adversarial loss: 0.422736\n",
      "epoch 35; iter: 0; batch classifier loss: 0.136716; batch adversarial loss: 0.499581\n",
      "epoch 36; iter: 0; batch classifier loss: 0.120536; batch adversarial loss: 0.524108\n",
      "epoch 37; iter: 0; batch classifier loss: 0.118749; batch adversarial loss: 0.437695\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148856; batch adversarial loss: 0.416378\n",
      "epoch 39; iter: 0; batch classifier loss: 0.089870; batch adversarial loss: 0.375320\n",
      "epoch 40; iter: 0; batch classifier loss: 0.102858; batch adversarial loss: 0.465834\n",
      "epoch 41; iter: 0; batch classifier loss: 0.149657; batch adversarial loss: 0.476827\n",
      "epoch 42; iter: 0; batch classifier loss: 0.130758; batch adversarial loss: 0.502450\n",
      "epoch 43; iter: 0; batch classifier loss: 0.101879; batch adversarial loss: 0.500699\n",
      "epoch 44; iter: 0; batch classifier loss: 0.165567; batch adversarial loss: 0.422084\n",
      "epoch 45; iter: 0; batch classifier loss: 0.121385; batch adversarial loss: 0.452301\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116135; batch adversarial loss: 0.507202\n",
      "epoch 47; iter: 0; batch classifier loss: 0.167553; batch adversarial loss: 0.421652\n",
      "epoch 48; iter: 0; batch classifier loss: 0.136530; batch adversarial loss: 0.441657\n",
      "epoch 49; iter: 0; batch classifier loss: 0.137371; batch adversarial loss: 0.522454\n",
      "epoch 50; iter: 0; batch classifier loss: 0.130990; batch adversarial loss: 0.330498\n",
      "epoch 51; iter: 0; batch classifier loss: 0.136246; batch adversarial loss: 0.437627\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161000; batch adversarial loss: 0.478625\n",
      "epoch 53; iter: 0; batch classifier loss: 0.100088; batch adversarial loss: 0.460550\n",
      "epoch 54; iter: 0; batch classifier loss: 0.141881; batch adversarial loss: 0.434109\n",
      "epoch 55; iter: 0; batch classifier loss: 0.103860; batch adversarial loss: 0.545944\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103237; batch adversarial loss: 0.472786\n",
      "epoch 57; iter: 0; batch classifier loss: 0.098221; batch adversarial loss: 0.458476\n",
      "epoch 58; iter: 0; batch classifier loss: 0.151684; batch adversarial loss: 0.442006\n",
      "epoch 59; iter: 0; batch classifier loss: 0.117433; batch adversarial loss: 0.421807\n",
      "epoch 60; iter: 0; batch classifier loss: 0.162864; batch adversarial loss: 0.498434\n",
      "epoch 61; iter: 0; batch classifier loss: 0.084299; batch adversarial loss: 0.431234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.130688; batch adversarial loss: 0.474325\n",
      "epoch 63; iter: 0; batch classifier loss: 0.117181; batch adversarial loss: 0.437236\n",
      "epoch 64; iter: 0; batch classifier loss: 0.108751; batch adversarial loss: 0.415845\n",
      "epoch 65; iter: 0; batch classifier loss: 0.125528; batch adversarial loss: 0.367600\n",
      "epoch 66; iter: 0; batch classifier loss: 0.161448; batch adversarial loss: 0.436516\n",
      "epoch 67; iter: 0; batch classifier loss: 0.123809; batch adversarial loss: 0.490118\n",
      "epoch 68; iter: 0; batch classifier loss: 0.130418; batch adversarial loss: 0.406970\n",
      "epoch 69; iter: 0; batch classifier loss: 0.184079; batch adversarial loss: 0.499982\n",
      "epoch 70; iter: 0; batch classifier loss: 0.153667; batch adversarial loss: 0.415140\n",
      "epoch 71; iter: 0; batch classifier loss: 0.111957; batch adversarial loss: 0.478990\n",
      "epoch 72; iter: 0; batch classifier loss: 0.066243; batch adversarial loss: 0.487445\n",
      "epoch 73; iter: 0; batch classifier loss: 0.131070; batch adversarial loss: 0.433232\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089961; batch adversarial loss: 0.506177\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096099; batch adversarial loss: 0.446110\n",
      "epoch 76; iter: 0; batch classifier loss: 0.183848; batch adversarial loss: 0.434782\n",
      "epoch 77; iter: 0; batch classifier loss: 0.101204; batch adversarial loss: 0.413690\n",
      "epoch 78; iter: 0; batch classifier loss: 0.141236; batch adversarial loss: 0.478509\n",
      "epoch 79; iter: 0; batch classifier loss: 0.153615; batch adversarial loss: 0.425416\n",
      "epoch 80; iter: 0; batch classifier loss: 0.123389; batch adversarial loss: 0.476741\n",
      "epoch 81; iter: 0; batch classifier loss: 0.132160; batch adversarial loss: 0.338620\n",
      "epoch 82; iter: 0; batch classifier loss: 0.150692; batch adversarial loss: 0.453777\n",
      "epoch 83; iter: 0; batch classifier loss: 0.143148; batch adversarial loss: 0.477496\n",
      "epoch 84; iter: 0; batch classifier loss: 0.111111; batch adversarial loss: 0.534435\n",
      "epoch 85; iter: 0; batch classifier loss: 0.118668; batch adversarial loss: 0.412338\n",
      "epoch 86; iter: 0; batch classifier loss: 0.145683; batch adversarial loss: 0.450415\n",
      "epoch 87; iter: 0; batch classifier loss: 0.166816; batch adversarial loss: 0.464631\n",
      "epoch 88; iter: 0; batch classifier loss: 0.111927; batch adversarial loss: 0.466235\n",
      "epoch 89; iter: 0; batch classifier loss: 0.115312; batch adversarial loss: 0.460804\n",
      "epoch 90; iter: 0; batch classifier loss: 0.113128; batch adversarial loss: 0.480389\n",
      "epoch 91; iter: 0; batch classifier loss: 0.129941; batch adversarial loss: 0.448229\n",
      "epoch 92; iter: 0; batch classifier loss: 0.161444; batch adversarial loss: 0.476630\n",
      "epoch 93; iter: 0; batch classifier loss: 0.089483; batch adversarial loss: 0.420710\n",
      "epoch 94; iter: 0; batch classifier loss: 0.125738; batch adversarial loss: 0.451630\n",
      "epoch 95; iter: 0; batch classifier loss: 0.160491; batch adversarial loss: 0.431393\n",
      "epoch 96; iter: 0; batch classifier loss: 0.130041; batch adversarial loss: 0.464554\n",
      "epoch 97; iter: 0; batch classifier loss: 0.155597; batch adversarial loss: 0.441149\n",
      "epoch 98; iter: 0; batch classifier loss: 0.097711; batch adversarial loss: 0.494736\n",
      "epoch 99; iter: 0; batch classifier loss: 0.158741; batch adversarial loss: 0.425905\n",
      "epoch 100; iter: 0; batch classifier loss: 0.124862; batch adversarial loss: 0.439694\n",
      "epoch 101; iter: 0; batch classifier loss: 0.142295; batch adversarial loss: 0.320122\n",
      "epoch 102; iter: 0; batch classifier loss: 0.146706; batch adversarial loss: 0.403148\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048399; batch adversarial loss: 0.486499\n",
      "epoch 104; iter: 0; batch classifier loss: 0.133302; batch adversarial loss: 0.366496\n",
      "epoch 105; iter: 0; batch classifier loss: 0.097738; batch adversarial loss: 0.469664\n",
      "epoch 106; iter: 0; batch classifier loss: 0.171945; batch adversarial loss: 0.476683\n",
      "epoch 107; iter: 0; batch classifier loss: 0.086728; batch adversarial loss: 0.460380\n",
      "epoch 108; iter: 0; batch classifier loss: 0.085546; batch adversarial loss: 0.415670\n",
      "epoch 109; iter: 0; batch classifier loss: 0.114459; batch adversarial loss: 0.377968\n",
      "epoch 110; iter: 0; batch classifier loss: 0.090623; batch adversarial loss: 0.471683\n",
      "epoch 111; iter: 0; batch classifier loss: 0.086757; batch adversarial loss: 0.524271\n",
      "epoch 112; iter: 0; batch classifier loss: 0.140782; batch adversarial loss: 0.425267\n",
      "epoch 113; iter: 0; batch classifier loss: 0.080319; batch adversarial loss: 0.464558\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062471; batch adversarial loss: 0.434515\n",
      "epoch 115; iter: 0; batch classifier loss: 0.081791; batch adversarial loss: 0.463049\n",
      "epoch 116; iter: 0; batch classifier loss: 0.069467; batch adversarial loss: 0.363887\n",
      "epoch 117; iter: 0; batch classifier loss: 0.065263; batch adversarial loss: 0.436486\n",
      "epoch 118; iter: 0; batch classifier loss: 0.079309; batch adversarial loss: 0.413572\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044714; batch adversarial loss: 0.504938\n",
      "epoch 120; iter: 0; batch classifier loss: 0.058243; batch adversarial loss: 0.481108\n",
      "epoch 121; iter: 0; batch classifier loss: 0.067689; batch adversarial loss: 0.496555\n",
      "epoch 122; iter: 0; batch classifier loss: 0.114971; batch adversarial loss: 0.437437\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039633; batch adversarial loss: 0.403188\n",
      "epoch 124; iter: 0; batch classifier loss: 0.118367; batch adversarial loss: 0.488222\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068910; batch adversarial loss: 0.406617\n",
      "epoch 126; iter: 0; batch classifier loss: 0.071390; batch adversarial loss: 0.528247\n",
      "epoch 127; iter: 0; batch classifier loss: 0.096682; batch adversarial loss: 0.409523\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058943; batch adversarial loss: 0.375431\n",
      "epoch 129; iter: 0; batch classifier loss: 0.074720; batch adversarial loss: 0.456715\n",
      "epoch 130; iter: 0; batch classifier loss: 0.058693; batch adversarial loss: 0.375050\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026339; batch adversarial loss: 0.459031\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027698; batch adversarial loss: 0.509912\n",
      "epoch 133; iter: 0; batch classifier loss: 0.047187; batch adversarial loss: 0.368604\n",
      "epoch 134; iter: 0; batch classifier loss: 0.085842; batch adversarial loss: 0.458963\n",
      "epoch 135; iter: 0; batch classifier loss: 0.017222; batch adversarial loss: 0.401726\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022635; batch adversarial loss: 0.549382\n",
      "epoch 137; iter: 0; batch classifier loss: 0.069419; batch adversarial loss: 0.457152\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049967; batch adversarial loss: 0.635484\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034499; batch adversarial loss: 0.367478\n",
      "epoch 140; iter: 0; batch classifier loss: 0.039650; batch adversarial loss: 0.431680\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037788; batch adversarial loss: 0.418369\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028581; batch adversarial loss: 0.380197\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030257; batch adversarial loss: 0.491173\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031990; batch adversarial loss: 0.503859\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041968; batch adversarial loss: 0.449989\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020657; batch adversarial loss: 0.499737\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016760; batch adversarial loss: 0.419112\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024169; batch adversarial loss: 0.388963\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053057; batch adversarial loss: 0.429560\n",
      "epoch 150; iter: 0; batch classifier loss: 0.051913; batch adversarial loss: 0.471061\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019278; batch adversarial loss: 0.398981\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026293; batch adversarial loss: 0.518590\n",
      "epoch 153; iter: 0; batch classifier loss: 0.046019; batch adversarial loss: 0.497665\n",
      "epoch 154; iter: 0; batch classifier loss: 0.069147; batch adversarial loss: 0.458442\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030505; batch adversarial loss: 0.441982\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027194; batch adversarial loss: 0.447731\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030464; batch adversarial loss: 0.460959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.022725; batch adversarial loss: 0.419235\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036186; batch adversarial loss: 0.436958\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015120; batch adversarial loss: 0.497756\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038240; batch adversarial loss: 0.453389\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013842; batch adversarial loss: 0.449674\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019626; batch adversarial loss: 0.424133\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017279; batch adversarial loss: 0.494998\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011152; batch adversarial loss: 0.423036\n",
      "epoch 166; iter: 0; batch classifier loss: 0.054773; batch adversarial loss: 0.453558\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041910; batch adversarial loss: 0.475029\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037960; batch adversarial loss: 0.527319\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017764; batch adversarial loss: 0.514921\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037395; batch adversarial loss: 0.411553\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018171; batch adversarial loss: 0.443989\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017879; batch adversarial loss: 0.564271\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033784; batch adversarial loss: 0.397560\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038381; batch adversarial loss: 0.478825\n",
      "epoch 175; iter: 0; batch classifier loss: 0.047346; batch adversarial loss: 0.436699\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009826; batch adversarial loss: 0.418486\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027313; batch adversarial loss: 0.373557\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029105; batch adversarial loss: 0.518015\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021064; batch adversarial loss: 0.539704\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029066; batch adversarial loss: 0.468034\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012883; batch adversarial loss: 0.438701\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017489; batch adversarial loss: 0.440215\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036979; batch adversarial loss: 0.449501\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017283; batch adversarial loss: 0.428046\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008755; batch adversarial loss: 0.407848\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012211; batch adversarial loss: 0.451741\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019002; batch adversarial loss: 0.456967\n",
      "epoch 188; iter: 0; batch classifier loss: 0.037422; batch adversarial loss: 0.463941\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024510; batch adversarial loss: 0.433586\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023806; batch adversarial loss: 0.440434\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030391; batch adversarial loss: 0.425560\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026971; batch adversarial loss: 0.441990\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024124; batch adversarial loss: 0.394407\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026366; batch adversarial loss: 0.375418\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018167; batch adversarial loss: 0.434270\n",
      "epoch 196; iter: 0; batch classifier loss: 0.059091; batch adversarial loss: 0.450369\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020592; batch adversarial loss: 0.431366\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008692; batch adversarial loss: 0.500081\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008298; batch adversarial loss: 0.532342\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728203; batch adversarial loss: 0.522679\n",
      "epoch 1; iter: 0; batch classifier loss: 0.418794; batch adversarial loss: 0.595447\n",
      "epoch 2; iter: 0; batch classifier loss: 0.330928; batch adversarial loss: 0.570863\n",
      "epoch 3; iter: 0; batch classifier loss: 0.388463; batch adversarial loss: 0.574160\n",
      "epoch 4; iter: 0; batch classifier loss: 0.452460; batch adversarial loss: 0.576292\n",
      "epoch 5; iter: 0; batch classifier loss: 0.391595; batch adversarial loss: 0.528810\n",
      "epoch 6; iter: 0; batch classifier loss: 0.400689; batch adversarial loss: 0.586958\n",
      "epoch 7; iter: 0; batch classifier loss: 0.522075; batch adversarial loss: 0.570679\n",
      "epoch 8; iter: 0; batch classifier loss: 0.402979; batch adversarial loss: 0.614790\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527350; batch adversarial loss: 0.541481\n",
      "epoch 10; iter: 0; batch classifier loss: 0.402581; batch adversarial loss: 0.538882\n",
      "epoch 11; iter: 0; batch classifier loss: 0.385333; batch adversarial loss: 0.464807\n",
      "epoch 12; iter: 0; batch classifier loss: 0.325121; batch adversarial loss: 0.481771\n",
      "epoch 13; iter: 0; batch classifier loss: 0.306575; batch adversarial loss: 0.510319\n",
      "epoch 14; iter: 0; batch classifier loss: 0.296614; batch adversarial loss: 0.460316\n",
      "epoch 15; iter: 0; batch classifier loss: 0.350612; batch adversarial loss: 0.483327\n",
      "epoch 16; iter: 0; batch classifier loss: 0.192380; batch adversarial loss: 0.518847\n",
      "epoch 17; iter: 0; batch classifier loss: 0.253388; batch adversarial loss: 0.446255\n",
      "epoch 18; iter: 0; batch classifier loss: 0.225207; batch adversarial loss: 0.427424\n",
      "epoch 19; iter: 0; batch classifier loss: 0.241140; batch adversarial loss: 0.499334\n",
      "epoch 20; iter: 0; batch classifier loss: 0.212706; batch adversarial loss: 0.526643\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258215; batch adversarial loss: 0.487761\n",
      "epoch 22; iter: 0; batch classifier loss: 0.201925; batch adversarial loss: 0.475641\n",
      "epoch 23; iter: 0; batch classifier loss: 0.182525; batch adversarial loss: 0.399406\n",
      "epoch 24; iter: 0; batch classifier loss: 0.246737; batch adversarial loss: 0.401902\n",
      "epoch 25; iter: 0; batch classifier loss: 0.220041; batch adversarial loss: 0.434178\n",
      "epoch 26; iter: 0; batch classifier loss: 0.134371; batch adversarial loss: 0.557465\n",
      "epoch 27; iter: 0; batch classifier loss: 0.136079; batch adversarial loss: 0.511366\n",
      "epoch 28; iter: 0; batch classifier loss: 0.109936; batch adversarial loss: 0.631290\n",
      "epoch 29; iter: 0; batch classifier loss: 0.140644; batch adversarial loss: 0.480277\n",
      "epoch 30; iter: 0; batch classifier loss: 0.135305; batch adversarial loss: 0.444179\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156149; batch adversarial loss: 0.418533\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126945; batch adversarial loss: 0.544519\n",
      "epoch 33; iter: 0; batch classifier loss: 0.097317; batch adversarial loss: 0.405910\n",
      "epoch 34; iter: 0; batch classifier loss: 0.124889; batch adversarial loss: 0.414866\n",
      "epoch 35; iter: 0; batch classifier loss: 0.100075; batch adversarial loss: 0.463864\n",
      "epoch 36; iter: 0; batch classifier loss: 0.114146; batch adversarial loss: 0.472744\n",
      "epoch 37; iter: 0; batch classifier loss: 0.143730; batch adversarial loss: 0.481105\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117952; batch adversarial loss: 0.396306\n",
      "epoch 39; iter: 0; batch classifier loss: 0.108089; batch adversarial loss: 0.365659\n",
      "epoch 40; iter: 0; batch classifier loss: 0.148707; batch adversarial loss: 0.389206\n",
      "epoch 41; iter: 0; batch classifier loss: 0.146961; batch adversarial loss: 0.446509\n",
      "epoch 42; iter: 0; batch classifier loss: 0.133753; batch adversarial loss: 0.374841\n",
      "epoch 43; iter: 0; batch classifier loss: 0.142500; batch adversarial loss: 0.520840\n",
      "epoch 44; iter: 0; batch classifier loss: 0.131656; batch adversarial loss: 0.424788\n",
      "epoch 45; iter: 0; batch classifier loss: 0.105945; batch adversarial loss: 0.521105\n",
      "epoch 46; iter: 0; batch classifier loss: 0.130674; batch adversarial loss: 0.431129\n",
      "epoch 47; iter: 0; batch classifier loss: 0.120753; batch adversarial loss: 0.378410\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099153; batch adversarial loss: 0.475598\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074202; batch adversarial loss: 0.369795\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087360; batch adversarial loss: 0.434759\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092322; batch adversarial loss: 0.528537\n",
      "epoch 52; iter: 0; batch classifier loss: 0.074261; batch adversarial loss: 0.548718\n",
      "epoch 53; iter: 0; batch classifier loss: 0.081667; batch adversarial loss: 0.468927\n",
      "epoch 54; iter: 0; batch classifier loss: 0.129712; batch adversarial loss: 0.432800\n",
      "epoch 55; iter: 0; batch classifier loss: 0.150371; batch adversarial loss: 0.366763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.115075; batch adversarial loss: 0.429558\n",
      "epoch 57; iter: 0; batch classifier loss: 0.085982; batch adversarial loss: 0.409210\n",
      "epoch 58; iter: 0; batch classifier loss: 0.145033; batch adversarial loss: 0.483849\n",
      "epoch 59; iter: 0; batch classifier loss: 0.082878; batch adversarial loss: 0.437081\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079723; batch adversarial loss: 0.535342\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090582; batch adversarial loss: 0.346772\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089406; batch adversarial loss: 0.513079\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097069; batch adversarial loss: 0.439304\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082402; batch adversarial loss: 0.408226\n",
      "epoch 65; iter: 0; batch classifier loss: 0.101675; batch adversarial loss: 0.521696\n",
      "epoch 66; iter: 0; batch classifier loss: 0.124805; batch adversarial loss: 0.399597\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094179; batch adversarial loss: 0.455373\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081420; batch adversarial loss: 0.444226\n",
      "epoch 69; iter: 0; batch classifier loss: 0.104562; batch adversarial loss: 0.426859\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079415; batch adversarial loss: 0.475154\n",
      "epoch 71; iter: 0; batch classifier loss: 0.039576; batch adversarial loss: 0.508390\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100225; batch adversarial loss: 0.473408\n",
      "epoch 73; iter: 0; batch classifier loss: 0.059606; batch adversarial loss: 0.509915\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089192; batch adversarial loss: 0.449776\n",
      "epoch 75; iter: 0; batch classifier loss: 0.092968; batch adversarial loss: 0.430578\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070131; batch adversarial loss: 0.409829\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064779; batch adversarial loss: 0.407771\n",
      "epoch 78; iter: 0; batch classifier loss: 0.099041; batch adversarial loss: 0.442179\n",
      "epoch 79; iter: 0; batch classifier loss: 0.081073; batch adversarial loss: 0.445189\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088802; batch adversarial loss: 0.367151\n",
      "epoch 81; iter: 0; batch classifier loss: 0.109719; batch adversarial loss: 0.507787\n",
      "epoch 82; iter: 0; batch classifier loss: 0.103764; batch adversarial loss: 0.405267\n",
      "epoch 83; iter: 0; batch classifier loss: 0.077252; batch adversarial loss: 0.432707\n",
      "epoch 84; iter: 0; batch classifier loss: 0.078386; batch adversarial loss: 0.339200\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055960; batch adversarial loss: 0.411057\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089131; batch adversarial loss: 0.377724\n",
      "epoch 87; iter: 0; batch classifier loss: 0.061239; batch adversarial loss: 0.465424\n",
      "epoch 88; iter: 0; batch classifier loss: 0.112384; batch adversarial loss: 0.411199\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065665; batch adversarial loss: 0.488256\n",
      "epoch 90; iter: 0; batch classifier loss: 0.093154; batch adversarial loss: 0.434593\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073621; batch adversarial loss: 0.538818\n",
      "epoch 92; iter: 0; batch classifier loss: 0.104326; batch adversarial loss: 0.385901\n",
      "epoch 93; iter: 0; batch classifier loss: 0.049499; batch adversarial loss: 0.519193\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066553; batch adversarial loss: 0.439147\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052901; batch adversarial loss: 0.442128\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063490; batch adversarial loss: 0.448274\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055931; batch adversarial loss: 0.436135\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039749; batch adversarial loss: 0.456930\n",
      "epoch 99; iter: 0; batch classifier loss: 0.048097; batch adversarial loss: 0.542575\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039137; batch adversarial loss: 0.353408\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048196; batch adversarial loss: 0.465567\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055482; batch adversarial loss: 0.412447\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046771; batch adversarial loss: 0.387402\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062110; batch adversarial loss: 0.482320\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038951; batch adversarial loss: 0.414690\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068835; batch adversarial loss: 0.410511\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046573; batch adversarial loss: 0.504632\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045523; batch adversarial loss: 0.494186\n",
      "epoch 109; iter: 0; batch classifier loss: 0.052367; batch adversarial loss: 0.473674\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060153; batch adversarial loss: 0.406304\n",
      "epoch 111; iter: 0; batch classifier loss: 0.025198; batch adversarial loss: 0.606786\n",
      "epoch 112; iter: 0; batch classifier loss: 0.094250; batch adversarial loss: 0.494450\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037004; batch adversarial loss: 0.461623\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034652; batch adversarial loss: 0.405853\n",
      "epoch 115; iter: 0; batch classifier loss: 0.076532; batch adversarial loss: 0.440031\n",
      "epoch 116; iter: 0; batch classifier loss: 0.047386; batch adversarial loss: 0.443358\n",
      "epoch 117; iter: 0; batch classifier loss: 0.020587; batch adversarial loss: 0.425133\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026729; batch adversarial loss: 0.510270\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056270; batch adversarial loss: 0.381459\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054322; batch adversarial loss: 0.481931\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037709; batch adversarial loss: 0.479116\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045729; batch adversarial loss: 0.361539\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036344; batch adversarial loss: 0.378636\n",
      "epoch 124; iter: 0; batch classifier loss: 0.018344; batch adversarial loss: 0.456768\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043146; batch adversarial loss: 0.488127\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031834; batch adversarial loss: 0.445431\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025447; batch adversarial loss: 0.581733\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035503; batch adversarial loss: 0.409938\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026785; batch adversarial loss: 0.554021\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023588; batch adversarial loss: 0.423874\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021221; batch adversarial loss: 0.438225\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036272; batch adversarial loss: 0.486978\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053073; batch adversarial loss: 0.521368\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021285; batch adversarial loss: 0.484547\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029004; batch adversarial loss: 0.466991\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036763; batch adversarial loss: 0.424402\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041042; batch adversarial loss: 0.358283\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014079; batch adversarial loss: 0.531079\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031315; batch adversarial loss: 0.483829\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025838; batch adversarial loss: 0.462116\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038585; batch adversarial loss: 0.410469\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026865; batch adversarial loss: 0.400102\n",
      "epoch 143; iter: 0; batch classifier loss: 0.052537; batch adversarial loss: 0.453300\n",
      "epoch 144; iter: 0; batch classifier loss: 0.070017; batch adversarial loss: 0.461735\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019374; batch adversarial loss: 0.501911\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031646; batch adversarial loss: 0.456898\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013880; batch adversarial loss: 0.512707\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018854; batch adversarial loss: 0.414137\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030654; batch adversarial loss: 0.391466\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036030; batch adversarial loss: 0.488741\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032772; batch adversarial loss: 0.518447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.022054; batch adversarial loss: 0.394722\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031925; batch adversarial loss: 0.472404\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016904; batch adversarial loss: 0.510358\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028430; batch adversarial loss: 0.372584\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044710; batch adversarial loss: 0.421771\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027571; batch adversarial loss: 0.453317\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017789; batch adversarial loss: 0.428158\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019994; batch adversarial loss: 0.424355\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033170; batch adversarial loss: 0.415107\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032609; batch adversarial loss: 0.381357\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023897; batch adversarial loss: 0.587961\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012342; batch adversarial loss: 0.454618\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027402; batch adversarial loss: 0.409226\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016362; batch adversarial loss: 0.407302\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011296; batch adversarial loss: 0.439754\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016278; batch adversarial loss: 0.484135\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019257; batch adversarial loss: 0.463265\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011557; batch adversarial loss: 0.468036\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030380; batch adversarial loss: 0.586733\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029006; batch adversarial loss: 0.538213\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007309; batch adversarial loss: 0.339806\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012765; batch adversarial loss: 0.418361\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015186; batch adversarial loss: 0.475096\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015826; batch adversarial loss: 0.436601\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018918; batch adversarial loss: 0.451102\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010971; batch adversarial loss: 0.498987\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025840; batch adversarial loss: 0.435048\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037538; batch adversarial loss: 0.376345\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022880; batch adversarial loss: 0.491994\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010424; batch adversarial loss: 0.509026\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016246; batch adversarial loss: 0.521279\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011353; batch adversarial loss: 0.537629\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018646; batch adversarial loss: 0.433596\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035769; batch adversarial loss: 0.431826\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012385; batch adversarial loss: 0.456974\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020198; batch adversarial loss: 0.519790\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014910; batch adversarial loss: 0.309741\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008706; batch adversarial loss: 0.426480\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012692; batch adversarial loss: 0.517234\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013577; batch adversarial loss: 0.464240\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013782; batch adversarial loss: 0.457475\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022846; batch adversarial loss: 0.434463\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036285; batch adversarial loss: 0.440403\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014766; batch adversarial loss: 0.361295\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037099; batch adversarial loss: 0.441530\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014433; batch adversarial loss: 0.470687\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028298; batch adversarial loss: 0.416759\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032664; batch adversarial loss: 0.430178\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707701; batch adversarial loss: 0.583678\n",
      "epoch 1; iter: 0; batch classifier loss: 0.443064; batch adversarial loss: 0.620098\n",
      "epoch 2; iter: 0; batch classifier loss: 0.451391; batch adversarial loss: 0.585805\n",
      "epoch 3; iter: 0; batch classifier loss: 0.390249; batch adversarial loss: 0.551797\n",
      "epoch 4; iter: 0; batch classifier loss: 0.486122; batch adversarial loss: 0.544484\n",
      "epoch 5; iter: 0; batch classifier loss: 0.268978; batch adversarial loss: 0.522650\n",
      "epoch 6; iter: 0; batch classifier loss: 0.307218; batch adversarial loss: 0.553859\n",
      "epoch 7; iter: 0; batch classifier loss: 0.306312; batch adversarial loss: 0.501665\n",
      "epoch 8; iter: 0; batch classifier loss: 0.277832; batch adversarial loss: 0.463289\n",
      "epoch 9; iter: 0; batch classifier loss: 0.242165; batch adversarial loss: 0.464585\n",
      "epoch 10; iter: 0; batch classifier loss: 0.234920; batch adversarial loss: 0.498877\n",
      "epoch 11; iter: 0; batch classifier loss: 0.240405; batch adversarial loss: 0.471894\n",
      "epoch 12; iter: 0; batch classifier loss: 0.281132; batch adversarial loss: 0.490341\n",
      "epoch 13; iter: 0; batch classifier loss: 0.221774; batch adversarial loss: 0.477637\n",
      "epoch 14; iter: 0; batch classifier loss: 0.221323; batch adversarial loss: 0.543844\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307822; batch adversarial loss: 0.495864\n",
      "epoch 16; iter: 0; batch classifier loss: 0.262940; batch adversarial loss: 0.617455\n",
      "epoch 17; iter: 0; batch classifier loss: 0.250539; batch adversarial loss: 0.561676\n",
      "epoch 18; iter: 0; batch classifier loss: 0.162079; batch adversarial loss: 0.460285\n",
      "epoch 19; iter: 0; batch classifier loss: 0.184819; batch adversarial loss: 0.487715\n",
      "epoch 20; iter: 0; batch classifier loss: 0.243856; batch adversarial loss: 0.500116\n",
      "epoch 21; iter: 0; batch classifier loss: 0.236925; batch adversarial loss: 0.525408\n",
      "epoch 22; iter: 0; batch classifier loss: 0.158904; batch adversarial loss: 0.477927\n",
      "epoch 23; iter: 0; batch classifier loss: 0.277600; batch adversarial loss: 0.467119\n",
      "epoch 24; iter: 0; batch classifier loss: 0.274718; batch adversarial loss: 0.467279\n",
      "epoch 25; iter: 0; batch classifier loss: 0.236879; batch adversarial loss: 0.489753\n",
      "epoch 26; iter: 0; batch classifier loss: 0.196998; batch adversarial loss: 0.366205\n",
      "epoch 27; iter: 0; batch classifier loss: 0.312999; batch adversarial loss: 0.505341\n",
      "epoch 28; iter: 0; batch classifier loss: 0.363500; batch adversarial loss: 0.446334\n",
      "epoch 29; iter: 0; batch classifier loss: 0.295479; batch adversarial loss: 0.447542\n",
      "epoch 30; iter: 0; batch classifier loss: 0.184408; batch adversarial loss: 0.478697\n",
      "epoch 31; iter: 0; batch classifier loss: 0.148720; batch adversarial loss: 0.437901\n",
      "epoch 32; iter: 0; batch classifier loss: 0.125299; batch adversarial loss: 0.528468\n",
      "epoch 33; iter: 0; batch classifier loss: 0.081962; batch adversarial loss: 0.497605\n",
      "epoch 34; iter: 0; batch classifier loss: 0.141419; batch adversarial loss: 0.376477\n",
      "epoch 35; iter: 0; batch classifier loss: 0.127530; batch adversarial loss: 0.407630\n",
      "epoch 36; iter: 0; batch classifier loss: 0.132192; batch adversarial loss: 0.449562\n",
      "epoch 37; iter: 0; batch classifier loss: 0.103694; batch adversarial loss: 0.436713\n",
      "epoch 38; iter: 0; batch classifier loss: 0.104639; batch adversarial loss: 0.495222\n",
      "epoch 39; iter: 0; batch classifier loss: 0.113010; batch adversarial loss: 0.424393\n",
      "epoch 40; iter: 0; batch classifier loss: 0.125011; batch adversarial loss: 0.489035\n",
      "epoch 41; iter: 0; batch classifier loss: 0.120677; batch adversarial loss: 0.446221\n",
      "epoch 42; iter: 0; batch classifier loss: 0.095474; batch adversarial loss: 0.437644\n",
      "epoch 43; iter: 0; batch classifier loss: 0.082997; batch adversarial loss: 0.344237\n",
      "epoch 44; iter: 0; batch classifier loss: 0.133157; batch adversarial loss: 0.359009\n",
      "epoch 45; iter: 0; batch classifier loss: 0.167486; batch adversarial loss: 0.379975\n",
      "epoch 46; iter: 0; batch classifier loss: 0.113065; batch adversarial loss: 0.390855\n",
      "epoch 47; iter: 0; batch classifier loss: 0.069861; batch adversarial loss: 0.455786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.075881; batch adversarial loss: 0.472705\n",
      "epoch 49; iter: 0; batch classifier loss: 0.058907; batch adversarial loss: 0.492526\n",
      "epoch 50; iter: 0; batch classifier loss: 0.056856; batch adversarial loss: 0.437525\n",
      "epoch 51; iter: 0; batch classifier loss: 0.120928; batch adversarial loss: 0.470752\n",
      "epoch 52; iter: 0; batch classifier loss: 0.076026; batch adversarial loss: 0.508722\n",
      "epoch 53; iter: 0; batch classifier loss: 0.045560; batch adversarial loss: 0.559464\n",
      "epoch 54; iter: 0; batch classifier loss: 0.092714; batch adversarial loss: 0.426084\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089061; batch adversarial loss: 0.422232\n",
      "epoch 56; iter: 0; batch classifier loss: 0.068687; batch adversarial loss: 0.411023\n",
      "epoch 57; iter: 0; batch classifier loss: 0.048833; batch adversarial loss: 0.579269\n",
      "epoch 58; iter: 0; batch classifier loss: 0.124063; batch adversarial loss: 0.574545\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087110; batch adversarial loss: 0.473872\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072715; batch adversarial loss: 0.472040\n",
      "epoch 61; iter: 0; batch classifier loss: 0.054449; batch adversarial loss: 0.531534\n",
      "epoch 62; iter: 0; batch classifier loss: 0.060114; batch adversarial loss: 0.491510\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070024; batch adversarial loss: 0.474040\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090075; batch adversarial loss: 0.516690\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088768; batch adversarial loss: 0.387279\n",
      "epoch 66; iter: 0; batch classifier loss: 0.082049; batch adversarial loss: 0.456656\n",
      "epoch 67; iter: 0; batch classifier loss: 0.106531; batch adversarial loss: 0.380201\n",
      "epoch 68; iter: 0; batch classifier loss: 0.052822; batch adversarial loss: 0.589760\n",
      "epoch 69; iter: 0; batch classifier loss: 0.110513; batch adversarial loss: 0.529721\n",
      "epoch 70; iter: 0; batch classifier loss: 0.054864; batch adversarial loss: 0.452157\n",
      "epoch 71; iter: 0; batch classifier loss: 0.126335; batch adversarial loss: 0.417768\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071834; batch adversarial loss: 0.457246\n",
      "epoch 73; iter: 0; batch classifier loss: 0.049692; batch adversarial loss: 0.461710\n",
      "epoch 74; iter: 0; batch classifier loss: 0.056677; batch adversarial loss: 0.404761\n",
      "epoch 75; iter: 0; batch classifier loss: 0.105755; batch adversarial loss: 0.439290\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058407; batch adversarial loss: 0.520333\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065472; batch adversarial loss: 0.413520\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054718; batch adversarial loss: 0.540643\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065702; batch adversarial loss: 0.455448\n",
      "epoch 80; iter: 0; batch classifier loss: 0.066823; batch adversarial loss: 0.415582\n",
      "epoch 81; iter: 0; batch classifier loss: 0.061162; batch adversarial loss: 0.535457\n",
      "epoch 82; iter: 0; batch classifier loss: 0.043955; batch adversarial loss: 0.490497\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086574; batch adversarial loss: 0.446176\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062501; batch adversarial loss: 0.416318\n",
      "epoch 85; iter: 0; batch classifier loss: 0.113753; batch adversarial loss: 0.446953\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068539; batch adversarial loss: 0.451362\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073324; batch adversarial loss: 0.447939\n",
      "epoch 88; iter: 0; batch classifier loss: 0.088114; batch adversarial loss: 0.488007\n",
      "epoch 89; iter: 0; batch classifier loss: 0.076427; batch adversarial loss: 0.408551\n",
      "epoch 90; iter: 0; batch classifier loss: 0.070888; batch adversarial loss: 0.354083\n",
      "epoch 91; iter: 0; batch classifier loss: 0.044573; batch adversarial loss: 0.497540\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058616; batch adversarial loss: 0.530151\n",
      "epoch 93; iter: 0; batch classifier loss: 0.089652; batch adversarial loss: 0.452863\n",
      "epoch 94; iter: 0; batch classifier loss: 0.031862; batch adversarial loss: 0.537040\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063063; batch adversarial loss: 0.397610\n",
      "epoch 96; iter: 0; batch classifier loss: 0.061310; batch adversarial loss: 0.428531\n",
      "epoch 97; iter: 0; batch classifier loss: 0.130551; batch adversarial loss: 0.334937\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047723; batch adversarial loss: 0.475567\n",
      "epoch 99; iter: 0; batch classifier loss: 0.080999; batch adversarial loss: 0.430970\n",
      "epoch 100; iter: 0; batch classifier loss: 0.080080; batch adversarial loss: 0.508466\n",
      "epoch 101; iter: 0; batch classifier loss: 0.105521; batch adversarial loss: 0.405552\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066962; batch adversarial loss: 0.453088\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055639; batch adversarial loss: 0.472845\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038608; batch adversarial loss: 0.477757\n",
      "epoch 105; iter: 0; batch classifier loss: 0.083231; batch adversarial loss: 0.437153\n",
      "epoch 106; iter: 0; batch classifier loss: 0.024872; batch adversarial loss: 0.543295\n",
      "epoch 107; iter: 0; batch classifier loss: 0.067104; batch adversarial loss: 0.524372\n",
      "epoch 108; iter: 0; batch classifier loss: 0.050498; batch adversarial loss: 0.492089\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027281; batch adversarial loss: 0.494919\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044003; batch adversarial loss: 0.497648\n",
      "epoch 111; iter: 0; batch classifier loss: 0.095759; batch adversarial loss: 0.420357\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034527; batch adversarial loss: 0.457843\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054198; batch adversarial loss: 0.454652\n",
      "epoch 114; iter: 0; batch classifier loss: 0.089886; batch adversarial loss: 0.544707\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059233; batch adversarial loss: 0.527748\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062587; batch adversarial loss: 0.451792\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032900; batch adversarial loss: 0.419690\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036681; batch adversarial loss: 0.529843\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032852; batch adversarial loss: 0.524732\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037771; batch adversarial loss: 0.453845\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046404; batch adversarial loss: 0.423978\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028252; batch adversarial loss: 0.464168\n",
      "epoch 123; iter: 0; batch classifier loss: 0.095374; batch adversarial loss: 0.456658\n",
      "epoch 124; iter: 0; batch classifier loss: 0.089492; batch adversarial loss: 0.416609\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040745; batch adversarial loss: 0.468864\n",
      "epoch 126; iter: 0; batch classifier loss: 0.098525; batch adversarial loss: 0.324081\n",
      "epoch 127; iter: 0; batch classifier loss: 0.091511; batch adversarial loss: 0.570875\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052696; batch adversarial loss: 0.480481\n",
      "epoch 129; iter: 0; batch classifier loss: 0.057476; batch adversarial loss: 0.517118\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061805; batch adversarial loss: 0.438971\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050642; batch adversarial loss: 0.446339\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058326; batch adversarial loss: 0.421998\n",
      "epoch 133; iter: 0; batch classifier loss: 0.048447; batch adversarial loss: 0.485925\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023220; batch adversarial loss: 0.422732\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034299; batch adversarial loss: 0.484282\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043311; batch adversarial loss: 0.424682\n",
      "epoch 137; iter: 0; batch classifier loss: 0.076297; batch adversarial loss: 0.466364\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046634; batch adversarial loss: 0.363919\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034955; batch adversarial loss: 0.452951\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034838; batch adversarial loss: 0.473564\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028200; batch adversarial loss: 0.421630\n",
      "epoch 142; iter: 0; batch classifier loss: 0.053810; batch adversarial loss: 0.420230\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024357; batch adversarial loss: 0.461962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.023374; batch adversarial loss: 0.461817\n",
      "epoch 145; iter: 0; batch classifier loss: 0.050893; batch adversarial loss: 0.527577\n",
      "epoch 146; iter: 0; batch classifier loss: 0.047978; batch adversarial loss: 0.454626\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022573; batch adversarial loss: 0.473430\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046728; batch adversarial loss: 0.371708\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035813; batch adversarial loss: 0.461788\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027565; batch adversarial loss: 0.459211\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028566; batch adversarial loss: 0.468884\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041897; batch adversarial loss: 0.530894\n",
      "epoch 153; iter: 0; batch classifier loss: 0.055188; batch adversarial loss: 0.545706\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020994; batch adversarial loss: 0.362055\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035588; batch adversarial loss: 0.429412\n",
      "epoch 156; iter: 0; batch classifier loss: 0.071993; batch adversarial loss: 0.406577\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029175; batch adversarial loss: 0.355512\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037261; batch adversarial loss: 0.431003\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024594; batch adversarial loss: 0.488611\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028850; batch adversarial loss: 0.468419\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042337; batch adversarial loss: 0.512137\n",
      "epoch 162; iter: 0; batch classifier loss: 0.068348; batch adversarial loss: 0.531067\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029255; batch adversarial loss: 0.358630\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036447; batch adversarial loss: 0.545418\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023649; batch adversarial loss: 0.547368\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015194; batch adversarial loss: 0.499116\n",
      "epoch 167; iter: 0; batch classifier loss: 0.070258; batch adversarial loss: 0.388036\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045871; batch adversarial loss: 0.463582\n",
      "epoch 169; iter: 0; batch classifier loss: 0.061761; batch adversarial loss: 0.461223\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040870; batch adversarial loss: 0.424829\n",
      "epoch 171; iter: 0; batch classifier loss: 0.056205; batch adversarial loss: 0.436038\n",
      "epoch 172; iter: 0; batch classifier loss: 0.055703; batch adversarial loss: 0.417390\n",
      "epoch 173; iter: 0; batch classifier loss: 0.039226; batch adversarial loss: 0.333648\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013232; batch adversarial loss: 0.427996\n",
      "epoch 175; iter: 0; batch classifier loss: 0.058275; batch adversarial loss: 0.425269\n",
      "epoch 176; iter: 0; batch classifier loss: 0.051707; batch adversarial loss: 0.440279\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038372; batch adversarial loss: 0.562883\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031054; batch adversarial loss: 0.388453\n",
      "epoch 179; iter: 0; batch classifier loss: 0.046586; batch adversarial loss: 0.363649\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026022; batch adversarial loss: 0.397531\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021779; batch adversarial loss: 0.391040\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030931; batch adversarial loss: 0.515731\n",
      "epoch 183; iter: 0; batch classifier loss: 0.035592; batch adversarial loss: 0.444250\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015653; batch adversarial loss: 0.438394\n",
      "epoch 185; iter: 0; batch classifier loss: 0.041980; batch adversarial loss: 0.431834\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033181; batch adversarial loss: 0.444892\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035662; batch adversarial loss: 0.396129\n",
      "epoch 188; iter: 0; batch classifier loss: 0.059453; batch adversarial loss: 0.421432\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027172; batch adversarial loss: 0.471020\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034276; batch adversarial loss: 0.500732\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008296; batch adversarial loss: 0.497756\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019686; batch adversarial loss: 0.441171\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037239; batch adversarial loss: 0.357813\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015646; batch adversarial loss: 0.529683\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025959; batch adversarial loss: 0.399831\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026495; batch adversarial loss: 0.404380\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016454; batch adversarial loss: 0.446153\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030384; batch adversarial loss: 0.453213\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035241; batch adversarial loss: 0.361451\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708874; batch adversarial loss: 0.607462\n",
      "epoch 1; iter: 0; batch classifier loss: 0.389498; batch adversarial loss: 0.589777\n",
      "epoch 2; iter: 0; batch classifier loss: 0.334992; batch adversarial loss: 0.586773\n",
      "epoch 3; iter: 0; batch classifier loss: 0.402573; batch adversarial loss: 0.601123\n",
      "epoch 4; iter: 0; batch classifier loss: 0.362458; batch adversarial loss: 0.531029\n",
      "epoch 5; iter: 0; batch classifier loss: 0.382235; batch adversarial loss: 0.557824\n",
      "epoch 6; iter: 0; batch classifier loss: 0.310190; batch adversarial loss: 0.554090\n",
      "epoch 7; iter: 0; batch classifier loss: 0.258516; batch adversarial loss: 0.478785\n",
      "epoch 8; iter: 0; batch classifier loss: 0.254094; batch adversarial loss: 0.533894\n",
      "epoch 9; iter: 0; batch classifier loss: 0.276195; batch adversarial loss: 0.547773\n",
      "epoch 10; iter: 0; batch classifier loss: 0.311303; batch adversarial loss: 0.581929\n",
      "epoch 11; iter: 0; batch classifier loss: 0.332703; batch adversarial loss: 0.596467\n",
      "epoch 12; iter: 0; batch classifier loss: 0.246168; batch adversarial loss: 0.522594\n",
      "epoch 13; iter: 0; batch classifier loss: 0.273284; batch adversarial loss: 0.521015\n",
      "epoch 14; iter: 0; batch classifier loss: 0.354708; batch adversarial loss: 0.534710\n",
      "epoch 15; iter: 0; batch classifier loss: 0.397811; batch adversarial loss: 0.559528\n",
      "epoch 16; iter: 0; batch classifier loss: 0.399702; batch adversarial loss: 0.515399\n",
      "epoch 17; iter: 0; batch classifier loss: 0.556414; batch adversarial loss: 0.511375\n",
      "epoch 18; iter: 0; batch classifier loss: 0.485590; batch adversarial loss: 0.533675\n",
      "epoch 19; iter: 0; batch classifier loss: 0.327129; batch adversarial loss: 0.465781\n",
      "epoch 20; iter: 0; batch classifier loss: 0.249041; batch adversarial loss: 0.462758\n",
      "epoch 21; iter: 0; batch classifier loss: 0.173654; batch adversarial loss: 0.569085\n",
      "epoch 22; iter: 0; batch classifier loss: 0.270735; batch adversarial loss: 0.492962\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168079; batch adversarial loss: 0.486866\n",
      "epoch 24; iter: 0; batch classifier loss: 0.207474; batch adversarial loss: 0.482085\n",
      "epoch 25; iter: 0; batch classifier loss: 0.212034; batch adversarial loss: 0.436118\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165677; batch adversarial loss: 0.527431\n",
      "epoch 27; iter: 0; batch classifier loss: 0.149040; batch adversarial loss: 0.401477\n",
      "epoch 28; iter: 0; batch classifier loss: 0.111443; batch adversarial loss: 0.467637\n",
      "epoch 29; iter: 0; batch classifier loss: 0.185117; batch adversarial loss: 0.459029\n",
      "epoch 30; iter: 0; batch classifier loss: 0.149531; batch adversarial loss: 0.501049\n",
      "epoch 31; iter: 0; batch classifier loss: 0.166049; batch adversarial loss: 0.448936\n",
      "epoch 32; iter: 0; batch classifier loss: 0.149547; batch adversarial loss: 0.430530\n",
      "epoch 33; iter: 0; batch classifier loss: 0.080371; batch adversarial loss: 0.474688\n",
      "epoch 34; iter: 0; batch classifier loss: 0.116386; batch adversarial loss: 0.362553\n",
      "epoch 35; iter: 0; batch classifier loss: 0.084661; batch adversarial loss: 0.475610\n",
      "epoch 36; iter: 0; batch classifier loss: 0.110324; batch adversarial loss: 0.461503\n",
      "epoch 37; iter: 0; batch classifier loss: 0.119133; batch adversarial loss: 0.434350\n",
      "epoch 38; iter: 0; batch classifier loss: 0.137092; batch adversarial loss: 0.406376\n",
      "epoch 39; iter: 0; batch classifier loss: 0.094048; batch adversarial loss: 0.493235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.127705; batch adversarial loss: 0.494188\n",
      "epoch 41; iter: 0; batch classifier loss: 0.159283; batch adversarial loss: 0.485473\n",
      "epoch 42; iter: 0; batch classifier loss: 0.119737; batch adversarial loss: 0.451290\n",
      "epoch 43; iter: 0; batch classifier loss: 0.098320; batch adversarial loss: 0.457085\n",
      "epoch 44; iter: 0; batch classifier loss: 0.141353; batch adversarial loss: 0.431058\n",
      "epoch 45; iter: 0; batch classifier loss: 0.087515; batch adversarial loss: 0.466200\n",
      "epoch 46; iter: 0; batch classifier loss: 0.056096; batch adversarial loss: 0.432737\n",
      "epoch 47; iter: 0; batch classifier loss: 0.082445; batch adversarial loss: 0.516772\n",
      "epoch 48; iter: 0; batch classifier loss: 0.065293; batch adversarial loss: 0.448011\n",
      "epoch 49; iter: 0; batch classifier loss: 0.081793; batch adversarial loss: 0.527387\n",
      "epoch 50; iter: 0; batch classifier loss: 0.121592; batch adversarial loss: 0.385397\n",
      "epoch 51; iter: 0; batch classifier loss: 0.072994; batch adversarial loss: 0.450824\n",
      "epoch 52; iter: 0; batch classifier loss: 0.086259; batch adversarial loss: 0.498913\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095622; batch adversarial loss: 0.451167\n",
      "epoch 54; iter: 0; batch classifier loss: 0.115237; batch adversarial loss: 0.364585\n",
      "epoch 55; iter: 0; batch classifier loss: 0.092845; batch adversarial loss: 0.441800\n",
      "epoch 56; iter: 0; batch classifier loss: 0.086642; batch adversarial loss: 0.419671\n",
      "epoch 57; iter: 0; batch classifier loss: 0.064214; batch adversarial loss: 0.443195\n",
      "epoch 58; iter: 0; batch classifier loss: 0.039610; batch adversarial loss: 0.517251\n",
      "epoch 59; iter: 0; batch classifier loss: 0.064404; batch adversarial loss: 0.476890\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118266; batch adversarial loss: 0.479014\n",
      "epoch 61; iter: 0; batch classifier loss: 0.094795; batch adversarial loss: 0.475855\n",
      "epoch 62; iter: 0; batch classifier loss: 0.077767; batch adversarial loss: 0.478979\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095762; batch adversarial loss: 0.459624\n",
      "epoch 64; iter: 0; batch classifier loss: 0.068190; batch adversarial loss: 0.470589\n",
      "epoch 65; iter: 0; batch classifier loss: 0.081367; batch adversarial loss: 0.412293\n",
      "epoch 66; iter: 0; batch classifier loss: 0.181538; batch adversarial loss: 0.418441\n",
      "epoch 67; iter: 0; batch classifier loss: 0.049860; batch adversarial loss: 0.477023\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094380; batch adversarial loss: 0.540261\n",
      "epoch 69; iter: 0; batch classifier loss: 0.085712; batch adversarial loss: 0.526392\n",
      "epoch 70; iter: 0; batch classifier loss: 0.051785; batch adversarial loss: 0.554873\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064698; batch adversarial loss: 0.448385\n",
      "epoch 72; iter: 0; batch classifier loss: 0.059689; batch adversarial loss: 0.393119\n",
      "epoch 73; iter: 0; batch classifier loss: 0.039526; batch adversarial loss: 0.541379\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079943; batch adversarial loss: 0.466128\n",
      "epoch 75; iter: 0; batch classifier loss: 0.057721; batch adversarial loss: 0.514713\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083922; batch adversarial loss: 0.437541\n",
      "epoch 77; iter: 0; batch classifier loss: 0.159571; batch adversarial loss: 0.366526\n",
      "epoch 78; iter: 0; batch classifier loss: 0.122957; batch adversarial loss: 0.439567\n",
      "epoch 79; iter: 0; batch classifier loss: 0.098876; batch adversarial loss: 0.387837\n",
      "epoch 80; iter: 0; batch classifier loss: 0.102117; batch adversarial loss: 0.455996\n",
      "epoch 81; iter: 0; batch classifier loss: 0.061864; batch adversarial loss: 0.450199\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083252; batch adversarial loss: 0.450170\n",
      "epoch 83; iter: 0; batch classifier loss: 0.042418; batch adversarial loss: 0.526794\n",
      "epoch 84; iter: 0; batch classifier loss: 0.083479; batch adversarial loss: 0.476744\n",
      "epoch 85; iter: 0; batch classifier loss: 0.099560; batch adversarial loss: 0.414758\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081322; batch adversarial loss: 0.455714\n",
      "epoch 87; iter: 0; batch classifier loss: 0.065804; batch adversarial loss: 0.358651\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067316; batch adversarial loss: 0.418148\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054423; batch adversarial loss: 0.475814\n",
      "epoch 90; iter: 0; batch classifier loss: 0.091217; batch adversarial loss: 0.445039\n",
      "epoch 91; iter: 0; batch classifier loss: 0.076427; batch adversarial loss: 0.385831\n",
      "epoch 92; iter: 0; batch classifier loss: 0.086053; batch adversarial loss: 0.464577\n",
      "epoch 93; iter: 0; batch classifier loss: 0.059215; batch adversarial loss: 0.521863\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048012; batch adversarial loss: 0.472386\n",
      "epoch 95; iter: 0; batch classifier loss: 0.067978; batch adversarial loss: 0.491592\n",
      "epoch 96; iter: 0; batch classifier loss: 0.089719; batch adversarial loss: 0.420381\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081622; batch adversarial loss: 0.463307\n",
      "epoch 98; iter: 0; batch classifier loss: 0.104921; batch adversarial loss: 0.527661\n",
      "epoch 99; iter: 0; batch classifier loss: 0.107710; batch adversarial loss: 0.522713\n",
      "epoch 100; iter: 0; batch classifier loss: 0.073853; batch adversarial loss: 0.424620\n",
      "epoch 101; iter: 0; batch classifier loss: 0.093441; batch adversarial loss: 0.555615\n",
      "epoch 102; iter: 0; batch classifier loss: 0.093418; batch adversarial loss: 0.426766\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055204; batch adversarial loss: 0.534073\n",
      "epoch 104; iter: 0; batch classifier loss: 0.025386; batch adversarial loss: 0.387116\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043260; batch adversarial loss: 0.378395\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050236; batch adversarial loss: 0.460301\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058035; batch adversarial loss: 0.457658\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049027; batch adversarial loss: 0.433164\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039800; batch adversarial loss: 0.461499\n",
      "epoch 110; iter: 0; batch classifier loss: 0.095131; batch adversarial loss: 0.467637\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048117; batch adversarial loss: 0.503395\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040086; batch adversarial loss: 0.465624\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051651; batch adversarial loss: 0.438652\n",
      "epoch 114; iter: 0; batch classifier loss: 0.089481; batch adversarial loss: 0.481982\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029649; batch adversarial loss: 0.525705\n",
      "epoch 116; iter: 0; batch classifier loss: 0.075332; batch adversarial loss: 0.496166\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040126; batch adversarial loss: 0.427669\n",
      "epoch 118; iter: 0; batch classifier loss: 0.021219; batch adversarial loss: 0.456930\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044114; batch adversarial loss: 0.503218\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049667; batch adversarial loss: 0.421494\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040693; batch adversarial loss: 0.408517\n",
      "epoch 122; iter: 0; batch classifier loss: 0.072067; batch adversarial loss: 0.509960\n",
      "epoch 123; iter: 0; batch classifier loss: 0.084595; batch adversarial loss: 0.405545\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021277; batch adversarial loss: 0.561936\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033729; batch adversarial loss: 0.508732\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028857; batch adversarial loss: 0.476493\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045922; batch adversarial loss: 0.508131\n",
      "epoch 128; iter: 0; batch classifier loss: 0.064757; batch adversarial loss: 0.421340\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027601; batch adversarial loss: 0.415851\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026788; batch adversarial loss: 0.368079\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018153; batch adversarial loss: 0.388802\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041975; batch adversarial loss: 0.438012\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042490; batch adversarial loss: 0.426989\n",
      "epoch 134; iter: 0; batch classifier loss: 0.059927; batch adversarial loss: 0.420903\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033762; batch adversarial loss: 0.550200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.026754; batch adversarial loss: 0.392346\n",
      "epoch 137; iter: 0; batch classifier loss: 0.075218; batch adversarial loss: 0.554003\n",
      "epoch 138; iter: 0; batch classifier loss: 0.054556; batch adversarial loss: 0.462529\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040008; batch adversarial loss: 0.373073\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035520; batch adversarial loss: 0.581544\n",
      "epoch 141; iter: 0; batch classifier loss: 0.011459; batch adversarial loss: 0.454089\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027167; batch adversarial loss: 0.422720\n",
      "epoch 143; iter: 0; batch classifier loss: 0.012253; batch adversarial loss: 0.506766\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031529; batch adversarial loss: 0.514917\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031398; batch adversarial loss: 0.415465\n",
      "epoch 146; iter: 0; batch classifier loss: 0.071699; batch adversarial loss: 0.532809\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033233; batch adversarial loss: 0.434196\n",
      "epoch 148; iter: 0; batch classifier loss: 0.052614; batch adversarial loss: 0.412172\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025718; batch adversarial loss: 0.473701\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044055; batch adversarial loss: 0.549558\n",
      "epoch 151; iter: 0; batch classifier loss: 0.047556; batch adversarial loss: 0.348914\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022640; batch adversarial loss: 0.451072\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014530; batch adversarial loss: 0.498160\n",
      "epoch 154; iter: 0; batch classifier loss: 0.042076; batch adversarial loss: 0.404496\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021698; batch adversarial loss: 0.427965\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045152; batch adversarial loss: 0.562123\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034392; batch adversarial loss: 0.437515\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008933; batch adversarial loss: 0.436598\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035413; batch adversarial loss: 0.591533\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028043; batch adversarial loss: 0.470723\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019381; batch adversarial loss: 0.482153\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039049; batch adversarial loss: 0.508867\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025783; batch adversarial loss: 0.508884\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021262; batch adversarial loss: 0.423937\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008189; batch adversarial loss: 0.504150\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018964; batch adversarial loss: 0.495168\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013049; batch adversarial loss: 0.458665\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013772; batch adversarial loss: 0.464778\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013795; batch adversarial loss: 0.502592\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020218; batch adversarial loss: 0.436525\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009008; batch adversarial loss: 0.441146\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016837; batch adversarial loss: 0.500216\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020886; batch adversarial loss: 0.509930\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011955; batch adversarial loss: 0.452449\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028949; batch adversarial loss: 0.461388\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008834; batch adversarial loss: 0.391912\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013990; batch adversarial loss: 0.420463\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021384; batch adversarial loss: 0.430014\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021933; batch adversarial loss: 0.427964\n",
      "epoch 180; iter: 0; batch classifier loss: 0.047302; batch adversarial loss: 0.476239\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017715; batch adversarial loss: 0.527509\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033426; batch adversarial loss: 0.461894\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022983; batch adversarial loss: 0.392230\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012099; batch adversarial loss: 0.445324\n",
      "epoch 185; iter: 0; batch classifier loss: 0.030824; batch adversarial loss: 0.486270\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012965; batch adversarial loss: 0.477905\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031814; batch adversarial loss: 0.443421\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024259; batch adversarial loss: 0.462040\n",
      "epoch 189; iter: 0; batch classifier loss: 0.043411; batch adversarial loss: 0.537078\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008519; batch adversarial loss: 0.383430\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019475; batch adversarial loss: 0.551998\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028014; batch adversarial loss: 0.462081\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021287; batch adversarial loss: 0.470848\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032861; batch adversarial loss: 0.515342\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015194; batch adversarial loss: 0.486219\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032241; batch adversarial loss: 0.480269\n",
      "epoch 197; iter: 0; batch classifier loss: 0.035293; batch adversarial loss: 0.488772\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011493; batch adversarial loss: 0.433817\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016971; batch adversarial loss: 0.534557\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673924; batch adversarial loss: 0.716920\n",
      "epoch 1; iter: 0; batch classifier loss: 0.504452; batch adversarial loss: 0.685398\n",
      "epoch 2; iter: 0; batch classifier loss: 0.444040; batch adversarial loss: 0.642523\n",
      "epoch 3; iter: 0; batch classifier loss: 0.384627; batch adversarial loss: 0.594055\n",
      "epoch 4; iter: 0; batch classifier loss: 0.273401; batch adversarial loss: 0.573258\n",
      "epoch 5; iter: 0; batch classifier loss: 0.368796; batch adversarial loss: 0.556574\n",
      "epoch 6; iter: 0; batch classifier loss: 0.270472; batch adversarial loss: 0.549097\n",
      "epoch 7; iter: 0; batch classifier loss: 0.364205; batch adversarial loss: 0.519972\n",
      "epoch 8; iter: 0; batch classifier loss: 0.245144; batch adversarial loss: 0.503370\n",
      "epoch 9; iter: 0; batch classifier loss: 0.296993; batch adversarial loss: 0.488174\n",
      "epoch 10; iter: 0; batch classifier loss: 0.223107; batch adversarial loss: 0.493254\n",
      "epoch 11; iter: 0; batch classifier loss: 0.246536; batch adversarial loss: 0.459784\n",
      "epoch 12; iter: 0; batch classifier loss: 0.236066; batch adversarial loss: 0.513839\n",
      "epoch 13; iter: 0; batch classifier loss: 0.195123; batch adversarial loss: 0.503098\n",
      "epoch 14; iter: 0; batch classifier loss: 0.180224; batch adversarial loss: 0.476393\n",
      "epoch 15; iter: 0; batch classifier loss: 0.185178; batch adversarial loss: 0.491685\n",
      "epoch 16; iter: 0; batch classifier loss: 0.190730; batch adversarial loss: 0.510128\n",
      "epoch 17; iter: 0; batch classifier loss: 0.213906; batch adversarial loss: 0.485946\n",
      "epoch 18; iter: 0; batch classifier loss: 0.157418; batch adversarial loss: 0.460023\n",
      "epoch 19; iter: 0; batch classifier loss: 0.163601; batch adversarial loss: 0.479091\n",
      "epoch 20; iter: 0; batch classifier loss: 0.167456; batch adversarial loss: 0.548411\n",
      "epoch 21; iter: 0; batch classifier loss: 0.210621; batch adversarial loss: 0.480803\n",
      "epoch 22; iter: 0; batch classifier loss: 0.178596; batch adversarial loss: 0.399662\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168244; batch adversarial loss: 0.508872\n",
      "epoch 24; iter: 0; batch classifier loss: 0.157139; batch adversarial loss: 0.566108\n",
      "epoch 25; iter: 0; batch classifier loss: 0.188139; batch adversarial loss: 0.514679\n",
      "epoch 26; iter: 0; batch classifier loss: 0.226645; batch adversarial loss: 0.491913\n",
      "epoch 27; iter: 0; batch classifier loss: 0.253633; batch adversarial loss: 0.579705\n",
      "epoch 28; iter: 0; batch classifier loss: 0.180494; batch adversarial loss: 0.395988\n",
      "epoch 29; iter: 0; batch classifier loss: 0.317381; batch adversarial loss: 0.496048\n",
      "epoch 30; iter: 0; batch classifier loss: 0.323245; batch adversarial loss: 0.432501\n",
      "epoch 31; iter: 0; batch classifier loss: 0.278560; batch adversarial loss: 0.498697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.150852; batch adversarial loss: 0.478055\n",
      "epoch 33; iter: 0; batch classifier loss: 0.142702; batch adversarial loss: 0.477444\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122180; batch adversarial loss: 0.461155\n",
      "epoch 35; iter: 0; batch classifier loss: 0.095169; batch adversarial loss: 0.499677\n",
      "epoch 36; iter: 0; batch classifier loss: 0.159553; batch adversarial loss: 0.377974\n",
      "epoch 37; iter: 0; batch classifier loss: 0.100236; batch adversarial loss: 0.388637\n",
      "epoch 38; iter: 0; batch classifier loss: 0.161763; batch adversarial loss: 0.443328\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131384; batch adversarial loss: 0.482981\n",
      "epoch 40; iter: 0; batch classifier loss: 0.148183; batch adversarial loss: 0.404769\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125482; batch adversarial loss: 0.425711\n",
      "epoch 42; iter: 0; batch classifier loss: 0.115168; batch adversarial loss: 0.397043\n",
      "epoch 43; iter: 0; batch classifier loss: 0.083940; batch adversarial loss: 0.528943\n",
      "epoch 44; iter: 0; batch classifier loss: 0.149931; batch adversarial loss: 0.492658\n",
      "epoch 45; iter: 0; batch classifier loss: 0.096132; batch adversarial loss: 0.498145\n",
      "epoch 46; iter: 0; batch classifier loss: 0.083960; batch adversarial loss: 0.477561\n",
      "epoch 47; iter: 0; batch classifier loss: 0.072529; batch adversarial loss: 0.477609\n",
      "epoch 48; iter: 0; batch classifier loss: 0.118387; batch adversarial loss: 0.461079\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099355; batch adversarial loss: 0.361853\n",
      "epoch 50; iter: 0; batch classifier loss: 0.104426; batch adversarial loss: 0.524425\n",
      "epoch 51; iter: 0; batch classifier loss: 0.101850; batch adversarial loss: 0.476906\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101757; batch adversarial loss: 0.439809\n",
      "epoch 53; iter: 0; batch classifier loss: 0.116812; batch adversarial loss: 0.424619\n",
      "epoch 54; iter: 0; batch classifier loss: 0.094497; batch adversarial loss: 0.498384\n",
      "epoch 55; iter: 0; batch classifier loss: 0.080326; batch adversarial loss: 0.511113\n",
      "epoch 56; iter: 0; batch classifier loss: 0.097173; batch adversarial loss: 0.435854\n",
      "epoch 57; iter: 0; batch classifier loss: 0.088998; batch adversarial loss: 0.534640\n",
      "epoch 58; iter: 0; batch classifier loss: 0.079889; batch adversarial loss: 0.428510\n",
      "epoch 59; iter: 0; batch classifier loss: 0.061578; batch adversarial loss: 0.523122\n",
      "epoch 60; iter: 0; batch classifier loss: 0.080311; batch adversarial loss: 0.487492\n",
      "epoch 61; iter: 0; batch classifier loss: 0.189687; batch adversarial loss: 0.372520\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101690; batch adversarial loss: 0.501221\n",
      "epoch 63; iter: 0; batch classifier loss: 0.080521; batch adversarial loss: 0.509393\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098825; batch adversarial loss: 0.465458\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079975; batch adversarial loss: 0.532242\n",
      "epoch 66; iter: 0; batch classifier loss: 0.080016; batch adversarial loss: 0.606718\n",
      "epoch 67; iter: 0; batch classifier loss: 0.052648; batch adversarial loss: 0.501330\n",
      "epoch 68; iter: 0; batch classifier loss: 0.114607; batch adversarial loss: 0.469672\n",
      "epoch 69; iter: 0; batch classifier loss: 0.090976; batch adversarial loss: 0.397667\n",
      "epoch 70; iter: 0; batch classifier loss: 0.055620; batch adversarial loss: 0.601113\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073920; batch adversarial loss: 0.555000\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080280; batch adversarial loss: 0.593499\n",
      "epoch 73; iter: 0; batch classifier loss: 0.089604; batch adversarial loss: 0.499401\n",
      "epoch 74; iter: 0; batch classifier loss: 0.116128; batch adversarial loss: 0.441609\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096901; batch adversarial loss: 0.491215\n",
      "epoch 76; iter: 0; batch classifier loss: 0.054340; batch adversarial loss: 0.419861\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064308; batch adversarial loss: 0.499330\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090489; batch adversarial loss: 0.474070\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082237; batch adversarial loss: 0.445294\n",
      "epoch 80; iter: 0; batch classifier loss: 0.123773; batch adversarial loss: 0.363385\n",
      "epoch 81; iter: 0; batch classifier loss: 0.089645; batch adversarial loss: 0.383012\n",
      "epoch 82; iter: 0; batch classifier loss: 0.084944; batch adversarial loss: 0.451747\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035131; batch adversarial loss: 0.500469\n",
      "epoch 84; iter: 0; batch classifier loss: 0.074958; batch adversarial loss: 0.356319\n",
      "epoch 85; iter: 0; batch classifier loss: 0.080486; batch adversarial loss: 0.486719\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051784; batch adversarial loss: 0.519572\n",
      "epoch 87; iter: 0; batch classifier loss: 0.094282; batch adversarial loss: 0.479935\n",
      "epoch 88; iter: 0; batch classifier loss: 0.106474; batch adversarial loss: 0.463828\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073833; batch adversarial loss: 0.420487\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068685; batch adversarial loss: 0.487300\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060990; batch adversarial loss: 0.580352\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069125; batch adversarial loss: 0.566907\n",
      "epoch 93; iter: 0; batch classifier loss: 0.049952; batch adversarial loss: 0.432242\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033303; batch adversarial loss: 0.476867\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058372; batch adversarial loss: 0.465511\n",
      "epoch 96; iter: 0; batch classifier loss: 0.084289; batch adversarial loss: 0.514069\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060089; batch adversarial loss: 0.518849\n",
      "epoch 98; iter: 0; batch classifier loss: 0.028357; batch adversarial loss: 0.549553\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064170; batch adversarial loss: 0.409583\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056332; batch adversarial loss: 0.465553\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056809; batch adversarial loss: 0.416424\n",
      "epoch 102; iter: 0; batch classifier loss: 0.077691; batch adversarial loss: 0.455900\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054099; batch adversarial loss: 0.485000\n",
      "epoch 104; iter: 0; batch classifier loss: 0.055148; batch adversarial loss: 0.567644\n",
      "epoch 105; iter: 0; batch classifier loss: 0.039330; batch adversarial loss: 0.555622\n",
      "epoch 106; iter: 0; batch classifier loss: 0.100771; batch adversarial loss: 0.446122\n",
      "epoch 107; iter: 0; batch classifier loss: 0.079269; batch adversarial loss: 0.432923\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067447; batch adversarial loss: 0.511772\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044922; batch adversarial loss: 0.470449\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040722; batch adversarial loss: 0.429058\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037966; batch adversarial loss: 0.461258\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031683; batch adversarial loss: 0.475065\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049812; batch adversarial loss: 0.515176\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035216; batch adversarial loss: 0.488824\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045548; batch adversarial loss: 0.545353\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051927; batch adversarial loss: 0.335481\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032293; batch adversarial loss: 0.481448\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029243; batch adversarial loss: 0.513456\n",
      "epoch 119; iter: 0; batch classifier loss: 0.015664; batch adversarial loss: 0.454737\n",
      "epoch 120; iter: 0; batch classifier loss: 0.020722; batch adversarial loss: 0.490550\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040444; batch adversarial loss: 0.517886\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025501; batch adversarial loss: 0.454857\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025520; batch adversarial loss: 0.456831\n",
      "epoch 124; iter: 0; batch classifier loss: 0.016956; batch adversarial loss: 0.580332\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044829; batch adversarial loss: 0.422827\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028297; batch adversarial loss: 0.489516\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030616; batch adversarial loss: 0.382003\n",
      "epoch 128; iter: 0; batch classifier loss: 0.062282; batch adversarial loss: 0.346871\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029365; batch adversarial loss: 0.493295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.021727; batch adversarial loss: 0.398639\n",
      "epoch 131; iter: 0; batch classifier loss: 0.058842; batch adversarial loss: 0.506238\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027689; batch adversarial loss: 0.607834\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022890; batch adversarial loss: 0.475003\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018452; batch adversarial loss: 0.473221\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033150; batch adversarial loss: 0.449579\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019320; batch adversarial loss: 0.509092\n",
      "epoch 137; iter: 0; batch classifier loss: 0.059303; batch adversarial loss: 0.446815\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031568; batch adversarial loss: 0.374525\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013584; batch adversarial loss: 0.647090\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026893; batch adversarial loss: 0.549126\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022801; batch adversarial loss: 0.476436\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016036; batch adversarial loss: 0.447365\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020074; batch adversarial loss: 0.445577\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013496; batch adversarial loss: 0.491393\n",
      "epoch 145; iter: 0; batch classifier loss: 0.057804; batch adversarial loss: 0.487700\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022835; batch adversarial loss: 0.408999\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031541; batch adversarial loss: 0.400609\n",
      "epoch 148; iter: 0; batch classifier loss: 0.050866; batch adversarial loss: 0.576371\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021447; batch adversarial loss: 0.479580\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036087; batch adversarial loss: 0.442779\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025273; batch adversarial loss: 0.512011\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019435; batch adversarial loss: 0.375178\n",
      "epoch 153; iter: 0; batch classifier loss: 0.064219; batch adversarial loss: 0.443597\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018901; batch adversarial loss: 0.576071\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019239; batch adversarial loss: 0.472790\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015292; batch adversarial loss: 0.392879\n",
      "epoch 157; iter: 0; batch classifier loss: 0.048873; batch adversarial loss: 0.381284\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022432; batch adversarial loss: 0.423890\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020952; batch adversarial loss: 0.436148\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041575; batch adversarial loss: 0.414285\n",
      "epoch 161; iter: 0; batch classifier loss: 0.054173; batch adversarial loss: 0.531513\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033446; batch adversarial loss: 0.390092\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012080; batch adversarial loss: 0.480648\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028717; batch adversarial loss: 0.373736\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010983; batch adversarial loss: 0.496965\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018079; batch adversarial loss: 0.428019\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025439; batch adversarial loss: 0.625354\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023392; batch adversarial loss: 0.487124\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038272; batch adversarial loss: 0.390355\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017124; batch adversarial loss: 0.407457\n",
      "epoch 171; iter: 0; batch classifier loss: 0.064787; batch adversarial loss: 0.568565\n",
      "epoch 172; iter: 0; batch classifier loss: 0.043202; batch adversarial loss: 0.449763\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011010; batch adversarial loss: 0.520546\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027352; batch adversarial loss: 0.413674\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016513; batch adversarial loss: 0.428529\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007171; batch adversarial loss: 0.485212\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021660; batch adversarial loss: 0.477581\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033012; batch adversarial loss: 0.331962\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015385; batch adversarial loss: 0.611883\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041235; batch adversarial loss: 0.406723\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009794; batch adversarial loss: 0.460181\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011707; batch adversarial loss: 0.446082\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019062; batch adversarial loss: 0.539757\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025076; batch adversarial loss: 0.463109\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026019; batch adversarial loss: 0.485912\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011468; batch adversarial loss: 0.497637\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008291; batch adversarial loss: 0.458034\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028955; batch adversarial loss: 0.472523\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027911; batch adversarial loss: 0.492440\n",
      "epoch 190; iter: 0; batch classifier loss: 0.041167; batch adversarial loss: 0.475526\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033387; batch adversarial loss: 0.528043\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012321; batch adversarial loss: 0.505579\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007852; batch adversarial loss: 0.445372\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021316; batch adversarial loss: 0.575075\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027175; batch adversarial loss: 0.473460\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016866; batch adversarial loss: 0.474009\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005765; batch adversarial loss: 0.418733\n",
      "epoch 198; iter: 0; batch classifier loss: 0.043488; batch adversarial loss: 0.373368\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010554; batch adversarial loss: 0.518784\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703107; batch adversarial loss: 0.512162\n",
      "epoch 1; iter: 0; batch classifier loss: 0.476778; batch adversarial loss: 0.623600\n",
      "epoch 2; iter: 0; batch classifier loss: 0.343979; batch adversarial loss: 0.626644\n",
      "epoch 3; iter: 0; batch classifier loss: 0.330213; batch adversarial loss: 0.544303\n",
      "epoch 4; iter: 0; batch classifier loss: 0.339117; batch adversarial loss: 0.592862\n",
      "epoch 5; iter: 0; batch classifier loss: 0.457585; batch adversarial loss: 0.612694\n",
      "epoch 6; iter: 0; batch classifier loss: 0.424121; batch adversarial loss: 0.521766\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338338; batch adversarial loss: 0.505343\n",
      "epoch 8; iter: 0; batch classifier loss: 0.399526; batch adversarial loss: 0.641521\n",
      "epoch 9; iter: 0; batch classifier loss: 0.337708; batch adversarial loss: 0.523119\n",
      "epoch 10; iter: 0; batch classifier loss: 0.324915; batch adversarial loss: 0.505740\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403160; batch adversarial loss: 0.506426\n",
      "epoch 12; iter: 0; batch classifier loss: 0.464560; batch adversarial loss: 0.482191\n",
      "epoch 13; iter: 0; batch classifier loss: 0.773948; batch adversarial loss: 0.585649\n",
      "epoch 14; iter: 0; batch classifier loss: 0.601786; batch adversarial loss: 0.495908\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487343; batch adversarial loss: 0.558221\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311000; batch adversarial loss: 0.438167\n",
      "epoch 17; iter: 0; batch classifier loss: 0.301657; batch adversarial loss: 0.500167\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251902; batch adversarial loss: 0.472369\n",
      "epoch 19; iter: 0; batch classifier loss: 0.224616; batch adversarial loss: 0.392369\n",
      "epoch 20; iter: 0; batch classifier loss: 0.205604; batch adversarial loss: 0.464126\n",
      "epoch 21; iter: 0; batch classifier loss: 0.233617; batch adversarial loss: 0.467909\n",
      "epoch 22; iter: 0; batch classifier loss: 0.177992; batch adversarial loss: 0.515713\n",
      "epoch 23; iter: 0; batch classifier loss: 0.135356; batch adversarial loss: 0.448272\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195083; batch adversarial loss: 0.471573\n",
      "epoch 25; iter: 0; batch classifier loss: 0.136409; batch adversarial loss: 0.386413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.161030; batch adversarial loss: 0.547727\n",
      "epoch 27; iter: 0; batch classifier loss: 0.189950; batch adversarial loss: 0.469420\n",
      "epoch 28; iter: 0; batch classifier loss: 0.106877; batch adversarial loss: 0.466854\n",
      "epoch 29; iter: 0; batch classifier loss: 0.117409; batch adversarial loss: 0.449974\n",
      "epoch 30; iter: 0; batch classifier loss: 0.157342; batch adversarial loss: 0.396451\n",
      "epoch 31; iter: 0; batch classifier loss: 0.166992; batch adversarial loss: 0.490258\n",
      "epoch 32; iter: 0; batch classifier loss: 0.098549; batch adversarial loss: 0.412123\n",
      "epoch 33; iter: 0; batch classifier loss: 0.108291; batch adversarial loss: 0.448400\n",
      "epoch 34; iter: 0; batch classifier loss: 0.115532; batch adversarial loss: 0.509270\n",
      "epoch 35; iter: 0; batch classifier loss: 0.109835; batch adversarial loss: 0.418191\n",
      "epoch 36; iter: 0; batch classifier loss: 0.100441; batch adversarial loss: 0.446421\n",
      "epoch 37; iter: 0; batch classifier loss: 0.140751; batch adversarial loss: 0.454218\n",
      "epoch 38; iter: 0; batch classifier loss: 0.123834; batch adversarial loss: 0.494396\n",
      "epoch 39; iter: 0; batch classifier loss: 0.137730; batch adversarial loss: 0.484595\n",
      "epoch 40; iter: 0; batch classifier loss: 0.165459; batch adversarial loss: 0.440094\n",
      "epoch 41; iter: 0; batch classifier loss: 0.092876; batch adversarial loss: 0.555791\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103142; batch adversarial loss: 0.451427\n",
      "epoch 43; iter: 0; batch classifier loss: 0.100465; batch adversarial loss: 0.433614\n",
      "epoch 44; iter: 0; batch classifier loss: 0.099190; batch adversarial loss: 0.389158\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108079; batch adversarial loss: 0.458916\n",
      "epoch 46; iter: 0; batch classifier loss: 0.121944; batch adversarial loss: 0.418206\n",
      "epoch 47; iter: 0; batch classifier loss: 0.151513; batch adversarial loss: 0.430166\n",
      "epoch 48; iter: 0; batch classifier loss: 0.127760; batch adversarial loss: 0.483794\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114937; batch adversarial loss: 0.553411\n",
      "epoch 50; iter: 0; batch classifier loss: 0.067731; batch adversarial loss: 0.523377\n",
      "epoch 51; iter: 0; batch classifier loss: 0.125957; batch adversarial loss: 0.460997\n",
      "epoch 52; iter: 0; batch classifier loss: 0.110656; batch adversarial loss: 0.538157\n",
      "epoch 53; iter: 0; batch classifier loss: 0.147941; batch adversarial loss: 0.467277\n",
      "epoch 54; iter: 0; batch classifier loss: 0.139038; batch adversarial loss: 0.378676\n",
      "epoch 55; iter: 0; batch classifier loss: 0.116116; batch adversarial loss: 0.459178\n",
      "epoch 56; iter: 0; batch classifier loss: 0.117942; batch adversarial loss: 0.499569\n",
      "epoch 57; iter: 0; batch classifier loss: 0.129097; batch adversarial loss: 0.423173\n",
      "epoch 58; iter: 0; batch classifier loss: 0.122355; batch adversarial loss: 0.446410\n",
      "epoch 59; iter: 0; batch classifier loss: 0.089968; batch adversarial loss: 0.455225\n",
      "epoch 60; iter: 0; batch classifier loss: 0.130917; batch adversarial loss: 0.407448\n",
      "epoch 61; iter: 0; batch classifier loss: 0.175175; batch adversarial loss: 0.469907\n",
      "epoch 62; iter: 0; batch classifier loss: 0.115425; batch adversarial loss: 0.448114\n",
      "epoch 63; iter: 0; batch classifier loss: 0.176791; batch adversarial loss: 0.441238\n",
      "epoch 64; iter: 0; batch classifier loss: 0.134430; batch adversarial loss: 0.419694\n",
      "epoch 65; iter: 0; batch classifier loss: 0.147334; batch adversarial loss: 0.467436\n",
      "epoch 66; iter: 0; batch classifier loss: 0.130218; batch adversarial loss: 0.474253\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094709; batch adversarial loss: 0.460927\n",
      "epoch 68; iter: 0; batch classifier loss: 0.144338; batch adversarial loss: 0.509356\n",
      "epoch 69; iter: 0; batch classifier loss: 0.112765; batch adversarial loss: 0.417523\n",
      "epoch 70; iter: 0; batch classifier loss: 0.100420; batch adversarial loss: 0.508198\n",
      "epoch 71; iter: 0; batch classifier loss: 0.116610; batch adversarial loss: 0.466771\n",
      "epoch 72; iter: 0; batch classifier loss: 0.115357; batch adversarial loss: 0.454544\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079168; batch adversarial loss: 0.461558\n",
      "epoch 74; iter: 0; batch classifier loss: 0.090942; batch adversarial loss: 0.449438\n",
      "epoch 75; iter: 0; batch classifier loss: 0.170095; batch adversarial loss: 0.471110\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081278; batch adversarial loss: 0.412867\n",
      "epoch 77; iter: 0; batch classifier loss: 0.090507; batch adversarial loss: 0.385882\n",
      "epoch 78; iter: 0; batch classifier loss: 0.116007; batch adversarial loss: 0.475262\n",
      "epoch 79; iter: 0; batch classifier loss: 0.089086; batch adversarial loss: 0.540062\n",
      "epoch 80; iter: 0; batch classifier loss: 0.133823; batch adversarial loss: 0.372259\n",
      "epoch 81; iter: 0; batch classifier loss: 0.105892; batch adversarial loss: 0.461028\n",
      "epoch 82; iter: 0; batch classifier loss: 0.079093; batch adversarial loss: 0.419269\n",
      "epoch 83; iter: 0; batch classifier loss: 0.123097; batch adversarial loss: 0.344760\n",
      "epoch 84; iter: 0; batch classifier loss: 0.071745; batch adversarial loss: 0.475919\n",
      "epoch 85; iter: 0; batch classifier loss: 0.100721; batch adversarial loss: 0.473131\n",
      "epoch 86; iter: 0; batch classifier loss: 0.077272; batch adversarial loss: 0.511538\n",
      "epoch 87; iter: 0; batch classifier loss: 0.090461; batch adversarial loss: 0.460589\n",
      "epoch 88; iter: 0; batch classifier loss: 0.101538; batch adversarial loss: 0.499513\n",
      "epoch 89; iter: 0; batch classifier loss: 0.193216; batch adversarial loss: 0.368243\n",
      "epoch 90; iter: 0; batch classifier loss: 0.113571; batch adversarial loss: 0.474780\n",
      "epoch 91; iter: 0; batch classifier loss: 0.119602; batch adversarial loss: 0.468107\n",
      "epoch 92; iter: 0; batch classifier loss: 0.107153; batch adversarial loss: 0.462810\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065587; batch adversarial loss: 0.512954\n",
      "epoch 94; iter: 0; batch classifier loss: 0.104737; batch adversarial loss: 0.554815\n",
      "epoch 95; iter: 0; batch classifier loss: 0.084215; batch adversarial loss: 0.526007\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070856; batch adversarial loss: 0.478289\n",
      "epoch 97; iter: 0; batch classifier loss: 0.094505; batch adversarial loss: 0.428941\n",
      "epoch 98; iter: 0; batch classifier loss: 0.068927; batch adversarial loss: 0.492664\n",
      "epoch 99; iter: 0; batch classifier loss: 0.088552; batch adversarial loss: 0.417521\n",
      "epoch 100; iter: 0; batch classifier loss: 0.103812; batch adversarial loss: 0.451200\n",
      "epoch 101; iter: 0; batch classifier loss: 0.073678; batch adversarial loss: 0.431482\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067492; batch adversarial loss: 0.441700\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032716; batch adversarial loss: 0.350579\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063950; batch adversarial loss: 0.419725\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060522; batch adversarial loss: 0.491304\n",
      "epoch 106; iter: 0; batch classifier loss: 0.073673; batch adversarial loss: 0.414142\n",
      "epoch 107; iter: 0; batch classifier loss: 0.129843; batch adversarial loss: 0.436292\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057490; batch adversarial loss: 0.553182\n",
      "epoch 109; iter: 0; batch classifier loss: 0.069225; batch adversarial loss: 0.431312\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036850; batch adversarial loss: 0.446193\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048874; batch adversarial loss: 0.444232\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075351; batch adversarial loss: 0.419380\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048573; batch adversarial loss: 0.506760\n",
      "epoch 114; iter: 0; batch classifier loss: 0.087546; batch adversarial loss: 0.563064\n",
      "epoch 115; iter: 0; batch classifier loss: 0.066481; batch adversarial loss: 0.396681\n",
      "epoch 116; iter: 0; batch classifier loss: 0.087464; batch adversarial loss: 0.452519\n",
      "epoch 117; iter: 0; batch classifier loss: 0.079004; batch adversarial loss: 0.426075\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048777; batch adversarial loss: 0.480862\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041376; batch adversarial loss: 0.479638\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044771; batch adversarial loss: 0.441009\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050718; batch adversarial loss: 0.452675\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059478; batch adversarial loss: 0.458413\n",
      "epoch 123; iter: 0; batch classifier loss: 0.097917; batch adversarial loss: 0.442928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.044714; batch adversarial loss: 0.389628\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043315; batch adversarial loss: 0.442171\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032648; batch adversarial loss: 0.497742\n",
      "epoch 127; iter: 0; batch classifier loss: 0.020400; batch adversarial loss: 0.426481\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037796; batch adversarial loss: 0.462321\n",
      "epoch 129; iter: 0; batch classifier loss: 0.082973; batch adversarial loss: 0.449101\n",
      "epoch 130; iter: 0; batch classifier loss: 0.066993; batch adversarial loss: 0.447519\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027873; batch adversarial loss: 0.378600\n",
      "epoch 132; iter: 0; batch classifier loss: 0.059112; batch adversarial loss: 0.417501\n",
      "epoch 133; iter: 0; batch classifier loss: 0.058351; batch adversarial loss: 0.507614\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037354; batch adversarial loss: 0.351889\n",
      "epoch 135; iter: 0; batch classifier loss: 0.064617; batch adversarial loss: 0.443336\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028371; batch adversarial loss: 0.422210\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038810; batch adversarial loss: 0.454547\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026986; batch adversarial loss: 0.552250\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038047; batch adversarial loss: 0.468779\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036784; batch adversarial loss: 0.420802\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020598; batch adversarial loss: 0.506344\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025638; batch adversarial loss: 0.331652\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043318; batch adversarial loss: 0.371518\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018550; batch adversarial loss: 0.429955\n",
      "epoch 145; iter: 0; batch classifier loss: 0.047499; batch adversarial loss: 0.420963\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015360; batch adversarial loss: 0.474484\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040575; batch adversarial loss: 0.397380\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034073; batch adversarial loss: 0.549783\n",
      "epoch 149; iter: 0; batch classifier loss: 0.049258; batch adversarial loss: 0.386773\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026324; batch adversarial loss: 0.455225\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024673; batch adversarial loss: 0.424977\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024764; batch adversarial loss: 0.478851\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027041; batch adversarial loss: 0.466761\n",
      "epoch 154; iter: 0; batch classifier loss: 0.072728; batch adversarial loss: 0.473469\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028087; batch adversarial loss: 0.446153\n",
      "epoch 156; iter: 0; batch classifier loss: 0.049516; batch adversarial loss: 0.505983\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027307; batch adversarial loss: 0.360541\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025225; batch adversarial loss: 0.461015\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028305; batch adversarial loss: 0.414645\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024842; batch adversarial loss: 0.492796\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027928; batch adversarial loss: 0.459854\n",
      "epoch 162; iter: 0; batch classifier loss: 0.058623; batch adversarial loss: 0.441413\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024011; batch adversarial loss: 0.440624\n",
      "epoch 164; iter: 0; batch classifier loss: 0.042368; batch adversarial loss: 0.534369\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015299; batch adversarial loss: 0.462254\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015879; batch adversarial loss: 0.474778\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042280; batch adversarial loss: 0.501149\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025267; batch adversarial loss: 0.460587\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015173; batch adversarial loss: 0.516776\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014197; batch adversarial loss: 0.513463\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011675; batch adversarial loss: 0.484268\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022521; batch adversarial loss: 0.478727\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031250; batch adversarial loss: 0.411086\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025624; batch adversarial loss: 0.420935\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014511; batch adversarial loss: 0.423712\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018287; batch adversarial loss: 0.473942\n",
      "epoch 177; iter: 0; batch classifier loss: 0.051921; batch adversarial loss: 0.373358\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009455; batch adversarial loss: 0.509399\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016281; batch adversarial loss: 0.419674\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035326; batch adversarial loss: 0.471026\n",
      "epoch 181; iter: 0; batch classifier loss: 0.040373; batch adversarial loss: 0.459033\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022554; batch adversarial loss: 0.440916\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025912; batch adversarial loss: 0.459533\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003822; batch adversarial loss: 0.453222\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026151; batch adversarial loss: 0.493781\n",
      "epoch 186; iter: 0; batch classifier loss: 0.037573; batch adversarial loss: 0.455605\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012921; batch adversarial loss: 0.444775\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009946; batch adversarial loss: 0.369346\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013318; batch adversarial loss: 0.361275\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022519; batch adversarial loss: 0.440397\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018014; batch adversarial loss: 0.437541\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007801; batch adversarial loss: 0.359427\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007799; batch adversarial loss: 0.367043\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031218; batch adversarial loss: 0.363464\n",
      "epoch 195; iter: 0; batch classifier loss: 0.007644; batch adversarial loss: 0.496377\n",
      "epoch 196; iter: 0; batch classifier loss: 0.046111; batch adversarial loss: 0.387016\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022056; batch adversarial loss: 0.404188\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015607; batch adversarial loss: 0.411292\n",
      "epoch 199; iter: 0; batch classifier loss: 0.050601; batch adversarial loss: 0.442107\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683727; batch adversarial loss: 0.641868\n",
      "epoch 1; iter: 0; batch classifier loss: 0.461432; batch adversarial loss: 0.649663\n",
      "epoch 2; iter: 0; batch classifier loss: 0.404864; batch adversarial loss: 0.619210\n",
      "epoch 3; iter: 0; batch classifier loss: 0.314079; batch adversarial loss: 0.583221\n",
      "epoch 4; iter: 0; batch classifier loss: 0.279126; batch adversarial loss: 0.575695\n",
      "epoch 5; iter: 0; batch classifier loss: 0.355678; batch adversarial loss: 0.556549\n",
      "epoch 6; iter: 0; batch classifier loss: 0.304239; batch adversarial loss: 0.534531\n",
      "epoch 7; iter: 0; batch classifier loss: 0.285959; batch adversarial loss: 0.515695\n",
      "epoch 8; iter: 0; batch classifier loss: 0.315048; batch adversarial loss: 0.498604\n",
      "epoch 9; iter: 0; batch classifier loss: 0.242422; batch adversarial loss: 0.454704\n",
      "epoch 10; iter: 0; batch classifier loss: 0.254260; batch adversarial loss: 0.415757\n",
      "epoch 11; iter: 0; batch classifier loss: 0.169232; batch adversarial loss: 0.548025\n",
      "epoch 12; iter: 0; batch classifier loss: 0.242970; batch adversarial loss: 0.538147\n",
      "epoch 13; iter: 0; batch classifier loss: 0.209273; batch adversarial loss: 0.484403\n",
      "epoch 14; iter: 0; batch classifier loss: 0.186950; batch adversarial loss: 0.464767\n",
      "epoch 15; iter: 0; batch classifier loss: 0.185698; batch adversarial loss: 0.456995\n",
      "epoch 16; iter: 0; batch classifier loss: 0.164903; batch adversarial loss: 0.448138\n",
      "epoch 17; iter: 0; batch classifier loss: 0.131989; batch adversarial loss: 0.432537\n",
      "epoch 18; iter: 0; batch classifier loss: 0.134850; batch adversarial loss: 0.471349\n",
      "epoch 19; iter: 0; batch classifier loss: 0.188393; batch adversarial loss: 0.420034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.199604; batch adversarial loss: 0.475832\n",
      "epoch 21; iter: 0; batch classifier loss: 0.158530; batch adversarial loss: 0.457696\n",
      "epoch 22; iter: 0; batch classifier loss: 0.188298; batch adversarial loss: 0.567901\n",
      "epoch 23; iter: 0; batch classifier loss: 0.182171; batch adversarial loss: 0.522370\n",
      "epoch 24; iter: 0; batch classifier loss: 0.179512; batch adversarial loss: 0.559144\n",
      "epoch 25; iter: 0; batch classifier loss: 0.170635; batch adversarial loss: 0.503630\n",
      "epoch 26; iter: 0; batch classifier loss: 0.151247; batch adversarial loss: 0.541544\n",
      "epoch 27; iter: 0; batch classifier loss: 0.203187; batch adversarial loss: 0.445171\n",
      "epoch 28; iter: 0; batch classifier loss: 0.163370; batch adversarial loss: 0.450738\n",
      "epoch 29; iter: 0; batch classifier loss: 0.171721; batch adversarial loss: 0.464779\n",
      "epoch 30; iter: 0; batch classifier loss: 0.217517; batch adversarial loss: 0.391009\n",
      "epoch 31; iter: 0; batch classifier loss: 0.314345; batch adversarial loss: 0.466087\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238117; batch adversarial loss: 0.491974\n",
      "epoch 33; iter: 0; batch classifier loss: 0.207146; batch adversarial loss: 0.435021\n",
      "epoch 34; iter: 0; batch classifier loss: 0.340674; batch adversarial loss: 0.395959\n",
      "epoch 35; iter: 0; batch classifier loss: 0.212022; batch adversarial loss: 0.393758\n",
      "epoch 36; iter: 0; batch classifier loss: 0.155919; batch adversarial loss: 0.558239\n",
      "epoch 37; iter: 0; batch classifier loss: 0.124479; batch adversarial loss: 0.437343\n",
      "epoch 38; iter: 0; batch classifier loss: 0.083951; batch adversarial loss: 0.426092\n",
      "epoch 39; iter: 0; batch classifier loss: 0.060603; batch adversarial loss: 0.447871\n",
      "epoch 40; iter: 0; batch classifier loss: 0.143319; batch adversarial loss: 0.402713\n",
      "epoch 41; iter: 0; batch classifier loss: 0.065952; batch adversarial loss: 0.456128\n",
      "epoch 42; iter: 0; batch classifier loss: 0.080251; batch adversarial loss: 0.432643\n",
      "epoch 43; iter: 0; batch classifier loss: 0.049807; batch adversarial loss: 0.406321\n",
      "epoch 44; iter: 0; batch classifier loss: 0.060065; batch adversarial loss: 0.423777\n",
      "epoch 45; iter: 0; batch classifier loss: 0.080645; batch adversarial loss: 0.456523\n",
      "epoch 46; iter: 0; batch classifier loss: 0.087567; batch adversarial loss: 0.388063\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114405; batch adversarial loss: 0.419135\n",
      "epoch 48; iter: 0; batch classifier loss: 0.075516; batch adversarial loss: 0.448059\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080060; batch adversarial loss: 0.448986\n",
      "epoch 50; iter: 0; batch classifier loss: 0.081558; batch adversarial loss: 0.390258\n",
      "epoch 51; iter: 0; batch classifier loss: 0.065687; batch adversarial loss: 0.370515\n",
      "epoch 52; iter: 0; batch classifier loss: 0.085783; batch adversarial loss: 0.455003\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096089; batch adversarial loss: 0.472686\n",
      "epoch 54; iter: 0; batch classifier loss: 0.060021; batch adversarial loss: 0.539153\n",
      "epoch 55; iter: 0; batch classifier loss: 0.082247; batch adversarial loss: 0.440809\n",
      "epoch 56; iter: 0; batch classifier loss: 0.060915; batch adversarial loss: 0.429238\n",
      "epoch 57; iter: 0; batch classifier loss: 0.083931; batch adversarial loss: 0.427626\n",
      "epoch 58; iter: 0; batch classifier loss: 0.053363; batch adversarial loss: 0.390235\n",
      "epoch 59; iter: 0; batch classifier loss: 0.056440; batch adversarial loss: 0.435573\n",
      "epoch 60; iter: 0; batch classifier loss: 0.068939; batch adversarial loss: 0.422059\n",
      "epoch 61; iter: 0; batch classifier loss: 0.069973; batch adversarial loss: 0.423567\n",
      "epoch 62; iter: 0; batch classifier loss: 0.102257; batch adversarial loss: 0.450483\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070062; batch adversarial loss: 0.490426\n",
      "epoch 64; iter: 0; batch classifier loss: 0.053028; batch adversarial loss: 0.366463\n",
      "epoch 65; iter: 0; batch classifier loss: 0.076676; batch adversarial loss: 0.403211\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068188; batch adversarial loss: 0.503806\n",
      "epoch 67; iter: 0; batch classifier loss: 0.068833; batch adversarial loss: 0.424527\n",
      "epoch 68; iter: 0; batch classifier loss: 0.093064; batch adversarial loss: 0.436142\n",
      "epoch 69; iter: 0; batch classifier loss: 0.039566; batch adversarial loss: 0.405372\n",
      "epoch 70; iter: 0; batch classifier loss: 0.092554; batch adversarial loss: 0.397885\n",
      "epoch 71; iter: 0; batch classifier loss: 0.053084; batch adversarial loss: 0.436212\n",
      "epoch 72; iter: 0; batch classifier loss: 0.060677; batch adversarial loss: 0.481226\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065005; batch adversarial loss: 0.528520\n",
      "epoch 74; iter: 0; batch classifier loss: 0.110639; batch adversarial loss: 0.490249\n",
      "epoch 75; iter: 0; batch classifier loss: 0.062034; batch adversarial loss: 0.393068\n",
      "epoch 76; iter: 0; batch classifier loss: 0.054507; batch adversarial loss: 0.441039\n",
      "epoch 77; iter: 0; batch classifier loss: 0.034813; batch adversarial loss: 0.440178\n",
      "epoch 78; iter: 0; batch classifier loss: 0.091301; batch adversarial loss: 0.431209\n",
      "epoch 79; iter: 0; batch classifier loss: 0.059044; batch adversarial loss: 0.400197\n",
      "epoch 80; iter: 0; batch classifier loss: 0.071600; batch adversarial loss: 0.378007\n",
      "epoch 81; iter: 0; batch classifier loss: 0.052254; batch adversarial loss: 0.452505\n",
      "epoch 82; iter: 0; batch classifier loss: 0.027357; batch adversarial loss: 0.451068\n",
      "epoch 83; iter: 0; batch classifier loss: 0.055048; batch adversarial loss: 0.414529\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056540; batch adversarial loss: 0.521890\n",
      "epoch 85; iter: 0; batch classifier loss: 0.098387; batch adversarial loss: 0.323512\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051777; batch adversarial loss: 0.452802\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082903; batch adversarial loss: 0.493793\n",
      "epoch 88; iter: 0; batch classifier loss: 0.087841; batch adversarial loss: 0.493727\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080947; batch adversarial loss: 0.452211\n",
      "epoch 90; iter: 0; batch classifier loss: 0.069306; batch adversarial loss: 0.396892\n",
      "epoch 91; iter: 0; batch classifier loss: 0.053097; batch adversarial loss: 0.546030\n",
      "epoch 92; iter: 0; batch classifier loss: 0.078751; batch adversarial loss: 0.426410\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062108; batch adversarial loss: 0.464682\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062416; batch adversarial loss: 0.568027\n",
      "epoch 95; iter: 0; batch classifier loss: 0.097205; batch adversarial loss: 0.407795\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047860; batch adversarial loss: 0.390156\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072280; batch adversarial loss: 0.491749\n",
      "epoch 98; iter: 0; batch classifier loss: 0.057187; batch adversarial loss: 0.425453\n",
      "epoch 99; iter: 0; batch classifier loss: 0.094902; batch adversarial loss: 0.497504\n",
      "epoch 100; iter: 0; batch classifier loss: 0.081857; batch adversarial loss: 0.522977\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071139; batch adversarial loss: 0.462670\n",
      "epoch 102; iter: 0; batch classifier loss: 0.028942; batch adversarial loss: 0.435808\n",
      "epoch 103; iter: 0; batch classifier loss: 0.034005; batch adversarial loss: 0.443239\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037441; batch adversarial loss: 0.451374\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040110; batch adversarial loss: 0.426853\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041552; batch adversarial loss: 0.494002\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035338; batch adversarial loss: 0.420893\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055665; batch adversarial loss: 0.471294\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030285; batch adversarial loss: 0.365634\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033629; batch adversarial loss: 0.405967\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042066; batch adversarial loss: 0.492605\n",
      "epoch 112; iter: 0; batch classifier loss: 0.058637; batch adversarial loss: 0.370942\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052343; batch adversarial loss: 0.413516\n",
      "epoch 114; iter: 0; batch classifier loss: 0.064852; batch adversarial loss: 0.488811\n",
      "epoch 115; iter: 0; batch classifier loss: 0.058976; batch adversarial loss: 0.438991\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051025; batch adversarial loss: 0.432773\n",
      "epoch 117; iter: 0; batch classifier loss: 0.093493; batch adversarial loss: 0.505963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.075976; batch adversarial loss: 0.493964\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041898; batch adversarial loss: 0.377624\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032690; batch adversarial loss: 0.399925\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032059; batch adversarial loss: 0.432573\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036293; batch adversarial loss: 0.408940\n",
      "epoch 123; iter: 0; batch classifier loss: 0.072412; batch adversarial loss: 0.324366\n",
      "epoch 124; iter: 0; batch classifier loss: 0.072313; batch adversarial loss: 0.375974\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025800; batch adversarial loss: 0.426649\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024437; batch adversarial loss: 0.479390\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024780; batch adversarial loss: 0.384164\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040555; batch adversarial loss: 0.392700\n",
      "epoch 129; iter: 0; batch classifier loss: 0.072785; batch adversarial loss: 0.368648\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034696; batch adversarial loss: 0.500551\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039947; batch adversarial loss: 0.424748\n",
      "epoch 132; iter: 0; batch classifier loss: 0.011819; batch adversarial loss: 0.391537\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042784; batch adversarial loss: 0.401921\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035955; batch adversarial loss: 0.314189\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032645; batch adversarial loss: 0.452681\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038270; batch adversarial loss: 0.492442\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031786; batch adversarial loss: 0.395742\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038697; batch adversarial loss: 0.569710\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038036; batch adversarial loss: 0.505185\n",
      "epoch 140; iter: 0; batch classifier loss: 0.064493; batch adversarial loss: 0.486543\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021032; batch adversarial loss: 0.510162\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025502; batch adversarial loss: 0.375581\n",
      "epoch 143; iter: 0; batch classifier loss: 0.055502; batch adversarial loss: 0.502786\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030426; batch adversarial loss: 0.410368\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040729; batch adversarial loss: 0.464308\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029208; batch adversarial loss: 0.443760\n",
      "epoch 147; iter: 0; batch classifier loss: 0.050353; batch adversarial loss: 0.516056\n",
      "epoch 148; iter: 0; batch classifier loss: 0.037957; batch adversarial loss: 0.427421\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037482; batch adversarial loss: 0.469251\n",
      "epoch 150; iter: 0; batch classifier loss: 0.057874; batch adversarial loss: 0.395647\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019732; batch adversarial loss: 0.368509\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036351; batch adversarial loss: 0.398760\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034581; batch adversarial loss: 0.365645\n",
      "epoch 154; iter: 0; batch classifier loss: 0.042738; batch adversarial loss: 0.335299\n",
      "epoch 155; iter: 0; batch classifier loss: 0.039073; batch adversarial loss: 0.488576\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018031; batch adversarial loss: 0.480555\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011721; batch adversarial loss: 0.390094\n",
      "epoch 158; iter: 0; batch classifier loss: 0.069670; batch adversarial loss: 0.433925\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014332; batch adversarial loss: 0.482822\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014446; batch adversarial loss: 0.401251\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011485; batch adversarial loss: 0.415167\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029048; batch adversarial loss: 0.533515\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018420; batch adversarial loss: 0.417234\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034563; batch adversarial loss: 0.417515\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018425; batch adversarial loss: 0.335860\n",
      "epoch 166; iter: 0; batch classifier loss: 0.055300; batch adversarial loss: 0.476543\n",
      "epoch 167; iter: 0; batch classifier loss: 0.043367; batch adversarial loss: 0.446756\n",
      "epoch 168; iter: 0; batch classifier loss: 0.059806; batch adversarial loss: 0.377619\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031762; batch adversarial loss: 0.352964\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025505; batch adversarial loss: 0.492128\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029625; batch adversarial loss: 0.395727\n",
      "epoch 172; iter: 0; batch classifier loss: 0.046310; batch adversarial loss: 0.465003\n",
      "epoch 173; iter: 0; batch classifier loss: 0.045219; batch adversarial loss: 0.472247\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020946; batch adversarial loss: 0.455464\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014121; batch adversarial loss: 0.533742\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045727; batch adversarial loss: 0.422740\n",
      "epoch 177; iter: 0; batch classifier loss: 0.045776; batch adversarial loss: 0.522520\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025017; batch adversarial loss: 0.470220\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009034; batch adversarial loss: 0.492787\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021851; batch adversarial loss: 0.397214\n",
      "epoch 181; iter: 0; batch classifier loss: 0.040404; batch adversarial loss: 0.435149\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012244; batch adversarial loss: 0.382475\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027728; batch adversarial loss: 0.349136\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033054; batch adversarial loss: 0.451414\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026460; batch adversarial loss: 0.465709\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020107; batch adversarial loss: 0.464076\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009127; batch adversarial loss: 0.418954\n",
      "epoch 188; iter: 0; batch classifier loss: 0.051659; batch adversarial loss: 0.489850\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022017; batch adversarial loss: 0.437890\n",
      "epoch 190; iter: 0; batch classifier loss: 0.046255; batch adversarial loss: 0.358380\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028259; batch adversarial loss: 0.427960\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021363; batch adversarial loss: 0.526658\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015345; batch adversarial loss: 0.538889\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015129; batch adversarial loss: 0.386479\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024499; batch adversarial loss: 0.482857\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027971; batch adversarial loss: 0.423083\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010687; batch adversarial loss: 0.496723\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021166; batch adversarial loss: 0.410007\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025702; batch adversarial loss: 0.522356\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706604; batch adversarial loss: 0.719274\n",
      "epoch 1; iter: 0; batch classifier loss: 0.419017; batch adversarial loss: 0.676381\n",
      "epoch 2; iter: 0; batch classifier loss: 0.371795; batch adversarial loss: 0.640167\n",
      "epoch 3; iter: 0; batch classifier loss: 0.247475; batch adversarial loss: 0.630163\n",
      "epoch 4; iter: 0; batch classifier loss: 0.444751; batch adversarial loss: 0.582359\n",
      "epoch 5; iter: 0; batch classifier loss: 0.219901; batch adversarial loss: 0.553192\n",
      "epoch 6; iter: 0; batch classifier loss: 0.309823; batch adversarial loss: 0.577115\n",
      "epoch 7; iter: 0; batch classifier loss: 0.299188; batch adversarial loss: 0.527426\n",
      "epoch 8; iter: 0; batch classifier loss: 0.333968; batch adversarial loss: 0.501182\n",
      "epoch 9; iter: 0; batch classifier loss: 0.288561; batch adversarial loss: 0.512792\n",
      "epoch 10; iter: 0; batch classifier loss: 0.234897; batch adversarial loss: 0.507820\n",
      "epoch 11; iter: 0; batch classifier loss: 0.312829; batch adversarial loss: 0.575089\n",
      "epoch 12; iter: 0; batch classifier loss: 0.462108; batch adversarial loss: 0.542010\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528160; batch adversarial loss: 0.531360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.507086; batch adversarial loss: 0.537170\n",
      "epoch 15; iter: 0; batch classifier loss: 0.463489; batch adversarial loss: 0.508873\n",
      "epoch 16; iter: 0; batch classifier loss: 0.290716; batch adversarial loss: 0.501178\n",
      "epoch 17; iter: 0; batch classifier loss: 0.252039; batch adversarial loss: 0.443885\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214454; batch adversarial loss: 0.498816\n",
      "epoch 19; iter: 0; batch classifier loss: 0.282683; batch adversarial loss: 0.458939\n",
      "epoch 20; iter: 0; batch classifier loss: 0.207859; batch adversarial loss: 0.480532\n",
      "epoch 21; iter: 0; batch classifier loss: 0.260378; batch adversarial loss: 0.457526\n",
      "epoch 22; iter: 0; batch classifier loss: 0.279928; batch adversarial loss: 0.437895\n",
      "epoch 23; iter: 0; batch classifier loss: 0.280384; batch adversarial loss: 0.414406\n",
      "epoch 24; iter: 0; batch classifier loss: 0.275272; batch adversarial loss: 0.445408\n",
      "epoch 25; iter: 0; batch classifier loss: 0.218189; batch adversarial loss: 0.418948\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193782; batch adversarial loss: 0.454305\n",
      "epoch 27; iter: 0; batch classifier loss: 0.197399; batch adversarial loss: 0.454232\n",
      "epoch 28; iter: 0; batch classifier loss: 0.229782; batch adversarial loss: 0.443004\n",
      "epoch 29; iter: 0; batch classifier loss: 0.176387; batch adversarial loss: 0.480726\n",
      "epoch 30; iter: 0; batch classifier loss: 0.267459; batch adversarial loss: 0.486386\n",
      "epoch 31; iter: 0; batch classifier loss: 0.170043; batch adversarial loss: 0.428954\n",
      "epoch 32; iter: 0; batch classifier loss: 0.156531; batch adversarial loss: 0.511586\n",
      "epoch 33; iter: 0; batch classifier loss: 0.215651; batch adversarial loss: 0.438765\n",
      "epoch 34; iter: 0; batch classifier loss: 0.217637; batch adversarial loss: 0.430984\n",
      "epoch 35; iter: 0; batch classifier loss: 0.177956; batch adversarial loss: 0.533280\n",
      "epoch 36; iter: 0; batch classifier loss: 0.195017; batch adversarial loss: 0.571418\n",
      "epoch 37; iter: 0; batch classifier loss: 0.176278; batch adversarial loss: 0.435872\n",
      "epoch 38; iter: 0; batch classifier loss: 0.252111; batch adversarial loss: 0.371381\n",
      "epoch 39; iter: 0; batch classifier loss: 0.181131; batch adversarial loss: 0.480827\n",
      "epoch 40; iter: 0; batch classifier loss: 0.199711; batch adversarial loss: 0.450452\n",
      "epoch 41; iter: 0; batch classifier loss: 0.255274; batch adversarial loss: 0.450283\n",
      "epoch 42; iter: 0; batch classifier loss: 0.170860; batch adversarial loss: 0.578426\n",
      "epoch 43; iter: 0; batch classifier loss: 0.203980; batch adversarial loss: 0.590155\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105563; batch adversarial loss: 0.638275\n",
      "epoch 45; iter: 0; batch classifier loss: 0.215672; batch adversarial loss: 0.382757\n",
      "epoch 46; iter: 0; batch classifier loss: 0.166263; batch adversarial loss: 0.411467\n",
      "epoch 47; iter: 0; batch classifier loss: 0.186363; batch adversarial loss: 0.428436\n",
      "epoch 48; iter: 0; batch classifier loss: 0.173783; batch adversarial loss: 0.491650\n",
      "epoch 49; iter: 0; batch classifier loss: 0.196266; batch adversarial loss: 0.425743\n",
      "epoch 50; iter: 0; batch classifier loss: 0.140581; batch adversarial loss: 0.459026\n",
      "epoch 51; iter: 0; batch classifier loss: 0.162291; batch adversarial loss: 0.493263\n",
      "epoch 52; iter: 0; batch classifier loss: 0.152505; batch adversarial loss: 0.483444\n",
      "epoch 53; iter: 0; batch classifier loss: 0.186517; batch adversarial loss: 0.418742\n",
      "epoch 54; iter: 0; batch classifier loss: 0.155500; batch adversarial loss: 0.440597\n",
      "epoch 55; iter: 0; batch classifier loss: 0.175305; batch adversarial loss: 0.377001\n",
      "epoch 56; iter: 0; batch classifier loss: 0.137091; batch adversarial loss: 0.498247\n",
      "epoch 57; iter: 0; batch classifier loss: 0.206676; batch adversarial loss: 0.485640\n",
      "epoch 58; iter: 0; batch classifier loss: 0.171154; batch adversarial loss: 0.484474\n",
      "epoch 59; iter: 0; batch classifier loss: 0.156815; batch adversarial loss: 0.432356\n",
      "epoch 60; iter: 0; batch classifier loss: 0.152450; batch adversarial loss: 0.372582\n",
      "epoch 61; iter: 0; batch classifier loss: 0.229267; batch adversarial loss: 0.445389\n",
      "epoch 62; iter: 0; batch classifier loss: 0.141857; batch adversarial loss: 0.481941\n",
      "epoch 63; iter: 0; batch classifier loss: 0.196896; batch adversarial loss: 0.358507\n",
      "epoch 64; iter: 0; batch classifier loss: 0.225161; batch adversarial loss: 0.543678\n",
      "epoch 65; iter: 0; batch classifier loss: 0.184181; batch adversarial loss: 0.486195\n",
      "epoch 66; iter: 0; batch classifier loss: 0.215091; batch adversarial loss: 0.543412\n",
      "epoch 67; iter: 0; batch classifier loss: 0.208637; batch adversarial loss: 0.435143\n",
      "epoch 68; iter: 0; batch classifier loss: 0.211294; batch adversarial loss: 0.421442\n",
      "epoch 69; iter: 0; batch classifier loss: 0.261989; batch adversarial loss: 0.408166\n",
      "epoch 70; iter: 0; batch classifier loss: 0.185626; batch adversarial loss: 0.543959\n",
      "epoch 71; iter: 0; batch classifier loss: 0.281147; batch adversarial loss: 0.446682\n",
      "epoch 72; iter: 0; batch classifier loss: 0.197248; batch adversarial loss: 0.484915\n",
      "epoch 73; iter: 0; batch classifier loss: 0.201445; batch adversarial loss: 0.445758\n",
      "epoch 74; iter: 0; batch classifier loss: 0.180567; batch adversarial loss: 0.469704\n",
      "epoch 75; iter: 0; batch classifier loss: 0.205847; batch adversarial loss: 0.408155\n",
      "epoch 76; iter: 0; batch classifier loss: 0.180121; batch adversarial loss: 0.359746\n",
      "epoch 77; iter: 0; batch classifier loss: 0.227538; batch adversarial loss: 0.447155\n",
      "epoch 78; iter: 0; batch classifier loss: 0.206810; batch adversarial loss: 0.434976\n",
      "epoch 79; iter: 0; batch classifier loss: 0.233705; batch adversarial loss: 0.471694\n",
      "epoch 80; iter: 0; batch classifier loss: 0.205651; batch adversarial loss: 0.396731\n",
      "epoch 81; iter: 0; batch classifier loss: 0.223014; batch adversarial loss: 0.446167\n",
      "epoch 82; iter: 0; batch classifier loss: 0.173615; batch adversarial loss: 0.458465\n",
      "epoch 83; iter: 0; batch classifier loss: 0.132313; batch adversarial loss: 0.384263\n",
      "epoch 84; iter: 0; batch classifier loss: 0.251165; batch adversarial loss: 0.596229\n",
      "epoch 85; iter: 0; batch classifier loss: 0.219707; batch adversarial loss: 0.484196\n",
      "epoch 86; iter: 0; batch classifier loss: 0.185285; batch adversarial loss: 0.422140\n",
      "epoch 87; iter: 0; batch classifier loss: 0.193628; batch adversarial loss: 0.471549\n",
      "epoch 88; iter: 0; batch classifier loss: 0.193960; batch adversarial loss: 0.484003\n",
      "epoch 89; iter: 0; batch classifier loss: 0.163168; batch adversarial loss: 0.522140\n",
      "epoch 90; iter: 0; batch classifier loss: 0.211695; batch adversarial loss: 0.471736\n",
      "epoch 91; iter: 0; batch classifier loss: 0.176282; batch adversarial loss: 0.397432\n",
      "epoch 92; iter: 0; batch classifier loss: 0.177127; batch adversarial loss: 0.408971\n",
      "epoch 93; iter: 0; batch classifier loss: 0.167682; batch adversarial loss: 0.458706\n",
      "epoch 94; iter: 0; batch classifier loss: 0.135680; batch adversarial loss: 0.384351\n",
      "epoch 95; iter: 0; batch classifier loss: 0.143153; batch adversarial loss: 0.457982\n",
      "epoch 96; iter: 0; batch classifier loss: 0.169331; batch adversarial loss: 0.458142\n",
      "epoch 97; iter: 0; batch classifier loss: 0.165236; batch adversarial loss: 0.536495\n",
      "epoch 98; iter: 0; batch classifier loss: 0.154029; batch adversarial loss: 0.456992\n",
      "epoch 99; iter: 0; batch classifier loss: 0.200111; batch adversarial loss: 0.469992\n",
      "epoch 100; iter: 0; batch classifier loss: 0.185729; batch adversarial loss: 0.357757\n",
      "epoch 101; iter: 0; batch classifier loss: 0.215032; batch adversarial loss: 0.335530\n",
      "epoch 102; iter: 0; batch classifier loss: 0.202000; batch adversarial loss: 0.333910\n",
      "epoch 103; iter: 0; batch classifier loss: 0.152288; batch adversarial loss: 0.507658\n",
      "epoch 104; iter: 0; batch classifier loss: 0.119399; batch adversarial loss: 0.495843\n",
      "epoch 105; iter: 0; batch classifier loss: 0.147816; batch adversarial loss: 0.461487\n",
      "epoch 106; iter: 0; batch classifier loss: 0.165126; batch adversarial loss: 0.345438\n",
      "epoch 107; iter: 0; batch classifier loss: 0.174800; batch adversarial loss: 0.443729\n",
      "epoch 108; iter: 0; batch classifier loss: 0.109574; batch adversarial loss: 0.432168\n",
      "epoch 109; iter: 0; batch classifier loss: 0.134442; batch adversarial loss: 0.409000\n",
      "epoch 110; iter: 0; batch classifier loss: 0.078631; batch adversarial loss: 0.542140\n",
      "epoch 111; iter: 0; batch classifier loss: 0.093954; batch adversarial loss: 0.514486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.129929; batch adversarial loss: 0.583043\n",
      "epoch 113; iter: 0; batch classifier loss: 0.084366; batch adversarial loss: 0.455378\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037654; batch adversarial loss: 0.426200\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052638; batch adversarial loss: 0.449860\n",
      "epoch 116; iter: 0; batch classifier loss: 0.080444; batch adversarial loss: 0.479258\n",
      "epoch 117; iter: 0; batch classifier loss: 0.065963; batch adversarial loss: 0.461830\n",
      "epoch 118; iter: 0; batch classifier loss: 0.086895; batch adversarial loss: 0.447220\n",
      "epoch 119; iter: 0; batch classifier loss: 0.088231; batch adversarial loss: 0.521493\n",
      "epoch 120; iter: 0; batch classifier loss: 0.070402; batch adversarial loss: 0.464376\n",
      "epoch 121; iter: 0; batch classifier loss: 0.056253; batch adversarial loss: 0.503123\n",
      "epoch 122; iter: 0; batch classifier loss: 0.074167; batch adversarial loss: 0.480003\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031754; batch adversarial loss: 0.397707\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036006; batch adversarial loss: 0.404032\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045504; batch adversarial loss: 0.446431\n",
      "epoch 126; iter: 0; batch classifier loss: 0.058382; batch adversarial loss: 0.413361\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021407; batch adversarial loss: 0.524052\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023300; batch adversarial loss: 0.464209\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050853; batch adversarial loss: 0.406570\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035065; batch adversarial loss: 0.413039\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040881; batch adversarial loss: 0.451722\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027220; batch adversarial loss: 0.440605\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018622; batch adversarial loss: 0.512325\n",
      "epoch 134; iter: 0; batch classifier loss: 0.017727; batch adversarial loss: 0.436121\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020621; batch adversarial loss: 0.483071\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022000; batch adversarial loss: 0.519036\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025017; batch adversarial loss: 0.388728\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035373; batch adversarial loss: 0.499572\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036061; batch adversarial loss: 0.420054\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019946; batch adversarial loss: 0.454155\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030357; batch adversarial loss: 0.611061\n",
      "epoch 142; iter: 0; batch classifier loss: 0.038178; batch adversarial loss: 0.450321\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028145; batch adversarial loss: 0.491406\n",
      "epoch 144; iter: 0; batch classifier loss: 0.009671; batch adversarial loss: 0.430961\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029696; batch adversarial loss: 0.476351\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027035; batch adversarial loss: 0.436530\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019338; batch adversarial loss: 0.480881\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025460; batch adversarial loss: 0.486834\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024727; batch adversarial loss: 0.392984\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016917; batch adversarial loss: 0.503476\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022399; batch adversarial loss: 0.466198\n",
      "epoch 152; iter: 0; batch classifier loss: 0.012227; batch adversarial loss: 0.438887\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017646; batch adversarial loss: 0.409634\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020142; batch adversarial loss: 0.477881\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020663; batch adversarial loss: 0.499771\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036989; batch adversarial loss: 0.380776\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013552; batch adversarial loss: 0.527948\n",
      "epoch 158; iter: 0; batch classifier loss: 0.043340; batch adversarial loss: 0.376517\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017961; batch adversarial loss: 0.467643\n",
      "epoch 160; iter: 0; batch classifier loss: 0.047186; batch adversarial loss: 0.472539\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019578; batch adversarial loss: 0.538586\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036862; batch adversarial loss: 0.466631\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022099; batch adversarial loss: 0.530901\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018915; batch adversarial loss: 0.439024\n",
      "epoch 165; iter: 0; batch classifier loss: 0.042903; batch adversarial loss: 0.361305\n",
      "epoch 166; iter: 0; batch classifier loss: 0.009439; batch adversarial loss: 0.421443\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035860; batch adversarial loss: 0.446048\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015428; batch adversarial loss: 0.392254\n",
      "epoch 169; iter: 0; batch classifier loss: 0.005878; batch adversarial loss: 0.428887\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025758; batch adversarial loss: 0.473312\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015173; batch adversarial loss: 0.488800\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012079; batch adversarial loss: 0.481012\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021154; batch adversarial loss: 0.452134\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013015; batch adversarial loss: 0.471037\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038799; batch adversarial loss: 0.538689\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034944; batch adversarial loss: 0.546011\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037687; batch adversarial loss: 0.308849\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038093; batch adversarial loss: 0.540967\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029720; batch adversarial loss: 0.440471\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018388; batch adversarial loss: 0.453742\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021927; batch adversarial loss: 0.387021\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009562; batch adversarial loss: 0.497987\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011735; batch adversarial loss: 0.455220\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010825; batch adversarial loss: 0.399330\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019175; batch adversarial loss: 0.457079\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012867; batch adversarial loss: 0.378790\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009038; batch adversarial loss: 0.553252\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019325; batch adversarial loss: 0.529562\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035898; batch adversarial loss: 0.408411\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016237; batch adversarial loss: 0.481343\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012022; batch adversarial loss: 0.578183\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017359; batch adversarial loss: 0.435845\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020489; batch adversarial loss: 0.458876\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018513; batch adversarial loss: 0.409794\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017837; batch adversarial loss: 0.458892\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026965; batch adversarial loss: 0.408484\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032795; batch adversarial loss: 0.418476\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009400; batch adversarial loss: 0.495013\n",
      "epoch 199; iter: 0; batch classifier loss: 0.002908; batch adversarial loss: 0.542783\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728419; batch adversarial loss: 0.870859\n",
      "epoch 1; iter: 0; batch classifier loss: 0.581693; batch adversarial loss: 0.854838\n",
      "epoch 2; iter: 0; batch classifier loss: 0.649140; batch adversarial loss: 0.785667\n",
      "epoch 3; iter: 0; batch classifier loss: 0.605606; batch adversarial loss: 0.744571\n",
      "epoch 4; iter: 0; batch classifier loss: 0.736973; batch adversarial loss: 0.684753\n",
      "epoch 5; iter: 0; batch classifier loss: 0.713950; batch adversarial loss: 0.613686\n",
      "epoch 6; iter: 0; batch classifier loss: 0.420834; batch adversarial loss: 0.604757\n",
      "epoch 7; iter: 0; batch classifier loss: 0.326254; batch adversarial loss: 0.564995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.421436; batch adversarial loss: 0.557861\n",
      "epoch 9; iter: 0; batch classifier loss: 0.273622; batch adversarial loss: 0.529431\n",
      "epoch 10; iter: 0; batch classifier loss: 0.272902; batch adversarial loss: 0.514602\n",
      "epoch 11; iter: 0; batch classifier loss: 0.284988; batch adversarial loss: 0.489480\n",
      "epoch 12; iter: 0; batch classifier loss: 0.236275; batch adversarial loss: 0.486164\n",
      "epoch 13; iter: 0; batch classifier loss: 0.206632; batch adversarial loss: 0.489954\n",
      "epoch 14; iter: 0; batch classifier loss: 0.183696; batch adversarial loss: 0.482532\n",
      "epoch 15; iter: 0; batch classifier loss: 0.203315; batch adversarial loss: 0.537245\n",
      "epoch 16; iter: 0; batch classifier loss: 0.190266; batch adversarial loss: 0.526855\n",
      "epoch 17; iter: 0; batch classifier loss: 0.146030; batch adversarial loss: 0.468872\n",
      "epoch 18; iter: 0; batch classifier loss: 0.193746; batch adversarial loss: 0.540537\n",
      "epoch 19; iter: 0; batch classifier loss: 0.224964; batch adversarial loss: 0.503852\n",
      "epoch 20; iter: 0; batch classifier loss: 0.224557; batch adversarial loss: 0.496741\n",
      "epoch 21; iter: 0; batch classifier loss: 0.171877; batch adversarial loss: 0.453818\n",
      "epoch 22; iter: 0; batch classifier loss: 0.173099; batch adversarial loss: 0.502870\n",
      "epoch 23; iter: 0; batch classifier loss: 0.169975; batch adversarial loss: 0.526204\n",
      "epoch 24; iter: 0; batch classifier loss: 0.168095; batch adversarial loss: 0.459445\n",
      "epoch 25; iter: 0; batch classifier loss: 0.227860; batch adversarial loss: 0.496895\n",
      "epoch 26; iter: 0; batch classifier loss: 0.209785; batch adversarial loss: 0.399302\n",
      "epoch 27; iter: 0; batch classifier loss: 0.172718; batch adversarial loss: 0.443423\n",
      "epoch 28; iter: 0; batch classifier loss: 0.215250; batch adversarial loss: 0.520944\n",
      "epoch 29; iter: 0; batch classifier loss: 0.190853; batch adversarial loss: 0.431642\n",
      "epoch 30; iter: 0; batch classifier loss: 0.183008; batch adversarial loss: 0.456493\n",
      "epoch 31; iter: 0; batch classifier loss: 0.230039; batch adversarial loss: 0.493991\n",
      "epoch 32; iter: 0; batch classifier loss: 0.226115; batch adversarial loss: 0.438564\n",
      "epoch 33; iter: 0; batch classifier loss: 0.187192; batch adversarial loss: 0.470185\n",
      "epoch 34; iter: 0; batch classifier loss: 0.157917; batch adversarial loss: 0.524270\n",
      "epoch 35; iter: 0; batch classifier loss: 0.195896; batch adversarial loss: 0.473060\n",
      "epoch 36; iter: 0; batch classifier loss: 0.166955; batch adversarial loss: 0.437011\n",
      "epoch 37; iter: 0; batch classifier loss: 0.124360; batch adversarial loss: 0.450320\n",
      "epoch 38; iter: 0; batch classifier loss: 0.155095; batch adversarial loss: 0.447122\n",
      "epoch 39; iter: 0; batch classifier loss: 0.118070; batch adversarial loss: 0.531827\n",
      "epoch 40; iter: 0; batch classifier loss: 0.090366; batch adversarial loss: 0.483953\n",
      "epoch 41; iter: 0; batch classifier loss: 0.121423; batch adversarial loss: 0.492796\n",
      "epoch 42; iter: 0; batch classifier loss: 0.111301; batch adversarial loss: 0.397335\n",
      "epoch 43; iter: 0; batch classifier loss: 0.102978; batch adversarial loss: 0.467933\n",
      "epoch 44; iter: 0; batch classifier loss: 0.120894; batch adversarial loss: 0.390081\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108806; batch adversarial loss: 0.495881\n",
      "epoch 46; iter: 0; batch classifier loss: 0.080864; batch adversarial loss: 0.460781\n",
      "epoch 47; iter: 0; batch classifier loss: 0.097216; batch adversarial loss: 0.453757\n",
      "epoch 48; iter: 0; batch classifier loss: 0.132630; batch adversarial loss: 0.430980\n",
      "epoch 49; iter: 0; batch classifier loss: 0.104887; batch adversarial loss: 0.454601\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091364; batch adversarial loss: 0.406426\n",
      "epoch 51; iter: 0; batch classifier loss: 0.094953; batch adversarial loss: 0.458001\n",
      "epoch 52; iter: 0; batch classifier loss: 0.169960; batch adversarial loss: 0.439123\n",
      "epoch 53; iter: 0; batch classifier loss: 0.117415; batch adversarial loss: 0.379935\n",
      "epoch 54; iter: 0; batch classifier loss: 0.120586; batch adversarial loss: 0.475750\n",
      "epoch 55; iter: 0; batch classifier loss: 0.070726; batch adversarial loss: 0.428386\n",
      "epoch 56; iter: 0; batch classifier loss: 0.071882; batch adversarial loss: 0.357666\n",
      "epoch 57; iter: 0; batch classifier loss: 0.066919; batch adversarial loss: 0.497328\n",
      "epoch 58; iter: 0; batch classifier loss: 0.062161; batch adversarial loss: 0.424269\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102925; batch adversarial loss: 0.402707\n",
      "epoch 60; iter: 0; batch classifier loss: 0.088941; batch adversarial loss: 0.349186\n",
      "epoch 61; iter: 0; batch classifier loss: 0.100199; batch adversarial loss: 0.437313\n",
      "epoch 62; iter: 0; batch classifier loss: 0.086062; batch adversarial loss: 0.474377\n",
      "epoch 63; iter: 0; batch classifier loss: 0.052815; batch adversarial loss: 0.517350\n",
      "epoch 64; iter: 0; batch classifier loss: 0.086547; batch adversarial loss: 0.462966\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087266; batch adversarial loss: 0.403072\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085600; batch adversarial loss: 0.521744\n",
      "epoch 67; iter: 0; batch classifier loss: 0.123990; batch adversarial loss: 0.389181\n",
      "epoch 68; iter: 0; batch classifier loss: 0.046352; batch adversarial loss: 0.437930\n",
      "epoch 69; iter: 0; batch classifier loss: 0.050173; batch adversarial loss: 0.408411\n",
      "epoch 70; iter: 0; batch classifier loss: 0.123725; batch adversarial loss: 0.424626\n",
      "epoch 71; iter: 0; batch classifier loss: 0.102833; batch adversarial loss: 0.392035\n",
      "epoch 72; iter: 0; batch classifier loss: 0.076673; batch adversarial loss: 0.380565\n",
      "epoch 73; iter: 0; batch classifier loss: 0.125413; batch adversarial loss: 0.428584\n",
      "epoch 74; iter: 0; batch classifier loss: 0.113982; batch adversarial loss: 0.367477\n",
      "epoch 75; iter: 0; batch classifier loss: 0.068812; batch adversarial loss: 0.481012\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055190; batch adversarial loss: 0.527535\n",
      "epoch 77; iter: 0; batch classifier loss: 0.037950; batch adversarial loss: 0.523236\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062468; batch adversarial loss: 0.463902\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061604; batch adversarial loss: 0.461897\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061063; batch adversarial loss: 0.448517\n",
      "epoch 81; iter: 0; batch classifier loss: 0.036025; batch adversarial loss: 0.444208\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066356; batch adversarial loss: 0.466994\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062381; batch adversarial loss: 0.487991\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067383; batch adversarial loss: 0.469230\n",
      "epoch 85; iter: 0; batch classifier loss: 0.069964; batch adversarial loss: 0.484668\n",
      "epoch 86; iter: 0; batch classifier loss: 0.066142; batch adversarial loss: 0.460931\n",
      "epoch 87; iter: 0; batch classifier loss: 0.080527; batch adversarial loss: 0.460474\n",
      "epoch 88; iter: 0; batch classifier loss: 0.077360; batch adversarial loss: 0.469491\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058801; batch adversarial loss: 0.471076\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051270; batch adversarial loss: 0.439598\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075937; batch adversarial loss: 0.462813\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074515; batch adversarial loss: 0.436165\n",
      "epoch 93; iter: 0; batch classifier loss: 0.080435; batch adversarial loss: 0.420085\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061143; batch adversarial loss: 0.506852\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081249; batch adversarial loss: 0.451174\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070696; batch adversarial loss: 0.467386\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042042; batch adversarial loss: 0.405276\n",
      "epoch 98; iter: 0; batch classifier loss: 0.031236; batch adversarial loss: 0.462089\n",
      "epoch 99; iter: 0; batch classifier loss: 0.016679; batch adversarial loss: 0.523088\n",
      "epoch 100; iter: 0; batch classifier loss: 0.083077; batch adversarial loss: 0.456767\n",
      "epoch 101; iter: 0; batch classifier loss: 0.032103; batch adversarial loss: 0.403907\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049458; batch adversarial loss: 0.507022\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048179; batch adversarial loss: 0.389451\n",
      "epoch 104; iter: 0; batch classifier loss: 0.086129; batch adversarial loss: 0.442119\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045263; batch adversarial loss: 0.519159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.029585; batch adversarial loss: 0.473247\n",
      "epoch 107; iter: 0; batch classifier loss: 0.068840; batch adversarial loss: 0.470628\n",
      "epoch 108; iter: 0; batch classifier loss: 0.029781; batch adversarial loss: 0.349390\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032529; batch adversarial loss: 0.456620\n",
      "epoch 110; iter: 0; batch classifier loss: 0.018255; batch adversarial loss: 0.523902\n",
      "epoch 111; iter: 0; batch classifier loss: 0.063184; batch adversarial loss: 0.411037\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034063; batch adversarial loss: 0.436521\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043130; batch adversarial loss: 0.485063\n",
      "epoch 114; iter: 0; batch classifier loss: 0.021280; batch adversarial loss: 0.445955\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052019; batch adversarial loss: 0.363259\n",
      "epoch 116; iter: 0; batch classifier loss: 0.031941; batch adversarial loss: 0.389654\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041679; batch adversarial loss: 0.368051\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037215; batch adversarial loss: 0.405985\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023341; batch adversarial loss: 0.436019\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044583; batch adversarial loss: 0.443418\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037314; batch adversarial loss: 0.427146\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051108; batch adversarial loss: 0.306168\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029091; batch adversarial loss: 0.504870\n",
      "epoch 124; iter: 0; batch classifier loss: 0.062409; batch adversarial loss: 0.360107\n",
      "epoch 125; iter: 0; batch classifier loss: 0.021894; batch adversarial loss: 0.481081\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028232; batch adversarial loss: 0.411996\n",
      "epoch 127; iter: 0; batch classifier loss: 0.054985; batch adversarial loss: 0.360096\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043302; batch adversarial loss: 0.501419\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029321; batch adversarial loss: 0.431108\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029539; batch adversarial loss: 0.389854\n",
      "epoch 131; iter: 0; batch classifier loss: 0.076743; batch adversarial loss: 0.452422\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020915; batch adversarial loss: 0.540478\n",
      "epoch 133; iter: 0; batch classifier loss: 0.011325; batch adversarial loss: 0.443618\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048342; batch adversarial loss: 0.428414\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038688; batch adversarial loss: 0.504550\n",
      "epoch 136; iter: 0; batch classifier loss: 0.010136; batch adversarial loss: 0.449767\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037199; batch adversarial loss: 0.485018\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039257; batch adversarial loss: 0.448024\n",
      "epoch 139; iter: 0; batch classifier loss: 0.027815; batch adversarial loss: 0.448885\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037522; batch adversarial loss: 0.464732\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032711; batch adversarial loss: 0.468222\n",
      "epoch 142; iter: 0; batch classifier loss: 0.056059; batch adversarial loss: 0.335444\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020206; batch adversarial loss: 0.432830\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024005; batch adversarial loss: 0.466912\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018890; batch adversarial loss: 0.373857\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044566; batch adversarial loss: 0.454979\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025461; batch adversarial loss: 0.362896\n",
      "epoch 148; iter: 0; batch classifier loss: 0.009393; batch adversarial loss: 0.491861\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015015; batch adversarial loss: 0.480834\n",
      "epoch 150; iter: 0; batch classifier loss: 0.068853; batch adversarial loss: 0.519153\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038520; batch adversarial loss: 0.391648\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030367; batch adversarial loss: 0.466695\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022781; batch adversarial loss: 0.434485\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035889; batch adversarial loss: 0.410139\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029371; batch adversarial loss: 0.337818\n",
      "epoch 156; iter: 0; batch classifier loss: 0.052765; batch adversarial loss: 0.346951\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016382; batch adversarial loss: 0.450737\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017365; batch adversarial loss: 0.633955\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022585; batch adversarial loss: 0.432760\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034075; batch adversarial loss: 0.416093\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038174; batch adversarial loss: 0.445008\n",
      "epoch 162; iter: 0; batch classifier loss: 0.040092; batch adversarial loss: 0.350801\n",
      "epoch 163; iter: 0; batch classifier loss: 0.056151; batch adversarial loss: 0.459024\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019408; batch adversarial loss: 0.464733\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038021; batch adversarial loss: 0.502520\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030302; batch adversarial loss: 0.471016\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021869; batch adversarial loss: 0.472824\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016757; batch adversarial loss: 0.431122\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035724; batch adversarial loss: 0.430037\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023919; batch adversarial loss: 0.451082\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023117; batch adversarial loss: 0.432577\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021891; batch adversarial loss: 0.447861\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013040; batch adversarial loss: 0.374996\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012832; batch adversarial loss: 0.387843\n",
      "epoch 175; iter: 0; batch classifier loss: 0.089571; batch adversarial loss: 0.578447\n",
      "epoch 176; iter: 0; batch classifier loss: 0.047583; batch adversarial loss: 0.447763\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034146; batch adversarial loss: 0.416652\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040430; batch adversarial loss: 0.440630\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021091; batch adversarial loss: 0.520210\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017124; batch adversarial loss: 0.403770\n",
      "epoch 181; iter: 0; batch classifier loss: 0.051869; batch adversarial loss: 0.451416\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011749; batch adversarial loss: 0.393233\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033515; batch adversarial loss: 0.417277\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022655; batch adversarial loss: 0.408922\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017028; batch adversarial loss: 0.355828\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023580; batch adversarial loss: 0.448879\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018871; batch adversarial loss: 0.339359\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009258; batch adversarial loss: 0.500959\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020651; batch adversarial loss: 0.433616\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016865; batch adversarial loss: 0.539036\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017307; batch adversarial loss: 0.420842\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021173; batch adversarial loss: 0.446973\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029391; batch adversarial loss: 0.402783\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032826; batch adversarial loss: 0.488841\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009630; batch adversarial loss: 0.521087\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011416; batch adversarial loss: 0.477670\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014379; batch adversarial loss: 0.428984\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029725; batch adversarial loss: 0.346081\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005282; batch adversarial loss: 0.421367\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710075; batch adversarial loss: 0.678310\n",
      "epoch 1; iter: 0; batch classifier loss: 0.473773; batch adversarial loss: 0.655140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.418032; batch adversarial loss: 0.600039\n",
      "epoch 3; iter: 0; batch classifier loss: 0.396293; batch adversarial loss: 0.592196\n",
      "epoch 4; iter: 0; batch classifier loss: 0.443288; batch adversarial loss: 0.566925\n",
      "epoch 5; iter: 0; batch classifier loss: 0.377099; batch adversarial loss: 0.527222\n",
      "epoch 6; iter: 0; batch classifier loss: 0.270906; batch adversarial loss: 0.505384\n",
      "epoch 7; iter: 0; batch classifier loss: 0.275322; batch adversarial loss: 0.542442\n",
      "epoch 8; iter: 0; batch classifier loss: 0.238413; batch adversarial loss: 0.486483\n",
      "epoch 9; iter: 0; batch classifier loss: 0.254855; batch adversarial loss: 0.555651\n",
      "epoch 10; iter: 0; batch classifier loss: 0.273428; batch adversarial loss: 0.491898\n",
      "epoch 11; iter: 0; batch classifier loss: 0.255734; batch adversarial loss: 0.473283\n",
      "epoch 12; iter: 0; batch classifier loss: 0.236732; batch adversarial loss: 0.465065\n",
      "epoch 13; iter: 0; batch classifier loss: 0.179737; batch adversarial loss: 0.462492\n",
      "epoch 14; iter: 0; batch classifier loss: 0.198927; batch adversarial loss: 0.441713\n",
      "epoch 15; iter: 0; batch classifier loss: 0.161154; batch adversarial loss: 0.475516\n",
      "epoch 16; iter: 0; batch classifier loss: 0.132918; batch adversarial loss: 0.477719\n",
      "epoch 17; iter: 0; batch classifier loss: 0.119019; batch adversarial loss: 0.477223\n",
      "epoch 18; iter: 0; batch classifier loss: 0.140854; batch adversarial loss: 0.472149\n",
      "epoch 19; iter: 0; batch classifier loss: 0.131734; batch adversarial loss: 0.424896\n",
      "epoch 20; iter: 0; batch classifier loss: 0.159606; batch adversarial loss: 0.462439\n",
      "epoch 21; iter: 0; batch classifier loss: 0.168678; batch adversarial loss: 0.537377\n",
      "epoch 22; iter: 0; batch classifier loss: 0.126826; batch adversarial loss: 0.426929\n",
      "epoch 23; iter: 0; batch classifier loss: 0.148837; batch adversarial loss: 0.500156\n",
      "epoch 24; iter: 0; batch classifier loss: 0.117445; batch adversarial loss: 0.476485\n",
      "epoch 25; iter: 0; batch classifier loss: 0.220376; batch adversarial loss: 0.506275\n",
      "epoch 26; iter: 0; batch classifier loss: 0.224155; batch adversarial loss: 0.544906\n",
      "epoch 27; iter: 0; batch classifier loss: 0.158215; batch adversarial loss: 0.627915\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185710; batch adversarial loss: 0.624278\n",
      "epoch 29; iter: 0; batch classifier loss: 0.208018; batch adversarial loss: 0.502086\n",
      "epoch 30; iter: 0; batch classifier loss: 0.188377; batch adversarial loss: 0.539718\n",
      "epoch 31; iter: 0; batch classifier loss: 0.141005; batch adversarial loss: 0.389961\n",
      "epoch 32; iter: 0; batch classifier loss: 0.134175; batch adversarial loss: 0.458883\n",
      "epoch 33; iter: 0; batch classifier loss: 0.183242; batch adversarial loss: 0.482642\n",
      "epoch 34; iter: 0; batch classifier loss: 0.162238; batch adversarial loss: 0.393420\n",
      "epoch 35; iter: 0; batch classifier loss: 0.152224; batch adversarial loss: 0.513324\n",
      "epoch 36; iter: 0; batch classifier loss: 0.209271; batch adversarial loss: 0.496420\n",
      "epoch 37; iter: 0; batch classifier loss: 0.262164; batch adversarial loss: 0.449636\n",
      "epoch 38; iter: 0; batch classifier loss: 0.157023; batch adversarial loss: 0.470558\n",
      "epoch 39; iter: 0; batch classifier loss: 0.061384; batch adversarial loss: 0.445845\n",
      "epoch 40; iter: 0; batch classifier loss: 0.111369; batch adversarial loss: 0.517717\n",
      "epoch 41; iter: 0; batch classifier loss: 0.091354; batch adversarial loss: 0.542160\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117852; batch adversarial loss: 0.481424\n",
      "epoch 43; iter: 0; batch classifier loss: 0.062610; batch adversarial loss: 0.513759\n",
      "epoch 44; iter: 0; batch classifier loss: 0.053024; batch adversarial loss: 0.422372\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091843; batch adversarial loss: 0.391830\n",
      "epoch 46; iter: 0; batch classifier loss: 0.083771; batch adversarial loss: 0.335711\n",
      "epoch 47; iter: 0; batch classifier loss: 0.062005; batch adversarial loss: 0.495036\n",
      "epoch 48; iter: 0; batch classifier loss: 0.062560; batch adversarial loss: 0.410100\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099538; batch adversarial loss: 0.552683\n",
      "epoch 50; iter: 0; batch classifier loss: 0.050592; batch adversarial loss: 0.406850\n",
      "epoch 51; iter: 0; batch classifier loss: 0.063885; batch adversarial loss: 0.506843\n",
      "epoch 52; iter: 0; batch classifier loss: 0.077758; batch adversarial loss: 0.483844\n",
      "epoch 53; iter: 0; batch classifier loss: 0.060284; batch adversarial loss: 0.515600\n",
      "epoch 54; iter: 0; batch classifier loss: 0.071813; batch adversarial loss: 0.381153\n",
      "epoch 55; iter: 0; batch classifier loss: 0.113668; batch adversarial loss: 0.327794\n",
      "epoch 56; iter: 0; batch classifier loss: 0.096702; batch adversarial loss: 0.448824\n",
      "epoch 57; iter: 0; batch classifier loss: 0.060128; batch adversarial loss: 0.477938\n",
      "epoch 58; iter: 0; batch classifier loss: 0.057041; batch adversarial loss: 0.477051\n",
      "epoch 59; iter: 0; batch classifier loss: 0.054796; batch adversarial loss: 0.413694\n",
      "epoch 60; iter: 0; batch classifier loss: 0.058133; batch adversarial loss: 0.415679\n",
      "epoch 61; iter: 0; batch classifier loss: 0.046588; batch adversarial loss: 0.497497\n",
      "epoch 62; iter: 0; batch classifier loss: 0.103176; batch adversarial loss: 0.484840\n",
      "epoch 63; iter: 0; batch classifier loss: 0.064665; batch adversarial loss: 0.453152\n",
      "epoch 64; iter: 0; batch classifier loss: 0.060553; batch adversarial loss: 0.489832\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082808; batch adversarial loss: 0.452952\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062240; batch adversarial loss: 0.384212\n",
      "epoch 67; iter: 0; batch classifier loss: 0.060832; batch adversarial loss: 0.477205\n",
      "epoch 68; iter: 0; batch classifier loss: 0.119456; batch adversarial loss: 0.364643\n",
      "epoch 69; iter: 0; batch classifier loss: 0.043168; batch adversarial loss: 0.440803\n",
      "epoch 70; iter: 0; batch classifier loss: 0.106827; batch adversarial loss: 0.467398\n",
      "epoch 71; iter: 0; batch classifier loss: 0.114490; batch adversarial loss: 0.351300\n",
      "epoch 72; iter: 0; batch classifier loss: 0.111394; batch adversarial loss: 0.409056\n",
      "epoch 73; iter: 0; batch classifier loss: 0.113411; batch adversarial loss: 0.364339\n",
      "epoch 74; iter: 0; batch classifier loss: 0.047039; batch adversarial loss: 0.397915\n",
      "epoch 75; iter: 0; batch classifier loss: 0.083846; batch adversarial loss: 0.445932\n",
      "epoch 76; iter: 0; batch classifier loss: 0.052598; batch adversarial loss: 0.447789\n",
      "epoch 77; iter: 0; batch classifier loss: 0.047785; batch adversarial loss: 0.431228\n",
      "epoch 78; iter: 0; batch classifier loss: 0.068141; batch adversarial loss: 0.431206\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080778; batch adversarial loss: 0.409094\n",
      "epoch 80; iter: 0; batch classifier loss: 0.046575; batch adversarial loss: 0.422744\n",
      "epoch 81; iter: 0; batch classifier loss: 0.037897; batch adversarial loss: 0.383030\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083489; batch adversarial loss: 0.472820\n",
      "epoch 83; iter: 0; batch classifier loss: 0.099340; batch adversarial loss: 0.342615\n",
      "epoch 84; iter: 0; batch classifier loss: 0.059680; batch adversarial loss: 0.520502\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051328; batch adversarial loss: 0.402728\n",
      "epoch 86; iter: 0; batch classifier loss: 0.066164; batch adversarial loss: 0.349845\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056482; batch adversarial loss: 0.493387\n",
      "epoch 88; iter: 0; batch classifier loss: 0.052515; batch adversarial loss: 0.332688\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042987; batch adversarial loss: 0.406559\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056622; batch adversarial loss: 0.442670\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073452; batch adversarial loss: 0.329422\n",
      "epoch 92; iter: 0; batch classifier loss: 0.045943; batch adversarial loss: 0.426366\n",
      "epoch 93; iter: 0; batch classifier loss: 0.049926; batch adversarial loss: 0.386518\n",
      "epoch 94; iter: 0; batch classifier loss: 0.057143; batch adversarial loss: 0.419426\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079677; batch adversarial loss: 0.472732\n",
      "epoch 96; iter: 0; batch classifier loss: 0.073716; batch adversarial loss: 0.420229\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042498; batch adversarial loss: 0.499169\n",
      "epoch 98; iter: 0; batch classifier loss: 0.041670; batch adversarial loss: 0.517724\n",
      "epoch 99; iter: 0; batch classifier loss: 0.085868; batch adversarial loss: 0.425715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.044487; batch adversarial loss: 0.360427\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039020; batch adversarial loss: 0.408258\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038693; batch adversarial loss: 0.426155\n",
      "epoch 103; iter: 0; batch classifier loss: 0.087701; batch adversarial loss: 0.508474\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044350; batch adversarial loss: 0.440533\n",
      "epoch 105; iter: 0; batch classifier loss: 0.063423; batch adversarial loss: 0.475482\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042285; batch adversarial loss: 0.480919\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040036; batch adversarial loss: 0.474033\n",
      "epoch 108; iter: 0; batch classifier loss: 0.098605; batch adversarial loss: 0.469525\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057302; batch adversarial loss: 0.378627\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043834; batch adversarial loss: 0.427933\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042783; batch adversarial loss: 0.383501\n",
      "epoch 112; iter: 0; batch classifier loss: 0.081902; batch adversarial loss: 0.431814\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055875; batch adversarial loss: 0.474922\n",
      "epoch 114; iter: 0; batch classifier loss: 0.017174; batch adversarial loss: 0.474604\n",
      "epoch 115; iter: 0; batch classifier loss: 0.061880; batch adversarial loss: 0.521074\n",
      "epoch 116; iter: 0; batch classifier loss: 0.020120; batch adversarial loss: 0.402180\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023022; batch adversarial loss: 0.434654\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025258; batch adversarial loss: 0.457853\n",
      "epoch 119; iter: 0; batch classifier loss: 0.060704; batch adversarial loss: 0.390673\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049061; batch adversarial loss: 0.440894\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039386; batch adversarial loss: 0.477861\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030441; batch adversarial loss: 0.466826\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027251; batch adversarial loss: 0.490687\n",
      "epoch 124; iter: 0; batch classifier loss: 0.058858; batch adversarial loss: 0.465754\n",
      "epoch 125; iter: 0; batch classifier loss: 0.063793; batch adversarial loss: 0.500949\n",
      "epoch 126; iter: 0; batch classifier loss: 0.068541; batch adversarial loss: 0.470633\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028332; batch adversarial loss: 0.524736\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027831; batch adversarial loss: 0.603101\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036558; batch adversarial loss: 0.485974\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059484; batch adversarial loss: 0.497211\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021024; batch adversarial loss: 0.404556\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040803; batch adversarial loss: 0.460373\n",
      "epoch 133; iter: 0; batch classifier loss: 0.061458; batch adversarial loss: 0.405324\n",
      "epoch 134; iter: 0; batch classifier loss: 0.022403; batch adversarial loss: 0.518156\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036998; batch adversarial loss: 0.421076\n",
      "epoch 136; iter: 0; batch classifier loss: 0.015665; batch adversarial loss: 0.476663\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024082; batch adversarial loss: 0.524842\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021550; batch adversarial loss: 0.449314\n",
      "epoch 139; iter: 0; batch classifier loss: 0.052572; batch adversarial loss: 0.439579\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050070; batch adversarial loss: 0.425228\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025757; batch adversarial loss: 0.448555\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016572; batch adversarial loss: 0.479516\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019612; batch adversarial loss: 0.414587\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049548; batch adversarial loss: 0.468290\n",
      "epoch 145; iter: 0; batch classifier loss: 0.067489; batch adversarial loss: 0.449487\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038621; batch adversarial loss: 0.497643\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039091; batch adversarial loss: 0.421515\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030349; batch adversarial loss: 0.409136\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016118; batch adversarial loss: 0.417812\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042790; batch adversarial loss: 0.362966\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026455; batch adversarial loss: 0.445558\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011776; batch adversarial loss: 0.473533\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018089; batch adversarial loss: 0.375602\n",
      "epoch 154; iter: 0; batch classifier loss: 0.047997; batch adversarial loss: 0.454830\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009118; batch adversarial loss: 0.464524\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023235; batch adversarial loss: 0.380776\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014485; batch adversarial loss: 0.450853\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018369; batch adversarial loss: 0.459265\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021671; batch adversarial loss: 0.466920\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024097; batch adversarial loss: 0.462454\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017423; batch adversarial loss: 0.352922\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020977; batch adversarial loss: 0.441271\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011452; batch adversarial loss: 0.473525\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011405; batch adversarial loss: 0.438322\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015421; batch adversarial loss: 0.364727\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010307; batch adversarial loss: 0.437115\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023973; batch adversarial loss: 0.501339\n",
      "epoch 168; iter: 0; batch classifier loss: 0.049279; batch adversarial loss: 0.378531\n",
      "epoch 169; iter: 0; batch classifier loss: 0.054298; batch adversarial loss: 0.445778\n",
      "epoch 170; iter: 0; batch classifier loss: 0.004466; batch adversarial loss: 0.480822\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017283; batch adversarial loss: 0.439837\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008995; batch adversarial loss: 0.484870\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031044; batch adversarial loss: 0.421066\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019800; batch adversarial loss: 0.546952\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028254; batch adversarial loss: 0.388968\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028664; batch adversarial loss: 0.368071\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034470; batch adversarial loss: 0.487744\n",
      "epoch 178; iter: 0; batch classifier loss: 0.049038; batch adversarial loss: 0.416684\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020557; batch adversarial loss: 0.392894\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023448; batch adversarial loss: 0.454391\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020770; batch adversarial loss: 0.439694\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020685; batch adversarial loss: 0.428411\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025990; batch adversarial loss: 0.421578\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006736; batch adversarial loss: 0.574760\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007961; batch adversarial loss: 0.402629\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017823; batch adversarial loss: 0.452246\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031473; batch adversarial loss: 0.381552\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033651; batch adversarial loss: 0.477613\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016103; batch adversarial loss: 0.378346\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019071; batch adversarial loss: 0.493801\n",
      "epoch 191; iter: 0; batch classifier loss: 0.035942; batch adversarial loss: 0.401549\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030448; batch adversarial loss: 0.456123\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015369; batch adversarial loss: 0.488859\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011508; batch adversarial loss: 0.481516\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028528; batch adversarial loss: 0.487279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.013340; batch adversarial loss: 0.417178\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028791; batch adversarial loss: 0.493824\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011123; batch adversarial loss: 0.511669\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026359; batch adversarial loss: 0.427875\n",
      "epoch 0; iter: 0; batch classifier loss: 0.721650; batch adversarial loss: 0.862041\n",
      "epoch 1; iter: 0; batch classifier loss: 0.447561; batch adversarial loss: 0.763286\n",
      "epoch 2; iter: 0; batch classifier loss: 0.332054; batch adversarial loss: 0.781026\n",
      "epoch 3; iter: 0; batch classifier loss: 0.379362; batch adversarial loss: 0.714505\n",
      "epoch 4; iter: 0; batch classifier loss: 0.303083; batch adversarial loss: 0.698874\n",
      "epoch 5; iter: 0; batch classifier loss: 0.280814; batch adversarial loss: 0.643658\n",
      "epoch 6; iter: 0; batch classifier loss: 0.378407; batch adversarial loss: 0.633090\n",
      "epoch 7; iter: 0; batch classifier loss: 0.330956; batch adversarial loss: 0.605330\n",
      "epoch 8; iter: 0; batch classifier loss: 0.316199; batch adversarial loss: 0.553907\n",
      "epoch 9; iter: 0; batch classifier loss: 0.309829; batch adversarial loss: 0.563510\n",
      "epoch 10; iter: 0; batch classifier loss: 0.331880; batch adversarial loss: 0.509066\n",
      "epoch 11; iter: 0; batch classifier loss: 0.346215; batch adversarial loss: 0.455752\n",
      "epoch 12; iter: 0; batch classifier loss: 0.313223; batch adversarial loss: 0.489834\n",
      "epoch 13; iter: 0; batch classifier loss: 0.336029; batch adversarial loss: 0.502015\n",
      "epoch 14; iter: 0; batch classifier loss: 0.273009; batch adversarial loss: 0.459983\n",
      "epoch 15; iter: 0; batch classifier loss: 0.177499; batch adversarial loss: 0.469112\n",
      "epoch 16; iter: 0; batch classifier loss: 0.225949; batch adversarial loss: 0.483662\n",
      "epoch 17; iter: 0; batch classifier loss: 0.170481; batch adversarial loss: 0.456427\n",
      "epoch 18; iter: 0; batch classifier loss: 0.189214; batch adversarial loss: 0.378434\n",
      "epoch 19; iter: 0; batch classifier loss: 0.271527; batch adversarial loss: 0.398996\n",
      "epoch 20; iter: 0; batch classifier loss: 0.214942; batch adversarial loss: 0.420761\n",
      "epoch 21; iter: 0; batch classifier loss: 0.263755; batch adversarial loss: 0.397873\n",
      "epoch 22; iter: 0; batch classifier loss: 0.161695; batch adversarial loss: 0.374483\n",
      "epoch 23; iter: 0; batch classifier loss: 0.226970; batch adversarial loss: 0.447435\n",
      "epoch 24; iter: 0; batch classifier loss: 0.206913; batch adversarial loss: 0.428828\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177684; batch adversarial loss: 0.417487\n",
      "epoch 26; iter: 0; batch classifier loss: 0.184610; batch adversarial loss: 0.448691\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162098; batch adversarial loss: 0.410442\n",
      "epoch 28; iter: 0; batch classifier loss: 0.162941; batch adversarial loss: 0.445911\n",
      "epoch 29; iter: 0; batch classifier loss: 0.185353; batch adversarial loss: 0.369868\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144760; batch adversarial loss: 0.370468\n",
      "epoch 31; iter: 0; batch classifier loss: 0.185962; batch adversarial loss: 0.382952\n",
      "epoch 32; iter: 0; batch classifier loss: 0.142145; batch adversarial loss: 0.415342\n",
      "epoch 33; iter: 0; batch classifier loss: 0.136164; batch adversarial loss: 0.377758\n",
      "epoch 34; iter: 0; batch classifier loss: 0.140242; batch adversarial loss: 0.361644\n",
      "epoch 35; iter: 0; batch classifier loss: 0.198896; batch adversarial loss: 0.367031\n",
      "epoch 36; iter: 0; batch classifier loss: 0.162027; batch adversarial loss: 0.369852\n",
      "epoch 37; iter: 0; batch classifier loss: 0.156135; batch adversarial loss: 0.450909\n",
      "epoch 38; iter: 0; batch classifier loss: 0.116874; batch adversarial loss: 0.420043\n",
      "epoch 39; iter: 0; batch classifier loss: 0.164198; batch adversarial loss: 0.466962\n",
      "epoch 40; iter: 0; batch classifier loss: 0.115323; batch adversarial loss: 0.422813\n",
      "epoch 41; iter: 0; batch classifier loss: 0.096189; batch adversarial loss: 0.395009\n",
      "epoch 42; iter: 0; batch classifier loss: 0.130350; batch adversarial loss: 0.490573\n",
      "epoch 43; iter: 0; batch classifier loss: 0.112725; batch adversarial loss: 0.361445\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127073; batch adversarial loss: 0.413942\n",
      "epoch 45; iter: 0; batch classifier loss: 0.107863; batch adversarial loss: 0.413108\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126265; batch adversarial loss: 0.512716\n",
      "epoch 47; iter: 0; batch classifier loss: 0.118567; batch adversarial loss: 0.450957\n",
      "epoch 48; iter: 0; batch classifier loss: 0.089765; batch adversarial loss: 0.451448\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107062; batch adversarial loss: 0.391878\n",
      "epoch 50; iter: 0; batch classifier loss: 0.139166; batch adversarial loss: 0.390746\n",
      "epoch 51; iter: 0; batch classifier loss: 0.112505; batch adversarial loss: 0.399654\n",
      "epoch 52; iter: 0; batch classifier loss: 0.055217; batch adversarial loss: 0.364595\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098624; batch adversarial loss: 0.351144\n",
      "epoch 54; iter: 0; batch classifier loss: 0.084761; batch adversarial loss: 0.423775\n",
      "epoch 55; iter: 0; batch classifier loss: 0.094206; batch adversarial loss: 0.430592\n",
      "epoch 56; iter: 0; batch classifier loss: 0.109544; batch adversarial loss: 0.453381\n",
      "epoch 57; iter: 0; batch classifier loss: 0.089972; batch adversarial loss: 0.509400\n",
      "epoch 58; iter: 0; batch classifier loss: 0.100394; batch adversarial loss: 0.384889\n",
      "epoch 59; iter: 0; batch classifier loss: 0.086490; batch adversarial loss: 0.458055\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095749; batch adversarial loss: 0.340676\n",
      "epoch 61; iter: 0; batch classifier loss: 0.091277; batch adversarial loss: 0.398045\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082264; batch adversarial loss: 0.529117\n",
      "epoch 63; iter: 0; batch classifier loss: 0.068604; batch adversarial loss: 0.400645\n",
      "epoch 64; iter: 0; batch classifier loss: 0.077787; batch adversarial loss: 0.338235\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088718; batch adversarial loss: 0.405353\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066895; batch adversarial loss: 0.525466\n",
      "epoch 67; iter: 0; batch classifier loss: 0.086526; batch adversarial loss: 0.382084\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078574; batch adversarial loss: 0.371396\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094207; batch adversarial loss: 0.545258\n",
      "epoch 70; iter: 0; batch classifier loss: 0.085752; batch adversarial loss: 0.522789\n",
      "epoch 71; iter: 0; batch classifier loss: 0.044801; batch adversarial loss: 0.434977\n",
      "epoch 72; iter: 0; batch classifier loss: 0.063925; batch adversarial loss: 0.451731\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065467; batch adversarial loss: 0.496272\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066659; batch adversarial loss: 0.415666\n",
      "epoch 75; iter: 0; batch classifier loss: 0.043136; batch adversarial loss: 0.572932\n",
      "epoch 76; iter: 0; batch classifier loss: 0.051770; batch adversarial loss: 0.478516\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055802; batch adversarial loss: 0.294718\n",
      "epoch 78; iter: 0; batch classifier loss: 0.058454; batch adversarial loss: 0.439853\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085725; batch adversarial loss: 0.375555\n",
      "epoch 80; iter: 0; batch classifier loss: 0.038507; batch adversarial loss: 0.462965\n",
      "epoch 81; iter: 0; batch classifier loss: 0.089450; batch adversarial loss: 0.380035\n",
      "epoch 82; iter: 0; batch classifier loss: 0.040649; batch adversarial loss: 0.459919\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059314; batch adversarial loss: 0.419467\n",
      "epoch 84; iter: 0; batch classifier loss: 0.069414; batch adversarial loss: 0.466236\n",
      "epoch 85; iter: 0; batch classifier loss: 0.040886; batch adversarial loss: 0.364482\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058615; batch adversarial loss: 0.425134\n",
      "epoch 87; iter: 0; batch classifier loss: 0.037671; batch adversarial loss: 0.440491\n",
      "epoch 88; iter: 0; batch classifier loss: 0.036393; batch adversarial loss: 0.491076\n",
      "epoch 89; iter: 0; batch classifier loss: 0.028130; batch adversarial loss: 0.513235\n",
      "epoch 90; iter: 0; batch classifier loss: 0.032177; batch adversarial loss: 0.440410\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052360; batch adversarial loss: 0.476812\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065914; batch adversarial loss: 0.462561\n",
      "epoch 93; iter: 0; batch classifier loss: 0.037864; batch adversarial loss: 0.415483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.031556; batch adversarial loss: 0.441781\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056625; batch adversarial loss: 0.459546\n",
      "epoch 96; iter: 0; batch classifier loss: 0.029315; batch adversarial loss: 0.525866\n",
      "epoch 97; iter: 0; batch classifier loss: 0.026971; batch adversarial loss: 0.417397\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045026; batch adversarial loss: 0.532068\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063775; batch adversarial loss: 0.499218\n",
      "epoch 100; iter: 0; batch classifier loss: 0.084696; batch adversarial loss: 0.524821\n",
      "epoch 101; iter: 0; batch classifier loss: 0.074506; batch adversarial loss: 0.699927\n",
      "epoch 102; iter: 0; batch classifier loss: 0.122272; batch adversarial loss: 0.558501\n",
      "epoch 103; iter: 0; batch classifier loss: 0.099398; batch adversarial loss: 0.516069\n",
      "epoch 104; iter: 0; batch classifier loss: 0.126053; batch adversarial loss: 0.565921\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084243; batch adversarial loss: 0.560023\n",
      "epoch 106; iter: 0; batch classifier loss: 0.094619; batch adversarial loss: 0.499298\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050898; batch adversarial loss: 0.564538\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060725; batch adversarial loss: 0.423821\n",
      "epoch 109; iter: 0; batch classifier loss: 0.151670; batch adversarial loss: 0.630361\n",
      "epoch 110; iter: 0; batch classifier loss: 0.115099; batch adversarial loss: 0.571254\n",
      "epoch 111; iter: 0; batch classifier loss: 0.122533; batch adversarial loss: 0.562622\n",
      "epoch 112; iter: 0; batch classifier loss: 0.109794; batch adversarial loss: 0.527979\n",
      "epoch 113; iter: 0; batch classifier loss: 0.133505; batch adversarial loss: 0.544753\n",
      "epoch 114; iter: 0; batch classifier loss: 0.080319; batch adversarial loss: 0.428460\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041963; batch adversarial loss: 0.484023\n",
      "epoch 116; iter: 0; batch classifier loss: 0.116382; batch adversarial loss: 0.490459\n",
      "epoch 117; iter: 0; batch classifier loss: 0.079705; batch adversarial loss: 0.401433\n",
      "epoch 118; iter: 0; batch classifier loss: 0.105288; batch adversarial loss: 0.616327\n",
      "epoch 119; iter: 0; batch classifier loss: 0.099346; batch adversarial loss: 0.496687\n",
      "epoch 120; iter: 0; batch classifier loss: 0.157309; batch adversarial loss: 0.506815\n",
      "epoch 121; iter: 0; batch classifier loss: 0.126469; batch adversarial loss: 0.477039\n",
      "epoch 122; iter: 0; batch classifier loss: 0.095427; batch adversarial loss: 0.530195\n",
      "epoch 123; iter: 0; batch classifier loss: 0.074486; batch adversarial loss: 0.495672\n",
      "epoch 124; iter: 0; batch classifier loss: 0.086510; batch adversarial loss: 0.414311\n",
      "epoch 125; iter: 0; batch classifier loss: 0.100966; batch adversarial loss: 0.443434\n",
      "epoch 126; iter: 0; batch classifier loss: 0.110275; batch adversarial loss: 0.429379\n",
      "epoch 127; iter: 0; batch classifier loss: 0.084011; batch adversarial loss: 0.422956\n",
      "epoch 128; iter: 0; batch classifier loss: 0.144595; batch adversarial loss: 0.456718\n",
      "epoch 129; iter: 0; batch classifier loss: 0.179521; batch adversarial loss: 0.468501\n",
      "epoch 130; iter: 0; batch classifier loss: 0.087362; batch adversarial loss: 0.498481\n",
      "epoch 131; iter: 0; batch classifier loss: 0.095496; batch adversarial loss: 0.525857\n",
      "epoch 132; iter: 0; batch classifier loss: 0.106161; batch adversarial loss: 0.482480\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052620; batch adversarial loss: 0.389442\n",
      "epoch 134; iter: 0; batch classifier loss: 0.124691; batch adversarial loss: 0.464142\n",
      "epoch 135; iter: 0; batch classifier loss: 0.128052; batch adversarial loss: 0.460021\n",
      "epoch 136; iter: 0; batch classifier loss: 0.112753; batch adversarial loss: 0.474599\n",
      "epoch 137; iter: 0; batch classifier loss: 0.067196; batch adversarial loss: 0.446804\n",
      "epoch 138; iter: 0; batch classifier loss: 0.057648; batch adversarial loss: 0.482960\n",
      "epoch 139; iter: 0; batch classifier loss: 0.059907; batch adversarial loss: 0.513164\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032001; batch adversarial loss: 0.452288\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030239; batch adversarial loss: 0.463778\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048867; batch adversarial loss: 0.522544\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035826; batch adversarial loss: 0.395824\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019877; batch adversarial loss: 0.380005\n",
      "epoch 145; iter: 0; batch classifier loss: 0.073526; batch adversarial loss: 0.401910\n",
      "epoch 146; iter: 0; batch classifier loss: 0.064334; batch adversarial loss: 0.484421\n",
      "epoch 147; iter: 0; batch classifier loss: 0.059383; batch adversarial loss: 0.507574\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029385; batch adversarial loss: 0.557720\n",
      "epoch 149; iter: 0; batch classifier loss: 0.051074; batch adversarial loss: 0.468873\n",
      "epoch 150; iter: 0; batch classifier loss: 0.087725; batch adversarial loss: 0.470129\n",
      "epoch 151; iter: 0; batch classifier loss: 0.055233; batch adversarial loss: 0.479579\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032088; batch adversarial loss: 0.550370\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038977; batch adversarial loss: 0.411450\n",
      "epoch 154; iter: 0; batch classifier loss: 0.071832; batch adversarial loss: 0.458244\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040876; batch adversarial loss: 0.403881\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032595; batch adversarial loss: 0.498942\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034459; batch adversarial loss: 0.567063\n",
      "epoch 158; iter: 0; batch classifier loss: 0.061142; batch adversarial loss: 0.454395\n",
      "epoch 159; iter: 0; batch classifier loss: 0.044231; batch adversarial loss: 0.461905\n",
      "epoch 160; iter: 0; batch classifier loss: 0.039002; batch adversarial loss: 0.411186\n",
      "epoch 161; iter: 0; batch classifier loss: 0.089633; batch adversarial loss: 0.530326\n",
      "epoch 162; iter: 0; batch classifier loss: 0.056621; batch adversarial loss: 0.369499\n",
      "epoch 163; iter: 0; batch classifier loss: 0.046728; batch adversarial loss: 0.516570\n",
      "epoch 164; iter: 0; batch classifier loss: 0.067843; batch adversarial loss: 0.411997\n",
      "epoch 165; iter: 0; batch classifier loss: 0.083372; batch adversarial loss: 0.413143\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033107; batch adversarial loss: 0.432810\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028303; batch adversarial loss: 0.415252\n",
      "epoch 168; iter: 0; batch classifier loss: 0.049389; batch adversarial loss: 0.402119\n",
      "epoch 169; iter: 0; batch classifier loss: 0.041796; batch adversarial loss: 0.494948\n",
      "epoch 170; iter: 0; batch classifier loss: 0.049211; batch adversarial loss: 0.358190\n",
      "epoch 171; iter: 0; batch classifier loss: 0.097793; batch adversarial loss: 0.448470\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022311; batch adversarial loss: 0.432829\n",
      "epoch 173; iter: 0; batch classifier loss: 0.069958; batch adversarial loss: 0.453920\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030506; batch adversarial loss: 0.611063\n",
      "epoch 175; iter: 0; batch classifier loss: 0.052211; batch adversarial loss: 0.366040\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029046; batch adversarial loss: 0.468665\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026779; batch adversarial loss: 0.395360\n",
      "epoch 178; iter: 0; batch classifier loss: 0.054485; batch adversarial loss: 0.428293\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036660; batch adversarial loss: 0.457654\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024444; batch adversarial loss: 0.448120\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025695; batch adversarial loss: 0.373475\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038157; batch adversarial loss: 0.507144\n",
      "epoch 183; iter: 0; batch classifier loss: 0.078545; batch adversarial loss: 0.435934\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031801; batch adversarial loss: 0.406663\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026968; batch adversarial loss: 0.374532\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021790; batch adversarial loss: 0.587656\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023907; batch adversarial loss: 0.499631\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023073; batch adversarial loss: 0.528538\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033147; batch adversarial loss: 0.498580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.073784; batch adversarial loss: 0.340113\n",
      "epoch 191; iter: 0; batch classifier loss: 0.057832; batch adversarial loss: 0.472925\n",
      "epoch 192; iter: 0; batch classifier loss: 0.042261; batch adversarial loss: 0.416984\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029712; batch adversarial loss: 0.444216\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035010; batch adversarial loss: 0.479255\n",
      "epoch 195; iter: 0; batch classifier loss: 0.075705; batch adversarial loss: 0.419007\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032597; batch adversarial loss: 0.552150\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034947; batch adversarial loss: 0.501151\n",
      "epoch 198; iter: 0; batch classifier loss: 0.062790; batch adversarial loss: 0.482849\n",
      "epoch 199; iter: 0; batch classifier loss: 0.048065; batch adversarial loss: 0.489190\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722177; batch adversarial loss: 0.583389\n",
      "epoch 1; iter: 0; batch classifier loss: 0.448827; batch adversarial loss: 0.596293\n",
      "epoch 2; iter: 0; batch classifier loss: 0.434533; batch adversarial loss: 0.591580\n",
      "epoch 3; iter: 0; batch classifier loss: 0.362436; batch adversarial loss: 0.560578\n",
      "epoch 4; iter: 0; batch classifier loss: 0.343682; batch adversarial loss: 0.601696\n",
      "epoch 5; iter: 0; batch classifier loss: 0.346511; batch adversarial loss: 0.514522\n",
      "epoch 6; iter: 0; batch classifier loss: 0.371667; batch adversarial loss: 0.561007\n",
      "epoch 7; iter: 0; batch classifier loss: 0.270499; batch adversarial loss: 0.523055\n",
      "epoch 8; iter: 0; batch classifier loss: 0.261602; batch adversarial loss: 0.501200\n",
      "epoch 9; iter: 0; batch classifier loss: 0.226929; batch adversarial loss: 0.556688\n",
      "epoch 10; iter: 0; batch classifier loss: 0.251144; batch adversarial loss: 0.480727\n",
      "epoch 11; iter: 0; batch classifier loss: 0.239527; batch adversarial loss: 0.576910\n",
      "epoch 12; iter: 0; batch classifier loss: 0.329699; batch adversarial loss: 0.476745\n",
      "epoch 13; iter: 0; batch classifier loss: 0.299502; batch adversarial loss: 0.501531\n",
      "epoch 14; iter: 0; batch classifier loss: 0.215357; batch adversarial loss: 0.483793\n",
      "epoch 15; iter: 0; batch classifier loss: 0.241204; batch adversarial loss: 0.491857\n",
      "epoch 16; iter: 0; batch classifier loss: 0.275548; batch adversarial loss: 0.540090\n",
      "epoch 17; iter: 0; batch classifier loss: 0.257189; batch adversarial loss: 0.439483\n",
      "epoch 18; iter: 0; batch classifier loss: 0.352922; batch adversarial loss: 0.506990\n",
      "epoch 19; iter: 0; batch classifier loss: 0.313149; batch adversarial loss: 0.479501\n",
      "epoch 20; iter: 0; batch classifier loss: 0.482221; batch adversarial loss: 0.464342\n",
      "epoch 21; iter: 0; batch classifier loss: 0.447225; batch adversarial loss: 0.497819\n",
      "epoch 22; iter: 0; batch classifier loss: 0.298446; batch adversarial loss: 0.536418\n",
      "epoch 23; iter: 0; batch classifier loss: 0.200473; batch adversarial loss: 0.434362\n",
      "epoch 24; iter: 0; batch classifier loss: 0.170966; batch adversarial loss: 0.411161\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177663; batch adversarial loss: 0.436303\n",
      "epoch 26; iter: 0; batch classifier loss: 0.126518; batch adversarial loss: 0.484961\n",
      "epoch 27; iter: 0; batch classifier loss: 0.159462; batch adversarial loss: 0.416591\n",
      "epoch 28; iter: 0; batch classifier loss: 0.182282; batch adversarial loss: 0.395953\n",
      "epoch 29; iter: 0; batch classifier loss: 0.138048; batch adversarial loss: 0.545125\n",
      "epoch 30; iter: 0; batch classifier loss: 0.155665; batch adversarial loss: 0.422572\n",
      "epoch 31; iter: 0; batch classifier loss: 0.202944; batch adversarial loss: 0.433150\n",
      "epoch 32; iter: 0; batch classifier loss: 0.152282; batch adversarial loss: 0.426836\n",
      "epoch 33; iter: 0; batch classifier loss: 0.085164; batch adversarial loss: 0.524477\n",
      "epoch 34; iter: 0; batch classifier loss: 0.172835; batch adversarial loss: 0.378174\n",
      "epoch 35; iter: 0; batch classifier loss: 0.123602; batch adversarial loss: 0.426106\n",
      "epoch 36; iter: 0; batch classifier loss: 0.189845; batch adversarial loss: 0.445834\n",
      "epoch 37; iter: 0; batch classifier loss: 0.096116; batch adversarial loss: 0.481199\n",
      "epoch 38; iter: 0; batch classifier loss: 0.167677; batch adversarial loss: 0.464836\n",
      "epoch 39; iter: 0; batch classifier loss: 0.168994; batch adversarial loss: 0.518304\n",
      "epoch 40; iter: 0; batch classifier loss: 0.080186; batch adversarial loss: 0.443835\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098321; batch adversarial loss: 0.441062\n",
      "epoch 42; iter: 0; batch classifier loss: 0.095607; batch adversarial loss: 0.441058\n",
      "epoch 43; iter: 0; batch classifier loss: 0.133273; batch adversarial loss: 0.473145\n",
      "epoch 44; iter: 0; batch classifier loss: 0.137584; batch adversarial loss: 0.466432\n",
      "epoch 45; iter: 0; batch classifier loss: 0.116747; batch adversarial loss: 0.372801\n",
      "epoch 46; iter: 0; batch classifier loss: 0.141450; batch adversarial loss: 0.455185\n",
      "epoch 47; iter: 0; batch classifier loss: 0.098328; batch adversarial loss: 0.464045\n",
      "epoch 48; iter: 0; batch classifier loss: 0.118363; batch adversarial loss: 0.471490\n",
      "epoch 49; iter: 0; batch classifier loss: 0.106970; batch adversarial loss: 0.489616\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091663; batch adversarial loss: 0.525150\n",
      "epoch 51; iter: 0; batch classifier loss: 0.159382; batch adversarial loss: 0.479884\n",
      "epoch 52; iter: 0; batch classifier loss: 0.109540; batch adversarial loss: 0.473675\n",
      "epoch 53; iter: 0; batch classifier loss: 0.137294; batch adversarial loss: 0.469097\n",
      "epoch 54; iter: 0; batch classifier loss: 0.107324; batch adversarial loss: 0.457414\n",
      "epoch 55; iter: 0; batch classifier loss: 0.116161; batch adversarial loss: 0.456253\n",
      "epoch 56; iter: 0; batch classifier loss: 0.089347; batch adversarial loss: 0.401376\n",
      "epoch 57; iter: 0; batch classifier loss: 0.128193; batch adversarial loss: 0.401000\n",
      "epoch 58; iter: 0; batch classifier loss: 0.178957; batch adversarial loss: 0.364678\n",
      "epoch 59; iter: 0; batch classifier loss: 0.114762; batch adversarial loss: 0.408343\n",
      "epoch 60; iter: 0; batch classifier loss: 0.146647; batch adversarial loss: 0.425861\n",
      "epoch 61; iter: 0; batch classifier loss: 0.136399; batch adversarial loss: 0.513581\n",
      "epoch 62; iter: 0; batch classifier loss: 0.100444; batch adversarial loss: 0.413748\n",
      "epoch 63; iter: 0; batch classifier loss: 0.163116; batch adversarial loss: 0.378804\n",
      "epoch 64; iter: 0; batch classifier loss: 0.128553; batch adversarial loss: 0.480394\n",
      "epoch 65; iter: 0; batch classifier loss: 0.114256; batch adversarial loss: 0.439298\n",
      "epoch 66; iter: 0; batch classifier loss: 0.128530; batch adversarial loss: 0.447747\n",
      "epoch 67; iter: 0; batch classifier loss: 0.084291; batch adversarial loss: 0.439437\n",
      "epoch 68; iter: 0; batch classifier loss: 0.084808; batch adversarial loss: 0.456736\n",
      "epoch 69; iter: 0; batch classifier loss: 0.099018; batch adversarial loss: 0.359212\n",
      "epoch 70; iter: 0; batch classifier loss: 0.128445; batch adversarial loss: 0.452954\n",
      "epoch 71; iter: 0; batch classifier loss: 0.074701; batch adversarial loss: 0.471880\n",
      "epoch 72; iter: 0; batch classifier loss: 0.169848; batch adversarial loss: 0.395405\n",
      "epoch 73; iter: 0; batch classifier loss: 0.124854; batch adversarial loss: 0.478018\n",
      "epoch 74; iter: 0; batch classifier loss: 0.116080; batch adversarial loss: 0.517386\n",
      "epoch 75; iter: 0; batch classifier loss: 0.117433; batch adversarial loss: 0.415801\n",
      "epoch 76; iter: 0; batch classifier loss: 0.123648; batch adversarial loss: 0.497788\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069070; batch adversarial loss: 0.499020\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090300; batch adversarial loss: 0.466617\n",
      "epoch 79; iter: 0; batch classifier loss: 0.128037; batch adversarial loss: 0.474598\n",
      "epoch 80; iter: 0; batch classifier loss: 0.145121; batch adversarial loss: 0.508171\n",
      "epoch 81; iter: 0; batch classifier loss: 0.100115; batch adversarial loss: 0.395371\n",
      "epoch 82; iter: 0; batch classifier loss: 0.039845; batch adversarial loss: 0.499372\n",
      "epoch 83; iter: 0; batch classifier loss: 0.171690; batch adversarial loss: 0.349930\n",
      "epoch 84; iter: 0; batch classifier loss: 0.104926; batch adversarial loss: 0.464861\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077562; batch adversarial loss: 0.367421\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076226; batch adversarial loss: 0.391866\n",
      "epoch 87; iter: 0; batch classifier loss: 0.104466; batch adversarial loss: 0.460667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.145277; batch adversarial loss: 0.436604\n",
      "epoch 89; iter: 0; batch classifier loss: 0.108083; batch adversarial loss: 0.411177\n",
      "epoch 90; iter: 0; batch classifier loss: 0.117212; batch adversarial loss: 0.382137\n",
      "epoch 91; iter: 0; batch classifier loss: 0.112134; batch adversarial loss: 0.377249\n",
      "epoch 92; iter: 0; batch classifier loss: 0.160928; batch adversarial loss: 0.420924\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051755; batch adversarial loss: 0.394356\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039189; batch adversarial loss: 0.425590\n",
      "epoch 95; iter: 0; batch classifier loss: 0.132451; batch adversarial loss: 0.423637\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045358; batch adversarial loss: 0.422104\n",
      "epoch 97; iter: 0; batch classifier loss: 0.070460; batch adversarial loss: 0.344950\n",
      "epoch 98; iter: 0; batch classifier loss: 0.087379; batch adversarial loss: 0.385388\n",
      "epoch 99; iter: 0; batch classifier loss: 0.072925; batch adversarial loss: 0.404200\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074758; batch adversarial loss: 0.415225\n",
      "epoch 101; iter: 0; batch classifier loss: 0.028109; batch adversarial loss: 0.425248\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041043; batch adversarial loss: 0.343348\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076941; batch adversarial loss: 0.452274\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063579; batch adversarial loss: 0.428578\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047666; batch adversarial loss: 0.528074\n",
      "epoch 106; iter: 0; batch classifier loss: 0.056061; batch adversarial loss: 0.488476\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066269; batch adversarial loss: 0.371052\n",
      "epoch 108; iter: 0; batch classifier loss: 0.082357; batch adversarial loss: 0.438110\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026430; batch adversarial loss: 0.386334\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048679; batch adversarial loss: 0.371384\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041294; batch adversarial loss: 0.427703\n",
      "epoch 112; iter: 0; batch classifier loss: 0.074290; batch adversarial loss: 0.495035\n",
      "epoch 113; iter: 0; batch classifier loss: 0.016775; batch adversarial loss: 0.472609\n",
      "epoch 114; iter: 0; batch classifier loss: 0.075132; batch adversarial loss: 0.395188\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029419; batch adversarial loss: 0.488119\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032984; batch adversarial loss: 0.531387\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039252; batch adversarial loss: 0.459583\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047192; batch adversarial loss: 0.432976\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026670; batch adversarial loss: 0.497813\n",
      "epoch 120; iter: 0; batch classifier loss: 0.070884; batch adversarial loss: 0.421606\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042527; batch adversarial loss: 0.404527\n",
      "epoch 122; iter: 0; batch classifier loss: 0.078905; batch adversarial loss: 0.515356\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041569; batch adversarial loss: 0.359254\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048285; batch adversarial loss: 0.515815\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043732; batch adversarial loss: 0.492364\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035295; batch adversarial loss: 0.447245\n",
      "epoch 127; iter: 0; batch classifier loss: 0.052880; batch adversarial loss: 0.444241\n",
      "epoch 128; iter: 0; batch classifier loss: 0.016977; batch adversarial loss: 0.437400\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027472; batch adversarial loss: 0.361213\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044711; batch adversarial loss: 0.401816\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036877; batch adversarial loss: 0.393388\n",
      "epoch 132; iter: 0; batch classifier loss: 0.066679; batch adversarial loss: 0.422727\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046399; batch adversarial loss: 0.486579\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024425; batch adversarial loss: 0.529050\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033082; batch adversarial loss: 0.367231\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030839; batch adversarial loss: 0.528076\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018536; batch adversarial loss: 0.350762\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020277; batch adversarial loss: 0.360040\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010999; batch adversarial loss: 0.459351\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022050; batch adversarial loss: 0.461404\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020348; batch adversarial loss: 0.466272\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022932; batch adversarial loss: 0.495761\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031810; batch adversarial loss: 0.447806\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034769; batch adversarial loss: 0.487061\n",
      "epoch 145; iter: 0; batch classifier loss: 0.072297; batch adversarial loss: 0.432039\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013172; batch adversarial loss: 0.432988\n",
      "epoch 147; iter: 0; batch classifier loss: 0.058672; batch adversarial loss: 0.365520\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022364; batch adversarial loss: 0.473552\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028052; batch adversarial loss: 0.491890\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017234; batch adversarial loss: 0.418892\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014043; batch adversarial loss: 0.535736\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036498; batch adversarial loss: 0.427045\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032820; batch adversarial loss: 0.396157\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035720; batch adversarial loss: 0.409786\n",
      "epoch 155; iter: 0; batch classifier loss: 0.055459; batch adversarial loss: 0.404835\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034117; batch adversarial loss: 0.344669\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041326; batch adversarial loss: 0.386397\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037466; batch adversarial loss: 0.505982\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013782; batch adversarial loss: 0.434672\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023549; batch adversarial loss: 0.458399\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019726; batch adversarial loss: 0.400933\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010473; batch adversarial loss: 0.436315\n",
      "epoch 163; iter: 0; batch classifier loss: 0.048126; batch adversarial loss: 0.491469\n",
      "epoch 164; iter: 0; batch classifier loss: 0.075885; batch adversarial loss: 0.439853\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017788; batch adversarial loss: 0.446421\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010905; batch adversarial loss: 0.463168\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010628; batch adversarial loss: 0.465900\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013585; batch adversarial loss: 0.455970\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018848; batch adversarial loss: 0.463864\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022521; batch adversarial loss: 0.423222\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016726; batch adversarial loss: 0.497988\n",
      "epoch 172; iter: 0; batch classifier loss: 0.049575; batch adversarial loss: 0.406684\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016524; batch adversarial loss: 0.421364\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028594; batch adversarial loss: 0.372828\n",
      "epoch 175; iter: 0; batch classifier loss: 0.047189; batch adversarial loss: 0.366282\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029588; batch adversarial loss: 0.463570\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018502; batch adversarial loss: 0.442162\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028211; batch adversarial loss: 0.524444\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016147; batch adversarial loss: 0.595967\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013628; batch adversarial loss: 0.424032\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019214; batch adversarial loss: 0.385619\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042912; batch adversarial loss: 0.519138\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034879; batch adversarial loss: 0.508863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.008315; batch adversarial loss: 0.568436\n",
      "epoch 185; iter: 0; batch classifier loss: 0.005076; batch adversarial loss: 0.440680\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030504; batch adversarial loss: 0.447901\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034118; batch adversarial loss: 0.470874\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025957; batch adversarial loss: 0.468431\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011170; batch adversarial loss: 0.450902\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007448; batch adversarial loss: 0.498775\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009130; batch adversarial loss: 0.453599\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032327; batch adversarial loss: 0.386529\n",
      "epoch 193; iter: 0; batch classifier loss: 0.033953; batch adversarial loss: 0.439331\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008234; batch adversarial loss: 0.451404\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012665; batch adversarial loss: 0.501407\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012899; batch adversarial loss: 0.447571\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022726; batch adversarial loss: 0.413863\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016522; batch adversarial loss: 0.399591\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014385; batch adversarial loss: 0.480636\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703005; batch adversarial loss: 0.925838\n",
      "epoch 1; iter: 0; batch classifier loss: 0.555644; batch adversarial loss: 1.045876\n",
      "epoch 2; iter: 0; batch classifier loss: 0.725012; batch adversarial loss: 1.062718\n",
      "epoch 3; iter: 0; batch classifier loss: 0.917876; batch adversarial loss: 1.005987\n",
      "epoch 4; iter: 0; batch classifier loss: 0.843980; batch adversarial loss: 0.896163\n",
      "epoch 5; iter: 0; batch classifier loss: 0.811284; batch adversarial loss: 0.804740\n",
      "epoch 6; iter: 0; batch classifier loss: 0.954182; batch adversarial loss: 0.745129\n",
      "epoch 7; iter: 0; batch classifier loss: 0.940386; batch adversarial loss: 0.687383\n",
      "epoch 8; iter: 0; batch classifier loss: 0.870425; batch adversarial loss: 0.628454\n",
      "epoch 9; iter: 0; batch classifier loss: 0.947755; batch adversarial loss: 0.567544\n",
      "epoch 10; iter: 0; batch classifier loss: 0.547518; batch adversarial loss: 0.535125\n",
      "epoch 11; iter: 0; batch classifier loss: 0.333868; batch adversarial loss: 0.565096\n",
      "epoch 12; iter: 0; batch classifier loss: 0.361073; batch adversarial loss: 0.529281\n",
      "epoch 13; iter: 0; batch classifier loss: 0.328391; batch adversarial loss: 0.525436\n",
      "epoch 14; iter: 0; batch classifier loss: 0.347927; batch adversarial loss: 0.512955\n",
      "epoch 15; iter: 0; batch classifier loss: 0.297834; batch adversarial loss: 0.513972\n",
      "epoch 16; iter: 0; batch classifier loss: 0.294575; batch adversarial loss: 0.512661\n",
      "epoch 17; iter: 0; batch classifier loss: 0.313748; batch adversarial loss: 0.451754\n",
      "epoch 18; iter: 0; batch classifier loss: 0.322224; batch adversarial loss: 0.491108\n",
      "epoch 19; iter: 0; batch classifier loss: 0.413304; batch adversarial loss: 0.479553\n",
      "epoch 20; iter: 0; batch classifier loss: 0.324747; batch adversarial loss: 0.544390\n",
      "epoch 21; iter: 0; batch classifier loss: 0.358281; batch adversarial loss: 0.471319\n",
      "epoch 22; iter: 0; batch classifier loss: 0.390458; batch adversarial loss: 0.479343\n",
      "epoch 23; iter: 0; batch classifier loss: 0.415726; batch adversarial loss: 0.501751\n",
      "epoch 24; iter: 0; batch classifier loss: 0.330779; batch adversarial loss: 0.506723\n",
      "epoch 25; iter: 0; batch classifier loss: 0.277655; batch adversarial loss: 0.490651\n",
      "epoch 26; iter: 0; batch classifier loss: 0.290128; batch adversarial loss: 0.440468\n",
      "epoch 27; iter: 0; batch classifier loss: 0.350962; batch adversarial loss: 0.475185\n",
      "epoch 28; iter: 0; batch classifier loss: 0.354687; batch adversarial loss: 0.459039\n",
      "epoch 29; iter: 0; batch classifier loss: 0.320914; batch adversarial loss: 0.454837\n",
      "epoch 30; iter: 0; batch classifier loss: 0.317429; batch adversarial loss: 0.398421\n",
      "epoch 31; iter: 0; batch classifier loss: 0.252911; batch adversarial loss: 0.497553\n",
      "epoch 32; iter: 0; batch classifier loss: 0.270452; batch adversarial loss: 0.495587\n",
      "epoch 33; iter: 0; batch classifier loss: 0.306987; batch adversarial loss: 0.500918\n",
      "epoch 34; iter: 0; batch classifier loss: 0.268239; batch adversarial loss: 0.452751\n",
      "epoch 35; iter: 0; batch classifier loss: 0.226085; batch adversarial loss: 0.477661\n",
      "epoch 36; iter: 0; batch classifier loss: 0.233692; batch adversarial loss: 0.418142\n",
      "epoch 37; iter: 0; batch classifier loss: 0.191593; batch adversarial loss: 0.506053\n",
      "epoch 38; iter: 0; batch classifier loss: 0.306992; batch adversarial loss: 0.386129\n",
      "epoch 39; iter: 0; batch classifier loss: 0.239778; batch adversarial loss: 0.394821\n",
      "epoch 40; iter: 0; batch classifier loss: 0.175489; batch adversarial loss: 0.470602\n",
      "epoch 41; iter: 0; batch classifier loss: 0.217231; batch adversarial loss: 0.463643\n",
      "epoch 42; iter: 0; batch classifier loss: 0.216037; batch adversarial loss: 0.404342\n",
      "epoch 43; iter: 0; batch classifier loss: 0.239022; batch adversarial loss: 0.403379\n",
      "epoch 44; iter: 0; batch classifier loss: 0.250424; batch adversarial loss: 0.412297\n",
      "epoch 45; iter: 0; batch classifier loss: 0.216107; batch adversarial loss: 0.412590\n",
      "epoch 46; iter: 0; batch classifier loss: 0.211386; batch adversarial loss: 0.462789\n",
      "epoch 47; iter: 0; batch classifier loss: 0.230213; batch adversarial loss: 0.447923\n",
      "epoch 48; iter: 0; batch classifier loss: 0.205142; batch adversarial loss: 0.489380\n",
      "epoch 49; iter: 0; batch classifier loss: 0.229515; batch adversarial loss: 0.327657\n",
      "epoch 50; iter: 0; batch classifier loss: 0.236970; batch adversarial loss: 0.397083\n",
      "epoch 51; iter: 0; batch classifier loss: 0.208206; batch adversarial loss: 0.516597\n",
      "epoch 52; iter: 0; batch classifier loss: 0.181915; batch adversarial loss: 0.387513\n",
      "epoch 53; iter: 0; batch classifier loss: 0.164141; batch adversarial loss: 0.485120\n",
      "epoch 54; iter: 0; batch classifier loss: 0.214854; batch adversarial loss: 0.370491\n",
      "epoch 55; iter: 0; batch classifier loss: 0.198851; batch adversarial loss: 0.460162\n",
      "epoch 56; iter: 0; batch classifier loss: 0.204690; batch adversarial loss: 0.396870\n",
      "epoch 57; iter: 0; batch classifier loss: 0.206047; batch adversarial loss: 0.411912\n",
      "epoch 58; iter: 0; batch classifier loss: 0.227896; batch adversarial loss: 0.397499\n",
      "epoch 59; iter: 0; batch classifier loss: 0.174644; batch adversarial loss: 0.420373\n",
      "epoch 60; iter: 0; batch classifier loss: 0.180663; batch adversarial loss: 0.383654\n",
      "epoch 61; iter: 0; batch classifier loss: 0.126912; batch adversarial loss: 0.432416\n",
      "epoch 62; iter: 0; batch classifier loss: 0.127806; batch adversarial loss: 0.456839\n",
      "epoch 63; iter: 0; batch classifier loss: 0.221007; batch adversarial loss: 0.448173\n",
      "epoch 64; iter: 0; batch classifier loss: 0.196516; batch adversarial loss: 0.559708\n",
      "epoch 65; iter: 0; batch classifier loss: 0.188868; batch adversarial loss: 0.582938\n",
      "epoch 66; iter: 0; batch classifier loss: 0.234030; batch adversarial loss: 0.421085\n",
      "epoch 67; iter: 0; batch classifier loss: 0.168172; batch adversarial loss: 0.408203\n",
      "epoch 68; iter: 0; batch classifier loss: 0.166745; batch adversarial loss: 0.496610\n",
      "epoch 69; iter: 0; batch classifier loss: 0.147174; batch adversarial loss: 0.448019\n",
      "epoch 70; iter: 0; batch classifier loss: 0.196358; batch adversarial loss: 0.470376\n",
      "epoch 71; iter: 0; batch classifier loss: 0.183040; batch adversarial loss: 0.494860\n",
      "epoch 72; iter: 0; batch classifier loss: 0.136065; batch adversarial loss: 0.458820\n",
      "epoch 73; iter: 0; batch classifier loss: 0.209212; batch adversarial loss: 0.358317\n",
      "epoch 74; iter: 0; batch classifier loss: 0.236303; batch adversarial loss: 0.385582\n",
      "epoch 75; iter: 0; batch classifier loss: 0.193792; batch adversarial loss: 0.410109\n",
      "epoch 76; iter: 0; batch classifier loss: 0.160874; batch adversarial loss: 0.445536\n",
      "epoch 77; iter: 0; batch classifier loss: 0.183584; batch adversarial loss: 0.359280\n",
      "epoch 78; iter: 0; batch classifier loss: 0.112443; batch adversarial loss: 0.397167\n",
      "epoch 79; iter: 0; batch classifier loss: 0.190769; batch adversarial loss: 0.445618\n",
      "epoch 80; iter: 0; batch classifier loss: 0.172815; batch adversarial loss: 0.458266\n",
      "epoch 81; iter: 0; batch classifier loss: 0.156058; batch adversarial loss: 0.421465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.174622; batch adversarial loss: 0.395624\n",
      "epoch 83; iter: 0; batch classifier loss: 0.170047; batch adversarial loss: 0.471919\n",
      "epoch 84; iter: 0; batch classifier loss: 0.198925; batch adversarial loss: 0.370648\n",
      "epoch 85; iter: 0; batch classifier loss: 0.183694; batch adversarial loss: 0.508995\n",
      "epoch 86; iter: 0; batch classifier loss: 0.155385; batch adversarial loss: 0.622165\n",
      "epoch 87; iter: 0; batch classifier loss: 0.209775; batch adversarial loss: 0.458991\n",
      "epoch 88; iter: 0; batch classifier loss: 0.165883; batch adversarial loss: 0.484109\n",
      "epoch 89; iter: 0; batch classifier loss: 0.126354; batch adversarial loss: 0.521675\n",
      "epoch 90; iter: 0; batch classifier loss: 0.154191; batch adversarial loss: 0.482976\n",
      "epoch 91; iter: 0; batch classifier loss: 0.181031; batch adversarial loss: 0.535012\n",
      "epoch 92; iter: 0; batch classifier loss: 0.225083; batch adversarial loss: 0.383521\n",
      "epoch 93; iter: 0; batch classifier loss: 0.175012; batch adversarial loss: 0.521983\n",
      "epoch 94; iter: 0; batch classifier loss: 0.155302; batch adversarial loss: 0.421227\n",
      "epoch 95; iter: 0; batch classifier loss: 0.179396; batch adversarial loss: 0.572997\n",
      "epoch 96; iter: 0; batch classifier loss: 0.211283; batch adversarial loss: 0.396094\n",
      "epoch 97; iter: 0; batch classifier loss: 0.118372; batch adversarial loss: 0.433729\n",
      "epoch 98; iter: 0; batch classifier loss: 0.224320; batch adversarial loss: 0.496792\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064734; batch adversarial loss: 0.471328\n",
      "epoch 100; iter: 0; batch classifier loss: 0.128485; batch adversarial loss: 0.459320\n",
      "epoch 101; iter: 0; batch classifier loss: 0.078586; batch adversarial loss: 0.469213\n",
      "epoch 102; iter: 0; batch classifier loss: 0.098757; batch adversarial loss: 0.429915\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059063; batch adversarial loss: 0.366020\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069519; batch adversarial loss: 0.507434\n",
      "epoch 105; iter: 0; batch classifier loss: 0.071967; batch adversarial loss: 0.367284\n",
      "epoch 106; iter: 0; batch classifier loss: 0.084262; batch adversarial loss: 0.379933\n",
      "epoch 107; iter: 0; batch classifier loss: 0.073318; batch adversarial loss: 0.461255\n",
      "epoch 108; iter: 0; batch classifier loss: 0.131252; batch adversarial loss: 0.473573\n",
      "epoch 109; iter: 0; batch classifier loss: 0.118809; batch adversarial loss: 0.321693\n",
      "epoch 110; iter: 0; batch classifier loss: 0.066215; batch adversarial loss: 0.443503\n",
      "epoch 111; iter: 0; batch classifier loss: 0.078328; batch adversarial loss: 0.424680\n",
      "epoch 112; iter: 0; batch classifier loss: 0.087966; batch adversarial loss: 0.398040\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043283; batch adversarial loss: 0.395093\n",
      "epoch 114; iter: 0; batch classifier loss: 0.071501; batch adversarial loss: 0.389332\n",
      "epoch 115; iter: 0; batch classifier loss: 0.078618; batch adversarial loss: 0.532929\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042090; batch adversarial loss: 0.440044\n",
      "epoch 117; iter: 0; batch classifier loss: 0.057927; batch adversarial loss: 0.393923\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056681; batch adversarial loss: 0.447810\n",
      "epoch 119; iter: 0; batch classifier loss: 0.070738; batch adversarial loss: 0.447106\n",
      "epoch 120; iter: 0; batch classifier loss: 0.029219; batch adversarial loss: 0.538658\n",
      "epoch 121; iter: 0; batch classifier loss: 0.093643; batch adversarial loss: 0.405718\n",
      "epoch 122; iter: 0; batch classifier loss: 0.077778; batch adversarial loss: 0.451633\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037125; batch adversarial loss: 0.436234\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057532; batch adversarial loss: 0.350631\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047029; batch adversarial loss: 0.348845\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037774; batch adversarial loss: 0.380939\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032247; batch adversarial loss: 0.394595\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056135; batch adversarial loss: 0.521804\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033488; batch adversarial loss: 0.453412\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023155; batch adversarial loss: 0.511974\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047566; batch adversarial loss: 0.405240\n",
      "epoch 132; iter: 0; batch classifier loss: 0.063101; batch adversarial loss: 0.537059\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035504; batch adversarial loss: 0.399488\n",
      "epoch 134; iter: 0; batch classifier loss: 0.044182; batch adversarial loss: 0.474049\n",
      "epoch 135; iter: 0; batch classifier loss: 0.052804; batch adversarial loss: 0.473862\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040827; batch adversarial loss: 0.417274\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023804; batch adversarial loss: 0.399077\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029797; batch adversarial loss: 0.455582\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022027; batch adversarial loss: 0.401228\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030461; batch adversarial loss: 0.539926\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033236; batch adversarial loss: 0.395608\n",
      "epoch 142; iter: 0; batch classifier loss: 0.065392; batch adversarial loss: 0.453711\n",
      "epoch 143; iter: 0; batch classifier loss: 0.038532; batch adversarial loss: 0.553480\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031699; batch adversarial loss: 0.507350\n",
      "epoch 145; iter: 0; batch classifier loss: 0.056851; batch adversarial loss: 0.436500\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032591; batch adversarial loss: 0.534449\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034810; batch adversarial loss: 0.518033\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020599; batch adversarial loss: 0.494273\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034268; batch adversarial loss: 0.452635\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042775; batch adversarial loss: 0.397566\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014663; batch adversarial loss: 0.490830\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019118; batch adversarial loss: 0.508593\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026601; batch adversarial loss: 0.476976\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034129; batch adversarial loss: 0.501572\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016997; batch adversarial loss: 0.321300\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023851; batch adversarial loss: 0.384908\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025728; batch adversarial loss: 0.589282\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012388; batch adversarial loss: 0.415692\n",
      "epoch 159; iter: 0; batch classifier loss: 0.071738; batch adversarial loss: 0.409250\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017364; batch adversarial loss: 0.556971\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013370; batch adversarial loss: 0.432004\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028870; batch adversarial loss: 0.363051\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025338; batch adversarial loss: 0.444488\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030787; batch adversarial loss: 0.410292\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015002; batch adversarial loss: 0.405888\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046584; batch adversarial loss: 0.458270\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015135; batch adversarial loss: 0.365501\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025724; batch adversarial loss: 0.345084\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014970; batch adversarial loss: 0.354525\n",
      "epoch 170; iter: 0; batch classifier loss: 0.007877; batch adversarial loss: 0.393048\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021364; batch adversarial loss: 0.443484\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020574; batch adversarial loss: 0.348905\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026517; batch adversarial loss: 0.483347\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017744; batch adversarial loss: 0.369081\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020355; batch adversarial loss: 0.442917\n",
      "epoch 176; iter: 0; batch classifier loss: 0.044236; batch adversarial loss: 0.568263\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010123; batch adversarial loss: 0.514703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.027276; batch adversarial loss: 0.439961\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031096; batch adversarial loss: 0.395331\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009959; batch adversarial loss: 0.364298\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013890; batch adversarial loss: 0.362085\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021706; batch adversarial loss: 0.422333\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009335; batch adversarial loss: 0.491093\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022416; batch adversarial loss: 0.514922\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026418; batch adversarial loss: 0.377161\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009785; batch adversarial loss: 0.498489\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007250; batch adversarial loss: 0.401630\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013642; batch adversarial loss: 0.443054\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028541; batch adversarial loss: 0.394124\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006406; batch adversarial loss: 0.508428\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018348; batch adversarial loss: 0.484600\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014266; batch adversarial loss: 0.452378\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016987; batch adversarial loss: 0.482593\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011591; batch adversarial loss: 0.464601\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023242; batch adversarial loss: 0.451636\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016157; batch adversarial loss: 0.428597\n",
      "epoch 197; iter: 0; batch classifier loss: 0.035271; batch adversarial loss: 0.424201\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011300; batch adversarial loss: 0.451518\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014646; batch adversarial loss: 0.446487\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681936; batch adversarial loss: 0.740661\n",
      "epoch 1; iter: 0; batch classifier loss: 0.436900; batch adversarial loss: 0.697875\n",
      "epoch 2; iter: 0; batch classifier loss: 0.414676; batch adversarial loss: 0.666840\n",
      "epoch 3; iter: 0; batch classifier loss: 0.340121; batch adversarial loss: 0.631396\n",
      "epoch 4; iter: 0; batch classifier loss: 0.379689; batch adversarial loss: 0.593014\n",
      "epoch 5; iter: 0; batch classifier loss: 0.336709; batch adversarial loss: 0.563061\n",
      "epoch 6; iter: 0; batch classifier loss: 0.284025; batch adversarial loss: 0.521941\n",
      "epoch 7; iter: 0; batch classifier loss: 0.369856; batch adversarial loss: 0.511326\n",
      "epoch 8; iter: 0; batch classifier loss: 0.247513; batch adversarial loss: 0.522923\n",
      "epoch 9; iter: 0; batch classifier loss: 0.261987; batch adversarial loss: 0.540136\n",
      "epoch 10; iter: 0; batch classifier loss: 0.240873; batch adversarial loss: 0.534151\n",
      "epoch 11; iter: 0; batch classifier loss: 0.209860; batch adversarial loss: 0.522725\n",
      "epoch 12; iter: 0; batch classifier loss: 0.219159; batch adversarial loss: 0.525280\n",
      "epoch 13; iter: 0; batch classifier loss: 0.239829; batch adversarial loss: 0.529085\n",
      "epoch 14; iter: 0; batch classifier loss: 0.198209; batch adversarial loss: 0.433487\n",
      "epoch 15; iter: 0; batch classifier loss: 0.208145; batch adversarial loss: 0.471286\n",
      "epoch 16; iter: 0; batch classifier loss: 0.168054; batch adversarial loss: 0.585005\n",
      "epoch 17; iter: 0; batch classifier loss: 0.201182; batch adversarial loss: 0.516361\n",
      "epoch 18; iter: 0; batch classifier loss: 0.126980; batch adversarial loss: 0.510734\n",
      "epoch 19; iter: 0; batch classifier loss: 0.188405; batch adversarial loss: 0.518548\n",
      "epoch 20; iter: 0; batch classifier loss: 0.166095; batch adversarial loss: 0.481570\n",
      "epoch 21; iter: 0; batch classifier loss: 0.160852; batch adversarial loss: 0.552269\n",
      "epoch 22; iter: 0; batch classifier loss: 0.202175; batch adversarial loss: 0.450412\n",
      "epoch 23; iter: 0; batch classifier loss: 0.275420; batch adversarial loss: 0.507759\n",
      "epoch 24; iter: 0; batch classifier loss: 0.252101; batch adversarial loss: 0.512164\n",
      "epoch 25; iter: 0; batch classifier loss: 0.259093; batch adversarial loss: 0.569067\n",
      "epoch 26; iter: 0; batch classifier loss: 0.253004; batch adversarial loss: 0.448211\n",
      "epoch 27; iter: 0; batch classifier loss: 0.219059; batch adversarial loss: 0.484694\n",
      "epoch 28; iter: 0; batch classifier loss: 0.265207; batch adversarial loss: 0.496383\n",
      "epoch 29; iter: 0; batch classifier loss: 0.295824; batch adversarial loss: 0.504320\n",
      "epoch 30; iter: 0; batch classifier loss: 0.130619; batch adversarial loss: 0.505144\n",
      "epoch 31; iter: 0; batch classifier loss: 0.177078; batch adversarial loss: 0.481094\n",
      "epoch 32; iter: 0; batch classifier loss: 0.131965; batch adversarial loss: 0.386281\n",
      "epoch 33; iter: 0; batch classifier loss: 0.098510; batch adversarial loss: 0.437316\n",
      "epoch 34; iter: 0; batch classifier loss: 0.123845; batch adversarial loss: 0.484416\n",
      "epoch 35; iter: 0; batch classifier loss: 0.098605; batch adversarial loss: 0.535163\n",
      "epoch 36; iter: 0; batch classifier loss: 0.155293; batch adversarial loss: 0.419535\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113043; batch adversarial loss: 0.429497\n",
      "epoch 38; iter: 0; batch classifier loss: 0.090810; batch adversarial loss: 0.504998\n",
      "epoch 39; iter: 0; batch classifier loss: 0.095070; batch adversarial loss: 0.343067\n",
      "epoch 40; iter: 0; batch classifier loss: 0.106752; batch adversarial loss: 0.465997\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106992; batch adversarial loss: 0.465387\n",
      "epoch 42; iter: 0; batch classifier loss: 0.089292; batch adversarial loss: 0.405483\n",
      "epoch 43; iter: 0; batch classifier loss: 0.125322; batch adversarial loss: 0.354510\n",
      "epoch 44; iter: 0; batch classifier loss: 0.082282; batch adversarial loss: 0.390949\n",
      "epoch 45; iter: 0; batch classifier loss: 0.084609; batch adversarial loss: 0.416556\n",
      "epoch 46; iter: 0; batch classifier loss: 0.108592; batch adversarial loss: 0.464367\n",
      "epoch 47; iter: 0; batch classifier loss: 0.090521; batch adversarial loss: 0.464122\n",
      "epoch 48; iter: 0; batch classifier loss: 0.080966; batch adversarial loss: 0.382661\n",
      "epoch 49; iter: 0; batch classifier loss: 0.071929; batch adversarial loss: 0.496092\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087375; batch adversarial loss: 0.502687\n",
      "epoch 51; iter: 0; batch classifier loss: 0.104799; batch adversarial loss: 0.422626\n",
      "epoch 52; iter: 0; batch classifier loss: 0.095135; batch adversarial loss: 0.501847\n",
      "epoch 53; iter: 0; batch classifier loss: 0.143424; batch adversarial loss: 0.468150\n",
      "epoch 54; iter: 0; batch classifier loss: 0.072926; batch adversarial loss: 0.477359\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091170; batch adversarial loss: 0.453854\n",
      "epoch 56; iter: 0; batch classifier loss: 0.062877; batch adversarial loss: 0.483916\n",
      "epoch 57; iter: 0; batch classifier loss: 0.062732; batch adversarial loss: 0.425188\n",
      "epoch 58; iter: 0; batch classifier loss: 0.115991; batch adversarial loss: 0.469148\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084659; batch adversarial loss: 0.431474\n",
      "epoch 60; iter: 0; batch classifier loss: 0.059299; batch adversarial loss: 0.433086\n",
      "epoch 61; iter: 0; batch classifier loss: 0.073612; batch adversarial loss: 0.403726\n",
      "epoch 62; iter: 0; batch classifier loss: 0.066985; batch adversarial loss: 0.366611\n",
      "epoch 63; iter: 0; batch classifier loss: 0.062729; batch adversarial loss: 0.386493\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070367; batch adversarial loss: 0.502615\n",
      "epoch 65; iter: 0; batch classifier loss: 0.066384; batch adversarial loss: 0.457646\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060021; batch adversarial loss: 0.470317\n",
      "epoch 67; iter: 0; batch classifier loss: 0.081090; batch adversarial loss: 0.426707\n",
      "epoch 68; iter: 0; batch classifier loss: 0.080720; batch adversarial loss: 0.377847\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065127; batch adversarial loss: 0.479159\n",
      "epoch 70; iter: 0; batch classifier loss: 0.074653; batch adversarial loss: 0.496672\n",
      "epoch 71; iter: 0; batch classifier loss: 0.050361; batch adversarial loss: 0.486066\n",
      "epoch 72; iter: 0; batch classifier loss: 0.107025; batch adversarial loss: 0.457501\n",
      "epoch 73; iter: 0; batch classifier loss: 0.055261; batch adversarial loss: 0.387344\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066614; batch adversarial loss: 0.480072\n",
      "epoch 75; iter: 0; batch classifier loss: 0.110973; batch adversarial loss: 0.410354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.106498; batch adversarial loss: 0.411157\n",
      "epoch 77; iter: 0; batch classifier loss: 0.098553; batch adversarial loss: 0.451611\n",
      "epoch 78; iter: 0; batch classifier loss: 0.088469; batch adversarial loss: 0.419536\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061642; batch adversarial loss: 0.406860\n",
      "epoch 80; iter: 0; batch classifier loss: 0.047574; batch adversarial loss: 0.475234\n",
      "epoch 81; iter: 0; batch classifier loss: 0.062440; batch adversarial loss: 0.391629\n",
      "epoch 82; iter: 0; batch classifier loss: 0.042581; batch adversarial loss: 0.432923\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065094; batch adversarial loss: 0.456051\n",
      "epoch 84; iter: 0; batch classifier loss: 0.073616; batch adversarial loss: 0.406463\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084165; batch adversarial loss: 0.465203\n",
      "epoch 86; iter: 0; batch classifier loss: 0.077794; batch adversarial loss: 0.426402\n",
      "epoch 87; iter: 0; batch classifier loss: 0.027187; batch adversarial loss: 0.401712\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070972; batch adversarial loss: 0.465003\n",
      "epoch 89; iter: 0; batch classifier loss: 0.055167; batch adversarial loss: 0.382073\n",
      "epoch 90; iter: 0; batch classifier loss: 0.078049; batch adversarial loss: 0.452415\n",
      "epoch 91; iter: 0; batch classifier loss: 0.084297; batch adversarial loss: 0.425063\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069661; batch adversarial loss: 0.376477\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062318; batch adversarial loss: 0.428750\n",
      "epoch 94; iter: 0; batch classifier loss: 0.031390; batch adversarial loss: 0.528174\n",
      "epoch 95; iter: 0; batch classifier loss: 0.033150; batch adversarial loss: 0.442455\n",
      "epoch 96; iter: 0; batch classifier loss: 0.081679; batch adversarial loss: 0.528292\n",
      "epoch 97; iter: 0; batch classifier loss: 0.035781; batch adversarial loss: 0.407499\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074118; batch adversarial loss: 0.419902\n",
      "epoch 99; iter: 0; batch classifier loss: 0.022154; batch adversarial loss: 0.472870\n",
      "epoch 100; iter: 0; batch classifier loss: 0.082159; batch adversarial loss: 0.441530\n",
      "epoch 101; iter: 0; batch classifier loss: 0.086977; batch adversarial loss: 0.441764\n",
      "epoch 102; iter: 0; batch classifier loss: 0.045345; batch adversarial loss: 0.428021\n",
      "epoch 103; iter: 0; batch classifier loss: 0.023733; batch adversarial loss: 0.427496\n",
      "epoch 104; iter: 0; batch classifier loss: 0.040291; batch adversarial loss: 0.444350\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049508; batch adversarial loss: 0.464692\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059994; batch adversarial loss: 0.495544\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053306; batch adversarial loss: 0.426281\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052826; batch adversarial loss: 0.408049\n",
      "epoch 109; iter: 0; batch classifier loss: 0.055510; batch adversarial loss: 0.528953\n",
      "epoch 110; iter: 0; batch classifier loss: 0.129956; batch adversarial loss: 0.413534\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031440; batch adversarial loss: 0.501901\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059159; batch adversarial loss: 0.428345\n",
      "epoch 113; iter: 0; batch classifier loss: 0.090548; batch adversarial loss: 0.514806\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041654; batch adversarial loss: 0.421829\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057405; batch adversarial loss: 0.464344\n",
      "epoch 116; iter: 0; batch classifier loss: 0.068518; batch adversarial loss: 0.453492\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027686; batch adversarial loss: 0.347405\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028551; batch adversarial loss: 0.355771\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045836; batch adversarial loss: 0.577066\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057300; batch adversarial loss: 0.422817\n",
      "epoch 121; iter: 0; batch classifier loss: 0.068061; batch adversarial loss: 0.416765\n",
      "epoch 122; iter: 0; batch classifier loss: 0.083021; batch adversarial loss: 0.467230\n",
      "epoch 123; iter: 0; batch classifier loss: 0.083860; batch adversarial loss: 0.450665\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032677; batch adversarial loss: 0.507196\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033738; batch adversarial loss: 0.571047\n",
      "epoch 126; iter: 0; batch classifier loss: 0.054367; batch adversarial loss: 0.433833\n",
      "epoch 127; iter: 0; batch classifier loss: 0.059794; batch adversarial loss: 0.398952\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031803; batch adversarial loss: 0.375402\n",
      "epoch 129; iter: 0; batch classifier loss: 0.055012; batch adversarial loss: 0.447333\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018550; batch adversarial loss: 0.474435\n",
      "epoch 131; iter: 0; batch classifier loss: 0.060938; batch adversarial loss: 0.411643\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032945; batch adversarial loss: 0.388048\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027432; batch adversarial loss: 0.373262\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029527; batch adversarial loss: 0.424586\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031205; batch adversarial loss: 0.414814\n",
      "epoch 136; iter: 0; batch classifier loss: 0.055481; batch adversarial loss: 0.433894\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032279; batch adversarial loss: 0.430477\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019634; batch adversarial loss: 0.465460\n",
      "epoch 139; iter: 0; batch classifier loss: 0.047461; batch adversarial loss: 0.381933\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020971; batch adversarial loss: 0.499829\n",
      "epoch 141; iter: 0; batch classifier loss: 0.085112; batch adversarial loss: 0.393742\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027092; batch adversarial loss: 0.429799\n",
      "epoch 143; iter: 0; batch classifier loss: 0.007631; batch adversarial loss: 0.379299\n",
      "epoch 144; iter: 0; batch classifier loss: 0.076416; batch adversarial loss: 0.417615\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024128; batch adversarial loss: 0.440576\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018224; batch adversarial loss: 0.439954\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042412; batch adversarial loss: 0.480173\n",
      "epoch 148; iter: 0; batch classifier loss: 0.010261; batch adversarial loss: 0.396162\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013661; batch adversarial loss: 0.506428\n",
      "epoch 150; iter: 0; batch classifier loss: 0.047518; batch adversarial loss: 0.431353\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019869; batch adversarial loss: 0.447973\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031025; batch adversarial loss: 0.454011\n",
      "epoch 153; iter: 0; batch classifier loss: 0.052887; batch adversarial loss: 0.436710\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040448; batch adversarial loss: 0.567237\n",
      "epoch 155; iter: 0; batch classifier loss: 0.047025; batch adversarial loss: 0.443883\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030435; batch adversarial loss: 0.462001\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030694; batch adversarial loss: 0.482617\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034773; batch adversarial loss: 0.474648\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038189; batch adversarial loss: 0.417556\n",
      "epoch 160; iter: 0; batch classifier loss: 0.011409; batch adversarial loss: 0.411531\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007144; batch adversarial loss: 0.421031\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018946; batch adversarial loss: 0.444502\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024564; batch adversarial loss: 0.508293\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011467; batch adversarial loss: 0.367459\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040002; batch adversarial loss: 0.564517\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023742; batch adversarial loss: 0.424061\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020126; batch adversarial loss: 0.455843\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029328; batch adversarial loss: 0.467531\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034745; batch adversarial loss: 0.455191\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018526; batch adversarial loss: 0.459576\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033173; batch adversarial loss: 0.498879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.005869; batch adversarial loss: 0.402644\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040245; batch adversarial loss: 0.456993\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038688; batch adversarial loss: 0.421560\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017956; batch adversarial loss: 0.498047\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037458; batch adversarial loss: 0.404091\n",
      "epoch 177; iter: 0; batch classifier loss: 0.064261; batch adversarial loss: 0.517563\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030518; batch adversarial loss: 0.481425\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019551; batch adversarial loss: 0.598303\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022424; batch adversarial loss: 0.450738\n",
      "epoch 181; iter: 0; batch classifier loss: 0.051339; batch adversarial loss: 0.367273\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032869; batch adversarial loss: 0.417520\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011375; batch adversarial loss: 0.327425\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037981; batch adversarial loss: 0.406156\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026101; batch adversarial loss: 0.434326\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017765; batch adversarial loss: 0.431490\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025568; batch adversarial loss: 0.464344\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025225; batch adversarial loss: 0.484007\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012351; batch adversarial loss: 0.404461\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034902; batch adversarial loss: 0.471825\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009040; batch adversarial loss: 0.511360\n",
      "epoch 192; iter: 0; batch classifier loss: 0.081162; batch adversarial loss: 0.346044\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009772; batch adversarial loss: 0.482279\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012284; batch adversarial loss: 0.462407\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009471; batch adversarial loss: 0.446663\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016220; batch adversarial loss: 0.465211\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010046; batch adversarial loss: 0.385362\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019733; batch adversarial loss: 0.409952\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019461; batch adversarial loss: 0.468760\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688494; batch adversarial loss: 0.516233\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433945; batch adversarial loss: 0.579834\n",
      "epoch 2; iter: 0; batch classifier loss: 0.321080; batch adversarial loss: 0.593045\n",
      "epoch 3; iter: 0; batch classifier loss: 0.413406; batch adversarial loss: 0.540855\n",
      "epoch 4; iter: 0; batch classifier loss: 0.435297; batch adversarial loss: 0.575350\n",
      "epoch 5; iter: 0; batch classifier loss: 0.398318; batch adversarial loss: 0.618378\n",
      "epoch 6; iter: 0; batch classifier loss: 0.334105; batch adversarial loss: 0.605569\n",
      "epoch 7; iter: 0; batch classifier loss: 0.359008; batch adversarial loss: 0.575359\n",
      "epoch 8; iter: 0; batch classifier loss: 0.310525; batch adversarial loss: 0.511850\n",
      "epoch 9; iter: 0; batch classifier loss: 0.400216; batch adversarial loss: 0.629529\n",
      "epoch 10; iter: 0; batch classifier loss: 0.388725; batch adversarial loss: 0.554028\n",
      "epoch 11; iter: 0; batch classifier loss: 0.367972; batch adversarial loss: 0.481893\n",
      "epoch 12; iter: 0; batch classifier loss: 0.684145; batch adversarial loss: 0.509974\n",
      "epoch 13; iter: 0; batch classifier loss: 0.682589; batch adversarial loss: 0.547625\n",
      "epoch 14; iter: 0; batch classifier loss: 0.532409; batch adversarial loss: 0.515674\n",
      "epoch 15; iter: 0; batch classifier loss: 0.305978; batch adversarial loss: 0.536794\n",
      "epoch 16; iter: 0; batch classifier loss: 0.263397; batch adversarial loss: 0.495652\n",
      "epoch 17; iter: 0; batch classifier loss: 0.209211; batch adversarial loss: 0.483219\n",
      "epoch 18; iter: 0; batch classifier loss: 0.194328; batch adversarial loss: 0.504222\n",
      "epoch 19; iter: 0; batch classifier loss: 0.174984; batch adversarial loss: 0.518427\n",
      "epoch 20; iter: 0; batch classifier loss: 0.219058; batch adversarial loss: 0.531940\n",
      "epoch 21; iter: 0; batch classifier loss: 0.181889; batch adversarial loss: 0.454322\n",
      "epoch 22; iter: 0; batch classifier loss: 0.219057; batch adversarial loss: 0.533233\n",
      "epoch 23; iter: 0; batch classifier loss: 0.237230; batch adversarial loss: 0.462926\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192441; batch adversarial loss: 0.470279\n",
      "epoch 25; iter: 0; batch classifier loss: 0.168446; batch adversarial loss: 0.495069\n",
      "epoch 26; iter: 0; batch classifier loss: 0.167372; batch adversarial loss: 0.453658\n",
      "epoch 27; iter: 0; batch classifier loss: 0.199714; batch adversarial loss: 0.469208\n",
      "epoch 28; iter: 0; batch classifier loss: 0.159611; batch adversarial loss: 0.471562\n",
      "epoch 29; iter: 0; batch classifier loss: 0.149276; batch adversarial loss: 0.474994\n",
      "epoch 30; iter: 0; batch classifier loss: 0.149484; batch adversarial loss: 0.391667\n",
      "epoch 31; iter: 0; batch classifier loss: 0.140902; batch adversarial loss: 0.433210\n",
      "epoch 32; iter: 0; batch classifier loss: 0.156284; batch adversarial loss: 0.413393\n",
      "epoch 33; iter: 0; batch classifier loss: 0.248138; batch adversarial loss: 0.481179\n",
      "epoch 34; iter: 0; batch classifier loss: 0.163418; batch adversarial loss: 0.461598\n",
      "epoch 35; iter: 0; batch classifier loss: 0.116688; batch adversarial loss: 0.376395\n",
      "epoch 36; iter: 0; batch classifier loss: 0.110317; batch adversarial loss: 0.523837\n",
      "epoch 37; iter: 0; batch classifier loss: 0.147064; batch adversarial loss: 0.473318\n",
      "epoch 38; iter: 0; batch classifier loss: 0.135146; batch adversarial loss: 0.432216\n",
      "epoch 39; iter: 0; batch classifier loss: 0.145814; batch adversarial loss: 0.471211\n",
      "epoch 40; iter: 0; batch classifier loss: 0.163616; batch adversarial loss: 0.408779\n",
      "epoch 41; iter: 0; batch classifier loss: 0.188176; batch adversarial loss: 0.363589\n",
      "epoch 42; iter: 0; batch classifier loss: 0.181835; batch adversarial loss: 0.435309\n",
      "epoch 43; iter: 0; batch classifier loss: 0.165936; batch adversarial loss: 0.417793\n",
      "epoch 44; iter: 0; batch classifier loss: 0.186178; batch adversarial loss: 0.459166\n",
      "epoch 45; iter: 0; batch classifier loss: 0.106932; batch adversarial loss: 0.476265\n",
      "epoch 46; iter: 0; batch classifier loss: 0.155015; batch adversarial loss: 0.340482\n",
      "epoch 47; iter: 0; batch classifier loss: 0.133695; batch adversarial loss: 0.487093\n",
      "epoch 48; iter: 0; batch classifier loss: 0.179872; batch adversarial loss: 0.497706\n",
      "epoch 49; iter: 0; batch classifier loss: 0.199333; batch adversarial loss: 0.465010\n",
      "epoch 50; iter: 0; batch classifier loss: 0.164521; batch adversarial loss: 0.432501\n",
      "epoch 51; iter: 0; batch classifier loss: 0.207057; batch adversarial loss: 0.472887\n",
      "epoch 52; iter: 0; batch classifier loss: 0.156211; batch adversarial loss: 0.558804\n",
      "epoch 53; iter: 0; batch classifier loss: 0.093005; batch adversarial loss: 0.461917\n",
      "epoch 54; iter: 0; batch classifier loss: 0.149748; batch adversarial loss: 0.387231\n",
      "epoch 55; iter: 0; batch classifier loss: 0.132923; batch adversarial loss: 0.335423\n",
      "epoch 56; iter: 0; batch classifier loss: 0.141879; batch adversarial loss: 0.333564\n",
      "epoch 57; iter: 0; batch classifier loss: 0.077271; batch adversarial loss: 0.420334\n",
      "epoch 58; iter: 0; batch classifier loss: 0.141312; batch adversarial loss: 0.404594\n",
      "epoch 59; iter: 0; batch classifier loss: 0.110809; batch adversarial loss: 0.410128\n",
      "epoch 60; iter: 0; batch classifier loss: 0.137073; batch adversarial loss: 0.434194\n",
      "epoch 61; iter: 0; batch classifier loss: 0.146935; batch adversarial loss: 0.385082\n",
      "epoch 62; iter: 0; batch classifier loss: 0.170051; batch adversarial loss: 0.442809\n",
      "epoch 63; iter: 0; batch classifier loss: 0.112852; batch adversarial loss: 0.398972\n",
      "epoch 64; iter: 0; batch classifier loss: 0.151535; batch adversarial loss: 0.433791\n",
      "epoch 65; iter: 0; batch classifier loss: 0.171658; batch adversarial loss: 0.359184\n",
      "epoch 66; iter: 0; batch classifier loss: 0.169992; batch adversarial loss: 0.380269\n",
      "epoch 67; iter: 0; batch classifier loss: 0.196767; batch adversarial loss: 0.438528\n",
      "epoch 68; iter: 0; batch classifier loss: 0.146156; batch adversarial loss: 0.508490\n",
      "epoch 69; iter: 0; batch classifier loss: 0.114899; batch adversarial loss: 0.394957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.163052; batch adversarial loss: 0.376565\n",
      "epoch 71; iter: 0; batch classifier loss: 0.103002; batch adversarial loss: 0.462427\n",
      "epoch 72; iter: 0; batch classifier loss: 0.110749; batch adversarial loss: 0.410827\n",
      "epoch 73; iter: 0; batch classifier loss: 0.148184; batch adversarial loss: 0.543848\n",
      "epoch 74; iter: 0; batch classifier loss: 0.227798; batch adversarial loss: 0.309914\n",
      "epoch 75; iter: 0; batch classifier loss: 0.144845; batch adversarial loss: 0.494821\n",
      "epoch 76; iter: 0; batch classifier loss: 0.181987; batch adversarial loss: 0.383894\n",
      "epoch 77; iter: 0; batch classifier loss: 0.175569; batch adversarial loss: 0.334961\n",
      "epoch 78; iter: 0; batch classifier loss: 0.191921; batch adversarial loss: 0.483960\n",
      "epoch 79; iter: 0; batch classifier loss: 0.212223; batch adversarial loss: 0.369243\n",
      "epoch 80; iter: 0; batch classifier loss: 0.233947; batch adversarial loss: 0.513294\n",
      "epoch 81; iter: 0; batch classifier loss: 0.167818; batch adversarial loss: 0.523454\n",
      "epoch 82; iter: 0; batch classifier loss: 0.144563; batch adversarial loss: 0.444883\n",
      "epoch 83; iter: 0; batch classifier loss: 0.200840; batch adversarial loss: 0.457154\n",
      "epoch 84; iter: 0; batch classifier loss: 0.153308; batch adversarial loss: 0.459805\n",
      "epoch 85; iter: 0; batch classifier loss: 0.181465; batch adversarial loss: 0.446287\n",
      "epoch 86; iter: 0; batch classifier loss: 0.145005; batch adversarial loss: 0.445627\n",
      "epoch 87; iter: 0; batch classifier loss: 0.198404; batch adversarial loss: 0.387808\n",
      "epoch 88; iter: 0; batch classifier loss: 0.216009; batch adversarial loss: 0.432716\n",
      "epoch 89; iter: 0; batch classifier loss: 0.132470; batch adversarial loss: 0.432627\n",
      "epoch 90; iter: 0; batch classifier loss: 0.253482; batch adversarial loss: 0.422710\n",
      "epoch 91; iter: 0; batch classifier loss: 0.167266; batch adversarial loss: 0.461246\n",
      "epoch 92; iter: 0; batch classifier loss: 0.225798; batch adversarial loss: 0.578963\n",
      "epoch 93; iter: 0; batch classifier loss: 0.149810; batch adversarial loss: 0.432652\n",
      "epoch 94; iter: 0; batch classifier loss: 0.135551; batch adversarial loss: 0.461706\n",
      "epoch 95; iter: 0; batch classifier loss: 0.187532; batch adversarial loss: 0.336358\n",
      "epoch 96; iter: 0; batch classifier loss: 0.180489; batch adversarial loss: 0.433126\n",
      "epoch 97; iter: 0; batch classifier loss: 0.177661; batch adversarial loss: 0.507313\n",
      "epoch 98; iter: 0; batch classifier loss: 0.172851; batch adversarial loss: 0.459599\n",
      "epoch 99; iter: 0; batch classifier loss: 0.184908; batch adversarial loss: 0.396692\n",
      "epoch 100; iter: 0; batch classifier loss: 0.191044; batch adversarial loss: 0.495930\n",
      "epoch 101; iter: 0; batch classifier loss: 0.164299; batch adversarial loss: 0.511031\n",
      "epoch 102; iter: 0; batch classifier loss: 0.141732; batch adversarial loss: 0.484034\n",
      "epoch 103; iter: 0; batch classifier loss: 0.169875; batch adversarial loss: 0.520648\n",
      "epoch 104; iter: 0; batch classifier loss: 0.206200; batch adversarial loss: 0.569056\n",
      "epoch 105; iter: 0; batch classifier loss: 0.170855; batch adversarial loss: 0.357686\n",
      "epoch 106; iter: 0; batch classifier loss: 0.216048; batch adversarial loss: 0.395576\n",
      "epoch 107; iter: 0; batch classifier loss: 0.143466; batch adversarial loss: 0.395361\n",
      "epoch 108; iter: 0; batch classifier loss: 0.136274; batch adversarial loss: 0.507683\n",
      "epoch 109; iter: 0; batch classifier loss: 0.162673; batch adversarial loss: 0.471254\n",
      "epoch 110; iter: 0; batch classifier loss: 0.177737; batch adversarial loss: 0.422803\n",
      "epoch 111; iter: 0; batch classifier loss: 0.221208; batch adversarial loss: 0.359475\n",
      "epoch 112; iter: 0; batch classifier loss: 0.134697; batch adversarial loss: 0.407029\n",
      "epoch 113; iter: 0; batch classifier loss: 0.139051; batch adversarial loss: 0.506718\n",
      "epoch 114; iter: 0; batch classifier loss: 0.105129; batch adversarial loss: 0.385810\n",
      "epoch 115; iter: 0; batch classifier loss: 0.149820; batch adversarial loss: 0.482394\n",
      "epoch 116; iter: 0; batch classifier loss: 0.138934; batch adversarial loss: 0.458893\n",
      "epoch 117; iter: 0; batch classifier loss: 0.176495; batch adversarial loss: 0.499681\n",
      "epoch 118; iter: 0; batch classifier loss: 0.184344; batch adversarial loss: 0.445944\n",
      "epoch 119; iter: 0; batch classifier loss: 0.192000; batch adversarial loss: 0.446881\n",
      "epoch 120; iter: 0; batch classifier loss: 0.188431; batch adversarial loss: 0.385230\n",
      "epoch 121; iter: 0; batch classifier loss: 0.153774; batch adversarial loss: 0.395268\n",
      "epoch 122; iter: 0; batch classifier loss: 0.177787; batch adversarial loss: 0.433044\n",
      "epoch 123; iter: 0; batch classifier loss: 0.190760; batch adversarial loss: 0.435243\n",
      "epoch 124; iter: 0; batch classifier loss: 0.185124; batch adversarial loss: 0.372684\n",
      "epoch 125; iter: 0; batch classifier loss: 0.162596; batch adversarial loss: 0.430237\n",
      "epoch 126; iter: 0; batch classifier loss: 0.178478; batch adversarial loss: 0.369031\n",
      "epoch 127; iter: 0; batch classifier loss: 0.138785; batch adversarial loss: 0.530896\n",
      "epoch 128; iter: 0; batch classifier loss: 0.191988; batch adversarial loss: 0.534465\n",
      "epoch 129; iter: 0; batch classifier loss: 0.145182; batch adversarial loss: 0.434907\n",
      "epoch 130; iter: 0; batch classifier loss: 0.122036; batch adversarial loss: 0.406978\n",
      "epoch 131; iter: 0; batch classifier loss: 0.115226; batch adversarial loss: 0.470111\n",
      "epoch 132; iter: 0; batch classifier loss: 0.158277; batch adversarial loss: 0.318675\n",
      "epoch 133; iter: 0; batch classifier loss: 0.140600; batch adversarial loss: 0.561227\n",
      "epoch 134; iter: 0; batch classifier loss: 0.120579; batch adversarial loss: 0.468330\n",
      "epoch 135; iter: 0; batch classifier loss: 0.160132; batch adversarial loss: 0.411365\n",
      "epoch 136; iter: 0; batch classifier loss: 0.174939; batch adversarial loss: 0.428742\n",
      "epoch 137; iter: 0; batch classifier loss: 0.168040; batch adversarial loss: 0.406435\n",
      "epoch 138; iter: 0; batch classifier loss: 0.137741; batch adversarial loss: 0.453956\n",
      "epoch 139; iter: 0; batch classifier loss: 0.136407; batch adversarial loss: 0.383528\n",
      "epoch 140; iter: 0; batch classifier loss: 0.138369; batch adversarial loss: 0.407554\n",
      "epoch 141; iter: 0; batch classifier loss: 0.109494; batch adversarial loss: 0.411383\n",
      "epoch 142; iter: 0; batch classifier loss: 0.100269; batch adversarial loss: 0.393619\n",
      "epoch 143; iter: 0; batch classifier loss: 0.052364; batch adversarial loss: 0.356449\n",
      "epoch 144; iter: 0; batch classifier loss: 0.081840; batch adversarial loss: 0.453423\n",
      "epoch 145; iter: 0; batch classifier loss: 0.087051; batch adversarial loss: 0.447865\n",
      "epoch 146; iter: 0; batch classifier loss: 0.057682; batch adversarial loss: 0.474365\n",
      "epoch 147; iter: 0; batch classifier loss: 0.062760; batch adversarial loss: 0.385253\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032406; batch adversarial loss: 0.445964\n",
      "epoch 149; iter: 0; batch classifier loss: 0.042746; batch adversarial loss: 0.374772\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038011; batch adversarial loss: 0.471049\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037947; batch adversarial loss: 0.475840\n",
      "epoch 152; iter: 0; batch classifier loss: 0.072811; batch adversarial loss: 0.389320\n",
      "epoch 153; iter: 0; batch classifier loss: 0.054439; batch adversarial loss: 0.558414\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044843; batch adversarial loss: 0.346122\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041121; batch adversarial loss: 0.564455\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022448; batch adversarial loss: 0.427272\n",
      "epoch 157; iter: 0; batch classifier loss: 0.044465; batch adversarial loss: 0.540650\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023775; batch adversarial loss: 0.506624\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049787; batch adversarial loss: 0.448437\n",
      "epoch 160; iter: 0; batch classifier loss: 0.064283; batch adversarial loss: 0.367522\n",
      "epoch 161; iter: 0; batch classifier loss: 0.079619; batch adversarial loss: 0.399911\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033006; batch adversarial loss: 0.392530\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012893; batch adversarial loss: 0.467635\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027451; batch adversarial loss: 0.478619\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035845; batch adversarial loss: 0.410315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.028573; batch adversarial loss: 0.455067\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016561; batch adversarial loss: 0.494807\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024827; batch adversarial loss: 0.403511\n",
      "epoch 169; iter: 0; batch classifier loss: 0.039218; batch adversarial loss: 0.473024\n",
      "epoch 170; iter: 0; batch classifier loss: 0.036775; batch adversarial loss: 0.526512\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026155; batch adversarial loss: 0.433176\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026415; batch adversarial loss: 0.443828\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022352; batch adversarial loss: 0.456139\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023362; batch adversarial loss: 0.520090\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016028; batch adversarial loss: 0.457459\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023834; batch adversarial loss: 0.448533\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014520; batch adversarial loss: 0.351922\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020347; batch adversarial loss: 0.418946\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027297; batch adversarial loss: 0.480941\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049807; batch adversarial loss: 0.461321\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023309; batch adversarial loss: 0.419535\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042700; batch adversarial loss: 0.533424\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033978; batch adversarial loss: 0.404773\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020325; batch adversarial loss: 0.459890\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020548; batch adversarial loss: 0.451885\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014758; batch adversarial loss: 0.527554\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031975; batch adversarial loss: 0.424461\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040218; batch adversarial loss: 0.305081\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028437; batch adversarial loss: 0.437320\n",
      "epoch 190; iter: 0; batch classifier loss: 0.033672; batch adversarial loss: 0.362311\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030870; batch adversarial loss: 0.466024\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005688; batch adversarial loss: 0.357502\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018793; batch adversarial loss: 0.362196\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014374; batch adversarial loss: 0.464534\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013467; batch adversarial loss: 0.420122\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017356; batch adversarial loss: 0.454627\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007144; batch adversarial loss: 0.495711\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020319; batch adversarial loss: 0.401957\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031494; batch adversarial loss: 0.447255\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720039; batch adversarial loss: 0.727138\n",
      "epoch 1; iter: 0; batch classifier loss: 0.490756; batch adversarial loss: 0.693344\n",
      "epoch 2; iter: 0; batch classifier loss: 0.395264; batch adversarial loss: 0.667855\n",
      "epoch 3; iter: 0; batch classifier loss: 0.395574; batch adversarial loss: 0.614998\n",
      "epoch 4; iter: 0; batch classifier loss: 0.325347; batch adversarial loss: 0.594402\n",
      "epoch 5; iter: 0; batch classifier loss: 0.259269; batch adversarial loss: 0.562520\n",
      "epoch 6; iter: 0; batch classifier loss: 0.333531; batch adversarial loss: 0.512084\n",
      "epoch 7; iter: 0; batch classifier loss: 0.337896; batch adversarial loss: 0.496655\n",
      "epoch 8; iter: 0; batch classifier loss: 0.274892; batch adversarial loss: 0.503916\n",
      "epoch 9; iter: 0; batch classifier loss: 0.366752; batch adversarial loss: 0.487181\n",
      "epoch 10; iter: 0; batch classifier loss: 0.212275; batch adversarial loss: 0.519283\n",
      "epoch 11; iter: 0; batch classifier loss: 0.266721; batch adversarial loss: 0.495334\n",
      "epoch 12; iter: 0; batch classifier loss: 0.200607; batch adversarial loss: 0.547314\n",
      "epoch 13; iter: 0; batch classifier loss: 0.187924; batch adversarial loss: 0.529300\n",
      "epoch 14; iter: 0; batch classifier loss: 0.147246; batch adversarial loss: 0.467597\n",
      "epoch 15; iter: 0; batch classifier loss: 0.185189; batch adversarial loss: 0.470594\n",
      "epoch 16; iter: 0; batch classifier loss: 0.204031; batch adversarial loss: 0.426405\n",
      "epoch 17; iter: 0; batch classifier loss: 0.179769; batch adversarial loss: 0.486756\n",
      "epoch 18; iter: 0; batch classifier loss: 0.144535; batch adversarial loss: 0.532247\n",
      "epoch 19; iter: 0; batch classifier loss: 0.146509; batch adversarial loss: 0.475598\n",
      "epoch 20; iter: 0; batch classifier loss: 0.176630; batch adversarial loss: 0.497670\n",
      "epoch 21; iter: 0; batch classifier loss: 0.189478; batch adversarial loss: 0.488098\n",
      "epoch 22; iter: 0; batch classifier loss: 0.166658; batch adversarial loss: 0.436766\n",
      "epoch 23; iter: 0; batch classifier loss: 0.111344; batch adversarial loss: 0.419759\n",
      "epoch 24; iter: 0; batch classifier loss: 0.138231; batch adversarial loss: 0.536697\n",
      "epoch 25; iter: 0; batch classifier loss: 0.087082; batch adversarial loss: 0.459908\n",
      "epoch 26; iter: 0; batch classifier loss: 0.140727; batch adversarial loss: 0.406073\n",
      "epoch 27; iter: 0; batch classifier loss: 0.138041; batch adversarial loss: 0.485038\n",
      "epoch 28; iter: 0; batch classifier loss: 0.085569; batch adversarial loss: 0.465980\n",
      "epoch 29; iter: 0; batch classifier loss: 0.140051; batch adversarial loss: 0.407447\n",
      "epoch 30; iter: 0; batch classifier loss: 0.134559; batch adversarial loss: 0.455711\n",
      "epoch 31; iter: 0; batch classifier loss: 0.224159; batch adversarial loss: 0.505140\n",
      "epoch 32; iter: 0; batch classifier loss: 0.193241; batch adversarial loss: 0.524411\n",
      "epoch 33; iter: 0; batch classifier loss: 0.299613; batch adversarial loss: 0.589754\n",
      "epoch 34; iter: 0; batch classifier loss: 0.218200; batch adversarial loss: 0.570103\n",
      "epoch 35; iter: 0; batch classifier loss: 0.224329; batch adversarial loss: 0.512719\n",
      "epoch 36; iter: 0; batch classifier loss: 0.284428; batch adversarial loss: 0.472486\n",
      "epoch 37; iter: 0; batch classifier loss: 0.159031; batch adversarial loss: 0.459135\n",
      "epoch 38; iter: 0; batch classifier loss: 0.130581; batch adversarial loss: 0.517873\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107034; batch adversarial loss: 0.424776\n",
      "epoch 40; iter: 0; batch classifier loss: 0.078503; batch adversarial loss: 0.496481\n",
      "epoch 41; iter: 0; batch classifier loss: 0.101058; batch adversarial loss: 0.453321\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088533; batch adversarial loss: 0.381234\n",
      "epoch 43; iter: 0; batch classifier loss: 0.113016; batch adversarial loss: 0.492946\n",
      "epoch 44; iter: 0; batch classifier loss: 0.113733; batch adversarial loss: 0.401520\n",
      "epoch 45; iter: 0; batch classifier loss: 0.069569; batch adversarial loss: 0.391803\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086705; batch adversarial loss: 0.476531\n",
      "epoch 47; iter: 0; batch classifier loss: 0.085174; batch adversarial loss: 0.361149\n",
      "epoch 48; iter: 0; batch classifier loss: 0.046337; batch adversarial loss: 0.632546\n",
      "epoch 49; iter: 0; batch classifier loss: 0.121945; batch adversarial loss: 0.352597\n",
      "epoch 50; iter: 0; batch classifier loss: 0.051352; batch adversarial loss: 0.460305\n",
      "epoch 51; iter: 0; batch classifier loss: 0.111267; batch adversarial loss: 0.421967\n",
      "epoch 52; iter: 0; batch classifier loss: 0.069981; batch adversarial loss: 0.502371\n",
      "epoch 53; iter: 0; batch classifier loss: 0.070931; batch adversarial loss: 0.394636\n",
      "epoch 54; iter: 0; batch classifier loss: 0.086842; batch adversarial loss: 0.378786\n",
      "epoch 55; iter: 0; batch classifier loss: 0.026590; batch adversarial loss: 0.400162\n",
      "epoch 56; iter: 0; batch classifier loss: 0.049513; batch adversarial loss: 0.424727\n",
      "epoch 57; iter: 0; batch classifier loss: 0.123992; batch adversarial loss: 0.367139\n",
      "epoch 58; iter: 0; batch classifier loss: 0.105753; batch adversarial loss: 0.489115\n",
      "epoch 59; iter: 0; batch classifier loss: 0.053581; batch adversarial loss: 0.511646\n",
      "epoch 60; iter: 0; batch classifier loss: 0.050581; batch adversarial loss: 0.450161\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113190; batch adversarial loss: 0.485560\n",
      "epoch 62; iter: 0; batch classifier loss: 0.051298; batch adversarial loss: 0.488478\n",
      "epoch 63; iter: 0; batch classifier loss: 0.082718; batch adversarial loss: 0.544345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.048253; batch adversarial loss: 0.541341\n",
      "epoch 65; iter: 0; batch classifier loss: 0.060347; batch adversarial loss: 0.391738\n",
      "epoch 66; iter: 0; batch classifier loss: 0.043104; batch adversarial loss: 0.474278\n",
      "epoch 67; iter: 0; batch classifier loss: 0.099489; batch adversarial loss: 0.482942\n",
      "epoch 68; iter: 0; batch classifier loss: 0.090586; batch adversarial loss: 0.440435\n",
      "epoch 69; iter: 0; batch classifier loss: 0.048362; batch adversarial loss: 0.470613\n",
      "epoch 70; iter: 0; batch classifier loss: 0.081268; batch adversarial loss: 0.406611\n",
      "epoch 71; iter: 0; batch classifier loss: 0.069913; batch adversarial loss: 0.440849\n",
      "epoch 72; iter: 0; batch classifier loss: 0.061763; batch adversarial loss: 0.415826\n",
      "epoch 73; iter: 0; batch classifier loss: 0.033097; batch adversarial loss: 0.450814\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076988; batch adversarial loss: 0.461957\n",
      "epoch 75; iter: 0; batch classifier loss: 0.094498; batch adversarial loss: 0.417667\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075550; batch adversarial loss: 0.508417\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050765; batch adversarial loss: 0.413373\n",
      "epoch 78; iter: 0; batch classifier loss: 0.068756; batch adversarial loss: 0.527615\n",
      "epoch 79; iter: 0; batch classifier loss: 0.048589; batch adversarial loss: 0.384047\n",
      "epoch 80; iter: 0; batch classifier loss: 0.047376; batch adversarial loss: 0.422062\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067800; batch adversarial loss: 0.369197\n",
      "epoch 82; iter: 0; batch classifier loss: 0.085472; batch adversarial loss: 0.431200\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085275; batch adversarial loss: 0.383860\n",
      "epoch 84; iter: 0; batch classifier loss: 0.037164; batch adversarial loss: 0.438975\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061332; batch adversarial loss: 0.419033\n",
      "epoch 86; iter: 0; batch classifier loss: 0.034413; batch adversarial loss: 0.438905\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049032; batch adversarial loss: 0.430893\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070668; batch adversarial loss: 0.448919\n",
      "epoch 89; iter: 0; batch classifier loss: 0.108780; batch adversarial loss: 0.462196\n",
      "epoch 90; iter: 0; batch classifier loss: 0.077864; batch adversarial loss: 0.420697\n",
      "epoch 91; iter: 0; batch classifier loss: 0.039219; batch adversarial loss: 0.479667\n",
      "epoch 92; iter: 0; batch classifier loss: 0.039378; batch adversarial loss: 0.412533\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065397; batch adversarial loss: 0.424761\n",
      "epoch 94; iter: 0; batch classifier loss: 0.060504; batch adversarial loss: 0.446879\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045065; batch adversarial loss: 0.505581\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051557; batch adversarial loss: 0.421328\n",
      "epoch 97; iter: 0; batch classifier loss: 0.022641; batch adversarial loss: 0.444919\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036495; batch adversarial loss: 0.395132\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047468; batch adversarial loss: 0.359516\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060639; batch adversarial loss: 0.469394\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042357; batch adversarial loss: 0.450299\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036973; batch adversarial loss: 0.550758\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052906; batch adversarial loss: 0.489910\n",
      "epoch 104; iter: 0; batch classifier loss: 0.014534; batch adversarial loss: 0.454974\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038827; batch adversarial loss: 0.387934\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053187; batch adversarial loss: 0.446061\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051242; batch adversarial loss: 0.570164\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033659; batch adversarial loss: 0.473254\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043557; batch adversarial loss: 0.463332\n",
      "epoch 110; iter: 0; batch classifier loss: 0.013842; batch adversarial loss: 0.453700\n",
      "epoch 111; iter: 0; batch classifier loss: 0.052697; batch adversarial loss: 0.430054\n",
      "epoch 112; iter: 0; batch classifier loss: 0.018685; batch adversarial loss: 0.381291\n",
      "epoch 113; iter: 0; batch classifier loss: 0.017764; batch adversarial loss: 0.472210\n",
      "epoch 114; iter: 0; batch classifier loss: 0.024641; batch adversarial loss: 0.298436\n",
      "epoch 115; iter: 0; batch classifier loss: 0.021786; batch adversarial loss: 0.413017\n",
      "epoch 116; iter: 0; batch classifier loss: 0.011067; batch adversarial loss: 0.531017\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044725; batch adversarial loss: 0.437785\n",
      "epoch 118; iter: 0; batch classifier loss: 0.027346; batch adversarial loss: 0.479798\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034076; batch adversarial loss: 0.458006\n",
      "epoch 120; iter: 0; batch classifier loss: 0.059824; batch adversarial loss: 0.399185\n",
      "epoch 121; iter: 0; batch classifier loss: 0.017138; batch adversarial loss: 0.402616\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046869; batch adversarial loss: 0.377246\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036760; batch adversarial loss: 0.427283\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022621; batch adversarial loss: 0.443397\n",
      "epoch 125; iter: 0; batch classifier loss: 0.014676; batch adversarial loss: 0.378128\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027548; batch adversarial loss: 0.349998\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023946; batch adversarial loss: 0.392245\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040734; batch adversarial loss: 0.436340\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037711; batch adversarial loss: 0.351559\n",
      "epoch 130; iter: 0; batch classifier loss: 0.067834; batch adversarial loss: 0.521634\n",
      "epoch 131; iter: 0; batch classifier loss: 0.016935; batch adversarial loss: 0.420767\n",
      "epoch 132; iter: 0; batch classifier loss: 0.017952; batch adversarial loss: 0.376674\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030609; batch adversarial loss: 0.530505\n",
      "epoch 134; iter: 0; batch classifier loss: 0.054091; batch adversarial loss: 0.438612\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018033; batch adversarial loss: 0.418362\n",
      "epoch 136; iter: 0; batch classifier loss: 0.048847; batch adversarial loss: 0.364950\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037345; batch adversarial loss: 0.403805\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038637; batch adversarial loss: 0.493525\n",
      "epoch 139; iter: 0; batch classifier loss: 0.052372; batch adversarial loss: 0.441723\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031814; batch adversarial loss: 0.486411\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022565; batch adversarial loss: 0.380165\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014483; batch adversarial loss: 0.498564\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022905; batch adversarial loss: 0.460782\n",
      "epoch 144; iter: 0; batch classifier loss: 0.008638; batch adversarial loss: 0.470257\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016346; batch adversarial loss: 0.429136\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020300; batch adversarial loss: 0.353398\n",
      "epoch 147; iter: 0; batch classifier loss: 0.012426; batch adversarial loss: 0.433078\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018073; batch adversarial loss: 0.476795\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034933; batch adversarial loss: 0.409036\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022372; batch adversarial loss: 0.472423\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025644; batch adversarial loss: 0.432284\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019912; batch adversarial loss: 0.426855\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032981; batch adversarial loss: 0.485644\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013863; batch adversarial loss: 0.366952\n",
      "epoch 155; iter: 0; batch classifier loss: 0.048224; batch adversarial loss: 0.417450\n",
      "epoch 156; iter: 0; batch classifier loss: 0.010347; batch adversarial loss: 0.415401\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033945; batch adversarial loss: 0.469355\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021456; batch adversarial loss: 0.370545\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019349; batch adversarial loss: 0.352885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.026319; batch adversarial loss: 0.395575\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011171; batch adversarial loss: 0.422392\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033644; batch adversarial loss: 0.485553\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034640; batch adversarial loss: 0.439616\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022057; batch adversarial loss: 0.383339\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025433; batch adversarial loss: 0.434470\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022002; batch adversarial loss: 0.480279\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033554; batch adversarial loss: 0.459600\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015806; batch adversarial loss: 0.496076\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034960; batch adversarial loss: 0.368521\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022188; batch adversarial loss: 0.327230\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022224; batch adversarial loss: 0.488788\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008964; batch adversarial loss: 0.428990\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019679; batch adversarial loss: 0.507794\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024918; batch adversarial loss: 0.438945\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034637; batch adversarial loss: 0.406757\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024042; batch adversarial loss: 0.416578\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013539; batch adversarial loss: 0.327540\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009429; batch adversarial loss: 0.426759\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008270; batch adversarial loss: 0.489310\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008499; batch adversarial loss: 0.440239\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008688; batch adversarial loss: 0.494833\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019898; batch adversarial loss: 0.379064\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019612; batch adversarial loss: 0.451701\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032655; batch adversarial loss: 0.441705\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010847; batch adversarial loss: 0.421236\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008223; batch adversarial loss: 0.412276\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036025; batch adversarial loss: 0.491566\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010090; batch adversarial loss: 0.418032\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007259; batch adversarial loss: 0.512962\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034417; batch adversarial loss: 0.487014\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018051; batch adversarial loss: 0.408104\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027055; batch adversarial loss: 0.506231\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018826; batch adversarial loss: 0.399081\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013524; batch adversarial loss: 0.417043\n",
      "epoch 195; iter: 0; batch classifier loss: 0.037590; batch adversarial loss: 0.507624\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019378; batch adversarial loss: 0.494295\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014242; batch adversarial loss: 0.524530\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023462; batch adversarial loss: 0.396332\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017281; batch adversarial loss: 0.491903\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707661; batch adversarial loss: 0.910248\n",
      "epoch 1; iter: 0; batch classifier loss: 0.470834; batch adversarial loss: 0.943047\n",
      "epoch 2; iter: 0; batch classifier loss: 0.337710; batch adversarial loss: 0.859503\n",
      "epoch 3; iter: 0; batch classifier loss: 0.431826; batch adversarial loss: 0.789023\n",
      "epoch 4; iter: 0; batch classifier loss: 0.348652; batch adversarial loss: 0.789488\n",
      "epoch 5; iter: 0; batch classifier loss: 0.384412; batch adversarial loss: 0.704021\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340731; batch adversarial loss: 0.680363\n",
      "epoch 7; iter: 0; batch classifier loss: 0.286386; batch adversarial loss: 0.634012\n",
      "epoch 8; iter: 0; batch classifier loss: 0.253616; batch adversarial loss: 0.593821\n",
      "epoch 9; iter: 0; batch classifier loss: 0.308900; batch adversarial loss: 0.602194\n",
      "epoch 10; iter: 0; batch classifier loss: 0.368239; batch adversarial loss: 0.572262\n",
      "epoch 11; iter: 0; batch classifier loss: 0.225009; batch adversarial loss: 0.562371\n",
      "epoch 12; iter: 0; batch classifier loss: 0.213716; batch adversarial loss: 0.548312\n",
      "epoch 13; iter: 0; batch classifier loss: 0.226969; batch adversarial loss: 0.521814\n",
      "epoch 14; iter: 0; batch classifier loss: 0.245513; batch adversarial loss: 0.540118\n",
      "epoch 15; iter: 0; batch classifier loss: 0.197156; batch adversarial loss: 0.545286\n",
      "epoch 16; iter: 0; batch classifier loss: 0.194859; batch adversarial loss: 0.536740\n",
      "epoch 17; iter: 0; batch classifier loss: 0.205660; batch adversarial loss: 0.490833\n",
      "epoch 18; iter: 0; batch classifier loss: 0.229608; batch adversarial loss: 0.471520\n",
      "epoch 19; iter: 0; batch classifier loss: 0.291729; batch adversarial loss: 0.472674\n",
      "epoch 20; iter: 0; batch classifier loss: 0.297047; batch adversarial loss: 0.440679\n",
      "epoch 21; iter: 0; batch classifier loss: 0.266079; batch adversarial loss: 0.538510\n",
      "epoch 22; iter: 0; batch classifier loss: 0.305467; batch adversarial loss: 0.438456\n",
      "epoch 23; iter: 0; batch classifier loss: 0.299592; batch adversarial loss: 0.401047\n",
      "epoch 24; iter: 0; batch classifier loss: 0.213687; batch adversarial loss: 0.459732\n",
      "epoch 25; iter: 0; batch classifier loss: 0.222663; batch adversarial loss: 0.364935\n",
      "epoch 26; iter: 0; batch classifier loss: 0.240465; batch adversarial loss: 0.490769\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152686; batch adversarial loss: 0.379530\n",
      "epoch 28; iter: 0; batch classifier loss: 0.193735; batch adversarial loss: 0.428374\n",
      "epoch 29; iter: 0; batch classifier loss: 0.165979; batch adversarial loss: 0.425045\n",
      "epoch 30; iter: 0; batch classifier loss: 0.166854; batch adversarial loss: 0.420211\n",
      "epoch 31; iter: 0; batch classifier loss: 0.152140; batch adversarial loss: 0.483564\n",
      "epoch 32; iter: 0; batch classifier loss: 0.183694; batch adversarial loss: 0.421525\n",
      "epoch 33; iter: 0; batch classifier loss: 0.218566; batch adversarial loss: 0.456404\n",
      "epoch 34; iter: 0; batch classifier loss: 0.145670; batch adversarial loss: 0.461864\n",
      "epoch 35; iter: 0; batch classifier loss: 0.153493; batch adversarial loss: 0.341555\n",
      "epoch 36; iter: 0; batch classifier loss: 0.136932; batch adversarial loss: 0.452002\n",
      "epoch 37; iter: 0; batch classifier loss: 0.199960; batch adversarial loss: 0.393474\n",
      "epoch 38; iter: 0; batch classifier loss: 0.105939; batch adversarial loss: 0.437994\n",
      "epoch 39; iter: 0; batch classifier loss: 0.153154; batch adversarial loss: 0.398102\n",
      "epoch 40; iter: 0; batch classifier loss: 0.155167; batch adversarial loss: 0.331440\n",
      "epoch 41; iter: 0; batch classifier loss: 0.109002; batch adversarial loss: 0.422641\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131834; batch adversarial loss: 0.434015\n",
      "epoch 43; iter: 0; batch classifier loss: 0.155463; batch adversarial loss: 0.454932\n",
      "epoch 44; iter: 0; batch classifier loss: 0.133697; batch adversarial loss: 0.479881\n",
      "epoch 45; iter: 0; batch classifier loss: 0.144441; batch adversarial loss: 0.368644\n",
      "epoch 46; iter: 0; batch classifier loss: 0.124297; batch adversarial loss: 0.426050\n",
      "epoch 47; iter: 0; batch classifier loss: 0.082050; batch adversarial loss: 0.433272\n",
      "epoch 48; iter: 0; batch classifier loss: 0.096358; batch adversarial loss: 0.436164\n",
      "epoch 49; iter: 0; batch classifier loss: 0.095525; batch adversarial loss: 0.377357\n",
      "epoch 50; iter: 0; batch classifier loss: 0.121649; batch adversarial loss: 0.340212\n",
      "epoch 51; iter: 0; batch classifier loss: 0.120924; batch adversarial loss: 0.397231\n",
      "epoch 52; iter: 0; batch classifier loss: 0.125867; batch adversarial loss: 0.463970\n",
      "epoch 53; iter: 0; batch classifier loss: 0.150765; batch adversarial loss: 0.463916\n",
      "epoch 54; iter: 0; batch classifier loss: 0.127427; batch adversarial loss: 0.442473\n",
      "epoch 55; iter: 0; batch classifier loss: 0.124020; batch adversarial loss: 0.423486\n",
      "epoch 56; iter: 0; batch classifier loss: 0.118627; batch adversarial loss: 0.435042\n",
      "epoch 57; iter: 0; batch classifier loss: 0.099670; batch adversarial loss: 0.429923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.104004; batch adversarial loss: 0.507826\n",
      "epoch 59; iter: 0; batch classifier loss: 0.080107; batch adversarial loss: 0.474634\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076937; batch adversarial loss: 0.378469\n",
      "epoch 61; iter: 0; batch classifier loss: 0.072702; batch adversarial loss: 0.404741\n",
      "epoch 62; iter: 0; batch classifier loss: 0.071014; batch adversarial loss: 0.365171\n",
      "epoch 63; iter: 0; batch classifier loss: 0.055184; batch adversarial loss: 0.364843\n",
      "epoch 64; iter: 0; batch classifier loss: 0.058455; batch adversarial loss: 0.370122\n",
      "epoch 65; iter: 0; batch classifier loss: 0.129125; batch adversarial loss: 0.467018\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088432; batch adversarial loss: 0.500021\n",
      "epoch 67; iter: 0; batch classifier loss: 0.074415; batch adversarial loss: 0.374438\n",
      "epoch 68; iter: 0; batch classifier loss: 0.109167; batch adversarial loss: 0.368302\n",
      "epoch 69; iter: 0; batch classifier loss: 0.113412; batch adversarial loss: 0.408825\n",
      "epoch 70; iter: 0; batch classifier loss: 0.099641; batch adversarial loss: 0.388502\n",
      "epoch 71; iter: 0; batch classifier loss: 0.105986; batch adversarial loss: 0.456107\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080010; batch adversarial loss: 0.528964\n",
      "epoch 73; iter: 0; batch classifier loss: 0.082734; batch adversarial loss: 0.439254\n",
      "epoch 74; iter: 0; batch classifier loss: 0.093025; batch adversarial loss: 0.451139\n",
      "epoch 75; iter: 0; batch classifier loss: 0.052418; batch adversarial loss: 0.403745\n",
      "epoch 76; iter: 0; batch classifier loss: 0.053431; batch adversarial loss: 0.392957\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076367; batch adversarial loss: 0.375838\n",
      "epoch 78; iter: 0; batch classifier loss: 0.115652; batch adversarial loss: 0.481295\n",
      "epoch 79; iter: 0; batch classifier loss: 0.049215; batch adversarial loss: 0.384746\n",
      "epoch 80; iter: 0; batch classifier loss: 0.074389; batch adversarial loss: 0.415896\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075131; batch adversarial loss: 0.393672\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062884; batch adversarial loss: 0.490767\n",
      "epoch 83; iter: 0; batch classifier loss: 0.094979; batch adversarial loss: 0.499647\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070458; batch adversarial loss: 0.400377\n",
      "epoch 85; iter: 0; batch classifier loss: 0.060461; batch adversarial loss: 0.380009\n",
      "epoch 86; iter: 0; batch classifier loss: 0.123827; batch adversarial loss: 0.450016\n",
      "epoch 87; iter: 0; batch classifier loss: 0.083729; batch adversarial loss: 0.457935\n",
      "epoch 88; iter: 0; batch classifier loss: 0.088004; batch adversarial loss: 0.388468\n",
      "epoch 89; iter: 0; batch classifier loss: 0.087932; batch adversarial loss: 0.403450\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064219; batch adversarial loss: 0.413491\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052687; batch adversarial loss: 0.407334\n",
      "epoch 92; iter: 0; batch classifier loss: 0.067214; batch adversarial loss: 0.413473\n",
      "epoch 93; iter: 0; batch classifier loss: 0.088306; batch adversarial loss: 0.382505\n",
      "epoch 94; iter: 0; batch classifier loss: 0.076982; batch adversarial loss: 0.369342\n",
      "epoch 95; iter: 0; batch classifier loss: 0.072392; batch adversarial loss: 0.437012\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070363; batch adversarial loss: 0.422017\n",
      "epoch 97; iter: 0; batch classifier loss: 0.101116; batch adversarial loss: 0.367316\n",
      "epoch 98; iter: 0; batch classifier loss: 0.064131; batch adversarial loss: 0.427492\n",
      "epoch 99; iter: 0; batch classifier loss: 0.083133; batch adversarial loss: 0.493801\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045445; batch adversarial loss: 0.413596\n",
      "epoch 101; iter: 0; batch classifier loss: 0.094568; batch adversarial loss: 0.446299\n",
      "epoch 102; iter: 0; batch classifier loss: 0.101161; batch adversarial loss: 0.456388\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054546; batch adversarial loss: 0.408899\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047332; batch adversarial loss: 0.357822\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050756; batch adversarial loss: 0.420731\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041237; batch adversarial loss: 0.495043\n",
      "epoch 107; iter: 0; batch classifier loss: 0.103032; batch adversarial loss: 0.430687\n",
      "epoch 108; iter: 0; batch classifier loss: 0.072819; batch adversarial loss: 0.477034\n",
      "epoch 109; iter: 0; batch classifier loss: 0.074214; batch adversarial loss: 0.378401\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047747; batch adversarial loss: 0.482661\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061537; batch adversarial loss: 0.485200\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044199; batch adversarial loss: 0.470314\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049544; batch adversarial loss: 0.444476\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041784; batch adversarial loss: 0.371808\n",
      "epoch 115; iter: 0; batch classifier loss: 0.047791; batch adversarial loss: 0.458317\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060070; batch adversarial loss: 0.336478\n",
      "epoch 117; iter: 0; batch classifier loss: 0.087318; batch adversarial loss: 0.399158\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057248; batch adversarial loss: 0.387726\n",
      "epoch 119; iter: 0; batch classifier loss: 0.068738; batch adversarial loss: 0.413945\n",
      "epoch 120; iter: 0; batch classifier loss: 0.094093; batch adversarial loss: 0.396299\n",
      "epoch 121; iter: 0; batch classifier loss: 0.077421; batch adversarial loss: 0.476353\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046668; batch adversarial loss: 0.491052\n",
      "epoch 123; iter: 0; batch classifier loss: 0.060692; batch adversarial loss: 0.388630\n",
      "epoch 124; iter: 0; batch classifier loss: 0.065786; batch adversarial loss: 0.447699\n",
      "epoch 125; iter: 0; batch classifier loss: 0.059681; batch adversarial loss: 0.359280\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036740; batch adversarial loss: 0.397904\n",
      "epoch 127; iter: 0; batch classifier loss: 0.068588; batch adversarial loss: 0.452603\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063286; batch adversarial loss: 0.423333\n",
      "epoch 129; iter: 0; batch classifier loss: 0.063945; batch adversarial loss: 0.412267\n",
      "epoch 130; iter: 0; batch classifier loss: 0.064354; batch adversarial loss: 0.413202\n",
      "epoch 131; iter: 0; batch classifier loss: 0.078313; batch adversarial loss: 0.388608\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035914; batch adversarial loss: 0.424668\n",
      "epoch 133; iter: 0; batch classifier loss: 0.081477; batch adversarial loss: 0.425809\n",
      "epoch 134; iter: 0; batch classifier loss: 0.064635; batch adversarial loss: 0.436364\n",
      "epoch 135; iter: 0; batch classifier loss: 0.081660; batch adversarial loss: 0.397030\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034914; batch adversarial loss: 0.319779\n",
      "epoch 137; iter: 0; batch classifier loss: 0.071710; batch adversarial loss: 0.460188\n",
      "epoch 138; iter: 0; batch classifier loss: 0.068519; batch adversarial loss: 0.468142\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044224; batch adversarial loss: 0.451982\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041540; batch adversarial loss: 0.412887\n",
      "epoch 141; iter: 0; batch classifier loss: 0.050879; batch adversarial loss: 0.456958\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022164; batch adversarial loss: 0.309384\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032470; batch adversarial loss: 0.428173\n",
      "epoch 144; iter: 0; batch classifier loss: 0.057037; batch adversarial loss: 0.508898\n",
      "epoch 145; iter: 0; batch classifier loss: 0.055520; batch adversarial loss: 0.432666\n",
      "epoch 146; iter: 0; batch classifier loss: 0.049378; batch adversarial loss: 0.392024\n",
      "epoch 147; iter: 0; batch classifier loss: 0.068212; batch adversarial loss: 0.505480\n",
      "epoch 148; iter: 0; batch classifier loss: 0.055502; batch adversarial loss: 0.375331\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029555; batch adversarial loss: 0.416039\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042040; batch adversarial loss: 0.474918\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044941; batch adversarial loss: 0.473010\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038502; batch adversarial loss: 0.416363\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019309; batch adversarial loss: 0.437353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.032645; batch adversarial loss: 0.482455\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037433; batch adversarial loss: 0.470103\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030503; batch adversarial loss: 0.440025\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018639; batch adversarial loss: 0.372432\n",
      "epoch 158; iter: 0; batch classifier loss: 0.052929; batch adversarial loss: 0.445101\n",
      "epoch 159; iter: 0; batch classifier loss: 0.054157; batch adversarial loss: 0.456888\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020251; batch adversarial loss: 0.462722\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036572; batch adversarial loss: 0.523224\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032982; batch adversarial loss: 0.400422\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036296; batch adversarial loss: 0.479693\n",
      "epoch 164; iter: 0; batch classifier loss: 0.043688; batch adversarial loss: 0.415757\n",
      "epoch 165; iter: 0; batch classifier loss: 0.043803; batch adversarial loss: 0.400938\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026757; batch adversarial loss: 0.523220\n",
      "epoch 167; iter: 0; batch classifier loss: 0.043426; batch adversarial loss: 0.531192\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028622; batch adversarial loss: 0.481641\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019595; batch adversarial loss: 0.417171\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014562; batch adversarial loss: 0.335757\n",
      "epoch 171; iter: 0; batch classifier loss: 0.077363; batch adversarial loss: 0.436378\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028384; batch adversarial loss: 0.490105\n",
      "epoch 173; iter: 0; batch classifier loss: 0.067517; batch adversarial loss: 0.490266\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021362; batch adversarial loss: 0.459991\n",
      "epoch 175; iter: 0; batch classifier loss: 0.099122; batch adversarial loss: 0.681957\n",
      "epoch 176; iter: 0; batch classifier loss: 0.126349; batch adversarial loss: 0.637811\n",
      "epoch 177; iter: 0; batch classifier loss: 0.136384; batch adversarial loss: 0.644329\n",
      "epoch 178; iter: 0; batch classifier loss: 0.074311; batch adversarial loss: 0.559779\n",
      "epoch 179; iter: 0; batch classifier loss: 0.072140; batch adversarial loss: 0.574338\n",
      "epoch 180; iter: 0; batch classifier loss: 0.106405; batch adversarial loss: 0.595814\n",
      "epoch 181; iter: 0; batch classifier loss: 0.105910; batch adversarial loss: 0.575435\n",
      "epoch 182; iter: 0; batch classifier loss: 0.142143; batch adversarial loss: 0.726485\n",
      "epoch 183; iter: 0; batch classifier loss: 0.107362; batch adversarial loss: 0.615254\n",
      "epoch 184; iter: 0; batch classifier loss: 0.138472; batch adversarial loss: 0.776402\n",
      "epoch 185; iter: 0; batch classifier loss: 0.196325; batch adversarial loss: 0.660318\n",
      "epoch 186; iter: 0; batch classifier loss: 0.090163; batch adversarial loss: 0.514281\n",
      "epoch 187; iter: 0; batch classifier loss: 0.114437; batch adversarial loss: 0.442041\n",
      "epoch 188; iter: 0; batch classifier loss: 0.122901; batch adversarial loss: 0.592981\n",
      "epoch 189; iter: 0; batch classifier loss: 0.180928; batch adversarial loss: 0.694214\n",
      "epoch 190; iter: 0; batch classifier loss: 0.120634; batch adversarial loss: 0.496474\n",
      "epoch 191; iter: 0; batch classifier loss: 0.118746; batch adversarial loss: 0.667786\n",
      "epoch 192; iter: 0; batch classifier loss: 0.222412; batch adversarial loss: 0.862878\n",
      "epoch 193; iter: 0; batch classifier loss: 0.141926; batch adversarial loss: 0.662829\n",
      "epoch 194; iter: 0; batch classifier loss: 0.124504; batch adversarial loss: 0.545945\n",
      "epoch 195; iter: 0; batch classifier loss: 0.156969; batch adversarial loss: 0.646360\n",
      "epoch 196; iter: 0; batch classifier loss: 0.144662; batch adversarial loss: 0.626868\n",
      "epoch 197; iter: 0; batch classifier loss: 0.213465; batch adversarial loss: 0.666705\n",
      "epoch 198; iter: 0; batch classifier loss: 0.094868; batch adversarial loss: 0.439844\n",
      "epoch 199; iter: 0; batch classifier loss: 0.172174; batch adversarial loss: 0.625405\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717660; batch adversarial loss: 0.696710\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599382; batch adversarial loss: 0.658855\n",
      "epoch 2; iter: 0; batch classifier loss: 0.449112; batch adversarial loss: 0.621813\n",
      "epoch 3; iter: 0; batch classifier loss: 0.460916; batch adversarial loss: 0.606274\n",
      "epoch 4; iter: 0; batch classifier loss: 0.486169; batch adversarial loss: 0.589325\n",
      "epoch 5; iter: 0; batch classifier loss: 0.420115; batch adversarial loss: 0.576130\n",
      "epoch 6; iter: 0; batch classifier loss: 0.449180; batch adversarial loss: 0.549340\n",
      "epoch 7; iter: 0; batch classifier loss: 0.400840; batch adversarial loss: 0.600507\n",
      "epoch 8; iter: 0; batch classifier loss: 0.377156; batch adversarial loss: 0.577053\n",
      "epoch 9; iter: 0; batch classifier loss: 0.402046; batch adversarial loss: 0.589443\n",
      "epoch 10; iter: 0; batch classifier loss: 0.388444; batch adversarial loss: 0.504750\n",
      "epoch 11; iter: 0; batch classifier loss: 0.464247; batch adversarial loss: 0.495358\n",
      "epoch 12; iter: 0; batch classifier loss: 0.462394; batch adversarial loss: 0.502047\n",
      "epoch 13; iter: 0; batch classifier loss: 0.418151; batch adversarial loss: 0.446475\n",
      "epoch 14; iter: 0; batch classifier loss: 0.456696; batch adversarial loss: 0.530996\n",
      "epoch 15; iter: 0; batch classifier loss: 0.383426; batch adversarial loss: 0.475991\n",
      "epoch 16; iter: 0; batch classifier loss: 0.256478; batch adversarial loss: 0.454628\n",
      "epoch 17; iter: 0; batch classifier loss: 0.382242; batch adversarial loss: 0.511376\n",
      "epoch 18; iter: 0; batch classifier loss: 0.444155; batch adversarial loss: 0.362559\n",
      "epoch 19; iter: 0; batch classifier loss: 0.385508; batch adversarial loss: 0.463308\n",
      "epoch 20; iter: 0; batch classifier loss: 0.378590; batch adversarial loss: 0.479739\n",
      "epoch 21; iter: 0; batch classifier loss: 0.298305; batch adversarial loss: 0.523125\n",
      "epoch 22; iter: 0; batch classifier loss: 0.343434; batch adversarial loss: 0.470789\n",
      "epoch 23; iter: 0; batch classifier loss: 0.322831; batch adversarial loss: 0.491541\n",
      "epoch 24; iter: 0; batch classifier loss: 0.298886; batch adversarial loss: 0.527220\n",
      "epoch 25; iter: 0; batch classifier loss: 0.332443; batch adversarial loss: 0.414662\n",
      "epoch 26; iter: 0; batch classifier loss: 0.303399; batch adversarial loss: 0.454243\n",
      "epoch 27; iter: 0; batch classifier loss: 0.260299; batch adversarial loss: 0.561398\n",
      "epoch 28; iter: 0; batch classifier loss: 0.304269; batch adversarial loss: 0.320580\n",
      "epoch 29; iter: 0; batch classifier loss: 0.238005; batch adversarial loss: 0.413124\n",
      "epoch 30; iter: 0; batch classifier loss: 0.324308; batch adversarial loss: 0.472384\n",
      "epoch 31; iter: 0; batch classifier loss: 0.328711; batch adversarial loss: 0.489342\n",
      "epoch 32; iter: 0; batch classifier loss: 0.216056; batch adversarial loss: 0.507858\n",
      "epoch 33; iter: 0; batch classifier loss: 0.290962; batch adversarial loss: 0.424619\n",
      "epoch 34; iter: 0; batch classifier loss: 0.199522; batch adversarial loss: 0.572847\n",
      "epoch 35; iter: 0; batch classifier loss: 0.216840; batch adversarial loss: 0.513154\n",
      "epoch 36; iter: 0; batch classifier loss: 0.322013; batch adversarial loss: 0.479681\n",
      "epoch 37; iter: 0; batch classifier loss: 0.348653; batch adversarial loss: 0.398362\n",
      "epoch 38; iter: 0; batch classifier loss: 0.338370; batch adversarial loss: 0.441447\n",
      "epoch 39; iter: 0; batch classifier loss: 0.286740; batch adversarial loss: 0.456626\n",
      "epoch 40; iter: 0; batch classifier loss: 0.230934; batch adversarial loss: 0.468520\n",
      "epoch 41; iter: 0; batch classifier loss: 0.298771; batch adversarial loss: 0.426990\n",
      "epoch 42; iter: 0; batch classifier loss: 0.316109; batch adversarial loss: 0.484061\n",
      "epoch 43; iter: 0; batch classifier loss: 0.246968; batch adversarial loss: 0.363234\n",
      "epoch 44; iter: 0; batch classifier loss: 0.258130; batch adversarial loss: 0.440480\n",
      "epoch 45; iter: 0; batch classifier loss: 0.268049; batch adversarial loss: 0.401014\n",
      "epoch 46; iter: 0; batch classifier loss: 0.283272; batch adversarial loss: 0.425572\n",
      "epoch 47; iter: 0; batch classifier loss: 0.384580; batch adversarial loss: 0.409121\n",
      "epoch 48; iter: 0; batch classifier loss: 0.270879; batch adversarial loss: 0.427663\n",
      "epoch 49; iter: 0; batch classifier loss: 0.284511; batch adversarial loss: 0.349545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.426643; batch adversarial loss: 0.435667\n",
      "epoch 51; iter: 0; batch classifier loss: 0.252039; batch adversarial loss: 0.461962\n",
      "epoch 52; iter: 0; batch classifier loss: 0.256603; batch adversarial loss: 0.412931\n",
      "epoch 53; iter: 0; batch classifier loss: 0.287702; batch adversarial loss: 0.546257\n",
      "epoch 54; iter: 0; batch classifier loss: 0.263984; batch adversarial loss: 0.424040\n",
      "epoch 55; iter: 0; batch classifier loss: 0.233729; batch adversarial loss: 0.469932\n",
      "epoch 56; iter: 0; batch classifier loss: 0.273609; batch adversarial loss: 0.396987\n",
      "epoch 57; iter: 0; batch classifier loss: 0.243209; batch adversarial loss: 0.435207\n",
      "epoch 58; iter: 0; batch classifier loss: 0.197556; batch adversarial loss: 0.446777\n",
      "epoch 59; iter: 0; batch classifier loss: 0.224980; batch adversarial loss: 0.343909\n",
      "epoch 60; iter: 0; batch classifier loss: 0.191437; batch adversarial loss: 0.433337\n",
      "epoch 61; iter: 0; batch classifier loss: 0.254711; batch adversarial loss: 0.537509\n",
      "epoch 62; iter: 0; batch classifier loss: 0.308035; batch adversarial loss: 0.447256\n",
      "epoch 63; iter: 0; batch classifier loss: 0.215062; batch adversarial loss: 0.446381\n",
      "epoch 64; iter: 0; batch classifier loss: 0.152852; batch adversarial loss: 0.354736\n",
      "epoch 65; iter: 0; batch classifier loss: 0.239050; batch adversarial loss: 0.535033\n",
      "epoch 66; iter: 0; batch classifier loss: 0.235398; batch adversarial loss: 0.406959\n",
      "epoch 67; iter: 0; batch classifier loss: 0.238919; batch adversarial loss: 0.472508\n",
      "epoch 68; iter: 0; batch classifier loss: 0.221528; batch adversarial loss: 0.496901\n",
      "epoch 69; iter: 0; batch classifier loss: 0.270201; batch adversarial loss: 0.433458\n",
      "epoch 70; iter: 0; batch classifier loss: 0.232688; batch adversarial loss: 0.510371\n",
      "epoch 71; iter: 0; batch classifier loss: 0.144887; batch adversarial loss: 0.458549\n",
      "epoch 72; iter: 0; batch classifier loss: 0.127007; batch adversarial loss: 0.353183\n",
      "epoch 73; iter: 0; batch classifier loss: 0.113201; batch adversarial loss: 0.436325\n",
      "epoch 74; iter: 0; batch classifier loss: 0.258003; batch adversarial loss: 0.449275\n",
      "epoch 75; iter: 0; batch classifier loss: 0.194655; batch adversarial loss: 0.495140\n",
      "epoch 76; iter: 0; batch classifier loss: 0.218194; batch adversarial loss: 0.456423\n",
      "epoch 77; iter: 0; batch classifier loss: 0.216668; batch adversarial loss: 0.419188\n",
      "epoch 78; iter: 0; batch classifier loss: 0.238819; batch adversarial loss: 0.485370\n",
      "epoch 79; iter: 0; batch classifier loss: 0.232690; batch adversarial loss: 0.460642\n",
      "epoch 80; iter: 0; batch classifier loss: 0.256003; batch adversarial loss: 0.343798\n",
      "epoch 81; iter: 0; batch classifier loss: 0.191201; batch adversarial loss: 0.408068\n",
      "epoch 82; iter: 0; batch classifier loss: 0.282079; batch adversarial loss: 0.394865\n",
      "epoch 83; iter: 0; batch classifier loss: 0.121129; batch adversarial loss: 0.484717\n",
      "epoch 84; iter: 0; batch classifier loss: 0.108709; batch adversarial loss: 0.407186\n",
      "epoch 85; iter: 0; batch classifier loss: 0.207751; batch adversarial loss: 0.394293\n",
      "epoch 86; iter: 0; batch classifier loss: 0.235332; batch adversarial loss: 0.433693\n",
      "epoch 87; iter: 0; batch classifier loss: 0.257725; batch adversarial loss: 0.485839\n",
      "epoch 88; iter: 0; batch classifier loss: 0.196493; batch adversarial loss: 0.432688\n",
      "epoch 89; iter: 0; batch classifier loss: 0.232139; batch adversarial loss: 0.368388\n",
      "epoch 90; iter: 0; batch classifier loss: 0.278824; batch adversarial loss: 0.472018\n",
      "epoch 91; iter: 0; batch classifier loss: 0.253617; batch adversarial loss: 0.433675\n",
      "epoch 92; iter: 0; batch classifier loss: 0.112622; batch adversarial loss: 0.446265\n",
      "epoch 93; iter: 0; batch classifier loss: 0.190406; batch adversarial loss: 0.381115\n",
      "epoch 94; iter: 0; batch classifier loss: 0.177585; batch adversarial loss: 0.495693\n",
      "epoch 95; iter: 0; batch classifier loss: 0.333674; batch adversarial loss: 0.510319\n",
      "epoch 96; iter: 0; batch classifier loss: 0.205883; batch adversarial loss: 0.369907\n",
      "epoch 97; iter: 0; batch classifier loss: 0.253367; batch adversarial loss: 0.484421\n",
      "epoch 98; iter: 0; batch classifier loss: 0.180757; batch adversarial loss: 0.395214\n",
      "epoch 99; iter: 0; batch classifier loss: 0.168708; batch adversarial loss: 0.486375\n",
      "epoch 100; iter: 0; batch classifier loss: 0.274508; batch adversarial loss: 0.394712\n",
      "epoch 101; iter: 0; batch classifier loss: 0.278170; batch adversarial loss: 0.407470\n",
      "epoch 102; iter: 0; batch classifier loss: 0.196862; batch adversarial loss: 0.330668\n",
      "epoch 103; iter: 0; batch classifier loss: 0.173874; batch adversarial loss: 0.420495\n",
      "epoch 104; iter: 0; batch classifier loss: 0.154430; batch adversarial loss: 0.415506\n",
      "epoch 105; iter: 0; batch classifier loss: 0.205417; batch adversarial loss: 0.469696\n",
      "epoch 106; iter: 0; batch classifier loss: 0.208661; batch adversarial loss: 0.472390\n",
      "epoch 107; iter: 0; batch classifier loss: 0.210349; batch adversarial loss: 0.421763\n",
      "epoch 108; iter: 0; batch classifier loss: 0.186669; batch adversarial loss: 0.472536\n",
      "epoch 109; iter: 0; batch classifier loss: 0.207721; batch adversarial loss: 0.406568\n",
      "epoch 110; iter: 0; batch classifier loss: 0.277078; batch adversarial loss: 0.446238\n",
      "epoch 111; iter: 0; batch classifier loss: 0.226385; batch adversarial loss: 0.369263\n",
      "epoch 112; iter: 0; batch classifier loss: 0.254204; batch adversarial loss: 0.369942\n",
      "epoch 113; iter: 0; batch classifier loss: 0.200843; batch adversarial loss: 0.446357\n",
      "epoch 114; iter: 0; batch classifier loss: 0.199894; batch adversarial loss: 0.548952\n",
      "epoch 115; iter: 0; batch classifier loss: 0.259744; batch adversarial loss: 0.459498\n",
      "epoch 116; iter: 0; batch classifier loss: 0.191258; batch adversarial loss: 0.447617\n",
      "epoch 117; iter: 0; batch classifier loss: 0.262504; batch adversarial loss: 0.343461\n",
      "epoch 118; iter: 0; batch classifier loss: 0.259390; batch adversarial loss: 0.381182\n",
      "epoch 119; iter: 0; batch classifier loss: 0.261625; batch adversarial loss: 0.382365\n",
      "epoch 120; iter: 0; batch classifier loss: 0.263076; batch adversarial loss: 0.511548\n",
      "epoch 121; iter: 0; batch classifier loss: 0.279080; batch adversarial loss: 0.484581\n",
      "epoch 122; iter: 0; batch classifier loss: 0.253369; batch adversarial loss: 0.407892\n",
      "epoch 123; iter: 0; batch classifier loss: 0.086256; batch adversarial loss: 0.393992\n",
      "epoch 124; iter: 0; batch classifier loss: 0.073944; batch adversarial loss: 0.387162\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052740; batch adversarial loss: 0.460262\n",
      "epoch 126; iter: 0; batch classifier loss: 0.067466; batch adversarial loss: 0.389866\n",
      "epoch 127; iter: 0; batch classifier loss: 0.070123; batch adversarial loss: 0.405775\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056565; batch adversarial loss: 0.360450\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039425; batch adversarial loss: 0.440412\n",
      "epoch 130; iter: 0; batch classifier loss: 0.069186; batch adversarial loss: 0.405507\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029564; batch adversarial loss: 0.435715\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038326; batch adversarial loss: 0.491251\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045333; batch adversarial loss: 0.376349\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043396; batch adversarial loss: 0.416251\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046356; batch adversarial loss: 0.550240\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038796; batch adversarial loss: 0.430617\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026203; batch adversarial loss: 0.394245\n",
      "epoch 138; iter: 0; batch classifier loss: 0.055574; batch adversarial loss: 0.422940\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031830; batch adversarial loss: 0.486446\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029662; batch adversarial loss: 0.403915\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025948; batch adversarial loss: 0.517681\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028768; batch adversarial loss: 0.522161\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042208; batch adversarial loss: 0.408358\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030151; batch adversarial loss: 0.464085\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042135; batch adversarial loss: 0.366283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.016312; batch adversarial loss: 0.447018\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034984; batch adversarial loss: 0.483874\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022953; batch adversarial loss: 0.443492\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040650; batch adversarial loss: 0.524562\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025947; batch adversarial loss: 0.424192\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020910; batch adversarial loss: 0.496423\n",
      "epoch 152; iter: 0; batch classifier loss: 0.055268; batch adversarial loss: 0.354693\n",
      "epoch 153; iter: 0; batch classifier loss: 0.009778; batch adversarial loss: 0.445015\n",
      "epoch 154; iter: 0; batch classifier loss: 0.075014; batch adversarial loss: 0.385835\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027845; batch adversarial loss: 0.375125\n",
      "epoch 156; iter: 0; batch classifier loss: 0.009090; batch adversarial loss: 0.360061\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009590; batch adversarial loss: 0.545464\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032492; batch adversarial loss: 0.424159\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022476; batch adversarial loss: 0.414646\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017339; batch adversarial loss: 0.403857\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033698; batch adversarial loss: 0.377115\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030560; batch adversarial loss: 0.328795\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023198; batch adversarial loss: 0.393159\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013074; batch adversarial loss: 0.413939\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023618; batch adversarial loss: 0.493481\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018938; batch adversarial loss: 0.431121\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016354; batch adversarial loss: 0.420467\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014308; batch adversarial loss: 0.460797\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016091; batch adversarial loss: 0.471479\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021772; batch adversarial loss: 0.359668\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013811; batch adversarial loss: 0.437021\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028650; batch adversarial loss: 0.387526\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030855; batch adversarial loss: 0.452783\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023740; batch adversarial loss: 0.401257\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032653; batch adversarial loss: 0.394728\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012415; batch adversarial loss: 0.443450\n",
      "epoch 177; iter: 0; batch classifier loss: 0.035731; batch adversarial loss: 0.428906\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024942; batch adversarial loss: 0.353416\n",
      "epoch 179; iter: 0; batch classifier loss: 0.060322; batch adversarial loss: 0.404302\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018742; batch adversarial loss: 0.444188\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014363; batch adversarial loss: 0.423623\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022500; batch adversarial loss: 0.470679\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006137; batch adversarial loss: 0.380589\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022510; batch adversarial loss: 0.352420\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036405; batch adversarial loss: 0.521251\n",
      "epoch 186; iter: 0; batch classifier loss: 0.038952; batch adversarial loss: 0.355285\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021056; batch adversarial loss: 0.511291\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014185; batch adversarial loss: 0.531078\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024264; batch adversarial loss: 0.507676\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018323; batch adversarial loss: 0.456763\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006954; batch adversarial loss: 0.469877\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006687; batch adversarial loss: 0.464357\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016164; batch adversarial loss: 0.477011\n",
      "epoch 194; iter: 0; batch classifier loss: 0.003112; batch adversarial loss: 0.510166\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018751; batch adversarial loss: 0.472703\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028385; batch adversarial loss: 0.394417\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005478; batch adversarial loss: 0.474598\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003477; batch adversarial loss: 0.454978\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013200; batch adversarial loss: 0.441658\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707216; batch adversarial loss: 0.723922\n",
      "epoch 1; iter: 0; batch classifier loss: 0.446380; batch adversarial loss: 0.705261\n",
      "epoch 2; iter: 0; batch classifier loss: 0.421608; batch adversarial loss: 0.690419\n",
      "epoch 3; iter: 0; batch classifier loss: 0.301448; batch adversarial loss: 0.680002\n",
      "epoch 4; iter: 0; batch classifier loss: 0.359127; batch adversarial loss: 0.672912\n",
      "epoch 5; iter: 0; batch classifier loss: 0.324879; batch adversarial loss: 0.602917\n",
      "epoch 6; iter: 0; batch classifier loss: 0.321158; batch adversarial loss: 0.563694\n",
      "epoch 7; iter: 0; batch classifier loss: 0.362876; batch adversarial loss: 0.523213\n",
      "epoch 8; iter: 0; batch classifier loss: 0.290326; batch adversarial loss: 0.567540\n",
      "epoch 9; iter: 0; batch classifier loss: 0.304144; batch adversarial loss: 0.515878\n",
      "epoch 10; iter: 0; batch classifier loss: 0.245384; batch adversarial loss: 0.478936\n",
      "epoch 11; iter: 0; batch classifier loss: 0.188811; batch adversarial loss: 0.499843\n",
      "epoch 12; iter: 0; batch classifier loss: 0.242914; batch adversarial loss: 0.432670\n",
      "epoch 13; iter: 0; batch classifier loss: 0.221361; batch adversarial loss: 0.476865\n",
      "epoch 14; iter: 0; batch classifier loss: 0.221245; batch adversarial loss: 0.504803\n",
      "epoch 15; iter: 0; batch classifier loss: 0.198441; batch adversarial loss: 0.414181\n",
      "epoch 16; iter: 0; batch classifier loss: 0.189544; batch adversarial loss: 0.489446\n",
      "epoch 17; iter: 0; batch classifier loss: 0.161016; batch adversarial loss: 0.427751\n",
      "epoch 18; iter: 0; batch classifier loss: 0.141067; batch adversarial loss: 0.373404\n",
      "epoch 19; iter: 0; batch classifier loss: 0.240180; batch adversarial loss: 0.399013\n",
      "epoch 20; iter: 0; batch classifier loss: 0.127241; batch adversarial loss: 0.495498\n",
      "epoch 21; iter: 0; batch classifier loss: 0.113846; batch adversarial loss: 0.408879\n",
      "epoch 22; iter: 0; batch classifier loss: 0.120376; batch adversarial loss: 0.381294\n",
      "epoch 23; iter: 0; batch classifier loss: 0.106512; batch adversarial loss: 0.456247\n",
      "epoch 24; iter: 0; batch classifier loss: 0.092009; batch adversarial loss: 0.372852\n",
      "epoch 25; iter: 0; batch classifier loss: 0.108159; batch adversarial loss: 0.472143\n",
      "epoch 26; iter: 0; batch classifier loss: 0.087525; batch adversarial loss: 0.421698\n",
      "epoch 27; iter: 0; batch classifier loss: 0.105529; batch adversarial loss: 0.419055\n",
      "epoch 28; iter: 0; batch classifier loss: 0.068257; batch adversarial loss: 0.403878\n",
      "epoch 29; iter: 0; batch classifier loss: 0.136948; batch adversarial loss: 0.417220\n",
      "epoch 30; iter: 0; batch classifier loss: 0.081547; batch adversarial loss: 0.427262\n",
      "epoch 31; iter: 0; batch classifier loss: 0.085234; batch adversarial loss: 0.458819\n",
      "epoch 32; iter: 0; batch classifier loss: 0.099483; batch adversarial loss: 0.400257\n",
      "epoch 33; iter: 0; batch classifier loss: 0.102891; batch adversarial loss: 0.371478\n",
      "epoch 34; iter: 0; batch classifier loss: 0.112206; batch adversarial loss: 0.475121\n",
      "epoch 35; iter: 0; batch classifier loss: 0.119868; batch adversarial loss: 0.362772\n",
      "epoch 36; iter: 0; batch classifier loss: 0.111462; batch adversarial loss: 0.426958\n",
      "epoch 37; iter: 0; batch classifier loss: 0.114454; batch adversarial loss: 0.452033\n",
      "epoch 38; iter: 0; batch classifier loss: 0.145797; batch adversarial loss: 0.453790\n",
      "epoch 39; iter: 0; batch classifier loss: 0.088055; batch adversarial loss: 0.485356\n",
      "epoch 40; iter: 0; batch classifier loss: 0.098930; batch adversarial loss: 0.406361\n",
      "epoch 41; iter: 0; batch classifier loss: 0.129670; batch adversarial loss: 0.453027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.136242; batch adversarial loss: 0.473289\n",
      "epoch 43; iter: 0; batch classifier loss: 0.081953; batch adversarial loss: 0.383037\n",
      "epoch 44; iter: 0; batch classifier loss: 0.126676; batch adversarial loss: 0.393931\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089260; batch adversarial loss: 0.402803\n",
      "epoch 46; iter: 0; batch classifier loss: 0.094810; batch adversarial loss: 0.427329\n",
      "epoch 47; iter: 0; batch classifier loss: 0.143579; batch adversarial loss: 0.435530\n",
      "epoch 48; iter: 0; batch classifier loss: 0.157198; batch adversarial loss: 0.335517\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098014; batch adversarial loss: 0.403468\n",
      "epoch 50; iter: 0; batch classifier loss: 0.100404; batch adversarial loss: 0.434560\n",
      "epoch 51; iter: 0; batch classifier loss: 0.090956; batch adversarial loss: 0.333199\n",
      "epoch 52; iter: 0; batch classifier loss: 0.102523; batch adversarial loss: 0.392759\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098943; batch adversarial loss: 0.418455\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074493; batch adversarial loss: 0.439334\n",
      "epoch 55; iter: 0; batch classifier loss: 0.101116; batch adversarial loss: 0.426754\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119477; batch adversarial loss: 0.455945\n",
      "epoch 57; iter: 0; batch classifier loss: 0.052647; batch adversarial loss: 0.420917\n",
      "epoch 58; iter: 0; batch classifier loss: 0.069687; batch adversarial loss: 0.384259\n",
      "epoch 59; iter: 0; batch classifier loss: 0.115269; batch adversarial loss: 0.436168\n",
      "epoch 60; iter: 0; batch classifier loss: 0.073478; batch adversarial loss: 0.411943\n",
      "epoch 61; iter: 0; batch classifier loss: 0.066021; batch adversarial loss: 0.339836\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092188; batch adversarial loss: 0.390489\n",
      "epoch 63; iter: 0; batch classifier loss: 0.100738; batch adversarial loss: 0.437651\n",
      "epoch 64; iter: 0; batch classifier loss: 0.093594; batch adversarial loss: 0.431219\n",
      "epoch 65; iter: 0; batch classifier loss: 0.062225; batch adversarial loss: 0.386958\n",
      "epoch 66; iter: 0; batch classifier loss: 0.128228; batch adversarial loss: 0.370593\n",
      "epoch 67; iter: 0; batch classifier loss: 0.088727; batch adversarial loss: 0.381156\n",
      "epoch 68; iter: 0; batch classifier loss: 0.105573; batch adversarial loss: 0.384302\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078834; batch adversarial loss: 0.353813\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066203; batch adversarial loss: 0.503829\n",
      "epoch 71; iter: 0; batch classifier loss: 0.082786; batch adversarial loss: 0.431194\n",
      "epoch 72; iter: 0; batch classifier loss: 0.091316; batch adversarial loss: 0.417804\n",
      "epoch 73; iter: 0; batch classifier loss: 0.037913; batch adversarial loss: 0.513042\n",
      "epoch 74; iter: 0; batch classifier loss: 0.100422; batch adversarial loss: 0.374311\n",
      "epoch 75; iter: 0; batch classifier loss: 0.068760; batch adversarial loss: 0.391005\n",
      "epoch 76; iter: 0; batch classifier loss: 0.079622; batch adversarial loss: 0.343861\n",
      "epoch 77; iter: 0; batch classifier loss: 0.093329; batch adversarial loss: 0.432982\n",
      "epoch 78; iter: 0; batch classifier loss: 0.036652; batch adversarial loss: 0.337803\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053361; batch adversarial loss: 0.336650\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068548; batch adversarial loss: 0.390965\n",
      "epoch 81; iter: 0; batch classifier loss: 0.052900; batch adversarial loss: 0.411138\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074777; batch adversarial loss: 0.388177\n",
      "epoch 83; iter: 0; batch classifier loss: 0.076376; batch adversarial loss: 0.365371\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048473; batch adversarial loss: 0.396537\n",
      "epoch 85; iter: 0; batch classifier loss: 0.062536; batch adversarial loss: 0.393865\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054054; batch adversarial loss: 0.343063\n",
      "epoch 87; iter: 0; batch classifier loss: 0.045182; batch adversarial loss: 0.383847\n",
      "epoch 88; iter: 0; batch classifier loss: 0.074768; batch adversarial loss: 0.402202\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060770; batch adversarial loss: 0.337767\n",
      "epoch 90; iter: 0; batch classifier loss: 0.069327; batch adversarial loss: 0.353740\n",
      "epoch 91; iter: 0; batch classifier loss: 0.085073; batch adversarial loss: 0.483529\n",
      "epoch 92; iter: 0; batch classifier loss: 0.035664; batch adversarial loss: 0.563639\n",
      "epoch 93; iter: 0; batch classifier loss: 0.059346; batch adversarial loss: 0.419063\n",
      "epoch 94; iter: 0; batch classifier loss: 0.036773; batch adversarial loss: 0.369489\n",
      "epoch 95; iter: 0; batch classifier loss: 0.083448; batch adversarial loss: 0.410375\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043240; batch adversarial loss: 0.437727\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077348; batch adversarial loss: 0.440620\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047237; batch adversarial loss: 0.363052\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042829; batch adversarial loss: 0.474447\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043631; batch adversarial loss: 0.403584\n",
      "epoch 101; iter: 0; batch classifier loss: 0.047571; batch adversarial loss: 0.388984\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029882; batch adversarial loss: 0.449071\n",
      "epoch 103; iter: 0; batch classifier loss: 0.074173; batch adversarial loss: 0.463141\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066160; batch adversarial loss: 0.390481\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041644; batch adversarial loss: 0.466252\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037026; batch adversarial loss: 0.482704\n",
      "epoch 107; iter: 0; batch classifier loss: 0.070698; batch adversarial loss: 0.522602\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028068; batch adversarial loss: 0.373460\n",
      "epoch 109; iter: 0; batch classifier loss: 0.025397; batch adversarial loss: 0.387721\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031013; batch adversarial loss: 0.479182\n",
      "epoch 111; iter: 0; batch classifier loss: 0.046772; batch adversarial loss: 0.351289\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037214; batch adversarial loss: 0.405197\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034680; batch adversarial loss: 0.410027\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037281; batch adversarial loss: 0.426765\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039834; batch adversarial loss: 0.495807\n",
      "epoch 116; iter: 0; batch classifier loss: 0.022668; batch adversarial loss: 0.431500\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029718; batch adversarial loss: 0.474535\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042454; batch adversarial loss: 0.353234\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021563; batch adversarial loss: 0.460302\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047035; batch adversarial loss: 0.442624\n",
      "epoch 121; iter: 0; batch classifier loss: 0.014611; batch adversarial loss: 0.467586\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017635; batch adversarial loss: 0.335614\n",
      "epoch 123; iter: 0; batch classifier loss: 0.015881; batch adversarial loss: 0.489552\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020238; batch adversarial loss: 0.461674\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028312; batch adversarial loss: 0.421861\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031793; batch adversarial loss: 0.427385\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043892; batch adversarial loss: 0.377721\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030317; batch adversarial loss: 0.414585\n",
      "epoch 129; iter: 0; batch classifier loss: 0.014750; batch adversarial loss: 0.467521\n",
      "epoch 130; iter: 0; batch classifier loss: 0.020881; batch adversarial loss: 0.446284\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022616; batch adversarial loss: 0.398782\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016870; batch adversarial loss: 0.383920\n",
      "epoch 133; iter: 0; batch classifier loss: 0.009722; batch adversarial loss: 0.390619\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027887; batch adversarial loss: 0.509122\n",
      "epoch 135; iter: 0; batch classifier loss: 0.054104; batch adversarial loss: 0.437817\n",
      "epoch 136; iter: 0; batch classifier loss: 0.052980; batch adversarial loss: 0.612839\n",
      "epoch 137; iter: 0; batch classifier loss: 0.021685; batch adversarial loss: 0.444001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.025648; batch adversarial loss: 0.374201\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009182; batch adversarial loss: 0.518502\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035615; batch adversarial loss: 0.407519\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025304; batch adversarial loss: 0.344763\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042261; batch adversarial loss: 0.485422\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030461; batch adversarial loss: 0.418873\n",
      "epoch 144; iter: 0; batch classifier loss: 0.064767; batch adversarial loss: 0.652451\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035306; batch adversarial loss: 0.490576\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037051; batch adversarial loss: 0.352377\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026971; batch adversarial loss: 0.418068\n",
      "epoch 148; iter: 0; batch classifier loss: 0.060073; batch adversarial loss: 0.531635\n",
      "epoch 149; iter: 0; batch classifier loss: 0.042801; batch adversarial loss: 0.528872\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033494; batch adversarial loss: 0.514716\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038523; batch adversarial loss: 0.468935\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040090; batch adversarial loss: 0.547460\n",
      "epoch 153; iter: 0; batch classifier loss: 0.148932; batch adversarial loss: 0.803934\n",
      "epoch 154; iter: 0; batch classifier loss: 0.129048; batch adversarial loss: 0.698689\n",
      "epoch 155; iter: 0; batch classifier loss: 0.066111; batch adversarial loss: 0.500213\n",
      "epoch 156; iter: 0; batch classifier loss: 0.063036; batch adversarial loss: 0.553431\n",
      "epoch 157; iter: 0; batch classifier loss: 0.173474; batch adversarial loss: 0.625366\n",
      "epoch 158; iter: 0; batch classifier loss: 0.054134; batch adversarial loss: 0.441998\n",
      "epoch 159; iter: 0; batch classifier loss: 0.053287; batch adversarial loss: 0.515055\n",
      "epoch 160; iter: 0; batch classifier loss: 0.071140; batch adversarial loss: 0.503680\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034950; batch adversarial loss: 0.460665\n",
      "epoch 162; iter: 0; batch classifier loss: 0.129338; batch adversarial loss: 0.647143\n",
      "epoch 163; iter: 0; batch classifier loss: 0.077264; batch adversarial loss: 0.592519\n",
      "epoch 164; iter: 0; batch classifier loss: 0.110350; batch adversarial loss: 0.589163\n",
      "epoch 165; iter: 0; batch classifier loss: 0.194369; batch adversarial loss: 0.750182\n",
      "epoch 166; iter: 0; batch classifier loss: 0.068873; batch adversarial loss: 0.489858\n",
      "epoch 167; iter: 0; batch classifier loss: 0.113411; batch adversarial loss: 0.574858\n",
      "epoch 168; iter: 0; batch classifier loss: 0.086770; batch adversarial loss: 0.470610\n",
      "epoch 169; iter: 0; batch classifier loss: 0.157206; batch adversarial loss: 0.656994\n",
      "epoch 170; iter: 0; batch classifier loss: 0.073475; batch adversarial loss: 0.566570\n",
      "epoch 171; iter: 0; batch classifier loss: 0.168759; batch adversarial loss: 0.662048\n",
      "epoch 172; iter: 0; batch classifier loss: 0.234748; batch adversarial loss: 0.755175\n",
      "epoch 173; iter: 0; batch classifier loss: 0.140276; batch adversarial loss: 0.572593\n",
      "epoch 174; iter: 0; batch classifier loss: 0.196834; batch adversarial loss: 0.639912\n",
      "epoch 175; iter: 0; batch classifier loss: 0.162360; batch adversarial loss: 0.591931\n",
      "epoch 176; iter: 0; batch classifier loss: 0.138268; batch adversarial loss: 0.568415\n",
      "epoch 177; iter: 0; batch classifier loss: 0.150469; batch adversarial loss: 0.504476\n",
      "epoch 178; iter: 0; batch classifier loss: 0.112386; batch adversarial loss: 0.618961\n",
      "epoch 179; iter: 0; batch classifier loss: 0.101982; batch adversarial loss: 0.473031\n",
      "epoch 180; iter: 0; batch classifier loss: 0.137536; batch adversarial loss: 0.452901\n",
      "epoch 181; iter: 0; batch classifier loss: 0.121221; batch adversarial loss: 0.576730\n",
      "epoch 182; iter: 0; batch classifier loss: 0.186216; batch adversarial loss: 0.676008\n",
      "epoch 183; iter: 0; batch classifier loss: 0.126325; batch adversarial loss: 0.625867\n",
      "epoch 184; iter: 0; batch classifier loss: 0.125811; batch adversarial loss: 0.536678\n",
      "epoch 185; iter: 0; batch classifier loss: 0.161875; batch adversarial loss: 0.513683\n",
      "epoch 186; iter: 0; batch classifier loss: 0.198156; batch adversarial loss: 0.707237\n",
      "epoch 187; iter: 0; batch classifier loss: 0.121415; batch adversarial loss: 0.501241\n",
      "epoch 188; iter: 0; batch classifier loss: 0.172780; batch adversarial loss: 0.629875\n",
      "epoch 189; iter: 0; batch classifier loss: 0.127135; batch adversarial loss: 0.533952\n",
      "epoch 190; iter: 0; batch classifier loss: 0.158843; batch adversarial loss: 0.559479\n",
      "epoch 191; iter: 0; batch classifier loss: 0.103800; batch adversarial loss: 0.615111\n",
      "epoch 192; iter: 0; batch classifier loss: 0.135309; batch adversarial loss: 0.501648\n",
      "epoch 193; iter: 0; batch classifier loss: 0.119741; batch adversarial loss: 0.469617\n",
      "epoch 194; iter: 0; batch classifier loss: 0.179206; batch adversarial loss: 0.657697\n",
      "epoch 195; iter: 0; batch classifier loss: 0.102830; batch adversarial loss: 0.480143\n",
      "epoch 196; iter: 0; batch classifier loss: 0.133165; batch adversarial loss: 0.596105\n",
      "epoch 197; iter: 0; batch classifier loss: 0.184024; batch adversarial loss: 0.596733\n",
      "epoch 198; iter: 0; batch classifier loss: 0.171500; batch adversarial loss: 0.603861\n",
      "epoch 199; iter: 0; batch classifier loss: 0.154709; batch adversarial loss: 0.511604\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699037; batch adversarial loss: 0.874045\n",
      "epoch 1; iter: 0; batch classifier loss: 0.521862; batch adversarial loss: 0.804108\n",
      "epoch 2; iter: 0; batch classifier loss: 0.636082; batch adversarial loss: 0.792708\n",
      "epoch 3; iter: 0; batch classifier loss: 0.878740; batch adversarial loss: 0.736114\n",
      "epoch 4; iter: 0; batch classifier loss: 0.816058; batch adversarial loss: 0.669204\n",
      "epoch 5; iter: 0; batch classifier loss: 0.619145; batch adversarial loss: 0.607979\n",
      "epoch 6; iter: 0; batch classifier loss: 0.418167; batch adversarial loss: 0.588357\n",
      "epoch 7; iter: 0; batch classifier loss: 0.362836; batch adversarial loss: 0.595315\n",
      "epoch 8; iter: 0; batch classifier loss: 0.390990; batch adversarial loss: 0.553325\n",
      "epoch 9; iter: 0; batch classifier loss: 0.321790; batch adversarial loss: 0.532319\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358379; batch adversarial loss: 0.537187\n",
      "epoch 11; iter: 0; batch classifier loss: 0.283148; batch adversarial loss: 0.468124\n",
      "epoch 12; iter: 0; batch classifier loss: 0.310509; batch adversarial loss: 0.504307\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331825; batch adversarial loss: 0.575755\n",
      "epoch 14; iter: 0; batch classifier loss: 0.299227; batch adversarial loss: 0.504919\n",
      "epoch 15; iter: 0; batch classifier loss: 0.249843; batch adversarial loss: 0.504272\n",
      "epoch 16; iter: 0; batch classifier loss: 0.324282; batch adversarial loss: 0.481458\n",
      "epoch 17; iter: 0; batch classifier loss: 0.338274; batch adversarial loss: 0.439652\n",
      "epoch 18; iter: 0; batch classifier loss: 0.375199; batch adversarial loss: 0.410446\n",
      "epoch 19; iter: 0; batch classifier loss: 0.343721; batch adversarial loss: 0.478556\n",
      "epoch 20; iter: 0; batch classifier loss: 0.340676; batch adversarial loss: 0.510911\n",
      "epoch 21; iter: 0; batch classifier loss: 0.329882; batch adversarial loss: 0.444950\n",
      "epoch 22; iter: 0; batch classifier loss: 0.307546; batch adversarial loss: 0.478619\n",
      "epoch 23; iter: 0; batch classifier loss: 0.281769; batch adversarial loss: 0.446892\n",
      "epoch 24; iter: 0; batch classifier loss: 0.291992; batch adversarial loss: 0.449534\n",
      "epoch 25; iter: 0; batch classifier loss: 0.323109; batch adversarial loss: 0.452171\n",
      "epoch 26; iter: 0; batch classifier loss: 0.348347; batch adversarial loss: 0.444151\n",
      "epoch 27; iter: 0; batch classifier loss: 0.367394; batch adversarial loss: 0.438189\n",
      "epoch 28; iter: 0; batch classifier loss: 0.257105; batch adversarial loss: 0.499823\n",
      "epoch 29; iter: 0; batch classifier loss: 0.219979; batch adversarial loss: 0.475576\n",
      "epoch 30; iter: 0; batch classifier loss: 0.292241; batch adversarial loss: 0.452627\n",
      "epoch 31; iter: 0; batch classifier loss: 0.192596; batch adversarial loss: 0.415874\n",
      "epoch 32; iter: 0; batch classifier loss: 0.255158; batch adversarial loss: 0.418575\n",
      "epoch 33; iter: 0; batch classifier loss: 0.254591; batch adversarial loss: 0.537088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.214106; batch adversarial loss: 0.445345\n",
      "epoch 35; iter: 0; batch classifier loss: 0.242202; batch adversarial loss: 0.463762\n",
      "epoch 36; iter: 0; batch classifier loss: 0.216480; batch adversarial loss: 0.466244\n",
      "epoch 37; iter: 0; batch classifier loss: 0.238290; batch adversarial loss: 0.420468\n",
      "epoch 38; iter: 0; batch classifier loss: 0.232941; batch adversarial loss: 0.473085\n",
      "epoch 39; iter: 0; batch classifier loss: 0.253677; batch adversarial loss: 0.405305\n",
      "epoch 40; iter: 0; batch classifier loss: 0.220477; batch adversarial loss: 0.516782\n",
      "epoch 41; iter: 0; batch classifier loss: 0.145610; batch adversarial loss: 0.465296\n",
      "epoch 42; iter: 0; batch classifier loss: 0.229113; batch adversarial loss: 0.476165\n",
      "epoch 43; iter: 0; batch classifier loss: 0.224718; batch adversarial loss: 0.423547\n",
      "epoch 44; iter: 0; batch classifier loss: 0.196643; batch adversarial loss: 0.448678\n",
      "epoch 45; iter: 0; batch classifier loss: 0.252389; batch adversarial loss: 0.414108\n",
      "epoch 46; iter: 0; batch classifier loss: 0.197641; batch adversarial loss: 0.404116\n",
      "epoch 47; iter: 0; batch classifier loss: 0.180384; batch adversarial loss: 0.401865\n",
      "epoch 48; iter: 0; batch classifier loss: 0.229785; batch adversarial loss: 0.527522\n",
      "epoch 49; iter: 0; batch classifier loss: 0.184112; batch adversarial loss: 0.495264\n",
      "epoch 50; iter: 0; batch classifier loss: 0.230155; batch adversarial loss: 0.403014\n",
      "epoch 51; iter: 0; batch classifier loss: 0.164942; batch adversarial loss: 0.459041\n",
      "epoch 52; iter: 0; batch classifier loss: 0.157380; batch adversarial loss: 0.493656\n",
      "epoch 53; iter: 0; batch classifier loss: 0.189206; batch adversarial loss: 0.449945\n",
      "epoch 54; iter: 0; batch classifier loss: 0.136360; batch adversarial loss: 0.398508\n",
      "epoch 55; iter: 0; batch classifier loss: 0.218615; batch adversarial loss: 0.411641\n",
      "epoch 56; iter: 0; batch classifier loss: 0.210133; batch adversarial loss: 0.447309\n",
      "epoch 57; iter: 0; batch classifier loss: 0.153636; batch adversarial loss: 0.446510\n",
      "epoch 58; iter: 0; batch classifier loss: 0.210254; batch adversarial loss: 0.458705\n",
      "epoch 59; iter: 0; batch classifier loss: 0.176466; batch adversarial loss: 0.447010\n",
      "epoch 60; iter: 0; batch classifier loss: 0.192022; batch adversarial loss: 0.362186\n",
      "epoch 61; iter: 0; batch classifier loss: 0.100725; batch adversarial loss: 0.434852\n",
      "epoch 62; iter: 0; batch classifier loss: 0.146403; batch adversarial loss: 0.410365\n",
      "epoch 63; iter: 0; batch classifier loss: 0.158189; batch adversarial loss: 0.507275\n",
      "epoch 64; iter: 0; batch classifier loss: 0.208436; batch adversarial loss: 0.544628\n",
      "epoch 65; iter: 0; batch classifier loss: 0.133437; batch adversarial loss: 0.421898\n",
      "epoch 66; iter: 0; batch classifier loss: 0.179653; batch adversarial loss: 0.507573\n",
      "epoch 67; iter: 0; batch classifier loss: 0.241778; batch adversarial loss: 0.372795\n",
      "epoch 68; iter: 0; batch classifier loss: 0.112902; batch adversarial loss: 0.458713\n",
      "epoch 69; iter: 0; batch classifier loss: 0.120711; batch adversarial loss: 0.495238\n",
      "epoch 70; iter: 0; batch classifier loss: 0.170518; batch adversarial loss: 0.481989\n",
      "epoch 71; iter: 0; batch classifier loss: 0.209525; batch adversarial loss: 0.434961\n",
      "epoch 72; iter: 0; batch classifier loss: 0.070697; batch adversarial loss: 0.446536\n",
      "epoch 73; iter: 0; batch classifier loss: 0.078508; batch adversarial loss: 0.521806\n",
      "epoch 74; iter: 0; batch classifier loss: 0.124310; batch adversarial loss: 0.458681\n",
      "epoch 75; iter: 0; batch classifier loss: 0.163829; batch adversarial loss: 0.459786\n",
      "epoch 76; iter: 0; batch classifier loss: 0.165531; batch adversarial loss: 0.521170\n",
      "epoch 77; iter: 0; batch classifier loss: 0.147371; batch adversarial loss: 0.508274\n",
      "epoch 78; iter: 0; batch classifier loss: 0.192848; batch adversarial loss: 0.446158\n",
      "epoch 79; iter: 0; batch classifier loss: 0.206833; batch adversarial loss: 0.532601\n",
      "epoch 80; iter: 0; batch classifier loss: 0.151659; batch adversarial loss: 0.507669\n",
      "epoch 81; iter: 0; batch classifier loss: 0.117859; batch adversarial loss: 0.409809\n",
      "epoch 82; iter: 0; batch classifier loss: 0.185963; batch adversarial loss: 0.508434\n",
      "epoch 83; iter: 0; batch classifier loss: 0.154028; batch adversarial loss: 0.508376\n",
      "epoch 84; iter: 0; batch classifier loss: 0.191176; batch adversarial loss: 0.434253\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073407; batch adversarial loss: 0.458595\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083580; batch adversarial loss: 0.533361\n",
      "epoch 87; iter: 0; batch classifier loss: 0.084743; batch adversarial loss: 0.580211\n",
      "epoch 88; iter: 0; batch classifier loss: 0.090339; batch adversarial loss: 0.444785\n",
      "epoch 89; iter: 0; batch classifier loss: 0.082213; batch adversarial loss: 0.383826\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048359; batch adversarial loss: 0.371262\n",
      "epoch 91; iter: 0; batch classifier loss: 0.072992; batch adversarial loss: 0.583801\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060863; batch adversarial loss: 0.432493\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054391; batch adversarial loss: 0.446369\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061809; batch adversarial loss: 0.441381\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079537; batch adversarial loss: 0.492388\n",
      "epoch 96; iter: 0; batch classifier loss: 0.078814; batch adversarial loss: 0.394995\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055474; batch adversarial loss: 0.482507\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072646; batch adversarial loss: 0.446837\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042278; batch adversarial loss: 0.476215\n",
      "epoch 100; iter: 0; batch classifier loss: 0.098929; batch adversarial loss: 0.418938\n",
      "epoch 101; iter: 0; batch classifier loss: 0.045895; batch adversarial loss: 0.499177\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044546; batch adversarial loss: 0.497686\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050125; batch adversarial loss: 0.433110\n",
      "epoch 104; iter: 0; batch classifier loss: 0.080052; batch adversarial loss: 0.475369\n",
      "epoch 105; iter: 0; batch classifier loss: 0.095781; batch adversarial loss: 0.556580\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035230; batch adversarial loss: 0.502271\n",
      "epoch 107; iter: 0; batch classifier loss: 0.064134; batch adversarial loss: 0.469438\n",
      "epoch 108; iter: 0; batch classifier loss: 0.093405; batch adversarial loss: 0.365862\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036215; batch adversarial loss: 0.555485\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037082; batch adversarial loss: 0.439704\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041503; batch adversarial loss: 0.569554\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040217; batch adversarial loss: 0.530456\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035307; batch adversarial loss: 0.423439\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028944; batch adversarial loss: 0.485464\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063590; batch adversarial loss: 0.389070\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046923; batch adversarial loss: 0.425808\n",
      "epoch 117; iter: 0; batch classifier loss: 0.071538; batch adversarial loss: 0.430330\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044482; batch adversarial loss: 0.494103\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035262; batch adversarial loss: 0.528468\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039617; batch adversarial loss: 0.410064\n",
      "epoch 121; iter: 0; batch classifier loss: 0.063854; batch adversarial loss: 0.432142\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031538; batch adversarial loss: 0.462459\n",
      "epoch 123; iter: 0; batch classifier loss: 0.017779; batch adversarial loss: 0.389526\n",
      "epoch 124; iter: 0; batch classifier loss: 0.013219; batch adversarial loss: 0.490107\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054855; batch adversarial loss: 0.529955\n",
      "epoch 126; iter: 0; batch classifier loss: 0.016494; batch adversarial loss: 0.456058\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022771; batch adversarial loss: 0.382647\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037046; batch adversarial loss: 0.446328\n",
      "epoch 129; iter: 0; batch classifier loss: 0.073789; batch adversarial loss: 0.405825\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024186; batch adversarial loss: 0.517408\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035106; batch adversarial loss: 0.471799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.046251; batch adversarial loss: 0.546415\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038769; batch adversarial loss: 0.449345\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036452; batch adversarial loss: 0.418606\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012541; batch adversarial loss: 0.494548\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017327; batch adversarial loss: 0.405461\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018971; batch adversarial loss: 0.495772\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027675; batch adversarial loss: 0.476743\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031166; batch adversarial loss: 0.516381\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025463; batch adversarial loss: 0.383948\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032378; batch adversarial loss: 0.355290\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016103; batch adversarial loss: 0.440447\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024367; batch adversarial loss: 0.486847\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037096; batch adversarial loss: 0.417552\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038982; batch adversarial loss: 0.418097\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019175; batch adversarial loss: 0.467346\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013018; batch adversarial loss: 0.523720\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018604; batch adversarial loss: 0.411893\n",
      "epoch 149; iter: 0; batch classifier loss: 0.006898; batch adversarial loss: 0.473206\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033910; batch adversarial loss: 0.510813\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020807; batch adversarial loss: 0.470223\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017642; batch adversarial loss: 0.456460\n",
      "epoch 153; iter: 0; batch classifier loss: 0.005723; batch adversarial loss: 0.579462\n",
      "epoch 154; iter: 0; batch classifier loss: 0.008879; batch adversarial loss: 0.428862\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032435; batch adversarial loss: 0.419278\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030296; batch adversarial loss: 0.405288\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021247; batch adversarial loss: 0.388190\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030283; batch adversarial loss: 0.410111\n",
      "epoch 159; iter: 0; batch classifier loss: 0.007717; batch adversarial loss: 0.418486\n",
      "epoch 160; iter: 0; batch classifier loss: 0.006711; batch adversarial loss: 0.461313\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012896; batch adversarial loss: 0.493441\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007494; batch adversarial loss: 0.477848\n",
      "epoch 163; iter: 0; batch classifier loss: 0.053453; batch adversarial loss: 0.395624\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037679; batch adversarial loss: 0.420753\n",
      "epoch 165; iter: 0; batch classifier loss: 0.049281; batch adversarial loss: 0.359474\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025366; batch adversarial loss: 0.465029\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026625; batch adversarial loss: 0.394864\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021447; batch adversarial loss: 0.469494\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030469; batch adversarial loss: 0.496115\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028784; batch adversarial loss: 0.374671\n",
      "epoch 171; iter: 0; batch classifier loss: 0.059245; batch adversarial loss: 0.462333\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018829; batch adversarial loss: 0.478612\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019154; batch adversarial loss: 0.353600\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020764; batch adversarial loss: 0.463202\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021643; batch adversarial loss: 0.384244\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028925; batch adversarial loss: 0.438280\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017090; batch adversarial loss: 0.437544\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023516; batch adversarial loss: 0.520645\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011975; batch adversarial loss: 0.451983\n",
      "epoch 180; iter: 0; batch classifier loss: 0.004674; batch adversarial loss: 0.529882\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017022; batch adversarial loss: 0.421127\n",
      "epoch 182; iter: 0; batch classifier loss: 0.004062; batch adversarial loss: 0.439174\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015719; batch adversarial loss: 0.411054\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006855; batch adversarial loss: 0.418608\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020181; batch adversarial loss: 0.486703\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018415; batch adversarial loss: 0.444485\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024118; batch adversarial loss: 0.547085\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009631; batch adversarial loss: 0.470987\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033219; batch adversarial loss: 0.500229\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004176; batch adversarial loss: 0.514399\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026630; batch adversarial loss: 0.414407\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004338; batch adversarial loss: 0.406538\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025261; batch adversarial loss: 0.437083\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015449; batch adversarial loss: 0.524747\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009926; batch adversarial loss: 0.378479\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008072; batch adversarial loss: 0.419816\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020298; batch adversarial loss: 0.398277\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005557; batch adversarial loss: 0.492128\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007392; batch adversarial loss: 0.484055\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691421; batch adversarial loss: 0.757142\n",
      "epoch 1; iter: 0; batch classifier loss: 0.421594; batch adversarial loss: 0.709731\n",
      "epoch 2; iter: 0; batch classifier loss: 0.330826; batch adversarial loss: 0.663123\n",
      "epoch 3; iter: 0; batch classifier loss: 0.307431; batch adversarial loss: 0.639561\n",
      "epoch 4; iter: 0; batch classifier loss: 0.351051; batch adversarial loss: 0.599542\n",
      "epoch 5; iter: 0; batch classifier loss: 0.310568; batch adversarial loss: 0.576952\n",
      "epoch 6; iter: 0; batch classifier loss: 0.323449; batch adversarial loss: 0.535195\n",
      "epoch 7; iter: 0; batch classifier loss: 0.225228; batch adversarial loss: 0.510589\n",
      "epoch 8; iter: 0; batch classifier loss: 0.234528; batch adversarial loss: 0.547182\n",
      "epoch 9; iter: 0; batch classifier loss: 0.271495; batch adversarial loss: 0.478358\n",
      "epoch 10; iter: 0; batch classifier loss: 0.207990; batch adversarial loss: 0.455280\n",
      "epoch 11; iter: 0; batch classifier loss: 0.283159; batch adversarial loss: 0.471102\n",
      "epoch 12; iter: 0; batch classifier loss: 0.304209; batch adversarial loss: 0.454467\n",
      "epoch 13; iter: 0; batch classifier loss: 0.247576; batch adversarial loss: 0.504855\n",
      "epoch 14; iter: 0; batch classifier loss: 0.245574; batch adversarial loss: 0.500799\n",
      "epoch 15; iter: 0; batch classifier loss: 0.216284; batch adversarial loss: 0.489576\n",
      "epoch 16; iter: 0; batch classifier loss: 0.205760; batch adversarial loss: 0.491945\n",
      "epoch 17; iter: 0; batch classifier loss: 0.197028; batch adversarial loss: 0.484704\n",
      "epoch 18; iter: 0; batch classifier loss: 0.146226; batch adversarial loss: 0.426425\n",
      "epoch 19; iter: 0; batch classifier loss: 0.178753; batch adversarial loss: 0.495324\n",
      "epoch 20; iter: 0; batch classifier loss: 0.147499; batch adversarial loss: 0.389717\n",
      "epoch 21; iter: 0; batch classifier loss: 0.148209; batch adversarial loss: 0.386003\n",
      "epoch 22; iter: 0; batch classifier loss: 0.148777; batch adversarial loss: 0.479652\n",
      "epoch 23; iter: 0; batch classifier loss: 0.172592; batch adversarial loss: 0.413638\n",
      "epoch 24; iter: 0; batch classifier loss: 0.162523; batch adversarial loss: 0.362246\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177609; batch adversarial loss: 0.369589\n",
      "epoch 26; iter: 0; batch classifier loss: 0.158999; batch adversarial loss: 0.436452\n",
      "epoch 27; iter: 0; batch classifier loss: 0.199560; batch adversarial loss: 0.467319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.165294; batch adversarial loss: 0.507293\n",
      "epoch 29; iter: 0; batch classifier loss: 0.133891; batch adversarial loss: 0.428601\n",
      "epoch 30; iter: 0; batch classifier loss: 0.192628; batch adversarial loss: 0.388982\n",
      "epoch 31; iter: 0; batch classifier loss: 0.182171; batch adversarial loss: 0.446147\n",
      "epoch 32; iter: 0; batch classifier loss: 0.163767; batch adversarial loss: 0.452429\n",
      "epoch 33; iter: 0; batch classifier loss: 0.132738; batch adversarial loss: 0.381848\n",
      "epoch 34; iter: 0; batch classifier loss: 0.174594; batch adversarial loss: 0.420051\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137802; batch adversarial loss: 0.381051\n",
      "epoch 36; iter: 0; batch classifier loss: 0.103163; batch adversarial loss: 0.487166\n",
      "epoch 37; iter: 0; batch classifier loss: 0.106644; batch adversarial loss: 0.346232\n",
      "epoch 38; iter: 0; batch classifier loss: 0.213598; batch adversarial loss: 0.477828\n",
      "epoch 39; iter: 0; batch classifier loss: 0.150020; batch adversarial loss: 0.380376\n",
      "epoch 40; iter: 0; batch classifier loss: 0.130504; batch adversarial loss: 0.453995\n",
      "epoch 41; iter: 0; batch classifier loss: 0.116301; batch adversarial loss: 0.360022\n",
      "epoch 42; iter: 0; batch classifier loss: 0.087112; batch adversarial loss: 0.386813\n",
      "epoch 43; iter: 0; batch classifier loss: 0.170231; batch adversarial loss: 0.404196\n",
      "epoch 44; iter: 0; batch classifier loss: 0.135774; batch adversarial loss: 0.370654\n",
      "epoch 45; iter: 0; batch classifier loss: 0.114253; batch adversarial loss: 0.350727\n",
      "epoch 46; iter: 0; batch classifier loss: 0.120734; batch adversarial loss: 0.335123\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114322; batch adversarial loss: 0.424907\n",
      "epoch 48; iter: 0; batch classifier loss: 0.094067; batch adversarial loss: 0.466781\n",
      "epoch 49; iter: 0; batch classifier loss: 0.135495; batch adversarial loss: 0.432357\n",
      "epoch 50; iter: 0; batch classifier loss: 0.069297; batch adversarial loss: 0.420880\n",
      "epoch 51; iter: 0; batch classifier loss: 0.174458; batch adversarial loss: 0.372211\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161558; batch adversarial loss: 0.447983\n",
      "epoch 53; iter: 0; batch classifier loss: 0.102976; batch adversarial loss: 0.366659\n",
      "epoch 54; iter: 0; batch classifier loss: 0.083647; batch adversarial loss: 0.458806\n",
      "epoch 55; iter: 0; batch classifier loss: 0.094363; batch adversarial loss: 0.387905\n",
      "epoch 56; iter: 0; batch classifier loss: 0.093755; batch adversarial loss: 0.439421\n",
      "epoch 57; iter: 0; batch classifier loss: 0.075452; batch adversarial loss: 0.419657\n",
      "epoch 58; iter: 0; batch classifier loss: 0.107804; batch adversarial loss: 0.386611\n",
      "epoch 59; iter: 0; batch classifier loss: 0.095007; batch adversarial loss: 0.397902\n",
      "epoch 60; iter: 0; batch classifier loss: 0.107479; batch adversarial loss: 0.397285\n",
      "epoch 61; iter: 0; batch classifier loss: 0.116367; batch adversarial loss: 0.504429\n",
      "epoch 62; iter: 0; batch classifier loss: 0.075512; batch adversarial loss: 0.399853\n",
      "epoch 63; iter: 0; batch classifier loss: 0.137036; batch adversarial loss: 0.488722\n",
      "epoch 64; iter: 0; batch classifier loss: 0.092432; batch adversarial loss: 0.421230\n",
      "epoch 65; iter: 0; batch classifier loss: 0.101130; batch adversarial loss: 0.440496\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084937; batch adversarial loss: 0.276693\n",
      "epoch 67; iter: 0; batch classifier loss: 0.041750; batch adversarial loss: 0.392624\n",
      "epoch 68; iter: 0; batch classifier loss: 0.074799; batch adversarial loss: 0.436654\n",
      "epoch 69; iter: 0; batch classifier loss: 0.089085; batch adversarial loss: 0.411958\n",
      "epoch 70; iter: 0; batch classifier loss: 0.092794; batch adversarial loss: 0.383876\n",
      "epoch 71; iter: 0; batch classifier loss: 0.102617; batch adversarial loss: 0.434802\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097949; batch adversarial loss: 0.431891\n",
      "epoch 73; iter: 0; batch classifier loss: 0.081057; batch adversarial loss: 0.386593\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053649; batch adversarial loss: 0.407006\n",
      "epoch 75; iter: 0; batch classifier loss: 0.111963; batch adversarial loss: 0.534359\n",
      "epoch 76; iter: 0; batch classifier loss: 0.095645; batch adversarial loss: 0.466036\n",
      "epoch 77; iter: 0; batch classifier loss: 0.094416; batch adversarial loss: 0.416968\n",
      "epoch 78; iter: 0; batch classifier loss: 0.101050; batch adversarial loss: 0.429851\n",
      "epoch 79; iter: 0; batch classifier loss: 0.079586; batch adversarial loss: 0.436213\n",
      "epoch 80; iter: 0; batch classifier loss: 0.094045; batch adversarial loss: 0.450328\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071746; batch adversarial loss: 0.474200\n",
      "epoch 82; iter: 0; batch classifier loss: 0.092274; batch adversarial loss: 0.516319\n",
      "epoch 83; iter: 0; batch classifier loss: 0.041885; batch adversarial loss: 0.463658\n",
      "epoch 84; iter: 0; batch classifier loss: 0.096511; batch adversarial loss: 0.437328\n",
      "epoch 85; iter: 0; batch classifier loss: 0.102122; batch adversarial loss: 0.425834\n",
      "epoch 86; iter: 0; batch classifier loss: 0.086726; batch adversarial loss: 0.443892\n",
      "epoch 87; iter: 0; batch classifier loss: 0.087422; batch adversarial loss: 0.448688\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057638; batch adversarial loss: 0.419270\n",
      "epoch 89; iter: 0; batch classifier loss: 0.078268; batch adversarial loss: 0.437136\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053486; batch adversarial loss: 0.441451\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074493; batch adversarial loss: 0.362809\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058896; batch adversarial loss: 0.433414\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065900; batch adversarial loss: 0.432813\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075126; batch adversarial loss: 0.431716\n",
      "epoch 95; iter: 0; batch classifier loss: 0.099900; batch adversarial loss: 0.397320\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049069; batch adversarial loss: 0.464770\n",
      "epoch 97; iter: 0; batch classifier loss: 0.108134; batch adversarial loss: 0.484911\n",
      "epoch 98; iter: 0; batch classifier loss: 0.100431; batch adversarial loss: 0.437969\n",
      "epoch 99; iter: 0; batch classifier loss: 0.060844; batch adversarial loss: 0.402447\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037183; batch adversarial loss: 0.414895\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055893; batch adversarial loss: 0.388781\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052849; batch adversarial loss: 0.432352\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049883; batch adversarial loss: 0.391077\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057892; batch adversarial loss: 0.411777\n",
      "epoch 105; iter: 0; batch classifier loss: 0.069835; batch adversarial loss: 0.399985\n",
      "epoch 106; iter: 0; batch classifier loss: 0.115584; batch adversarial loss: 0.552571\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047855; batch adversarial loss: 0.449078\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069339; batch adversarial loss: 0.444145\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062270; batch adversarial loss: 0.472224\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040084; batch adversarial loss: 0.392106\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057758; batch adversarial loss: 0.446826\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041778; batch adversarial loss: 0.412259\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034699; batch adversarial loss: 0.419447\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026723; batch adversarial loss: 0.443122\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042740; batch adversarial loss: 0.470929\n",
      "epoch 116; iter: 0; batch classifier loss: 0.031807; batch adversarial loss: 0.438234\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038464; batch adversarial loss: 0.448567\n",
      "epoch 118; iter: 0; batch classifier loss: 0.073714; batch adversarial loss: 0.486044\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041446; batch adversarial loss: 0.503571\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055681; batch adversarial loss: 0.369401\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035295; batch adversarial loss: 0.420696\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048313; batch adversarial loss: 0.384013\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033953; batch adversarial loss: 0.463149\n",
      "epoch 124; iter: 0; batch classifier loss: 0.015801; batch adversarial loss: 0.449099\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030809; batch adversarial loss: 0.448277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.032013; batch adversarial loss: 0.442217\n",
      "epoch 127; iter: 0; batch classifier loss: 0.054016; batch adversarial loss: 0.487373\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031734; batch adversarial loss: 0.507703\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031129; batch adversarial loss: 0.440524\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039625; batch adversarial loss: 0.436392\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031744; batch adversarial loss: 0.446089\n",
      "epoch 132; iter: 0; batch classifier loss: 0.147577; batch adversarial loss: 0.590929\n",
      "epoch 133; iter: 0; batch classifier loss: 0.054124; batch adversarial loss: 0.535949\n",
      "epoch 134; iter: 0; batch classifier loss: 0.107404; batch adversarial loss: 0.574679\n",
      "epoch 135; iter: 0; batch classifier loss: 0.133975; batch adversarial loss: 0.554734\n",
      "epoch 136; iter: 0; batch classifier loss: 0.150317; batch adversarial loss: 0.640932\n",
      "epoch 137; iter: 0; batch classifier loss: 0.126757; batch adversarial loss: 0.512685\n",
      "epoch 138; iter: 0; batch classifier loss: 0.098362; batch adversarial loss: 0.561723\n",
      "epoch 139; iter: 0; batch classifier loss: 0.083377; batch adversarial loss: 0.438135\n",
      "epoch 140; iter: 0; batch classifier loss: 0.131222; batch adversarial loss: 0.649326\n",
      "epoch 141; iter: 0; batch classifier loss: 0.209444; batch adversarial loss: 0.688514\n",
      "epoch 142; iter: 0; batch classifier loss: 0.091085; batch adversarial loss: 0.533292\n",
      "epoch 143; iter: 0; batch classifier loss: 0.180365; batch adversarial loss: 0.571433\n",
      "epoch 144; iter: 0; batch classifier loss: 0.200355; batch adversarial loss: 0.607484\n",
      "epoch 145; iter: 0; batch classifier loss: 0.098830; batch adversarial loss: 0.439572\n",
      "epoch 146; iter: 0; batch classifier loss: 0.192714; batch adversarial loss: 0.559126\n",
      "epoch 147; iter: 0; batch classifier loss: 0.105695; batch adversarial loss: 0.476957\n",
      "epoch 148; iter: 0; batch classifier loss: 0.127356; batch adversarial loss: 0.545579\n",
      "epoch 149; iter: 0; batch classifier loss: 0.160810; batch adversarial loss: 0.643791\n",
      "epoch 150; iter: 0; batch classifier loss: 0.182891; batch adversarial loss: 0.565951\n",
      "epoch 151; iter: 0; batch classifier loss: 0.198473; batch adversarial loss: 0.542607\n",
      "epoch 152; iter: 0; batch classifier loss: 0.181748; batch adversarial loss: 0.576468\n",
      "epoch 153; iter: 0; batch classifier loss: 0.124943; batch adversarial loss: 0.531685\n",
      "epoch 154; iter: 0; batch classifier loss: 0.147100; batch adversarial loss: 0.505092\n",
      "epoch 155; iter: 0; batch classifier loss: 0.125362; batch adversarial loss: 0.480336\n",
      "epoch 156; iter: 0; batch classifier loss: 0.164651; batch adversarial loss: 0.699070\n",
      "epoch 157; iter: 0; batch classifier loss: 0.159584; batch adversarial loss: 0.548768\n",
      "epoch 158; iter: 0; batch classifier loss: 0.130724; batch adversarial loss: 0.488656\n",
      "epoch 159; iter: 0; batch classifier loss: 0.150435; batch adversarial loss: 0.493155\n",
      "epoch 160; iter: 0; batch classifier loss: 0.117721; batch adversarial loss: 0.514867\n",
      "epoch 161; iter: 0; batch classifier loss: 0.131770; batch adversarial loss: 0.569165\n",
      "epoch 162; iter: 0; batch classifier loss: 0.138827; batch adversarial loss: 0.572227\n",
      "epoch 163; iter: 0; batch classifier loss: 0.108110; batch adversarial loss: 0.365241\n",
      "epoch 164; iter: 0; batch classifier loss: 0.160520; batch adversarial loss: 0.546920\n",
      "epoch 165; iter: 0; batch classifier loss: 0.147991; batch adversarial loss: 0.601213\n",
      "epoch 166; iter: 0; batch classifier loss: 0.098385; batch adversarial loss: 0.404980\n",
      "epoch 167; iter: 0; batch classifier loss: 0.120157; batch adversarial loss: 0.542773\n",
      "epoch 168; iter: 0; batch classifier loss: 0.118902; batch adversarial loss: 0.425449\n",
      "epoch 169; iter: 0; batch classifier loss: 0.101136; batch adversarial loss: 0.445416\n",
      "epoch 170; iter: 0; batch classifier loss: 0.100344; batch adversarial loss: 0.455073\n",
      "epoch 171; iter: 0; batch classifier loss: 0.075766; batch adversarial loss: 0.391311\n",
      "epoch 172; iter: 0; batch classifier loss: 0.102510; batch adversarial loss: 0.500510\n",
      "epoch 173; iter: 0; batch classifier loss: 0.102431; batch adversarial loss: 0.535311\n",
      "epoch 174; iter: 0; batch classifier loss: 0.070078; batch adversarial loss: 0.484981\n",
      "epoch 175; iter: 0; batch classifier loss: 0.078990; batch adversarial loss: 0.494014\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026687; batch adversarial loss: 0.434782\n",
      "epoch 177; iter: 0; batch classifier loss: 0.059996; batch adversarial loss: 0.493017\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013579; batch adversarial loss: 0.434182\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043313; batch adversarial loss: 0.465852\n",
      "epoch 180; iter: 0; batch classifier loss: 0.058609; batch adversarial loss: 0.457139\n",
      "epoch 181; iter: 0; batch classifier loss: 0.050948; batch adversarial loss: 0.444795\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031011; batch adversarial loss: 0.386605\n",
      "epoch 183; iter: 0; batch classifier loss: 0.059263; batch adversarial loss: 0.345993\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033085; batch adversarial loss: 0.402474\n",
      "epoch 185; iter: 0; batch classifier loss: 0.056601; batch adversarial loss: 0.403719\n",
      "epoch 186; iter: 0; batch classifier loss: 0.049200; batch adversarial loss: 0.549185\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024443; batch adversarial loss: 0.383176\n",
      "epoch 188; iter: 0; batch classifier loss: 0.063045; batch adversarial loss: 0.392070\n",
      "epoch 189; iter: 0; batch classifier loss: 0.059213; batch adversarial loss: 0.356613\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022296; batch adversarial loss: 0.523979\n",
      "epoch 191; iter: 0; batch classifier loss: 0.042678; batch adversarial loss: 0.472102\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027425; batch adversarial loss: 0.421957\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037847; batch adversarial loss: 0.446332\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028337; batch adversarial loss: 0.566087\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031720; batch adversarial loss: 0.543824\n",
      "epoch 196; iter: 0; batch classifier loss: 0.034627; batch adversarial loss: 0.415628\n",
      "epoch 197; iter: 0; batch classifier loss: 0.043932; batch adversarial loss: 0.458476\n",
      "epoch 198; iter: 0; batch classifier loss: 0.061686; batch adversarial loss: 0.577432\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028305; batch adversarial loss: 0.425595\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686912; batch adversarial loss: 0.564643\n",
      "epoch 1; iter: 0; batch classifier loss: 0.389981; batch adversarial loss: 0.635056\n",
      "epoch 2; iter: 0; batch classifier loss: 0.339249; batch adversarial loss: 0.583671\n",
      "epoch 3; iter: 0; batch classifier loss: 0.406708; batch adversarial loss: 0.563876\n",
      "epoch 4; iter: 0; batch classifier loss: 0.313598; batch adversarial loss: 0.571065\n",
      "epoch 5; iter: 0; batch classifier loss: 0.291461; batch adversarial loss: 0.547142\n",
      "epoch 6; iter: 0; batch classifier loss: 0.252327; batch adversarial loss: 0.501720\n",
      "epoch 7; iter: 0; batch classifier loss: 0.326128; batch adversarial loss: 0.498527\n",
      "epoch 8; iter: 0; batch classifier loss: 0.262574; batch adversarial loss: 0.497904\n",
      "epoch 9; iter: 0; batch classifier loss: 0.273455; batch adversarial loss: 0.473596\n",
      "epoch 10; iter: 0; batch classifier loss: 0.257988; batch adversarial loss: 0.520783\n",
      "epoch 11; iter: 0; batch classifier loss: 0.185946; batch adversarial loss: 0.413135\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285328; batch adversarial loss: 0.498179\n",
      "epoch 13; iter: 0; batch classifier loss: 0.226096; batch adversarial loss: 0.547727\n",
      "epoch 14; iter: 0; batch classifier loss: 0.233962; batch adversarial loss: 0.555525\n",
      "epoch 15; iter: 0; batch classifier loss: 0.216897; batch adversarial loss: 0.562454\n",
      "epoch 16; iter: 0; batch classifier loss: 0.221321; batch adversarial loss: 0.500050\n",
      "epoch 17; iter: 0; batch classifier loss: 0.201957; batch adversarial loss: 0.513794\n",
      "epoch 18; iter: 0; batch classifier loss: 0.194008; batch adversarial loss: 0.484810\n",
      "epoch 19; iter: 0; batch classifier loss: 0.275657; batch adversarial loss: 0.506333\n",
      "epoch 20; iter: 0; batch classifier loss: 0.242081; batch adversarial loss: 0.513568\n",
      "epoch 21; iter: 0; batch classifier loss: 0.237500; batch adversarial loss: 0.446332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.214837; batch adversarial loss: 0.524218\n",
      "epoch 23; iter: 0; batch classifier loss: 0.248694; batch adversarial loss: 0.513200\n",
      "epoch 24; iter: 0; batch classifier loss: 0.266094; batch adversarial loss: 0.515510\n",
      "epoch 25; iter: 0; batch classifier loss: 0.238277; batch adversarial loss: 0.488756\n",
      "epoch 26; iter: 0; batch classifier loss: 0.235616; batch adversarial loss: 0.441178\n",
      "epoch 27; iter: 0; batch classifier loss: 0.216444; batch adversarial loss: 0.472214\n",
      "epoch 28; iter: 0; batch classifier loss: 0.352222; batch adversarial loss: 0.440474\n",
      "epoch 29; iter: 0; batch classifier loss: 0.267852; batch adversarial loss: 0.455118\n",
      "epoch 30; iter: 0; batch classifier loss: 0.181199; batch adversarial loss: 0.480603\n",
      "epoch 31; iter: 0; batch classifier loss: 0.200491; batch adversarial loss: 0.412963\n",
      "epoch 32; iter: 0; batch classifier loss: 0.124421; batch adversarial loss: 0.350234\n",
      "epoch 33; iter: 0; batch classifier loss: 0.094301; batch adversarial loss: 0.366680\n",
      "epoch 34; iter: 0; batch classifier loss: 0.160609; batch adversarial loss: 0.352447\n",
      "epoch 35; iter: 0; batch classifier loss: 0.147300; batch adversarial loss: 0.445140\n",
      "epoch 36; iter: 0; batch classifier loss: 0.075335; batch adversarial loss: 0.422914\n",
      "epoch 37; iter: 0; batch classifier loss: 0.107908; batch adversarial loss: 0.528324\n",
      "epoch 38; iter: 0; batch classifier loss: 0.122292; batch adversarial loss: 0.411208\n",
      "epoch 39; iter: 0; batch classifier loss: 0.089479; batch adversarial loss: 0.474697\n",
      "epoch 40; iter: 0; batch classifier loss: 0.073635; batch adversarial loss: 0.548696\n",
      "epoch 41; iter: 0; batch classifier loss: 0.096950; batch adversarial loss: 0.495159\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105006; batch adversarial loss: 0.484625\n",
      "epoch 43; iter: 0; batch classifier loss: 0.100275; batch adversarial loss: 0.433344\n",
      "epoch 44; iter: 0; batch classifier loss: 0.088785; batch adversarial loss: 0.383218\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086440; batch adversarial loss: 0.406604\n",
      "epoch 46; iter: 0; batch classifier loss: 0.100521; batch adversarial loss: 0.414775\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114770; batch adversarial loss: 0.510865\n",
      "epoch 48; iter: 0; batch classifier loss: 0.091280; batch adversarial loss: 0.419234\n",
      "epoch 49; iter: 0; batch classifier loss: 0.104558; batch adversarial loss: 0.337293\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094886; batch adversarial loss: 0.393655\n",
      "epoch 51; iter: 0; batch classifier loss: 0.106753; batch adversarial loss: 0.438766\n",
      "epoch 52; iter: 0; batch classifier loss: 0.077827; batch adversarial loss: 0.470977\n",
      "epoch 53; iter: 0; batch classifier loss: 0.083488; batch adversarial loss: 0.435858\n",
      "epoch 54; iter: 0; batch classifier loss: 0.080810; batch adversarial loss: 0.442527\n",
      "epoch 55; iter: 0; batch classifier loss: 0.043838; batch adversarial loss: 0.574323\n",
      "epoch 56; iter: 0; batch classifier loss: 0.073957; batch adversarial loss: 0.408984\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072159; batch adversarial loss: 0.413201\n",
      "epoch 58; iter: 0; batch classifier loss: 0.063981; batch adversarial loss: 0.408134\n",
      "epoch 59; iter: 0; batch classifier loss: 0.091375; batch adversarial loss: 0.401978\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076720; batch adversarial loss: 0.347989\n",
      "epoch 61; iter: 0; batch classifier loss: 0.059166; batch adversarial loss: 0.403851\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094400; batch adversarial loss: 0.427247\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076412; batch adversarial loss: 0.416735\n",
      "epoch 64; iter: 0; batch classifier loss: 0.074376; batch adversarial loss: 0.430181\n",
      "epoch 65; iter: 0; batch classifier loss: 0.130375; batch adversarial loss: 0.378421\n",
      "epoch 66; iter: 0; batch classifier loss: 0.077862; batch adversarial loss: 0.421032\n",
      "epoch 67; iter: 0; batch classifier loss: 0.119413; batch adversarial loss: 0.398425\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082098; batch adversarial loss: 0.408526\n",
      "epoch 69; iter: 0; batch classifier loss: 0.063052; batch adversarial loss: 0.484354\n",
      "epoch 70; iter: 0; batch classifier loss: 0.100878; batch adversarial loss: 0.469042\n",
      "epoch 71; iter: 0; batch classifier loss: 0.096312; batch adversarial loss: 0.384156\n",
      "epoch 72; iter: 0; batch classifier loss: 0.098356; batch adversarial loss: 0.465385\n",
      "epoch 73; iter: 0; batch classifier loss: 0.053969; batch adversarial loss: 0.433756\n",
      "epoch 74; iter: 0; batch classifier loss: 0.074102; batch adversarial loss: 0.429710\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075672; batch adversarial loss: 0.469677\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063027; batch adversarial loss: 0.404197\n",
      "epoch 77; iter: 0; batch classifier loss: 0.097472; batch adversarial loss: 0.468567\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090833; batch adversarial loss: 0.336774\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082343; batch adversarial loss: 0.412557\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076007; batch adversarial loss: 0.501208\n",
      "epoch 81; iter: 0; batch classifier loss: 0.143906; batch adversarial loss: 0.436733\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090725; batch adversarial loss: 0.391492\n",
      "epoch 83; iter: 0; batch classifier loss: 0.106012; batch adversarial loss: 0.427070\n",
      "epoch 84; iter: 0; batch classifier loss: 0.069335; batch adversarial loss: 0.534761\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070665; batch adversarial loss: 0.385598\n",
      "epoch 86; iter: 0; batch classifier loss: 0.048184; batch adversarial loss: 0.501163\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049949; batch adversarial loss: 0.547639\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067814; batch adversarial loss: 0.519390\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081619; batch adversarial loss: 0.485931\n",
      "epoch 90; iter: 0; batch classifier loss: 0.074868; batch adversarial loss: 0.388380\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082523; batch adversarial loss: 0.375086\n",
      "epoch 92; iter: 0; batch classifier loss: 0.088179; batch adversarial loss: 0.458445\n",
      "epoch 93; iter: 0; batch classifier loss: 0.101490; batch adversarial loss: 0.430955\n",
      "epoch 94; iter: 0; batch classifier loss: 0.091815; batch adversarial loss: 0.418689\n",
      "epoch 95; iter: 0; batch classifier loss: 0.049674; batch adversarial loss: 0.474167\n",
      "epoch 96; iter: 0; batch classifier loss: 0.110943; batch adversarial loss: 0.401455\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056040; batch adversarial loss: 0.397961\n",
      "epoch 98; iter: 0; batch classifier loss: 0.093097; batch adversarial loss: 0.423255\n",
      "epoch 99; iter: 0; batch classifier loss: 0.083688; batch adversarial loss: 0.398494\n",
      "epoch 100; iter: 0; batch classifier loss: 0.103149; batch adversarial loss: 0.464753\n",
      "epoch 101; iter: 0; batch classifier loss: 0.036339; batch adversarial loss: 0.410191\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058849; batch adversarial loss: 0.448412\n",
      "epoch 103; iter: 0; batch classifier loss: 0.123003; batch adversarial loss: 0.359941\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063207; batch adversarial loss: 0.580204\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035351; batch adversarial loss: 0.547410\n",
      "epoch 106; iter: 0; batch classifier loss: 0.074607; batch adversarial loss: 0.439196\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037230; batch adversarial loss: 0.512681\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049393; batch adversarial loss: 0.496835\n",
      "epoch 109; iter: 0; batch classifier loss: 0.035073; batch adversarial loss: 0.385250\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053620; batch adversarial loss: 0.392786\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030987; batch adversarial loss: 0.408567\n",
      "epoch 112; iter: 0; batch classifier loss: 0.071546; batch adversarial loss: 0.455898\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052369; batch adversarial loss: 0.403521\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040464; batch adversarial loss: 0.513961\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049771; batch adversarial loss: 0.448824\n",
      "epoch 116; iter: 0; batch classifier loss: 0.058542; batch adversarial loss: 0.397276\n",
      "epoch 117; iter: 0; batch classifier loss: 0.126010; batch adversarial loss: 0.459127\n",
      "epoch 118; iter: 0; batch classifier loss: 0.072185; batch adversarial loss: 0.354283\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034907; batch adversarial loss: 0.459474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.070138; batch adversarial loss: 0.465826\n",
      "epoch 121; iter: 0; batch classifier loss: 0.096642; batch adversarial loss: 0.479764\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034238; batch adversarial loss: 0.446159\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055856; batch adversarial loss: 0.512243\n",
      "epoch 124; iter: 0; batch classifier loss: 0.060026; batch adversarial loss: 0.449270\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034459; batch adversarial loss: 0.427146\n",
      "epoch 126; iter: 0; batch classifier loss: 0.054763; batch adversarial loss: 0.392110\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039192; batch adversarial loss: 0.484138\n",
      "epoch 128; iter: 0; batch classifier loss: 0.061427; batch adversarial loss: 0.451942\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023094; batch adversarial loss: 0.377442\n",
      "epoch 130; iter: 0; batch classifier loss: 0.066824; batch adversarial loss: 0.473077\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037546; batch adversarial loss: 0.395219\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026761; batch adversarial loss: 0.514088\n",
      "epoch 133; iter: 0; batch classifier loss: 0.061444; batch adversarial loss: 0.393910\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062611; batch adversarial loss: 0.506600\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050895; batch adversarial loss: 0.491247\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033307; batch adversarial loss: 0.545564\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029356; batch adversarial loss: 0.432594\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041208; batch adversarial loss: 0.408168\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042957; batch adversarial loss: 0.406617\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028255; batch adversarial loss: 0.352565\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039125; batch adversarial loss: 0.431873\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042641; batch adversarial loss: 0.391486\n",
      "epoch 143; iter: 0; batch classifier loss: 0.066580; batch adversarial loss: 0.398870\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022382; batch adversarial loss: 0.391061\n",
      "epoch 145; iter: 0; batch classifier loss: 0.071763; batch adversarial loss: 0.356383\n",
      "epoch 146; iter: 0; batch classifier loss: 0.065084; batch adversarial loss: 0.450045\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024452; batch adversarial loss: 0.382107\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018935; batch adversarial loss: 0.361322\n",
      "epoch 149; iter: 0; batch classifier loss: 0.060883; batch adversarial loss: 0.421028\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014864; batch adversarial loss: 0.415398\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044329; batch adversarial loss: 0.468778\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023388; batch adversarial loss: 0.415331\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027094; batch adversarial loss: 0.533817\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044015; batch adversarial loss: 0.411596\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036976; batch adversarial loss: 0.445632\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023011; batch adversarial loss: 0.392142\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022624; batch adversarial loss: 0.390940\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035643; batch adversarial loss: 0.394259\n",
      "epoch 159; iter: 0; batch classifier loss: 0.071272; batch adversarial loss: 0.477539\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017051; batch adversarial loss: 0.467335\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021008; batch adversarial loss: 0.372418\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011080; batch adversarial loss: 0.430046\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039009; batch adversarial loss: 0.435279\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018186; batch adversarial loss: 0.479094\n",
      "epoch 165; iter: 0; batch classifier loss: 0.048724; batch adversarial loss: 0.435995\n",
      "epoch 166; iter: 0; batch classifier loss: 0.009517; batch adversarial loss: 0.390447\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022272; batch adversarial loss: 0.452007\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027576; batch adversarial loss: 0.424099\n",
      "epoch 169; iter: 0; batch classifier loss: 0.070519; batch adversarial loss: 0.457001\n",
      "epoch 170; iter: 0; batch classifier loss: 0.059603; batch adversarial loss: 0.410624\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016697; batch adversarial loss: 0.436596\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023560; batch adversarial loss: 0.447839\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035979; batch adversarial loss: 0.455068\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020720; batch adversarial loss: 0.368644\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021517; batch adversarial loss: 0.342321\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023463; batch adversarial loss: 0.412989\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013000; batch adversarial loss: 0.422453\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025528; batch adversarial loss: 0.486312\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022405; batch adversarial loss: 0.434853\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032538; batch adversarial loss: 0.369287\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033396; batch adversarial loss: 0.432633\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020690; batch adversarial loss: 0.405915\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030926; batch adversarial loss: 0.454561\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026302; batch adversarial loss: 0.421845\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017300; batch adversarial loss: 0.494795\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014361; batch adversarial loss: 0.470069\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020825; batch adversarial loss: 0.487404\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017794; batch adversarial loss: 0.486416\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020348; batch adversarial loss: 0.413449\n",
      "epoch 190; iter: 0; batch classifier loss: 0.051716; batch adversarial loss: 0.499842\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015918; batch adversarial loss: 0.488133\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025689; batch adversarial loss: 0.570657\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029845; batch adversarial loss: 0.358464\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021622; batch adversarial loss: 0.483438\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018920; batch adversarial loss: 0.387234\n",
      "epoch 196; iter: 0; batch classifier loss: 0.048011; batch adversarial loss: 0.432170\n",
      "epoch 197; iter: 0; batch classifier loss: 0.036461; batch adversarial loss: 0.365073\n",
      "epoch 198; iter: 0; batch classifier loss: 0.050449; batch adversarial loss: 0.392467\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008308; batch adversarial loss: 0.380842\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699085; batch adversarial loss: 0.903122\n",
      "epoch 1; iter: 0; batch classifier loss: 0.545042; batch adversarial loss: 0.906071\n",
      "epoch 2; iter: 0; batch classifier loss: 0.632150; batch adversarial loss: 0.881097\n",
      "epoch 3; iter: 0; batch classifier loss: 0.873741; batch adversarial loss: 0.830782\n",
      "epoch 4; iter: 0; batch classifier loss: 0.997282; batch adversarial loss: 0.754350\n",
      "epoch 5; iter: 0; batch classifier loss: 0.877833; batch adversarial loss: 0.676940\n",
      "epoch 6; iter: 0; batch classifier loss: 0.946002; batch adversarial loss: 0.612741\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527274; batch adversarial loss: 0.575339\n",
      "epoch 8; iter: 0; batch classifier loss: 0.381951; batch adversarial loss: 0.562618\n",
      "epoch 9; iter: 0; batch classifier loss: 0.391195; batch adversarial loss: 0.545961\n",
      "epoch 10; iter: 0; batch classifier loss: 0.338648; batch adversarial loss: 0.518230\n",
      "epoch 11; iter: 0; batch classifier loss: 0.287518; batch adversarial loss: 0.505021\n",
      "epoch 12; iter: 0; batch classifier loss: 0.346327; batch adversarial loss: 0.505002\n",
      "epoch 13; iter: 0; batch classifier loss: 0.400193; batch adversarial loss: 0.456190\n",
      "epoch 14; iter: 0; batch classifier loss: 0.319438; batch adversarial loss: 0.457580\n",
      "epoch 15; iter: 0; batch classifier loss: 0.278392; batch adversarial loss: 0.550019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.291399; batch adversarial loss: 0.504242\n",
      "epoch 17; iter: 0; batch classifier loss: 0.321602; batch adversarial loss: 0.454225\n",
      "epoch 18; iter: 0; batch classifier loss: 0.332826; batch adversarial loss: 0.477170\n",
      "epoch 19; iter: 0; batch classifier loss: 0.271254; batch adversarial loss: 0.523132\n",
      "epoch 20; iter: 0; batch classifier loss: 0.277552; batch adversarial loss: 0.458397\n",
      "epoch 21; iter: 0; batch classifier loss: 0.344109; batch adversarial loss: 0.456597\n",
      "epoch 22; iter: 0; batch classifier loss: 0.316708; batch adversarial loss: 0.463992\n",
      "epoch 23; iter: 0; batch classifier loss: 0.381843; batch adversarial loss: 0.486669\n",
      "epoch 24; iter: 0; batch classifier loss: 0.330930; batch adversarial loss: 0.488886\n",
      "epoch 25; iter: 0; batch classifier loss: 0.297604; batch adversarial loss: 0.458717\n",
      "epoch 26; iter: 0; batch classifier loss: 0.297071; batch adversarial loss: 0.580417\n",
      "epoch 27; iter: 0; batch classifier loss: 0.244757; batch adversarial loss: 0.480581\n",
      "epoch 28; iter: 0; batch classifier loss: 0.319958; batch adversarial loss: 0.505823\n",
      "epoch 29; iter: 0; batch classifier loss: 0.184293; batch adversarial loss: 0.591550\n",
      "epoch 30; iter: 0; batch classifier loss: 0.253611; batch adversarial loss: 0.499441\n",
      "epoch 31; iter: 0; batch classifier loss: 0.263909; batch adversarial loss: 0.517219\n",
      "epoch 32; iter: 0; batch classifier loss: 0.208745; batch adversarial loss: 0.461152\n",
      "epoch 33; iter: 0; batch classifier loss: 0.221234; batch adversarial loss: 0.454355\n",
      "epoch 34; iter: 0; batch classifier loss: 0.232847; batch adversarial loss: 0.454710\n",
      "epoch 35; iter: 0; batch classifier loss: 0.195152; batch adversarial loss: 0.523882\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187657; batch adversarial loss: 0.537849\n",
      "epoch 37; iter: 0; batch classifier loss: 0.195927; batch adversarial loss: 0.516911\n",
      "epoch 38; iter: 0; batch classifier loss: 0.252639; batch adversarial loss: 0.381086\n",
      "epoch 39; iter: 0; batch classifier loss: 0.190482; batch adversarial loss: 0.417839\n",
      "epoch 40; iter: 0; batch classifier loss: 0.223131; batch adversarial loss: 0.427661\n",
      "epoch 41; iter: 0; batch classifier loss: 0.145676; batch adversarial loss: 0.478900\n",
      "epoch 42; iter: 0; batch classifier loss: 0.153136; batch adversarial loss: 0.532677\n",
      "epoch 43; iter: 0; batch classifier loss: 0.156407; batch adversarial loss: 0.546541\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136280; batch adversarial loss: 0.529922\n",
      "epoch 45; iter: 0; batch classifier loss: 0.139891; batch adversarial loss: 0.440790\n",
      "epoch 46; iter: 0; batch classifier loss: 0.236724; batch adversarial loss: 0.383738\n",
      "epoch 47; iter: 0; batch classifier loss: 0.131807; batch adversarial loss: 0.459915\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125714; batch adversarial loss: 0.419039\n",
      "epoch 49; iter: 0; batch classifier loss: 0.118002; batch adversarial loss: 0.405884\n",
      "epoch 50; iter: 0; batch classifier loss: 0.156694; batch adversarial loss: 0.431008\n",
      "epoch 51; iter: 0; batch classifier loss: 0.118947; batch adversarial loss: 0.419666\n",
      "epoch 52; iter: 0; batch classifier loss: 0.092400; batch adversarial loss: 0.498307\n",
      "epoch 53; iter: 0; batch classifier loss: 0.099315; batch adversarial loss: 0.423634\n",
      "epoch 54; iter: 0; batch classifier loss: 0.097856; batch adversarial loss: 0.411114\n",
      "epoch 55; iter: 0; batch classifier loss: 0.103724; batch adversarial loss: 0.449133\n",
      "epoch 56; iter: 0; batch classifier loss: 0.094868; batch adversarial loss: 0.454231\n",
      "epoch 57; iter: 0; batch classifier loss: 0.116658; batch adversarial loss: 0.406929\n",
      "epoch 58; iter: 0; batch classifier loss: 0.108540; batch adversarial loss: 0.405005\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072409; batch adversarial loss: 0.450521\n",
      "epoch 60; iter: 0; batch classifier loss: 0.080430; batch adversarial loss: 0.387527\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074100; batch adversarial loss: 0.455671\n",
      "epoch 62; iter: 0; batch classifier loss: 0.100081; batch adversarial loss: 0.446918\n",
      "epoch 63; iter: 0; batch classifier loss: 0.068353; batch adversarial loss: 0.427322\n",
      "epoch 64; iter: 0; batch classifier loss: 0.066762; batch adversarial loss: 0.336034\n",
      "epoch 65; iter: 0; batch classifier loss: 0.043456; batch adversarial loss: 0.340631\n",
      "epoch 66; iter: 0; batch classifier loss: 0.064927; batch adversarial loss: 0.385621\n",
      "epoch 67; iter: 0; batch classifier loss: 0.083392; batch adversarial loss: 0.474999\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061642; batch adversarial loss: 0.463664\n",
      "epoch 69; iter: 0; batch classifier loss: 0.059979; batch adversarial loss: 0.441568\n",
      "epoch 70; iter: 0; batch classifier loss: 0.052176; batch adversarial loss: 0.489962\n",
      "epoch 71; iter: 0; batch classifier loss: 0.075507; batch adversarial loss: 0.444415\n",
      "epoch 72; iter: 0; batch classifier loss: 0.049213; batch adversarial loss: 0.477907\n",
      "epoch 73; iter: 0; batch classifier loss: 0.048353; batch adversarial loss: 0.387777\n",
      "epoch 74; iter: 0; batch classifier loss: 0.047686; batch adversarial loss: 0.462562\n",
      "epoch 75; iter: 0; batch classifier loss: 0.044148; batch adversarial loss: 0.440449\n",
      "epoch 76; iter: 0; batch classifier loss: 0.048808; batch adversarial loss: 0.520354\n",
      "epoch 77; iter: 0; batch classifier loss: 0.044900; batch adversarial loss: 0.486172\n",
      "epoch 78; iter: 0; batch classifier loss: 0.053237; batch adversarial loss: 0.508220\n",
      "epoch 79; iter: 0; batch classifier loss: 0.081166; batch adversarial loss: 0.523928\n",
      "epoch 80; iter: 0; batch classifier loss: 0.044987; batch adversarial loss: 0.418283\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076325; batch adversarial loss: 0.374732\n",
      "epoch 82; iter: 0; batch classifier loss: 0.089884; batch adversarial loss: 0.355557\n",
      "epoch 83; iter: 0; batch classifier loss: 0.025253; batch adversarial loss: 0.539141\n",
      "epoch 84; iter: 0; batch classifier loss: 0.023376; batch adversarial loss: 0.466035\n",
      "epoch 85; iter: 0; batch classifier loss: 0.043209; batch adversarial loss: 0.499114\n",
      "epoch 86; iter: 0; batch classifier loss: 0.044105; batch adversarial loss: 0.549774\n",
      "epoch 87; iter: 0; batch classifier loss: 0.028174; batch adversarial loss: 0.503587\n",
      "epoch 88; iter: 0; batch classifier loss: 0.033923; batch adversarial loss: 0.363989\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048825; batch adversarial loss: 0.511020\n",
      "epoch 90; iter: 0; batch classifier loss: 0.043247; batch adversarial loss: 0.476357\n",
      "epoch 91; iter: 0; batch classifier loss: 0.027084; batch adversarial loss: 0.387323\n",
      "epoch 92; iter: 0; batch classifier loss: 0.038359; batch adversarial loss: 0.411843\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043165; batch adversarial loss: 0.390895\n",
      "epoch 94; iter: 0; batch classifier loss: 0.029329; batch adversarial loss: 0.440659\n",
      "epoch 95; iter: 0; batch classifier loss: 0.033643; batch adversarial loss: 0.472347\n",
      "epoch 96; iter: 0; batch classifier loss: 0.028616; batch adversarial loss: 0.501313\n",
      "epoch 97; iter: 0; batch classifier loss: 0.036061; batch adversarial loss: 0.461398\n",
      "epoch 98; iter: 0; batch classifier loss: 0.018224; batch adversarial loss: 0.457290\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062663; batch adversarial loss: 0.517552\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034411; batch adversarial loss: 0.475968\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063308; batch adversarial loss: 0.501531\n",
      "epoch 102; iter: 0; batch classifier loss: 0.024848; batch adversarial loss: 0.403274\n",
      "epoch 103; iter: 0; batch classifier loss: 0.020314; batch adversarial loss: 0.399329\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033939; batch adversarial loss: 0.466124\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038541; batch adversarial loss: 0.440553\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034937; batch adversarial loss: 0.443386\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050145; batch adversarial loss: 0.459042\n",
      "epoch 108; iter: 0; batch classifier loss: 0.047357; batch adversarial loss: 0.323972\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032337; batch adversarial loss: 0.526121\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045951; batch adversarial loss: 0.458556\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034201; batch adversarial loss: 0.457553\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025288; batch adversarial loss: 0.469794\n",
      "epoch 113; iter: 0; batch classifier loss: 0.014696; batch adversarial loss: 0.540860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.014755; batch adversarial loss: 0.615037\n",
      "epoch 115; iter: 0; batch classifier loss: 0.030367; batch adversarial loss: 0.445499\n",
      "epoch 116; iter: 0; batch classifier loss: 0.022155; batch adversarial loss: 0.454205\n",
      "epoch 117; iter: 0; batch classifier loss: 0.015614; batch adversarial loss: 0.432574\n",
      "epoch 118; iter: 0; batch classifier loss: 0.018496; batch adversarial loss: 0.457254\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025228; batch adversarial loss: 0.519188\n",
      "epoch 120; iter: 0; batch classifier loss: 0.015902; batch adversarial loss: 0.387605\n",
      "epoch 121; iter: 0; batch classifier loss: 0.020031; batch adversarial loss: 0.437600\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040373; batch adversarial loss: 0.433146\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030599; batch adversarial loss: 0.349029\n",
      "epoch 124; iter: 0; batch classifier loss: 0.010471; batch adversarial loss: 0.414843\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028395; batch adversarial loss: 0.545236\n",
      "epoch 126; iter: 0; batch classifier loss: 0.015336; batch adversarial loss: 0.479775\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030215; batch adversarial loss: 0.480930\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023797; batch adversarial loss: 0.397434\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041599; batch adversarial loss: 0.438439\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017951; batch adversarial loss: 0.451760\n",
      "epoch 131; iter: 0; batch classifier loss: 0.007306; batch adversarial loss: 0.534015\n",
      "epoch 132; iter: 0; batch classifier loss: 0.017459; batch adversarial loss: 0.461578\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027437; batch adversarial loss: 0.458803\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052730; batch adversarial loss: 0.480035\n",
      "epoch 135; iter: 0; batch classifier loss: 0.015827; batch adversarial loss: 0.357063\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033517; batch adversarial loss: 0.469744\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022817; batch adversarial loss: 0.614467\n",
      "epoch 138; iter: 0; batch classifier loss: 0.005979; batch adversarial loss: 0.401033\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018705; batch adversarial loss: 0.418255\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020348; batch adversarial loss: 0.415074\n",
      "epoch 141; iter: 0; batch classifier loss: 0.041878; batch adversarial loss: 0.389715\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029320; batch adversarial loss: 0.445564\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022810; batch adversarial loss: 0.503314\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022730; batch adversarial loss: 0.365327\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040501; batch adversarial loss: 0.425866\n",
      "epoch 146; iter: 0; batch classifier loss: 0.011927; batch adversarial loss: 0.500522\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016708; batch adversarial loss: 0.508622\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030014; batch adversarial loss: 0.462203\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012183; batch adversarial loss: 0.427898\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025502; batch adversarial loss: 0.455758\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029896; batch adversarial loss: 0.454679\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022136; batch adversarial loss: 0.429437\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020086; batch adversarial loss: 0.517419\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012382; batch adversarial loss: 0.475876\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026079; batch adversarial loss: 0.411607\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030318; batch adversarial loss: 0.486641\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010958; batch adversarial loss: 0.450281\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017390; batch adversarial loss: 0.427175\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034572; batch adversarial loss: 0.439964\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015240; batch adversarial loss: 0.406580\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031635; batch adversarial loss: 0.474966\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013022; batch adversarial loss: 0.415824\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027351; batch adversarial loss: 0.517573\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020872; batch adversarial loss: 0.433479\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017343; batch adversarial loss: 0.489713\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031802; batch adversarial loss: 0.475855\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009398; batch adversarial loss: 0.461332\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008200; batch adversarial loss: 0.459275\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009911; batch adversarial loss: 0.505884\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015674; batch adversarial loss: 0.432243\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024921; batch adversarial loss: 0.424134\n",
      "epoch 172; iter: 0; batch classifier loss: 0.006656; batch adversarial loss: 0.487799\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015514; batch adversarial loss: 0.434081\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008319; batch adversarial loss: 0.459483\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018526; batch adversarial loss: 0.369101\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020472; batch adversarial loss: 0.493592\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042862; batch adversarial loss: 0.502996\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014955; batch adversarial loss: 0.433696\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018177; batch adversarial loss: 0.401355\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037958; batch adversarial loss: 0.448542\n",
      "epoch 181; iter: 0; batch classifier loss: 0.003567; batch adversarial loss: 0.472699\n",
      "epoch 182; iter: 0; batch classifier loss: 0.004365; batch adversarial loss: 0.443859\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027253; batch adversarial loss: 0.488948\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013615; batch adversarial loss: 0.400232\n",
      "epoch 185; iter: 0; batch classifier loss: 0.059773; batch adversarial loss: 0.408988\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017610; batch adversarial loss: 0.531827\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020291; batch adversarial loss: 0.446136\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024443; batch adversarial loss: 0.459011\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010251; batch adversarial loss: 0.442988\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023904; batch adversarial loss: 0.509136\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031637; batch adversarial loss: 0.367380\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006288; batch adversarial loss: 0.377452\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018190; batch adversarial loss: 0.336026\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008313; batch adversarial loss: 0.438574\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014945; batch adversarial loss: 0.506795\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025563; batch adversarial loss: 0.418658\n",
      "epoch 197; iter: 0; batch classifier loss: 0.003726; batch adversarial loss: 0.480945\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003415; batch adversarial loss: 0.507602\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008263; batch adversarial loss: 0.452755\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685274; batch adversarial loss: 0.597167\n",
      "epoch 1; iter: 0; batch classifier loss: 0.522381; batch adversarial loss: 0.601507\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396554; batch adversarial loss: 0.598493\n",
      "epoch 3; iter: 0; batch classifier loss: 0.305545; batch adversarial loss: 0.549898\n",
      "epoch 4; iter: 0; batch classifier loss: 0.343891; batch adversarial loss: 0.567240\n",
      "epoch 5; iter: 0; batch classifier loss: 0.415047; batch adversarial loss: 0.576776\n",
      "epoch 6; iter: 0; batch classifier loss: 0.336254; batch adversarial loss: 0.575018\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300179; batch adversarial loss: 0.563172\n",
      "epoch 8; iter: 0; batch classifier loss: 0.329453; batch adversarial loss: 0.536596\n",
      "epoch 9; iter: 0; batch classifier loss: 0.291364; batch adversarial loss: 0.622697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.306423; batch adversarial loss: 0.509311\n",
      "epoch 11; iter: 0; batch classifier loss: 0.281095; batch adversarial loss: 0.502304\n",
      "epoch 12; iter: 0; batch classifier loss: 0.239101; batch adversarial loss: 0.472741\n",
      "epoch 13; iter: 0; batch classifier loss: 0.247595; batch adversarial loss: 0.508136\n",
      "epoch 14; iter: 0; batch classifier loss: 0.234509; batch adversarial loss: 0.471863\n",
      "epoch 15; iter: 0; batch classifier loss: 0.311303; batch adversarial loss: 0.475098\n",
      "epoch 16; iter: 0; batch classifier loss: 0.266536; batch adversarial loss: 0.572776\n",
      "epoch 17; iter: 0; batch classifier loss: 0.304498; batch adversarial loss: 0.562819\n",
      "epoch 18; iter: 0; batch classifier loss: 0.445809; batch adversarial loss: 0.494454\n",
      "epoch 19; iter: 0; batch classifier loss: 0.397367; batch adversarial loss: 0.462107\n",
      "epoch 20; iter: 0; batch classifier loss: 0.551905; batch adversarial loss: 0.436863\n",
      "epoch 21; iter: 0; batch classifier loss: 0.270633; batch adversarial loss: 0.491616\n",
      "epoch 22; iter: 0; batch classifier loss: 0.190386; batch adversarial loss: 0.527746\n",
      "epoch 23; iter: 0; batch classifier loss: 0.178069; batch adversarial loss: 0.390351\n",
      "epoch 24; iter: 0; batch classifier loss: 0.184984; batch adversarial loss: 0.488077\n",
      "epoch 25; iter: 0; batch classifier loss: 0.168966; batch adversarial loss: 0.386029\n",
      "epoch 26; iter: 0; batch classifier loss: 0.153418; batch adversarial loss: 0.381645\n",
      "epoch 27; iter: 0; batch classifier loss: 0.189908; batch adversarial loss: 0.431310\n",
      "epoch 28; iter: 0; batch classifier loss: 0.172992; batch adversarial loss: 0.378213\n",
      "epoch 29; iter: 0; batch classifier loss: 0.116312; batch adversarial loss: 0.511706\n",
      "epoch 30; iter: 0; batch classifier loss: 0.214791; batch adversarial loss: 0.480450\n",
      "epoch 31; iter: 0; batch classifier loss: 0.151587; batch adversarial loss: 0.484185\n",
      "epoch 32; iter: 0; batch classifier loss: 0.150383; batch adversarial loss: 0.481507\n",
      "epoch 33; iter: 0; batch classifier loss: 0.144315; batch adversarial loss: 0.456362\n",
      "epoch 34; iter: 0; batch classifier loss: 0.109484; batch adversarial loss: 0.503555\n",
      "epoch 35; iter: 0; batch classifier loss: 0.113934; batch adversarial loss: 0.428734\n",
      "epoch 36; iter: 0; batch classifier loss: 0.106620; batch adversarial loss: 0.459548\n",
      "epoch 37; iter: 0; batch classifier loss: 0.126244; batch adversarial loss: 0.419529\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115290; batch adversarial loss: 0.369621\n",
      "epoch 39; iter: 0; batch classifier loss: 0.140580; batch adversarial loss: 0.491699\n",
      "epoch 40; iter: 0; batch classifier loss: 0.169467; batch adversarial loss: 0.380778\n",
      "epoch 41; iter: 0; batch classifier loss: 0.116005; batch adversarial loss: 0.459858\n",
      "epoch 42; iter: 0; batch classifier loss: 0.125427; batch adversarial loss: 0.402898\n",
      "epoch 43; iter: 0; batch classifier loss: 0.221334; batch adversarial loss: 0.433344\n",
      "epoch 44; iter: 0; batch classifier loss: 0.135450; batch adversarial loss: 0.406336\n",
      "epoch 45; iter: 0; batch classifier loss: 0.090948; batch adversarial loss: 0.480788\n",
      "epoch 46; iter: 0; batch classifier loss: 0.120371; batch adversarial loss: 0.420713\n",
      "epoch 47; iter: 0; batch classifier loss: 0.115645; batch adversarial loss: 0.512404\n",
      "epoch 48; iter: 0; batch classifier loss: 0.159716; batch adversarial loss: 0.443960\n",
      "epoch 49; iter: 0; batch classifier loss: 0.093639; batch adversarial loss: 0.432458\n",
      "epoch 50; iter: 0; batch classifier loss: 0.137135; batch adversarial loss: 0.390067\n",
      "epoch 51; iter: 0; batch classifier loss: 0.106796; batch adversarial loss: 0.504785\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112512; batch adversarial loss: 0.465928\n",
      "epoch 53; iter: 0; batch classifier loss: 0.124708; batch adversarial loss: 0.440573\n",
      "epoch 54; iter: 0; batch classifier loss: 0.085569; batch adversarial loss: 0.492324\n",
      "epoch 55; iter: 0; batch classifier loss: 0.156049; batch adversarial loss: 0.407926\n",
      "epoch 56; iter: 0; batch classifier loss: 0.121365; batch adversarial loss: 0.447342\n",
      "epoch 57; iter: 0; batch classifier loss: 0.120977; batch adversarial loss: 0.525741\n",
      "epoch 58; iter: 0; batch classifier loss: 0.098033; batch adversarial loss: 0.479346\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087217; batch adversarial loss: 0.434825\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081780; batch adversarial loss: 0.403013\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078663; batch adversarial loss: 0.468484\n",
      "epoch 62; iter: 0; batch classifier loss: 0.183171; batch adversarial loss: 0.426531\n",
      "epoch 63; iter: 0; batch classifier loss: 0.177626; batch adversarial loss: 0.401953\n",
      "epoch 64; iter: 0; batch classifier loss: 0.143779; batch adversarial loss: 0.383781\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075507; batch adversarial loss: 0.470692\n",
      "epoch 66; iter: 0; batch classifier loss: 0.125641; batch adversarial loss: 0.442413\n",
      "epoch 67; iter: 0; batch classifier loss: 0.130904; batch adversarial loss: 0.460708\n",
      "epoch 68; iter: 0; batch classifier loss: 0.132513; batch adversarial loss: 0.434469\n",
      "epoch 69; iter: 0; batch classifier loss: 0.132296; batch adversarial loss: 0.425823\n",
      "epoch 70; iter: 0; batch classifier loss: 0.115361; batch adversarial loss: 0.497907\n",
      "epoch 71; iter: 0; batch classifier loss: 0.107375; batch adversarial loss: 0.411787\n",
      "epoch 72; iter: 0; batch classifier loss: 0.111790; batch adversarial loss: 0.373655\n",
      "epoch 73; iter: 0; batch classifier loss: 0.136405; batch adversarial loss: 0.409794\n",
      "epoch 74; iter: 0; batch classifier loss: 0.114429; batch adversarial loss: 0.480444\n",
      "epoch 75; iter: 0; batch classifier loss: 0.132300; batch adversarial loss: 0.423943\n",
      "epoch 76; iter: 0; batch classifier loss: 0.100654; batch adversarial loss: 0.384884\n",
      "epoch 77; iter: 0; batch classifier loss: 0.162223; batch adversarial loss: 0.412734\n",
      "epoch 78; iter: 0; batch classifier loss: 0.092982; batch adversarial loss: 0.421223\n",
      "epoch 79; iter: 0; batch classifier loss: 0.150114; batch adversarial loss: 0.340240\n",
      "epoch 80; iter: 0; batch classifier loss: 0.079025; batch adversarial loss: 0.323033\n",
      "epoch 81; iter: 0; batch classifier loss: 0.177474; batch adversarial loss: 0.447348\n",
      "epoch 82; iter: 0; batch classifier loss: 0.156086; batch adversarial loss: 0.507807\n",
      "epoch 83; iter: 0; batch classifier loss: 0.142592; batch adversarial loss: 0.431377\n",
      "epoch 84; iter: 0; batch classifier loss: 0.194442; batch adversarial loss: 0.446027\n",
      "epoch 85; iter: 0; batch classifier loss: 0.195522; batch adversarial loss: 0.356152\n",
      "epoch 86; iter: 0; batch classifier loss: 0.122495; batch adversarial loss: 0.469534\n",
      "epoch 87; iter: 0; batch classifier loss: 0.177729; batch adversarial loss: 0.338358\n",
      "epoch 88; iter: 0; batch classifier loss: 0.139138; batch adversarial loss: 0.449681\n",
      "epoch 89; iter: 0; batch classifier loss: 0.139617; batch adversarial loss: 0.448250\n",
      "epoch 90; iter: 0; batch classifier loss: 0.108043; batch adversarial loss: 0.387356\n",
      "epoch 91; iter: 0; batch classifier loss: 0.094552; batch adversarial loss: 0.528773\n",
      "epoch 92; iter: 0; batch classifier loss: 0.094653; batch adversarial loss: 0.488769\n",
      "epoch 93; iter: 0; batch classifier loss: 0.083010; batch adversarial loss: 0.458817\n",
      "epoch 94; iter: 0; batch classifier loss: 0.099374; batch adversarial loss: 0.467253\n",
      "epoch 95; iter: 0; batch classifier loss: 0.111948; batch adversarial loss: 0.360016\n",
      "epoch 96; iter: 0; batch classifier loss: 0.122632; batch adversarial loss: 0.446410\n",
      "epoch 97; iter: 0; batch classifier loss: 0.102377; batch adversarial loss: 0.445045\n",
      "epoch 98; iter: 0; batch classifier loss: 0.094528; batch adversarial loss: 0.369588\n",
      "epoch 99; iter: 0; batch classifier loss: 0.110429; batch adversarial loss: 0.448836\n",
      "epoch 100; iter: 0; batch classifier loss: 0.076276; batch adversarial loss: 0.528948\n",
      "epoch 101; iter: 0; batch classifier loss: 0.130915; batch adversarial loss: 0.438437\n",
      "epoch 102; iter: 0; batch classifier loss: 0.129134; batch adversarial loss: 0.490309\n",
      "epoch 103; iter: 0; batch classifier loss: 0.092132; batch adversarial loss: 0.496716\n",
      "epoch 104; iter: 0; batch classifier loss: 0.137835; batch adversarial loss: 0.360360\n",
      "epoch 105; iter: 0; batch classifier loss: 0.096518; batch adversarial loss: 0.518614\n",
      "epoch 106; iter: 0; batch classifier loss: 0.114276; batch adversarial loss: 0.562471\n",
      "epoch 107; iter: 0; batch classifier loss: 0.075250; batch adversarial loss: 0.467515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.106478; batch adversarial loss: 0.460873\n",
      "epoch 109; iter: 0; batch classifier loss: 0.098745; batch adversarial loss: 0.431700\n",
      "epoch 110; iter: 0; batch classifier loss: 0.094634; batch adversarial loss: 0.408426\n",
      "epoch 111; iter: 0; batch classifier loss: 0.083575; batch adversarial loss: 0.456736\n",
      "epoch 112; iter: 0; batch classifier loss: 0.116723; batch adversarial loss: 0.409218\n",
      "epoch 113; iter: 0; batch classifier loss: 0.083786; batch adversarial loss: 0.405300\n",
      "epoch 114; iter: 0; batch classifier loss: 0.121682; batch adversarial loss: 0.364158\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053943; batch adversarial loss: 0.451471\n",
      "epoch 116; iter: 0; batch classifier loss: 0.098775; batch adversarial loss: 0.463020\n",
      "epoch 117; iter: 0; batch classifier loss: 0.118662; batch adversarial loss: 0.395252\n",
      "epoch 118; iter: 0; batch classifier loss: 0.074497; batch adversarial loss: 0.430044\n",
      "epoch 119; iter: 0; batch classifier loss: 0.093690; batch adversarial loss: 0.426671\n",
      "epoch 120; iter: 0; batch classifier loss: 0.073561; batch adversarial loss: 0.441161\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044156; batch adversarial loss: 0.336887\n",
      "epoch 122; iter: 0; batch classifier loss: 0.081893; batch adversarial loss: 0.480102\n",
      "epoch 123; iter: 0; batch classifier loss: 0.103850; batch adversarial loss: 0.463290\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046137; batch adversarial loss: 0.481759\n",
      "epoch 125; iter: 0; batch classifier loss: 0.063402; batch adversarial loss: 0.405533\n",
      "epoch 126; iter: 0; batch classifier loss: 0.053884; batch adversarial loss: 0.515862\n",
      "epoch 127; iter: 0; batch classifier loss: 0.084110; batch adversarial loss: 0.491919\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045089; batch adversarial loss: 0.304450\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027747; batch adversarial loss: 0.350012\n",
      "epoch 130; iter: 0; batch classifier loss: 0.060708; batch adversarial loss: 0.368827\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039554; batch adversarial loss: 0.524087\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051197; batch adversarial loss: 0.451429\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030308; batch adversarial loss: 0.492060\n",
      "epoch 134; iter: 0; batch classifier loss: 0.060066; batch adversarial loss: 0.396471\n",
      "epoch 135; iter: 0; batch classifier loss: 0.089781; batch adversarial loss: 0.511652\n",
      "epoch 136; iter: 0; batch classifier loss: 0.084116; batch adversarial loss: 0.381135\n",
      "epoch 137; iter: 0; batch classifier loss: 0.067763; batch adversarial loss: 0.340392\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022350; batch adversarial loss: 0.434421\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024537; batch adversarial loss: 0.354500\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027194; batch adversarial loss: 0.473202\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023860; batch adversarial loss: 0.435089\n",
      "epoch 142; iter: 0; batch classifier loss: 0.053075; batch adversarial loss: 0.459411\n",
      "epoch 143; iter: 0; batch classifier loss: 0.048331; batch adversarial loss: 0.410819\n",
      "epoch 144; iter: 0; batch classifier loss: 0.023776; batch adversarial loss: 0.386870\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044725; batch adversarial loss: 0.412754\n",
      "epoch 146; iter: 0; batch classifier loss: 0.055857; batch adversarial loss: 0.486192\n",
      "epoch 147; iter: 0; batch classifier loss: 0.071382; batch adversarial loss: 0.319018\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045235; batch adversarial loss: 0.462659\n",
      "epoch 149; iter: 0; batch classifier loss: 0.055374; batch adversarial loss: 0.419517\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023761; batch adversarial loss: 0.311155\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017480; batch adversarial loss: 0.367694\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018016; batch adversarial loss: 0.484701\n",
      "epoch 153; iter: 0; batch classifier loss: 0.056730; batch adversarial loss: 0.497664\n",
      "epoch 154; iter: 0; batch classifier loss: 0.070582; batch adversarial loss: 0.436883\n",
      "epoch 155; iter: 0; batch classifier loss: 0.045912; batch adversarial loss: 0.455786\n",
      "epoch 156; iter: 0; batch classifier loss: 0.063827; batch adversarial loss: 0.467892\n",
      "epoch 157; iter: 0; batch classifier loss: 0.044482; batch adversarial loss: 0.501866\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018825; batch adversarial loss: 0.392971\n",
      "epoch 159; iter: 0; batch classifier loss: 0.059579; batch adversarial loss: 0.431199\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027728; batch adversarial loss: 0.467700\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014479; batch adversarial loss: 0.383834\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017269; batch adversarial loss: 0.452708\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026328; batch adversarial loss: 0.449932\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036277; batch adversarial loss: 0.452269\n",
      "epoch 165; iter: 0; batch classifier loss: 0.089757; batch adversarial loss: 0.428393\n",
      "epoch 166; iter: 0; batch classifier loss: 0.043726; batch adversarial loss: 0.404849\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019854; batch adversarial loss: 0.489256\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029209; batch adversarial loss: 0.470240\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008964; batch adversarial loss: 0.435737\n",
      "epoch 170; iter: 0; batch classifier loss: 0.050086; batch adversarial loss: 0.370126\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010788; batch adversarial loss: 0.494120\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024109; batch adversarial loss: 0.430507\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029196; batch adversarial loss: 0.477111\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025084; batch adversarial loss: 0.532180\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026814; batch adversarial loss: 0.480792\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020390; batch adversarial loss: 0.491341\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020944; batch adversarial loss: 0.345902\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009900; batch adversarial loss: 0.431219\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022059; batch adversarial loss: 0.423724\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027503; batch adversarial loss: 0.500525\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017507; batch adversarial loss: 0.412677\n",
      "epoch 182; iter: 0; batch classifier loss: 0.041818; batch adversarial loss: 0.424307\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010077; batch adversarial loss: 0.480666\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031266; batch adversarial loss: 0.440662\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013428; batch adversarial loss: 0.490206\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031486; batch adversarial loss: 0.447496\n",
      "epoch 187; iter: 0; batch classifier loss: 0.046985; batch adversarial loss: 0.342737\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023401; batch adversarial loss: 0.405100\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027495; batch adversarial loss: 0.534129\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036535; batch adversarial loss: 0.454109\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016541; batch adversarial loss: 0.433802\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035720; batch adversarial loss: 0.447852\n",
      "epoch 193; iter: 0; batch classifier loss: 0.047110; batch adversarial loss: 0.522374\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021212; batch adversarial loss: 0.469174\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006553; batch adversarial loss: 0.412345\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009481; batch adversarial loss: 0.420066\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013585; batch adversarial loss: 0.421357\n",
      "epoch 198; iter: 0; batch classifier loss: 0.060731; batch adversarial loss: 0.386280\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016751; batch adversarial loss: 0.445138\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697708; batch adversarial loss: 0.898000\n",
      "epoch 1; iter: 0; batch classifier loss: 0.478518; batch adversarial loss: 0.854943\n",
      "epoch 2; iter: 0; batch classifier loss: 0.770724; batch adversarial loss: 0.908813\n",
      "epoch 3; iter: 0; batch classifier loss: 0.939951; batch adversarial loss: 0.854628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 1.027881; batch adversarial loss: 0.784252\n",
      "epoch 5; iter: 0; batch classifier loss: 0.924587; batch adversarial loss: 0.710044\n",
      "epoch 6; iter: 0; batch classifier loss: 0.661039; batch adversarial loss: 0.617231\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517635; batch adversarial loss: 0.585613\n",
      "epoch 8; iter: 0; batch classifier loss: 0.355829; batch adversarial loss: 0.544119\n",
      "epoch 9; iter: 0; batch classifier loss: 0.312834; batch adversarial loss: 0.555788\n",
      "epoch 10; iter: 0; batch classifier loss: 0.309043; batch adversarial loss: 0.495703\n",
      "epoch 11; iter: 0; batch classifier loss: 0.276718; batch adversarial loss: 0.579527\n",
      "epoch 12; iter: 0; batch classifier loss: 0.346966; batch adversarial loss: 0.528654\n",
      "epoch 13; iter: 0; batch classifier loss: 0.279023; batch adversarial loss: 0.541757\n",
      "epoch 14; iter: 0; batch classifier loss: 0.281604; batch adversarial loss: 0.498060\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307103; batch adversarial loss: 0.503902\n",
      "epoch 16; iter: 0; batch classifier loss: 0.332923; batch adversarial loss: 0.474224\n",
      "epoch 17; iter: 0; batch classifier loss: 0.300163; batch adversarial loss: 0.523565\n",
      "epoch 18; iter: 0; batch classifier loss: 0.270186; batch adversarial loss: 0.454145\n",
      "epoch 19; iter: 0; batch classifier loss: 0.216585; batch adversarial loss: 0.455816\n",
      "epoch 20; iter: 0; batch classifier loss: 0.328141; batch adversarial loss: 0.546878\n",
      "epoch 21; iter: 0; batch classifier loss: 0.264970; batch adversarial loss: 0.538094\n",
      "epoch 22; iter: 0; batch classifier loss: 0.273863; batch adversarial loss: 0.572143\n",
      "epoch 23; iter: 0; batch classifier loss: 0.314413; batch adversarial loss: 0.479258\n",
      "epoch 24; iter: 0; batch classifier loss: 0.301868; batch adversarial loss: 0.450531\n",
      "epoch 25; iter: 0; batch classifier loss: 0.252289; batch adversarial loss: 0.487851\n",
      "epoch 26; iter: 0; batch classifier loss: 0.221922; batch adversarial loss: 0.495729\n",
      "epoch 27; iter: 0; batch classifier loss: 0.268591; batch adversarial loss: 0.469819\n",
      "epoch 28; iter: 0; batch classifier loss: 0.294145; batch adversarial loss: 0.470403\n",
      "epoch 29; iter: 0; batch classifier loss: 0.353036; batch adversarial loss: 0.462191\n",
      "epoch 30; iter: 0; batch classifier loss: 0.166137; batch adversarial loss: 0.429943\n",
      "epoch 31; iter: 0; batch classifier loss: 0.233814; batch adversarial loss: 0.447975\n",
      "epoch 32; iter: 0; batch classifier loss: 0.266727; batch adversarial loss: 0.516570\n",
      "epoch 33; iter: 0; batch classifier loss: 0.247975; batch adversarial loss: 0.457766\n",
      "epoch 34; iter: 0; batch classifier loss: 0.247266; batch adversarial loss: 0.344552\n",
      "epoch 35; iter: 0; batch classifier loss: 0.211965; batch adversarial loss: 0.441936\n",
      "epoch 36; iter: 0; batch classifier loss: 0.204673; batch adversarial loss: 0.498436\n",
      "epoch 37; iter: 0; batch classifier loss: 0.191511; batch adversarial loss: 0.470512\n",
      "epoch 38; iter: 0; batch classifier loss: 0.179260; batch adversarial loss: 0.428455\n",
      "epoch 39; iter: 0; batch classifier loss: 0.207144; batch adversarial loss: 0.395220\n",
      "epoch 40; iter: 0; batch classifier loss: 0.230608; batch adversarial loss: 0.419001\n",
      "epoch 41; iter: 0; batch classifier loss: 0.235870; batch adversarial loss: 0.477394\n",
      "epoch 42; iter: 0; batch classifier loss: 0.192773; batch adversarial loss: 0.536235\n",
      "epoch 43; iter: 0; batch classifier loss: 0.299386; batch adversarial loss: 0.384533\n",
      "epoch 44; iter: 0; batch classifier loss: 0.285883; batch adversarial loss: 0.514625\n",
      "epoch 45; iter: 0; batch classifier loss: 0.190794; batch adversarial loss: 0.531360\n",
      "epoch 46; iter: 0; batch classifier loss: 0.216577; batch adversarial loss: 0.408471\n",
      "epoch 47; iter: 0; batch classifier loss: 0.201104; batch adversarial loss: 0.503295\n",
      "epoch 48; iter: 0; batch classifier loss: 0.184005; batch adversarial loss: 0.433371\n",
      "epoch 49; iter: 0; batch classifier loss: 0.236153; batch adversarial loss: 0.382639\n",
      "epoch 50; iter: 0; batch classifier loss: 0.182200; batch adversarial loss: 0.475698\n",
      "epoch 51; iter: 0; batch classifier loss: 0.280725; batch adversarial loss: 0.529847\n",
      "epoch 52; iter: 0; batch classifier loss: 0.232422; batch adversarial loss: 0.322486\n",
      "epoch 53; iter: 0; batch classifier loss: 0.144158; batch adversarial loss: 0.504103\n",
      "epoch 54; iter: 0; batch classifier loss: 0.274790; batch adversarial loss: 0.463089\n",
      "epoch 55; iter: 0; batch classifier loss: 0.242662; batch adversarial loss: 0.454367\n",
      "epoch 56; iter: 0; batch classifier loss: 0.221377; batch adversarial loss: 0.551160\n",
      "epoch 57; iter: 0; batch classifier loss: 0.212362; batch adversarial loss: 0.345140\n",
      "epoch 58; iter: 0; batch classifier loss: 0.160984; batch adversarial loss: 0.440253\n",
      "epoch 59; iter: 0; batch classifier loss: 0.229630; batch adversarial loss: 0.481979\n",
      "epoch 60; iter: 0; batch classifier loss: 0.211545; batch adversarial loss: 0.392383\n",
      "epoch 61; iter: 0; batch classifier loss: 0.158703; batch adversarial loss: 0.497911\n",
      "epoch 62; iter: 0; batch classifier loss: 0.150320; batch adversarial loss: 0.413688\n",
      "epoch 63; iter: 0; batch classifier loss: 0.183359; batch adversarial loss: 0.488367\n",
      "epoch 64; iter: 0; batch classifier loss: 0.179967; batch adversarial loss: 0.480577\n",
      "epoch 65; iter: 0; batch classifier loss: 0.169574; batch adversarial loss: 0.441417\n",
      "epoch 66; iter: 0; batch classifier loss: 0.151934; batch adversarial loss: 0.508767\n",
      "epoch 67; iter: 0; batch classifier loss: 0.150621; batch adversarial loss: 0.438282\n",
      "epoch 68; iter: 0; batch classifier loss: 0.191222; batch adversarial loss: 0.537962\n",
      "epoch 69; iter: 0; batch classifier loss: 0.185089; batch adversarial loss: 0.420945\n",
      "epoch 70; iter: 0; batch classifier loss: 0.215384; batch adversarial loss: 0.461474\n",
      "epoch 71; iter: 0; batch classifier loss: 0.240854; batch adversarial loss: 0.430833\n",
      "epoch 72; iter: 0; batch classifier loss: 0.185905; batch adversarial loss: 0.453762\n",
      "epoch 73; iter: 0; batch classifier loss: 0.164289; batch adversarial loss: 0.513719\n",
      "epoch 74; iter: 0; batch classifier loss: 0.194926; batch adversarial loss: 0.538985\n",
      "epoch 75; iter: 0; batch classifier loss: 0.179050; batch adversarial loss: 0.422227\n",
      "epoch 76; iter: 0; batch classifier loss: 0.125127; batch adversarial loss: 0.485671\n",
      "epoch 77; iter: 0; batch classifier loss: 0.184879; batch adversarial loss: 0.470459\n",
      "epoch 78; iter: 0; batch classifier loss: 0.212370; batch adversarial loss: 0.471103\n",
      "epoch 79; iter: 0; batch classifier loss: 0.217108; batch adversarial loss: 0.398824\n",
      "epoch 80; iter: 0; batch classifier loss: 0.161989; batch adversarial loss: 0.538557\n",
      "epoch 81; iter: 0; batch classifier loss: 0.172401; batch adversarial loss: 0.394628\n",
      "epoch 82; iter: 0; batch classifier loss: 0.177345; batch adversarial loss: 0.478744\n",
      "epoch 83; iter: 0; batch classifier loss: 0.144520; batch adversarial loss: 0.373343\n",
      "epoch 84; iter: 0; batch classifier loss: 0.217146; batch adversarial loss: 0.460953\n",
      "epoch 85; iter: 0; batch classifier loss: 0.139956; batch adversarial loss: 0.476765\n",
      "epoch 86; iter: 0; batch classifier loss: 0.192880; batch adversarial loss: 0.410464\n",
      "epoch 87; iter: 0; batch classifier loss: 0.200789; batch adversarial loss: 0.454518\n",
      "epoch 88; iter: 0; batch classifier loss: 0.235749; batch adversarial loss: 0.405950\n",
      "epoch 89; iter: 0; batch classifier loss: 0.187326; batch adversarial loss: 0.485561\n",
      "epoch 90; iter: 0; batch classifier loss: 0.179604; batch adversarial loss: 0.519507\n",
      "epoch 91; iter: 0; batch classifier loss: 0.206821; batch adversarial loss: 0.416780\n",
      "epoch 92; iter: 0; batch classifier loss: 0.209654; batch adversarial loss: 0.517389\n",
      "epoch 93; iter: 0; batch classifier loss: 0.189492; batch adversarial loss: 0.503710\n",
      "epoch 94; iter: 0; batch classifier loss: 0.136913; batch adversarial loss: 0.430945\n",
      "epoch 95; iter: 0; batch classifier loss: 0.135211; batch adversarial loss: 0.506672\n",
      "epoch 96; iter: 0; batch classifier loss: 0.127777; batch adversarial loss: 0.454047\n",
      "epoch 97; iter: 0; batch classifier loss: 0.132773; batch adversarial loss: 0.531338\n",
      "epoch 98; iter: 0; batch classifier loss: 0.131643; batch adversarial loss: 0.546920\n",
      "epoch 99; iter: 0; batch classifier loss: 0.120443; batch adversarial loss: 0.604863\n",
      "epoch 100; iter: 0; batch classifier loss: 0.144436; batch adversarial loss: 0.493737\n",
      "epoch 101; iter: 0; batch classifier loss: 0.082872; batch adversarial loss: 0.460032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.090506; batch adversarial loss: 0.552169\n",
      "epoch 103; iter: 0; batch classifier loss: 0.070819; batch adversarial loss: 0.426247\n",
      "epoch 104; iter: 0; batch classifier loss: 0.103458; batch adversarial loss: 0.447944\n",
      "epoch 105; iter: 0; batch classifier loss: 0.169345; batch adversarial loss: 0.412598\n",
      "epoch 106; iter: 0; batch classifier loss: 0.077431; batch adversarial loss: 0.407783\n",
      "epoch 107; iter: 0; batch classifier loss: 0.090728; batch adversarial loss: 0.420696\n",
      "epoch 108; iter: 0; batch classifier loss: 0.089477; batch adversarial loss: 0.498871\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059214; batch adversarial loss: 0.425229\n",
      "epoch 110; iter: 0; batch classifier loss: 0.066599; batch adversarial loss: 0.360186\n",
      "epoch 111; iter: 0; batch classifier loss: 0.092753; batch adversarial loss: 0.406608\n",
      "epoch 112; iter: 0; batch classifier loss: 0.028401; batch adversarial loss: 0.458371\n",
      "epoch 113; iter: 0; batch classifier loss: 0.088373; batch adversarial loss: 0.425320\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062052; batch adversarial loss: 0.354642\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050661; batch adversarial loss: 0.434938\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060727; batch adversarial loss: 0.450893\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047961; batch adversarial loss: 0.333301\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041677; batch adversarial loss: 0.503078\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039353; batch adversarial loss: 0.423147\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034224; batch adversarial loss: 0.508838\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058952; batch adversarial loss: 0.383200\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038590; batch adversarial loss: 0.351284\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040305; batch adversarial loss: 0.470265\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051615; batch adversarial loss: 0.471195\n",
      "epoch 125; iter: 0; batch classifier loss: 0.024630; batch adversarial loss: 0.390379\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031725; batch adversarial loss: 0.390550\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028409; batch adversarial loss: 0.544241\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028029; batch adversarial loss: 0.447651\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028628; batch adversarial loss: 0.497695\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019409; batch adversarial loss: 0.497147\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028173; batch adversarial loss: 0.509855\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023172; batch adversarial loss: 0.422546\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032864; batch adversarial loss: 0.463353\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036466; batch adversarial loss: 0.483142\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018737; batch adversarial loss: 0.437462\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032466; batch adversarial loss: 0.466683\n",
      "epoch 137; iter: 0; batch classifier loss: 0.050266; batch adversarial loss: 0.442694\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030233; batch adversarial loss: 0.414812\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010004; batch adversarial loss: 0.528530\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017370; batch adversarial loss: 0.415887\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019144; batch adversarial loss: 0.456586\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024486; batch adversarial loss: 0.533098\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032020; batch adversarial loss: 0.451180\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026301; batch adversarial loss: 0.535520\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033250; batch adversarial loss: 0.401282\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044396; batch adversarial loss: 0.433385\n",
      "epoch 147; iter: 0; batch classifier loss: 0.012990; batch adversarial loss: 0.460751\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015457; batch adversarial loss: 0.364106\n",
      "epoch 149; iter: 0; batch classifier loss: 0.008105; batch adversarial loss: 0.500622\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021423; batch adversarial loss: 0.466694\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021664; batch adversarial loss: 0.433685\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034851; batch adversarial loss: 0.419835\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010500; batch adversarial loss: 0.496151\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033595; batch adversarial loss: 0.396823\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032489; batch adversarial loss: 0.448313\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038030; batch adversarial loss: 0.489394\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023899; batch adversarial loss: 0.458828\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035650; batch adversarial loss: 0.432775\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013924; batch adversarial loss: 0.395637\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014134; batch adversarial loss: 0.435234\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028223; batch adversarial loss: 0.410195\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016548; batch adversarial loss: 0.437097\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011378; batch adversarial loss: 0.444960\n",
      "epoch 164; iter: 0; batch classifier loss: 0.003298; batch adversarial loss: 0.510685\n",
      "epoch 165; iter: 0; batch classifier loss: 0.039396; batch adversarial loss: 0.485633\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016517; batch adversarial loss: 0.462312\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009582; batch adversarial loss: 0.426841\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029090; batch adversarial loss: 0.362508\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006519; batch adversarial loss: 0.463812\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021221; batch adversarial loss: 0.396817\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013939; batch adversarial loss: 0.469232\n",
      "epoch 172; iter: 0; batch classifier loss: 0.039016; batch adversarial loss: 0.375077\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019871; batch adversarial loss: 0.454405\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021241; batch adversarial loss: 0.369693\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015424; batch adversarial loss: 0.396928\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013202; batch adversarial loss: 0.420706\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042997; batch adversarial loss: 0.446540\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009544; batch adversarial loss: 0.467444\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006056; batch adversarial loss: 0.509167\n",
      "epoch 180; iter: 0; batch classifier loss: 0.045745; batch adversarial loss: 0.454324\n",
      "epoch 181; iter: 0; batch classifier loss: 0.046024; batch adversarial loss: 0.456943\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010076; batch adversarial loss: 0.498161\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026797; batch adversarial loss: 0.407999\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008766; batch adversarial loss: 0.482242\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010340; batch adversarial loss: 0.413377\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024580; batch adversarial loss: 0.509599\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033876; batch adversarial loss: 0.503296\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013090; batch adversarial loss: 0.411949\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012687; batch adversarial loss: 0.410555\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004028; batch adversarial loss: 0.473393\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005065; batch adversarial loss: 0.401646\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004988; batch adversarial loss: 0.379960\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032182; batch adversarial loss: 0.513876\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017328; batch adversarial loss: 0.434232\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022100; batch adversarial loss: 0.485598\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018213; batch adversarial loss: 0.444457\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008072; batch adversarial loss: 0.401449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.006333; batch adversarial loss: 0.466998\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015159; batch adversarial loss: 0.440657\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697309; batch adversarial loss: 0.583203\n",
      "epoch 1; iter: 0; batch classifier loss: 0.460219; batch adversarial loss: 0.601017\n",
      "epoch 2; iter: 0; batch classifier loss: 0.490435; batch adversarial loss: 0.575868\n",
      "epoch 3; iter: 0; batch classifier loss: 0.474560; batch adversarial loss: 0.608914\n",
      "epoch 4; iter: 0; batch classifier loss: 0.500345; batch adversarial loss: 0.684158\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541766; batch adversarial loss: 0.592742\n",
      "epoch 6; iter: 0; batch classifier loss: 0.594019; batch adversarial loss: 0.591066\n",
      "epoch 7; iter: 0; batch classifier loss: 0.620169; batch adversarial loss: 0.523306\n",
      "epoch 8; iter: 0; batch classifier loss: 0.505062; batch adversarial loss: 0.577336\n",
      "epoch 9; iter: 0; batch classifier loss: 0.475770; batch adversarial loss: 0.541817\n",
      "epoch 10; iter: 0; batch classifier loss: 0.434858; batch adversarial loss: 0.576135\n",
      "epoch 11; iter: 0; batch classifier loss: 0.384568; batch adversarial loss: 0.523381\n",
      "epoch 12; iter: 0; batch classifier loss: 0.365264; batch adversarial loss: 0.497919\n",
      "epoch 13; iter: 0; batch classifier loss: 0.269191; batch adversarial loss: 0.521215\n",
      "epoch 14; iter: 0; batch classifier loss: 0.334121; batch adversarial loss: 0.496627\n",
      "epoch 15; iter: 0; batch classifier loss: 0.332563; batch adversarial loss: 0.462740\n",
      "epoch 16; iter: 0; batch classifier loss: 0.334318; batch adversarial loss: 0.498474\n",
      "epoch 17; iter: 0; batch classifier loss: 0.352651; batch adversarial loss: 0.407130\n",
      "epoch 18; iter: 0; batch classifier loss: 0.292617; batch adversarial loss: 0.462664\n",
      "epoch 19; iter: 0; batch classifier loss: 0.272233; batch adversarial loss: 0.542512\n",
      "epoch 20; iter: 0; batch classifier loss: 0.241339; batch adversarial loss: 0.554726\n",
      "epoch 21; iter: 0; batch classifier loss: 0.215511; batch adversarial loss: 0.431045\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224900; batch adversarial loss: 0.440720\n",
      "epoch 23; iter: 0; batch classifier loss: 0.219864; batch adversarial loss: 0.546331\n",
      "epoch 24; iter: 0; batch classifier loss: 0.315202; batch adversarial loss: 0.552145\n",
      "epoch 25; iter: 0; batch classifier loss: 0.272770; batch adversarial loss: 0.472031\n",
      "epoch 26; iter: 0; batch classifier loss: 0.256938; batch adversarial loss: 0.426276\n",
      "epoch 27; iter: 0; batch classifier loss: 0.169666; batch adversarial loss: 0.572839\n",
      "epoch 28; iter: 0; batch classifier loss: 0.179919; batch adversarial loss: 0.447118\n",
      "epoch 29; iter: 0; batch classifier loss: 0.228014; batch adversarial loss: 0.486251\n",
      "epoch 30; iter: 0; batch classifier loss: 0.214890; batch adversarial loss: 0.492237\n",
      "epoch 31; iter: 0; batch classifier loss: 0.197212; batch adversarial loss: 0.427156\n",
      "epoch 32; iter: 0; batch classifier loss: 0.200091; batch adversarial loss: 0.458229\n",
      "epoch 33; iter: 0; batch classifier loss: 0.232025; batch adversarial loss: 0.434284\n",
      "epoch 34; iter: 0; batch classifier loss: 0.232641; batch adversarial loss: 0.447118\n",
      "epoch 35; iter: 0; batch classifier loss: 0.282527; batch adversarial loss: 0.475452\n",
      "epoch 36; iter: 0; batch classifier loss: 0.254950; batch adversarial loss: 0.384145\n",
      "epoch 37; iter: 0; batch classifier loss: 0.266529; batch adversarial loss: 0.470732\n",
      "epoch 38; iter: 0; batch classifier loss: 0.247395; batch adversarial loss: 0.482920\n",
      "epoch 39; iter: 0; batch classifier loss: 0.224311; batch adversarial loss: 0.447636\n",
      "epoch 40; iter: 0; batch classifier loss: 0.220415; batch adversarial loss: 0.526782\n",
      "epoch 41; iter: 0; batch classifier loss: 0.195480; batch adversarial loss: 0.469285\n",
      "epoch 42; iter: 0; batch classifier loss: 0.235069; batch adversarial loss: 0.504461\n",
      "epoch 43; iter: 0; batch classifier loss: 0.222388; batch adversarial loss: 0.367041\n",
      "epoch 44; iter: 0; batch classifier loss: 0.192564; batch adversarial loss: 0.430203\n",
      "epoch 45; iter: 0; batch classifier loss: 0.183214; batch adversarial loss: 0.559925\n",
      "epoch 46; iter: 0; batch classifier loss: 0.228491; batch adversarial loss: 0.442379\n",
      "epoch 47; iter: 0; batch classifier loss: 0.196382; batch adversarial loss: 0.456572\n",
      "epoch 48; iter: 0; batch classifier loss: 0.199960; batch adversarial loss: 0.546527\n",
      "epoch 49; iter: 0; batch classifier loss: 0.218502; batch adversarial loss: 0.398238\n",
      "epoch 50; iter: 0; batch classifier loss: 0.274511; batch adversarial loss: 0.455700\n",
      "epoch 51; iter: 0; batch classifier loss: 0.167813; batch adversarial loss: 0.496733\n",
      "epoch 52; iter: 0; batch classifier loss: 0.234741; batch adversarial loss: 0.434047\n",
      "epoch 53; iter: 0; batch classifier loss: 0.261037; batch adversarial loss: 0.482913\n",
      "epoch 54; iter: 0; batch classifier loss: 0.243096; batch adversarial loss: 0.409915\n",
      "epoch 55; iter: 0; batch classifier loss: 0.250193; batch adversarial loss: 0.360926\n",
      "epoch 56; iter: 0; batch classifier loss: 0.251591; batch adversarial loss: 0.532578\n",
      "epoch 57; iter: 0; batch classifier loss: 0.210048; batch adversarial loss: 0.360133\n",
      "epoch 58; iter: 0; batch classifier loss: 0.197603; batch adversarial loss: 0.397426\n",
      "epoch 59; iter: 0; batch classifier loss: 0.121641; batch adversarial loss: 0.445697\n",
      "epoch 60; iter: 0; batch classifier loss: 0.230518; batch adversarial loss: 0.421164\n",
      "epoch 61; iter: 0; batch classifier loss: 0.157741; batch adversarial loss: 0.446655\n",
      "epoch 62; iter: 0; batch classifier loss: 0.138629; batch adversarial loss: 0.509248\n",
      "epoch 63; iter: 0; batch classifier loss: 0.142487; batch adversarial loss: 0.370673\n",
      "epoch 64; iter: 0; batch classifier loss: 0.239690; batch adversarial loss: 0.483966\n",
      "epoch 65; iter: 0; batch classifier loss: 0.175863; batch adversarial loss: 0.446740\n",
      "epoch 66; iter: 0; batch classifier loss: 0.138643; batch adversarial loss: 0.543727\n",
      "epoch 67; iter: 0; batch classifier loss: 0.184414; batch adversarial loss: 0.432772\n",
      "epoch 68; iter: 0; batch classifier loss: 0.249128; batch adversarial loss: 0.386083\n",
      "epoch 69; iter: 0; batch classifier loss: 0.194858; batch adversarial loss: 0.457121\n",
      "epoch 70; iter: 0; batch classifier loss: 0.157091; batch adversarial loss: 0.484049\n",
      "epoch 71; iter: 0; batch classifier loss: 0.159922; batch adversarial loss: 0.521752\n",
      "epoch 72; iter: 0; batch classifier loss: 0.211644; batch adversarial loss: 0.396452\n",
      "epoch 73; iter: 0; batch classifier loss: 0.225723; batch adversarial loss: 0.371887\n",
      "epoch 74; iter: 0; batch classifier loss: 0.287916; batch adversarial loss: 0.434135\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076424; batch adversarial loss: 0.419565\n",
      "epoch 76; iter: 0; batch classifier loss: 0.056718; batch adversarial loss: 0.417516\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069404; batch adversarial loss: 0.400108\n",
      "epoch 78; iter: 0; batch classifier loss: 0.086398; batch adversarial loss: 0.333844\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044964; batch adversarial loss: 0.380932\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060356; batch adversarial loss: 0.423936\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057172; batch adversarial loss: 0.509825\n",
      "epoch 82; iter: 0; batch classifier loss: 0.058319; batch adversarial loss: 0.420838\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063433; batch adversarial loss: 0.448728\n",
      "epoch 84; iter: 0; batch classifier loss: 0.033143; batch adversarial loss: 0.427259\n",
      "epoch 85; iter: 0; batch classifier loss: 0.040962; batch adversarial loss: 0.506824\n",
      "epoch 86; iter: 0; batch classifier loss: 0.032860; batch adversarial loss: 0.386549\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042735; batch adversarial loss: 0.465546\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058230; batch adversarial loss: 0.434099\n",
      "epoch 89; iter: 0; batch classifier loss: 0.023961; batch adversarial loss: 0.333551\n",
      "epoch 90; iter: 0; batch classifier loss: 0.043294; batch adversarial loss: 0.405377\n",
      "epoch 91; iter: 0; batch classifier loss: 0.033267; batch adversarial loss: 0.375288\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062986; batch adversarial loss: 0.438203\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063129; batch adversarial loss: 0.386354\n",
      "epoch 94; iter: 0; batch classifier loss: 0.081293; batch adversarial loss: 0.485265\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058202; batch adversarial loss: 0.432974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.037538; batch adversarial loss: 0.528029\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046453; batch adversarial loss: 0.421073\n",
      "epoch 98; iter: 0; batch classifier loss: 0.081289; batch adversarial loss: 0.427776\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062696; batch adversarial loss: 0.494109\n",
      "epoch 100; iter: 0; batch classifier loss: 0.058637; batch adversarial loss: 0.377140\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043829; batch adversarial loss: 0.388543\n",
      "epoch 102; iter: 0; batch classifier loss: 0.090679; batch adversarial loss: 0.461609\n",
      "epoch 103; iter: 0; batch classifier loss: 0.068550; batch adversarial loss: 0.496369\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053150; batch adversarial loss: 0.379323\n",
      "epoch 105; iter: 0; batch classifier loss: 0.027795; batch adversarial loss: 0.365249\n",
      "epoch 106; iter: 0; batch classifier loss: 0.120660; batch adversarial loss: 0.390218\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055011; batch adversarial loss: 0.387627\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048976; batch adversarial loss: 0.336599\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048670; batch adversarial loss: 0.498043\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033504; batch adversarial loss: 0.406753\n",
      "epoch 111; iter: 0; batch classifier loss: 0.063110; batch adversarial loss: 0.483565\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057172; batch adversarial loss: 0.374463\n",
      "epoch 113; iter: 0; batch classifier loss: 0.060535; batch adversarial loss: 0.366835\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037777; batch adversarial loss: 0.408953\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060164; batch adversarial loss: 0.460820\n",
      "epoch 116; iter: 0; batch classifier loss: 0.047568; batch adversarial loss: 0.415908\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041807; batch adversarial loss: 0.483099\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033219; batch adversarial loss: 0.363716\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047027; batch adversarial loss: 0.419513\n",
      "epoch 120; iter: 0; batch classifier loss: 0.091156; batch adversarial loss: 0.529708\n",
      "epoch 121; iter: 0; batch classifier loss: 0.073203; batch adversarial loss: 0.412676\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031897; batch adversarial loss: 0.450301\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042337; batch adversarial loss: 0.476344\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044268; batch adversarial loss: 0.317383\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026658; batch adversarial loss: 0.340082\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038085; batch adversarial loss: 0.409357\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039417; batch adversarial loss: 0.437936\n",
      "epoch 128; iter: 0; batch classifier loss: 0.084880; batch adversarial loss: 0.410134\n",
      "epoch 129; iter: 0; batch classifier loss: 0.060241; batch adversarial loss: 0.469818\n",
      "epoch 130; iter: 0; batch classifier loss: 0.082412; batch adversarial loss: 0.577358\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039138; batch adversarial loss: 0.541572\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047951; batch adversarial loss: 0.362026\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052978; batch adversarial loss: 0.479924\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049598; batch adversarial loss: 0.438802\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046251; batch adversarial loss: 0.393856\n",
      "epoch 136; iter: 0; batch classifier loss: 0.075320; batch adversarial loss: 0.459431\n",
      "epoch 137; iter: 0; batch classifier loss: 0.066225; batch adversarial loss: 0.456792\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026175; batch adversarial loss: 0.397622\n",
      "epoch 139; iter: 0; batch classifier loss: 0.059949; batch adversarial loss: 0.397825\n",
      "epoch 140; iter: 0; batch classifier loss: 0.092494; batch adversarial loss: 0.404971\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046823; batch adversarial loss: 0.470746\n",
      "epoch 142; iter: 0; batch classifier loss: 0.093011; batch adversarial loss: 0.407320\n",
      "epoch 143; iter: 0; batch classifier loss: 0.066948; batch adversarial loss: 0.445029\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032092; batch adversarial loss: 0.418719\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044550; batch adversarial loss: 0.428543\n",
      "epoch 146; iter: 0; batch classifier loss: 0.094926; batch adversarial loss: 0.455157\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041660; batch adversarial loss: 0.331451\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054804; batch adversarial loss: 0.467035\n",
      "epoch 149; iter: 0; batch classifier loss: 0.048780; batch adversarial loss: 0.511592\n",
      "epoch 150; iter: 0; batch classifier loss: 0.045527; batch adversarial loss: 0.501088\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042336; batch adversarial loss: 0.395269\n",
      "epoch 152; iter: 0; batch classifier loss: 0.067676; batch adversarial loss: 0.462208\n",
      "epoch 153; iter: 0; batch classifier loss: 0.044426; batch adversarial loss: 0.401980\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041140; batch adversarial loss: 0.370543\n",
      "epoch 155; iter: 0; batch classifier loss: 0.039510; batch adversarial loss: 0.422910\n",
      "epoch 156; iter: 0; batch classifier loss: 0.057110; batch adversarial loss: 0.422059\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034096; batch adversarial loss: 0.462733\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034759; batch adversarial loss: 0.417713\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038424; batch adversarial loss: 0.373318\n",
      "epoch 160; iter: 0; batch classifier loss: 0.053786; batch adversarial loss: 0.490501\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033616; batch adversarial loss: 0.460160\n",
      "epoch 162; iter: 0; batch classifier loss: 0.061644; batch adversarial loss: 0.450669\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039688; batch adversarial loss: 0.369558\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035195; batch adversarial loss: 0.373204\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036913; batch adversarial loss: 0.425335\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029862; batch adversarial loss: 0.405858\n",
      "epoch 167; iter: 0; batch classifier loss: 0.059222; batch adversarial loss: 0.330189\n",
      "epoch 168; iter: 0; batch classifier loss: 0.047415; batch adversarial loss: 0.478882\n",
      "epoch 169; iter: 0; batch classifier loss: 0.048067; batch adversarial loss: 0.503225\n",
      "epoch 170; iter: 0; batch classifier loss: 0.045426; batch adversarial loss: 0.448685\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022306; batch adversarial loss: 0.361986\n",
      "epoch 172; iter: 0; batch classifier loss: 0.053469; batch adversarial loss: 0.361306\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030007; batch adversarial loss: 0.367908\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014562; batch adversarial loss: 0.463675\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025628; batch adversarial loss: 0.436560\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030787; batch adversarial loss: 0.412351\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028290; batch adversarial loss: 0.432501\n",
      "epoch 178; iter: 0; batch classifier loss: 0.050458; batch adversarial loss: 0.442094\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034260; batch adversarial loss: 0.376492\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028031; batch adversarial loss: 0.373050\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027862; batch adversarial loss: 0.422158\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020479; batch adversarial loss: 0.425833\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026402; batch adversarial loss: 0.412984\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033293; batch adversarial loss: 0.380726\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026633; batch adversarial loss: 0.503859\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017238; batch adversarial loss: 0.443924\n",
      "epoch 187; iter: 0; batch classifier loss: 0.093250; batch adversarial loss: 0.382093\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032656; batch adversarial loss: 0.462948\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024740; batch adversarial loss: 0.522108\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013542; batch adversarial loss: 0.414908\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028225; batch adversarial loss: 0.439074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.030150; batch adversarial loss: 0.393125\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028012; batch adversarial loss: 0.468603\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025263; batch adversarial loss: 0.425284\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023382; batch adversarial loss: 0.349732\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012954; batch adversarial loss: 0.390142\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028960; batch adversarial loss: 0.386892\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023034; batch adversarial loss: 0.506075\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016712; batch adversarial loss: 0.403259\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695846; batch adversarial loss: 0.862340\n",
      "epoch 1; iter: 0; batch classifier loss: 0.480563; batch adversarial loss: 0.809886\n",
      "epoch 2; iter: 0; batch classifier loss: 0.344778; batch adversarial loss: 0.778765\n",
      "epoch 3; iter: 0; batch classifier loss: 0.363703; batch adversarial loss: 0.708962\n",
      "epoch 4; iter: 0; batch classifier loss: 0.400475; batch adversarial loss: 0.718721\n",
      "epoch 5; iter: 0; batch classifier loss: 0.276433; batch adversarial loss: 0.672796\n",
      "epoch 6; iter: 0; batch classifier loss: 0.259287; batch adversarial loss: 0.652913\n",
      "epoch 7; iter: 0; batch classifier loss: 0.344648; batch adversarial loss: 0.623251\n",
      "epoch 8; iter: 0; batch classifier loss: 0.311746; batch adversarial loss: 0.614363\n",
      "epoch 9; iter: 0; batch classifier loss: 0.318129; batch adversarial loss: 0.550498\n",
      "epoch 10; iter: 0; batch classifier loss: 0.221165; batch adversarial loss: 0.566987\n",
      "epoch 11; iter: 0; batch classifier loss: 0.323260; batch adversarial loss: 0.556880\n",
      "epoch 12; iter: 0; batch classifier loss: 0.242480; batch adversarial loss: 0.468374\n",
      "epoch 13; iter: 0; batch classifier loss: 0.242310; batch adversarial loss: 0.457881\n",
      "epoch 14; iter: 0; batch classifier loss: 0.226576; batch adversarial loss: 0.466120\n",
      "epoch 15; iter: 0; batch classifier loss: 0.207654; batch adversarial loss: 0.470710\n",
      "epoch 16; iter: 0; batch classifier loss: 0.256688; batch adversarial loss: 0.402896\n",
      "epoch 17; iter: 0; batch classifier loss: 0.209192; batch adversarial loss: 0.463418\n",
      "epoch 18; iter: 0; batch classifier loss: 0.180712; batch adversarial loss: 0.507224\n",
      "epoch 19; iter: 0; batch classifier loss: 0.179885; batch adversarial loss: 0.405990\n",
      "epoch 20; iter: 0; batch classifier loss: 0.198616; batch adversarial loss: 0.471913\n",
      "epoch 21; iter: 0; batch classifier loss: 0.146276; batch adversarial loss: 0.469659\n",
      "epoch 22; iter: 0; batch classifier loss: 0.183808; batch adversarial loss: 0.403647\n",
      "epoch 23; iter: 0; batch classifier loss: 0.159681; batch adversarial loss: 0.414597\n",
      "epoch 24; iter: 0; batch classifier loss: 0.160224; batch adversarial loss: 0.435757\n",
      "epoch 25; iter: 0; batch classifier loss: 0.163580; batch adversarial loss: 0.356337\n",
      "epoch 26; iter: 0; batch classifier loss: 0.152488; batch adversarial loss: 0.381372\n",
      "epoch 27; iter: 0; batch classifier loss: 0.083060; batch adversarial loss: 0.439449\n",
      "epoch 28; iter: 0; batch classifier loss: 0.100667; batch adversarial loss: 0.435096\n",
      "epoch 29; iter: 0; batch classifier loss: 0.091109; batch adversarial loss: 0.555923\n",
      "epoch 30; iter: 0; batch classifier loss: 0.098748; batch adversarial loss: 0.503429\n",
      "epoch 31; iter: 0; batch classifier loss: 0.127100; batch adversarial loss: 0.391971\n",
      "epoch 32; iter: 0; batch classifier loss: 0.135512; batch adversarial loss: 0.367814\n",
      "epoch 33; iter: 0; batch classifier loss: 0.086157; batch adversarial loss: 0.362683\n",
      "epoch 34; iter: 0; batch classifier loss: 0.095383; batch adversarial loss: 0.507657\n",
      "epoch 35; iter: 0; batch classifier loss: 0.127813; batch adversarial loss: 0.426118\n",
      "epoch 36; iter: 0; batch classifier loss: 0.099179; batch adversarial loss: 0.384568\n",
      "epoch 37; iter: 0; batch classifier loss: 0.130485; batch adversarial loss: 0.483391\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127287; batch adversarial loss: 0.376782\n",
      "epoch 39; iter: 0; batch classifier loss: 0.111698; batch adversarial loss: 0.371255\n",
      "epoch 40; iter: 0; batch classifier loss: 0.109843; batch adversarial loss: 0.378375\n",
      "epoch 41; iter: 0; batch classifier loss: 0.130336; batch adversarial loss: 0.425935\n",
      "epoch 42; iter: 0; batch classifier loss: 0.130769; batch adversarial loss: 0.419573\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110846; batch adversarial loss: 0.413737\n",
      "epoch 44; iter: 0; batch classifier loss: 0.102753; batch adversarial loss: 0.453654\n",
      "epoch 45; iter: 0; batch classifier loss: 0.107816; batch adversarial loss: 0.420522\n",
      "epoch 46; iter: 0; batch classifier loss: 0.160694; batch adversarial loss: 0.516944\n",
      "epoch 47; iter: 0; batch classifier loss: 0.109908; batch adversarial loss: 0.457462\n",
      "epoch 48; iter: 0; batch classifier loss: 0.074860; batch adversarial loss: 0.385812\n",
      "epoch 49; iter: 0; batch classifier loss: 0.091502; batch adversarial loss: 0.392458\n",
      "epoch 50; iter: 0; batch classifier loss: 0.095865; batch adversarial loss: 0.373033\n",
      "epoch 51; iter: 0; batch classifier loss: 0.078854; batch adversarial loss: 0.440485\n",
      "epoch 52; iter: 0; batch classifier loss: 0.129554; batch adversarial loss: 0.346370\n",
      "epoch 53; iter: 0; batch classifier loss: 0.079285; batch adversarial loss: 0.319883\n",
      "epoch 54; iter: 0; batch classifier loss: 0.092670; batch adversarial loss: 0.413117\n",
      "epoch 55; iter: 0; batch classifier loss: 0.106009; batch adversarial loss: 0.390000\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084881; batch adversarial loss: 0.392716\n",
      "epoch 57; iter: 0; batch classifier loss: 0.106583; batch adversarial loss: 0.404254\n",
      "epoch 58; iter: 0; batch classifier loss: 0.101809; batch adversarial loss: 0.471721\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105612; batch adversarial loss: 0.482006\n",
      "epoch 60; iter: 0; batch classifier loss: 0.083886; batch adversarial loss: 0.434126\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074359; batch adversarial loss: 0.433314\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090114; batch adversarial loss: 0.407216\n",
      "epoch 63; iter: 0; batch classifier loss: 0.086700; batch adversarial loss: 0.316174\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072351; batch adversarial loss: 0.411649\n",
      "epoch 65; iter: 0; batch classifier loss: 0.072795; batch adversarial loss: 0.314371\n",
      "epoch 66; iter: 0; batch classifier loss: 0.064634; batch adversarial loss: 0.404360\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082837; batch adversarial loss: 0.379806\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071816; batch adversarial loss: 0.471963\n",
      "epoch 69; iter: 0; batch classifier loss: 0.079810; batch adversarial loss: 0.410477\n",
      "epoch 70; iter: 0; batch classifier loss: 0.054540; batch adversarial loss: 0.385806\n",
      "epoch 71; iter: 0; batch classifier loss: 0.057181; batch adversarial loss: 0.473038\n",
      "epoch 72; iter: 0; batch classifier loss: 0.047051; batch adversarial loss: 0.399691\n",
      "epoch 73; iter: 0; batch classifier loss: 0.066068; batch adversarial loss: 0.514158\n",
      "epoch 74; iter: 0; batch classifier loss: 0.051027; batch adversarial loss: 0.441389\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059205; batch adversarial loss: 0.386562\n",
      "epoch 76; iter: 0; batch classifier loss: 0.039066; batch adversarial loss: 0.459051\n",
      "epoch 77; iter: 0; batch classifier loss: 0.046182; batch adversarial loss: 0.404087\n",
      "epoch 78; iter: 0; batch classifier loss: 0.037681; batch adversarial loss: 0.380866\n",
      "epoch 79; iter: 0; batch classifier loss: 0.026073; batch adversarial loss: 0.502995\n",
      "epoch 80; iter: 0; batch classifier loss: 0.045267; batch adversarial loss: 0.416739\n",
      "epoch 81; iter: 0; batch classifier loss: 0.048496; batch adversarial loss: 0.468267\n",
      "epoch 82; iter: 0; batch classifier loss: 0.032667; batch adversarial loss: 0.545735\n",
      "epoch 83; iter: 0; batch classifier loss: 0.040715; batch adversarial loss: 0.482115\n",
      "epoch 84; iter: 0; batch classifier loss: 0.063003; batch adversarial loss: 0.464274\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077661; batch adversarial loss: 0.479087\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083814; batch adversarial loss: 0.503317\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048189; batch adversarial loss: 0.441981\n",
      "epoch 88; iter: 0; batch classifier loss: 0.095078; batch adversarial loss: 0.552553\n",
      "epoch 89; iter: 0; batch classifier loss: 0.094416; batch adversarial loss: 0.494095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.125153; batch adversarial loss: 0.473320\n",
      "epoch 91; iter: 0; batch classifier loss: 0.155745; batch adversarial loss: 0.579384\n",
      "epoch 92; iter: 0; batch classifier loss: 0.121480; batch adversarial loss: 0.608631\n",
      "epoch 93; iter: 0; batch classifier loss: 0.121906; batch adversarial loss: 0.438906\n",
      "epoch 94; iter: 0; batch classifier loss: 0.173235; batch adversarial loss: 0.710586\n",
      "epoch 95; iter: 0; batch classifier loss: 0.144591; batch adversarial loss: 0.591832\n",
      "epoch 96; iter: 0; batch classifier loss: 0.139869; batch adversarial loss: 0.575507\n",
      "epoch 97; iter: 0; batch classifier loss: 0.126454; batch adversarial loss: 0.631794\n",
      "epoch 98; iter: 0; batch classifier loss: 0.138344; batch adversarial loss: 0.549372\n",
      "epoch 99; iter: 0; batch classifier loss: 0.177605; batch adversarial loss: 0.681415\n",
      "epoch 100; iter: 0; batch classifier loss: 0.172928; batch adversarial loss: 0.642162\n",
      "epoch 101; iter: 0; batch classifier loss: 0.060660; batch adversarial loss: 0.465074\n",
      "epoch 102; iter: 0; batch classifier loss: 0.120229; batch adversarial loss: 0.504159\n",
      "epoch 103; iter: 0; batch classifier loss: 0.148707; batch adversarial loss: 0.540344\n",
      "epoch 104; iter: 0; batch classifier loss: 0.136273; batch adversarial loss: 0.654162\n",
      "epoch 105; iter: 0; batch classifier loss: 0.081473; batch adversarial loss: 0.423858\n",
      "epoch 106; iter: 0; batch classifier loss: 0.132838; batch adversarial loss: 0.516352\n",
      "epoch 107; iter: 0; batch classifier loss: 0.190141; batch adversarial loss: 0.635471\n",
      "epoch 108; iter: 0; batch classifier loss: 0.135325; batch adversarial loss: 0.503854\n",
      "epoch 109; iter: 0; batch classifier loss: 0.156609; batch adversarial loss: 0.542462\n",
      "epoch 110; iter: 0; batch classifier loss: 0.144323; batch adversarial loss: 0.514299\n",
      "epoch 111; iter: 0; batch classifier loss: 0.138945; batch adversarial loss: 0.544240\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075883; batch adversarial loss: 0.490821\n",
      "epoch 113; iter: 0; batch classifier loss: 0.169342; batch adversarial loss: 0.538521\n",
      "epoch 114; iter: 0; batch classifier loss: 0.094943; batch adversarial loss: 0.488590\n",
      "epoch 115; iter: 0; batch classifier loss: 0.093744; batch adversarial loss: 0.501208\n",
      "epoch 116; iter: 0; batch classifier loss: 0.122746; batch adversarial loss: 0.434341\n",
      "epoch 117; iter: 0; batch classifier loss: 0.096006; batch adversarial loss: 0.455051\n",
      "epoch 118; iter: 0; batch classifier loss: 0.139845; batch adversarial loss: 0.451926\n",
      "epoch 119; iter: 0; batch classifier loss: 0.129675; batch adversarial loss: 0.513414\n",
      "epoch 120; iter: 0; batch classifier loss: 0.112912; batch adversarial loss: 0.497030\n",
      "epoch 121; iter: 0; batch classifier loss: 0.089314; batch adversarial loss: 0.569692\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030007; batch adversarial loss: 0.477293\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030575; batch adversarial loss: 0.515007\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036763; batch adversarial loss: 0.431792\n",
      "epoch 125; iter: 0; batch classifier loss: 0.072109; batch adversarial loss: 0.471411\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045640; batch adversarial loss: 0.426178\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051004; batch adversarial loss: 0.448393\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029256; batch adversarial loss: 0.427957\n",
      "epoch 129; iter: 0; batch classifier loss: 0.053872; batch adversarial loss: 0.517941\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031835; batch adversarial loss: 0.389511\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026158; batch adversarial loss: 0.465830\n",
      "epoch 132; iter: 0; batch classifier loss: 0.059600; batch adversarial loss: 0.463931\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037690; batch adversarial loss: 0.457246\n",
      "epoch 134; iter: 0; batch classifier loss: 0.057820; batch adversarial loss: 0.417803\n",
      "epoch 135; iter: 0; batch classifier loss: 0.078444; batch adversarial loss: 0.581646\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042296; batch adversarial loss: 0.417384\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045916; batch adversarial loss: 0.369203\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027089; batch adversarial loss: 0.540712\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032541; batch adversarial loss: 0.401743\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023460; batch adversarial loss: 0.495322\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048021; batch adversarial loss: 0.410263\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028072; batch adversarial loss: 0.409223\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028083; batch adversarial loss: 0.506891\n",
      "epoch 144; iter: 0; batch classifier loss: 0.015006; batch adversarial loss: 0.459464\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045872; batch adversarial loss: 0.433869\n",
      "epoch 146; iter: 0; batch classifier loss: 0.047959; batch adversarial loss: 0.508608\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029476; batch adversarial loss: 0.548529\n",
      "epoch 148; iter: 0; batch classifier loss: 0.058393; batch adversarial loss: 0.421274\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025295; batch adversarial loss: 0.557803\n",
      "epoch 150; iter: 0; batch classifier loss: 0.058274; batch adversarial loss: 0.337570\n",
      "epoch 151; iter: 0; batch classifier loss: 0.084467; batch adversarial loss: 0.431841\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037286; batch adversarial loss: 0.405434\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029394; batch adversarial loss: 0.425653\n",
      "epoch 154; iter: 0; batch classifier loss: 0.063825; batch adversarial loss: 0.458452\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034041; batch adversarial loss: 0.461659\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017546; batch adversarial loss: 0.459029\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016465; batch adversarial loss: 0.523012\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036606; batch adversarial loss: 0.440612\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035688; batch adversarial loss: 0.434613\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025194; batch adversarial loss: 0.484892\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031717; batch adversarial loss: 0.530620\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023018; batch adversarial loss: 0.470872\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028510; batch adversarial loss: 0.410640\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025594; batch adversarial loss: 0.437032\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030938; batch adversarial loss: 0.532416\n",
      "epoch 166; iter: 0; batch classifier loss: 0.043418; batch adversarial loss: 0.489250\n",
      "epoch 167; iter: 0; batch classifier loss: 0.065586; batch adversarial loss: 0.419488\n",
      "epoch 168; iter: 0; batch classifier loss: 0.103300; batch adversarial loss: 0.446082\n",
      "epoch 169; iter: 0; batch classifier loss: 0.048813; batch adversarial loss: 0.425118\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031637; batch adversarial loss: 0.345026\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027265; batch adversarial loss: 0.444454\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019637; batch adversarial loss: 0.452060\n",
      "epoch 173; iter: 0; batch classifier loss: 0.053540; batch adversarial loss: 0.516982\n",
      "epoch 174; iter: 0; batch classifier loss: 0.054195; batch adversarial loss: 0.510007\n",
      "epoch 175; iter: 0; batch classifier loss: 0.053864; batch adversarial loss: 0.457818\n",
      "epoch 176; iter: 0; batch classifier loss: 0.077150; batch adversarial loss: 0.564042\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022456; batch adversarial loss: 0.448070\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030763; batch adversarial loss: 0.467247\n",
      "epoch 179; iter: 0; batch classifier loss: 0.063048; batch adversarial loss: 0.527613\n",
      "epoch 180; iter: 0; batch classifier loss: 0.045941; batch adversarial loss: 0.430173\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033056; batch adversarial loss: 0.377524\n",
      "epoch 182; iter: 0; batch classifier loss: 0.041288; batch adversarial loss: 0.517051\n",
      "epoch 183; iter: 0; batch classifier loss: 0.060454; batch adversarial loss: 0.585356\n",
      "epoch 184; iter: 0; batch classifier loss: 0.039599; batch adversarial loss: 0.451553\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019751; batch adversarial loss: 0.462823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.017539; batch adversarial loss: 0.423038\n",
      "epoch 187; iter: 0; batch classifier loss: 0.049239; batch adversarial loss: 0.459885\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027796; batch adversarial loss: 0.532449\n",
      "epoch 189; iter: 0; batch classifier loss: 0.037540; batch adversarial loss: 0.538216\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021634; batch adversarial loss: 0.449823\n",
      "epoch 191; iter: 0; batch classifier loss: 0.047741; batch adversarial loss: 0.429653\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030121; batch adversarial loss: 0.462481\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023406; batch adversarial loss: 0.480185\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027227; batch adversarial loss: 0.388515\n",
      "epoch 195; iter: 0; batch classifier loss: 0.032210; batch adversarial loss: 0.471963\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033218; batch adversarial loss: 0.317232\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012997; batch adversarial loss: 0.430797\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010692; batch adversarial loss: 0.522093\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033187; batch adversarial loss: 0.524588\n",
      "epoch 0; iter: 0; batch classifier loss: 0.727704; batch adversarial loss: 0.729914\n",
      "epoch 1; iter: 0; batch classifier loss: 0.550099; batch adversarial loss: 0.649765\n",
      "epoch 2; iter: 0; batch classifier loss: 0.491988; batch adversarial loss: 0.631222\n",
      "epoch 3; iter: 0; batch classifier loss: 0.419339; batch adversarial loss: 0.591922\n",
      "epoch 4; iter: 0; batch classifier loss: 0.324972; batch adversarial loss: 0.627009\n",
      "epoch 5; iter: 0; batch classifier loss: 0.440960; batch adversarial loss: 0.566944\n",
      "epoch 6; iter: 0; batch classifier loss: 0.271917; batch adversarial loss: 0.586474\n",
      "epoch 7; iter: 0; batch classifier loss: 0.321221; batch adversarial loss: 0.526584\n",
      "epoch 8; iter: 0; batch classifier loss: 0.366549; batch adversarial loss: 0.517181\n",
      "epoch 9; iter: 0; batch classifier loss: 0.315850; batch adversarial loss: 0.529852\n",
      "epoch 10; iter: 0; batch classifier loss: 0.371239; batch adversarial loss: 0.527008\n",
      "epoch 11; iter: 0; batch classifier loss: 0.345439; batch adversarial loss: 0.464076\n",
      "epoch 12; iter: 0; batch classifier loss: 0.373331; batch adversarial loss: 0.548995\n",
      "epoch 13; iter: 0; batch classifier loss: 0.293390; batch adversarial loss: 0.551018\n",
      "epoch 14; iter: 0; batch classifier loss: 0.238905; batch adversarial loss: 0.530689\n",
      "epoch 15; iter: 0; batch classifier loss: 0.294332; batch adversarial loss: 0.478958\n",
      "epoch 16; iter: 0; batch classifier loss: 0.326134; batch adversarial loss: 0.519556\n",
      "epoch 17; iter: 0; batch classifier loss: 0.214546; batch adversarial loss: 0.441723\n",
      "epoch 18; iter: 0; batch classifier loss: 0.304651; batch adversarial loss: 0.447480\n",
      "epoch 19; iter: 0; batch classifier loss: 0.328269; batch adversarial loss: 0.468888\n",
      "epoch 20; iter: 0; batch classifier loss: 0.233643; batch adversarial loss: 0.568814\n",
      "epoch 21; iter: 0; batch classifier loss: 0.230971; batch adversarial loss: 0.445519\n",
      "epoch 22; iter: 0; batch classifier loss: 0.185212; batch adversarial loss: 0.427040\n",
      "epoch 23; iter: 0; batch classifier loss: 0.240688; batch adversarial loss: 0.574888\n",
      "epoch 24; iter: 0; batch classifier loss: 0.190446; batch adversarial loss: 0.516420\n",
      "epoch 25; iter: 0; batch classifier loss: 0.203914; batch adversarial loss: 0.463814\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208542; batch adversarial loss: 0.470588\n",
      "epoch 27; iter: 0; batch classifier loss: 0.219280; batch adversarial loss: 0.429288\n",
      "epoch 28; iter: 0; batch classifier loss: 0.225013; batch adversarial loss: 0.455584\n",
      "epoch 29; iter: 0; batch classifier loss: 0.230296; batch adversarial loss: 0.434459\n",
      "epoch 30; iter: 0; batch classifier loss: 0.244388; batch adversarial loss: 0.463677\n",
      "epoch 31; iter: 0; batch classifier loss: 0.192556; batch adversarial loss: 0.560619\n",
      "epoch 32; iter: 0; batch classifier loss: 0.213648; batch adversarial loss: 0.512532\n",
      "epoch 33; iter: 0; batch classifier loss: 0.179860; batch adversarial loss: 0.508055\n",
      "epoch 34; iter: 0; batch classifier loss: 0.285904; batch adversarial loss: 0.404075\n",
      "epoch 35; iter: 0; batch classifier loss: 0.237637; batch adversarial loss: 0.450994\n",
      "epoch 36; iter: 0; batch classifier loss: 0.219901; batch adversarial loss: 0.463122\n",
      "epoch 37; iter: 0; batch classifier loss: 0.229297; batch adversarial loss: 0.473243\n",
      "epoch 38; iter: 0; batch classifier loss: 0.229763; batch adversarial loss: 0.393995\n",
      "epoch 39; iter: 0; batch classifier loss: 0.293065; batch adversarial loss: 0.525375\n",
      "epoch 40; iter: 0; batch classifier loss: 0.234730; batch adversarial loss: 0.436948\n",
      "epoch 41; iter: 0; batch classifier loss: 0.221702; batch adversarial loss: 0.496590\n",
      "epoch 42; iter: 0; batch classifier loss: 0.223059; batch adversarial loss: 0.499452\n",
      "epoch 43; iter: 0; batch classifier loss: 0.271317; batch adversarial loss: 0.418712\n",
      "epoch 44; iter: 0; batch classifier loss: 0.183038; batch adversarial loss: 0.398062\n",
      "epoch 45; iter: 0; batch classifier loss: 0.212418; batch adversarial loss: 0.637708\n",
      "epoch 46; iter: 0; batch classifier loss: 0.200606; batch adversarial loss: 0.533036\n",
      "epoch 47; iter: 0; batch classifier loss: 0.252519; batch adversarial loss: 0.533970\n",
      "epoch 48; iter: 0; batch classifier loss: 0.191332; batch adversarial loss: 0.391088\n",
      "epoch 49; iter: 0; batch classifier loss: 0.180130; batch adversarial loss: 0.518942\n",
      "epoch 50; iter: 0; batch classifier loss: 0.197783; batch adversarial loss: 0.482484\n",
      "epoch 51; iter: 0; batch classifier loss: 0.258883; batch adversarial loss: 0.555959\n",
      "epoch 52; iter: 0; batch classifier loss: 0.214669; batch adversarial loss: 0.385590\n",
      "epoch 53; iter: 0; batch classifier loss: 0.280377; batch adversarial loss: 0.459178\n",
      "epoch 54; iter: 0; batch classifier loss: 0.100602; batch adversarial loss: 0.544818\n",
      "epoch 55; iter: 0; batch classifier loss: 0.102196; batch adversarial loss: 0.381968\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065525; batch adversarial loss: 0.540465\n",
      "epoch 57; iter: 0; batch classifier loss: 0.074116; batch adversarial loss: 0.385912\n",
      "epoch 58; iter: 0; batch classifier loss: 0.111752; batch adversarial loss: 0.472671\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083840; batch adversarial loss: 0.452851\n",
      "epoch 60; iter: 0; batch classifier loss: 0.056555; batch adversarial loss: 0.413079\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104004; batch adversarial loss: 0.493362\n",
      "epoch 62; iter: 0; batch classifier loss: 0.049215; batch adversarial loss: 0.386594\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089286; batch adversarial loss: 0.478247\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090502; batch adversarial loss: 0.446193\n",
      "epoch 65; iter: 0; batch classifier loss: 0.084941; batch adversarial loss: 0.411379\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086114; batch adversarial loss: 0.540329\n",
      "epoch 67; iter: 0; batch classifier loss: 0.051516; batch adversarial loss: 0.466697\n",
      "epoch 68; iter: 0; batch classifier loss: 0.045691; batch adversarial loss: 0.359311\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064334; batch adversarial loss: 0.367186\n",
      "epoch 70; iter: 0; batch classifier loss: 0.061658; batch adversarial loss: 0.365925\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115376; batch adversarial loss: 0.328239\n",
      "epoch 72; iter: 0; batch classifier loss: 0.044548; batch adversarial loss: 0.548564\n",
      "epoch 73; iter: 0; batch classifier loss: 0.055514; batch adversarial loss: 0.440138\n",
      "epoch 74; iter: 0; batch classifier loss: 0.102046; batch adversarial loss: 0.351282\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076846; batch adversarial loss: 0.416451\n",
      "epoch 76; iter: 0; batch classifier loss: 0.087466; batch adversarial loss: 0.421973\n",
      "epoch 77; iter: 0; batch classifier loss: 0.061556; batch adversarial loss: 0.399596\n",
      "epoch 78; iter: 0; batch classifier loss: 0.106228; batch adversarial loss: 0.459200\n",
      "epoch 79; iter: 0; batch classifier loss: 0.126209; batch adversarial loss: 0.423239\n",
      "epoch 80; iter: 0; batch classifier loss: 0.051785; batch adversarial loss: 0.450793\n",
      "epoch 81; iter: 0; batch classifier loss: 0.039587; batch adversarial loss: 0.420743\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083748; batch adversarial loss: 0.460684\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081121; batch adversarial loss: 0.350988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.048856; batch adversarial loss: 0.448770\n",
      "epoch 85; iter: 0; batch classifier loss: 0.087131; batch adversarial loss: 0.529731\n",
      "epoch 86; iter: 0; batch classifier loss: 0.056894; batch adversarial loss: 0.421811\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049892; batch adversarial loss: 0.361326\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075358; batch adversarial loss: 0.415048\n",
      "epoch 89; iter: 0; batch classifier loss: 0.088923; batch adversarial loss: 0.305646\n",
      "epoch 90; iter: 0; batch classifier loss: 0.080375; batch adversarial loss: 0.488036\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060808; batch adversarial loss: 0.370806\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064354; batch adversarial loss: 0.427115\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062563; batch adversarial loss: 0.431622\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061395; batch adversarial loss: 0.375204\n",
      "epoch 95; iter: 0; batch classifier loss: 0.078722; batch adversarial loss: 0.386528\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051267; batch adversarial loss: 0.442892\n",
      "epoch 97; iter: 0; batch classifier loss: 0.068859; batch adversarial loss: 0.577884\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044885; batch adversarial loss: 0.378565\n",
      "epoch 99; iter: 0; batch classifier loss: 0.077439; batch adversarial loss: 0.436838\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057800; batch adversarial loss: 0.436426\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055037; batch adversarial loss: 0.410689\n",
      "epoch 102; iter: 0; batch classifier loss: 0.091979; batch adversarial loss: 0.452663\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048233; batch adversarial loss: 0.435470\n",
      "epoch 104; iter: 0; batch classifier loss: 0.088338; batch adversarial loss: 0.389256\n",
      "epoch 105; iter: 0; batch classifier loss: 0.069423; batch adversarial loss: 0.409399\n",
      "epoch 106; iter: 0; batch classifier loss: 0.060921; batch adversarial loss: 0.429346\n",
      "epoch 107; iter: 0; batch classifier loss: 0.100638; batch adversarial loss: 0.446275\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069525; batch adversarial loss: 0.429954\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059440; batch adversarial loss: 0.368872\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052714; batch adversarial loss: 0.440601\n",
      "epoch 111; iter: 0; batch classifier loss: 0.108260; batch adversarial loss: 0.396125\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054028; batch adversarial loss: 0.536431\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055889; batch adversarial loss: 0.444612\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056087; batch adversarial loss: 0.339799\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059997; batch adversarial loss: 0.454378\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056547; batch adversarial loss: 0.427600\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060381; batch adversarial loss: 0.481136\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057133; batch adversarial loss: 0.366637\n",
      "epoch 119; iter: 0; batch classifier loss: 0.052375; batch adversarial loss: 0.494850\n",
      "epoch 120; iter: 0; batch classifier loss: 0.063265; batch adversarial loss: 0.433523\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038102; batch adversarial loss: 0.499071\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036400; batch adversarial loss: 0.447158\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043355; batch adversarial loss: 0.366183\n",
      "epoch 124; iter: 0; batch classifier loss: 0.068365; batch adversarial loss: 0.458206\n",
      "epoch 125; iter: 0; batch classifier loss: 0.082256; batch adversarial loss: 0.393472\n",
      "epoch 126; iter: 0; batch classifier loss: 0.060808; batch adversarial loss: 0.357256\n",
      "epoch 127; iter: 0; batch classifier loss: 0.057824; batch adversarial loss: 0.439720\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038434; batch adversarial loss: 0.468254\n",
      "epoch 129; iter: 0; batch classifier loss: 0.067834; batch adversarial loss: 0.483856\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047002; batch adversarial loss: 0.425513\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043962; batch adversarial loss: 0.397496\n",
      "epoch 132; iter: 0; batch classifier loss: 0.065597; batch adversarial loss: 0.370010\n",
      "epoch 133; iter: 0; batch classifier loss: 0.066936; batch adversarial loss: 0.412299\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026233; batch adversarial loss: 0.420198\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043388; batch adversarial loss: 0.414738\n",
      "epoch 136; iter: 0; batch classifier loss: 0.055561; batch adversarial loss: 0.400446\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046930; batch adversarial loss: 0.406113\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033039; batch adversarial loss: 0.549290\n",
      "epoch 139; iter: 0; batch classifier loss: 0.058389; batch adversarial loss: 0.401953\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025362; batch adversarial loss: 0.458320\n",
      "epoch 141; iter: 0; batch classifier loss: 0.080484; batch adversarial loss: 0.444012\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042990; batch adversarial loss: 0.400169\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051178; batch adversarial loss: 0.462216\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045829; batch adversarial loss: 0.407592\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045113; batch adversarial loss: 0.377728\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030860; batch adversarial loss: 0.481543\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031745; batch adversarial loss: 0.504489\n",
      "epoch 148; iter: 0; batch classifier loss: 0.061254; batch adversarial loss: 0.386492\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035712; batch adversarial loss: 0.322188\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035244; batch adversarial loss: 0.468964\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023819; batch adversarial loss: 0.429539\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024452; batch adversarial loss: 0.423914\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034739; batch adversarial loss: 0.415531\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016942; batch adversarial loss: 0.389174\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036468; batch adversarial loss: 0.491856\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042502; batch adversarial loss: 0.401509\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034365; batch adversarial loss: 0.456674\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029930; batch adversarial loss: 0.381291\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023597; batch adversarial loss: 0.430714\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017064; batch adversarial loss: 0.364565\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027042; batch adversarial loss: 0.439897\n",
      "epoch 162; iter: 0; batch classifier loss: 0.042839; batch adversarial loss: 0.385483\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027977; batch adversarial loss: 0.395711\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038701; batch adversarial loss: 0.341109\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019481; batch adversarial loss: 0.456828\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046020; batch adversarial loss: 0.419169\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022052; batch adversarial loss: 0.414935\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034090; batch adversarial loss: 0.456179\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029013; batch adversarial loss: 0.379511\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033105; batch adversarial loss: 0.451332\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014655; batch adversarial loss: 0.336657\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019032; batch adversarial loss: 0.460281\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035324; batch adversarial loss: 0.422229\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029377; batch adversarial loss: 0.471789\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015210; batch adversarial loss: 0.490903\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035073; batch adversarial loss: 0.355874\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011732; batch adversarial loss: 0.456044\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022533; batch adversarial loss: 0.430777\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016235; batch adversarial loss: 0.347724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.005847; batch adversarial loss: 0.489314\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017756; batch adversarial loss: 0.384563\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017859; batch adversarial loss: 0.424295\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025614; batch adversarial loss: 0.470220\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031430; batch adversarial loss: 0.464312\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013935; batch adversarial loss: 0.400618\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026891; batch adversarial loss: 0.446734\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033119; batch adversarial loss: 0.363124\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009539; batch adversarial loss: 0.470665\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014323; batch adversarial loss: 0.494281\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013778; batch adversarial loss: 0.445261\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022938; batch adversarial loss: 0.426064\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013548; batch adversarial loss: 0.407515\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017120; batch adversarial loss: 0.514590\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022669; batch adversarial loss: 0.380929\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023669; batch adversarial loss: 0.501568\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011971; batch adversarial loss: 0.465313\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033474; batch adversarial loss: 0.481083\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018024; batch adversarial loss: 0.433663\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031181; batch adversarial loss: 0.482244\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677390; batch adversarial loss: 0.920361\n",
      "epoch 1; iter: 0; batch classifier loss: 0.496849; batch adversarial loss: 0.990739\n",
      "epoch 2; iter: 0; batch classifier loss: 0.328082; batch adversarial loss: 0.968972\n",
      "epoch 3; iter: 0; batch classifier loss: 0.465362; batch adversarial loss: 0.887848\n",
      "epoch 4; iter: 0; batch classifier loss: 0.316557; batch adversarial loss: 0.807967\n",
      "epoch 5; iter: 0; batch classifier loss: 0.307024; batch adversarial loss: 0.743094\n",
      "epoch 6; iter: 0; batch classifier loss: 0.277500; batch adversarial loss: 0.762097\n",
      "epoch 7; iter: 0; batch classifier loss: 0.271721; batch adversarial loss: 0.696546\n",
      "epoch 8; iter: 0; batch classifier loss: 0.292273; batch adversarial loss: 0.659390\n",
      "epoch 9; iter: 0; batch classifier loss: 0.265667; batch adversarial loss: 0.605084\n",
      "epoch 10; iter: 0; batch classifier loss: 0.267248; batch adversarial loss: 0.589575\n",
      "epoch 11; iter: 0; batch classifier loss: 0.245458; batch adversarial loss: 0.584257\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251171; batch adversarial loss: 0.533322\n",
      "epoch 13; iter: 0; batch classifier loss: 0.237529; batch adversarial loss: 0.528673\n",
      "epoch 14; iter: 0; batch classifier loss: 0.224986; batch adversarial loss: 0.547942\n",
      "epoch 15; iter: 0; batch classifier loss: 0.192288; batch adversarial loss: 0.559210\n",
      "epoch 16; iter: 0; batch classifier loss: 0.180466; batch adversarial loss: 0.497031\n",
      "epoch 17; iter: 0; batch classifier loss: 0.180737; batch adversarial loss: 0.521521\n",
      "epoch 18; iter: 0; batch classifier loss: 0.210692; batch adversarial loss: 0.481893\n",
      "epoch 19; iter: 0; batch classifier loss: 0.145925; batch adversarial loss: 0.515442\n",
      "epoch 20; iter: 0; batch classifier loss: 0.185707; batch adversarial loss: 0.513770\n",
      "epoch 21; iter: 0; batch classifier loss: 0.229440; batch adversarial loss: 0.529727\n",
      "epoch 22; iter: 0; batch classifier loss: 0.219957; batch adversarial loss: 0.440869\n",
      "epoch 23; iter: 0; batch classifier loss: 0.210904; batch adversarial loss: 0.486841\n",
      "epoch 24; iter: 0; batch classifier loss: 0.210112; batch adversarial loss: 0.427628\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172370; batch adversarial loss: 0.437277\n",
      "epoch 26; iter: 0; batch classifier loss: 0.215707; batch adversarial loss: 0.418612\n",
      "epoch 27; iter: 0; batch classifier loss: 0.268578; batch adversarial loss: 0.449696\n",
      "epoch 28; iter: 0; batch classifier loss: 0.214868; batch adversarial loss: 0.411019\n",
      "epoch 29; iter: 0; batch classifier loss: 0.207275; batch adversarial loss: 0.497358\n",
      "epoch 30; iter: 0; batch classifier loss: 0.184390; batch adversarial loss: 0.439417\n",
      "epoch 31; iter: 0; batch classifier loss: 0.184795; batch adversarial loss: 0.400109\n",
      "epoch 32; iter: 0; batch classifier loss: 0.211265; batch adversarial loss: 0.410491\n",
      "epoch 33; iter: 0; batch classifier loss: 0.118136; batch adversarial loss: 0.465509\n",
      "epoch 34; iter: 0; batch classifier loss: 0.192036; batch adversarial loss: 0.491558\n",
      "epoch 35; iter: 0; batch classifier loss: 0.135091; batch adversarial loss: 0.360196\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128458; batch adversarial loss: 0.459095\n",
      "epoch 37; iter: 0; batch classifier loss: 0.181176; batch adversarial loss: 0.374070\n",
      "epoch 38; iter: 0; batch classifier loss: 0.100386; batch adversarial loss: 0.375363\n",
      "epoch 39; iter: 0; batch classifier loss: 0.168432; batch adversarial loss: 0.367989\n",
      "epoch 40; iter: 0; batch classifier loss: 0.143881; batch adversarial loss: 0.435451\n",
      "epoch 41; iter: 0; batch classifier loss: 0.136820; batch adversarial loss: 0.437990\n",
      "epoch 42; iter: 0; batch classifier loss: 0.163438; batch adversarial loss: 0.331351\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110073; batch adversarial loss: 0.447881\n",
      "epoch 44; iter: 0; batch classifier loss: 0.069356; batch adversarial loss: 0.397881\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097422; batch adversarial loss: 0.436396\n",
      "epoch 46; iter: 0; batch classifier loss: 0.131687; batch adversarial loss: 0.439101\n",
      "epoch 47; iter: 0; batch classifier loss: 0.103070; batch adversarial loss: 0.336252\n",
      "epoch 48; iter: 0; batch classifier loss: 0.152602; batch adversarial loss: 0.453278\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119347; batch adversarial loss: 0.369009\n",
      "epoch 50; iter: 0; batch classifier loss: 0.044192; batch adversarial loss: 0.392981\n",
      "epoch 51; iter: 0; batch classifier loss: 0.117185; batch adversarial loss: 0.361626\n",
      "epoch 52; iter: 0; batch classifier loss: 0.124482; batch adversarial loss: 0.437552\n",
      "epoch 53; iter: 0; batch classifier loss: 0.135827; batch adversarial loss: 0.423439\n",
      "epoch 54; iter: 0; batch classifier loss: 0.149854; batch adversarial loss: 0.456075\n",
      "epoch 55; iter: 0; batch classifier loss: 0.156017; batch adversarial loss: 0.439167\n",
      "epoch 56; iter: 0; batch classifier loss: 0.086548; batch adversarial loss: 0.348298\n",
      "epoch 57; iter: 0; batch classifier loss: 0.110516; batch adversarial loss: 0.491739\n",
      "epoch 58; iter: 0; batch classifier loss: 0.071337; batch adversarial loss: 0.443015\n",
      "epoch 59; iter: 0; batch classifier loss: 0.082407; batch adversarial loss: 0.395820\n",
      "epoch 60; iter: 0; batch classifier loss: 0.134807; batch adversarial loss: 0.544007\n",
      "epoch 61; iter: 0; batch classifier loss: 0.073565; batch adversarial loss: 0.363499\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093753; batch adversarial loss: 0.409288\n",
      "epoch 63; iter: 0; batch classifier loss: 0.054943; batch adversarial loss: 0.329787\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078411; batch adversarial loss: 0.322404\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065596; batch adversarial loss: 0.388777\n",
      "epoch 66; iter: 0; batch classifier loss: 0.056590; batch adversarial loss: 0.390755\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096705; batch adversarial loss: 0.478858\n",
      "epoch 68; iter: 0; batch classifier loss: 0.057385; batch adversarial loss: 0.472757\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065924; batch adversarial loss: 0.372523\n",
      "epoch 70; iter: 0; batch classifier loss: 0.114619; batch adversarial loss: 0.530316\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073022; batch adversarial loss: 0.413441\n",
      "epoch 72; iter: 0; batch classifier loss: 0.057842; batch adversarial loss: 0.420970\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079675; batch adversarial loss: 0.451146\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067315; batch adversarial loss: 0.455151\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096934; batch adversarial loss: 0.396347\n",
      "epoch 76; iter: 0; batch classifier loss: 0.073346; batch adversarial loss: 0.487134\n",
      "epoch 77; iter: 0; batch classifier loss: 0.044583; batch adversarial loss: 0.379109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.049131; batch adversarial loss: 0.397475\n",
      "epoch 79; iter: 0; batch classifier loss: 0.040834; batch adversarial loss: 0.393019\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054838; batch adversarial loss: 0.445286\n",
      "epoch 81; iter: 0; batch classifier loss: 0.052499; batch adversarial loss: 0.415353\n",
      "epoch 82; iter: 0; batch classifier loss: 0.057856; batch adversarial loss: 0.384749\n",
      "epoch 83; iter: 0; batch classifier loss: 0.077729; batch adversarial loss: 0.441605\n",
      "epoch 84; iter: 0; batch classifier loss: 0.054115; batch adversarial loss: 0.437987\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083131; batch adversarial loss: 0.371521\n",
      "epoch 86; iter: 0; batch classifier loss: 0.103921; batch adversarial loss: 0.450912\n",
      "epoch 87; iter: 0; batch classifier loss: 0.086157; batch adversarial loss: 0.388805\n",
      "epoch 88; iter: 0; batch classifier loss: 0.056500; batch adversarial loss: 0.416726\n",
      "epoch 89; iter: 0; batch classifier loss: 0.087233; batch adversarial loss: 0.465869\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066381; batch adversarial loss: 0.501346\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059593; batch adversarial loss: 0.433897\n",
      "epoch 92; iter: 0; batch classifier loss: 0.067074; batch adversarial loss: 0.357324\n",
      "epoch 93; iter: 0; batch classifier loss: 0.110828; batch adversarial loss: 0.534169\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066424; batch adversarial loss: 0.407519\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081995; batch adversarial loss: 0.367020\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057098; batch adversarial loss: 0.402382\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081286; batch adversarial loss: 0.481778\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047000; batch adversarial loss: 0.384591\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043914; batch adversarial loss: 0.363722\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039669; batch adversarial loss: 0.348540\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071123; batch adversarial loss: 0.525853\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046767; batch adversarial loss: 0.447173\n",
      "epoch 103; iter: 0; batch classifier loss: 0.074470; batch adversarial loss: 0.452099\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061528; batch adversarial loss: 0.334605\n",
      "epoch 105; iter: 0; batch classifier loss: 0.078149; batch adversarial loss: 0.367821\n",
      "epoch 106; iter: 0; batch classifier loss: 0.069536; batch adversarial loss: 0.441919\n",
      "epoch 107; iter: 0; batch classifier loss: 0.080953; batch adversarial loss: 0.441565\n",
      "epoch 108; iter: 0; batch classifier loss: 0.078732; batch adversarial loss: 0.337301\n",
      "epoch 109; iter: 0; batch classifier loss: 0.071901; batch adversarial loss: 0.403724\n",
      "epoch 110; iter: 0; batch classifier loss: 0.066503; batch adversarial loss: 0.368593\n",
      "epoch 111; iter: 0; batch classifier loss: 0.088017; batch adversarial loss: 0.452410\n",
      "epoch 112; iter: 0; batch classifier loss: 0.073762; batch adversarial loss: 0.444317\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059313; batch adversarial loss: 0.419724\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062729; batch adversarial loss: 0.419507\n",
      "epoch 115; iter: 0; batch classifier loss: 0.067323; batch adversarial loss: 0.456933\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057761; batch adversarial loss: 0.432562\n",
      "epoch 117; iter: 0; batch classifier loss: 0.084934; batch adversarial loss: 0.449899\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054901; batch adversarial loss: 0.485264\n",
      "epoch 119; iter: 0; batch classifier loss: 0.028270; batch adversarial loss: 0.430523\n",
      "epoch 120; iter: 0; batch classifier loss: 0.069923; batch adversarial loss: 0.499371\n",
      "epoch 121; iter: 0; batch classifier loss: 0.062812; batch adversarial loss: 0.437850\n",
      "epoch 122; iter: 0; batch classifier loss: 0.056602; batch adversarial loss: 0.394057\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049368; batch adversarial loss: 0.447026\n",
      "epoch 124; iter: 0; batch classifier loss: 0.058975; batch adversarial loss: 0.395540\n",
      "epoch 125; iter: 0; batch classifier loss: 0.071164; batch adversarial loss: 0.357735\n",
      "epoch 126; iter: 0; batch classifier loss: 0.067560; batch adversarial loss: 0.446597\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034276; batch adversarial loss: 0.426887\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036150; batch adversarial loss: 0.440913\n",
      "epoch 129; iter: 0; batch classifier loss: 0.061815; batch adversarial loss: 0.391512\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059918; batch adversarial loss: 0.445750\n",
      "epoch 131; iter: 0; batch classifier loss: 0.070240; batch adversarial loss: 0.426388\n",
      "epoch 132; iter: 0; batch classifier loss: 0.073464; batch adversarial loss: 0.476574\n",
      "epoch 133; iter: 0; batch classifier loss: 0.056215; batch adversarial loss: 0.410260\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069517; batch adversarial loss: 0.400797\n",
      "epoch 135; iter: 0; batch classifier loss: 0.054993; batch adversarial loss: 0.450411\n",
      "epoch 136; iter: 0; batch classifier loss: 0.051197; batch adversarial loss: 0.439314\n",
      "epoch 137; iter: 0; batch classifier loss: 0.078798; batch adversarial loss: 0.474120\n",
      "epoch 138; iter: 0; batch classifier loss: 0.058596; batch adversarial loss: 0.452404\n",
      "epoch 139; iter: 0; batch classifier loss: 0.057777; batch adversarial loss: 0.479830\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027493; batch adversarial loss: 0.519511\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040207; batch adversarial loss: 0.395881\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048323; batch adversarial loss: 0.465322\n",
      "epoch 143; iter: 0; batch classifier loss: 0.061244; batch adversarial loss: 0.439352\n",
      "epoch 144; iter: 0; batch classifier loss: 0.065345; batch adversarial loss: 0.423545\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039053; batch adversarial loss: 0.404706\n",
      "epoch 146; iter: 0; batch classifier loss: 0.087316; batch adversarial loss: 0.453433\n",
      "epoch 147; iter: 0; batch classifier loss: 0.070338; batch adversarial loss: 0.389528\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035614; batch adversarial loss: 0.401162\n",
      "epoch 149; iter: 0; batch classifier loss: 0.052583; batch adversarial loss: 0.319617\n",
      "epoch 150; iter: 0; batch classifier loss: 0.047317; batch adversarial loss: 0.418633\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044068; batch adversarial loss: 0.369078\n",
      "epoch 152; iter: 0; batch classifier loss: 0.065509; batch adversarial loss: 0.372575\n",
      "epoch 153; iter: 0; batch classifier loss: 0.046843; batch adversarial loss: 0.418770\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037747; batch adversarial loss: 0.483835\n",
      "epoch 155; iter: 0; batch classifier loss: 0.055709; batch adversarial loss: 0.462382\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042572; batch adversarial loss: 0.463034\n",
      "epoch 157; iter: 0; batch classifier loss: 0.050194; batch adversarial loss: 0.507521\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045601; batch adversarial loss: 0.446420\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020686; batch adversarial loss: 0.495461\n",
      "epoch 160; iter: 0; batch classifier loss: 0.042711; batch adversarial loss: 0.419377\n",
      "epoch 161; iter: 0; batch classifier loss: 0.062265; batch adversarial loss: 0.453735\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028431; batch adversarial loss: 0.402586\n",
      "epoch 163; iter: 0; batch classifier loss: 0.047903; batch adversarial loss: 0.429388\n",
      "epoch 164; iter: 0; batch classifier loss: 0.047330; batch adversarial loss: 0.416111\n",
      "epoch 165; iter: 0; batch classifier loss: 0.063330; batch adversarial loss: 0.418606\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030416; batch adversarial loss: 0.471588\n",
      "epoch 167; iter: 0; batch classifier loss: 0.087662; batch adversarial loss: 0.363591\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031251; batch adversarial loss: 0.451205\n",
      "epoch 169; iter: 0; batch classifier loss: 0.043658; batch adversarial loss: 0.446035\n",
      "epoch 170; iter: 0; batch classifier loss: 0.050013; batch adversarial loss: 0.375435\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024930; batch adversarial loss: 0.439415\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036558; batch adversarial loss: 0.409189\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023364; batch adversarial loss: 0.457490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.022907; batch adversarial loss: 0.402725\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022251; batch adversarial loss: 0.491857\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017139; batch adversarial loss: 0.409381\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038195; batch adversarial loss: 0.414523\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035316; batch adversarial loss: 0.443401\n",
      "epoch 179; iter: 0; batch classifier loss: 0.041490; batch adversarial loss: 0.500974\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017368; batch adversarial loss: 0.482440\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017086; batch adversarial loss: 0.437667\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022006; batch adversarial loss: 0.438082\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012869; batch adversarial loss: 0.401286\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013135; batch adversarial loss: 0.451290\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033133; batch adversarial loss: 0.430691\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012805; batch adversarial loss: 0.463831\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012311; batch adversarial loss: 0.430853\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027088; batch adversarial loss: 0.412683\n",
      "epoch 189; iter: 0; batch classifier loss: 0.038106; batch adversarial loss: 0.439267\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018658; batch adversarial loss: 0.483098\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014028; batch adversarial loss: 0.410865\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013244; batch adversarial loss: 0.387859\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029601; batch adversarial loss: 0.405246\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022634; batch adversarial loss: 0.372938\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010418; batch adversarial loss: 0.432836\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023326; batch adversarial loss: 0.432288\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020337; batch adversarial loss: 0.547103\n",
      "epoch 198; iter: 0; batch classifier loss: 0.036068; batch adversarial loss: 0.468545\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015181; batch adversarial loss: 0.455132\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694523; batch adversarial loss: 0.670337\n",
      "epoch 1; iter: 0; batch classifier loss: 0.384819; batch adversarial loss: 0.652453\n",
      "epoch 2; iter: 0; batch classifier loss: 0.513866; batch adversarial loss: 0.642608\n",
      "epoch 3; iter: 0; batch classifier loss: 0.407724; batch adversarial loss: 0.618886\n",
      "epoch 4; iter: 0; batch classifier loss: 0.470026; batch adversarial loss: 0.600103\n",
      "epoch 5; iter: 0; batch classifier loss: 0.590621; batch adversarial loss: 0.599755\n",
      "epoch 6; iter: 0; batch classifier loss: 0.517210; batch adversarial loss: 0.587895\n",
      "epoch 7; iter: 0; batch classifier loss: 0.492803; batch adversarial loss: 0.567465\n",
      "epoch 8; iter: 0; batch classifier loss: 0.513793; batch adversarial loss: 0.554065\n",
      "epoch 9; iter: 0; batch classifier loss: 0.398179; batch adversarial loss: 0.559450\n",
      "epoch 10; iter: 0; batch classifier loss: 0.352206; batch adversarial loss: 0.586335\n",
      "epoch 11; iter: 0; batch classifier loss: 0.339344; batch adversarial loss: 0.545987\n",
      "epoch 12; iter: 0; batch classifier loss: 0.364361; batch adversarial loss: 0.475448\n",
      "epoch 13; iter: 0; batch classifier loss: 0.335997; batch adversarial loss: 0.473320\n",
      "epoch 14; iter: 0; batch classifier loss: 0.367537; batch adversarial loss: 0.527126\n",
      "epoch 15; iter: 0; batch classifier loss: 0.279887; batch adversarial loss: 0.545864\n",
      "epoch 16; iter: 0; batch classifier loss: 0.339224; batch adversarial loss: 0.492851\n",
      "epoch 17; iter: 0; batch classifier loss: 0.296811; batch adversarial loss: 0.530522\n",
      "epoch 18; iter: 0; batch classifier loss: 0.235783; batch adversarial loss: 0.496540\n",
      "epoch 19; iter: 0; batch classifier loss: 0.213411; batch adversarial loss: 0.489629\n",
      "epoch 20; iter: 0; batch classifier loss: 0.240184; batch adversarial loss: 0.487503\n",
      "epoch 21; iter: 0; batch classifier loss: 0.274257; batch adversarial loss: 0.434329\n",
      "epoch 22; iter: 0; batch classifier loss: 0.290224; batch adversarial loss: 0.426608\n",
      "epoch 23; iter: 0; batch classifier loss: 0.247239; batch adversarial loss: 0.496773\n",
      "epoch 24; iter: 0; batch classifier loss: 0.262360; batch adversarial loss: 0.454830\n",
      "epoch 25; iter: 0; batch classifier loss: 0.187784; batch adversarial loss: 0.480964\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181991; batch adversarial loss: 0.450845\n",
      "epoch 27; iter: 0; batch classifier loss: 0.202898; batch adversarial loss: 0.439603\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217812; batch adversarial loss: 0.448257\n",
      "epoch 29; iter: 0; batch classifier loss: 0.215549; batch adversarial loss: 0.431876\n",
      "epoch 30; iter: 0; batch classifier loss: 0.208939; batch adversarial loss: 0.374017\n",
      "epoch 31; iter: 0; batch classifier loss: 0.148534; batch adversarial loss: 0.457898\n",
      "epoch 32; iter: 0; batch classifier loss: 0.268259; batch adversarial loss: 0.449765\n",
      "epoch 33; iter: 0; batch classifier loss: 0.192461; batch adversarial loss: 0.450853\n",
      "epoch 34; iter: 0; batch classifier loss: 0.154782; batch adversarial loss: 0.451928\n",
      "epoch 35; iter: 0; batch classifier loss: 0.159127; batch adversarial loss: 0.526960\n",
      "epoch 36; iter: 0; batch classifier loss: 0.183552; batch adversarial loss: 0.391228\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166643; batch adversarial loss: 0.532547\n",
      "epoch 38; iter: 0; batch classifier loss: 0.218438; batch adversarial loss: 0.423964\n",
      "epoch 39; iter: 0; batch classifier loss: 0.198351; batch adversarial loss: 0.411769\n",
      "epoch 40; iter: 0; batch classifier loss: 0.176387; batch adversarial loss: 0.458577\n",
      "epoch 41; iter: 0; batch classifier loss: 0.247281; batch adversarial loss: 0.488211\n",
      "epoch 42; iter: 0; batch classifier loss: 0.205730; batch adversarial loss: 0.460454\n",
      "epoch 43; iter: 0; batch classifier loss: 0.170532; batch adversarial loss: 0.525260\n",
      "epoch 44; iter: 0; batch classifier loss: 0.185153; batch adversarial loss: 0.478948\n",
      "epoch 45; iter: 0; batch classifier loss: 0.227715; batch adversarial loss: 0.520713\n",
      "epoch 46; iter: 0; batch classifier loss: 0.305142; batch adversarial loss: 0.445197\n",
      "epoch 47; iter: 0; batch classifier loss: 0.156506; batch adversarial loss: 0.455950\n",
      "epoch 48; iter: 0; batch classifier loss: 0.174888; batch adversarial loss: 0.472118\n",
      "epoch 49; iter: 0; batch classifier loss: 0.149374; batch adversarial loss: 0.446364\n",
      "epoch 50; iter: 0; batch classifier loss: 0.181565; batch adversarial loss: 0.484098\n",
      "epoch 51; iter: 0; batch classifier loss: 0.190318; batch adversarial loss: 0.471366\n",
      "epoch 52; iter: 0; batch classifier loss: 0.183218; batch adversarial loss: 0.387997\n",
      "epoch 53; iter: 0; batch classifier loss: 0.159996; batch adversarial loss: 0.447577\n",
      "epoch 54; iter: 0; batch classifier loss: 0.154279; batch adversarial loss: 0.518851\n",
      "epoch 55; iter: 0; batch classifier loss: 0.144179; batch adversarial loss: 0.446839\n",
      "epoch 56; iter: 0; batch classifier loss: 0.228633; batch adversarial loss: 0.326095\n",
      "epoch 57; iter: 0; batch classifier loss: 0.170467; batch adversarial loss: 0.434772\n",
      "epoch 58; iter: 0; batch classifier loss: 0.130421; batch adversarial loss: 0.423800\n",
      "epoch 59; iter: 0; batch classifier loss: 0.187319; batch adversarial loss: 0.519602\n",
      "epoch 60; iter: 0; batch classifier loss: 0.217804; batch adversarial loss: 0.595174\n",
      "epoch 61; iter: 0; batch classifier loss: 0.109062; batch adversarial loss: 0.545846\n",
      "epoch 62; iter: 0; batch classifier loss: 0.178643; batch adversarial loss: 0.495055\n",
      "epoch 63; iter: 0; batch classifier loss: 0.168367; batch adversarial loss: 0.471590\n",
      "epoch 64; iter: 0; batch classifier loss: 0.128354; batch adversarial loss: 0.483918\n",
      "epoch 65; iter: 0; batch classifier loss: 0.153693; batch adversarial loss: 0.458939\n",
      "epoch 66; iter: 0; batch classifier loss: 0.120898; batch adversarial loss: 0.457193\n",
      "epoch 67; iter: 0; batch classifier loss: 0.205947; batch adversarial loss: 0.496406\n",
      "epoch 68; iter: 0; batch classifier loss: 0.138011; batch adversarial loss: 0.374727\n",
      "epoch 69; iter: 0; batch classifier loss: 0.251104; batch adversarial loss: 0.445977\n",
      "epoch 70; iter: 0; batch classifier loss: 0.154491; batch adversarial loss: 0.483440\n",
      "epoch 71; iter: 0; batch classifier loss: 0.214228; batch adversarial loss: 0.495885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.198236; batch adversarial loss: 0.470744\n",
      "epoch 73; iter: 0; batch classifier loss: 0.198477; batch adversarial loss: 0.556129\n",
      "epoch 74; iter: 0; batch classifier loss: 0.110285; batch adversarial loss: 0.556736\n",
      "epoch 75; iter: 0; batch classifier loss: 0.177728; batch adversarial loss: 0.471159\n",
      "epoch 76; iter: 0; batch classifier loss: 0.135452; batch adversarial loss: 0.360187\n",
      "epoch 77; iter: 0; batch classifier loss: 0.147481; batch adversarial loss: 0.520281\n",
      "epoch 78; iter: 0; batch classifier loss: 0.224726; batch adversarial loss: 0.457913\n",
      "epoch 79; iter: 0; batch classifier loss: 0.204723; batch adversarial loss: 0.409501\n",
      "epoch 80; iter: 0; batch classifier loss: 0.210065; batch adversarial loss: 0.520351\n",
      "epoch 81; iter: 0; batch classifier loss: 0.193242; batch adversarial loss: 0.445753\n",
      "epoch 82; iter: 0; batch classifier loss: 0.137688; batch adversarial loss: 0.398363\n",
      "epoch 83; iter: 0; batch classifier loss: 0.207598; batch adversarial loss: 0.446203\n",
      "epoch 84; iter: 0; batch classifier loss: 0.095340; batch adversarial loss: 0.434607\n",
      "epoch 85; iter: 0; batch classifier loss: 0.132290; batch adversarial loss: 0.556255\n",
      "epoch 86; iter: 0; batch classifier loss: 0.176914; batch adversarial loss: 0.543972\n",
      "epoch 87; iter: 0; batch classifier loss: 0.223863; batch adversarial loss: 0.385348\n",
      "epoch 88; iter: 0; batch classifier loss: 0.116420; batch adversarial loss: 0.543712\n",
      "epoch 89; iter: 0; batch classifier loss: 0.122035; batch adversarial loss: 0.434864\n",
      "epoch 90; iter: 0; batch classifier loss: 0.121667; batch adversarial loss: 0.447161\n",
      "epoch 91; iter: 0; batch classifier loss: 0.153305; batch adversarial loss: 0.409694\n",
      "epoch 92; iter: 0; batch classifier loss: 0.107407; batch adversarial loss: 0.547967\n",
      "epoch 93; iter: 0; batch classifier loss: 0.147211; batch adversarial loss: 0.594131\n",
      "epoch 94; iter: 0; batch classifier loss: 0.109694; batch adversarial loss: 0.431203\n",
      "epoch 95; iter: 0; batch classifier loss: 0.115682; batch adversarial loss: 0.462380\n",
      "epoch 96; iter: 0; batch classifier loss: 0.132504; batch adversarial loss: 0.461482\n",
      "epoch 97; iter: 0; batch classifier loss: 0.189362; batch adversarial loss: 0.396430\n",
      "epoch 98; iter: 0; batch classifier loss: 0.110199; batch adversarial loss: 0.493404\n",
      "epoch 99; iter: 0; batch classifier loss: 0.091044; batch adversarial loss: 0.511062\n",
      "epoch 100; iter: 0; batch classifier loss: 0.153152; batch adversarial loss: 0.407433\n",
      "epoch 101; iter: 0; batch classifier loss: 0.109076; batch adversarial loss: 0.524502\n",
      "epoch 102; iter: 0; batch classifier loss: 0.116066; batch adversarial loss: 0.495405\n",
      "epoch 103; iter: 0; batch classifier loss: 0.085653; batch adversarial loss: 0.576722\n",
      "epoch 104; iter: 0; batch classifier loss: 0.091070; batch adversarial loss: 0.530873\n",
      "epoch 105; iter: 0; batch classifier loss: 0.096585; batch adversarial loss: 0.465539\n",
      "epoch 106; iter: 0; batch classifier loss: 0.127149; batch adversarial loss: 0.576358\n",
      "epoch 107; iter: 0; batch classifier loss: 0.076916; batch adversarial loss: 0.475754\n",
      "epoch 108; iter: 0; batch classifier loss: 0.126301; batch adversarial loss: 0.453789\n",
      "epoch 109; iter: 0; batch classifier loss: 0.090997; batch adversarial loss: 0.491535\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036052; batch adversarial loss: 0.545649\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037010; batch adversarial loss: 0.585297\n",
      "epoch 112; iter: 0; batch classifier loss: 0.049278; batch adversarial loss: 0.478252\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049947; batch adversarial loss: 0.511948\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060187; batch adversarial loss: 0.405622\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046155; batch adversarial loss: 0.498500\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041150; batch adversarial loss: 0.422064\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037686; batch adversarial loss: 0.524364\n",
      "epoch 118; iter: 0; batch classifier loss: 0.019645; batch adversarial loss: 0.464396\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051448; batch adversarial loss: 0.485644\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055437; batch adversarial loss: 0.429630\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037344; batch adversarial loss: 0.468969\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028660; batch adversarial loss: 0.394429\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025885; batch adversarial loss: 0.521313\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027651; batch adversarial loss: 0.450870\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041058; batch adversarial loss: 0.360823\n",
      "epoch 126; iter: 0; batch classifier loss: 0.020740; batch adversarial loss: 0.499361\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050992; batch adversarial loss: 0.532522\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018288; batch adversarial loss: 0.540467\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034749; batch adversarial loss: 0.442690\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035473; batch adversarial loss: 0.549832\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020019; batch adversarial loss: 0.499595\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024254; batch adversarial loss: 0.385236\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041439; batch adversarial loss: 0.395156\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037291; batch adversarial loss: 0.502339\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030322; batch adversarial loss: 0.423985\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034913; batch adversarial loss: 0.493367\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027685; batch adversarial loss: 0.508496\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038906; batch adversarial loss: 0.449256\n",
      "epoch 139; iter: 0; batch classifier loss: 0.054164; batch adversarial loss: 0.601015\n",
      "epoch 140; iter: 0; batch classifier loss: 0.016136; batch adversarial loss: 0.407994\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026756; batch adversarial loss: 0.471389\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030230; batch adversarial loss: 0.471307\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019992; batch adversarial loss: 0.512218\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033111; batch adversarial loss: 0.437819\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042688; batch adversarial loss: 0.387776\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035156; batch adversarial loss: 0.422521\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015450; batch adversarial loss: 0.342800\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039461; batch adversarial loss: 0.535910\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030208; batch adversarial loss: 0.500018\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032223; batch adversarial loss: 0.412090\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030486; batch adversarial loss: 0.412847\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029996; batch adversarial loss: 0.454275\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026416; batch adversarial loss: 0.352664\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041489; batch adversarial loss: 0.413505\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020259; batch adversarial loss: 0.480191\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029621; batch adversarial loss: 0.444033\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015894; batch adversarial loss: 0.456081\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044246; batch adversarial loss: 0.403614\n",
      "epoch 159; iter: 0; batch classifier loss: 0.043373; batch adversarial loss: 0.427887\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019713; batch adversarial loss: 0.429266\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027290; batch adversarial loss: 0.529319\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017691; batch adversarial loss: 0.461331\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023302; batch adversarial loss: 0.393681\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021421; batch adversarial loss: 0.470677\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021020; batch adversarial loss: 0.412848\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010837; batch adversarial loss: 0.420351\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022644; batch adversarial loss: 0.409740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.032830; batch adversarial loss: 0.480599\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021376; batch adversarial loss: 0.481906\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010216; batch adversarial loss: 0.489186\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026901; batch adversarial loss: 0.541226\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025125; batch adversarial loss: 0.417244\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018179; batch adversarial loss: 0.371577\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013336; batch adversarial loss: 0.469110\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012984; batch adversarial loss: 0.407107\n",
      "epoch 176; iter: 0; batch classifier loss: 0.006559; batch adversarial loss: 0.508623\n",
      "epoch 177; iter: 0; batch classifier loss: 0.039730; batch adversarial loss: 0.497430\n",
      "epoch 178; iter: 0; batch classifier loss: 0.004056; batch adversarial loss: 0.452882\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028763; batch adversarial loss: 0.467525\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019499; batch adversarial loss: 0.512834\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020301; batch adversarial loss: 0.513301\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008507; batch adversarial loss: 0.395267\n",
      "epoch 183; iter: 0; batch classifier loss: 0.056529; batch adversarial loss: 0.475628\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026648; batch adversarial loss: 0.391763\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008027; batch adversarial loss: 0.389927\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029231; batch adversarial loss: 0.488785\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031718; batch adversarial loss: 0.444225\n",
      "epoch 188; iter: 0; batch classifier loss: 0.004492; batch adversarial loss: 0.481570\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013601; batch adversarial loss: 0.503043\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010199; batch adversarial loss: 0.443252\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010914; batch adversarial loss: 0.446006\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012552; batch adversarial loss: 0.457028\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032326; batch adversarial loss: 0.336361\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019358; batch adversarial loss: 0.397374\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026014; batch adversarial loss: 0.433915\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017431; batch adversarial loss: 0.551883\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024166; batch adversarial loss: 0.478428\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020915; batch adversarial loss: 0.504422\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007202; batch adversarial loss: 0.413675\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705815; batch adversarial loss: 0.550444\n",
      "epoch 1; iter: 0; batch classifier loss: 0.440365; batch adversarial loss: 0.585005\n",
      "epoch 2; iter: 0; batch classifier loss: 0.360203; batch adversarial loss: 0.619888\n",
      "epoch 3; iter: 0; batch classifier loss: 0.342647; batch adversarial loss: 0.585326\n",
      "epoch 4; iter: 0; batch classifier loss: 0.295363; batch adversarial loss: 0.562121\n",
      "epoch 5; iter: 0; batch classifier loss: 0.410681; batch adversarial loss: 0.534774\n",
      "epoch 6; iter: 0; batch classifier loss: 0.292998; batch adversarial loss: 0.526030\n",
      "epoch 7; iter: 0; batch classifier loss: 0.373026; batch adversarial loss: 0.575446\n",
      "epoch 8; iter: 0; batch classifier loss: 0.301701; batch adversarial loss: 0.586789\n",
      "epoch 9; iter: 0; batch classifier loss: 0.342260; batch adversarial loss: 0.544836\n",
      "epoch 10; iter: 0; batch classifier loss: 0.250495; batch adversarial loss: 0.554482\n",
      "epoch 11; iter: 0; batch classifier loss: 0.342388; batch adversarial loss: 0.587075\n",
      "epoch 12; iter: 0; batch classifier loss: 0.258350; batch adversarial loss: 0.410186\n",
      "epoch 13; iter: 0; batch classifier loss: 0.375660; batch adversarial loss: 0.509572\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487177; batch adversarial loss: 0.580689\n",
      "epoch 15; iter: 0; batch classifier loss: 0.483635; batch adversarial loss: 0.556861\n",
      "epoch 16; iter: 0; batch classifier loss: 0.429967; batch adversarial loss: 0.535792\n",
      "epoch 17; iter: 0; batch classifier loss: 0.564503; batch adversarial loss: 0.561558\n",
      "epoch 18; iter: 0; batch classifier loss: 0.254137; batch adversarial loss: 0.465939\n",
      "epoch 19; iter: 0; batch classifier loss: 0.297742; batch adversarial loss: 0.551499\n",
      "epoch 20; iter: 0; batch classifier loss: 0.218086; batch adversarial loss: 0.478706\n",
      "epoch 21; iter: 0; batch classifier loss: 0.226953; batch adversarial loss: 0.435474\n",
      "epoch 22; iter: 0; batch classifier loss: 0.192623; batch adversarial loss: 0.514144\n",
      "epoch 23; iter: 0; batch classifier loss: 0.214892; batch adversarial loss: 0.500036\n",
      "epoch 24; iter: 0; batch classifier loss: 0.260772; batch adversarial loss: 0.405224\n",
      "epoch 25; iter: 0; batch classifier loss: 0.143111; batch adversarial loss: 0.444917\n",
      "epoch 26; iter: 0; batch classifier loss: 0.121712; batch adversarial loss: 0.404388\n",
      "epoch 27; iter: 0; batch classifier loss: 0.147782; batch adversarial loss: 0.446140\n",
      "epoch 28; iter: 0; batch classifier loss: 0.175241; batch adversarial loss: 0.463272\n",
      "epoch 29; iter: 0; batch classifier loss: 0.171156; batch adversarial loss: 0.527267\n",
      "epoch 30; iter: 0; batch classifier loss: 0.141364; batch adversarial loss: 0.470009\n",
      "epoch 31; iter: 0; batch classifier loss: 0.145211; batch adversarial loss: 0.574442\n",
      "epoch 32; iter: 0; batch classifier loss: 0.168213; batch adversarial loss: 0.506914\n",
      "epoch 33; iter: 0; batch classifier loss: 0.099915; batch adversarial loss: 0.379548\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142706; batch adversarial loss: 0.428131\n",
      "epoch 35; iter: 0; batch classifier loss: 0.113453; batch adversarial loss: 0.490121\n",
      "epoch 36; iter: 0; batch classifier loss: 0.115502; batch adversarial loss: 0.471573\n",
      "epoch 37; iter: 0; batch classifier loss: 0.094215; batch adversarial loss: 0.507739\n",
      "epoch 38; iter: 0; batch classifier loss: 0.145472; batch adversarial loss: 0.409634\n",
      "epoch 39; iter: 0; batch classifier loss: 0.113902; batch adversarial loss: 0.449995\n",
      "epoch 40; iter: 0; batch classifier loss: 0.141416; batch adversarial loss: 0.395959\n",
      "epoch 41; iter: 0; batch classifier loss: 0.147818; batch adversarial loss: 0.447618\n",
      "epoch 42; iter: 0; batch classifier loss: 0.121216; batch adversarial loss: 0.416971\n",
      "epoch 43; iter: 0; batch classifier loss: 0.120356; batch adversarial loss: 0.409785\n",
      "epoch 44; iter: 0; batch classifier loss: 0.074569; batch adversarial loss: 0.412766\n",
      "epoch 45; iter: 0; batch classifier loss: 0.167490; batch adversarial loss: 0.450064\n",
      "epoch 46; iter: 0; batch classifier loss: 0.083985; batch adversarial loss: 0.461475\n",
      "epoch 47; iter: 0; batch classifier loss: 0.161909; batch adversarial loss: 0.364981\n",
      "epoch 48; iter: 0; batch classifier loss: 0.116743; batch adversarial loss: 0.472728\n",
      "epoch 49; iter: 0; batch classifier loss: 0.053763; batch adversarial loss: 0.509209\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098335; batch adversarial loss: 0.386260\n",
      "epoch 51; iter: 0; batch classifier loss: 0.134760; batch adversarial loss: 0.402282\n",
      "epoch 52; iter: 0; batch classifier loss: 0.116946; batch adversarial loss: 0.459384\n",
      "epoch 53; iter: 0; batch classifier loss: 0.130657; batch adversarial loss: 0.453553\n",
      "epoch 54; iter: 0; batch classifier loss: 0.117762; batch adversarial loss: 0.500475\n",
      "epoch 55; iter: 0; batch classifier loss: 0.062326; batch adversarial loss: 0.450467\n",
      "epoch 56; iter: 0; batch classifier loss: 0.143559; batch adversarial loss: 0.455406\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086663; batch adversarial loss: 0.479633\n",
      "epoch 58; iter: 0; batch classifier loss: 0.118547; batch adversarial loss: 0.537663\n",
      "epoch 59; iter: 0; batch classifier loss: 0.079969; batch adversarial loss: 0.423604\n",
      "epoch 60; iter: 0; batch classifier loss: 0.154397; batch adversarial loss: 0.428756\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074697; batch adversarial loss: 0.458046\n",
      "epoch 62; iter: 0; batch classifier loss: 0.098982; batch adversarial loss: 0.405796\n",
      "epoch 63; iter: 0; batch classifier loss: 0.094511; batch adversarial loss: 0.447195\n",
      "epoch 64; iter: 0; batch classifier loss: 0.101068; batch adversarial loss: 0.334683\n",
      "epoch 65; iter: 0; batch classifier loss: 0.091509; batch adversarial loss: 0.424810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.139150; batch adversarial loss: 0.410136\n",
      "epoch 67; iter: 0; batch classifier loss: 0.088496; batch adversarial loss: 0.521586\n",
      "epoch 68; iter: 0; batch classifier loss: 0.059452; batch adversarial loss: 0.419680\n",
      "epoch 69; iter: 0; batch classifier loss: 0.122923; batch adversarial loss: 0.566630\n",
      "epoch 70; iter: 0; batch classifier loss: 0.106918; batch adversarial loss: 0.459588\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078915; batch adversarial loss: 0.432690\n",
      "epoch 72; iter: 0; batch classifier loss: 0.089351; batch adversarial loss: 0.428241\n",
      "epoch 73; iter: 0; batch classifier loss: 0.104152; batch adversarial loss: 0.428577\n",
      "epoch 74; iter: 0; batch classifier loss: 0.059719; batch adversarial loss: 0.389904\n",
      "epoch 75; iter: 0; batch classifier loss: 0.124218; batch adversarial loss: 0.394526\n",
      "epoch 76; iter: 0; batch classifier loss: 0.052295; batch adversarial loss: 0.492063\n",
      "epoch 77; iter: 0; batch classifier loss: 0.042321; batch adversarial loss: 0.367219\n",
      "epoch 78; iter: 0; batch classifier loss: 0.083476; batch adversarial loss: 0.411370\n",
      "epoch 79; iter: 0; batch classifier loss: 0.093763; batch adversarial loss: 0.482136\n",
      "epoch 80; iter: 0; batch classifier loss: 0.085790; batch adversarial loss: 0.484932\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076021; batch adversarial loss: 0.359653\n",
      "epoch 82; iter: 0; batch classifier loss: 0.092321; batch adversarial loss: 0.391269\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079827; batch adversarial loss: 0.584293\n",
      "epoch 84; iter: 0; batch classifier loss: 0.077042; batch adversarial loss: 0.402618\n",
      "epoch 85; iter: 0; batch classifier loss: 0.103553; batch adversarial loss: 0.354465\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057216; batch adversarial loss: 0.584425\n",
      "epoch 87; iter: 0; batch classifier loss: 0.050181; batch adversarial loss: 0.433793\n",
      "epoch 88; iter: 0; batch classifier loss: 0.053570; batch adversarial loss: 0.513470\n",
      "epoch 89; iter: 0; batch classifier loss: 0.067436; batch adversarial loss: 0.403708\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066331; batch adversarial loss: 0.377685\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073317; batch adversarial loss: 0.393770\n",
      "epoch 92; iter: 0; batch classifier loss: 0.075375; batch adversarial loss: 0.447477\n",
      "epoch 93; iter: 0; batch classifier loss: 0.114077; batch adversarial loss: 0.469988\n",
      "epoch 94; iter: 0; batch classifier loss: 0.094773; batch adversarial loss: 0.458720\n",
      "epoch 95; iter: 0; batch classifier loss: 0.088000; batch adversarial loss: 0.558886\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036034; batch adversarial loss: 0.444415\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066167; batch adversarial loss: 0.513593\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063199; batch adversarial loss: 0.414643\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058070; batch adversarial loss: 0.493313\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061362; batch adversarial loss: 0.416971\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075683; batch adversarial loss: 0.408984\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066146; batch adversarial loss: 0.442573\n",
      "epoch 103; iter: 0; batch classifier loss: 0.069738; batch adversarial loss: 0.409609\n",
      "epoch 104; iter: 0; batch classifier loss: 0.084472; batch adversarial loss: 0.400656\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060649; batch adversarial loss: 0.455295\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046461; batch adversarial loss: 0.459656\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072510; batch adversarial loss: 0.549791\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051218; batch adversarial loss: 0.431956\n",
      "epoch 109; iter: 0; batch classifier loss: 0.074244; batch adversarial loss: 0.529671\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060224; batch adversarial loss: 0.446676\n",
      "epoch 111; iter: 0; batch classifier loss: 0.065926; batch adversarial loss: 0.484435\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037551; batch adversarial loss: 0.488127\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035953; batch adversarial loss: 0.436755\n",
      "epoch 114; iter: 0; batch classifier loss: 0.125662; batch adversarial loss: 0.423725\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050745; batch adversarial loss: 0.563703\n",
      "epoch 116; iter: 0; batch classifier loss: 0.073156; batch adversarial loss: 0.406098\n",
      "epoch 117; iter: 0; batch classifier loss: 0.070949; batch adversarial loss: 0.438031\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042647; batch adversarial loss: 0.413087\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042220; batch adversarial loss: 0.392049\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028967; batch adversarial loss: 0.477432\n",
      "epoch 121; iter: 0; batch classifier loss: 0.071133; batch adversarial loss: 0.335401\n",
      "epoch 122; iter: 0; batch classifier loss: 0.053383; batch adversarial loss: 0.503428\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039151; batch adversarial loss: 0.427962\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055720; batch adversarial loss: 0.397867\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068453; batch adversarial loss: 0.454231\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027243; batch adversarial loss: 0.502773\n",
      "epoch 127; iter: 0; batch classifier loss: 0.066876; batch adversarial loss: 0.437666\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036034; batch adversarial loss: 0.435238\n",
      "epoch 129; iter: 0; batch classifier loss: 0.049255; batch adversarial loss: 0.476632\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025058; batch adversarial loss: 0.387979\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035614; batch adversarial loss: 0.422177\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048905; batch adversarial loss: 0.422600\n",
      "epoch 133; iter: 0; batch classifier loss: 0.061533; batch adversarial loss: 0.491609\n",
      "epoch 134; iter: 0; batch classifier loss: 0.055611; batch adversarial loss: 0.495923\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026929; batch adversarial loss: 0.372703\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040185; batch adversarial loss: 0.367073\n",
      "epoch 137; iter: 0; batch classifier loss: 0.067260; batch adversarial loss: 0.459468\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020681; batch adversarial loss: 0.383224\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019616; batch adversarial loss: 0.470153\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032040; batch adversarial loss: 0.458500\n",
      "epoch 141; iter: 0; batch classifier loss: 0.059470; batch adversarial loss: 0.472850\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014213; batch adversarial loss: 0.499255\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037975; batch adversarial loss: 0.523411\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037444; batch adversarial loss: 0.512352\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039762; batch adversarial loss: 0.528117\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028586; batch adversarial loss: 0.546930\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017789; batch adversarial loss: 0.428412\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024049; batch adversarial loss: 0.481633\n",
      "epoch 149; iter: 0; batch classifier loss: 0.043837; batch adversarial loss: 0.401599\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027939; batch adversarial loss: 0.455495\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026898; batch adversarial loss: 0.395425\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010954; batch adversarial loss: 0.446603\n",
      "epoch 153; iter: 0; batch classifier loss: 0.057016; batch adversarial loss: 0.375687\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044757; batch adversarial loss: 0.397565\n",
      "epoch 155; iter: 0; batch classifier loss: 0.051648; batch adversarial loss: 0.468654\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038730; batch adversarial loss: 0.444127\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018003; batch adversarial loss: 0.484518\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020929; batch adversarial loss: 0.444769\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031534; batch adversarial loss: 0.500246\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027519; batch adversarial loss: 0.487258\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016623; batch adversarial loss: 0.476311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.020959; batch adversarial loss: 0.523206\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024170; batch adversarial loss: 0.441536\n",
      "epoch 164; iter: 0; batch classifier loss: 0.047668; batch adversarial loss: 0.477692\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029740; batch adversarial loss: 0.438479\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012520; batch adversarial loss: 0.493747\n",
      "epoch 167; iter: 0; batch classifier loss: 0.038040; batch adversarial loss: 0.411357\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018269; batch adversarial loss: 0.516252\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044578; batch adversarial loss: 0.457837\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027624; batch adversarial loss: 0.491866\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036402; batch adversarial loss: 0.510412\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011794; batch adversarial loss: 0.483984\n",
      "epoch 173; iter: 0; batch classifier loss: 0.039307; batch adversarial loss: 0.482631\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018883; batch adversarial loss: 0.348077\n",
      "epoch 175; iter: 0; batch classifier loss: 0.057395; batch adversarial loss: 0.480212\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022676; batch adversarial loss: 0.415379\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034801; batch adversarial loss: 0.390877\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033939; batch adversarial loss: 0.398446\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016752; batch adversarial loss: 0.387000\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022981; batch adversarial loss: 0.466382\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021894; batch adversarial loss: 0.437021\n",
      "epoch 182; iter: 0; batch classifier loss: 0.045792; batch adversarial loss: 0.420588\n",
      "epoch 183; iter: 0; batch classifier loss: 0.038220; batch adversarial loss: 0.404045\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016672; batch adversarial loss: 0.531174\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010851; batch adversarial loss: 0.613543\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022927; batch adversarial loss: 0.389249\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020912; batch adversarial loss: 0.386534\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014794; batch adversarial loss: 0.481093\n",
      "epoch 189; iter: 0; batch classifier loss: 0.054223; batch adversarial loss: 0.504352\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030354; batch adversarial loss: 0.382411\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018303; batch adversarial loss: 0.542813\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005529; batch adversarial loss: 0.508024\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028741; batch adversarial loss: 0.560953\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030030; batch adversarial loss: 0.355917\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017796; batch adversarial loss: 0.449365\n",
      "epoch 196; iter: 0; batch classifier loss: 0.049389; batch adversarial loss: 0.378915\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020978; batch adversarial loss: 0.444443\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030500; batch adversarial loss: 0.486398\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013322; batch adversarial loss: 0.502206\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695884; batch adversarial loss: 0.846210\n",
      "epoch 1; iter: 0; batch classifier loss: 0.579628; batch adversarial loss: 0.824541\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594100; batch adversarial loss: 0.797511\n",
      "epoch 3; iter: 0; batch classifier loss: 0.770468; batch adversarial loss: 0.748927\n",
      "epoch 4; iter: 0; batch classifier loss: 0.844853; batch adversarial loss: 0.683398\n",
      "epoch 5; iter: 0; batch classifier loss: 0.772016; batch adversarial loss: 0.629122\n",
      "epoch 6; iter: 0; batch classifier loss: 0.479513; batch adversarial loss: 0.574201\n",
      "epoch 7; iter: 0; batch classifier loss: 0.435043; batch adversarial loss: 0.555404\n",
      "epoch 8; iter: 0; batch classifier loss: 0.379564; batch adversarial loss: 0.561373\n",
      "epoch 9; iter: 0; batch classifier loss: 0.344670; batch adversarial loss: 0.523340\n",
      "epoch 10; iter: 0; batch classifier loss: 0.344030; batch adversarial loss: 0.586569\n",
      "epoch 11; iter: 0; batch classifier loss: 0.320246; batch adversarial loss: 0.553181\n",
      "epoch 12; iter: 0; batch classifier loss: 0.363997; batch adversarial loss: 0.554286\n",
      "epoch 13; iter: 0; batch classifier loss: 0.405308; batch adversarial loss: 0.544012\n",
      "epoch 14; iter: 0; batch classifier loss: 0.431533; batch adversarial loss: 0.491531\n",
      "epoch 15; iter: 0; batch classifier loss: 0.424399; batch adversarial loss: 0.512584\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387111; batch adversarial loss: 0.450668\n",
      "epoch 17; iter: 0; batch classifier loss: 0.451984; batch adversarial loss: 0.462463\n",
      "epoch 18; iter: 0; batch classifier loss: 0.363457; batch adversarial loss: 0.499353\n",
      "epoch 19; iter: 0; batch classifier loss: 0.303788; batch adversarial loss: 0.461188\n",
      "epoch 20; iter: 0; batch classifier loss: 0.320553; batch adversarial loss: 0.474534\n",
      "epoch 21; iter: 0; batch classifier loss: 0.350245; batch adversarial loss: 0.480837\n",
      "epoch 22; iter: 0; batch classifier loss: 0.388833; batch adversarial loss: 0.446045\n",
      "epoch 23; iter: 0; batch classifier loss: 0.372892; batch adversarial loss: 0.463501\n",
      "epoch 24; iter: 0; batch classifier loss: 0.353841; batch adversarial loss: 0.365121\n",
      "epoch 25; iter: 0; batch classifier loss: 0.309142; batch adversarial loss: 0.464854\n",
      "epoch 26; iter: 0; batch classifier loss: 0.336174; batch adversarial loss: 0.442219\n",
      "epoch 27; iter: 0; batch classifier loss: 0.337203; batch adversarial loss: 0.502571\n",
      "epoch 28; iter: 0; batch classifier loss: 0.336424; batch adversarial loss: 0.450175\n",
      "epoch 29; iter: 0; batch classifier loss: 0.339758; batch adversarial loss: 0.402190\n",
      "epoch 30; iter: 0; batch classifier loss: 0.327596; batch adversarial loss: 0.459429\n",
      "epoch 31; iter: 0; batch classifier loss: 0.292719; batch adversarial loss: 0.411680\n",
      "epoch 32; iter: 0; batch classifier loss: 0.245456; batch adversarial loss: 0.528493\n",
      "epoch 33; iter: 0; batch classifier loss: 0.170286; batch adversarial loss: 0.455251\n",
      "epoch 34; iter: 0; batch classifier loss: 0.239817; batch adversarial loss: 0.489268\n",
      "epoch 35; iter: 0; batch classifier loss: 0.228294; batch adversarial loss: 0.451976\n",
      "epoch 36; iter: 0; batch classifier loss: 0.263564; batch adversarial loss: 0.447558\n",
      "epoch 37; iter: 0; batch classifier loss: 0.258045; batch adversarial loss: 0.479429\n",
      "epoch 38; iter: 0; batch classifier loss: 0.204308; batch adversarial loss: 0.491480\n",
      "epoch 39; iter: 0; batch classifier loss: 0.280159; batch adversarial loss: 0.356638\n",
      "epoch 40; iter: 0; batch classifier loss: 0.223377; batch adversarial loss: 0.477269\n",
      "epoch 41; iter: 0; batch classifier loss: 0.186457; batch adversarial loss: 0.418604\n",
      "epoch 42; iter: 0; batch classifier loss: 0.192953; batch adversarial loss: 0.518129\n",
      "epoch 43; iter: 0; batch classifier loss: 0.183488; batch adversarial loss: 0.481151\n",
      "epoch 44; iter: 0; batch classifier loss: 0.203371; batch adversarial loss: 0.502758\n",
      "epoch 45; iter: 0; batch classifier loss: 0.119437; batch adversarial loss: 0.424780\n",
      "epoch 46; iter: 0; batch classifier loss: 0.156449; batch adversarial loss: 0.439861\n",
      "epoch 47; iter: 0; batch classifier loss: 0.138702; batch adversarial loss: 0.542078\n",
      "epoch 48; iter: 0; batch classifier loss: 0.195455; batch adversarial loss: 0.446690\n",
      "epoch 49; iter: 0; batch classifier loss: 0.144531; batch adversarial loss: 0.505581\n",
      "epoch 50; iter: 0; batch classifier loss: 0.260315; batch adversarial loss: 0.412955\n",
      "epoch 51; iter: 0; batch classifier loss: 0.206033; batch adversarial loss: 0.531754\n",
      "epoch 52; iter: 0; batch classifier loss: 0.227351; batch adversarial loss: 0.412751\n",
      "epoch 53; iter: 0; batch classifier loss: 0.201361; batch adversarial loss: 0.436584\n",
      "epoch 54; iter: 0; batch classifier loss: 0.156601; batch adversarial loss: 0.336347\n",
      "epoch 55; iter: 0; batch classifier loss: 0.178618; batch adversarial loss: 0.390983\n",
      "epoch 56; iter: 0; batch classifier loss: 0.163786; batch adversarial loss: 0.440514\n",
      "epoch 57; iter: 0; batch classifier loss: 0.159929; batch adversarial loss: 0.511030\n",
      "epoch 58; iter: 0; batch classifier loss: 0.151131; batch adversarial loss: 0.449558\n",
      "epoch 59; iter: 0; batch classifier loss: 0.170167; batch adversarial loss: 0.427833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.149010; batch adversarial loss: 0.514965\n",
      "epoch 61; iter: 0; batch classifier loss: 0.185751; batch adversarial loss: 0.485227\n",
      "epoch 62; iter: 0; batch classifier loss: 0.158623; batch adversarial loss: 0.310427\n",
      "epoch 63; iter: 0; batch classifier loss: 0.082154; batch adversarial loss: 0.490792\n",
      "epoch 64; iter: 0; batch classifier loss: 0.117652; batch adversarial loss: 0.500976\n",
      "epoch 65; iter: 0; batch classifier loss: 0.113436; batch adversarial loss: 0.402142\n",
      "epoch 66; iter: 0; batch classifier loss: 0.101865; batch adversarial loss: 0.480412\n",
      "epoch 67; iter: 0; batch classifier loss: 0.102587; batch adversarial loss: 0.379750\n",
      "epoch 68; iter: 0; batch classifier loss: 0.093943; batch adversarial loss: 0.455478\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103226; batch adversarial loss: 0.431448\n",
      "epoch 70; iter: 0; batch classifier loss: 0.045210; batch adversarial loss: 0.455756\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092890; batch adversarial loss: 0.495013\n",
      "epoch 72; iter: 0; batch classifier loss: 0.096547; batch adversarial loss: 0.501410\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084331; batch adversarial loss: 0.408975\n",
      "epoch 74; iter: 0; batch classifier loss: 0.141619; batch adversarial loss: 0.404527\n",
      "epoch 75; iter: 0; batch classifier loss: 0.082009; batch adversarial loss: 0.510025\n",
      "epoch 76; iter: 0; batch classifier loss: 0.115541; batch adversarial loss: 0.476154\n",
      "epoch 77; iter: 0; batch classifier loss: 0.107046; batch adversarial loss: 0.438589\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085858; batch adversarial loss: 0.417547\n",
      "epoch 79; iter: 0; batch classifier loss: 0.091086; batch adversarial loss: 0.417946\n",
      "epoch 80; iter: 0; batch classifier loss: 0.092843; batch adversarial loss: 0.535948\n",
      "epoch 81; iter: 0; batch classifier loss: 0.038987; batch adversarial loss: 0.425881\n",
      "epoch 82; iter: 0; batch classifier loss: 0.042557; batch adversarial loss: 0.417966\n",
      "epoch 83; iter: 0; batch classifier loss: 0.082256; batch adversarial loss: 0.496936\n",
      "epoch 84; iter: 0; batch classifier loss: 0.047397; batch adversarial loss: 0.360524\n",
      "epoch 85; iter: 0; batch classifier loss: 0.037394; batch adversarial loss: 0.510971\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054222; batch adversarial loss: 0.438111\n",
      "epoch 87; iter: 0; batch classifier loss: 0.064472; batch adversarial loss: 0.480669\n",
      "epoch 88; iter: 0; batch classifier loss: 0.045834; batch adversarial loss: 0.363194\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098701; batch adversarial loss: 0.381583\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054461; batch adversarial loss: 0.501912\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077846; batch adversarial loss: 0.336596\n",
      "epoch 92; iter: 0; batch classifier loss: 0.031104; batch adversarial loss: 0.406008\n",
      "epoch 93; iter: 0; batch classifier loss: 0.028279; batch adversarial loss: 0.479809\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038865; batch adversarial loss: 0.454876\n",
      "epoch 95; iter: 0; batch classifier loss: 0.034495; batch adversarial loss: 0.399908\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044833; batch adversarial loss: 0.454570\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039256; batch adversarial loss: 0.478915\n",
      "epoch 98; iter: 0; batch classifier loss: 0.032122; batch adversarial loss: 0.355600\n",
      "epoch 99; iter: 0; batch classifier loss: 0.097127; batch adversarial loss: 0.463640\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046364; batch adversarial loss: 0.459261\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057947; batch adversarial loss: 0.458378\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068705; batch adversarial loss: 0.401960\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064436; batch adversarial loss: 0.436707\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057344; batch adversarial loss: 0.383537\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030572; batch adversarial loss: 0.418559\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046100; batch adversarial loss: 0.398914\n",
      "epoch 107; iter: 0; batch classifier loss: 0.043613; batch adversarial loss: 0.449303\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042177; batch adversarial loss: 0.519184\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037430; batch adversarial loss: 0.521800\n",
      "epoch 110; iter: 0; batch classifier loss: 0.015165; batch adversarial loss: 0.540974\n",
      "epoch 111; iter: 0; batch classifier loss: 0.021019; batch adversarial loss: 0.477874\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027241; batch adversarial loss: 0.423185\n",
      "epoch 113; iter: 0; batch classifier loss: 0.024926; batch adversarial loss: 0.482058\n",
      "epoch 114; iter: 0; batch classifier loss: 0.018172; batch adversarial loss: 0.400294\n",
      "epoch 115; iter: 0; batch classifier loss: 0.015749; batch adversarial loss: 0.432931\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044148; batch adversarial loss: 0.452368\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030637; batch adversarial loss: 0.576285\n",
      "epoch 118; iter: 0; batch classifier loss: 0.019535; batch adversarial loss: 0.422709\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035366; batch adversarial loss: 0.435844\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032913; batch adversarial loss: 0.461337\n",
      "epoch 121; iter: 0; batch classifier loss: 0.016531; batch adversarial loss: 0.461723\n",
      "epoch 122; iter: 0; batch classifier loss: 0.020025; batch adversarial loss: 0.512024\n",
      "epoch 123; iter: 0; batch classifier loss: 0.010492; batch adversarial loss: 0.466709\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030461; batch adversarial loss: 0.521708\n",
      "epoch 125; iter: 0; batch classifier loss: 0.006955; batch adversarial loss: 0.400920\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021198; batch adversarial loss: 0.377285\n",
      "epoch 127; iter: 0; batch classifier loss: 0.017371; batch adversarial loss: 0.437510\n",
      "epoch 128; iter: 0; batch classifier loss: 0.013295; batch adversarial loss: 0.552406\n",
      "epoch 129; iter: 0; batch classifier loss: 0.014652; batch adversarial loss: 0.419477\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018784; batch adversarial loss: 0.533244\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036929; batch adversarial loss: 0.427530\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015639; batch adversarial loss: 0.358147\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035577; batch adversarial loss: 0.483227\n",
      "epoch 134; iter: 0; batch classifier loss: 0.056422; batch adversarial loss: 0.385590\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012204; batch adversarial loss: 0.389203\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017302; batch adversarial loss: 0.435229\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020617; batch adversarial loss: 0.413337\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040920; batch adversarial loss: 0.392185\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022032; batch adversarial loss: 0.401654\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013256; batch adversarial loss: 0.430606\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016097; batch adversarial loss: 0.393284\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017303; batch adversarial loss: 0.379438\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011701; batch adversarial loss: 0.457042\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024510; batch adversarial loss: 0.394621\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017017; batch adversarial loss: 0.473632\n",
      "epoch 146; iter: 0; batch classifier loss: 0.012007; batch adversarial loss: 0.563395\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035689; batch adversarial loss: 0.446544\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038878; batch adversarial loss: 0.401971\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013704; batch adversarial loss: 0.401674\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014057; batch adversarial loss: 0.326375\n",
      "epoch 151; iter: 0; batch classifier loss: 0.002975; batch adversarial loss: 0.461176\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034056; batch adversarial loss: 0.398945\n",
      "epoch 153; iter: 0; batch classifier loss: 0.007240; batch adversarial loss: 0.551472\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016043; batch adversarial loss: 0.451660\n",
      "epoch 155; iter: 0; batch classifier loss: 0.004266; batch adversarial loss: 0.429441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.008392; batch adversarial loss: 0.414327\n",
      "epoch 157; iter: 0; batch classifier loss: 0.007739; batch adversarial loss: 0.369157\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013235; batch adversarial loss: 0.439987\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027953; batch adversarial loss: 0.371260\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010610; batch adversarial loss: 0.352178\n",
      "epoch 161; iter: 0; batch classifier loss: 0.048743; batch adversarial loss: 0.450906\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013820; batch adversarial loss: 0.550658\n",
      "epoch 163; iter: 0; batch classifier loss: 0.003795; batch adversarial loss: 0.363840\n",
      "epoch 164; iter: 0; batch classifier loss: 0.053481; batch adversarial loss: 0.411751\n",
      "epoch 165; iter: 0; batch classifier loss: 0.049822; batch adversarial loss: 0.373027\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017895; batch adversarial loss: 0.410509\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028466; batch adversarial loss: 0.531651\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009028; batch adversarial loss: 0.495250\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034417; batch adversarial loss: 0.352267\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023399; batch adversarial loss: 0.431483\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013840; batch adversarial loss: 0.483889\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020446; batch adversarial loss: 0.394741\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031499; batch adversarial loss: 0.472823\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008816; batch adversarial loss: 0.447719\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007319; batch adversarial loss: 0.441161\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014723; batch adversarial loss: 0.417925\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010078; batch adversarial loss: 0.435037\n",
      "epoch 178; iter: 0; batch classifier loss: 0.041324; batch adversarial loss: 0.388217\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017993; batch adversarial loss: 0.471196\n",
      "epoch 180; iter: 0; batch classifier loss: 0.004664; batch adversarial loss: 0.477401\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006432; batch adversarial loss: 0.396670\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009286; batch adversarial loss: 0.404961\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009445; batch adversarial loss: 0.529815\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023726; batch adversarial loss: 0.350522\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011803; batch adversarial loss: 0.409434\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008442; batch adversarial loss: 0.453939\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018089; batch adversarial loss: 0.448787\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015735; batch adversarial loss: 0.451466\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009695; batch adversarial loss: 0.499593\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010704; batch adversarial loss: 0.508277\n",
      "epoch 191; iter: 0; batch classifier loss: 0.004647; batch adversarial loss: 0.484923\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033916; batch adversarial loss: 0.354844\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004226; batch adversarial loss: 0.473937\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004139; batch adversarial loss: 0.416968\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015111; batch adversarial loss: 0.498824\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005847; batch adversarial loss: 0.408203\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007601; batch adversarial loss: 0.442489\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006207; batch adversarial loss: 0.352521\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020841; batch adversarial loss: 0.461580\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704721; batch adversarial loss: 0.877318\n",
      "epoch 1; iter: 0; batch classifier loss: 0.457846; batch adversarial loss: 0.807919\n",
      "epoch 2; iter: 0; batch classifier loss: 0.372082; batch adversarial loss: 0.775172\n",
      "epoch 3; iter: 0; batch classifier loss: 0.302396; batch adversarial loss: 0.735894\n",
      "epoch 4; iter: 0; batch classifier loss: 0.378244; batch adversarial loss: 0.673405\n",
      "epoch 5; iter: 0; batch classifier loss: 0.421559; batch adversarial loss: 0.664204\n",
      "epoch 6; iter: 0; batch classifier loss: 0.369960; batch adversarial loss: 0.625134\n",
      "epoch 7; iter: 0; batch classifier loss: 0.354103; batch adversarial loss: 0.590791\n",
      "epoch 8; iter: 0; batch classifier loss: 0.304281; batch adversarial loss: 0.612291\n",
      "epoch 9; iter: 0; batch classifier loss: 0.278359; batch adversarial loss: 0.536481\n",
      "epoch 10; iter: 0; batch classifier loss: 0.283909; batch adversarial loss: 0.554804\n",
      "epoch 11; iter: 0; batch classifier loss: 0.306453; batch adversarial loss: 0.520517\n",
      "epoch 12; iter: 0; batch classifier loss: 0.226080; batch adversarial loss: 0.535100\n",
      "epoch 13; iter: 0; batch classifier loss: 0.239492; batch adversarial loss: 0.507780\n",
      "epoch 14; iter: 0; batch classifier loss: 0.319450; batch adversarial loss: 0.486719\n",
      "epoch 15; iter: 0; batch classifier loss: 0.213113; batch adversarial loss: 0.539559\n",
      "epoch 16; iter: 0; batch classifier loss: 0.218778; batch adversarial loss: 0.474915\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241769; batch adversarial loss: 0.462839\n",
      "epoch 18; iter: 0; batch classifier loss: 0.273899; batch adversarial loss: 0.488871\n",
      "epoch 19; iter: 0; batch classifier loss: 0.230972; batch adversarial loss: 0.406128\n",
      "epoch 20; iter: 0; batch classifier loss: 0.192381; batch adversarial loss: 0.328731\n",
      "epoch 21; iter: 0; batch classifier loss: 0.231611; batch adversarial loss: 0.422236\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206331; batch adversarial loss: 0.399706\n",
      "epoch 23; iter: 0; batch classifier loss: 0.279952; batch adversarial loss: 0.455362\n",
      "epoch 24; iter: 0; batch classifier loss: 0.215907; batch adversarial loss: 0.474586\n",
      "epoch 25; iter: 0; batch classifier loss: 0.306149; batch adversarial loss: 0.434346\n",
      "epoch 26; iter: 0; batch classifier loss: 0.264729; batch adversarial loss: 0.513709\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181508; batch adversarial loss: 0.452097\n",
      "epoch 28; iter: 0; batch classifier loss: 0.179449; batch adversarial loss: 0.429585\n",
      "epoch 29; iter: 0; batch classifier loss: 0.177279; batch adversarial loss: 0.375618\n",
      "epoch 30; iter: 0; batch classifier loss: 0.208083; batch adversarial loss: 0.408637\n",
      "epoch 31; iter: 0; batch classifier loss: 0.158330; batch adversarial loss: 0.348640\n",
      "epoch 32; iter: 0; batch classifier loss: 0.124269; batch adversarial loss: 0.351132\n",
      "epoch 33; iter: 0; batch classifier loss: 0.146241; batch adversarial loss: 0.401031\n",
      "epoch 34; iter: 0; batch classifier loss: 0.161444; batch adversarial loss: 0.323891\n",
      "epoch 35; iter: 0; batch classifier loss: 0.139350; batch adversarial loss: 0.367741\n",
      "epoch 36; iter: 0; batch classifier loss: 0.174422; batch adversarial loss: 0.366197\n",
      "epoch 37; iter: 0; batch classifier loss: 0.190851; batch adversarial loss: 0.443509\n",
      "epoch 38; iter: 0; batch classifier loss: 0.175428; batch adversarial loss: 0.451337\n",
      "epoch 39; iter: 0; batch classifier loss: 0.152853; batch adversarial loss: 0.392000\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154129; batch adversarial loss: 0.418078\n",
      "epoch 41; iter: 0; batch classifier loss: 0.130978; batch adversarial loss: 0.423186\n",
      "epoch 42; iter: 0; batch classifier loss: 0.091285; batch adversarial loss: 0.350259\n",
      "epoch 43; iter: 0; batch classifier loss: 0.159231; batch adversarial loss: 0.476689\n",
      "epoch 44; iter: 0; batch classifier loss: 0.139651; batch adversarial loss: 0.361740\n",
      "epoch 45; iter: 0; batch classifier loss: 0.093201; batch adversarial loss: 0.425105\n",
      "epoch 46; iter: 0; batch classifier loss: 0.093110; batch adversarial loss: 0.535842\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112837; batch adversarial loss: 0.340766\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082336; batch adversarial loss: 0.400327\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098648; batch adversarial loss: 0.391659\n",
      "epoch 50; iter: 0; batch classifier loss: 0.084373; batch adversarial loss: 0.406370\n",
      "epoch 51; iter: 0; batch classifier loss: 0.115766; batch adversarial loss: 0.421389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.076512; batch adversarial loss: 0.425461\n",
      "epoch 53; iter: 0; batch classifier loss: 0.078545; batch adversarial loss: 0.450373\n",
      "epoch 54; iter: 0; batch classifier loss: 0.097089; batch adversarial loss: 0.462865\n",
      "epoch 55; iter: 0; batch classifier loss: 0.105697; batch adversarial loss: 0.422851\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099183; batch adversarial loss: 0.453422\n",
      "epoch 57; iter: 0; batch classifier loss: 0.077881; batch adversarial loss: 0.465576\n",
      "epoch 58; iter: 0; batch classifier loss: 0.076532; batch adversarial loss: 0.452205\n",
      "epoch 59; iter: 0; batch classifier loss: 0.089747; batch adversarial loss: 0.392761\n",
      "epoch 60; iter: 0; batch classifier loss: 0.113776; batch adversarial loss: 0.445322\n",
      "epoch 61; iter: 0; batch classifier loss: 0.046219; batch adversarial loss: 0.377177\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085575; batch adversarial loss: 0.388140\n",
      "epoch 63; iter: 0; batch classifier loss: 0.096637; batch adversarial loss: 0.429917\n",
      "epoch 64; iter: 0; batch classifier loss: 0.049209; batch adversarial loss: 0.418597\n",
      "epoch 65; iter: 0; batch classifier loss: 0.056381; batch adversarial loss: 0.442805\n",
      "epoch 66; iter: 0; batch classifier loss: 0.111829; batch adversarial loss: 0.545936\n",
      "epoch 67; iter: 0; batch classifier loss: 0.114819; batch adversarial loss: 0.358696\n",
      "epoch 68; iter: 0; batch classifier loss: 0.093316; batch adversarial loss: 0.416913\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102656; batch adversarial loss: 0.406867\n",
      "epoch 70; iter: 0; batch classifier loss: 0.073077; batch adversarial loss: 0.382286\n",
      "epoch 71; iter: 0; batch classifier loss: 0.128018; batch adversarial loss: 0.402565\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080319; batch adversarial loss: 0.473756\n",
      "epoch 73; iter: 0; batch classifier loss: 0.095974; batch adversarial loss: 0.367590\n",
      "epoch 74; iter: 0; batch classifier loss: 0.094712; batch adversarial loss: 0.410450\n",
      "epoch 75; iter: 0; batch classifier loss: 0.062051; batch adversarial loss: 0.361087\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072436; batch adversarial loss: 0.427803\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069164; batch adversarial loss: 0.437649\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080739; batch adversarial loss: 0.454868\n",
      "epoch 79; iter: 0; batch classifier loss: 0.091844; batch adversarial loss: 0.407293\n",
      "epoch 80; iter: 0; batch classifier loss: 0.080955; batch adversarial loss: 0.479799\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068025; batch adversarial loss: 0.424872\n",
      "epoch 82; iter: 0; batch classifier loss: 0.076161; batch adversarial loss: 0.450856\n",
      "epoch 83; iter: 0; batch classifier loss: 0.051248; batch adversarial loss: 0.437198\n",
      "epoch 84; iter: 0; batch classifier loss: 0.076276; batch adversarial loss: 0.460609\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075274; batch adversarial loss: 0.472071\n",
      "epoch 86; iter: 0; batch classifier loss: 0.078988; batch adversarial loss: 0.403688\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073657; batch adversarial loss: 0.416672\n",
      "epoch 88; iter: 0; batch classifier loss: 0.052615; batch adversarial loss: 0.415892\n",
      "epoch 89; iter: 0; batch classifier loss: 0.096682; batch adversarial loss: 0.374994\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048042; batch adversarial loss: 0.396039\n",
      "epoch 91; iter: 0; batch classifier loss: 0.081932; batch adversarial loss: 0.396048\n",
      "epoch 92; iter: 0; batch classifier loss: 0.115030; batch adversarial loss: 0.394061\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046776; batch adversarial loss: 0.414389\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066305; batch adversarial loss: 0.434956\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068601; batch adversarial loss: 0.410657\n",
      "epoch 96; iter: 0; batch classifier loss: 0.038550; batch adversarial loss: 0.372505\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069552; batch adversarial loss: 0.395496\n",
      "epoch 98; iter: 0; batch classifier loss: 0.057187; batch adversarial loss: 0.436462\n",
      "epoch 99; iter: 0; batch classifier loss: 0.114981; batch adversarial loss: 0.361426\n",
      "epoch 100; iter: 0; batch classifier loss: 0.081693; batch adversarial loss: 0.392886\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049741; batch adversarial loss: 0.359680\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044868; batch adversarial loss: 0.455808\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038108; batch adversarial loss: 0.461174\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066597; batch adversarial loss: 0.444691\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053301; batch adversarial loss: 0.428467\n",
      "epoch 106; iter: 0; batch classifier loss: 0.065356; batch adversarial loss: 0.437320\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051786; batch adversarial loss: 0.437117\n",
      "epoch 108; iter: 0; batch classifier loss: 0.073652; batch adversarial loss: 0.358244\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057771; batch adversarial loss: 0.419834\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047322; batch adversarial loss: 0.395861\n",
      "epoch 111; iter: 0; batch classifier loss: 0.076001; batch adversarial loss: 0.365129\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075132; batch adversarial loss: 0.510253\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042560; batch adversarial loss: 0.605004\n",
      "epoch 114; iter: 0; batch classifier loss: 0.072897; batch adversarial loss: 0.466591\n",
      "epoch 115; iter: 0; batch classifier loss: 0.079589; batch adversarial loss: 0.502535\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042080; batch adversarial loss: 0.348487\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061130; batch adversarial loss: 0.326570\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059081; batch adversarial loss: 0.429674\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043394; batch adversarial loss: 0.379876\n",
      "epoch 120; iter: 0; batch classifier loss: 0.083594; batch adversarial loss: 0.360396\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054100; batch adversarial loss: 0.435758\n",
      "epoch 122; iter: 0; batch classifier loss: 0.072127; batch adversarial loss: 0.435083\n",
      "epoch 123; iter: 0; batch classifier loss: 0.066703; batch adversarial loss: 0.326902\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031569; batch adversarial loss: 0.421273\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045636; batch adversarial loss: 0.434996\n",
      "epoch 126; iter: 0; batch classifier loss: 0.058113; batch adversarial loss: 0.423063\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039836; batch adversarial loss: 0.411424\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043662; batch adversarial loss: 0.478830\n",
      "epoch 129; iter: 0; batch classifier loss: 0.074438; batch adversarial loss: 0.401726\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035114; batch adversarial loss: 0.506147\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049872; batch adversarial loss: 0.373972\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026970; batch adversarial loss: 0.423464\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046396; batch adversarial loss: 0.573354\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037180; batch adversarial loss: 0.364884\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033482; batch adversarial loss: 0.403045\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027204; batch adversarial loss: 0.466551\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039661; batch adversarial loss: 0.363629\n",
      "epoch 138; iter: 0; batch classifier loss: 0.063132; batch adversarial loss: 0.374800\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016349; batch adversarial loss: 0.438959\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028040; batch adversarial loss: 0.516427\n",
      "epoch 141; iter: 0; batch classifier loss: 0.060595; batch adversarial loss: 0.480091\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025613; batch adversarial loss: 0.395154\n",
      "epoch 143; iter: 0; batch classifier loss: 0.080390; batch adversarial loss: 0.475135\n",
      "epoch 144; iter: 0; batch classifier loss: 0.066453; batch adversarial loss: 0.354747\n",
      "epoch 145; iter: 0; batch classifier loss: 0.049578; batch adversarial loss: 0.469436\n",
      "epoch 146; iter: 0; batch classifier loss: 0.053468; batch adversarial loss: 0.486638\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028520; batch adversarial loss: 0.368499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.033717; batch adversarial loss: 0.365462\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030278; batch adversarial loss: 0.451320\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030872; batch adversarial loss: 0.383079\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027049; batch adversarial loss: 0.482531\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026686; batch adversarial loss: 0.387254\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031250; batch adversarial loss: 0.413048\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034943; batch adversarial loss: 0.484548\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022208; batch adversarial loss: 0.456756\n",
      "epoch 156; iter: 0; batch classifier loss: 0.048161; batch adversarial loss: 0.665623\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013464; batch adversarial loss: 0.396502\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011838; batch adversarial loss: 0.433512\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022057; batch adversarial loss: 0.474172\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018773; batch adversarial loss: 0.480492\n",
      "epoch 161; iter: 0; batch classifier loss: 0.055270; batch adversarial loss: 0.565880\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039570; batch adversarial loss: 0.504693\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034933; batch adversarial loss: 0.512548\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037688; batch adversarial loss: 0.536591\n",
      "epoch 165; iter: 0; batch classifier loss: 0.042623; batch adversarial loss: 0.544660\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045431; batch adversarial loss: 0.506760\n",
      "epoch 167; iter: 0; batch classifier loss: 0.067310; batch adversarial loss: 0.425206\n",
      "epoch 168; iter: 0; batch classifier loss: 0.148223; batch adversarial loss: 0.739274\n",
      "epoch 169; iter: 0; batch classifier loss: 0.090059; batch adversarial loss: 0.612581\n",
      "epoch 170; iter: 0; batch classifier loss: 0.085773; batch adversarial loss: 0.643320\n",
      "epoch 171; iter: 0; batch classifier loss: 0.240343; batch adversarial loss: 0.771411\n",
      "epoch 172; iter: 0; batch classifier loss: 0.091248; batch adversarial loss: 0.638345\n",
      "epoch 173; iter: 0; batch classifier loss: 0.135406; batch adversarial loss: 0.684646\n",
      "epoch 174; iter: 0; batch classifier loss: 0.214859; batch adversarial loss: 0.861936\n",
      "epoch 175; iter: 0; batch classifier loss: 0.117656; batch adversarial loss: 0.655760\n",
      "epoch 176; iter: 0; batch classifier loss: 0.101228; batch adversarial loss: 0.652869\n",
      "epoch 177; iter: 0; batch classifier loss: 0.173908; batch adversarial loss: 0.633942\n",
      "epoch 178; iter: 0; batch classifier loss: 0.272476; batch adversarial loss: 0.981071\n",
      "epoch 179; iter: 0; batch classifier loss: 0.109053; batch adversarial loss: 0.661386\n",
      "epoch 180; iter: 0; batch classifier loss: 0.164473; batch adversarial loss: 0.696094\n",
      "epoch 181; iter: 0; batch classifier loss: 0.165244; batch adversarial loss: 0.613712\n",
      "epoch 182; iter: 0; batch classifier loss: 0.161034; batch adversarial loss: 0.621568\n",
      "epoch 183; iter: 0; batch classifier loss: 0.130695; batch adversarial loss: 0.574964\n",
      "epoch 184; iter: 0; batch classifier loss: 0.155021; batch adversarial loss: 0.597659\n",
      "epoch 185; iter: 0; batch classifier loss: 0.247133; batch adversarial loss: 0.734780\n",
      "epoch 186; iter: 0; batch classifier loss: 0.183802; batch adversarial loss: 0.757614\n",
      "epoch 187; iter: 0; batch classifier loss: 0.229304; batch adversarial loss: 0.703660\n",
      "epoch 188; iter: 0; batch classifier loss: 0.227736; batch adversarial loss: 0.688450\n",
      "epoch 189; iter: 0; batch classifier loss: 0.247334; batch adversarial loss: 0.759349\n",
      "epoch 190; iter: 0; batch classifier loss: 0.112457; batch adversarial loss: 0.530958\n",
      "epoch 191; iter: 0; batch classifier loss: 0.105560; batch adversarial loss: 0.553667\n",
      "epoch 192; iter: 0; batch classifier loss: 0.200711; batch adversarial loss: 0.692645\n",
      "epoch 193; iter: 0; batch classifier loss: 0.094492; batch adversarial loss: 0.471041\n",
      "epoch 194; iter: 0; batch classifier loss: 0.189918; batch adversarial loss: 0.598329\n",
      "epoch 195; iter: 0; batch classifier loss: 0.175419; batch adversarial loss: 0.643638\n",
      "epoch 196; iter: 0; batch classifier loss: 0.182024; batch adversarial loss: 0.542750\n",
      "epoch 197; iter: 0; batch classifier loss: 0.145282; batch adversarial loss: 0.537585\n",
      "epoch 198; iter: 0; batch classifier loss: 0.145528; batch adversarial loss: 0.565268\n",
      "epoch 199; iter: 0; batch classifier loss: 0.184078; batch adversarial loss: 0.642641\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704515; batch adversarial loss: 0.842920\n",
      "epoch 1; iter: 0; batch classifier loss: 0.521516; batch adversarial loss: 0.831563\n",
      "epoch 2; iter: 0; batch classifier loss: 0.681356; batch adversarial loss: 0.810940\n",
      "epoch 3; iter: 0; batch classifier loss: 0.820984; batch adversarial loss: 0.759662\n",
      "epoch 4; iter: 0; batch classifier loss: 0.859405; batch adversarial loss: 0.672461\n",
      "epoch 5; iter: 0; batch classifier loss: 0.760387; batch adversarial loss: 0.642580\n",
      "epoch 6; iter: 0; batch classifier loss: 0.451212; batch adversarial loss: 0.573989\n",
      "epoch 7; iter: 0; batch classifier loss: 0.441926; batch adversarial loss: 0.576595\n",
      "epoch 8; iter: 0; batch classifier loss: 0.400546; batch adversarial loss: 0.550423\n",
      "epoch 9; iter: 0; batch classifier loss: 0.371324; batch adversarial loss: 0.556257\n",
      "epoch 10; iter: 0; batch classifier loss: 0.369175; batch adversarial loss: 0.541857\n",
      "epoch 11; iter: 0; batch classifier loss: 0.375411; batch adversarial loss: 0.548546\n",
      "epoch 12; iter: 0; batch classifier loss: 0.346023; batch adversarial loss: 0.518578\n",
      "epoch 13; iter: 0; batch classifier loss: 0.307601; batch adversarial loss: 0.501304\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263698; batch adversarial loss: 0.536597\n",
      "epoch 15; iter: 0; batch classifier loss: 0.285425; batch adversarial loss: 0.463752\n",
      "epoch 16; iter: 0; batch classifier loss: 0.327254; batch adversarial loss: 0.505051\n",
      "epoch 17; iter: 0; batch classifier loss: 0.306161; batch adversarial loss: 0.558157\n",
      "epoch 18; iter: 0; batch classifier loss: 0.310192; batch adversarial loss: 0.435944\n",
      "epoch 19; iter: 0; batch classifier loss: 0.341015; batch adversarial loss: 0.442310\n",
      "epoch 20; iter: 0; batch classifier loss: 0.261507; batch adversarial loss: 0.450127\n",
      "epoch 21; iter: 0; batch classifier loss: 0.294226; batch adversarial loss: 0.413308\n",
      "epoch 22; iter: 0; batch classifier loss: 0.262462; batch adversarial loss: 0.518811\n",
      "epoch 23; iter: 0; batch classifier loss: 0.259270; batch adversarial loss: 0.460309\n",
      "epoch 24; iter: 0; batch classifier loss: 0.201735; batch adversarial loss: 0.564555\n",
      "epoch 25; iter: 0; batch classifier loss: 0.253841; batch adversarial loss: 0.388741\n",
      "epoch 26; iter: 0; batch classifier loss: 0.338007; batch adversarial loss: 0.454326\n",
      "epoch 27; iter: 0; batch classifier loss: 0.308837; batch adversarial loss: 0.479892\n",
      "epoch 28; iter: 0; batch classifier loss: 0.367501; batch adversarial loss: 0.436333\n",
      "epoch 29; iter: 0; batch classifier loss: 0.295262; batch adversarial loss: 0.484257\n",
      "epoch 30; iter: 0; batch classifier loss: 0.340348; batch adversarial loss: 0.375153\n",
      "epoch 31; iter: 0; batch classifier loss: 0.215799; batch adversarial loss: 0.517161\n",
      "epoch 32; iter: 0; batch classifier loss: 0.259213; batch adversarial loss: 0.456951\n",
      "epoch 33; iter: 0; batch classifier loss: 0.239542; batch adversarial loss: 0.418840\n",
      "epoch 34; iter: 0; batch classifier loss: 0.247542; batch adversarial loss: 0.481682\n",
      "epoch 35; iter: 0; batch classifier loss: 0.229908; batch adversarial loss: 0.465874\n",
      "epoch 36; iter: 0; batch classifier loss: 0.204995; batch adversarial loss: 0.530527\n",
      "epoch 37; iter: 0; batch classifier loss: 0.272378; batch adversarial loss: 0.412917\n",
      "epoch 38; iter: 0; batch classifier loss: 0.265286; batch adversarial loss: 0.381607\n",
      "epoch 39; iter: 0; batch classifier loss: 0.172924; batch adversarial loss: 0.487092\n",
      "epoch 40; iter: 0; batch classifier loss: 0.210393; batch adversarial loss: 0.462803\n",
      "epoch 41; iter: 0; batch classifier loss: 0.262644; batch adversarial loss: 0.433218\n",
      "epoch 42; iter: 0; batch classifier loss: 0.243217; batch adversarial loss: 0.403696\n",
      "epoch 43; iter: 0; batch classifier loss: 0.194924; batch adversarial loss: 0.407204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.216000; batch adversarial loss: 0.431617\n",
      "epoch 45; iter: 0; batch classifier loss: 0.185569; batch adversarial loss: 0.430118\n",
      "epoch 46; iter: 0; batch classifier loss: 0.192584; batch adversarial loss: 0.445862\n",
      "epoch 47; iter: 0; batch classifier loss: 0.169838; batch adversarial loss: 0.414438\n",
      "epoch 48; iter: 0; batch classifier loss: 0.170255; batch adversarial loss: 0.510123\n",
      "epoch 49; iter: 0; batch classifier loss: 0.248744; batch adversarial loss: 0.452296\n",
      "epoch 50; iter: 0; batch classifier loss: 0.166013; batch adversarial loss: 0.494019\n",
      "epoch 51; iter: 0; batch classifier loss: 0.189430; batch adversarial loss: 0.434252\n",
      "epoch 52; iter: 0; batch classifier loss: 0.133456; batch adversarial loss: 0.440058\n",
      "epoch 53; iter: 0; batch classifier loss: 0.218182; batch adversarial loss: 0.370086\n",
      "epoch 54; iter: 0; batch classifier loss: 0.214108; batch adversarial loss: 0.495743\n",
      "epoch 55; iter: 0; batch classifier loss: 0.239125; batch adversarial loss: 0.421077\n",
      "epoch 56; iter: 0; batch classifier loss: 0.188550; batch adversarial loss: 0.454119\n",
      "epoch 57; iter: 0; batch classifier loss: 0.165023; batch adversarial loss: 0.495479\n",
      "epoch 58; iter: 0; batch classifier loss: 0.178272; batch adversarial loss: 0.408354\n",
      "epoch 59; iter: 0; batch classifier loss: 0.164188; batch adversarial loss: 0.488618\n",
      "epoch 60; iter: 0; batch classifier loss: 0.234677; batch adversarial loss: 0.416651\n",
      "epoch 61; iter: 0; batch classifier loss: 0.170242; batch adversarial loss: 0.423561\n",
      "epoch 62; iter: 0; batch classifier loss: 0.177489; batch adversarial loss: 0.409094\n",
      "epoch 63; iter: 0; batch classifier loss: 0.256424; batch adversarial loss: 0.458571\n",
      "epoch 64; iter: 0; batch classifier loss: 0.216751; batch adversarial loss: 0.465435\n",
      "epoch 65; iter: 0; batch classifier loss: 0.155216; batch adversarial loss: 0.458361\n",
      "epoch 66; iter: 0; batch classifier loss: 0.184605; batch adversarial loss: 0.484167\n",
      "epoch 67; iter: 0; batch classifier loss: 0.179270; batch adversarial loss: 0.411608\n",
      "epoch 68; iter: 0; batch classifier loss: 0.222474; batch adversarial loss: 0.523502\n",
      "epoch 69; iter: 0; batch classifier loss: 0.206134; batch adversarial loss: 0.453960\n",
      "epoch 70; iter: 0; batch classifier loss: 0.216578; batch adversarial loss: 0.495129\n",
      "epoch 71; iter: 0; batch classifier loss: 0.178991; batch adversarial loss: 0.370319\n",
      "epoch 72; iter: 0; batch classifier loss: 0.139806; batch adversarial loss: 0.456499\n",
      "epoch 73; iter: 0; batch classifier loss: 0.162393; batch adversarial loss: 0.505251\n",
      "epoch 74; iter: 0; batch classifier loss: 0.134888; batch adversarial loss: 0.507909\n",
      "epoch 75; iter: 0; batch classifier loss: 0.125465; batch adversarial loss: 0.424329\n",
      "epoch 76; iter: 0; batch classifier loss: 0.211926; batch adversarial loss: 0.519898\n",
      "epoch 77; iter: 0; batch classifier loss: 0.175561; batch adversarial loss: 0.451631\n",
      "epoch 78; iter: 0; batch classifier loss: 0.134882; batch adversarial loss: 0.469551\n",
      "epoch 79; iter: 0; batch classifier loss: 0.182655; batch adversarial loss: 0.407559\n",
      "epoch 80; iter: 0; batch classifier loss: 0.132390; batch adversarial loss: 0.445766\n",
      "epoch 81; iter: 0; batch classifier loss: 0.142465; batch adversarial loss: 0.419885\n",
      "epoch 82; iter: 0; batch classifier loss: 0.154197; batch adversarial loss: 0.421870\n",
      "epoch 83; iter: 0; batch classifier loss: 0.115625; batch adversarial loss: 0.463600\n",
      "epoch 84; iter: 0; batch classifier loss: 0.136860; batch adversarial loss: 0.496717\n",
      "epoch 85; iter: 0; batch classifier loss: 0.197963; batch adversarial loss: 0.543811\n",
      "epoch 86; iter: 0; batch classifier loss: 0.122425; batch adversarial loss: 0.378572\n",
      "epoch 87; iter: 0; batch classifier loss: 0.094476; batch adversarial loss: 0.621839\n",
      "epoch 88; iter: 0; batch classifier loss: 0.163120; batch adversarial loss: 0.451694\n",
      "epoch 89; iter: 0; batch classifier loss: 0.095738; batch adversarial loss: 0.499326\n",
      "epoch 90; iter: 0; batch classifier loss: 0.122594; batch adversarial loss: 0.445516\n",
      "epoch 91; iter: 0; batch classifier loss: 0.092350; batch adversarial loss: 0.444118\n",
      "epoch 92; iter: 0; batch classifier loss: 0.099149; batch adversarial loss: 0.337538\n",
      "epoch 93; iter: 0; batch classifier loss: 0.118755; batch adversarial loss: 0.339637\n",
      "epoch 94; iter: 0; batch classifier loss: 0.080613; batch adversarial loss: 0.322587\n",
      "epoch 95; iter: 0; batch classifier loss: 0.114857; batch adversarial loss: 0.490961\n",
      "epoch 96; iter: 0; batch classifier loss: 0.088226; batch adversarial loss: 0.457133\n",
      "epoch 97; iter: 0; batch classifier loss: 0.058741; batch adversarial loss: 0.437077\n",
      "epoch 98; iter: 0; batch classifier loss: 0.034286; batch adversarial loss: 0.439457\n",
      "epoch 99; iter: 0; batch classifier loss: 0.105299; batch adversarial loss: 0.490330\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036142; batch adversarial loss: 0.465959\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050844; batch adversarial loss: 0.462250\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043171; batch adversarial loss: 0.515606\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039025; batch adversarial loss: 0.469386\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047116; batch adversarial loss: 0.547836\n",
      "epoch 105; iter: 0; batch classifier loss: 0.096152; batch adversarial loss: 0.449148\n",
      "epoch 106; iter: 0; batch classifier loss: 0.056619; batch adversarial loss: 0.493989\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061842; batch adversarial loss: 0.417604\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044463; batch adversarial loss: 0.491131\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029949; batch adversarial loss: 0.379980\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045439; batch adversarial loss: 0.392474\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034374; batch adversarial loss: 0.418058\n",
      "epoch 112; iter: 0; batch classifier loss: 0.069933; batch adversarial loss: 0.361647\n",
      "epoch 113; iter: 0; batch classifier loss: 0.019107; batch adversarial loss: 0.458562\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033328; batch adversarial loss: 0.424701\n",
      "epoch 115; iter: 0; batch classifier loss: 0.011561; batch adversarial loss: 0.461697\n",
      "epoch 116; iter: 0; batch classifier loss: 0.022062; batch adversarial loss: 0.425349\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049407; batch adversarial loss: 0.484203\n",
      "epoch 118; iter: 0; batch classifier loss: 0.015026; batch adversarial loss: 0.458848\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042650; batch adversarial loss: 0.443671\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042238; batch adversarial loss: 0.444281\n",
      "epoch 121; iter: 0; batch classifier loss: 0.013421; batch adversarial loss: 0.405964\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025325; batch adversarial loss: 0.478940\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041491; batch adversarial loss: 0.445023\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026790; batch adversarial loss: 0.369505\n",
      "epoch 125; iter: 0; batch classifier loss: 0.015163; batch adversarial loss: 0.408023\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040216; batch adversarial loss: 0.502152\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032987; batch adversarial loss: 0.474347\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025550; batch adversarial loss: 0.363974\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046748; batch adversarial loss: 0.380528\n",
      "epoch 130; iter: 0; batch classifier loss: 0.058845; batch adversarial loss: 0.387047\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017122; batch adversarial loss: 0.460740\n",
      "epoch 132; iter: 0; batch classifier loss: 0.014767; batch adversarial loss: 0.432377\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014260; batch adversarial loss: 0.401483\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020341; batch adversarial loss: 0.486936\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020796; batch adversarial loss: 0.457612\n",
      "epoch 136; iter: 0; batch classifier loss: 0.008909; batch adversarial loss: 0.467179\n",
      "epoch 137; iter: 0; batch classifier loss: 0.019872; batch adversarial loss: 0.419064\n",
      "epoch 138; iter: 0; batch classifier loss: 0.006857; batch adversarial loss: 0.593931\n",
      "epoch 139; iter: 0; batch classifier loss: 0.008034; batch adversarial loss: 0.419082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.014428; batch adversarial loss: 0.437021\n",
      "epoch 141; iter: 0; batch classifier loss: 0.014271; batch adversarial loss: 0.398531\n",
      "epoch 142; iter: 0; batch classifier loss: 0.008027; batch adversarial loss: 0.537276\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042649; batch adversarial loss: 0.528276\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017091; batch adversarial loss: 0.333951\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048591; batch adversarial loss: 0.318068\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018847; batch adversarial loss: 0.513256\n",
      "epoch 147; iter: 0; batch classifier loss: 0.067081; batch adversarial loss: 0.397883\n",
      "epoch 148; iter: 0; batch classifier loss: 0.010486; batch adversarial loss: 0.417615\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011244; batch adversarial loss: 0.366320\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040578; batch adversarial loss: 0.377269\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024719; batch adversarial loss: 0.508424\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015105; batch adversarial loss: 0.440002\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023971; batch adversarial loss: 0.482682\n",
      "epoch 154; iter: 0; batch classifier loss: 0.008365; batch adversarial loss: 0.433012\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014552; batch adversarial loss: 0.439980\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026054; batch adversarial loss: 0.441402\n",
      "epoch 157; iter: 0; batch classifier loss: 0.004964; batch adversarial loss: 0.387384\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014443; batch adversarial loss: 0.466651\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011571; batch adversarial loss: 0.436918\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014916; batch adversarial loss: 0.475567\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018573; batch adversarial loss: 0.414120\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036577; batch adversarial loss: 0.329483\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015603; batch adversarial loss: 0.368348\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012391; batch adversarial loss: 0.428918\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020339; batch adversarial loss: 0.444753\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018356; batch adversarial loss: 0.418170\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019530; batch adversarial loss: 0.499468\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012093; batch adversarial loss: 0.418040\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011735; batch adversarial loss: 0.404375\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035049; batch adversarial loss: 0.396015\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033084; batch adversarial loss: 0.471110\n",
      "epoch 172; iter: 0; batch classifier loss: 0.004411; batch adversarial loss: 0.419402\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022641; batch adversarial loss: 0.420702\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011798; batch adversarial loss: 0.519407\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027364; batch adversarial loss: 0.525224\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041896; batch adversarial loss: 0.472484\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027983; batch adversarial loss: 0.365635\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015266; batch adversarial loss: 0.437946\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021663; batch adversarial loss: 0.388989\n",
      "epoch 180; iter: 0; batch classifier loss: 0.054430; batch adversarial loss: 0.380520\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013428; batch adversarial loss: 0.462711\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019767; batch adversarial loss: 0.311555\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025224; batch adversarial loss: 0.505036\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017634; batch adversarial loss: 0.490423\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020282; batch adversarial loss: 0.433282\n",
      "epoch 186; iter: 0; batch classifier loss: 0.037055; batch adversarial loss: 0.488949\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042702; batch adversarial loss: 0.476827\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006290; batch adversarial loss: 0.547888\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006171; batch adversarial loss: 0.541334\n",
      "epoch 190; iter: 0; batch classifier loss: 0.003271; batch adversarial loss: 0.483677\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017876; batch adversarial loss: 0.446686\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023241; batch adversarial loss: 0.457815\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014350; batch adversarial loss: 0.494112\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004106; batch adversarial loss: 0.497249\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005939; batch adversarial loss: 0.420021\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009059; batch adversarial loss: 0.493001\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012595; batch adversarial loss: 0.461412\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032495; batch adversarial loss: 0.398855\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008785; batch adversarial loss: 0.493965\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693319; batch adversarial loss: 1.017315\n",
      "epoch 1; iter: 0; batch classifier loss: 0.661061; batch adversarial loss: 1.138185\n",
      "epoch 2; iter: 0; batch classifier loss: 0.990357; batch adversarial loss: 1.142541\n",
      "epoch 3; iter: 0; batch classifier loss: 0.967399; batch adversarial loss: 1.061455\n",
      "epoch 4; iter: 0; batch classifier loss: 1.032405; batch adversarial loss: 0.961978\n",
      "epoch 5; iter: 0; batch classifier loss: 1.044506; batch adversarial loss: 0.869118\n",
      "epoch 6; iter: 0; batch classifier loss: 0.950654; batch adversarial loss: 0.792827\n",
      "epoch 7; iter: 0; batch classifier loss: 0.979172; batch adversarial loss: 0.722771\n",
      "epoch 8; iter: 0; batch classifier loss: 0.891562; batch adversarial loss: 0.671148\n",
      "epoch 9; iter: 0; batch classifier loss: 0.897213; batch adversarial loss: 0.628954\n",
      "epoch 10; iter: 0; batch classifier loss: 0.781202; batch adversarial loss: 0.570043\n",
      "epoch 11; iter: 0; batch classifier loss: 0.670937; batch adversarial loss: 0.526083\n",
      "epoch 12; iter: 0; batch classifier loss: 0.408736; batch adversarial loss: 0.524142\n",
      "epoch 13; iter: 0; batch classifier loss: 0.493462; batch adversarial loss: 0.532070\n",
      "epoch 14; iter: 0; batch classifier loss: 0.337085; batch adversarial loss: 0.489672\n",
      "epoch 15; iter: 0; batch classifier loss: 0.422920; batch adversarial loss: 0.462791\n",
      "epoch 16; iter: 0; batch classifier loss: 0.372861; batch adversarial loss: 0.492396\n",
      "epoch 17; iter: 0; batch classifier loss: 0.270996; batch adversarial loss: 0.493633\n",
      "epoch 18; iter: 0; batch classifier loss: 0.267013; batch adversarial loss: 0.520252\n",
      "epoch 19; iter: 0; batch classifier loss: 0.246910; batch adversarial loss: 0.446815\n",
      "epoch 20; iter: 0; batch classifier loss: 0.191248; batch adversarial loss: 0.392000\n",
      "epoch 21; iter: 0; batch classifier loss: 0.181700; batch adversarial loss: 0.430301\n",
      "epoch 22; iter: 0; batch classifier loss: 0.201599; batch adversarial loss: 0.405265\n",
      "epoch 23; iter: 0; batch classifier loss: 0.196346; batch adversarial loss: 0.484510\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199838; batch adversarial loss: 0.483409\n",
      "epoch 25; iter: 0; batch classifier loss: 0.159868; batch adversarial loss: 0.427561\n",
      "epoch 26; iter: 0; batch classifier loss: 0.124763; batch adversarial loss: 0.362253\n",
      "epoch 27; iter: 0; batch classifier loss: 0.164668; batch adversarial loss: 0.457429\n",
      "epoch 28; iter: 0; batch classifier loss: 0.114403; batch adversarial loss: 0.357830\n",
      "epoch 29; iter: 0; batch classifier loss: 0.135881; batch adversarial loss: 0.431507\n",
      "epoch 30; iter: 0; batch classifier loss: 0.135456; batch adversarial loss: 0.421310\n",
      "epoch 31; iter: 0; batch classifier loss: 0.092141; batch adversarial loss: 0.460278\n",
      "epoch 32; iter: 0; batch classifier loss: 0.118102; batch adversarial loss: 0.433141\n",
      "epoch 33; iter: 0; batch classifier loss: 0.117098; batch adversarial loss: 0.459713\n",
      "epoch 34; iter: 0; batch classifier loss: 0.105382; batch adversarial loss: 0.434844\n",
      "epoch 35; iter: 0; batch classifier loss: 0.107118; batch adversarial loss: 0.516759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.131804; batch adversarial loss: 0.413328\n",
      "epoch 37; iter: 0; batch classifier loss: 0.089922; batch adversarial loss: 0.435356\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099803; batch adversarial loss: 0.499449\n",
      "epoch 39; iter: 0; batch classifier loss: 0.161866; batch adversarial loss: 0.451374\n",
      "epoch 40; iter: 0; batch classifier loss: 0.103886; batch adversarial loss: 0.525000\n",
      "epoch 41; iter: 0; batch classifier loss: 0.082635; batch adversarial loss: 0.416225\n",
      "epoch 42; iter: 0; batch classifier loss: 0.082986; batch adversarial loss: 0.502499\n",
      "epoch 43; iter: 0; batch classifier loss: 0.080633; batch adversarial loss: 0.410022\n",
      "epoch 44; iter: 0; batch classifier loss: 0.074765; batch adversarial loss: 0.403286\n",
      "epoch 45; iter: 0; batch classifier loss: 0.051891; batch adversarial loss: 0.363758\n",
      "epoch 46; iter: 0; batch classifier loss: 0.041803; batch adversarial loss: 0.424710\n",
      "epoch 47; iter: 0; batch classifier loss: 0.098647; batch adversarial loss: 0.408983\n",
      "epoch 48; iter: 0; batch classifier loss: 0.061071; batch adversarial loss: 0.424049\n",
      "epoch 49; iter: 0; batch classifier loss: 0.071634; batch adversarial loss: 0.369487\n",
      "epoch 50; iter: 0; batch classifier loss: 0.090356; batch adversarial loss: 0.461211\n",
      "epoch 51; iter: 0; batch classifier loss: 0.052137; batch adversarial loss: 0.380080\n",
      "epoch 52; iter: 0; batch classifier loss: 0.078973; batch adversarial loss: 0.391715\n",
      "epoch 53; iter: 0; batch classifier loss: 0.047657; batch adversarial loss: 0.476211\n",
      "epoch 54; iter: 0; batch classifier loss: 0.063316; batch adversarial loss: 0.442130\n",
      "epoch 55; iter: 0; batch classifier loss: 0.052446; batch adversarial loss: 0.376528\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067930; batch adversarial loss: 0.501274\n",
      "epoch 57; iter: 0; batch classifier loss: 0.071904; batch adversarial loss: 0.362516\n",
      "epoch 58; iter: 0; batch classifier loss: 0.052078; batch adversarial loss: 0.479951\n",
      "epoch 59; iter: 0; batch classifier loss: 0.085002; batch adversarial loss: 0.378437\n",
      "epoch 60; iter: 0; batch classifier loss: 0.080965; batch adversarial loss: 0.437315\n",
      "epoch 61; iter: 0; batch classifier loss: 0.095885; batch adversarial loss: 0.452679\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084915; batch adversarial loss: 0.419345\n",
      "epoch 63; iter: 0; batch classifier loss: 0.037435; batch adversarial loss: 0.382568\n",
      "epoch 64; iter: 0; batch classifier loss: 0.062264; batch adversarial loss: 0.506246\n",
      "epoch 65; iter: 0; batch classifier loss: 0.064528; batch adversarial loss: 0.505941\n",
      "epoch 66; iter: 0; batch classifier loss: 0.065576; batch adversarial loss: 0.504530\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069764; batch adversarial loss: 0.410486\n",
      "epoch 68; iter: 0; batch classifier loss: 0.055824; batch adversarial loss: 0.437040\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071493; batch adversarial loss: 0.460677\n",
      "epoch 70; iter: 0; batch classifier loss: 0.054622; batch adversarial loss: 0.333310\n",
      "epoch 71; iter: 0; batch classifier loss: 0.090149; batch adversarial loss: 0.396498\n",
      "epoch 72; iter: 0; batch classifier loss: 0.036263; batch adversarial loss: 0.318058\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101765; batch adversarial loss: 0.407349\n",
      "epoch 74; iter: 0; batch classifier loss: 0.070018; batch adversarial loss: 0.349624\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061348; batch adversarial loss: 0.488219\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058314; batch adversarial loss: 0.472894\n",
      "epoch 77; iter: 0; batch classifier loss: 0.077539; batch adversarial loss: 0.381636\n",
      "epoch 78; iter: 0; batch classifier loss: 0.040420; batch adversarial loss: 0.443545\n",
      "epoch 79; iter: 0; batch classifier loss: 0.054071; batch adversarial loss: 0.432634\n",
      "epoch 80; iter: 0; batch classifier loss: 0.062876; batch adversarial loss: 0.351058\n",
      "epoch 81; iter: 0; batch classifier loss: 0.070042; batch adversarial loss: 0.426832\n",
      "epoch 82; iter: 0; batch classifier loss: 0.037519; batch adversarial loss: 0.430199\n",
      "epoch 83; iter: 0; batch classifier loss: 0.058417; batch adversarial loss: 0.347429\n",
      "epoch 84; iter: 0; batch classifier loss: 0.039321; batch adversarial loss: 0.366869\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064453; batch adversarial loss: 0.480493\n",
      "epoch 86; iter: 0; batch classifier loss: 0.048760; batch adversarial loss: 0.375239\n",
      "epoch 87; iter: 0; batch classifier loss: 0.028867; batch adversarial loss: 0.370518\n",
      "epoch 88; iter: 0; batch classifier loss: 0.032934; batch adversarial loss: 0.423411\n",
      "epoch 89; iter: 0; batch classifier loss: 0.045824; batch adversarial loss: 0.317159\n",
      "epoch 90; iter: 0; batch classifier loss: 0.040543; batch adversarial loss: 0.450187\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077825; batch adversarial loss: 0.463697\n",
      "epoch 92; iter: 0; batch classifier loss: 0.035765; batch adversarial loss: 0.342683\n",
      "epoch 93; iter: 0; batch classifier loss: 0.023881; batch adversarial loss: 0.400732\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077204; batch adversarial loss: 0.599988\n",
      "epoch 95; iter: 0; batch classifier loss: 0.091395; batch adversarial loss: 0.467966\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063273; batch adversarial loss: 0.673635\n",
      "epoch 97; iter: 0; batch classifier loss: 0.025254; batch adversarial loss: 0.426637\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058354; batch adversarial loss: 0.483620\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047548; batch adversarial loss: 0.435320\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064962; batch adversarial loss: 0.387629\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062196; batch adversarial loss: 0.484510\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053672; batch adversarial loss: 0.462849\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048408; batch adversarial loss: 0.430849\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058968; batch adversarial loss: 0.387163\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044805; batch adversarial loss: 0.436664\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036334; batch adversarial loss: 0.360583\n",
      "epoch 107; iter: 0; batch classifier loss: 0.025823; batch adversarial loss: 0.444153\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045511; batch adversarial loss: 0.459257\n",
      "epoch 109; iter: 0; batch classifier loss: 0.073236; batch adversarial loss: 0.525108\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051727; batch adversarial loss: 0.402687\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028274; batch adversarial loss: 0.356995\n",
      "epoch 112; iter: 0; batch classifier loss: 0.021439; batch adversarial loss: 0.433515\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038083; batch adversarial loss: 0.427455\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034710; batch adversarial loss: 0.435582\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029813; batch adversarial loss: 0.419127\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029133; batch adversarial loss: 0.504023\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047938; batch adversarial loss: 0.449783\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042951; batch adversarial loss: 0.360635\n",
      "epoch 119; iter: 0; batch classifier loss: 0.064695; batch adversarial loss: 0.363256\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028717; batch adversarial loss: 0.378472\n",
      "epoch 121; iter: 0; batch classifier loss: 0.075817; batch adversarial loss: 0.492634\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034485; batch adversarial loss: 0.425229\n",
      "epoch 123; iter: 0; batch classifier loss: 0.062359; batch adversarial loss: 0.471042\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039262; batch adversarial loss: 0.474477\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017882; batch adversarial loss: 0.429038\n",
      "epoch 126; iter: 0; batch classifier loss: 0.059856; batch adversarial loss: 0.463638\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021276; batch adversarial loss: 0.423845\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017846; batch adversarial loss: 0.459287\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033356; batch adversarial loss: 0.417488\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038586; batch adversarial loss: 0.386242\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052125; batch adversarial loss: 0.443287\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039717; batch adversarial loss: 0.339062\n",
      "epoch 133; iter: 0; batch classifier loss: 0.058715; batch adversarial loss: 0.437434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.048942; batch adversarial loss: 0.483433\n",
      "epoch 135; iter: 0; batch classifier loss: 0.058420; batch adversarial loss: 0.439855\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054435; batch adversarial loss: 0.427634\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030142; batch adversarial loss: 0.424208\n",
      "epoch 138; iter: 0; batch classifier loss: 0.064091; batch adversarial loss: 0.385606\n",
      "epoch 139; iter: 0; batch classifier loss: 0.068686; batch adversarial loss: 0.405749\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047850; batch adversarial loss: 0.461084\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026570; batch adversarial loss: 0.443223\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050455; batch adversarial loss: 0.377323\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025086; batch adversarial loss: 0.411856\n",
      "epoch 144; iter: 0; batch classifier loss: 0.065584; batch adversarial loss: 0.438020\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035702; batch adversarial loss: 0.470160\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034578; batch adversarial loss: 0.366467\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036213; batch adversarial loss: 0.468593\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054259; batch adversarial loss: 0.417748\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033850; batch adversarial loss: 0.396308\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030047; batch adversarial loss: 0.448098\n",
      "epoch 151; iter: 0; batch classifier loss: 0.058197; batch adversarial loss: 0.466756\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035690; batch adversarial loss: 0.446548\n",
      "epoch 153; iter: 0; batch classifier loss: 0.051099; batch adversarial loss: 0.442732\n",
      "epoch 154; iter: 0; batch classifier loss: 0.050506; batch adversarial loss: 0.573160\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037477; batch adversarial loss: 0.417597\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032006; batch adversarial loss: 0.379067\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033005; batch adversarial loss: 0.491926\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044913; batch adversarial loss: 0.387670\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029354; batch adversarial loss: 0.361380\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022876; batch adversarial loss: 0.374229\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022894; batch adversarial loss: 0.389497\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036388; batch adversarial loss: 0.336190\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035846; batch adversarial loss: 0.472394\n",
      "epoch 164; iter: 0; batch classifier loss: 0.062004; batch adversarial loss: 0.459680\n",
      "epoch 165; iter: 0; batch classifier loss: 0.075152; batch adversarial loss: 0.541679\n",
      "epoch 166; iter: 0; batch classifier loss: 0.059918; batch adversarial loss: 0.461017\n",
      "epoch 167; iter: 0; batch classifier loss: 0.059725; batch adversarial loss: 0.470345\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032368; batch adversarial loss: 0.456647\n",
      "epoch 169; iter: 0; batch classifier loss: 0.055549; batch adversarial loss: 0.512551\n",
      "epoch 170; iter: 0; batch classifier loss: 0.043404; batch adversarial loss: 0.346956\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025177; batch adversarial loss: 0.337832\n",
      "epoch 172; iter: 0; batch classifier loss: 0.093729; batch adversarial loss: 0.417390\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040575; batch adversarial loss: 0.422838\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039627; batch adversarial loss: 0.415994\n",
      "epoch 175; iter: 0; batch classifier loss: 0.074946; batch adversarial loss: 0.470928\n",
      "epoch 176; iter: 0; batch classifier loss: 0.039139; batch adversarial loss: 0.416704\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029989; batch adversarial loss: 0.458113\n",
      "epoch 178; iter: 0; batch classifier loss: 0.041478; batch adversarial loss: 0.493850\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032475; batch adversarial loss: 0.429138\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026775; batch adversarial loss: 0.395099\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030718; batch adversarial loss: 0.426969\n",
      "epoch 182; iter: 0; batch classifier loss: 0.073237; batch adversarial loss: 0.489695\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031916; batch adversarial loss: 0.455243\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021665; batch adversarial loss: 0.391463\n",
      "epoch 185; iter: 0; batch classifier loss: 0.049773; batch adversarial loss: 0.401427\n",
      "epoch 186; iter: 0; batch classifier loss: 0.044759; batch adversarial loss: 0.446175\n",
      "epoch 187; iter: 0; batch classifier loss: 0.043110; batch adversarial loss: 0.425703\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029146; batch adversarial loss: 0.427712\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026365; batch adversarial loss: 0.435288\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024391; batch adversarial loss: 0.394941\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025434; batch adversarial loss: 0.360716\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036936; batch adversarial loss: 0.387550\n",
      "epoch 193; iter: 0; batch classifier loss: 0.042232; batch adversarial loss: 0.382887\n",
      "epoch 194; iter: 0; batch classifier loss: 0.072209; batch adversarial loss: 0.492224\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023581; batch adversarial loss: 0.322477\n",
      "epoch 196; iter: 0; batch classifier loss: 0.054369; batch adversarial loss: 0.442346\n",
      "epoch 197; iter: 0; batch classifier loss: 0.052732; batch adversarial loss: 0.571239\n",
      "epoch 198; iter: 0; batch classifier loss: 0.051729; batch adversarial loss: 0.467559\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027811; batch adversarial loss: 0.475284\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681072; batch adversarial loss: 0.694630\n",
      "epoch 1; iter: 0; batch classifier loss: 0.460171; batch adversarial loss: 0.668363\n",
      "epoch 2; iter: 0; batch classifier loss: 0.422188; batch adversarial loss: 0.635745\n",
      "epoch 3; iter: 0; batch classifier loss: 0.527606; batch adversarial loss: 0.618219\n",
      "epoch 4; iter: 0; batch classifier loss: 0.435022; batch adversarial loss: 0.603372\n",
      "epoch 5; iter: 0; batch classifier loss: 0.473444; batch adversarial loss: 0.598771\n",
      "epoch 6; iter: 0; batch classifier loss: 0.502485; batch adversarial loss: 0.590603\n",
      "epoch 7; iter: 0; batch classifier loss: 0.499391; batch adversarial loss: 0.579040\n",
      "epoch 8; iter: 0; batch classifier loss: 0.397815; batch adversarial loss: 0.541307\n",
      "epoch 9; iter: 0; batch classifier loss: 0.492510; batch adversarial loss: 0.511154\n",
      "epoch 10; iter: 0; batch classifier loss: 0.360921; batch adversarial loss: 0.538151\n",
      "epoch 11; iter: 0; batch classifier loss: 0.393342; batch adversarial loss: 0.549049\n",
      "epoch 12; iter: 0; batch classifier loss: 0.406238; batch adversarial loss: 0.525335\n",
      "epoch 13; iter: 0; batch classifier loss: 0.465568; batch adversarial loss: 0.476066\n",
      "epoch 14; iter: 0; batch classifier loss: 0.378937; batch adversarial loss: 0.489582\n",
      "epoch 15; iter: 0; batch classifier loss: 0.332769; batch adversarial loss: 0.519531\n",
      "epoch 16; iter: 0; batch classifier loss: 0.389121; batch adversarial loss: 0.450339\n",
      "epoch 17; iter: 0; batch classifier loss: 0.329205; batch adversarial loss: 0.480431\n",
      "epoch 18; iter: 0; batch classifier loss: 0.328601; batch adversarial loss: 0.486638\n",
      "epoch 19; iter: 0; batch classifier loss: 0.320414; batch adversarial loss: 0.460239\n",
      "epoch 20; iter: 0; batch classifier loss: 0.350384; batch adversarial loss: 0.466774\n",
      "epoch 21; iter: 0; batch classifier loss: 0.305118; batch adversarial loss: 0.442742\n",
      "epoch 22; iter: 0; batch classifier loss: 0.278338; batch adversarial loss: 0.521908\n",
      "epoch 23; iter: 0; batch classifier loss: 0.330373; batch adversarial loss: 0.472122\n",
      "epoch 24; iter: 0; batch classifier loss: 0.259981; batch adversarial loss: 0.523210\n",
      "epoch 25; iter: 0; batch classifier loss: 0.273625; batch adversarial loss: 0.469728\n",
      "epoch 26; iter: 0; batch classifier loss: 0.227314; batch adversarial loss: 0.523947\n",
      "epoch 27; iter: 0; batch classifier loss: 0.270664; batch adversarial loss: 0.406715\n",
      "epoch 28; iter: 0; batch classifier loss: 0.282253; batch adversarial loss: 0.398363\n",
      "epoch 29; iter: 0; batch classifier loss: 0.246701; batch adversarial loss: 0.459601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.262478; batch adversarial loss: 0.469909\n",
      "epoch 31; iter: 0; batch classifier loss: 0.248208; batch adversarial loss: 0.487299\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181387; batch adversarial loss: 0.525042\n",
      "epoch 33; iter: 0; batch classifier loss: 0.230632; batch adversarial loss: 0.466569\n",
      "epoch 34; iter: 0; batch classifier loss: 0.236739; batch adversarial loss: 0.516979\n",
      "epoch 35; iter: 0; batch classifier loss: 0.223684; batch adversarial loss: 0.464701\n",
      "epoch 36; iter: 0; batch classifier loss: 0.232614; batch adversarial loss: 0.406646\n",
      "epoch 37; iter: 0; batch classifier loss: 0.222973; batch adversarial loss: 0.493868\n",
      "epoch 38; iter: 0; batch classifier loss: 0.234920; batch adversarial loss: 0.392542\n",
      "epoch 39; iter: 0; batch classifier loss: 0.200556; batch adversarial loss: 0.437683\n",
      "epoch 40; iter: 0; batch classifier loss: 0.189858; batch adversarial loss: 0.472484\n",
      "epoch 41; iter: 0; batch classifier loss: 0.199178; batch adversarial loss: 0.482398\n",
      "epoch 42; iter: 0; batch classifier loss: 0.150370; batch adversarial loss: 0.423929\n",
      "epoch 43; iter: 0; batch classifier loss: 0.132915; batch adversarial loss: 0.503200\n",
      "epoch 44; iter: 0; batch classifier loss: 0.169264; batch adversarial loss: 0.424285\n",
      "epoch 45; iter: 0; batch classifier loss: 0.123009; batch adversarial loss: 0.483121\n",
      "epoch 46; iter: 0; batch classifier loss: 0.108955; batch adversarial loss: 0.437549\n",
      "epoch 47; iter: 0; batch classifier loss: 0.202003; batch adversarial loss: 0.400142\n",
      "epoch 48; iter: 0; batch classifier loss: 0.159705; batch adversarial loss: 0.374853\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119429; batch adversarial loss: 0.409857\n",
      "epoch 50; iter: 0; batch classifier loss: 0.217440; batch adversarial loss: 0.422936\n",
      "epoch 51; iter: 0; batch classifier loss: 0.122757; batch adversarial loss: 0.495738\n",
      "epoch 52; iter: 0; batch classifier loss: 0.113805; batch adversarial loss: 0.481758\n",
      "epoch 53; iter: 0; batch classifier loss: 0.194078; batch adversarial loss: 0.509330\n",
      "epoch 54; iter: 0; batch classifier loss: 0.190148; batch adversarial loss: 0.483445\n",
      "epoch 55; iter: 0; batch classifier loss: 0.130968; batch adversarial loss: 0.446090\n",
      "epoch 56; iter: 0; batch classifier loss: 0.108158; batch adversarial loss: 0.406644\n",
      "epoch 57; iter: 0; batch classifier loss: 0.131306; batch adversarial loss: 0.533342\n",
      "epoch 58; iter: 0; batch classifier loss: 0.222840; batch adversarial loss: 0.518808\n",
      "epoch 59; iter: 0; batch classifier loss: 0.121010; batch adversarial loss: 0.410621\n",
      "epoch 60; iter: 0; batch classifier loss: 0.100090; batch adversarial loss: 0.396266\n",
      "epoch 61; iter: 0; batch classifier loss: 0.260365; batch adversarial loss: 0.447652\n",
      "epoch 62; iter: 0; batch classifier loss: 0.168321; batch adversarial loss: 0.421420\n",
      "epoch 63; iter: 0; batch classifier loss: 0.179013; batch adversarial loss: 0.459225\n",
      "epoch 64; iter: 0; batch classifier loss: 0.150211; batch adversarial loss: 0.410148\n",
      "epoch 65; iter: 0; batch classifier loss: 0.188163; batch adversarial loss: 0.434760\n",
      "epoch 66; iter: 0; batch classifier loss: 0.145606; batch adversarial loss: 0.495095\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080236; batch adversarial loss: 0.458935\n",
      "epoch 68; iter: 0; batch classifier loss: 0.132357; batch adversarial loss: 0.395035\n",
      "epoch 69; iter: 0; batch classifier loss: 0.145250; batch adversarial loss: 0.445154\n",
      "epoch 70; iter: 0; batch classifier loss: 0.171158; batch adversarial loss: 0.409084\n",
      "epoch 71; iter: 0; batch classifier loss: 0.132510; batch adversarial loss: 0.446555\n",
      "epoch 72; iter: 0; batch classifier loss: 0.148913; batch adversarial loss: 0.493683\n",
      "epoch 73; iter: 0; batch classifier loss: 0.114537; batch adversarial loss: 0.447056\n",
      "epoch 74; iter: 0; batch classifier loss: 0.136029; batch adversarial loss: 0.511490\n",
      "epoch 75; iter: 0; batch classifier loss: 0.118510; batch adversarial loss: 0.356868\n",
      "epoch 76; iter: 0; batch classifier loss: 0.114568; batch adversarial loss: 0.459925\n",
      "epoch 77; iter: 0; batch classifier loss: 0.147290; batch adversarial loss: 0.549256\n",
      "epoch 78; iter: 0; batch classifier loss: 0.138444; batch adversarial loss: 0.442936\n",
      "epoch 79; iter: 0; batch classifier loss: 0.167774; batch adversarial loss: 0.469441\n",
      "epoch 80; iter: 0; batch classifier loss: 0.118094; batch adversarial loss: 0.408489\n",
      "epoch 81; iter: 0; batch classifier loss: 0.138512; batch adversarial loss: 0.389528\n",
      "epoch 82; iter: 0; batch classifier loss: 0.089054; batch adversarial loss: 0.452036\n",
      "epoch 83; iter: 0; batch classifier loss: 0.106346; batch adversarial loss: 0.510856\n",
      "epoch 84; iter: 0; batch classifier loss: 0.109499; batch adversarial loss: 0.492047\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065906; batch adversarial loss: 0.470043\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076860; batch adversarial loss: 0.530715\n",
      "epoch 87; iter: 0; batch classifier loss: 0.091167; batch adversarial loss: 0.403971\n",
      "epoch 88; iter: 0; batch classifier loss: 0.092862; batch adversarial loss: 0.381937\n",
      "epoch 89; iter: 0; batch classifier loss: 0.049056; batch adversarial loss: 0.405636\n",
      "epoch 90; iter: 0; batch classifier loss: 0.095272; batch adversarial loss: 0.449397\n",
      "epoch 91; iter: 0; batch classifier loss: 0.065156; batch adversarial loss: 0.435378\n",
      "epoch 92; iter: 0; batch classifier loss: 0.053563; batch adversarial loss: 0.474719\n",
      "epoch 93; iter: 0; batch classifier loss: 0.096168; batch adversarial loss: 0.458632\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083658; batch adversarial loss: 0.481256\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071612; batch adversarial loss: 0.394817\n",
      "epoch 96; iter: 0; batch classifier loss: 0.050502; batch adversarial loss: 0.430088\n",
      "epoch 97; iter: 0; batch classifier loss: 0.068746; batch adversarial loss: 0.441637\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058847; batch adversarial loss: 0.499316\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049169; batch adversarial loss: 0.468725\n",
      "epoch 100; iter: 0; batch classifier loss: 0.028861; batch adversarial loss: 0.427085\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049237; batch adversarial loss: 0.440561\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049828; batch adversarial loss: 0.416798\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048031; batch adversarial loss: 0.364793\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045708; batch adversarial loss: 0.466581\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062851; batch adversarial loss: 0.386980\n",
      "epoch 106; iter: 0; batch classifier loss: 0.056949; batch adversarial loss: 0.442027\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045506; batch adversarial loss: 0.411005\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033472; batch adversarial loss: 0.457854\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041271; batch adversarial loss: 0.501849\n",
      "epoch 110; iter: 0; batch classifier loss: 0.032839; batch adversarial loss: 0.371054\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047425; batch adversarial loss: 0.435897\n",
      "epoch 112; iter: 0; batch classifier loss: 0.028506; batch adversarial loss: 0.481786\n",
      "epoch 113; iter: 0; batch classifier loss: 0.071701; batch adversarial loss: 0.429267\n",
      "epoch 114; iter: 0; batch classifier loss: 0.016023; batch adversarial loss: 0.547999\n",
      "epoch 115; iter: 0; batch classifier loss: 0.018971; batch adversarial loss: 0.460275\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030636; batch adversarial loss: 0.458149\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031390; batch adversarial loss: 0.366578\n",
      "epoch 118; iter: 0; batch classifier loss: 0.038013; batch adversarial loss: 0.433927\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041884; batch adversarial loss: 0.506331\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055564; batch adversarial loss: 0.421741\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032920; batch adversarial loss: 0.396533\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028146; batch adversarial loss: 0.427223\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019275; batch adversarial loss: 0.527273\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036888; batch adversarial loss: 0.446368\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023950; batch adversarial loss: 0.365414\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044295; batch adversarial loss: 0.478579\n",
      "epoch 127; iter: 0; batch classifier loss: 0.020569; batch adversarial loss: 0.389740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.044754; batch adversarial loss: 0.395683\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019590; batch adversarial loss: 0.461114\n",
      "epoch 130; iter: 0; batch classifier loss: 0.052198; batch adversarial loss: 0.468173\n",
      "epoch 131; iter: 0; batch classifier loss: 0.004109; batch adversarial loss: 0.502524\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031185; batch adversarial loss: 0.437693\n",
      "epoch 133; iter: 0; batch classifier loss: 0.048056; batch adversarial loss: 0.523116\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032419; batch adversarial loss: 0.470122\n",
      "epoch 135; iter: 0; batch classifier loss: 0.009066; batch adversarial loss: 0.363338\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044158; batch adversarial loss: 0.415457\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026595; batch adversarial loss: 0.505441\n",
      "epoch 138; iter: 0; batch classifier loss: 0.012177; batch adversarial loss: 0.390422\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046753; batch adversarial loss: 0.487935\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022106; batch adversarial loss: 0.479768\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042071; batch adversarial loss: 0.447816\n",
      "epoch 142; iter: 0; batch classifier loss: 0.047233; batch adversarial loss: 0.465168\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033557; batch adversarial loss: 0.479355\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045062; batch adversarial loss: 0.470624\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020994; batch adversarial loss: 0.440034\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029297; batch adversarial loss: 0.506285\n",
      "epoch 147; iter: 0; batch classifier loss: 0.004303; batch adversarial loss: 0.481002\n",
      "epoch 148; iter: 0; batch classifier loss: 0.043634; batch adversarial loss: 0.428284\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037687; batch adversarial loss: 0.498531\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022074; batch adversarial loss: 0.479985\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011258; batch adversarial loss: 0.509400\n",
      "epoch 152; iter: 0; batch classifier loss: 0.049786; batch adversarial loss: 0.480604\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018691; batch adversarial loss: 0.535504\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027435; batch adversarial loss: 0.365612\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012792; batch adversarial loss: 0.476856\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037790; batch adversarial loss: 0.511513\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022067; batch adversarial loss: 0.402773\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028615; batch adversarial loss: 0.434941\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038126; batch adversarial loss: 0.475109\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022061; batch adversarial loss: 0.453433\n",
      "epoch 161; iter: 0; batch classifier loss: 0.049706; batch adversarial loss: 0.353365\n",
      "epoch 162; iter: 0; batch classifier loss: 0.006946; batch adversarial loss: 0.409324\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039828; batch adversarial loss: 0.436410\n",
      "epoch 164; iter: 0; batch classifier loss: 0.040316; batch adversarial loss: 0.404596\n",
      "epoch 165; iter: 0; batch classifier loss: 0.083863; batch adversarial loss: 0.449070\n",
      "epoch 166; iter: 0; batch classifier loss: 0.004151; batch adversarial loss: 0.495934\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009907; batch adversarial loss: 0.547712\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023939; batch adversarial loss: 0.441425\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011584; batch adversarial loss: 0.471210\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029937; batch adversarial loss: 0.501060\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007859; batch adversarial loss: 0.370604\n",
      "epoch 172; iter: 0; batch classifier loss: 0.001864; batch adversarial loss: 0.471292\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010869; batch adversarial loss: 0.343760\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022042; batch adversarial loss: 0.364816\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024677; batch adversarial loss: 0.460348\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009590; batch adversarial loss: 0.503165\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012134; batch adversarial loss: 0.542513\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021365; batch adversarial loss: 0.522868\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006836; batch adversarial loss: 0.475660\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016399; batch adversarial loss: 0.448094\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012799; batch adversarial loss: 0.508199\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014023; batch adversarial loss: 0.361376\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022734; batch adversarial loss: 0.501722\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014936; batch adversarial loss: 0.498658\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007100; batch adversarial loss: 0.481672\n",
      "epoch 186; iter: 0; batch classifier loss: 0.002433; batch adversarial loss: 0.379714\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020772; batch adversarial loss: 0.335419\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007381; batch adversarial loss: 0.486235\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013856; batch adversarial loss: 0.464397\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006116; batch adversarial loss: 0.409637\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020612; batch adversarial loss: 0.479930\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017140; batch adversarial loss: 0.533074\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011168; batch adversarial loss: 0.425373\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010793; batch adversarial loss: 0.422745\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014982; batch adversarial loss: 0.451943\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014859; batch adversarial loss: 0.402095\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013188; batch adversarial loss: 0.486232\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007010; batch adversarial loss: 0.380136\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008207; batch adversarial loss: 0.444260\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702985; batch adversarial loss: 0.680788\n",
      "epoch 1; iter: 0; batch classifier loss: 0.421344; batch adversarial loss: 0.656276\n",
      "epoch 2; iter: 0; batch classifier loss: 0.334795; batch adversarial loss: 0.610349\n",
      "epoch 3; iter: 0; batch classifier loss: 0.263493; batch adversarial loss: 0.598997\n",
      "epoch 4; iter: 0; batch classifier loss: 0.301634; batch adversarial loss: 0.549012\n",
      "epoch 5; iter: 0; batch classifier loss: 0.256808; batch adversarial loss: 0.536662\n",
      "epoch 6; iter: 0; batch classifier loss: 0.336803; batch adversarial loss: 0.530186\n",
      "epoch 7; iter: 0; batch classifier loss: 0.314706; batch adversarial loss: 0.534458\n",
      "epoch 8; iter: 0; batch classifier loss: 0.204299; batch adversarial loss: 0.528044\n",
      "epoch 9; iter: 0; batch classifier loss: 0.291719; batch adversarial loss: 0.500414\n",
      "epoch 10; iter: 0; batch classifier loss: 0.252791; batch adversarial loss: 0.492476\n",
      "epoch 11; iter: 0; batch classifier loss: 0.245253; batch adversarial loss: 0.486937\n",
      "epoch 12; iter: 0; batch classifier loss: 0.221271; batch adversarial loss: 0.503494\n",
      "epoch 13; iter: 0; batch classifier loss: 0.199425; batch adversarial loss: 0.453163\n",
      "epoch 14; iter: 0; batch classifier loss: 0.168122; batch adversarial loss: 0.520673\n",
      "epoch 15; iter: 0; batch classifier loss: 0.172538; batch adversarial loss: 0.460329\n",
      "epoch 16; iter: 0; batch classifier loss: 0.163862; batch adversarial loss: 0.487786\n",
      "epoch 17; iter: 0; batch classifier loss: 0.170596; batch adversarial loss: 0.474505\n",
      "epoch 18; iter: 0; batch classifier loss: 0.164626; batch adversarial loss: 0.436654\n",
      "epoch 19; iter: 0; batch classifier loss: 0.203908; batch adversarial loss: 0.546743\n",
      "epoch 20; iter: 0; batch classifier loss: 0.151902; batch adversarial loss: 0.498033\n",
      "epoch 21; iter: 0; batch classifier loss: 0.141474; batch adversarial loss: 0.462263\n",
      "epoch 22; iter: 0; batch classifier loss: 0.139936; batch adversarial loss: 0.436923\n",
      "epoch 23; iter: 0; batch classifier loss: 0.150226; batch adversarial loss: 0.541690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.240975; batch adversarial loss: 0.441040\n",
      "epoch 25; iter: 0; batch classifier loss: 0.181551; batch adversarial loss: 0.422612\n",
      "epoch 26; iter: 0; batch classifier loss: 0.233530; batch adversarial loss: 0.508972\n",
      "epoch 27; iter: 0; batch classifier loss: 0.231739; batch adversarial loss: 0.514823\n",
      "epoch 28; iter: 0; batch classifier loss: 0.291058; batch adversarial loss: 0.507796\n",
      "epoch 29; iter: 0; batch classifier loss: 0.335040; batch adversarial loss: 0.494341\n",
      "epoch 30; iter: 0; batch classifier loss: 0.287241; batch adversarial loss: 0.466612\n",
      "epoch 31; iter: 0; batch classifier loss: 0.141978; batch adversarial loss: 0.527233\n",
      "epoch 32; iter: 0; batch classifier loss: 0.158851; batch adversarial loss: 0.410092\n",
      "epoch 33; iter: 0; batch classifier loss: 0.071955; batch adversarial loss: 0.415649\n",
      "epoch 34; iter: 0; batch classifier loss: 0.121280; batch adversarial loss: 0.564991\n",
      "epoch 35; iter: 0; batch classifier loss: 0.118505; batch adversarial loss: 0.515384\n",
      "epoch 36; iter: 0; batch classifier loss: 0.080472; batch adversarial loss: 0.391366\n",
      "epoch 37; iter: 0; batch classifier loss: 0.075386; batch adversarial loss: 0.436013\n",
      "epoch 38; iter: 0; batch classifier loss: 0.086834; batch adversarial loss: 0.439736\n",
      "epoch 39; iter: 0; batch classifier loss: 0.102756; batch adversarial loss: 0.460685\n",
      "epoch 40; iter: 0; batch classifier loss: 0.093090; batch adversarial loss: 0.489855\n",
      "epoch 41; iter: 0; batch classifier loss: 0.058733; batch adversarial loss: 0.436310\n",
      "epoch 42; iter: 0; batch classifier loss: 0.109425; batch adversarial loss: 0.441154\n",
      "epoch 43; iter: 0; batch classifier loss: 0.085113; batch adversarial loss: 0.366764\n",
      "epoch 44; iter: 0; batch classifier loss: 0.097813; batch adversarial loss: 0.442101\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086645; batch adversarial loss: 0.451943\n",
      "epoch 46; iter: 0; batch classifier loss: 0.088440; batch adversarial loss: 0.452078\n",
      "epoch 47; iter: 0; batch classifier loss: 0.071254; batch adversarial loss: 0.393726\n",
      "epoch 48; iter: 0; batch classifier loss: 0.076523; batch adversarial loss: 0.533077\n",
      "epoch 49; iter: 0; batch classifier loss: 0.088433; batch adversarial loss: 0.557736\n",
      "epoch 50; iter: 0; batch classifier loss: 0.085016; batch adversarial loss: 0.473286\n",
      "epoch 51; iter: 0; batch classifier loss: 0.104911; batch adversarial loss: 0.452159\n",
      "epoch 52; iter: 0; batch classifier loss: 0.175267; batch adversarial loss: 0.402824\n",
      "epoch 53; iter: 0; batch classifier loss: 0.074865; batch adversarial loss: 0.466514\n",
      "epoch 54; iter: 0; batch classifier loss: 0.041904; batch adversarial loss: 0.552931\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087649; batch adversarial loss: 0.358529\n",
      "epoch 56; iter: 0; batch classifier loss: 0.085370; batch adversarial loss: 0.430518\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086064; batch adversarial loss: 0.540927\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090262; batch adversarial loss: 0.361632\n",
      "epoch 59; iter: 0; batch classifier loss: 0.129478; batch adversarial loss: 0.409762\n",
      "epoch 60; iter: 0; batch classifier loss: 0.069545; batch adversarial loss: 0.509341\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074302; batch adversarial loss: 0.524974\n",
      "epoch 62; iter: 0; batch classifier loss: 0.138192; batch adversarial loss: 0.544932\n",
      "epoch 63; iter: 0; batch classifier loss: 0.051768; batch adversarial loss: 0.544936\n",
      "epoch 64; iter: 0; batch classifier loss: 0.038675; batch adversarial loss: 0.445258\n",
      "epoch 65; iter: 0; batch classifier loss: 0.069365; batch adversarial loss: 0.406521\n",
      "epoch 66; iter: 0; batch classifier loss: 0.101520; batch adversarial loss: 0.362868\n",
      "epoch 67; iter: 0; batch classifier loss: 0.092141; batch adversarial loss: 0.506573\n",
      "epoch 68; iter: 0; batch classifier loss: 0.090292; batch adversarial loss: 0.473350\n",
      "epoch 69; iter: 0; batch classifier loss: 0.039770; batch adversarial loss: 0.400886\n",
      "epoch 70; iter: 0; batch classifier loss: 0.051357; batch adversarial loss: 0.472568\n",
      "epoch 71; iter: 0; batch classifier loss: 0.111827; batch adversarial loss: 0.415147\n",
      "epoch 72; iter: 0; batch classifier loss: 0.113118; batch adversarial loss: 0.443557\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062284; batch adversarial loss: 0.407648\n",
      "epoch 74; iter: 0; batch classifier loss: 0.085330; batch adversarial loss: 0.536175\n",
      "epoch 75; iter: 0; batch classifier loss: 0.032896; batch adversarial loss: 0.545541\n",
      "epoch 76; iter: 0; batch classifier loss: 0.073740; batch adversarial loss: 0.480102\n",
      "epoch 77; iter: 0; batch classifier loss: 0.122974; batch adversarial loss: 0.468762\n",
      "epoch 78; iter: 0; batch classifier loss: 0.044221; batch adversarial loss: 0.446045\n",
      "epoch 79; iter: 0; batch classifier loss: 0.033061; batch adversarial loss: 0.543860\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056915; batch adversarial loss: 0.347218\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065952; batch adversarial loss: 0.356105\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071369; batch adversarial loss: 0.487581\n",
      "epoch 83; iter: 0; batch classifier loss: 0.058855; batch adversarial loss: 0.461170\n",
      "epoch 84; iter: 0; batch classifier loss: 0.087668; batch adversarial loss: 0.460614\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059228; batch adversarial loss: 0.361813\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054741; batch adversarial loss: 0.468648\n",
      "epoch 87; iter: 0; batch classifier loss: 0.090574; batch adversarial loss: 0.495379\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067027; batch adversarial loss: 0.517193\n",
      "epoch 89; iter: 0; batch classifier loss: 0.043034; batch adversarial loss: 0.411831\n",
      "epoch 90; iter: 0; batch classifier loss: 0.045797; batch adversarial loss: 0.549440\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067557; batch adversarial loss: 0.473826\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062301; batch adversarial loss: 0.505927\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058714; batch adversarial loss: 0.475131\n",
      "epoch 94; iter: 0; batch classifier loss: 0.095044; batch adversarial loss: 0.503459\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071444; batch adversarial loss: 0.461693\n",
      "epoch 96; iter: 0; batch classifier loss: 0.072662; batch adversarial loss: 0.419517\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056563; batch adversarial loss: 0.453682\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072713; batch adversarial loss: 0.462483\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064270; batch adversarial loss: 0.515376\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065710; batch adversarial loss: 0.351523\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075047; batch adversarial loss: 0.491041\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060182; batch adversarial loss: 0.412222\n",
      "epoch 103; iter: 0; batch classifier loss: 0.028572; batch adversarial loss: 0.441602\n",
      "epoch 104; iter: 0; batch classifier loss: 0.122521; batch adversarial loss: 0.413499\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046476; batch adversarial loss: 0.509689\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033177; batch adversarial loss: 0.383151\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050674; batch adversarial loss: 0.536017\n",
      "epoch 108; iter: 0; batch classifier loss: 0.015570; batch adversarial loss: 0.506841\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033779; batch adversarial loss: 0.540348\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053983; batch adversarial loss: 0.334363\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048281; batch adversarial loss: 0.412313\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051895; batch adversarial loss: 0.417866\n",
      "epoch 113; iter: 0; batch classifier loss: 0.015235; batch adversarial loss: 0.530801\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042051; batch adversarial loss: 0.497514\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027017; batch adversarial loss: 0.454232\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048083; batch adversarial loss: 0.564809\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038265; batch adversarial loss: 0.572936\n",
      "epoch 118; iter: 0; batch classifier loss: 0.013174; batch adversarial loss: 0.472634\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037518; batch adversarial loss: 0.402747\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038516; batch adversarial loss: 0.477113\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025049; batch adversarial loss: 0.490681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.036469; batch adversarial loss: 0.426194\n",
      "epoch 123; iter: 0; batch classifier loss: 0.068412; batch adversarial loss: 0.356800\n",
      "epoch 124; iter: 0; batch classifier loss: 0.028362; batch adversarial loss: 0.474683\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034513; batch adversarial loss: 0.386325\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030046; batch adversarial loss: 0.466557\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025483; batch adversarial loss: 0.467763\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026206; batch adversarial loss: 0.415819\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032727; batch adversarial loss: 0.455763\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041653; batch adversarial loss: 0.457069\n",
      "epoch 131; iter: 0; batch classifier loss: 0.063724; batch adversarial loss: 0.524707\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030128; batch adversarial loss: 0.456661\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034516; batch adversarial loss: 0.480223\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027558; batch adversarial loss: 0.413841\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027631; batch adversarial loss: 0.433894\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035692; batch adversarial loss: 0.529862\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031270; batch adversarial loss: 0.508425\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021910; batch adversarial loss: 0.526184\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023465; batch adversarial loss: 0.412820\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028603; batch adversarial loss: 0.441435\n",
      "epoch 141; iter: 0; batch classifier loss: 0.060333; batch adversarial loss: 0.448823\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024343; batch adversarial loss: 0.437308\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034641; batch adversarial loss: 0.511704\n",
      "epoch 144; iter: 0; batch classifier loss: 0.009640; batch adversarial loss: 0.417604\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031824; batch adversarial loss: 0.544392\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039687; batch adversarial loss: 0.492221\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013784; batch adversarial loss: 0.444433\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023333; batch adversarial loss: 0.429368\n",
      "epoch 149; iter: 0; batch classifier loss: 0.041953; batch adversarial loss: 0.429675\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022936; batch adversarial loss: 0.536515\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032677; batch adversarial loss: 0.468861\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019536; batch adversarial loss: 0.570590\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018866; batch adversarial loss: 0.485004\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027793; batch adversarial loss: 0.398405\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027853; batch adversarial loss: 0.427215\n",
      "epoch 156; iter: 0; batch classifier loss: 0.009217; batch adversarial loss: 0.530415\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027872; batch adversarial loss: 0.576052\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035160; batch adversarial loss: 0.471449\n",
      "epoch 159; iter: 0; batch classifier loss: 0.059173; batch adversarial loss: 0.485387\n",
      "epoch 160; iter: 0; batch classifier loss: 0.049993; batch adversarial loss: 0.380017\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031495; batch adversarial loss: 0.398101\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024532; batch adversarial loss: 0.440772\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013020; batch adversarial loss: 0.433856\n",
      "epoch 164; iter: 0; batch classifier loss: 0.048012; batch adversarial loss: 0.461973\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035329; batch adversarial loss: 0.499395\n",
      "epoch 166; iter: 0; batch classifier loss: 0.054749; batch adversarial loss: 0.558424\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008014; batch adversarial loss: 0.410524\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015600; batch adversarial loss: 0.499040\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037340; batch adversarial loss: 0.508197\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011131; batch adversarial loss: 0.472697\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018538; batch adversarial loss: 0.483021\n",
      "epoch 172; iter: 0; batch classifier loss: 0.045020; batch adversarial loss: 0.453604\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032027; batch adversarial loss: 0.394441\n",
      "epoch 174; iter: 0; batch classifier loss: 0.046045; batch adversarial loss: 0.364445\n",
      "epoch 175; iter: 0; batch classifier loss: 0.076059; batch adversarial loss: 0.385228\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020999; batch adversarial loss: 0.427429\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031981; batch adversarial loss: 0.382295\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029893; batch adversarial loss: 0.466918\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018317; batch adversarial loss: 0.455547\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029528; batch adversarial loss: 0.394515\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028511; batch adversarial loss: 0.378960\n",
      "epoch 182; iter: 0; batch classifier loss: 0.060446; batch adversarial loss: 0.502767\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014272; batch adversarial loss: 0.472383\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032867; batch adversarial loss: 0.455401\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013207; batch adversarial loss: 0.383365\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017628; batch adversarial loss: 0.436906\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015369; batch adversarial loss: 0.408546\n",
      "epoch 188; iter: 0; batch classifier loss: 0.004385; batch adversarial loss: 0.462302\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016236; batch adversarial loss: 0.442966\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025735; batch adversarial loss: 0.477279\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022968; batch adversarial loss: 0.458636\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023461; batch adversarial loss: 0.415250\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021501; batch adversarial loss: 0.470607\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018051; batch adversarial loss: 0.480329\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030629; batch adversarial loss: 0.437650\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020449; batch adversarial loss: 0.413794\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022420; batch adversarial loss: 0.547573\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009648; batch adversarial loss: 0.434684\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007725; batch adversarial loss: 0.555208\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689508; batch adversarial loss: 1.007543\n",
      "epoch 1; iter: 0; batch classifier loss: 0.794948; batch adversarial loss: 1.172512\n",
      "epoch 2; iter: 0; batch classifier loss: 0.883119; batch adversarial loss: 1.115517\n",
      "epoch 3; iter: 0; batch classifier loss: 1.051562; batch adversarial loss: 1.071905\n",
      "epoch 4; iter: 0; batch classifier loss: 1.081131; batch adversarial loss: 0.985663\n",
      "epoch 5; iter: 0; batch classifier loss: 1.077926; batch adversarial loss: 0.916030\n",
      "epoch 6; iter: 0; batch classifier loss: 0.980440; batch adversarial loss: 0.848736\n",
      "epoch 7; iter: 0; batch classifier loss: 0.869123; batch adversarial loss: 0.782113\n",
      "epoch 8; iter: 0; batch classifier loss: 0.705253; batch adversarial loss: 0.674100\n",
      "epoch 9; iter: 0; batch classifier loss: 0.691775; batch adversarial loss: 0.611267\n",
      "epoch 10; iter: 0; batch classifier loss: 0.677594; batch adversarial loss: 0.590204\n",
      "epoch 11; iter: 0; batch classifier loss: 0.463641; batch adversarial loss: 0.618827\n",
      "epoch 12; iter: 0; batch classifier loss: 0.381790; batch adversarial loss: 0.505822\n",
      "epoch 13; iter: 0; batch classifier loss: 0.348915; batch adversarial loss: 0.520716\n",
      "epoch 14; iter: 0; batch classifier loss: 0.288874; batch adversarial loss: 0.546291\n",
      "epoch 15; iter: 0; batch classifier loss: 0.284024; batch adversarial loss: 0.429305\n",
      "epoch 16; iter: 0; batch classifier loss: 0.226123; batch adversarial loss: 0.528386\n",
      "epoch 17; iter: 0; batch classifier loss: 0.277368; batch adversarial loss: 0.496879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.281678; batch adversarial loss: 0.456879\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223655; batch adversarial loss: 0.470552\n",
      "epoch 20; iter: 0; batch classifier loss: 0.241163; batch adversarial loss: 0.452362\n",
      "epoch 21; iter: 0; batch classifier loss: 0.245492; batch adversarial loss: 0.459900\n",
      "epoch 22; iter: 0; batch classifier loss: 0.199745; batch adversarial loss: 0.454595\n",
      "epoch 23; iter: 0; batch classifier loss: 0.206612; batch adversarial loss: 0.441501\n",
      "epoch 24; iter: 0; batch classifier loss: 0.188710; batch adversarial loss: 0.479692\n",
      "epoch 25; iter: 0; batch classifier loss: 0.178734; batch adversarial loss: 0.486672\n",
      "epoch 26; iter: 0; batch classifier loss: 0.167411; batch adversarial loss: 0.504724\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171175; batch adversarial loss: 0.504754\n",
      "epoch 28; iter: 0; batch classifier loss: 0.186325; batch adversarial loss: 0.509333\n",
      "epoch 29; iter: 0; batch classifier loss: 0.154382; batch adversarial loss: 0.469778\n",
      "epoch 30; iter: 0; batch classifier loss: 0.235153; batch adversarial loss: 0.433233\n",
      "epoch 31; iter: 0; batch classifier loss: 0.127866; batch adversarial loss: 0.468584\n",
      "epoch 32; iter: 0; batch classifier loss: 0.184982; batch adversarial loss: 0.491750\n",
      "epoch 33; iter: 0; batch classifier loss: 0.154406; batch adversarial loss: 0.522993\n",
      "epoch 34; iter: 0; batch classifier loss: 0.193791; batch adversarial loss: 0.414897\n",
      "epoch 35; iter: 0; batch classifier loss: 0.144408; batch adversarial loss: 0.460071\n",
      "epoch 36; iter: 0; batch classifier loss: 0.111101; batch adversarial loss: 0.497263\n",
      "epoch 37; iter: 0; batch classifier loss: 0.148830; batch adversarial loss: 0.513757\n",
      "epoch 38; iter: 0; batch classifier loss: 0.164136; batch adversarial loss: 0.490505\n",
      "epoch 39; iter: 0; batch classifier loss: 0.119935; batch adversarial loss: 0.481488\n",
      "epoch 40; iter: 0; batch classifier loss: 0.190688; batch adversarial loss: 0.495210\n",
      "epoch 41; iter: 0; batch classifier loss: 0.188085; batch adversarial loss: 0.491512\n",
      "epoch 42; iter: 0; batch classifier loss: 0.089328; batch adversarial loss: 0.460398\n",
      "epoch 43; iter: 0; batch classifier loss: 0.157412; batch adversarial loss: 0.508834\n",
      "epoch 44; iter: 0; batch classifier loss: 0.097915; batch adversarial loss: 0.373099\n",
      "epoch 45; iter: 0; batch classifier loss: 0.132498; batch adversarial loss: 0.453215\n",
      "epoch 46; iter: 0; batch classifier loss: 0.111695; batch adversarial loss: 0.392515\n",
      "epoch 47; iter: 0; batch classifier loss: 0.159843; batch adversarial loss: 0.377221\n",
      "epoch 48; iter: 0; batch classifier loss: 0.153917; batch adversarial loss: 0.438393\n",
      "epoch 49; iter: 0; batch classifier loss: 0.129580; batch adversarial loss: 0.453297\n",
      "epoch 50; iter: 0; batch classifier loss: 0.104021; batch adversarial loss: 0.520872\n",
      "epoch 51; iter: 0; batch classifier loss: 0.111388; batch adversarial loss: 0.484683\n",
      "epoch 52; iter: 0; batch classifier loss: 0.098960; batch adversarial loss: 0.442039\n",
      "epoch 53; iter: 0; batch classifier loss: 0.129000; batch adversarial loss: 0.367061\n",
      "epoch 54; iter: 0; batch classifier loss: 0.102743; batch adversarial loss: 0.498327\n",
      "epoch 55; iter: 0; batch classifier loss: 0.110087; batch adversarial loss: 0.417645\n",
      "epoch 56; iter: 0; batch classifier loss: 0.118425; batch adversarial loss: 0.487229\n",
      "epoch 57; iter: 0; batch classifier loss: 0.089436; batch adversarial loss: 0.468306\n",
      "epoch 58; iter: 0; batch classifier loss: 0.158556; batch adversarial loss: 0.448949\n",
      "epoch 59; iter: 0; batch classifier loss: 0.095114; batch adversarial loss: 0.515279\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105917; batch adversarial loss: 0.373199\n",
      "epoch 61; iter: 0; batch classifier loss: 0.072986; batch adversarial loss: 0.462685\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081964; batch adversarial loss: 0.501313\n",
      "epoch 63; iter: 0; batch classifier loss: 0.084256; batch adversarial loss: 0.435274\n",
      "epoch 64; iter: 0; batch classifier loss: 0.110419; batch adversarial loss: 0.458095\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122238; batch adversarial loss: 0.442702\n",
      "epoch 66; iter: 0; batch classifier loss: 0.087724; batch adversarial loss: 0.541198\n",
      "epoch 67; iter: 0; batch classifier loss: 0.099195; batch adversarial loss: 0.463731\n",
      "epoch 68; iter: 0; batch classifier loss: 0.089491; batch adversarial loss: 0.424871\n",
      "epoch 69; iter: 0; batch classifier loss: 0.111911; batch adversarial loss: 0.429815\n",
      "epoch 70; iter: 0; batch classifier loss: 0.093754; batch adversarial loss: 0.379909\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092056; batch adversarial loss: 0.439629\n",
      "epoch 72; iter: 0; batch classifier loss: 0.110118; batch adversarial loss: 0.532776\n",
      "epoch 73; iter: 0; batch classifier loss: 0.078272; batch adversarial loss: 0.418112\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075230; batch adversarial loss: 0.302262\n",
      "epoch 75; iter: 0; batch classifier loss: 0.105883; batch adversarial loss: 0.577669\n",
      "epoch 76; iter: 0; batch classifier loss: 0.098416; batch adversarial loss: 0.366534\n",
      "epoch 77; iter: 0; batch classifier loss: 0.057356; batch adversarial loss: 0.494674\n",
      "epoch 78; iter: 0; batch classifier loss: 0.096322; batch adversarial loss: 0.442245\n",
      "epoch 79; iter: 0; batch classifier loss: 0.093930; batch adversarial loss: 0.389776\n",
      "epoch 80; iter: 0; batch classifier loss: 0.079194; batch adversarial loss: 0.425464\n",
      "epoch 81; iter: 0; batch classifier loss: 0.137981; batch adversarial loss: 0.397866\n",
      "epoch 82; iter: 0; batch classifier loss: 0.120421; batch adversarial loss: 0.368625\n",
      "epoch 83; iter: 0; batch classifier loss: 0.046671; batch adversarial loss: 0.496375\n",
      "epoch 84; iter: 0; batch classifier loss: 0.084574; batch adversarial loss: 0.452772\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064474; batch adversarial loss: 0.421447\n",
      "epoch 86; iter: 0; batch classifier loss: 0.080093; batch adversarial loss: 0.465038\n",
      "epoch 87; iter: 0; batch classifier loss: 0.085638; batch adversarial loss: 0.487800\n",
      "epoch 88; iter: 0; batch classifier loss: 0.052461; batch adversarial loss: 0.467180\n",
      "epoch 89; iter: 0; batch classifier loss: 0.091489; batch adversarial loss: 0.409242\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063272; batch adversarial loss: 0.454902\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063810; batch adversarial loss: 0.431774\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064702; batch adversarial loss: 0.387518\n",
      "epoch 93; iter: 0; batch classifier loss: 0.025804; batch adversarial loss: 0.533385\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050681; batch adversarial loss: 0.413138\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073567; batch adversarial loss: 0.406734\n",
      "epoch 96; iter: 0; batch classifier loss: 0.069907; batch adversarial loss: 0.319405\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075459; batch adversarial loss: 0.454260\n",
      "epoch 98; iter: 0; batch classifier loss: 0.076293; batch adversarial loss: 0.441430\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049251; batch adversarial loss: 0.344105\n",
      "epoch 100; iter: 0; batch classifier loss: 0.084234; batch adversarial loss: 0.413284\n",
      "epoch 101; iter: 0; batch classifier loss: 0.085297; batch adversarial loss: 0.410297\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052631; batch adversarial loss: 0.496450\n",
      "epoch 103; iter: 0; batch classifier loss: 0.129339; batch adversarial loss: 0.449131\n",
      "epoch 104; iter: 0; batch classifier loss: 0.072372; batch adversarial loss: 0.463454\n",
      "epoch 105; iter: 0; batch classifier loss: 0.097399; batch adversarial loss: 0.445224\n",
      "epoch 106; iter: 0; batch classifier loss: 0.093081; batch adversarial loss: 0.444477\n",
      "epoch 107; iter: 0; batch classifier loss: 0.094107; batch adversarial loss: 0.408556\n",
      "epoch 108; iter: 0; batch classifier loss: 0.105836; batch adversarial loss: 0.383277\n",
      "epoch 109; iter: 0; batch classifier loss: 0.065379; batch adversarial loss: 0.381720\n",
      "epoch 110; iter: 0; batch classifier loss: 0.085781; batch adversarial loss: 0.460759\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057724; batch adversarial loss: 0.481268\n",
      "epoch 112; iter: 0; batch classifier loss: 0.073290; batch adversarial loss: 0.418050\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038482; batch adversarial loss: 0.381757\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044666; batch adversarial loss: 0.518205\n",
      "epoch 115; iter: 0; batch classifier loss: 0.089286; batch adversarial loss: 0.516676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.058545; batch adversarial loss: 0.417103\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041153; batch adversarial loss: 0.495449\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047612; batch adversarial loss: 0.453432\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042952; batch adversarial loss: 0.431603\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046212; batch adversarial loss: 0.493534\n",
      "epoch 121; iter: 0; batch classifier loss: 0.059615; batch adversarial loss: 0.510626\n",
      "epoch 122; iter: 0; batch classifier loss: 0.056946; batch adversarial loss: 0.449476\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033746; batch adversarial loss: 0.466780\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039981; batch adversarial loss: 0.435851\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049815; batch adversarial loss: 0.501231\n",
      "epoch 126; iter: 0; batch classifier loss: 0.052072; batch adversarial loss: 0.359942\n",
      "epoch 127; iter: 0; batch classifier loss: 0.055087; batch adversarial loss: 0.466180\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023067; batch adversarial loss: 0.386295\n",
      "epoch 129; iter: 0; batch classifier loss: 0.058531; batch adversarial loss: 0.417243\n",
      "epoch 130; iter: 0; batch classifier loss: 0.020372; batch adversarial loss: 0.551686\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034070; batch adversarial loss: 0.434667\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032499; batch adversarial loss: 0.410895\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034426; batch adversarial loss: 0.455765\n",
      "epoch 134; iter: 0; batch classifier loss: 0.057597; batch adversarial loss: 0.465838\n",
      "epoch 135; iter: 0; batch classifier loss: 0.048477; batch adversarial loss: 0.475711\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057467; batch adversarial loss: 0.479842\n",
      "epoch 137; iter: 0; batch classifier loss: 0.062543; batch adversarial loss: 0.317747\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039442; batch adversarial loss: 0.407079\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043587; batch adversarial loss: 0.459646\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034677; batch adversarial loss: 0.406126\n",
      "epoch 141; iter: 0; batch classifier loss: 0.079283; batch adversarial loss: 0.442588\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043913; batch adversarial loss: 0.380916\n",
      "epoch 143; iter: 0; batch classifier loss: 0.065896; batch adversarial loss: 0.444337\n",
      "epoch 144; iter: 0; batch classifier loss: 0.053276; batch adversarial loss: 0.515701\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025346; batch adversarial loss: 0.466542\n",
      "epoch 146; iter: 0; batch classifier loss: 0.057512; batch adversarial loss: 0.362712\n",
      "epoch 147; iter: 0; batch classifier loss: 0.050404; batch adversarial loss: 0.550732\n",
      "epoch 148; iter: 0; batch classifier loss: 0.041142; batch adversarial loss: 0.464905\n",
      "epoch 149; iter: 0; batch classifier loss: 0.049750; batch adversarial loss: 0.370343\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027227; batch adversarial loss: 0.456894\n",
      "epoch 151; iter: 0; batch classifier loss: 0.067835; batch adversarial loss: 0.390706\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017591; batch adversarial loss: 0.438642\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028975; batch adversarial loss: 0.476520\n",
      "epoch 154; iter: 0; batch classifier loss: 0.052102; batch adversarial loss: 0.475144\n",
      "epoch 155; iter: 0; batch classifier loss: 0.047943; batch adversarial loss: 0.467518\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037994; batch adversarial loss: 0.450109\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025681; batch adversarial loss: 0.437740\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027926; batch adversarial loss: 0.365632\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018069; batch adversarial loss: 0.495603\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024465; batch adversarial loss: 0.539664\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038425; batch adversarial loss: 0.402283\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019877; batch adversarial loss: 0.366174\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035289; batch adversarial loss: 0.477973\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025516; batch adversarial loss: 0.511505\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041958; batch adversarial loss: 0.423195\n",
      "epoch 166; iter: 0; batch classifier loss: 0.050280; batch adversarial loss: 0.482947\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039654; batch adversarial loss: 0.419173\n",
      "epoch 168; iter: 0; batch classifier loss: 0.059940; batch adversarial loss: 0.437878\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028203; batch adversarial loss: 0.385060\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020210; batch adversarial loss: 0.503779\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010051; batch adversarial loss: 0.551972\n",
      "epoch 172; iter: 0; batch classifier loss: 0.061952; batch adversarial loss: 0.490004\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020687; batch adversarial loss: 0.395482\n",
      "epoch 174; iter: 0; batch classifier loss: 0.059329; batch adversarial loss: 0.479834\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025572; batch adversarial loss: 0.500768\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028769; batch adversarial loss: 0.468084\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038195; batch adversarial loss: 0.474186\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029307; batch adversarial loss: 0.428840\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027724; batch adversarial loss: 0.465043\n",
      "epoch 180; iter: 0; batch classifier loss: 0.043016; batch adversarial loss: 0.443818\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025865; batch adversarial loss: 0.444051\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027680; batch adversarial loss: 0.564111\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021008; batch adversarial loss: 0.419311\n",
      "epoch 184; iter: 0; batch classifier loss: 0.039337; batch adversarial loss: 0.334456\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017310; batch adversarial loss: 0.439269\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019833; batch adversarial loss: 0.525637\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040656; batch adversarial loss: 0.403286\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029393; batch adversarial loss: 0.404606\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030034; batch adversarial loss: 0.391664\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019898; batch adversarial loss: 0.435303\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018104; batch adversarial loss: 0.295154\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018836; batch adversarial loss: 0.415787\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008323; batch adversarial loss: 0.444695\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032441; batch adversarial loss: 0.378223\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013009; batch adversarial loss: 0.386158\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030586; batch adversarial loss: 0.607879\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018299; batch adversarial loss: 0.404774\n",
      "epoch 198; iter: 0; batch classifier loss: 0.049676; batch adversarial loss: 0.393829\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021167; batch adversarial loss: 0.382709\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694629; batch adversarial loss: 0.743814\n",
      "epoch 1; iter: 0; batch classifier loss: 0.511330; batch adversarial loss: 0.691664\n",
      "epoch 2; iter: 0; batch classifier loss: 0.455212; batch adversarial loss: 0.634431\n",
      "epoch 3; iter: 0; batch classifier loss: 0.339864; batch adversarial loss: 0.621186\n",
      "epoch 4; iter: 0; batch classifier loss: 0.368451; batch adversarial loss: 0.573394\n",
      "epoch 5; iter: 0; batch classifier loss: 0.377496; batch adversarial loss: 0.589853\n",
      "epoch 6; iter: 0; batch classifier loss: 0.338054; batch adversarial loss: 0.554220\n",
      "epoch 7; iter: 0; batch classifier loss: 0.281258; batch adversarial loss: 0.593557\n",
      "epoch 8; iter: 0; batch classifier loss: 0.334511; batch adversarial loss: 0.559589\n",
      "epoch 9; iter: 0; batch classifier loss: 0.396523; batch adversarial loss: 0.516138\n",
      "epoch 10; iter: 0; batch classifier loss: 0.333833; batch adversarial loss: 0.534087\n",
      "epoch 11; iter: 0; batch classifier loss: 0.215626; batch adversarial loss: 0.558651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.406115; batch adversarial loss: 0.492803\n",
      "epoch 13; iter: 0; batch classifier loss: 0.388878; batch adversarial loss: 0.495195\n",
      "epoch 14; iter: 0; batch classifier loss: 0.385794; batch adversarial loss: 0.508375\n",
      "epoch 15; iter: 0; batch classifier loss: 0.271014; batch adversarial loss: 0.487551\n",
      "epoch 16; iter: 0; batch classifier loss: 0.343091; batch adversarial loss: 0.477785\n",
      "epoch 17; iter: 0; batch classifier loss: 0.317227; batch adversarial loss: 0.484444\n",
      "epoch 18; iter: 0; batch classifier loss: 0.256242; batch adversarial loss: 0.508555\n",
      "epoch 19; iter: 0; batch classifier loss: 0.256611; batch adversarial loss: 0.476636\n",
      "epoch 20; iter: 0; batch classifier loss: 0.335397; batch adversarial loss: 0.393156\n",
      "epoch 21; iter: 0; batch classifier loss: 0.323120; batch adversarial loss: 0.538193\n",
      "epoch 22; iter: 0; batch classifier loss: 0.330971; batch adversarial loss: 0.531275\n",
      "epoch 23; iter: 0; batch classifier loss: 0.240489; batch adversarial loss: 0.548974\n",
      "epoch 24; iter: 0; batch classifier loss: 0.253228; batch adversarial loss: 0.534924\n",
      "epoch 25; iter: 0; batch classifier loss: 0.270012; batch adversarial loss: 0.368999\n",
      "epoch 26; iter: 0; batch classifier loss: 0.247015; batch adversarial loss: 0.494829\n",
      "epoch 27; iter: 0; batch classifier loss: 0.270947; batch adversarial loss: 0.468055\n",
      "epoch 28; iter: 0; batch classifier loss: 0.212206; batch adversarial loss: 0.513236\n",
      "epoch 29; iter: 0; batch classifier loss: 0.190669; batch adversarial loss: 0.528097\n",
      "epoch 30; iter: 0; batch classifier loss: 0.224694; batch adversarial loss: 0.497517\n",
      "epoch 31; iter: 0; batch classifier loss: 0.266443; batch adversarial loss: 0.386449\n",
      "epoch 32; iter: 0; batch classifier loss: 0.233079; batch adversarial loss: 0.490209\n",
      "epoch 33; iter: 0; batch classifier loss: 0.219950; batch adversarial loss: 0.445417\n",
      "epoch 34; iter: 0; batch classifier loss: 0.263147; batch adversarial loss: 0.463362\n",
      "epoch 35; iter: 0; batch classifier loss: 0.217361; batch adversarial loss: 0.492403\n",
      "epoch 36; iter: 0; batch classifier loss: 0.180540; batch adversarial loss: 0.607476\n",
      "epoch 37; iter: 0; batch classifier loss: 0.235437; batch adversarial loss: 0.463128\n",
      "epoch 38; iter: 0; batch classifier loss: 0.192217; batch adversarial loss: 0.507185\n",
      "epoch 39; iter: 0; batch classifier loss: 0.276261; batch adversarial loss: 0.565370\n",
      "epoch 40; iter: 0; batch classifier loss: 0.204406; batch adversarial loss: 0.515588\n",
      "epoch 41; iter: 0; batch classifier loss: 0.261105; batch adversarial loss: 0.380401\n",
      "epoch 42; iter: 0; batch classifier loss: 0.157269; batch adversarial loss: 0.480139\n",
      "epoch 43; iter: 0; batch classifier loss: 0.215334; batch adversarial loss: 0.460778\n",
      "epoch 44; iter: 0; batch classifier loss: 0.232868; batch adversarial loss: 0.352805\n",
      "epoch 45; iter: 0; batch classifier loss: 0.229128; batch adversarial loss: 0.390797\n",
      "epoch 46; iter: 0; batch classifier loss: 0.156683; batch adversarial loss: 0.469322\n",
      "epoch 47; iter: 0; batch classifier loss: 0.187827; batch adversarial loss: 0.424887\n",
      "epoch 48; iter: 0; batch classifier loss: 0.195337; batch adversarial loss: 0.408944\n",
      "epoch 49; iter: 0; batch classifier loss: 0.226741; batch adversarial loss: 0.439714\n",
      "epoch 50; iter: 0; batch classifier loss: 0.222185; batch adversarial loss: 0.439429\n",
      "epoch 51; iter: 0; batch classifier loss: 0.277823; batch adversarial loss: 0.462022\n",
      "epoch 52; iter: 0; batch classifier loss: 0.183722; batch adversarial loss: 0.423878\n",
      "epoch 53; iter: 0; batch classifier loss: 0.249301; batch adversarial loss: 0.493627\n",
      "epoch 54; iter: 0; batch classifier loss: 0.195727; batch adversarial loss: 0.410744\n",
      "epoch 55; iter: 0; batch classifier loss: 0.148176; batch adversarial loss: 0.495134\n",
      "epoch 56; iter: 0; batch classifier loss: 0.301758; batch adversarial loss: 0.387594\n",
      "epoch 57; iter: 0; batch classifier loss: 0.196939; batch adversarial loss: 0.446818\n",
      "epoch 58; iter: 0; batch classifier loss: 0.162582; batch adversarial loss: 0.531039\n",
      "epoch 59; iter: 0; batch classifier loss: 0.188116; batch adversarial loss: 0.399345\n",
      "epoch 60; iter: 0; batch classifier loss: 0.271638; batch adversarial loss: 0.530784\n",
      "epoch 61; iter: 0; batch classifier loss: 0.141859; batch adversarial loss: 0.470586\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090472; batch adversarial loss: 0.443259\n",
      "epoch 63; iter: 0; batch classifier loss: 0.118812; batch adversarial loss: 0.517386\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078259; batch adversarial loss: 0.480712\n",
      "epoch 65; iter: 0; batch classifier loss: 0.125288; batch adversarial loss: 0.497788\n",
      "epoch 66; iter: 0; batch classifier loss: 0.156428; batch adversarial loss: 0.481825\n",
      "epoch 67; iter: 0; batch classifier loss: 0.180798; batch adversarial loss: 0.490194\n",
      "epoch 68; iter: 0; batch classifier loss: 0.165638; batch adversarial loss: 0.408664\n",
      "epoch 69; iter: 0; batch classifier loss: 0.128925; batch adversarial loss: 0.533070\n",
      "epoch 70; iter: 0; batch classifier loss: 0.137576; batch adversarial loss: 0.469446\n",
      "epoch 71; iter: 0; batch classifier loss: 0.112639; batch adversarial loss: 0.528378\n",
      "epoch 72; iter: 0; batch classifier loss: 0.156775; batch adversarial loss: 0.423598\n",
      "epoch 73; iter: 0; batch classifier loss: 0.150469; batch adversarial loss: 0.407591\n",
      "epoch 74; iter: 0; batch classifier loss: 0.136088; batch adversarial loss: 0.454621\n",
      "epoch 75; iter: 0; batch classifier loss: 0.126416; batch adversarial loss: 0.426860\n",
      "epoch 76; iter: 0; batch classifier loss: 0.178317; batch adversarial loss: 0.431045\n",
      "epoch 77; iter: 0; batch classifier loss: 0.130442; batch adversarial loss: 0.398848\n",
      "epoch 78; iter: 0; batch classifier loss: 0.170893; batch adversarial loss: 0.361277\n",
      "epoch 79; iter: 0; batch classifier loss: 0.099228; batch adversarial loss: 0.551004\n",
      "epoch 80; iter: 0; batch classifier loss: 0.147011; batch adversarial loss: 0.487137\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081989; batch adversarial loss: 0.524774\n",
      "epoch 82; iter: 0; batch classifier loss: 0.088223; batch adversarial loss: 0.433125\n",
      "epoch 83; iter: 0; batch classifier loss: 0.139008; batch adversarial loss: 0.430114\n",
      "epoch 84; iter: 0; batch classifier loss: 0.160409; batch adversarial loss: 0.493141\n",
      "epoch 85; iter: 0; batch classifier loss: 0.122356; batch adversarial loss: 0.507380\n",
      "epoch 86; iter: 0; batch classifier loss: 0.099526; batch adversarial loss: 0.450441\n",
      "epoch 87; iter: 0; batch classifier loss: 0.074909; batch adversarial loss: 0.348290\n",
      "epoch 88; iter: 0; batch classifier loss: 0.087559; batch adversarial loss: 0.387643\n",
      "epoch 89; iter: 0; batch classifier loss: 0.079343; batch adversarial loss: 0.518698\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063768; batch adversarial loss: 0.572500\n",
      "epoch 91; iter: 0; batch classifier loss: 0.100059; batch adversarial loss: 0.461349\n",
      "epoch 92; iter: 0; batch classifier loss: 0.084253; batch adversarial loss: 0.461703\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077786; batch adversarial loss: 0.405295\n",
      "epoch 94; iter: 0; batch classifier loss: 0.096774; batch adversarial loss: 0.558572\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066109; batch adversarial loss: 0.445101\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049853; batch adversarial loss: 0.403724\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050857; batch adversarial loss: 0.389073\n",
      "epoch 98; iter: 0; batch classifier loss: 0.069815; batch adversarial loss: 0.503574\n",
      "epoch 99; iter: 0; batch classifier loss: 0.025726; batch adversarial loss: 0.398269\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044573; batch adversarial loss: 0.515960\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043963; batch adversarial loss: 0.481059\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048141; batch adversarial loss: 0.435811\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049473; batch adversarial loss: 0.408399\n",
      "epoch 104; iter: 0; batch classifier loss: 0.029391; batch adversarial loss: 0.337613\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041931; batch adversarial loss: 0.583674\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044377; batch adversarial loss: 0.418496\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046962; batch adversarial loss: 0.527629\n",
      "epoch 108; iter: 0; batch classifier loss: 0.018868; batch adversarial loss: 0.444227\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054414; batch adversarial loss: 0.401952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.031429; batch adversarial loss: 0.428851\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032756; batch adversarial loss: 0.523180\n",
      "epoch 112; iter: 0; batch classifier loss: 0.060651; batch adversarial loss: 0.413135\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042082; batch adversarial loss: 0.562806\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028244; batch adversarial loss: 0.410084\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063075; batch adversarial loss: 0.459947\n",
      "epoch 116; iter: 0; batch classifier loss: 0.022136; batch adversarial loss: 0.472216\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036987; batch adversarial loss: 0.480305\n",
      "epoch 118; iter: 0; batch classifier loss: 0.062060; batch adversarial loss: 0.522709\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026256; batch adversarial loss: 0.464303\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033128; batch adversarial loss: 0.537391\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045479; batch adversarial loss: 0.464559\n",
      "epoch 122; iter: 0; batch classifier loss: 0.079803; batch adversarial loss: 0.442135\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048395; batch adversarial loss: 0.379134\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027650; batch adversarial loss: 0.524270\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034038; batch adversarial loss: 0.460831\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030731; batch adversarial loss: 0.379308\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060350; batch adversarial loss: 0.483118\n",
      "epoch 128; iter: 0; batch classifier loss: 0.015633; batch adversarial loss: 0.521625\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021972; batch adversarial loss: 0.499141\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022017; batch adversarial loss: 0.485656\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025113; batch adversarial loss: 0.522523\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022924; batch adversarial loss: 0.479358\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028235; batch adversarial loss: 0.425364\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030206; batch adversarial loss: 0.542161\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047382; batch adversarial loss: 0.491238\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026096; batch adversarial loss: 0.563931\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048262; batch adversarial loss: 0.344241\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028347; batch adversarial loss: 0.474777\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013564; batch adversarial loss: 0.431280\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020262; batch adversarial loss: 0.463950\n",
      "epoch 141; iter: 0; batch classifier loss: 0.041745; batch adversarial loss: 0.473317\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018684; batch adversarial loss: 0.447781\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013009; batch adversarial loss: 0.508474\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037795; batch adversarial loss: 0.454953\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024069; batch adversarial loss: 0.415658\n",
      "epoch 146; iter: 0; batch classifier loss: 0.033473; batch adversarial loss: 0.481388\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023816; batch adversarial loss: 0.498201\n",
      "epoch 148; iter: 0; batch classifier loss: 0.052685; batch adversarial loss: 0.544643\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027662; batch adversarial loss: 0.487704\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025314; batch adversarial loss: 0.470826\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034928; batch adversarial loss: 0.461678\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036630; batch adversarial loss: 0.476611\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013231; batch adversarial loss: 0.398102\n",
      "epoch 154; iter: 0; batch classifier loss: 0.042310; batch adversarial loss: 0.424202\n",
      "epoch 155; iter: 0; batch classifier loss: 0.006301; batch adversarial loss: 0.460544\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013779; batch adversarial loss: 0.462943\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014055; batch adversarial loss: 0.444340\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029894; batch adversarial loss: 0.522280\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017901; batch adversarial loss: 0.470098\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015417; batch adversarial loss: 0.472705\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023128; batch adversarial loss: 0.453282\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025648; batch adversarial loss: 0.399116\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026810; batch adversarial loss: 0.503482\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015819; batch adversarial loss: 0.490164\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015841; batch adversarial loss: 0.551075\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035627; batch adversarial loss: 0.376192\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033246; batch adversarial loss: 0.363661\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019881; batch adversarial loss: 0.504785\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022723; batch adversarial loss: 0.480783\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008709; batch adversarial loss: 0.504104\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036418; batch adversarial loss: 0.379683\n",
      "epoch 172; iter: 0; batch classifier loss: 0.053577; batch adversarial loss: 0.389202\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021857; batch adversarial loss: 0.358292\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028679; batch adversarial loss: 0.443722\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010956; batch adversarial loss: 0.495541\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045634; batch adversarial loss: 0.478541\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022171; batch adversarial loss: 0.435215\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011017; batch adversarial loss: 0.480628\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011257; batch adversarial loss: 0.429501\n",
      "epoch 180; iter: 0; batch classifier loss: 0.056221; batch adversarial loss: 0.535365\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017051; batch adversarial loss: 0.437753\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011066; batch adversarial loss: 0.354448\n",
      "epoch 183; iter: 0; batch classifier loss: 0.043513; batch adversarial loss: 0.464279\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014818; batch adversarial loss: 0.445377\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027725; batch adversarial loss: 0.407595\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013797; batch adversarial loss: 0.445441\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017316; batch adversarial loss: 0.456343\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020831; batch adversarial loss: 0.415813\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036480; batch adversarial loss: 0.422935\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026581; batch adversarial loss: 0.452729\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014645; batch adversarial loss: 0.429875\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031997; batch adversarial loss: 0.403100\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009431; batch adversarial loss: 0.368806\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035141; batch adversarial loss: 0.429594\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013752; batch adversarial loss: 0.466145\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014740; batch adversarial loss: 0.467110\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034591; batch adversarial loss: 0.406962\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016215; batch adversarial loss: 0.475527\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010954; batch adversarial loss: 0.455497\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678526; batch adversarial loss: 0.747579\n",
      "epoch 1; iter: 0; batch classifier loss: 0.479482; batch adversarial loss: 0.693736\n",
      "epoch 2; iter: 0; batch classifier loss: 0.422218; batch adversarial loss: 0.665648\n",
      "epoch 3; iter: 0; batch classifier loss: 0.326733; batch adversarial loss: 0.637155\n",
      "epoch 4; iter: 0; batch classifier loss: 0.354166; batch adversarial loss: 0.626993\n",
      "epoch 5; iter: 0; batch classifier loss: 0.325040; batch adversarial loss: 0.565138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.356395; batch adversarial loss: 0.527807\n",
      "epoch 7; iter: 0; batch classifier loss: 0.350280; batch adversarial loss: 0.500476\n",
      "epoch 8; iter: 0; batch classifier loss: 0.237735; batch adversarial loss: 0.501032\n",
      "epoch 9; iter: 0; batch classifier loss: 0.259219; batch adversarial loss: 0.493533\n",
      "epoch 10; iter: 0; batch classifier loss: 0.264232; batch adversarial loss: 0.484291\n",
      "epoch 11; iter: 0; batch classifier loss: 0.183201; batch adversarial loss: 0.414592\n",
      "epoch 12; iter: 0; batch classifier loss: 0.223830; batch adversarial loss: 0.431286\n",
      "epoch 13; iter: 0; batch classifier loss: 0.166262; batch adversarial loss: 0.431484\n",
      "epoch 14; iter: 0; batch classifier loss: 0.237730; batch adversarial loss: 0.506513\n",
      "epoch 15; iter: 0; batch classifier loss: 0.208149; batch adversarial loss: 0.447015\n",
      "epoch 16; iter: 0; batch classifier loss: 0.153099; batch adversarial loss: 0.501104\n",
      "epoch 17; iter: 0; batch classifier loss: 0.128577; batch adversarial loss: 0.515283\n",
      "epoch 18; iter: 0; batch classifier loss: 0.177598; batch adversarial loss: 0.461903\n",
      "epoch 19; iter: 0; batch classifier loss: 0.156884; batch adversarial loss: 0.413489\n",
      "epoch 20; iter: 0; batch classifier loss: 0.109176; batch adversarial loss: 0.461663\n",
      "epoch 21; iter: 0; batch classifier loss: 0.135694; batch adversarial loss: 0.350442\n",
      "epoch 22; iter: 0; batch classifier loss: 0.200518; batch adversarial loss: 0.348802\n",
      "epoch 23; iter: 0; batch classifier loss: 0.111692; batch adversarial loss: 0.381591\n",
      "epoch 24; iter: 0; batch classifier loss: 0.176662; batch adversarial loss: 0.467697\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174267; batch adversarial loss: 0.490013\n",
      "epoch 26; iter: 0; batch classifier loss: 0.149473; batch adversarial loss: 0.449357\n",
      "epoch 27; iter: 0; batch classifier loss: 0.129599; batch adversarial loss: 0.363506\n",
      "epoch 28; iter: 0; batch classifier loss: 0.151979; batch adversarial loss: 0.371660\n",
      "epoch 29; iter: 0; batch classifier loss: 0.225486; batch adversarial loss: 0.402582\n",
      "epoch 30; iter: 0; batch classifier loss: 0.070587; batch adversarial loss: 0.439071\n",
      "epoch 31; iter: 0; batch classifier loss: 0.135127; batch adversarial loss: 0.422091\n",
      "epoch 32; iter: 0; batch classifier loss: 0.134531; batch adversarial loss: 0.424008\n",
      "epoch 33; iter: 0; batch classifier loss: 0.101320; batch adversarial loss: 0.460770\n",
      "epoch 34; iter: 0; batch classifier loss: 0.092206; batch adversarial loss: 0.357308\n",
      "epoch 35; iter: 0; batch classifier loss: 0.097852; batch adversarial loss: 0.396846\n",
      "epoch 36; iter: 0; batch classifier loss: 0.147490; batch adversarial loss: 0.390872\n",
      "epoch 37; iter: 0; batch classifier loss: 0.150237; batch adversarial loss: 0.416667\n",
      "epoch 38; iter: 0; batch classifier loss: 0.124391; batch adversarial loss: 0.295947\n",
      "epoch 39; iter: 0; batch classifier loss: 0.124421; batch adversarial loss: 0.372252\n",
      "epoch 40; iter: 0; batch classifier loss: 0.106488; batch adversarial loss: 0.317772\n",
      "epoch 41; iter: 0; batch classifier loss: 0.128745; batch adversarial loss: 0.531398\n",
      "epoch 42; iter: 0; batch classifier loss: 0.119250; batch adversarial loss: 0.395703\n",
      "epoch 43; iter: 0; batch classifier loss: 0.088487; batch adversarial loss: 0.408224\n",
      "epoch 44; iter: 0; batch classifier loss: 0.093375; batch adversarial loss: 0.429181\n",
      "epoch 45; iter: 0; batch classifier loss: 0.082748; batch adversarial loss: 0.474904\n",
      "epoch 46; iter: 0; batch classifier loss: 0.121132; batch adversarial loss: 0.433115\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100113; batch adversarial loss: 0.476044\n",
      "epoch 48; iter: 0; batch classifier loss: 0.110579; batch adversarial loss: 0.426804\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099452; batch adversarial loss: 0.448923\n",
      "epoch 50; iter: 0; batch classifier loss: 0.106143; batch adversarial loss: 0.381064\n",
      "epoch 51; iter: 0; batch classifier loss: 0.102229; batch adversarial loss: 0.484235\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096167; batch adversarial loss: 0.477223\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096071; batch adversarial loss: 0.396414\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110979; batch adversarial loss: 0.517807\n",
      "epoch 55; iter: 0; batch classifier loss: 0.057304; batch adversarial loss: 0.486772\n",
      "epoch 56; iter: 0; batch classifier loss: 0.133349; batch adversarial loss: 0.475647\n",
      "epoch 57; iter: 0; batch classifier loss: 0.053914; batch adversarial loss: 0.405173\n",
      "epoch 58; iter: 0; batch classifier loss: 0.099894; batch adversarial loss: 0.364396\n",
      "epoch 59; iter: 0; batch classifier loss: 0.074319; batch adversarial loss: 0.374586\n",
      "epoch 60; iter: 0; batch classifier loss: 0.050490; batch adversarial loss: 0.447836\n",
      "epoch 61; iter: 0; batch classifier loss: 0.048880; batch adversarial loss: 0.419195\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093082; batch adversarial loss: 0.567197\n",
      "epoch 63; iter: 0; batch classifier loss: 0.086219; batch adversarial loss: 0.428787\n",
      "epoch 64; iter: 0; batch classifier loss: 0.093156; batch adversarial loss: 0.379531\n",
      "epoch 65; iter: 0; batch classifier loss: 0.080092; batch adversarial loss: 0.450595\n",
      "epoch 66; iter: 0; batch classifier loss: 0.079958; batch adversarial loss: 0.416396\n",
      "epoch 67; iter: 0; batch classifier loss: 0.127765; batch adversarial loss: 0.509492\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082924; batch adversarial loss: 0.479533\n",
      "epoch 69; iter: 0; batch classifier loss: 0.068318; batch adversarial loss: 0.491729\n",
      "epoch 70; iter: 0; batch classifier loss: 0.057819; batch adversarial loss: 0.499161\n",
      "epoch 71; iter: 0; batch classifier loss: 0.048086; batch adversarial loss: 0.357371\n",
      "epoch 72; iter: 0; batch classifier loss: 0.119305; batch adversarial loss: 0.512378\n",
      "epoch 73; iter: 0; batch classifier loss: 0.071353; batch adversarial loss: 0.397714\n",
      "epoch 74; iter: 0; batch classifier loss: 0.064847; batch adversarial loss: 0.429388\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071306; batch adversarial loss: 0.501142\n",
      "epoch 76; iter: 0; batch classifier loss: 0.056526; batch adversarial loss: 0.313563\n",
      "epoch 77; iter: 0; batch classifier loss: 0.085073; batch adversarial loss: 0.388635\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061525; batch adversarial loss: 0.326978\n",
      "epoch 79; iter: 0; batch classifier loss: 0.069662; batch adversarial loss: 0.392773\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056362; batch adversarial loss: 0.364170\n",
      "epoch 81; iter: 0; batch classifier loss: 0.089081; batch adversarial loss: 0.432097\n",
      "epoch 82; iter: 0; batch classifier loss: 0.077253; batch adversarial loss: 0.418980\n",
      "epoch 83; iter: 0; batch classifier loss: 0.067400; batch adversarial loss: 0.375816\n",
      "epoch 84; iter: 0; batch classifier loss: 0.145429; batch adversarial loss: 0.496528\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077436; batch adversarial loss: 0.414497\n",
      "epoch 86; iter: 0; batch classifier loss: 0.045955; batch adversarial loss: 0.511580\n",
      "epoch 87; iter: 0; batch classifier loss: 0.103662; batch adversarial loss: 0.434110\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059081; batch adversarial loss: 0.424768\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065360; batch adversarial loss: 0.332069\n",
      "epoch 90; iter: 0; batch classifier loss: 0.046144; batch adversarial loss: 0.418447\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077049; batch adversarial loss: 0.450029\n",
      "epoch 92; iter: 0; batch classifier loss: 0.075002; batch adversarial loss: 0.358605\n",
      "epoch 93; iter: 0; batch classifier loss: 0.096931; batch adversarial loss: 0.375765\n",
      "epoch 94; iter: 0; batch classifier loss: 0.071869; batch adversarial loss: 0.339424\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064390; batch adversarial loss: 0.387799\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047673; batch adversarial loss: 0.514337\n",
      "epoch 97; iter: 0; batch classifier loss: 0.104787; batch adversarial loss: 0.502672\n",
      "epoch 98; iter: 0; batch classifier loss: 0.082930; batch adversarial loss: 0.456524\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052583; batch adversarial loss: 0.392504\n",
      "epoch 100; iter: 0; batch classifier loss: 0.069372; batch adversarial loss: 0.486867\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054235; batch adversarial loss: 0.447469\n",
      "epoch 102; iter: 0; batch classifier loss: 0.072706; batch adversarial loss: 0.377739\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055806; batch adversarial loss: 0.451836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.045773; batch adversarial loss: 0.431730\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061562; batch adversarial loss: 0.487447\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053349; batch adversarial loss: 0.481741\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040824; batch adversarial loss: 0.425341\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057031; batch adversarial loss: 0.523267\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046805; batch adversarial loss: 0.465141\n",
      "epoch 110; iter: 0; batch classifier loss: 0.034112; batch adversarial loss: 0.442507\n",
      "epoch 111; iter: 0; batch classifier loss: 0.023933; batch adversarial loss: 0.436868\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040584; batch adversarial loss: 0.409958\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027855; batch adversarial loss: 0.471740\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030504; batch adversarial loss: 0.426816\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029767; batch adversarial loss: 0.457727\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039212; batch adversarial loss: 0.525279\n",
      "epoch 117; iter: 0; batch classifier loss: 0.019609; batch adversarial loss: 0.423916\n",
      "epoch 118; iter: 0; batch classifier loss: 0.017547; batch adversarial loss: 0.534615\n",
      "epoch 119; iter: 0; batch classifier loss: 0.017464; batch adversarial loss: 0.447739\n",
      "epoch 120; iter: 0; batch classifier loss: 0.024205; batch adversarial loss: 0.419538\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024922; batch adversarial loss: 0.555009\n",
      "epoch 122; iter: 0; batch classifier loss: 0.022901; batch adversarial loss: 0.443081\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024425; batch adversarial loss: 0.500961\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032488; batch adversarial loss: 0.461651\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036368; batch adversarial loss: 0.440623\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031323; batch adversarial loss: 0.391057\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031679; batch adversarial loss: 0.462916\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033699; batch adversarial loss: 0.509872\n",
      "epoch 129; iter: 0; batch classifier loss: 0.061981; batch adversarial loss: 0.481317\n",
      "epoch 130; iter: 0; batch classifier loss: 0.052581; batch adversarial loss: 0.467419\n",
      "epoch 131; iter: 0; batch classifier loss: 0.058259; batch adversarial loss: 0.527882\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046364; batch adversarial loss: 0.362606\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049897; batch adversarial loss: 0.566243\n",
      "epoch 134; iter: 0; batch classifier loss: 0.081303; batch adversarial loss: 0.506891\n",
      "epoch 135; iter: 0; batch classifier loss: 0.114517; batch adversarial loss: 0.652585\n",
      "epoch 136; iter: 0; batch classifier loss: 0.081999; batch adversarial loss: 0.439833\n",
      "epoch 137; iter: 0; batch classifier loss: 0.119150; batch adversarial loss: 0.661763\n",
      "epoch 138; iter: 0; batch classifier loss: 0.106257; batch adversarial loss: 0.511272\n",
      "epoch 139; iter: 0; batch classifier loss: 0.071371; batch adversarial loss: 0.584846\n",
      "epoch 140; iter: 0; batch classifier loss: 0.068141; batch adversarial loss: 0.581950\n",
      "epoch 141; iter: 0; batch classifier loss: 0.063752; batch adversarial loss: 0.499793\n",
      "epoch 142; iter: 0; batch classifier loss: 0.123258; batch adversarial loss: 0.595613\n",
      "epoch 143; iter: 0; batch classifier loss: 0.081449; batch adversarial loss: 0.470161\n",
      "epoch 144; iter: 0; batch classifier loss: 0.134463; batch adversarial loss: 0.612105\n",
      "epoch 145; iter: 0; batch classifier loss: 0.099742; batch adversarial loss: 0.547630\n",
      "epoch 146; iter: 0; batch classifier loss: 0.101474; batch adversarial loss: 0.530310\n",
      "epoch 147; iter: 0; batch classifier loss: 0.150105; batch adversarial loss: 0.517994\n",
      "epoch 148; iter: 0; batch classifier loss: 0.108996; batch adversarial loss: 0.523540\n",
      "epoch 149; iter: 0; batch classifier loss: 0.101898; batch adversarial loss: 0.565605\n",
      "epoch 150; iter: 0; batch classifier loss: 0.096376; batch adversarial loss: 0.535693\n",
      "epoch 151; iter: 0; batch classifier loss: 0.099946; batch adversarial loss: 0.480869\n",
      "epoch 152; iter: 0; batch classifier loss: 0.061944; batch adversarial loss: 0.457266\n",
      "epoch 153; iter: 0; batch classifier loss: 0.073298; batch adversarial loss: 0.525892\n",
      "epoch 154; iter: 0; batch classifier loss: 0.096010; batch adversarial loss: 0.545518\n",
      "epoch 155; iter: 0; batch classifier loss: 0.091232; batch adversarial loss: 0.518362\n",
      "epoch 156; iter: 0; batch classifier loss: 0.109042; batch adversarial loss: 0.534017\n",
      "epoch 157; iter: 0; batch classifier loss: 0.060543; batch adversarial loss: 0.424710\n",
      "epoch 158; iter: 0; batch classifier loss: 0.128960; batch adversarial loss: 0.483898\n",
      "epoch 159; iter: 0; batch classifier loss: 0.124384; batch adversarial loss: 0.502470\n",
      "epoch 160; iter: 0; batch classifier loss: 0.117242; batch adversarial loss: 0.480846\n",
      "epoch 161; iter: 0; batch classifier loss: 0.050305; batch adversarial loss: 0.497049\n",
      "epoch 162; iter: 0; batch classifier loss: 0.081925; batch adversarial loss: 0.434016\n",
      "epoch 163; iter: 0; batch classifier loss: 0.088304; batch adversarial loss: 0.441860\n",
      "epoch 164; iter: 0; batch classifier loss: 0.078084; batch adversarial loss: 0.485015\n",
      "epoch 165; iter: 0; batch classifier loss: 0.062569; batch adversarial loss: 0.458155\n",
      "epoch 166; iter: 0; batch classifier loss: 0.122714; batch adversarial loss: 0.552105\n",
      "epoch 167; iter: 0; batch classifier loss: 0.099906; batch adversarial loss: 0.434603\n",
      "epoch 168; iter: 0; batch classifier loss: 0.083900; batch adversarial loss: 0.447001\n",
      "epoch 169; iter: 0; batch classifier loss: 0.126803; batch adversarial loss: 0.471704\n",
      "epoch 170; iter: 0; batch classifier loss: 0.064607; batch adversarial loss: 0.433717\n",
      "epoch 171; iter: 0; batch classifier loss: 0.081868; batch adversarial loss: 0.418885\n",
      "epoch 172; iter: 0; batch classifier loss: 0.061762; batch adversarial loss: 0.391568\n",
      "epoch 173; iter: 0; batch classifier loss: 0.066547; batch adversarial loss: 0.463061\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035023; batch adversarial loss: 0.413575\n",
      "epoch 175; iter: 0; batch classifier loss: 0.075596; batch adversarial loss: 0.435153\n",
      "epoch 176; iter: 0; batch classifier loss: 0.060687; batch adversarial loss: 0.511738\n",
      "epoch 177; iter: 0; batch classifier loss: 0.093758; batch adversarial loss: 0.419821\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039824; batch adversarial loss: 0.387123\n",
      "epoch 179; iter: 0; batch classifier loss: 0.056740; batch adversarial loss: 0.458285\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040127; batch adversarial loss: 0.432914\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022874; batch adversarial loss: 0.530402\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031599; batch adversarial loss: 0.439659\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021758; batch adversarial loss: 0.490916\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018241; batch adversarial loss: 0.559659\n",
      "epoch 185; iter: 0; batch classifier loss: 0.058133; batch adversarial loss: 0.489425\n",
      "epoch 186; iter: 0; batch classifier loss: 0.048758; batch adversarial loss: 0.370397\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025008; batch adversarial loss: 0.489794\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031593; batch adversarial loss: 0.430256\n",
      "epoch 189; iter: 0; batch classifier loss: 0.057647; batch adversarial loss: 0.437310\n",
      "epoch 190; iter: 0; batch classifier loss: 0.047340; batch adversarial loss: 0.615216\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025056; batch adversarial loss: 0.480723\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016828; batch adversarial loss: 0.499593\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037822; batch adversarial loss: 0.471027\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030124; batch adversarial loss: 0.565986\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025743; batch adversarial loss: 0.428385\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020379; batch adversarial loss: 0.564879\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016823; batch adversarial loss: 0.458620\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023332; batch adversarial loss: 0.458306\n",
      "epoch 199; iter: 0; batch classifier loss: 0.041546; batch adversarial loss: 0.510388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.692801; batch adversarial loss: 0.769798\n",
      "epoch 1; iter: 0; batch classifier loss: 0.533657; batch adversarial loss: 0.734007\n",
      "epoch 2; iter: 0; batch classifier loss: 0.538803; batch adversarial loss: 0.683816\n",
      "epoch 3; iter: 0; batch classifier loss: 0.549552; batch adversarial loss: 0.632881\n",
      "epoch 4; iter: 0; batch classifier loss: 0.367934; batch adversarial loss: 0.587206\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387798; batch adversarial loss: 0.622884\n",
      "epoch 6; iter: 0; batch classifier loss: 0.358810; batch adversarial loss: 0.554615\n",
      "epoch 7; iter: 0; batch classifier loss: 0.334230; batch adversarial loss: 0.567592\n",
      "epoch 8; iter: 0; batch classifier loss: 0.339279; batch adversarial loss: 0.542591\n",
      "epoch 9; iter: 0; batch classifier loss: 0.300300; batch adversarial loss: 0.552649\n",
      "epoch 10; iter: 0; batch classifier loss: 0.283715; batch adversarial loss: 0.568062\n",
      "epoch 11; iter: 0; batch classifier loss: 0.301324; batch adversarial loss: 0.575138\n",
      "epoch 12; iter: 0; batch classifier loss: 0.388177; batch adversarial loss: 0.484298\n",
      "epoch 13; iter: 0; batch classifier loss: 0.239172; batch adversarial loss: 0.469559\n",
      "epoch 14; iter: 0; batch classifier loss: 0.359532; batch adversarial loss: 0.474360\n",
      "epoch 15; iter: 0; batch classifier loss: 0.288998; batch adversarial loss: 0.561689\n",
      "epoch 16; iter: 0; batch classifier loss: 0.250380; batch adversarial loss: 0.504933\n",
      "epoch 17; iter: 0; batch classifier loss: 0.319829; batch adversarial loss: 0.503671\n",
      "epoch 18; iter: 0; batch classifier loss: 0.317958; batch adversarial loss: 0.532457\n",
      "epoch 19; iter: 0; batch classifier loss: 0.277612; batch adversarial loss: 0.434812\n",
      "epoch 20; iter: 0; batch classifier loss: 0.199037; batch adversarial loss: 0.475691\n",
      "epoch 21; iter: 0; batch classifier loss: 0.291695; batch adversarial loss: 0.457569\n",
      "epoch 22; iter: 0; batch classifier loss: 0.296205; batch adversarial loss: 0.469479\n",
      "epoch 23; iter: 0; batch classifier loss: 0.279937; batch adversarial loss: 0.438338\n",
      "epoch 24; iter: 0; batch classifier loss: 0.180547; batch adversarial loss: 0.448300\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215421; batch adversarial loss: 0.410140\n",
      "epoch 26; iter: 0; batch classifier loss: 0.247247; batch adversarial loss: 0.461978\n",
      "epoch 27; iter: 0; batch classifier loss: 0.230556; batch adversarial loss: 0.512774\n",
      "epoch 28; iter: 0; batch classifier loss: 0.242881; batch adversarial loss: 0.454398\n",
      "epoch 29; iter: 0; batch classifier loss: 0.202992; batch adversarial loss: 0.478954\n",
      "epoch 30; iter: 0; batch classifier loss: 0.171640; batch adversarial loss: 0.360730\n",
      "epoch 31; iter: 0; batch classifier loss: 0.262421; batch adversarial loss: 0.465643\n",
      "epoch 32; iter: 0; batch classifier loss: 0.191496; batch adversarial loss: 0.443115\n",
      "epoch 33; iter: 0; batch classifier loss: 0.224987; batch adversarial loss: 0.475192\n",
      "epoch 34; iter: 0; batch classifier loss: 0.207194; batch adversarial loss: 0.510845\n",
      "epoch 35; iter: 0; batch classifier loss: 0.170031; batch adversarial loss: 0.428687\n",
      "epoch 36; iter: 0; batch classifier loss: 0.170684; batch adversarial loss: 0.486656\n",
      "epoch 37; iter: 0; batch classifier loss: 0.244503; batch adversarial loss: 0.465335\n",
      "epoch 38; iter: 0; batch classifier loss: 0.161865; batch adversarial loss: 0.464059\n",
      "epoch 39; iter: 0; batch classifier loss: 0.186386; batch adversarial loss: 0.413824\n",
      "epoch 40; iter: 0; batch classifier loss: 0.155154; batch adversarial loss: 0.467112\n",
      "epoch 41; iter: 0; batch classifier loss: 0.173593; batch adversarial loss: 0.603226\n",
      "epoch 42; iter: 0; batch classifier loss: 0.118835; batch adversarial loss: 0.564615\n",
      "epoch 43; iter: 0; batch classifier loss: 0.198354; batch adversarial loss: 0.394749\n",
      "epoch 44; iter: 0; batch classifier loss: 0.156792; batch adversarial loss: 0.380704\n",
      "epoch 45; iter: 0; batch classifier loss: 0.171512; batch adversarial loss: 0.396794\n",
      "epoch 46; iter: 0; batch classifier loss: 0.119443; batch adversarial loss: 0.415994\n",
      "epoch 47; iter: 0; batch classifier loss: 0.118575; batch adversarial loss: 0.465601\n",
      "epoch 48; iter: 0; batch classifier loss: 0.162647; batch adversarial loss: 0.452122\n",
      "epoch 49; iter: 0; batch classifier loss: 0.111387; batch adversarial loss: 0.552815\n",
      "epoch 50; iter: 0; batch classifier loss: 0.138848; batch adversarial loss: 0.518170\n",
      "epoch 51; iter: 0; batch classifier loss: 0.111486; batch adversarial loss: 0.529730\n",
      "epoch 52; iter: 0; batch classifier loss: 0.143774; batch adversarial loss: 0.398965\n",
      "epoch 53; iter: 0; batch classifier loss: 0.175745; batch adversarial loss: 0.491252\n",
      "epoch 54; iter: 0; batch classifier loss: 0.104207; batch adversarial loss: 0.472194\n",
      "epoch 55; iter: 0; batch classifier loss: 0.115965; batch adversarial loss: 0.490576\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098228; batch adversarial loss: 0.516916\n",
      "epoch 57; iter: 0; batch classifier loss: 0.156976; batch adversarial loss: 0.414783\n",
      "epoch 58; iter: 0; batch classifier loss: 0.122177; batch adversarial loss: 0.476245\n",
      "epoch 59; iter: 0; batch classifier loss: 0.177815; batch adversarial loss: 0.441937\n",
      "epoch 60; iter: 0; batch classifier loss: 0.059792; batch adversarial loss: 0.457301\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103199; batch adversarial loss: 0.419703\n",
      "epoch 62; iter: 0; batch classifier loss: 0.100422; batch adversarial loss: 0.401233\n",
      "epoch 63; iter: 0; batch classifier loss: 0.110451; batch adversarial loss: 0.379032\n",
      "epoch 64; iter: 0; batch classifier loss: 0.081838; batch adversarial loss: 0.443034\n",
      "epoch 65; iter: 0; batch classifier loss: 0.093933; batch adversarial loss: 0.446436\n",
      "epoch 66; iter: 0; batch classifier loss: 0.082985; batch adversarial loss: 0.456693\n",
      "epoch 67; iter: 0; batch classifier loss: 0.135216; batch adversarial loss: 0.517696\n",
      "epoch 68; iter: 0; batch classifier loss: 0.119555; batch adversarial loss: 0.370002\n",
      "epoch 69; iter: 0; batch classifier loss: 0.113137; batch adversarial loss: 0.313342\n",
      "epoch 70; iter: 0; batch classifier loss: 0.081523; batch adversarial loss: 0.491508\n",
      "epoch 71; iter: 0; batch classifier loss: 0.119205; batch adversarial loss: 0.526819\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082238; batch adversarial loss: 0.622021\n",
      "epoch 73; iter: 0; batch classifier loss: 0.122462; batch adversarial loss: 0.377859\n",
      "epoch 74; iter: 0; batch classifier loss: 0.078654; batch adversarial loss: 0.466712\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077154; batch adversarial loss: 0.473591\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083198; batch adversarial loss: 0.535438\n",
      "epoch 77; iter: 0; batch classifier loss: 0.072441; batch adversarial loss: 0.373854\n",
      "epoch 78; iter: 0; batch classifier loss: 0.081863; batch adversarial loss: 0.504262\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074415; batch adversarial loss: 0.399857\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078091; batch adversarial loss: 0.406367\n",
      "epoch 81; iter: 0; batch classifier loss: 0.061781; batch adversarial loss: 0.444728\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046722; batch adversarial loss: 0.415443\n",
      "epoch 83; iter: 0; batch classifier loss: 0.089594; batch adversarial loss: 0.462745\n",
      "epoch 84; iter: 0; batch classifier loss: 0.023453; batch adversarial loss: 0.467158\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052329; batch adversarial loss: 0.377046\n",
      "epoch 86; iter: 0; batch classifier loss: 0.047171; batch adversarial loss: 0.437073\n",
      "epoch 87; iter: 0; batch classifier loss: 0.034581; batch adversarial loss: 0.508496\n",
      "epoch 88; iter: 0; batch classifier loss: 0.039571; batch adversarial loss: 0.456545\n",
      "epoch 89; iter: 0; batch classifier loss: 0.070797; batch adversarial loss: 0.397136\n",
      "epoch 90; iter: 0; batch classifier loss: 0.035690; batch adversarial loss: 0.397749\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073129; batch adversarial loss: 0.493021\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071069; batch adversarial loss: 0.462263\n",
      "epoch 93; iter: 0; batch classifier loss: 0.032885; batch adversarial loss: 0.538221\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039260; batch adversarial loss: 0.509944\n",
      "epoch 95; iter: 0; batch classifier loss: 0.032797; batch adversarial loss: 0.409483\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043260; batch adversarial loss: 0.579191\n",
      "epoch 97; iter: 0; batch classifier loss: 0.041489; batch adversarial loss: 0.506225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.027244; batch adversarial loss: 0.390874\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050460; batch adversarial loss: 0.502015\n",
      "epoch 100; iter: 0; batch classifier loss: 0.033039; batch adversarial loss: 0.461614\n",
      "epoch 101; iter: 0; batch classifier loss: 0.038864; batch adversarial loss: 0.433678\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037555; batch adversarial loss: 0.506391\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043532; batch adversarial loss: 0.370497\n",
      "epoch 104; iter: 0; batch classifier loss: 0.022979; batch adversarial loss: 0.457639\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064131; batch adversarial loss: 0.446800\n",
      "epoch 106; iter: 0; batch classifier loss: 0.078160; batch adversarial loss: 0.388592\n",
      "epoch 107; iter: 0; batch classifier loss: 0.074779; batch adversarial loss: 0.447790\n",
      "epoch 108; iter: 0; batch classifier loss: 0.024757; batch adversarial loss: 0.534963\n",
      "epoch 109; iter: 0; batch classifier loss: 0.065160; batch adversarial loss: 0.435630\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036323; batch adversarial loss: 0.456081\n",
      "epoch 111; iter: 0; batch classifier loss: 0.023343; batch adversarial loss: 0.478896\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026604; batch adversarial loss: 0.386467\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043058; batch adversarial loss: 0.506183\n",
      "epoch 114; iter: 0; batch classifier loss: 0.022056; batch adversarial loss: 0.428591\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036819; batch adversarial loss: 0.372397\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026273; batch adversarial loss: 0.461470\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040201; batch adversarial loss: 0.490497\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036375; batch adversarial loss: 0.451752\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033922; batch adversarial loss: 0.526080\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051717; batch adversarial loss: 0.516781\n",
      "epoch 121; iter: 0; batch classifier loss: 0.019663; batch adversarial loss: 0.468410\n",
      "epoch 122; iter: 0; batch classifier loss: 0.009738; batch adversarial loss: 0.483247\n",
      "epoch 123; iter: 0; batch classifier loss: 0.020277; batch adversarial loss: 0.445517\n",
      "epoch 124; iter: 0; batch classifier loss: 0.013037; batch adversarial loss: 0.429623\n",
      "epoch 125; iter: 0; batch classifier loss: 0.024883; batch adversarial loss: 0.400080\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019370; batch adversarial loss: 0.501895\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023922; batch adversarial loss: 0.469402\n",
      "epoch 128; iter: 0; batch classifier loss: 0.015348; batch adversarial loss: 0.378971\n",
      "epoch 129; iter: 0; batch classifier loss: 0.012098; batch adversarial loss: 0.402330\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032405; batch adversarial loss: 0.399215\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021720; batch adversarial loss: 0.512660\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020220; batch adversarial loss: 0.414416\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023912; batch adversarial loss: 0.485561\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038055; batch adversarial loss: 0.464391\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011017; batch adversarial loss: 0.423165\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024506; batch adversarial loss: 0.501426\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020888; batch adversarial loss: 0.461052\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011375; batch adversarial loss: 0.475385\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044449; batch adversarial loss: 0.412975\n",
      "epoch 140; iter: 0; batch classifier loss: 0.008568; batch adversarial loss: 0.414118\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024887; batch adversarial loss: 0.537336\n",
      "epoch 142; iter: 0; batch classifier loss: 0.015794; batch adversarial loss: 0.447504\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036916; batch adversarial loss: 0.545943\n",
      "epoch 144; iter: 0; batch classifier loss: 0.044640; batch adversarial loss: 0.389789\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030520; batch adversarial loss: 0.382041\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017114; batch adversarial loss: 0.447345\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046303; batch adversarial loss: 0.453043\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016335; batch adversarial loss: 0.459448\n",
      "epoch 149; iter: 0; batch classifier loss: 0.005402; batch adversarial loss: 0.466910\n",
      "epoch 150; iter: 0; batch classifier loss: 0.056292; batch adversarial loss: 0.472285\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028376; batch adversarial loss: 0.391044\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016286; batch adversarial loss: 0.418977\n",
      "epoch 153; iter: 0; batch classifier loss: 0.007622; batch adversarial loss: 0.485200\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020940; batch adversarial loss: 0.567777\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016614; batch adversarial loss: 0.402532\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014817; batch adversarial loss: 0.508392\n",
      "epoch 157; iter: 0; batch classifier loss: 0.008281; batch adversarial loss: 0.412418\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020126; batch adversarial loss: 0.419246\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034659; batch adversarial loss: 0.541610\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024319; batch adversarial loss: 0.456740\n",
      "epoch 161; iter: 0; batch classifier loss: 0.005527; batch adversarial loss: 0.487998\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018666; batch adversarial loss: 0.533422\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012485; batch adversarial loss: 0.458982\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015631; batch adversarial loss: 0.493499\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019773; batch adversarial loss: 0.451114\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016195; batch adversarial loss: 0.508869\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021030; batch adversarial loss: 0.486001\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017511; batch adversarial loss: 0.392391\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014495; batch adversarial loss: 0.358099\n",
      "epoch 170; iter: 0; batch classifier loss: 0.006447; batch adversarial loss: 0.566491\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028203; batch adversarial loss: 0.518698\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011488; batch adversarial loss: 0.595035\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016834; batch adversarial loss: 0.474477\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018705; batch adversarial loss: 0.438243\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025123; batch adversarial loss: 0.429697\n",
      "epoch 176; iter: 0; batch classifier loss: 0.038169; batch adversarial loss: 0.379357\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006523; batch adversarial loss: 0.396071\n",
      "epoch 178; iter: 0; batch classifier loss: 0.003599; batch adversarial loss: 0.390130\n",
      "epoch 179; iter: 0; batch classifier loss: 0.049224; batch adversarial loss: 0.388315\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037355; batch adversarial loss: 0.495576\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010956; batch adversarial loss: 0.358814\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029456; batch adversarial loss: 0.476364\n",
      "epoch 183; iter: 0; batch classifier loss: 0.004332; batch adversarial loss: 0.462146\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020015; batch adversarial loss: 0.494760\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019231; batch adversarial loss: 0.363889\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016152; batch adversarial loss: 0.475522\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013522; batch adversarial loss: 0.434437\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006582; batch adversarial loss: 0.481430\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010823; batch adversarial loss: 0.401980\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012097; batch adversarial loss: 0.394516\n",
      "epoch 191; iter: 0; batch classifier loss: 0.003763; batch adversarial loss: 0.465587\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014584; batch adversarial loss: 0.463628\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021161; batch adversarial loss: 0.449807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.008216; batch adversarial loss: 0.450674\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012999; batch adversarial loss: 0.562569\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009425; batch adversarial loss: 0.493394\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020344; batch adversarial loss: 0.376269\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007228; batch adversarial loss: 0.439936\n",
      "epoch 199; iter: 0; batch classifier loss: 0.002951; batch adversarial loss: 0.362726\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711272; batch adversarial loss: 0.589320\n",
      "epoch 1; iter: 0; batch classifier loss: 0.370509; batch adversarial loss: 0.587638\n",
      "epoch 2; iter: 0; batch classifier loss: 0.385664; batch adversarial loss: 0.564430\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374882; batch adversarial loss: 0.644690\n",
      "epoch 4; iter: 0; batch classifier loss: 0.400625; batch adversarial loss: 0.588714\n",
      "epoch 5; iter: 0; batch classifier loss: 0.409039; batch adversarial loss: 0.542799\n",
      "epoch 6; iter: 0; batch classifier loss: 0.335654; batch adversarial loss: 0.560717\n",
      "epoch 7; iter: 0; batch classifier loss: 0.342124; batch adversarial loss: 0.498644\n",
      "epoch 8; iter: 0; batch classifier loss: 0.388090; batch adversarial loss: 0.565201\n",
      "epoch 9; iter: 0; batch classifier loss: 0.420372; batch adversarial loss: 0.525306\n",
      "epoch 10; iter: 0; batch classifier loss: 0.411878; batch adversarial loss: 0.489632\n",
      "epoch 11; iter: 0; batch classifier loss: 0.464333; batch adversarial loss: 0.573085\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511774; batch adversarial loss: 0.567190\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486101; batch adversarial loss: 0.503442\n",
      "epoch 14; iter: 0; batch classifier loss: 0.394179; batch adversarial loss: 0.468697\n",
      "epoch 15; iter: 0; batch classifier loss: 0.291335; batch adversarial loss: 0.478760\n",
      "epoch 16; iter: 0; batch classifier loss: 0.274579; batch adversarial loss: 0.472981\n",
      "epoch 17; iter: 0; batch classifier loss: 0.250988; batch adversarial loss: 0.554194\n",
      "epoch 18; iter: 0; batch classifier loss: 0.244160; batch adversarial loss: 0.479966\n",
      "epoch 19; iter: 0; batch classifier loss: 0.212876; batch adversarial loss: 0.404983\n",
      "epoch 20; iter: 0; batch classifier loss: 0.303120; batch adversarial loss: 0.537966\n",
      "epoch 21; iter: 0; batch classifier loss: 0.221308; batch adversarial loss: 0.443140\n",
      "epoch 22; iter: 0; batch classifier loss: 0.199417; batch adversarial loss: 0.495932\n",
      "epoch 23; iter: 0; batch classifier loss: 0.314587; batch adversarial loss: 0.467868\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195607; batch adversarial loss: 0.395816\n",
      "epoch 25; iter: 0; batch classifier loss: 0.207898; batch adversarial loss: 0.376899\n",
      "epoch 26; iter: 0; batch classifier loss: 0.173219; batch adversarial loss: 0.405736\n",
      "epoch 27; iter: 0; batch classifier loss: 0.160111; batch adversarial loss: 0.462177\n",
      "epoch 28; iter: 0; batch classifier loss: 0.142103; batch adversarial loss: 0.526077\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178655; batch adversarial loss: 0.454307\n",
      "epoch 30; iter: 0; batch classifier loss: 0.200576; batch adversarial loss: 0.455310\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178879; batch adversarial loss: 0.437163\n",
      "epoch 32; iter: 0; batch classifier loss: 0.105498; batch adversarial loss: 0.493024\n",
      "epoch 33; iter: 0; batch classifier loss: 0.108515; batch adversarial loss: 0.441449\n",
      "epoch 34; iter: 0; batch classifier loss: 0.149864; batch adversarial loss: 0.469123\n",
      "epoch 35; iter: 0; batch classifier loss: 0.181842; batch adversarial loss: 0.403886\n",
      "epoch 36; iter: 0; batch classifier loss: 0.120877; batch adversarial loss: 0.408879\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111612; batch adversarial loss: 0.440343\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107820; batch adversarial loss: 0.477392\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107680; batch adversarial loss: 0.433034\n",
      "epoch 40; iter: 0; batch classifier loss: 0.137664; batch adversarial loss: 0.490374\n",
      "epoch 41; iter: 0; batch classifier loss: 0.158764; batch adversarial loss: 0.448100\n",
      "epoch 42; iter: 0; batch classifier loss: 0.079714; batch adversarial loss: 0.456938\n",
      "epoch 43; iter: 0; batch classifier loss: 0.183694; batch adversarial loss: 0.415313\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127249; batch adversarial loss: 0.400944\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108927; batch adversarial loss: 0.559907\n",
      "epoch 46; iter: 0; batch classifier loss: 0.194684; batch adversarial loss: 0.348691\n",
      "epoch 47; iter: 0; batch classifier loss: 0.243050; batch adversarial loss: 0.464478\n",
      "epoch 48; iter: 0; batch classifier loss: 0.224551; batch adversarial loss: 0.467001\n",
      "epoch 49; iter: 0; batch classifier loss: 0.180933; batch adversarial loss: 0.481754\n",
      "epoch 50; iter: 0; batch classifier loss: 0.152821; batch adversarial loss: 0.446404\n",
      "epoch 51; iter: 0; batch classifier loss: 0.156368; batch adversarial loss: 0.471612\n",
      "epoch 52; iter: 0; batch classifier loss: 0.117046; batch adversarial loss: 0.494660\n",
      "epoch 53; iter: 0; batch classifier loss: 0.159200; batch adversarial loss: 0.369667\n",
      "epoch 54; iter: 0; batch classifier loss: 0.181606; batch adversarial loss: 0.524158\n",
      "epoch 55; iter: 0; batch classifier loss: 0.115433; batch adversarial loss: 0.422867\n",
      "epoch 56; iter: 0; batch classifier loss: 0.213960; batch adversarial loss: 0.373997\n",
      "epoch 57; iter: 0; batch classifier loss: 0.151165; batch adversarial loss: 0.483902\n",
      "epoch 58; iter: 0; batch classifier loss: 0.177382; batch adversarial loss: 0.433710\n",
      "epoch 59; iter: 0; batch classifier loss: 0.165864; batch adversarial loss: 0.495907\n",
      "epoch 60; iter: 0; batch classifier loss: 0.264016; batch adversarial loss: 0.362566\n",
      "epoch 61; iter: 0; batch classifier loss: 0.193487; batch adversarial loss: 0.412467\n",
      "epoch 62; iter: 0; batch classifier loss: 0.172254; batch adversarial loss: 0.422453\n",
      "epoch 63; iter: 0; batch classifier loss: 0.137750; batch adversarial loss: 0.461334\n",
      "epoch 64; iter: 0; batch classifier loss: 0.177230; batch adversarial loss: 0.460339\n",
      "epoch 65; iter: 0; batch classifier loss: 0.231475; batch adversarial loss: 0.459963\n",
      "epoch 66; iter: 0; batch classifier loss: 0.133527; batch adversarial loss: 0.495358\n",
      "epoch 67; iter: 0; batch classifier loss: 0.180888; batch adversarial loss: 0.372139\n",
      "epoch 68; iter: 0; batch classifier loss: 0.132183; batch adversarial loss: 0.372800\n",
      "epoch 69; iter: 0; batch classifier loss: 0.180984; batch adversarial loss: 0.445231\n",
      "epoch 70; iter: 0; batch classifier loss: 0.221973; batch adversarial loss: 0.447141\n",
      "epoch 71; iter: 0; batch classifier loss: 0.110931; batch adversarial loss: 0.446161\n",
      "epoch 72; iter: 0; batch classifier loss: 0.164621; batch adversarial loss: 0.445975\n",
      "epoch 73; iter: 0; batch classifier loss: 0.145100; batch adversarial loss: 0.458539\n",
      "epoch 74; iter: 0; batch classifier loss: 0.083014; batch adversarial loss: 0.496593\n",
      "epoch 75; iter: 0; batch classifier loss: 0.174690; batch adversarial loss: 0.495702\n",
      "epoch 76; iter: 0; batch classifier loss: 0.205285; batch adversarial loss: 0.458613\n",
      "epoch 77; iter: 0; batch classifier loss: 0.149730; batch adversarial loss: 0.483600\n",
      "epoch 78; iter: 0; batch classifier loss: 0.119836; batch adversarial loss: 0.483409\n",
      "epoch 79; iter: 0; batch classifier loss: 0.135473; batch adversarial loss: 0.433889\n",
      "epoch 80; iter: 0; batch classifier loss: 0.145508; batch adversarial loss: 0.557819\n",
      "epoch 81; iter: 0; batch classifier loss: 0.121586; batch adversarial loss: 0.483247\n",
      "epoch 82; iter: 0; batch classifier loss: 0.159588; batch adversarial loss: 0.434784\n",
      "epoch 83; iter: 0; batch classifier loss: 0.199920; batch adversarial loss: 0.446553\n",
      "epoch 84; iter: 0; batch classifier loss: 0.154653; batch adversarial loss: 0.471284\n",
      "epoch 85; iter: 0; batch classifier loss: 0.137600; batch adversarial loss: 0.545525\n",
      "epoch 86; iter: 0; batch classifier loss: 0.182713; batch adversarial loss: 0.433949\n",
      "epoch 87; iter: 0; batch classifier loss: 0.136163; batch adversarial loss: 0.421256\n",
      "epoch 88; iter: 0; batch classifier loss: 0.129555; batch adversarial loss: 0.472109\n",
      "epoch 89; iter: 0; batch classifier loss: 0.163711; batch adversarial loss: 0.457626\n",
      "epoch 90; iter: 0; batch classifier loss: 0.143748; batch adversarial loss: 0.509106\n",
      "epoch 91; iter: 0; batch classifier loss: 0.211040; batch adversarial loss: 0.358795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.138168; batch adversarial loss: 0.561068\n",
      "epoch 93; iter: 0; batch classifier loss: 0.101916; batch adversarial loss: 0.510440\n",
      "epoch 94; iter: 0; batch classifier loss: 0.154192; batch adversarial loss: 0.432687\n",
      "epoch 95; iter: 0; batch classifier loss: 0.142357; batch adversarial loss: 0.396152\n",
      "epoch 96; iter: 0; batch classifier loss: 0.167830; batch adversarial loss: 0.484053\n",
      "epoch 97; iter: 0; batch classifier loss: 0.152465; batch adversarial loss: 0.371733\n",
      "epoch 98; iter: 0; batch classifier loss: 0.213288; batch adversarial loss: 0.520989\n",
      "epoch 99; iter: 0; batch classifier loss: 0.170194; batch adversarial loss: 0.509006\n",
      "epoch 100; iter: 0; batch classifier loss: 0.185077; batch adversarial loss: 0.471327\n",
      "epoch 101; iter: 0; batch classifier loss: 0.163808; batch adversarial loss: 0.458460\n",
      "epoch 102; iter: 0; batch classifier loss: 0.188718; batch adversarial loss: 0.458791\n",
      "epoch 103; iter: 0; batch classifier loss: 0.202418; batch adversarial loss: 0.421465\n",
      "epoch 104; iter: 0; batch classifier loss: 0.171669; batch adversarial loss: 0.558530\n",
      "epoch 105; iter: 0; batch classifier loss: 0.096375; batch adversarial loss: 0.458836\n",
      "epoch 106; iter: 0; batch classifier loss: 0.130554; batch adversarial loss: 0.458237\n",
      "epoch 107; iter: 0; batch classifier loss: 0.129729; batch adversarial loss: 0.508645\n",
      "epoch 108; iter: 0; batch classifier loss: 0.199883; batch adversarial loss: 0.433718\n",
      "epoch 109; iter: 0; batch classifier loss: 0.137002; batch adversarial loss: 0.421597\n",
      "epoch 110; iter: 0; batch classifier loss: 0.149907; batch adversarial loss: 0.484946\n",
      "epoch 111; iter: 0; batch classifier loss: 0.124339; batch adversarial loss: 0.333518\n",
      "epoch 112; iter: 0; batch classifier loss: 0.209744; batch adversarial loss: 0.397055\n",
      "epoch 113; iter: 0; batch classifier loss: 0.157213; batch adversarial loss: 0.472138\n",
      "epoch 114; iter: 0; batch classifier loss: 0.153664; batch adversarial loss: 0.447277\n",
      "epoch 115; iter: 0; batch classifier loss: 0.136257; batch adversarial loss: 0.471387\n",
      "epoch 116; iter: 0; batch classifier loss: 0.104129; batch adversarial loss: 0.645498\n",
      "epoch 117; iter: 0; batch classifier loss: 0.174542; batch adversarial loss: 0.371223\n",
      "epoch 118; iter: 0; batch classifier loss: 0.162202; batch adversarial loss: 0.520022\n",
      "epoch 119; iter: 0; batch classifier loss: 0.200557; batch adversarial loss: 0.434432\n",
      "epoch 120; iter: 0; batch classifier loss: 0.106022; batch adversarial loss: 0.533632\n",
      "epoch 121; iter: 0; batch classifier loss: 0.092119; batch adversarial loss: 0.496011\n",
      "epoch 122; iter: 0; batch classifier loss: 0.132771; batch adversarial loss: 0.448741\n",
      "epoch 123; iter: 0; batch classifier loss: 0.142336; batch adversarial loss: 0.459059\n",
      "epoch 124; iter: 0; batch classifier loss: 0.119727; batch adversarial loss: 0.473744\n",
      "epoch 125; iter: 0; batch classifier loss: 0.091156; batch adversarial loss: 0.432247\n",
      "epoch 126; iter: 0; batch classifier loss: 0.117885; batch adversarial loss: 0.394213\n",
      "epoch 127; iter: 0; batch classifier loss: 0.115349; batch adversarial loss: 0.485720\n",
      "epoch 128; iter: 0; batch classifier loss: 0.116881; batch adversarial loss: 0.396580\n",
      "epoch 129; iter: 0; batch classifier loss: 0.152728; batch adversarial loss: 0.394892\n",
      "epoch 130; iter: 0; batch classifier loss: 0.110366; batch adversarial loss: 0.469930\n",
      "epoch 131; iter: 0; batch classifier loss: 0.106971; batch adversarial loss: 0.432988\n",
      "epoch 132; iter: 0; batch classifier loss: 0.083474; batch adversarial loss: 0.481449\n",
      "epoch 133; iter: 0; batch classifier loss: 0.077551; batch adversarial loss: 0.414407\n",
      "epoch 134; iter: 0; batch classifier loss: 0.097372; batch adversarial loss: 0.429546\n",
      "epoch 135; iter: 0; batch classifier loss: 0.063845; batch adversarial loss: 0.408706\n",
      "epoch 136; iter: 0; batch classifier loss: 0.102193; batch adversarial loss: 0.558587\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040130; batch adversarial loss: 0.499165\n",
      "epoch 138; iter: 0; batch classifier loss: 0.052401; batch adversarial loss: 0.492780\n",
      "epoch 139; iter: 0; batch classifier loss: 0.056890; batch adversarial loss: 0.384030\n",
      "epoch 140; iter: 0; batch classifier loss: 0.054518; batch adversarial loss: 0.509126\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026510; batch adversarial loss: 0.413525\n",
      "epoch 142; iter: 0; batch classifier loss: 0.066475; batch adversarial loss: 0.437105\n",
      "epoch 143; iter: 0; batch classifier loss: 0.059012; batch adversarial loss: 0.457949\n",
      "epoch 144; iter: 0; batch classifier loss: 0.066872; batch adversarial loss: 0.488271\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034804; batch adversarial loss: 0.464033\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024449; batch adversarial loss: 0.475203\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029479; batch adversarial loss: 0.510621\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022376; batch adversarial loss: 0.538064\n",
      "epoch 149; iter: 0; batch classifier loss: 0.051985; batch adversarial loss: 0.466209\n",
      "epoch 150; iter: 0; batch classifier loss: 0.049718; batch adversarial loss: 0.496243\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039743; batch adversarial loss: 0.423051\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042993; batch adversarial loss: 0.429414\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034527; batch adversarial loss: 0.464633\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025334; batch adversarial loss: 0.433073\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041270; batch adversarial loss: 0.357981\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032097; batch adversarial loss: 0.415159\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026426; batch adversarial loss: 0.413209\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029448; batch adversarial loss: 0.443052\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038203; batch adversarial loss: 0.482361\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032014; batch adversarial loss: 0.388393\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039372; batch adversarial loss: 0.353092\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023544; batch adversarial loss: 0.442289\n",
      "epoch 163; iter: 0; batch classifier loss: 0.052950; batch adversarial loss: 0.509959\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019710; batch adversarial loss: 0.553939\n",
      "epoch 165; iter: 0; batch classifier loss: 0.062393; batch adversarial loss: 0.408201\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015481; batch adversarial loss: 0.403435\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028671; batch adversarial loss: 0.541830\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019105; batch adversarial loss: 0.464525\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031926; batch adversarial loss: 0.451847\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019354; batch adversarial loss: 0.490308\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026588; batch adversarial loss: 0.393945\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025526; batch adversarial loss: 0.482102\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030954; batch adversarial loss: 0.480380\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032715; batch adversarial loss: 0.475703\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039521; batch adversarial loss: 0.461303\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030463; batch adversarial loss: 0.473243\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012515; batch adversarial loss: 0.518379\n",
      "epoch 178; iter: 0; batch classifier loss: 0.036386; batch adversarial loss: 0.454519\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034153; batch adversarial loss: 0.490342\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015113; batch adversarial loss: 0.450222\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034252; batch adversarial loss: 0.554095\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016375; batch adversarial loss: 0.413498\n",
      "epoch 183; iter: 0; batch classifier loss: 0.043408; batch adversarial loss: 0.490674\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033477; batch adversarial loss: 0.508036\n",
      "epoch 185; iter: 0; batch classifier loss: 0.060913; batch adversarial loss: 0.406546\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030214; batch adversarial loss: 0.427458\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008009; batch adversarial loss: 0.490181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.014415; batch adversarial loss: 0.428060\n",
      "epoch 189; iter: 0; batch classifier loss: 0.046709; batch adversarial loss: 0.322991\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006226; batch adversarial loss: 0.433940\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030328; batch adversarial loss: 0.457744\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022308; batch adversarial loss: 0.391186\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015278; batch adversarial loss: 0.444124\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021314; batch adversarial loss: 0.451220\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012592; batch adversarial loss: 0.424394\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022146; batch adversarial loss: 0.545063\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014896; batch adversarial loss: 0.473762\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011590; batch adversarial loss: 0.468683\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018183; batch adversarial loss: 0.414390\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687969; batch adversarial loss: 0.766113\n",
      "epoch 1; iter: 0; batch classifier loss: 0.477349; batch adversarial loss: 0.746969\n",
      "epoch 2; iter: 0; batch classifier loss: 0.375666; batch adversarial loss: 0.729142\n",
      "epoch 3; iter: 0; batch classifier loss: 0.328509; batch adversarial loss: 0.679835\n",
      "epoch 4; iter: 0; batch classifier loss: 0.342088; batch adversarial loss: 0.654559\n",
      "epoch 5; iter: 0; batch classifier loss: 0.278540; batch adversarial loss: 0.628026\n",
      "epoch 6; iter: 0; batch classifier loss: 0.302788; batch adversarial loss: 0.610359\n",
      "epoch 7; iter: 0; batch classifier loss: 0.301905; batch adversarial loss: 0.545569\n",
      "epoch 8; iter: 0; batch classifier loss: 0.356216; batch adversarial loss: 0.528340\n",
      "epoch 9; iter: 0; batch classifier loss: 0.273860; batch adversarial loss: 0.552670\n",
      "epoch 10; iter: 0; batch classifier loss: 0.235811; batch adversarial loss: 0.501141\n",
      "epoch 11; iter: 0; batch classifier loss: 0.284134; batch adversarial loss: 0.431326\n",
      "epoch 12; iter: 0; batch classifier loss: 0.247196; batch adversarial loss: 0.487191\n",
      "epoch 13; iter: 0; batch classifier loss: 0.252721; batch adversarial loss: 0.470294\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263067; batch adversarial loss: 0.459271\n",
      "epoch 15; iter: 0; batch classifier loss: 0.215140; batch adversarial loss: 0.458899\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227909; batch adversarial loss: 0.450663\n",
      "epoch 17; iter: 0; batch classifier loss: 0.139503; batch adversarial loss: 0.497349\n",
      "epoch 18; iter: 0; batch classifier loss: 0.187437; batch adversarial loss: 0.483482\n",
      "epoch 19; iter: 0; batch classifier loss: 0.201622; batch adversarial loss: 0.431004\n",
      "epoch 20; iter: 0; batch classifier loss: 0.251830; batch adversarial loss: 0.423236\n",
      "epoch 21; iter: 0; batch classifier loss: 0.144565; batch adversarial loss: 0.435663\n",
      "epoch 22; iter: 0; batch classifier loss: 0.177124; batch adversarial loss: 0.367340\n",
      "epoch 23; iter: 0; batch classifier loss: 0.227098; batch adversarial loss: 0.352263\n",
      "epoch 24; iter: 0; batch classifier loss: 0.130423; batch adversarial loss: 0.443283\n",
      "epoch 25; iter: 0; batch classifier loss: 0.143885; batch adversarial loss: 0.438225\n",
      "epoch 26; iter: 0; batch classifier loss: 0.110468; batch adversarial loss: 0.445584\n",
      "epoch 27; iter: 0; batch classifier loss: 0.150162; batch adversarial loss: 0.455234\n",
      "epoch 28; iter: 0; batch classifier loss: 0.149350; batch adversarial loss: 0.381589\n",
      "epoch 29; iter: 0; batch classifier loss: 0.118928; batch adversarial loss: 0.442359\n",
      "epoch 30; iter: 0; batch classifier loss: 0.112375; batch adversarial loss: 0.419889\n",
      "epoch 31; iter: 0; batch classifier loss: 0.104958; batch adversarial loss: 0.422788\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146108; batch adversarial loss: 0.357330\n",
      "epoch 33; iter: 0; batch classifier loss: 0.127119; batch adversarial loss: 0.409069\n",
      "epoch 34; iter: 0; batch classifier loss: 0.173481; batch adversarial loss: 0.393522\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142034; batch adversarial loss: 0.467424\n",
      "epoch 36; iter: 0; batch classifier loss: 0.179157; batch adversarial loss: 0.416096\n",
      "epoch 37; iter: 0; batch classifier loss: 0.144131; batch adversarial loss: 0.397735\n",
      "epoch 38; iter: 0; batch classifier loss: 0.136267; batch adversarial loss: 0.407554\n",
      "epoch 39; iter: 0; batch classifier loss: 0.102846; batch adversarial loss: 0.401356\n",
      "epoch 40; iter: 0; batch classifier loss: 0.149493; batch adversarial loss: 0.470856\n",
      "epoch 41; iter: 0; batch classifier loss: 0.113672; batch adversarial loss: 0.400835\n",
      "epoch 42; iter: 0; batch classifier loss: 0.097370; batch adversarial loss: 0.402605\n",
      "epoch 43; iter: 0; batch classifier loss: 0.147161; batch adversarial loss: 0.383329\n",
      "epoch 44; iter: 0; batch classifier loss: 0.093378; batch adversarial loss: 0.487495\n",
      "epoch 45; iter: 0; batch classifier loss: 0.125008; batch adversarial loss: 0.431222\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117067; batch adversarial loss: 0.429324\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112473; batch adversarial loss: 0.357257\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104302; batch adversarial loss: 0.353202\n",
      "epoch 49; iter: 0; batch classifier loss: 0.102614; batch adversarial loss: 0.454579\n",
      "epoch 50; iter: 0; batch classifier loss: 0.103545; batch adversarial loss: 0.491827\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121843; batch adversarial loss: 0.466006\n",
      "epoch 52; iter: 0; batch classifier loss: 0.054972; batch adversarial loss: 0.420233\n",
      "epoch 53; iter: 0; batch classifier loss: 0.103353; batch adversarial loss: 0.449132\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112698; batch adversarial loss: 0.468312\n",
      "epoch 55; iter: 0; batch classifier loss: 0.124158; batch adversarial loss: 0.494200\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067560; batch adversarial loss: 0.348603\n",
      "epoch 57; iter: 0; batch classifier loss: 0.080337; batch adversarial loss: 0.376400\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090177; batch adversarial loss: 0.421621\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084066; batch adversarial loss: 0.417002\n",
      "epoch 60; iter: 0; batch classifier loss: 0.061712; batch adversarial loss: 0.425697\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090105; batch adversarial loss: 0.552236\n",
      "epoch 62; iter: 0; batch classifier loss: 0.067949; batch adversarial loss: 0.388518\n",
      "epoch 63; iter: 0; batch classifier loss: 0.052475; batch adversarial loss: 0.411859\n",
      "epoch 64; iter: 0; batch classifier loss: 0.068442; batch adversarial loss: 0.454114\n",
      "epoch 65; iter: 0; batch classifier loss: 0.061768; batch adversarial loss: 0.438955\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078181; batch adversarial loss: 0.347674\n",
      "epoch 67; iter: 0; batch classifier loss: 0.089601; batch adversarial loss: 0.385864\n",
      "epoch 68; iter: 0; batch classifier loss: 0.041442; batch adversarial loss: 0.379396\n",
      "epoch 69; iter: 0; batch classifier loss: 0.066211; batch adversarial loss: 0.415334\n",
      "epoch 70; iter: 0; batch classifier loss: 0.043895; batch adversarial loss: 0.528146\n",
      "epoch 71; iter: 0; batch classifier loss: 0.053733; batch adversarial loss: 0.490112\n",
      "epoch 72; iter: 0; batch classifier loss: 0.055700; batch adversarial loss: 0.427682\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076491; batch adversarial loss: 0.497183\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081218; batch adversarial loss: 0.450099\n",
      "epoch 75; iter: 0; batch classifier loss: 0.044279; batch adversarial loss: 0.419398\n",
      "epoch 76; iter: 0; batch classifier loss: 0.062194; batch adversarial loss: 0.399357\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062940; batch adversarial loss: 0.391814\n",
      "epoch 78; iter: 0; batch classifier loss: 0.037374; batch adversarial loss: 0.504105\n",
      "epoch 79; iter: 0; batch classifier loss: 0.035978; batch adversarial loss: 0.533072\n",
      "epoch 80; iter: 0; batch classifier loss: 0.038472; batch adversarial loss: 0.499656\n",
      "epoch 81; iter: 0; batch classifier loss: 0.054043; batch adversarial loss: 0.456575\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053063; batch adversarial loss: 0.420407\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065765; batch adversarial loss: 0.458792\n",
      "epoch 84; iter: 0; batch classifier loss: 0.043272; batch adversarial loss: 0.510456\n",
      "epoch 85; iter: 0; batch classifier loss: 0.037780; batch adversarial loss: 0.361965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.050654; batch adversarial loss: 0.392267\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079129; batch adversarial loss: 0.463577\n",
      "epoch 88; iter: 0; batch classifier loss: 0.046206; batch adversarial loss: 0.460450\n",
      "epoch 89; iter: 0; batch classifier loss: 0.040127; batch adversarial loss: 0.420262\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050596; batch adversarial loss: 0.422606\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045161; batch adversarial loss: 0.422283\n",
      "epoch 92; iter: 0; batch classifier loss: 0.033309; batch adversarial loss: 0.391109\n",
      "epoch 93; iter: 0; batch classifier loss: 0.029806; batch adversarial loss: 0.449482\n",
      "epoch 94; iter: 0; batch classifier loss: 0.019229; batch adversarial loss: 0.512975\n",
      "epoch 95; iter: 0; batch classifier loss: 0.039867; batch adversarial loss: 0.377318\n",
      "epoch 96; iter: 0; batch classifier loss: 0.008523; batch adversarial loss: 0.501009\n",
      "epoch 97; iter: 0; batch classifier loss: 0.038745; batch adversarial loss: 0.414720\n",
      "epoch 98; iter: 0; batch classifier loss: 0.016737; batch adversarial loss: 0.484616\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059069; batch adversarial loss: 0.327871\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051288; batch adversarial loss: 0.452808\n",
      "epoch 101; iter: 0; batch classifier loss: 0.024185; batch adversarial loss: 0.532259\n",
      "epoch 102; iter: 0; batch classifier loss: 0.019472; batch adversarial loss: 0.404664\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037470; batch adversarial loss: 0.452252\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031609; batch adversarial loss: 0.488273\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059635; batch adversarial loss: 0.420887\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049188; batch adversarial loss: 0.500389\n",
      "epoch 107; iter: 0; batch classifier loss: 0.026827; batch adversarial loss: 0.501360\n",
      "epoch 108; iter: 0; batch classifier loss: 0.020684; batch adversarial loss: 0.523168\n",
      "epoch 109; iter: 0; batch classifier loss: 0.088368; batch adversarial loss: 0.459485\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041298; batch adversarial loss: 0.545316\n",
      "epoch 111; iter: 0; batch classifier loss: 0.076625; batch adversarial loss: 0.582299\n",
      "epoch 112; iter: 0; batch classifier loss: 0.105199; batch adversarial loss: 0.626542\n",
      "epoch 113; iter: 0; batch classifier loss: 0.104210; batch adversarial loss: 0.610719\n",
      "epoch 114; iter: 0; batch classifier loss: 0.130164; batch adversarial loss: 0.636120\n",
      "epoch 115; iter: 0; batch classifier loss: 0.153969; batch adversarial loss: 0.585570\n",
      "epoch 116; iter: 0; batch classifier loss: 0.091369; batch adversarial loss: 0.631923\n",
      "epoch 117; iter: 0; batch classifier loss: 0.134987; batch adversarial loss: 0.674727\n",
      "epoch 118; iter: 0; batch classifier loss: 0.115514; batch adversarial loss: 0.636170\n",
      "epoch 119; iter: 0; batch classifier loss: 0.137099; batch adversarial loss: 0.596401\n",
      "epoch 120; iter: 0; batch classifier loss: 0.138697; batch adversarial loss: 0.608651\n",
      "epoch 121; iter: 0; batch classifier loss: 0.089136; batch adversarial loss: 0.589438\n",
      "epoch 122; iter: 0; batch classifier loss: 0.211354; batch adversarial loss: 0.719841\n",
      "epoch 123; iter: 0; batch classifier loss: 0.101233; batch adversarial loss: 0.539611\n",
      "epoch 124; iter: 0; batch classifier loss: 0.185618; batch adversarial loss: 0.708966\n",
      "epoch 125; iter: 0; batch classifier loss: 0.078777; batch adversarial loss: 0.531573\n",
      "epoch 126; iter: 0; batch classifier loss: 0.203403; batch adversarial loss: 0.607724\n",
      "epoch 127; iter: 0; batch classifier loss: 0.151130; batch adversarial loss: 0.638578\n",
      "epoch 128; iter: 0; batch classifier loss: 0.184090; batch adversarial loss: 0.697230\n",
      "epoch 129; iter: 0; batch classifier loss: 0.123853; batch adversarial loss: 0.533415\n",
      "epoch 130; iter: 0; batch classifier loss: 0.162182; batch adversarial loss: 0.751820\n",
      "epoch 131; iter: 0; batch classifier loss: 0.151310; batch adversarial loss: 0.583385\n",
      "epoch 132; iter: 0; batch classifier loss: 0.159128; batch adversarial loss: 0.570964\n",
      "epoch 133; iter: 0; batch classifier loss: 0.118633; batch adversarial loss: 0.545568\n",
      "epoch 134; iter: 0; batch classifier loss: 0.099519; batch adversarial loss: 0.559802\n",
      "epoch 135; iter: 0; batch classifier loss: 0.134638; batch adversarial loss: 0.548482\n",
      "epoch 136; iter: 0; batch classifier loss: 0.111906; batch adversarial loss: 0.584733\n",
      "epoch 137; iter: 0; batch classifier loss: 0.163119; batch adversarial loss: 0.584391\n",
      "epoch 138; iter: 0; batch classifier loss: 0.111397; batch adversarial loss: 0.500520\n",
      "epoch 139; iter: 0; batch classifier loss: 0.191670; batch adversarial loss: 0.598694\n",
      "epoch 140; iter: 0; batch classifier loss: 0.107145; batch adversarial loss: 0.455921\n",
      "epoch 141; iter: 0; batch classifier loss: 0.100037; batch adversarial loss: 0.502953\n",
      "epoch 142; iter: 0; batch classifier loss: 0.142760; batch adversarial loss: 0.469992\n",
      "epoch 143; iter: 0; batch classifier loss: 0.174140; batch adversarial loss: 0.494263\n",
      "epoch 144; iter: 0; batch classifier loss: 0.115639; batch adversarial loss: 0.512701\n",
      "epoch 145; iter: 0; batch classifier loss: 0.100030; batch adversarial loss: 0.485417\n",
      "epoch 146; iter: 0; batch classifier loss: 0.084976; batch adversarial loss: 0.384307\n",
      "epoch 147; iter: 0; batch classifier loss: 0.102816; batch adversarial loss: 0.515559\n",
      "epoch 148; iter: 0; batch classifier loss: 0.114330; batch adversarial loss: 0.498242\n",
      "epoch 149; iter: 0; batch classifier loss: 0.127644; batch adversarial loss: 0.510110\n",
      "epoch 150; iter: 0; batch classifier loss: 0.088099; batch adversarial loss: 0.443485\n",
      "epoch 151; iter: 0; batch classifier loss: 0.130934; batch adversarial loss: 0.453225\n",
      "epoch 152; iter: 0; batch classifier loss: 0.070208; batch adversarial loss: 0.415239\n",
      "epoch 153; iter: 0; batch classifier loss: 0.119983; batch adversarial loss: 0.471497\n",
      "epoch 154; iter: 0; batch classifier loss: 0.099684; batch adversarial loss: 0.396892\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049095; batch adversarial loss: 0.504910\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029861; batch adversarial loss: 0.408167\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035993; batch adversarial loss: 0.420427\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045112; batch adversarial loss: 0.525703\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014855; batch adversarial loss: 0.471614\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019503; batch adversarial loss: 0.499147\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032294; batch adversarial loss: 0.498459\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039389; batch adversarial loss: 0.501610\n",
      "epoch 163; iter: 0; batch classifier loss: 0.060829; batch adversarial loss: 0.482300\n",
      "epoch 164; iter: 0; batch classifier loss: 0.055816; batch adversarial loss: 0.501927\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036141; batch adversarial loss: 0.486598\n",
      "epoch 166; iter: 0; batch classifier loss: 0.063700; batch adversarial loss: 0.392448\n",
      "epoch 167; iter: 0; batch classifier loss: 0.071726; batch adversarial loss: 0.362554\n",
      "epoch 168; iter: 0; batch classifier loss: 0.049706; batch adversarial loss: 0.428023\n",
      "epoch 169; iter: 0; batch classifier loss: 0.072232; batch adversarial loss: 0.431825\n",
      "epoch 170; iter: 0; batch classifier loss: 0.045471; batch adversarial loss: 0.373424\n",
      "epoch 171; iter: 0; batch classifier loss: 0.085528; batch adversarial loss: 0.496622\n",
      "epoch 172; iter: 0; batch classifier loss: 0.081843; batch adversarial loss: 0.404404\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037105; batch adversarial loss: 0.418281\n",
      "epoch 174; iter: 0; batch classifier loss: 0.120929; batch adversarial loss: 0.339624\n",
      "epoch 175; iter: 0; batch classifier loss: 0.068443; batch adversarial loss: 0.486087\n",
      "epoch 176; iter: 0; batch classifier loss: 0.068381; batch adversarial loss: 0.519194\n",
      "epoch 177; iter: 0; batch classifier loss: 0.063329; batch adversarial loss: 0.443890\n",
      "epoch 178; iter: 0; batch classifier loss: 0.088714; batch adversarial loss: 0.418960\n",
      "epoch 179; iter: 0; batch classifier loss: 0.065127; batch adversarial loss: 0.408702\n",
      "epoch 180; iter: 0; batch classifier loss: 0.095822; batch adversarial loss: 0.540123\n",
      "epoch 181; iter: 0; batch classifier loss: 0.103620; batch adversarial loss: 0.442561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.029949; batch adversarial loss: 0.414618\n",
      "epoch 183; iter: 0; batch classifier loss: 0.076276; batch adversarial loss: 0.511809\n",
      "epoch 184; iter: 0; batch classifier loss: 0.141857; batch adversarial loss: 0.452653\n",
      "epoch 185; iter: 0; batch classifier loss: 0.099613; batch adversarial loss: 0.492417\n",
      "epoch 186; iter: 0; batch classifier loss: 0.082541; batch adversarial loss: 0.459891\n",
      "epoch 187; iter: 0; batch classifier loss: 0.085122; batch adversarial loss: 0.517250\n",
      "epoch 188; iter: 0; batch classifier loss: 0.053767; batch adversarial loss: 0.431627\n",
      "epoch 189; iter: 0; batch classifier loss: 0.078535; batch adversarial loss: 0.446291\n",
      "epoch 190; iter: 0; batch classifier loss: 0.105211; batch adversarial loss: 0.447081\n",
      "epoch 191; iter: 0; batch classifier loss: 0.092842; batch adversarial loss: 0.453766\n",
      "epoch 192; iter: 0; batch classifier loss: 0.077927; batch adversarial loss: 0.425771\n",
      "epoch 193; iter: 0; batch classifier loss: 0.092506; batch adversarial loss: 0.505169\n",
      "epoch 194; iter: 0; batch classifier loss: 0.075520; batch adversarial loss: 0.518520\n",
      "epoch 195; iter: 0; batch classifier loss: 0.088757; batch adversarial loss: 0.465907\n",
      "epoch 196; iter: 0; batch classifier loss: 0.085254; batch adversarial loss: 0.424732\n",
      "epoch 197; iter: 0; batch classifier loss: 0.041512; batch adversarial loss: 0.487950\n",
      "epoch 198; iter: 0; batch classifier loss: 0.124893; batch adversarial loss: 0.396752\n",
      "epoch 199; iter: 0; batch classifier loss: 0.059361; batch adversarial loss: 0.340621\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674207; batch adversarial loss: 0.835828\n",
      "epoch 1; iter: 0; batch classifier loss: 0.581562; batch adversarial loss: 0.871255\n",
      "epoch 2; iter: 0; batch classifier loss: 0.818406; batch adversarial loss: 0.876361\n",
      "epoch 3; iter: 0; batch classifier loss: 0.855748; batch adversarial loss: 0.809738\n",
      "epoch 4; iter: 0; batch classifier loss: 0.800135; batch adversarial loss: 0.721456\n",
      "epoch 5; iter: 0; batch classifier loss: 0.694856; batch adversarial loss: 0.643501\n",
      "epoch 6; iter: 0; batch classifier loss: 0.567592; batch adversarial loss: 0.617378\n",
      "epoch 7; iter: 0; batch classifier loss: 0.430841; batch adversarial loss: 0.565682\n",
      "epoch 8; iter: 0; batch classifier loss: 0.341342; batch adversarial loss: 0.579685\n",
      "epoch 9; iter: 0; batch classifier loss: 0.364415; batch adversarial loss: 0.537874\n",
      "epoch 10; iter: 0; batch classifier loss: 0.361952; batch adversarial loss: 0.487664\n",
      "epoch 11; iter: 0; batch classifier loss: 0.350662; batch adversarial loss: 0.520208\n",
      "epoch 12; iter: 0; batch classifier loss: 0.331822; batch adversarial loss: 0.496641\n",
      "epoch 13; iter: 0; batch classifier loss: 0.345292; batch adversarial loss: 0.502641\n",
      "epoch 14; iter: 0; batch classifier loss: 0.259860; batch adversarial loss: 0.513066\n",
      "epoch 15; iter: 0; batch classifier loss: 0.314217; batch adversarial loss: 0.476760\n",
      "epoch 16; iter: 0; batch classifier loss: 0.315920; batch adversarial loss: 0.519347\n",
      "epoch 17; iter: 0; batch classifier loss: 0.313455; batch adversarial loss: 0.529641\n",
      "epoch 18; iter: 0; batch classifier loss: 0.206089; batch adversarial loss: 0.470263\n",
      "epoch 19; iter: 0; batch classifier loss: 0.248340; batch adversarial loss: 0.451065\n",
      "epoch 20; iter: 0; batch classifier loss: 0.187514; batch adversarial loss: 0.486396\n",
      "epoch 21; iter: 0; batch classifier loss: 0.248418; batch adversarial loss: 0.425183\n",
      "epoch 22; iter: 0; batch classifier loss: 0.235770; batch adversarial loss: 0.459275\n",
      "epoch 23; iter: 0; batch classifier loss: 0.219197; batch adversarial loss: 0.475794\n",
      "epoch 24; iter: 0; batch classifier loss: 0.201291; batch adversarial loss: 0.512543\n",
      "epoch 25; iter: 0; batch classifier loss: 0.216096; batch adversarial loss: 0.468241\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187255; batch adversarial loss: 0.503858\n",
      "epoch 27; iter: 0; batch classifier loss: 0.158703; batch adversarial loss: 0.442614\n",
      "epoch 28; iter: 0; batch classifier loss: 0.258801; batch adversarial loss: 0.459988\n",
      "epoch 29; iter: 0; batch classifier loss: 0.179227; batch adversarial loss: 0.426180\n",
      "epoch 30; iter: 0; batch classifier loss: 0.247086; batch adversarial loss: 0.485051\n",
      "epoch 31; iter: 0; batch classifier loss: 0.211703; batch adversarial loss: 0.437520\n",
      "epoch 32; iter: 0; batch classifier loss: 0.117473; batch adversarial loss: 0.495394\n",
      "epoch 33; iter: 0; batch classifier loss: 0.168057; batch adversarial loss: 0.342203\n",
      "epoch 34; iter: 0; batch classifier loss: 0.177492; batch adversarial loss: 0.429519\n",
      "epoch 35; iter: 0; batch classifier loss: 0.163759; batch adversarial loss: 0.414926\n",
      "epoch 36; iter: 0; batch classifier loss: 0.139009; batch adversarial loss: 0.501854\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153824; batch adversarial loss: 0.461299\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115475; batch adversarial loss: 0.411265\n",
      "epoch 39; iter: 0; batch classifier loss: 0.160252; batch adversarial loss: 0.525981\n",
      "epoch 40; iter: 0; batch classifier loss: 0.205254; batch adversarial loss: 0.573037\n",
      "epoch 41; iter: 0; batch classifier loss: 0.121120; batch adversarial loss: 0.530672\n",
      "epoch 42; iter: 0; batch classifier loss: 0.108600; batch adversarial loss: 0.463211\n",
      "epoch 43; iter: 0; batch classifier loss: 0.151446; batch adversarial loss: 0.472566\n",
      "epoch 44; iter: 0; batch classifier loss: 0.080339; batch adversarial loss: 0.466651\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097590; batch adversarial loss: 0.380340\n",
      "epoch 46; iter: 0; batch classifier loss: 0.123461; batch adversarial loss: 0.504401\n",
      "epoch 47; iter: 0; batch classifier loss: 0.101843; batch adversarial loss: 0.471881\n",
      "epoch 48; iter: 0; batch classifier loss: 0.110492; batch adversarial loss: 0.486369\n",
      "epoch 49; iter: 0; batch classifier loss: 0.091916; batch adversarial loss: 0.487914\n",
      "epoch 50; iter: 0; batch classifier loss: 0.088112; batch adversarial loss: 0.464695\n",
      "epoch 51; iter: 0; batch classifier loss: 0.069826; batch adversarial loss: 0.487825\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103946; batch adversarial loss: 0.467652\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096603; batch adversarial loss: 0.491015\n",
      "epoch 54; iter: 0; batch classifier loss: 0.077513; batch adversarial loss: 0.557587\n",
      "epoch 55; iter: 0; batch classifier loss: 0.063156; batch adversarial loss: 0.366150\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082081; batch adversarial loss: 0.556409\n",
      "epoch 57; iter: 0; batch classifier loss: 0.092287; batch adversarial loss: 0.432860\n",
      "epoch 58; iter: 0; batch classifier loss: 0.064683; batch adversarial loss: 0.459150\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070914; batch adversarial loss: 0.523367\n",
      "epoch 60; iter: 0; batch classifier loss: 0.111822; batch adversarial loss: 0.492863\n",
      "epoch 61; iter: 0; batch classifier loss: 0.155714; batch adversarial loss: 0.390258\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092284; batch adversarial loss: 0.380151\n",
      "epoch 63; iter: 0; batch classifier loss: 0.086047; batch adversarial loss: 0.451481\n",
      "epoch 64; iter: 0; batch classifier loss: 0.050895; batch adversarial loss: 0.451451\n",
      "epoch 65; iter: 0; batch classifier loss: 0.062410; batch adversarial loss: 0.470819\n",
      "epoch 66; iter: 0; batch classifier loss: 0.054705; batch adversarial loss: 0.569848\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080266; batch adversarial loss: 0.444676\n",
      "epoch 68; iter: 0; batch classifier loss: 0.101620; batch adversarial loss: 0.408415\n",
      "epoch 69; iter: 0; batch classifier loss: 0.127827; batch adversarial loss: 0.386111\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066995; batch adversarial loss: 0.423166\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078888; batch adversarial loss: 0.433461\n",
      "epoch 72; iter: 0; batch classifier loss: 0.086654; batch adversarial loss: 0.480982\n",
      "epoch 73; iter: 0; batch classifier loss: 0.095677; batch adversarial loss: 0.461907\n",
      "epoch 74; iter: 0; batch classifier loss: 0.103801; batch adversarial loss: 0.442491\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077666; batch adversarial loss: 0.475998\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069525; batch adversarial loss: 0.466521\n",
      "epoch 77; iter: 0; batch classifier loss: 0.079150; batch adversarial loss: 0.464518\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061515; batch adversarial loss: 0.357495\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065176; batch adversarial loss: 0.485004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.076524; batch adversarial loss: 0.497346\n",
      "epoch 81; iter: 0; batch classifier loss: 0.059575; batch adversarial loss: 0.353151\n",
      "epoch 82; iter: 0; batch classifier loss: 0.064475; batch adversarial loss: 0.401937\n",
      "epoch 83; iter: 0; batch classifier loss: 0.028427; batch adversarial loss: 0.450337\n",
      "epoch 84; iter: 0; batch classifier loss: 0.089488; batch adversarial loss: 0.435553\n",
      "epoch 85; iter: 0; batch classifier loss: 0.109415; batch adversarial loss: 0.416447\n",
      "epoch 86; iter: 0; batch classifier loss: 0.100828; batch adversarial loss: 0.366961\n",
      "epoch 87; iter: 0; batch classifier loss: 0.040454; batch adversarial loss: 0.519168\n",
      "epoch 88; iter: 0; batch classifier loss: 0.066622; batch adversarial loss: 0.445284\n",
      "epoch 89; iter: 0; batch classifier loss: 0.030948; batch adversarial loss: 0.431269\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060621; batch adversarial loss: 0.436600\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057831; batch adversarial loss: 0.567513\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066866; batch adversarial loss: 0.475774\n",
      "epoch 93; iter: 0; batch classifier loss: 0.037095; batch adversarial loss: 0.434885\n",
      "epoch 94; iter: 0; batch classifier loss: 0.097243; batch adversarial loss: 0.479021\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064676; batch adversarial loss: 0.511053\n",
      "epoch 96; iter: 0; batch classifier loss: 0.040661; batch adversarial loss: 0.446537\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037918; batch adversarial loss: 0.595621\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053740; batch adversarial loss: 0.449363\n",
      "epoch 99; iter: 0; batch classifier loss: 0.051654; batch adversarial loss: 0.418536\n",
      "epoch 100; iter: 0; batch classifier loss: 0.026334; batch adversarial loss: 0.420848\n",
      "epoch 101; iter: 0; batch classifier loss: 0.015655; batch adversarial loss: 0.470702\n",
      "epoch 102; iter: 0; batch classifier loss: 0.075423; batch adversarial loss: 0.409585\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037937; batch adversarial loss: 0.453590\n",
      "epoch 104; iter: 0; batch classifier loss: 0.048943; batch adversarial loss: 0.337024\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061358; batch adversarial loss: 0.484839\n",
      "epoch 106; iter: 0; batch classifier loss: 0.038666; batch adversarial loss: 0.348532\n",
      "epoch 107; iter: 0; batch classifier loss: 0.084287; batch adversarial loss: 0.495095\n",
      "epoch 108; iter: 0; batch classifier loss: 0.024527; batch adversarial loss: 0.479983\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049127; batch adversarial loss: 0.505427\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028488; batch adversarial loss: 0.487526\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043600; batch adversarial loss: 0.508706\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054796; batch adversarial loss: 0.466740\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054680; batch adversarial loss: 0.438106\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050212; batch adversarial loss: 0.528184\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036161; batch adversarial loss: 0.448840\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054720; batch adversarial loss: 0.446556\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034217; batch adversarial loss: 0.402716\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045450; batch adversarial loss: 0.441337\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023585; batch adversarial loss: 0.388537\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045279; batch adversarial loss: 0.490158\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057191; batch adversarial loss: 0.413488\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033882; batch adversarial loss: 0.510874\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045766; batch adversarial loss: 0.412597\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027878; batch adversarial loss: 0.458979\n",
      "epoch 125; iter: 0; batch classifier loss: 0.066162; batch adversarial loss: 0.500326\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028985; batch adversarial loss: 0.394648\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036698; batch adversarial loss: 0.465979\n",
      "epoch 128; iter: 0; batch classifier loss: 0.051132; batch adversarial loss: 0.436984\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048752; batch adversarial loss: 0.562734\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025356; batch adversarial loss: 0.615037\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024223; batch adversarial loss: 0.436655\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026436; batch adversarial loss: 0.490537\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037099; batch adversarial loss: 0.523003\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031752; batch adversarial loss: 0.481025\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033034; batch adversarial loss: 0.399608\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037053; batch adversarial loss: 0.526994\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018545; batch adversarial loss: 0.441671\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032634; batch adversarial loss: 0.475293\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019905; batch adversarial loss: 0.495544\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037623; batch adversarial loss: 0.463998\n",
      "epoch 141; iter: 0; batch classifier loss: 0.041123; batch adversarial loss: 0.355277\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024839; batch adversarial loss: 0.488204\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011395; batch adversarial loss: 0.468882\n",
      "epoch 144; iter: 0; batch classifier loss: 0.015580; batch adversarial loss: 0.442506\n",
      "epoch 145; iter: 0; batch classifier loss: 0.009991; batch adversarial loss: 0.471915\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023295; batch adversarial loss: 0.555036\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039166; batch adversarial loss: 0.435805\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025579; batch adversarial loss: 0.405618\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020966; batch adversarial loss: 0.487583\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018136; batch adversarial loss: 0.467852\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028682; batch adversarial loss: 0.459686\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020926; batch adversarial loss: 0.476048\n",
      "epoch 153; iter: 0; batch classifier loss: 0.054267; batch adversarial loss: 0.535122\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016351; batch adversarial loss: 0.521560\n",
      "epoch 155; iter: 0; batch classifier loss: 0.005855; batch adversarial loss: 0.488814\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036183; batch adversarial loss: 0.455720\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031711; batch adversarial loss: 0.354768\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013574; batch adversarial loss: 0.504265\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018202; batch adversarial loss: 0.386447\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035173; batch adversarial loss: 0.403947\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026906; batch adversarial loss: 0.425969\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036525; batch adversarial loss: 0.425654\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024752; batch adversarial loss: 0.452717\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014317; batch adversarial loss: 0.561267\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021910; batch adversarial loss: 0.465811\n",
      "epoch 166; iter: 0; batch classifier loss: 0.042407; batch adversarial loss: 0.425758\n",
      "epoch 167; iter: 0; batch classifier loss: 0.027352; batch adversarial loss: 0.427715\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026146; batch adversarial loss: 0.475214\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032431; batch adversarial loss: 0.561193\n",
      "epoch 170; iter: 0; batch classifier loss: 0.049866; batch adversarial loss: 0.503579\n",
      "epoch 171; iter: 0; batch classifier loss: 0.035331; batch adversarial loss: 0.393007\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013499; batch adversarial loss: 0.369209\n",
      "epoch 173; iter: 0; batch classifier loss: 0.005157; batch adversarial loss: 0.360511\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016290; batch adversarial loss: 0.491084\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029944; batch adversarial loss: 0.460677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.022397; batch adversarial loss: 0.463240\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014903; batch adversarial loss: 0.414133\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016367; batch adversarial loss: 0.497322\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027275; batch adversarial loss: 0.470409\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007424; batch adversarial loss: 0.458425\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022343; batch adversarial loss: 0.480543\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024430; batch adversarial loss: 0.504709\n",
      "epoch 183; iter: 0; batch classifier loss: 0.049314; batch adversarial loss: 0.407864\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004283; batch adversarial loss: 0.449891\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025829; batch adversarial loss: 0.603673\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040691; batch adversarial loss: 0.437699\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022317; batch adversarial loss: 0.539900\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035756; batch adversarial loss: 0.583539\n",
      "epoch 189; iter: 0; batch classifier loss: 0.002485; batch adversarial loss: 0.477628\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015962; batch adversarial loss: 0.371381\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014079; batch adversarial loss: 0.524920\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006919; batch adversarial loss: 0.421435\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020483; batch adversarial loss: 0.548661\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025182; batch adversarial loss: 0.407881\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036520; batch adversarial loss: 0.430235\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005961; batch adversarial loss: 0.421166\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014876; batch adversarial loss: 0.440319\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023271; batch adversarial loss: 0.463011\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012823; batch adversarial loss: 0.400345\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711786; batch adversarial loss: 0.505578\n",
      "epoch 1; iter: 0; batch classifier loss: 0.414197; batch adversarial loss: 0.584541\n",
      "epoch 2; iter: 0; batch classifier loss: 0.419452; batch adversarial loss: 0.546985\n",
      "epoch 3; iter: 0; batch classifier loss: 0.351262; batch adversarial loss: 0.577270\n",
      "epoch 4; iter: 0; batch classifier loss: 0.443451; batch adversarial loss: 0.646122\n",
      "epoch 5; iter: 0; batch classifier loss: 0.380817; batch adversarial loss: 0.572992\n",
      "epoch 6; iter: 0; batch classifier loss: 0.423078; batch adversarial loss: 0.618290\n",
      "epoch 7; iter: 0; batch classifier loss: 0.392547; batch adversarial loss: 0.507873\n",
      "epoch 8; iter: 0; batch classifier loss: 0.460763; batch adversarial loss: 0.528303\n",
      "epoch 9; iter: 0; batch classifier loss: 0.279287; batch adversarial loss: 0.489755\n",
      "epoch 10; iter: 0; batch classifier loss: 0.397598; batch adversarial loss: 0.617346\n",
      "epoch 11; iter: 0; batch classifier loss: 0.425969; batch adversarial loss: 0.536013\n",
      "epoch 12; iter: 0; batch classifier loss: 0.362727; batch adversarial loss: 0.529589\n",
      "epoch 13; iter: 0; batch classifier loss: 0.570532; batch adversarial loss: 0.509565\n",
      "epoch 14; iter: 0; batch classifier loss: 0.593847; batch adversarial loss: 0.584323\n",
      "epoch 15; iter: 0; batch classifier loss: 0.655517; batch adversarial loss: 0.538673\n",
      "epoch 16; iter: 0; batch classifier loss: 0.391874; batch adversarial loss: 0.556308\n",
      "epoch 17; iter: 0; batch classifier loss: 0.352983; batch adversarial loss: 0.547433\n",
      "epoch 18; iter: 0; batch classifier loss: 0.309898; batch adversarial loss: 0.396889\n",
      "epoch 19; iter: 0; batch classifier loss: 0.169658; batch adversarial loss: 0.515465\n",
      "epoch 20; iter: 0; batch classifier loss: 0.189744; batch adversarial loss: 0.491069\n",
      "epoch 21; iter: 0; batch classifier loss: 0.175928; batch adversarial loss: 0.468273\n",
      "epoch 22; iter: 0; batch classifier loss: 0.174283; batch adversarial loss: 0.512326\n",
      "epoch 23; iter: 0; batch classifier loss: 0.238715; batch adversarial loss: 0.484472\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194345; batch adversarial loss: 0.487515\n",
      "epoch 25; iter: 0; batch classifier loss: 0.198895; batch adversarial loss: 0.445010\n",
      "epoch 26; iter: 0; batch classifier loss: 0.281472; batch adversarial loss: 0.409592\n",
      "epoch 27; iter: 0; batch classifier loss: 0.134129; batch adversarial loss: 0.509272\n",
      "epoch 28; iter: 0; batch classifier loss: 0.145191; batch adversarial loss: 0.438898\n",
      "epoch 29; iter: 0; batch classifier loss: 0.136637; batch adversarial loss: 0.510394\n",
      "epoch 30; iter: 0; batch classifier loss: 0.217214; batch adversarial loss: 0.489040\n",
      "epoch 31; iter: 0; batch classifier loss: 0.125545; batch adversarial loss: 0.382521\n",
      "epoch 32; iter: 0; batch classifier loss: 0.172024; batch adversarial loss: 0.451122\n",
      "epoch 33; iter: 0; batch classifier loss: 0.176630; batch adversarial loss: 0.477262\n",
      "epoch 34; iter: 0; batch classifier loss: 0.144111; batch adversarial loss: 0.389843\n",
      "epoch 35; iter: 0; batch classifier loss: 0.195858; batch adversarial loss: 0.454407\n",
      "epoch 36; iter: 0; batch classifier loss: 0.120064; batch adversarial loss: 0.447623\n",
      "epoch 37; iter: 0; batch classifier loss: 0.118874; batch adversarial loss: 0.490347\n",
      "epoch 38; iter: 0; batch classifier loss: 0.114794; batch adversarial loss: 0.489323\n",
      "epoch 39; iter: 0; batch classifier loss: 0.143799; batch adversarial loss: 0.422668\n",
      "epoch 40; iter: 0; batch classifier loss: 0.130241; batch adversarial loss: 0.384499\n",
      "epoch 41; iter: 0; batch classifier loss: 0.132550; batch adversarial loss: 0.485749\n",
      "epoch 42; iter: 0; batch classifier loss: 0.166940; batch adversarial loss: 0.424317\n",
      "epoch 43; iter: 0; batch classifier loss: 0.155245; batch adversarial loss: 0.536370\n",
      "epoch 44; iter: 0; batch classifier loss: 0.125582; batch adversarial loss: 0.477034\n",
      "epoch 45; iter: 0; batch classifier loss: 0.133099; batch adversarial loss: 0.532798\n",
      "epoch 46; iter: 0; batch classifier loss: 0.198829; batch adversarial loss: 0.434145\n",
      "epoch 47; iter: 0; batch classifier loss: 0.157984; batch adversarial loss: 0.452962\n",
      "epoch 48; iter: 0; batch classifier loss: 0.216567; batch adversarial loss: 0.459658\n",
      "epoch 49; iter: 0; batch classifier loss: 0.148683; batch adversarial loss: 0.449283\n",
      "epoch 50; iter: 0; batch classifier loss: 0.124435; batch adversarial loss: 0.436868\n",
      "epoch 51; iter: 0; batch classifier loss: 0.119872; batch adversarial loss: 0.450404\n",
      "epoch 52; iter: 0; batch classifier loss: 0.163363; batch adversarial loss: 0.470398\n",
      "epoch 53; iter: 0; batch classifier loss: 0.168447; batch adversarial loss: 0.489171\n",
      "epoch 54; iter: 0; batch classifier loss: 0.164066; batch adversarial loss: 0.393576\n",
      "epoch 55; iter: 0; batch classifier loss: 0.143352; batch adversarial loss: 0.514173\n",
      "epoch 56; iter: 0; batch classifier loss: 0.194191; batch adversarial loss: 0.445387\n",
      "epoch 57; iter: 0; batch classifier loss: 0.188059; batch adversarial loss: 0.430136\n",
      "epoch 58; iter: 0; batch classifier loss: 0.106956; batch adversarial loss: 0.463423\n",
      "epoch 59; iter: 0; batch classifier loss: 0.097939; batch adversarial loss: 0.497157\n",
      "epoch 60; iter: 0; batch classifier loss: 0.161805; batch adversarial loss: 0.499736\n",
      "epoch 61; iter: 0; batch classifier loss: 0.180966; batch adversarial loss: 0.416124\n",
      "epoch 62; iter: 0; batch classifier loss: 0.138911; batch adversarial loss: 0.493860\n",
      "epoch 63; iter: 0; batch classifier loss: 0.116364; batch adversarial loss: 0.538901\n",
      "epoch 64; iter: 0; batch classifier loss: 0.124893; batch adversarial loss: 0.443769\n",
      "epoch 65; iter: 0; batch classifier loss: 0.129315; batch adversarial loss: 0.442673\n",
      "epoch 66; iter: 0; batch classifier loss: 0.187922; batch adversarial loss: 0.534657\n",
      "epoch 67; iter: 0; batch classifier loss: 0.145310; batch adversarial loss: 0.562077\n",
      "epoch 68; iter: 0; batch classifier loss: 0.126336; batch adversarial loss: 0.480856\n",
      "epoch 69; iter: 0; batch classifier loss: 0.145526; batch adversarial loss: 0.467900\n",
      "epoch 70; iter: 0; batch classifier loss: 0.148207; batch adversarial loss: 0.461988\n",
      "epoch 71; iter: 0; batch classifier loss: 0.149065; batch adversarial loss: 0.374194\n",
      "epoch 72; iter: 0; batch classifier loss: 0.210963; batch adversarial loss: 0.520976\n",
      "epoch 73; iter: 0; batch classifier loss: 0.102216; batch adversarial loss: 0.529839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.114506; batch adversarial loss: 0.365651\n",
      "epoch 75; iter: 0; batch classifier loss: 0.134018; batch adversarial loss: 0.414397\n",
      "epoch 76; iter: 0; batch classifier loss: 0.127433; batch adversarial loss: 0.494475\n",
      "epoch 77; iter: 0; batch classifier loss: 0.218666; batch adversarial loss: 0.500797\n",
      "epoch 78; iter: 0; batch classifier loss: 0.157860; batch adversarial loss: 0.513029\n",
      "epoch 79; iter: 0; batch classifier loss: 0.106311; batch adversarial loss: 0.544787\n",
      "epoch 80; iter: 0; batch classifier loss: 0.155825; batch adversarial loss: 0.452471\n",
      "epoch 81; iter: 0; batch classifier loss: 0.175313; batch adversarial loss: 0.520777\n",
      "epoch 82; iter: 0; batch classifier loss: 0.136844; batch adversarial loss: 0.506980\n",
      "epoch 83; iter: 0; batch classifier loss: 0.140857; batch adversarial loss: 0.477612\n",
      "epoch 84; iter: 0; batch classifier loss: 0.104348; batch adversarial loss: 0.371961\n",
      "epoch 85; iter: 0; batch classifier loss: 0.189395; batch adversarial loss: 0.462558\n",
      "epoch 86; iter: 0; batch classifier loss: 0.082896; batch adversarial loss: 0.474410\n",
      "epoch 87; iter: 0; batch classifier loss: 0.188109; batch adversarial loss: 0.397513\n",
      "epoch 88; iter: 0; batch classifier loss: 0.171122; batch adversarial loss: 0.454351\n",
      "epoch 89; iter: 0; batch classifier loss: 0.181356; batch adversarial loss: 0.509405\n",
      "epoch 90; iter: 0; batch classifier loss: 0.126011; batch adversarial loss: 0.423297\n",
      "epoch 91; iter: 0; batch classifier loss: 0.145980; batch adversarial loss: 0.478946\n",
      "epoch 92; iter: 0; batch classifier loss: 0.178590; batch adversarial loss: 0.493419\n",
      "epoch 93; iter: 0; batch classifier loss: 0.193786; batch adversarial loss: 0.487202\n",
      "epoch 94; iter: 0; batch classifier loss: 0.123987; batch adversarial loss: 0.405999\n",
      "epoch 95; iter: 0; batch classifier loss: 0.164118; batch adversarial loss: 0.427672\n",
      "epoch 96; iter: 0; batch classifier loss: 0.166816; batch adversarial loss: 0.524372\n",
      "epoch 97; iter: 0; batch classifier loss: 0.113880; batch adversarial loss: 0.509043\n",
      "epoch 98; iter: 0; batch classifier loss: 0.144864; batch adversarial loss: 0.516966\n",
      "epoch 99; iter: 0; batch classifier loss: 0.133340; batch adversarial loss: 0.485891\n",
      "epoch 100; iter: 0; batch classifier loss: 0.158081; batch adversarial loss: 0.439948\n",
      "epoch 101; iter: 0; batch classifier loss: 0.158248; batch adversarial loss: 0.394729\n",
      "epoch 102; iter: 0; batch classifier loss: 0.149998; batch adversarial loss: 0.444816\n",
      "epoch 103; iter: 0; batch classifier loss: 0.138375; batch adversarial loss: 0.498938\n",
      "epoch 104; iter: 0; batch classifier loss: 0.154527; batch adversarial loss: 0.472931\n",
      "epoch 105; iter: 0; batch classifier loss: 0.146751; batch adversarial loss: 0.516775\n",
      "epoch 106; iter: 0; batch classifier loss: 0.117142; batch adversarial loss: 0.439357\n",
      "epoch 107; iter: 0; batch classifier loss: 0.109825; batch adversarial loss: 0.505748\n",
      "epoch 108; iter: 0; batch classifier loss: 0.122226; batch adversarial loss: 0.458371\n",
      "epoch 109; iter: 0; batch classifier loss: 0.077963; batch adversarial loss: 0.505387\n",
      "epoch 110; iter: 0; batch classifier loss: 0.078401; batch adversarial loss: 0.498243\n",
      "epoch 111; iter: 0; batch classifier loss: 0.112349; batch adversarial loss: 0.440290\n",
      "epoch 112; iter: 0; batch classifier loss: 0.119221; batch adversarial loss: 0.408277\n",
      "epoch 113; iter: 0; batch classifier loss: 0.113845; batch adversarial loss: 0.517351\n",
      "epoch 114; iter: 0; batch classifier loss: 0.088252; batch adversarial loss: 0.439255\n",
      "epoch 115; iter: 0; batch classifier loss: 0.087448; batch adversarial loss: 0.560427\n",
      "epoch 116; iter: 0; batch classifier loss: 0.130859; batch adversarial loss: 0.388180\n",
      "epoch 117; iter: 0; batch classifier loss: 0.176099; batch adversarial loss: 0.466942\n",
      "epoch 118; iter: 0; batch classifier loss: 0.091105; batch adversarial loss: 0.577776\n",
      "epoch 119; iter: 0; batch classifier loss: 0.096252; batch adversarial loss: 0.448854\n",
      "epoch 120; iter: 0; batch classifier loss: 0.075143; batch adversarial loss: 0.425600\n",
      "epoch 121; iter: 0; batch classifier loss: 0.070481; batch adversarial loss: 0.453329\n",
      "epoch 122; iter: 0; batch classifier loss: 0.105520; batch adversarial loss: 0.477180\n",
      "epoch 123; iter: 0; batch classifier loss: 0.071559; batch adversarial loss: 0.511821\n",
      "epoch 124; iter: 0; batch classifier loss: 0.066957; batch adversarial loss: 0.411050\n",
      "epoch 125; iter: 0; batch classifier loss: 0.092643; batch adversarial loss: 0.426776\n",
      "epoch 126; iter: 0; batch classifier loss: 0.072196; batch adversarial loss: 0.487608\n",
      "epoch 127; iter: 0; batch classifier loss: 0.063405; batch adversarial loss: 0.424982\n",
      "epoch 128; iter: 0; batch classifier loss: 0.080847; batch adversarial loss: 0.488407\n",
      "epoch 129; iter: 0; batch classifier loss: 0.080081; batch adversarial loss: 0.448548\n",
      "epoch 130; iter: 0; batch classifier loss: 0.080628; batch adversarial loss: 0.367034\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033736; batch adversarial loss: 0.534176\n",
      "epoch 132; iter: 0; batch classifier loss: 0.073737; batch adversarial loss: 0.492500\n",
      "epoch 133; iter: 0; batch classifier loss: 0.061000; batch adversarial loss: 0.500269\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037580; batch adversarial loss: 0.529622\n",
      "epoch 135; iter: 0; batch classifier loss: 0.055357; batch adversarial loss: 0.540613\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033685; batch adversarial loss: 0.436513\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045378; batch adversarial loss: 0.543231\n",
      "epoch 138; iter: 0; batch classifier loss: 0.066160; batch adversarial loss: 0.487290\n",
      "epoch 139; iter: 0; batch classifier loss: 0.047574; batch adversarial loss: 0.419405\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037476; batch adversarial loss: 0.466312\n",
      "epoch 141; iter: 0; batch classifier loss: 0.069390; batch adversarial loss: 0.489524\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034181; batch adversarial loss: 0.332800\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020727; batch adversarial loss: 0.454824\n",
      "epoch 144; iter: 0; batch classifier loss: 0.065517; batch adversarial loss: 0.477344\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027970; batch adversarial loss: 0.507116\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029362; batch adversarial loss: 0.407288\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019866; batch adversarial loss: 0.534021\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040628; batch adversarial loss: 0.397381\n",
      "epoch 149; iter: 0; batch classifier loss: 0.064863; batch adversarial loss: 0.360640\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020616; batch adversarial loss: 0.417640\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038378; batch adversarial loss: 0.432531\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027566; batch adversarial loss: 0.585610\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010286; batch adversarial loss: 0.561314\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025632; batch adversarial loss: 0.415774\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013205; batch adversarial loss: 0.474047\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019536; batch adversarial loss: 0.420402\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015524; batch adversarial loss: 0.507267\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037203; batch adversarial loss: 0.416020\n",
      "epoch 159; iter: 0; batch classifier loss: 0.089745; batch adversarial loss: 0.494431\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034381; batch adversarial loss: 0.487912\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016537; batch adversarial loss: 0.382740\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037581; batch adversarial loss: 0.392225\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036312; batch adversarial loss: 0.478462\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020689; batch adversarial loss: 0.559655\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021170; batch adversarial loss: 0.469487\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015937; batch adversarial loss: 0.389021\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016319; batch adversarial loss: 0.488051\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032850; batch adversarial loss: 0.545869\n",
      "epoch 169; iter: 0; batch classifier loss: 0.043751; batch adversarial loss: 0.378485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.027056; batch adversarial loss: 0.382398\n",
      "epoch 171; iter: 0; batch classifier loss: 0.059186; batch adversarial loss: 0.384286\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018868; batch adversarial loss: 0.429139\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034241; batch adversarial loss: 0.451254\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010927; batch adversarial loss: 0.469054\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029212; batch adversarial loss: 0.481836\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029101; batch adversarial loss: 0.388466\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034415; batch adversarial loss: 0.455346\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024769; batch adversarial loss: 0.551018\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025191; batch adversarial loss: 0.464602\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019017; batch adversarial loss: 0.436996\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024927; batch adversarial loss: 0.389973\n",
      "epoch 182; iter: 0; batch classifier loss: 0.053557; batch adversarial loss: 0.470099\n",
      "epoch 183; iter: 0; batch classifier loss: 0.052790; batch adversarial loss: 0.451589\n",
      "epoch 184; iter: 0; batch classifier loss: 0.039966; batch adversarial loss: 0.402751\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027470; batch adversarial loss: 0.417442\n",
      "epoch 186; iter: 0; batch classifier loss: 0.034519; batch adversarial loss: 0.447946\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016391; batch adversarial loss: 0.515417\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013333; batch adversarial loss: 0.518657\n",
      "epoch 189; iter: 0; batch classifier loss: 0.040057; batch adversarial loss: 0.458990\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017546; batch adversarial loss: 0.459560\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011125; batch adversarial loss: 0.400103\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011176; batch adversarial loss: 0.399396\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004327; batch adversarial loss: 0.526926\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017280; batch adversarial loss: 0.411749\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023501; batch adversarial loss: 0.389367\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022302; batch adversarial loss: 0.535628\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014029; batch adversarial loss: 0.372836\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017776; batch adversarial loss: 0.468100\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033129; batch adversarial loss: 0.512096\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666636; batch adversarial loss: 0.671146\n",
      "epoch 1; iter: 0; batch classifier loss: 0.498619; batch adversarial loss: 0.611668\n",
      "epoch 2; iter: 0; batch classifier loss: 0.358647; batch adversarial loss: 0.596723\n",
      "epoch 3; iter: 0; batch classifier loss: 0.338652; batch adversarial loss: 0.556650\n",
      "epoch 4; iter: 0; batch classifier loss: 0.442878; batch adversarial loss: 0.587466\n",
      "epoch 5; iter: 0; batch classifier loss: 0.394729; batch adversarial loss: 0.544356\n",
      "epoch 6; iter: 0; batch classifier loss: 0.303930; batch adversarial loss: 0.583044\n",
      "epoch 7; iter: 0; batch classifier loss: 0.277424; batch adversarial loss: 0.613309\n",
      "epoch 8; iter: 0; batch classifier loss: 0.348648; batch adversarial loss: 0.487182\n",
      "epoch 9; iter: 0; batch classifier loss: 0.296238; batch adversarial loss: 0.567032\n",
      "epoch 10; iter: 0; batch classifier loss: 0.276535; batch adversarial loss: 0.503165\n",
      "epoch 11; iter: 0; batch classifier loss: 0.261257; batch adversarial loss: 0.429324\n",
      "epoch 12; iter: 0; batch classifier loss: 0.205979; batch adversarial loss: 0.617518\n",
      "epoch 13; iter: 0; batch classifier loss: 0.269294; batch adversarial loss: 0.501209\n",
      "epoch 14; iter: 0; batch classifier loss: 0.225545; batch adversarial loss: 0.457174\n",
      "epoch 15; iter: 0; batch classifier loss: 0.162814; batch adversarial loss: 0.502310\n",
      "epoch 16; iter: 0; batch classifier loss: 0.220534; batch adversarial loss: 0.509371\n",
      "epoch 17; iter: 0; batch classifier loss: 0.216071; batch adversarial loss: 0.454813\n",
      "epoch 18; iter: 0; batch classifier loss: 0.275296; batch adversarial loss: 0.500386\n",
      "epoch 19; iter: 0; batch classifier loss: 0.217980; batch adversarial loss: 0.452539\n",
      "epoch 20; iter: 0; batch classifier loss: 0.174862; batch adversarial loss: 0.506716\n",
      "epoch 21; iter: 0; batch classifier loss: 0.233867; batch adversarial loss: 0.432713\n",
      "epoch 22; iter: 0; batch classifier loss: 0.214068; batch adversarial loss: 0.545263\n",
      "epoch 23; iter: 0; batch classifier loss: 0.167836; batch adversarial loss: 0.451155\n",
      "epoch 24; iter: 0; batch classifier loss: 0.135550; batch adversarial loss: 0.469962\n",
      "epoch 25; iter: 0; batch classifier loss: 0.147663; batch adversarial loss: 0.493534\n",
      "epoch 26; iter: 0; batch classifier loss: 0.192730; batch adversarial loss: 0.479095\n",
      "epoch 27; iter: 0; batch classifier loss: 0.153862; batch adversarial loss: 0.424266\n",
      "epoch 28; iter: 0; batch classifier loss: 0.097874; batch adversarial loss: 0.418294\n",
      "epoch 29; iter: 0; batch classifier loss: 0.135105; batch adversarial loss: 0.430265\n",
      "epoch 30; iter: 0; batch classifier loss: 0.152455; batch adversarial loss: 0.430050\n",
      "epoch 31; iter: 0; batch classifier loss: 0.151090; batch adversarial loss: 0.464736\n",
      "epoch 32; iter: 0; batch classifier loss: 0.107413; batch adversarial loss: 0.359421\n",
      "epoch 33; iter: 0; batch classifier loss: 0.124346; batch adversarial loss: 0.466363\n",
      "epoch 34; iter: 0; batch classifier loss: 0.114876; batch adversarial loss: 0.574878\n",
      "epoch 35; iter: 0; batch classifier loss: 0.133668; batch adversarial loss: 0.514902\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128005; batch adversarial loss: 0.469765\n",
      "epoch 37; iter: 0; batch classifier loss: 0.106888; batch adversarial loss: 0.497155\n",
      "epoch 38; iter: 0; batch classifier loss: 0.153041; batch adversarial loss: 0.470120\n",
      "epoch 39; iter: 0; batch classifier loss: 0.133955; batch adversarial loss: 0.354979\n",
      "epoch 40; iter: 0; batch classifier loss: 0.108681; batch adversarial loss: 0.381852\n",
      "epoch 41; iter: 0; batch classifier loss: 0.091052; batch adversarial loss: 0.407316\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103595; batch adversarial loss: 0.459518\n",
      "epoch 43; iter: 0; batch classifier loss: 0.119261; batch adversarial loss: 0.540876\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123511; batch adversarial loss: 0.398270\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102834; batch adversarial loss: 0.381741\n",
      "epoch 46; iter: 0; batch classifier loss: 0.105332; batch adversarial loss: 0.458805\n",
      "epoch 47; iter: 0; batch classifier loss: 0.093525; batch adversarial loss: 0.510307\n",
      "epoch 48; iter: 0; batch classifier loss: 0.124289; batch adversarial loss: 0.511454\n",
      "epoch 49; iter: 0; batch classifier loss: 0.076193; batch adversarial loss: 0.394690\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108975; batch adversarial loss: 0.387256\n",
      "epoch 51; iter: 0; batch classifier loss: 0.139340; batch adversarial loss: 0.467567\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161185; batch adversarial loss: 0.513313\n",
      "epoch 53; iter: 0; batch classifier loss: 0.144665; batch adversarial loss: 0.516456\n",
      "epoch 54; iter: 0; batch classifier loss: 0.061076; batch adversarial loss: 0.499009\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096769; batch adversarial loss: 0.575801\n",
      "epoch 56; iter: 0; batch classifier loss: 0.108854; batch adversarial loss: 0.466893\n",
      "epoch 57; iter: 0; batch classifier loss: 0.120654; batch adversarial loss: 0.464441\n",
      "epoch 58; iter: 0; batch classifier loss: 0.075933; batch adversarial loss: 0.414715\n",
      "epoch 59; iter: 0; batch classifier loss: 0.035996; batch adversarial loss: 0.489903\n",
      "epoch 60; iter: 0; batch classifier loss: 0.110041; batch adversarial loss: 0.421497\n",
      "epoch 61; iter: 0; batch classifier loss: 0.134337; batch adversarial loss: 0.431853\n",
      "epoch 62; iter: 0; batch classifier loss: 0.075671; batch adversarial loss: 0.511126\n",
      "epoch 63; iter: 0; batch classifier loss: 0.111106; batch adversarial loss: 0.353553\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083954; batch adversarial loss: 0.404062\n",
      "epoch 65; iter: 0; batch classifier loss: 0.094104; batch adversarial loss: 0.455757\n",
      "epoch 66; iter: 0; batch classifier loss: 0.090487; batch adversarial loss: 0.478816\n",
      "epoch 67; iter: 0; batch classifier loss: 0.063943; batch adversarial loss: 0.388098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.095839; batch adversarial loss: 0.424012\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076069; batch adversarial loss: 0.446276\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066923; batch adversarial loss: 0.507703\n",
      "epoch 71; iter: 0; batch classifier loss: 0.049061; batch adversarial loss: 0.476115\n",
      "epoch 72; iter: 0; batch classifier loss: 0.076033; batch adversarial loss: 0.573323\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075684; batch adversarial loss: 0.487036\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066855; batch adversarial loss: 0.425589\n",
      "epoch 75; iter: 0; batch classifier loss: 0.097574; batch adversarial loss: 0.401819\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060355; batch adversarial loss: 0.429508\n",
      "epoch 77; iter: 0; batch classifier loss: 0.093160; batch adversarial loss: 0.442191\n",
      "epoch 78; iter: 0; batch classifier loss: 0.050998; batch adversarial loss: 0.434422\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044905; batch adversarial loss: 0.580238\n",
      "epoch 80; iter: 0; batch classifier loss: 0.082893; batch adversarial loss: 0.507863\n",
      "epoch 81; iter: 0; batch classifier loss: 0.087848; batch adversarial loss: 0.441396\n",
      "epoch 82; iter: 0; batch classifier loss: 0.039585; batch adversarial loss: 0.464653\n",
      "epoch 83; iter: 0; batch classifier loss: 0.053203; batch adversarial loss: 0.444335\n",
      "epoch 84; iter: 0; batch classifier loss: 0.074824; batch adversarial loss: 0.489825\n",
      "epoch 85; iter: 0; batch classifier loss: 0.023220; batch adversarial loss: 0.432419\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070771; batch adversarial loss: 0.540063\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062513; batch adversarial loss: 0.443113\n",
      "epoch 88; iter: 0; batch classifier loss: 0.044610; batch adversarial loss: 0.448428\n",
      "epoch 89; iter: 0; batch classifier loss: 0.035666; batch adversarial loss: 0.462958\n",
      "epoch 90; iter: 0; batch classifier loss: 0.035080; batch adversarial loss: 0.437098\n",
      "epoch 91; iter: 0; batch classifier loss: 0.038091; batch adversarial loss: 0.450739\n",
      "epoch 92; iter: 0; batch classifier loss: 0.056445; batch adversarial loss: 0.494634\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053450; batch adversarial loss: 0.437353\n",
      "epoch 94; iter: 0; batch classifier loss: 0.069192; batch adversarial loss: 0.376785\n",
      "epoch 95; iter: 0; batch classifier loss: 0.022787; batch adversarial loss: 0.538995\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046054; batch adversarial loss: 0.453876\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065980; batch adversarial loss: 0.385206\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050951; batch adversarial loss: 0.340798\n",
      "epoch 99; iter: 0; batch classifier loss: 0.083009; batch adversarial loss: 0.509724\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048347; batch adversarial loss: 0.430809\n",
      "epoch 101; iter: 0; batch classifier loss: 0.078218; batch adversarial loss: 0.494174\n",
      "epoch 102; iter: 0; batch classifier loss: 0.080690; batch adversarial loss: 0.505578\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048587; batch adversarial loss: 0.503446\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045635; batch adversarial loss: 0.464402\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047382; batch adversarial loss: 0.522764\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044589; batch adversarial loss: 0.401797\n",
      "epoch 107; iter: 0; batch classifier loss: 0.086552; batch adversarial loss: 0.480211\n",
      "epoch 108; iter: 0; batch classifier loss: 0.078081; batch adversarial loss: 0.448595\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054585; batch adversarial loss: 0.479499\n",
      "epoch 110; iter: 0; batch classifier loss: 0.102764; batch adversarial loss: 0.469290\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047925; batch adversarial loss: 0.363010\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040947; batch adversarial loss: 0.453565\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037034; batch adversarial loss: 0.419189\n",
      "epoch 114; iter: 0; batch classifier loss: 0.102394; batch adversarial loss: 0.513657\n",
      "epoch 115; iter: 0; batch classifier loss: 0.023899; batch adversarial loss: 0.368250\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035733; batch adversarial loss: 0.538812\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061155; batch adversarial loss: 0.423707\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031952; batch adversarial loss: 0.410396\n",
      "epoch 119; iter: 0; batch classifier loss: 0.085117; batch adversarial loss: 0.429844\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031911; batch adversarial loss: 0.491304\n",
      "epoch 121; iter: 0; batch classifier loss: 0.073349; batch adversarial loss: 0.469049\n",
      "epoch 122; iter: 0; batch classifier loss: 0.021191; batch adversarial loss: 0.459549\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026741; batch adversarial loss: 0.423891\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039607; batch adversarial loss: 0.587314\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050844; batch adversarial loss: 0.384110\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039924; batch adversarial loss: 0.494131\n",
      "epoch 127; iter: 0; batch classifier loss: 0.057500; batch adversarial loss: 0.385189\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039707; batch adversarial loss: 0.474281\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028936; batch adversarial loss: 0.539058\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045031; batch adversarial loss: 0.520627\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040300; batch adversarial loss: 0.426290\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029459; batch adversarial loss: 0.517165\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041590; batch adversarial loss: 0.474576\n",
      "epoch 134; iter: 0; batch classifier loss: 0.022861; batch adversarial loss: 0.533001\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043943; batch adversarial loss: 0.362585\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031161; batch adversarial loss: 0.520795\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044045; batch adversarial loss: 0.460718\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030320; batch adversarial loss: 0.467622\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033097; batch adversarial loss: 0.429605\n",
      "epoch 140; iter: 0; batch classifier loss: 0.076234; batch adversarial loss: 0.452850\n",
      "epoch 141; iter: 0; batch classifier loss: 0.041620; batch adversarial loss: 0.471454\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013560; batch adversarial loss: 0.494235\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035509; batch adversarial loss: 0.475820\n",
      "epoch 144; iter: 0; batch classifier loss: 0.015677; batch adversarial loss: 0.445874\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036492; batch adversarial loss: 0.401346\n",
      "epoch 146; iter: 0; batch classifier loss: 0.046939; batch adversarial loss: 0.516160\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032162; batch adversarial loss: 0.505416\n",
      "epoch 148; iter: 0; batch classifier loss: 0.037618; batch adversarial loss: 0.380678\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017887; batch adversarial loss: 0.417421\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024597; batch adversarial loss: 0.486228\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029871; batch adversarial loss: 0.521037\n",
      "epoch 152; iter: 0; batch classifier loss: 0.062215; batch adversarial loss: 0.451302\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025901; batch adversarial loss: 0.537321\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034584; batch adversarial loss: 0.476880\n",
      "epoch 155; iter: 0; batch classifier loss: 0.008994; batch adversarial loss: 0.486956\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015444; batch adversarial loss: 0.479165\n",
      "epoch 157; iter: 0; batch classifier loss: 0.044967; batch adversarial loss: 0.374713\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028375; batch adversarial loss: 0.432305\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049186; batch adversarial loss: 0.418116\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044562; batch adversarial loss: 0.373866\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014135; batch adversarial loss: 0.387927\n",
      "epoch 162; iter: 0; batch classifier loss: 0.008690; batch adversarial loss: 0.505447\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016664; batch adversarial loss: 0.487461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.040001; batch adversarial loss: 0.464590\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044139; batch adversarial loss: 0.380533\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014782; batch adversarial loss: 0.500067\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039011; batch adversarial loss: 0.503443\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037971; batch adversarial loss: 0.435402\n",
      "epoch 169; iter: 0; batch classifier loss: 0.047993; batch adversarial loss: 0.513203\n",
      "epoch 170; iter: 0; batch classifier loss: 0.005846; batch adversarial loss: 0.439318\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022680; batch adversarial loss: 0.452574\n",
      "epoch 172; iter: 0; batch classifier loss: 0.046758; batch adversarial loss: 0.382010\n",
      "epoch 173; iter: 0; batch classifier loss: 0.044712; batch adversarial loss: 0.458110\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011588; batch adversarial loss: 0.502278\n",
      "epoch 175; iter: 0; batch classifier loss: 0.044824; batch adversarial loss: 0.480611\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031388; batch adversarial loss: 0.456069\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028992; batch adversarial loss: 0.400362\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031103; batch adversarial loss: 0.355755\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037069; batch adversarial loss: 0.430158\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018766; batch adversarial loss: 0.528760\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032845; batch adversarial loss: 0.512905\n",
      "epoch 182; iter: 0; batch classifier loss: 0.035383; batch adversarial loss: 0.412512\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028809; batch adversarial loss: 0.443025\n",
      "epoch 184; iter: 0; batch classifier loss: 0.076797; batch adversarial loss: 0.522604\n",
      "epoch 185; iter: 0; batch classifier loss: 0.030181; batch adversarial loss: 0.464721\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020451; batch adversarial loss: 0.462619\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024591; batch adversarial loss: 0.389209\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028430; batch adversarial loss: 0.400861\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026086; batch adversarial loss: 0.457846\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019374; batch adversarial loss: 0.485598\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029791; batch adversarial loss: 0.373920\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025106; batch adversarial loss: 0.480787\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018687; batch adversarial loss: 0.422259\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032490; batch adversarial loss: 0.347948\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018026; batch adversarial loss: 0.416637\n",
      "epoch 196; iter: 0; batch classifier loss: 0.051769; batch adversarial loss: 0.366996\n",
      "epoch 197; iter: 0; batch classifier loss: 0.030848; batch adversarial loss: 0.464470\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041865; batch adversarial loss: 0.388850\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024723; batch adversarial loss: 0.430258\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720711; batch adversarial loss: 0.535330\n",
      "epoch 1; iter: 0; batch classifier loss: 0.361386; batch adversarial loss: 0.595371\n",
      "epoch 2; iter: 0; batch classifier loss: 0.301829; batch adversarial loss: 0.571799\n",
      "epoch 3; iter: 0; batch classifier loss: 0.440727; batch adversarial loss: 0.593675\n",
      "epoch 4; iter: 0; batch classifier loss: 0.345230; batch adversarial loss: 0.554975\n",
      "epoch 5; iter: 0; batch classifier loss: 0.328081; batch adversarial loss: 0.559385\n",
      "epoch 6; iter: 0; batch classifier loss: 0.344315; batch adversarial loss: 0.607946\n",
      "epoch 7; iter: 0; batch classifier loss: 0.343462; batch adversarial loss: 0.550853\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568797; batch adversarial loss: 0.571700\n",
      "epoch 9; iter: 0; batch classifier loss: 0.586306; batch adversarial loss: 0.555033\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549303; batch adversarial loss: 0.522232\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565276; batch adversarial loss: 0.488081\n",
      "epoch 12; iter: 0; batch classifier loss: 0.490880; batch adversarial loss: 0.481766\n",
      "epoch 13; iter: 0; batch classifier loss: 0.382900; batch adversarial loss: 0.503566\n",
      "epoch 14; iter: 0; batch classifier loss: 0.350444; batch adversarial loss: 0.459401\n",
      "epoch 15; iter: 0; batch classifier loss: 0.288537; batch adversarial loss: 0.445542\n",
      "epoch 16; iter: 0; batch classifier loss: 0.261219; batch adversarial loss: 0.480434\n",
      "epoch 17; iter: 0; batch classifier loss: 0.292860; batch adversarial loss: 0.459695\n",
      "epoch 18; iter: 0; batch classifier loss: 0.260415; batch adversarial loss: 0.466376\n",
      "epoch 19; iter: 0; batch classifier loss: 0.276108; batch adversarial loss: 0.446908\n",
      "epoch 20; iter: 0; batch classifier loss: 0.175845; batch adversarial loss: 0.416071\n",
      "epoch 21; iter: 0; batch classifier loss: 0.177182; batch adversarial loss: 0.476698\n",
      "epoch 22; iter: 0; batch classifier loss: 0.177643; batch adversarial loss: 0.484735\n",
      "epoch 23; iter: 0; batch classifier loss: 0.196381; batch adversarial loss: 0.500353\n",
      "epoch 24; iter: 0; batch classifier loss: 0.196136; batch adversarial loss: 0.413211\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132615; batch adversarial loss: 0.501728\n",
      "epoch 26; iter: 0; batch classifier loss: 0.137329; batch adversarial loss: 0.401509\n",
      "epoch 27; iter: 0; batch classifier loss: 0.099301; batch adversarial loss: 0.479657\n",
      "epoch 28; iter: 0; batch classifier loss: 0.150965; batch adversarial loss: 0.408779\n",
      "epoch 29; iter: 0; batch classifier loss: 0.159237; batch adversarial loss: 0.385400\n",
      "epoch 30; iter: 0; batch classifier loss: 0.168740; batch adversarial loss: 0.438339\n",
      "epoch 31; iter: 0; batch classifier loss: 0.227819; batch adversarial loss: 0.353558\n",
      "epoch 32; iter: 0; batch classifier loss: 0.200991; batch adversarial loss: 0.390431\n",
      "epoch 33; iter: 0; batch classifier loss: 0.122977; batch adversarial loss: 0.414111\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148898; batch adversarial loss: 0.392665\n",
      "epoch 35; iter: 0; batch classifier loss: 0.101179; batch adversarial loss: 0.453817\n",
      "epoch 36; iter: 0; batch classifier loss: 0.164416; batch adversarial loss: 0.486629\n",
      "epoch 37; iter: 0; batch classifier loss: 0.086631; batch adversarial loss: 0.525976\n",
      "epoch 38; iter: 0; batch classifier loss: 0.128430; batch adversarial loss: 0.417424\n",
      "epoch 39; iter: 0; batch classifier loss: 0.137808; batch adversarial loss: 0.444799\n",
      "epoch 40; iter: 0; batch classifier loss: 0.131317; batch adversarial loss: 0.562937\n",
      "epoch 41; iter: 0; batch classifier loss: 0.079970; batch adversarial loss: 0.497124\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110020; batch adversarial loss: 0.433806\n",
      "epoch 43; iter: 0; batch classifier loss: 0.091946; batch adversarial loss: 0.388300\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112253; batch adversarial loss: 0.507303\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097146; batch adversarial loss: 0.463690\n",
      "epoch 46; iter: 0; batch classifier loss: 0.109451; batch adversarial loss: 0.455457\n",
      "epoch 47; iter: 0; batch classifier loss: 0.070349; batch adversarial loss: 0.387403\n",
      "epoch 48; iter: 0; batch classifier loss: 0.060639; batch adversarial loss: 0.451364\n",
      "epoch 49; iter: 0; batch classifier loss: 0.136306; batch adversarial loss: 0.388998\n",
      "epoch 50; iter: 0; batch classifier loss: 0.116002; batch adversarial loss: 0.472727\n",
      "epoch 51; iter: 0; batch classifier loss: 0.100522; batch adversarial loss: 0.444081\n",
      "epoch 52; iter: 0; batch classifier loss: 0.052205; batch adversarial loss: 0.504166\n",
      "epoch 53; iter: 0; batch classifier loss: 0.069656; batch adversarial loss: 0.457805\n",
      "epoch 54; iter: 0; batch classifier loss: 0.071356; batch adversarial loss: 0.429248\n",
      "epoch 55; iter: 0; batch classifier loss: 0.075302; batch adversarial loss: 0.417358\n",
      "epoch 56; iter: 0; batch classifier loss: 0.108789; batch adversarial loss: 0.490493\n",
      "epoch 57; iter: 0; batch classifier loss: 0.066845; batch adversarial loss: 0.495562\n",
      "epoch 58; iter: 0; batch classifier loss: 0.093664; batch adversarial loss: 0.475216\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072467; batch adversarial loss: 0.506464\n",
      "epoch 60; iter: 0; batch classifier loss: 0.085502; batch adversarial loss: 0.388227\n",
      "epoch 61; iter: 0; batch classifier loss: 0.095522; batch adversarial loss: 0.468123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.093757; batch adversarial loss: 0.440277\n",
      "epoch 63; iter: 0; batch classifier loss: 0.107663; batch adversarial loss: 0.418142\n",
      "epoch 64; iter: 0; batch classifier loss: 0.057277; batch adversarial loss: 0.433515\n",
      "epoch 65; iter: 0; batch classifier loss: 0.089616; batch adversarial loss: 0.437101\n",
      "epoch 66; iter: 0; batch classifier loss: 0.153464; batch adversarial loss: 0.429195\n",
      "epoch 67; iter: 0; batch classifier loss: 0.132689; batch adversarial loss: 0.415597\n",
      "epoch 68; iter: 0; batch classifier loss: 0.108209; batch adversarial loss: 0.515621\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103366; batch adversarial loss: 0.486883\n",
      "epoch 70; iter: 0; batch classifier loss: 0.089171; batch adversarial loss: 0.430530\n",
      "epoch 71; iter: 0; batch classifier loss: 0.119632; batch adversarial loss: 0.405343\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064139; batch adversarial loss: 0.455394\n",
      "epoch 73; iter: 0; batch classifier loss: 0.122196; batch adversarial loss: 0.381981\n",
      "epoch 74; iter: 0; batch classifier loss: 0.105091; batch adversarial loss: 0.511367\n",
      "epoch 75; iter: 0; batch classifier loss: 0.099943; batch adversarial loss: 0.467025\n",
      "epoch 76; iter: 0; batch classifier loss: 0.045656; batch adversarial loss: 0.438489\n",
      "epoch 77; iter: 0; batch classifier loss: 0.105502; batch adversarial loss: 0.397222\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082090; batch adversarial loss: 0.525712\n",
      "epoch 79; iter: 0; batch classifier loss: 0.091678; batch adversarial loss: 0.475990\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076036; batch adversarial loss: 0.406208\n",
      "epoch 81; iter: 0; batch classifier loss: 0.052264; batch adversarial loss: 0.389439\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059036; batch adversarial loss: 0.471994\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056152; batch adversarial loss: 0.483724\n",
      "epoch 84; iter: 0; batch classifier loss: 0.066822; batch adversarial loss: 0.448391\n",
      "epoch 85; iter: 0; batch classifier loss: 0.040451; batch adversarial loss: 0.498248\n",
      "epoch 86; iter: 0; batch classifier loss: 0.049622; batch adversarial loss: 0.478799\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056895; batch adversarial loss: 0.426977\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057467; batch adversarial loss: 0.429858\n",
      "epoch 89; iter: 0; batch classifier loss: 0.089247; batch adversarial loss: 0.462367\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054270; batch adversarial loss: 0.389774\n",
      "epoch 91; iter: 0; batch classifier loss: 0.037139; batch adversarial loss: 0.509117\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082070; batch adversarial loss: 0.450082\n",
      "epoch 93; iter: 0; batch classifier loss: 0.066762; batch adversarial loss: 0.449686\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066306; batch adversarial loss: 0.505526\n",
      "epoch 95; iter: 0; batch classifier loss: 0.088998; batch adversarial loss: 0.501496\n",
      "epoch 96; iter: 0; batch classifier loss: 0.054449; batch adversarial loss: 0.391961\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081265; batch adversarial loss: 0.400578\n",
      "epoch 98; iter: 0; batch classifier loss: 0.099584; batch adversarial loss: 0.582415\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045959; batch adversarial loss: 0.459099\n",
      "epoch 100; iter: 0; batch classifier loss: 0.083799; batch adversarial loss: 0.432871\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061508; batch adversarial loss: 0.414445\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068519; batch adversarial loss: 0.411472\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045496; batch adversarial loss: 0.425875\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059893; batch adversarial loss: 0.480702\n",
      "epoch 105; iter: 0; batch classifier loss: 0.073903; batch adversarial loss: 0.441001\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047748; batch adversarial loss: 0.463140\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062821; batch adversarial loss: 0.497236\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057614; batch adversarial loss: 0.370688\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044881; batch adversarial loss: 0.472118\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057949; batch adversarial loss: 0.400300\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047558; batch adversarial loss: 0.463378\n",
      "epoch 112; iter: 0; batch classifier loss: 0.120357; batch adversarial loss: 0.470762\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052224; batch adversarial loss: 0.370035\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053569; batch adversarial loss: 0.476663\n",
      "epoch 115; iter: 0; batch classifier loss: 0.107584; batch adversarial loss: 0.376472\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026364; batch adversarial loss: 0.432692\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029620; batch adversarial loss: 0.449834\n",
      "epoch 118; iter: 0; batch classifier loss: 0.061066; batch adversarial loss: 0.409053\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044844; batch adversarial loss: 0.479470\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022976; batch adversarial loss: 0.440169\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028371; batch adversarial loss: 0.353564\n",
      "epoch 122; iter: 0; batch classifier loss: 0.063591; batch adversarial loss: 0.358907\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045968; batch adversarial loss: 0.524411\n",
      "epoch 124; iter: 0; batch classifier loss: 0.085403; batch adversarial loss: 0.376324\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018346; batch adversarial loss: 0.430513\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045552; batch adversarial loss: 0.522285\n",
      "epoch 127; iter: 0; batch classifier loss: 0.061180; batch adversarial loss: 0.344094\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040928; batch adversarial loss: 0.408842\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020392; batch adversarial loss: 0.491989\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035297; batch adversarial loss: 0.433344\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041437; batch adversarial loss: 0.454993\n",
      "epoch 132; iter: 0; batch classifier loss: 0.055801; batch adversarial loss: 0.499670\n",
      "epoch 133; iter: 0; batch classifier loss: 0.057921; batch adversarial loss: 0.447546\n",
      "epoch 134; iter: 0; batch classifier loss: 0.054421; batch adversarial loss: 0.281411\n",
      "epoch 135; iter: 0; batch classifier loss: 0.062501; batch adversarial loss: 0.486138\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043659; batch adversarial loss: 0.473430\n",
      "epoch 137; iter: 0; batch classifier loss: 0.065362; batch adversarial loss: 0.480097\n",
      "epoch 138; iter: 0; batch classifier loss: 0.057575; batch adversarial loss: 0.459959\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017787; batch adversarial loss: 0.472124\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037562; batch adversarial loss: 0.418462\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033103; batch adversarial loss: 0.411111\n",
      "epoch 142; iter: 0; batch classifier loss: 0.063833; batch adversarial loss: 0.473252\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029494; batch adversarial loss: 0.421524\n",
      "epoch 144; iter: 0; batch classifier loss: 0.015710; batch adversarial loss: 0.564801\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017370; batch adversarial loss: 0.324932\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029281; batch adversarial loss: 0.377651\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044434; batch adversarial loss: 0.447455\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019972; batch adversarial loss: 0.415285\n",
      "epoch 149; iter: 0; batch classifier loss: 0.073003; batch adversarial loss: 0.493226\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032225; batch adversarial loss: 0.382511\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013351; batch adversarial loss: 0.458127\n",
      "epoch 152; iter: 0; batch classifier loss: 0.052969; batch adversarial loss: 0.363912\n",
      "epoch 153; iter: 0; batch classifier loss: 0.050617; batch adversarial loss: 0.372834\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031386; batch adversarial loss: 0.440947\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038389; batch adversarial loss: 0.447684\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024048; batch adversarial loss: 0.488134\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031017; batch adversarial loss: 0.423118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.011295; batch adversarial loss: 0.407037\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034823; batch adversarial loss: 0.448055\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023002; batch adversarial loss: 0.423540\n",
      "epoch 161; iter: 0; batch classifier loss: 0.050760; batch adversarial loss: 0.525882\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033018; batch adversarial loss: 0.393093\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016711; batch adversarial loss: 0.384167\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014606; batch adversarial loss: 0.375812\n",
      "epoch 165; iter: 0; batch classifier loss: 0.055209; batch adversarial loss: 0.444238\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034728; batch adversarial loss: 0.410699\n",
      "epoch 167; iter: 0; batch classifier loss: 0.047622; batch adversarial loss: 0.396556\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012762; batch adversarial loss: 0.360370\n",
      "epoch 169; iter: 0; batch classifier loss: 0.053687; batch adversarial loss: 0.392852\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032894; batch adversarial loss: 0.443783\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028429; batch adversarial loss: 0.529313\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017518; batch adversarial loss: 0.343896\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023500; batch adversarial loss: 0.457807\n",
      "epoch 174; iter: 0; batch classifier loss: 0.053081; batch adversarial loss: 0.446417\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024407; batch adversarial loss: 0.431651\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014367; batch adversarial loss: 0.492610\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017604; batch adversarial loss: 0.400685\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026302; batch adversarial loss: 0.569942\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024517; batch adversarial loss: 0.368047\n",
      "epoch 180; iter: 0; batch classifier loss: 0.036066; batch adversarial loss: 0.463889\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024222; batch adversarial loss: 0.405121\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030947; batch adversarial loss: 0.335949\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017252; batch adversarial loss: 0.538267\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035199; batch adversarial loss: 0.391663\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040297; batch adversarial loss: 0.492084\n",
      "epoch 186; iter: 0; batch classifier loss: 0.042239; batch adversarial loss: 0.389396\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012160; batch adversarial loss: 0.456081\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014055; batch adversarial loss: 0.472739\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019763; batch adversarial loss: 0.395106\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009495; batch adversarial loss: 0.472483\n",
      "epoch 191; iter: 0; batch classifier loss: 0.049704; batch adversarial loss: 0.475865\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019529; batch adversarial loss: 0.343236\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023781; batch adversarial loss: 0.419140\n",
      "epoch 194; iter: 0; batch classifier loss: 0.063157; batch adversarial loss: 0.400515\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026475; batch adversarial loss: 0.491501\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026134; batch adversarial loss: 0.387278\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009979; batch adversarial loss: 0.419797\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017259; batch adversarial loss: 0.478472\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032199; batch adversarial loss: 0.515119\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703967; batch adversarial loss: 0.587208\n",
      "epoch 1; iter: 0; batch classifier loss: 0.387926; batch adversarial loss: 0.656877\n",
      "epoch 2; iter: 0; batch classifier loss: 0.429771; batch adversarial loss: 0.618265\n",
      "epoch 3; iter: 0; batch classifier loss: 0.318319; batch adversarial loss: 0.605706\n",
      "epoch 4; iter: 0; batch classifier loss: 0.352293; batch adversarial loss: 0.553049\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343731; batch adversarial loss: 0.551326\n",
      "epoch 6; iter: 0; batch classifier loss: 0.313810; batch adversarial loss: 0.555731\n",
      "epoch 7; iter: 0; batch classifier loss: 0.296315; batch adversarial loss: 0.495297\n",
      "epoch 8; iter: 0; batch classifier loss: 0.297858; batch adversarial loss: 0.492691\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282430; batch adversarial loss: 0.471923\n",
      "epoch 10; iter: 0; batch classifier loss: 0.243511; batch adversarial loss: 0.524735\n",
      "epoch 11; iter: 0; batch classifier loss: 0.262993; batch adversarial loss: 0.473462\n",
      "epoch 12; iter: 0; batch classifier loss: 0.279841; batch adversarial loss: 0.471231\n",
      "epoch 13; iter: 0; batch classifier loss: 0.193630; batch adversarial loss: 0.516482\n",
      "epoch 14; iter: 0; batch classifier loss: 0.218310; batch adversarial loss: 0.395318\n",
      "epoch 15; iter: 0; batch classifier loss: 0.157150; batch adversarial loss: 0.532008\n",
      "epoch 16; iter: 0; batch classifier loss: 0.174487; batch adversarial loss: 0.506409\n",
      "epoch 17; iter: 0; batch classifier loss: 0.196115; batch adversarial loss: 0.440282\n",
      "epoch 18; iter: 0; batch classifier loss: 0.183394; batch adversarial loss: 0.560239\n",
      "epoch 19; iter: 0; batch classifier loss: 0.227009; batch adversarial loss: 0.551447\n",
      "epoch 20; iter: 0; batch classifier loss: 0.155925; batch adversarial loss: 0.550826\n",
      "epoch 21; iter: 0; batch classifier loss: 0.192793; batch adversarial loss: 0.552081\n",
      "epoch 22; iter: 0; batch classifier loss: 0.179708; batch adversarial loss: 0.593961\n",
      "epoch 23; iter: 0; batch classifier loss: 0.155720; batch adversarial loss: 0.475306\n",
      "epoch 24; iter: 0; batch classifier loss: 0.249685; batch adversarial loss: 0.512398\n",
      "epoch 25; iter: 0; batch classifier loss: 0.201472; batch adversarial loss: 0.498933\n",
      "epoch 26; iter: 0; batch classifier loss: 0.164668; batch adversarial loss: 0.417540\n",
      "epoch 27; iter: 0; batch classifier loss: 0.251337; batch adversarial loss: 0.533460\n",
      "epoch 28; iter: 0; batch classifier loss: 0.201548; batch adversarial loss: 0.534811\n",
      "epoch 29; iter: 0; batch classifier loss: 0.182474; batch adversarial loss: 0.470278\n",
      "epoch 30; iter: 0; batch classifier loss: 0.214869; batch adversarial loss: 0.469053\n",
      "epoch 31; iter: 0; batch classifier loss: 0.216501; batch adversarial loss: 0.462813\n",
      "epoch 32; iter: 0; batch classifier loss: 0.172396; batch adversarial loss: 0.413331\n",
      "epoch 33; iter: 0; batch classifier loss: 0.239970; batch adversarial loss: 0.402056\n",
      "epoch 34; iter: 0; batch classifier loss: 0.402540; batch adversarial loss: 0.389996\n",
      "epoch 35; iter: 0; batch classifier loss: 0.222881; batch adversarial loss: 0.420644\n",
      "epoch 36; iter: 0; batch classifier loss: 0.114115; batch adversarial loss: 0.427528\n",
      "epoch 37; iter: 0; batch classifier loss: 0.106800; batch adversarial loss: 0.540257\n",
      "epoch 38; iter: 0; batch classifier loss: 0.113715; batch adversarial loss: 0.465197\n",
      "epoch 39; iter: 0; batch classifier loss: 0.064606; batch adversarial loss: 0.492361\n",
      "epoch 40; iter: 0; batch classifier loss: 0.098526; batch adversarial loss: 0.540783\n",
      "epoch 41; iter: 0; batch classifier loss: 0.091308; batch adversarial loss: 0.468219\n",
      "epoch 42; iter: 0; batch classifier loss: 0.104429; batch adversarial loss: 0.447951\n",
      "epoch 43; iter: 0; batch classifier loss: 0.103500; batch adversarial loss: 0.412642\n",
      "epoch 44; iter: 0; batch classifier loss: 0.051845; batch adversarial loss: 0.497864\n",
      "epoch 45; iter: 0; batch classifier loss: 0.063644; batch adversarial loss: 0.415455\n",
      "epoch 46; iter: 0; batch classifier loss: 0.082092; batch adversarial loss: 0.335198\n",
      "epoch 47; iter: 0; batch classifier loss: 0.088602; batch adversarial loss: 0.408204\n",
      "epoch 48; iter: 0; batch classifier loss: 0.090952; batch adversarial loss: 0.371403\n",
      "epoch 49; iter: 0; batch classifier loss: 0.066355; batch adversarial loss: 0.441683\n",
      "epoch 50; iter: 0; batch classifier loss: 0.095189; batch adversarial loss: 0.390932\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098106; batch adversarial loss: 0.397528\n",
      "epoch 52; iter: 0; batch classifier loss: 0.074919; batch adversarial loss: 0.468059\n",
      "epoch 53; iter: 0; batch classifier loss: 0.106488; batch adversarial loss: 0.534032\n",
      "epoch 54; iter: 0; batch classifier loss: 0.054217; batch adversarial loss: 0.508919\n",
      "epoch 55; iter: 0; batch classifier loss: 0.103042; batch adversarial loss: 0.342268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.068063; batch adversarial loss: 0.404788\n",
      "epoch 57; iter: 0; batch classifier loss: 0.185606; batch adversarial loss: 0.480991\n",
      "epoch 58; iter: 0; batch classifier loss: 0.082833; batch adversarial loss: 0.407348\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087203; batch adversarial loss: 0.367165\n",
      "epoch 60; iter: 0; batch classifier loss: 0.070598; batch adversarial loss: 0.519014\n",
      "epoch 61; iter: 0; batch classifier loss: 0.053059; batch adversarial loss: 0.430146\n",
      "epoch 62; iter: 0; batch classifier loss: 0.068448; batch adversarial loss: 0.503730\n",
      "epoch 63; iter: 0; batch classifier loss: 0.036372; batch adversarial loss: 0.533419\n",
      "epoch 64; iter: 0; batch classifier loss: 0.123189; batch adversarial loss: 0.532363\n",
      "epoch 65; iter: 0; batch classifier loss: 0.056121; batch adversarial loss: 0.510688\n",
      "epoch 66; iter: 0; batch classifier loss: 0.037742; batch adversarial loss: 0.347362\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061511; batch adversarial loss: 0.314662\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070267; batch adversarial loss: 0.427323\n",
      "epoch 69; iter: 0; batch classifier loss: 0.112566; batch adversarial loss: 0.454775\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066758; batch adversarial loss: 0.451280\n",
      "epoch 71; iter: 0; batch classifier loss: 0.082617; batch adversarial loss: 0.532268\n",
      "epoch 72; iter: 0; batch classifier loss: 0.075121; batch adversarial loss: 0.398834\n",
      "epoch 73; iter: 0; batch classifier loss: 0.049482; batch adversarial loss: 0.392412\n",
      "epoch 74; iter: 0; batch classifier loss: 0.071823; batch adversarial loss: 0.392749\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073630; batch adversarial loss: 0.457440\n",
      "epoch 76; iter: 0; batch classifier loss: 0.048928; batch adversarial loss: 0.490059\n",
      "epoch 77; iter: 0; batch classifier loss: 0.061965; batch adversarial loss: 0.412749\n",
      "epoch 78; iter: 0; batch classifier loss: 0.084712; batch adversarial loss: 0.481004\n",
      "epoch 79; iter: 0; batch classifier loss: 0.048755; batch adversarial loss: 0.453646\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075328; batch adversarial loss: 0.500839\n",
      "epoch 81; iter: 0; batch classifier loss: 0.042562; batch adversarial loss: 0.355652\n",
      "epoch 82; iter: 0; batch classifier loss: 0.089462; batch adversarial loss: 0.537784\n",
      "epoch 83; iter: 0; batch classifier loss: 0.038853; batch adversarial loss: 0.417247\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075875; batch adversarial loss: 0.497373\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055197; batch adversarial loss: 0.465079\n",
      "epoch 86; iter: 0; batch classifier loss: 0.066642; batch adversarial loss: 0.500585\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049553; batch adversarial loss: 0.515211\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063350; batch adversarial loss: 0.425978\n",
      "epoch 89; iter: 0; batch classifier loss: 0.094178; batch adversarial loss: 0.399906\n",
      "epoch 90; iter: 0; batch classifier loss: 0.047228; batch adversarial loss: 0.418488\n",
      "epoch 91; iter: 0; batch classifier loss: 0.069446; batch adversarial loss: 0.578765\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048378; batch adversarial loss: 0.493003\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056829; batch adversarial loss: 0.540726\n",
      "epoch 94; iter: 0; batch classifier loss: 0.067513; batch adversarial loss: 0.443177\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063937; batch adversarial loss: 0.466151\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048023; batch adversarial loss: 0.477041\n",
      "epoch 97; iter: 0; batch classifier loss: 0.086571; batch adversarial loss: 0.511477\n",
      "epoch 98; iter: 0; batch classifier loss: 0.033206; batch adversarial loss: 0.419461\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050193; batch adversarial loss: 0.464651\n",
      "epoch 100; iter: 0; batch classifier loss: 0.025234; batch adversarial loss: 0.450207\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049936; batch adversarial loss: 0.476060\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047736; batch adversarial loss: 0.508710\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050225; batch adversarial loss: 0.407628\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057747; batch adversarial loss: 0.563658\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045170; batch adversarial loss: 0.401239\n",
      "epoch 106; iter: 0; batch classifier loss: 0.048099; batch adversarial loss: 0.462224\n",
      "epoch 107; iter: 0; batch classifier loss: 0.026991; batch adversarial loss: 0.447767\n",
      "epoch 108; iter: 0; batch classifier loss: 0.081906; batch adversarial loss: 0.407170\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057413; batch adversarial loss: 0.452768\n",
      "epoch 110; iter: 0; batch classifier loss: 0.022578; batch adversarial loss: 0.453460\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039802; batch adversarial loss: 0.403938\n",
      "epoch 112; iter: 0; batch classifier loss: 0.048373; batch adversarial loss: 0.435883\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045164; batch adversarial loss: 0.476284\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048255; batch adversarial loss: 0.480721\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050672; batch adversarial loss: 0.457874\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044296; batch adversarial loss: 0.504940\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056132; batch adversarial loss: 0.428164\n",
      "epoch 118; iter: 0; batch classifier loss: 0.018882; batch adversarial loss: 0.436676\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057010; batch adversarial loss: 0.383757\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044588; batch adversarial loss: 0.448958\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027586; batch adversarial loss: 0.453121\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052077; batch adversarial loss: 0.481922\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049363; batch adversarial loss: 0.534612\n",
      "epoch 124; iter: 0; batch classifier loss: 0.028908; batch adversarial loss: 0.471392\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030617; batch adversarial loss: 0.448829\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046346; batch adversarial loss: 0.433012\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027359; batch adversarial loss: 0.432747\n",
      "epoch 128; iter: 0; batch classifier loss: 0.060353; batch adversarial loss: 0.391102\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034950; batch adversarial loss: 0.550880\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029385; batch adversarial loss: 0.429228\n",
      "epoch 131; iter: 0; batch classifier loss: 0.059564; batch adversarial loss: 0.413867\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039972; batch adversarial loss: 0.481075\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046801; batch adversarial loss: 0.483423\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023902; batch adversarial loss: 0.496714\n",
      "epoch 135; iter: 0; batch classifier loss: 0.052788; batch adversarial loss: 0.362783\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023637; batch adversarial loss: 0.390002\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046103; batch adversarial loss: 0.593884\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033923; batch adversarial loss: 0.398139\n",
      "epoch 139; iter: 0; batch classifier loss: 0.059228; batch adversarial loss: 0.511701\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037777; batch adversarial loss: 0.459403\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020898; batch adversarial loss: 0.474225\n",
      "epoch 142; iter: 0; batch classifier loss: 0.053044; batch adversarial loss: 0.437373\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029956; batch adversarial loss: 0.456930\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024691; batch adversarial loss: 0.447787\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012727; batch adversarial loss: 0.463462\n",
      "epoch 146; iter: 0; batch classifier loss: 0.004206; batch adversarial loss: 0.421780\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013073; batch adversarial loss: 0.503596\n",
      "epoch 148; iter: 0; batch classifier loss: 0.052633; batch adversarial loss: 0.461313\n",
      "epoch 149; iter: 0; batch classifier loss: 0.043597; batch adversarial loss: 0.453924\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042696; batch adversarial loss: 0.432552\n",
      "epoch 151; iter: 0; batch classifier loss: 0.055999; batch adversarial loss: 0.543159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.013905; batch adversarial loss: 0.380407\n",
      "epoch 153; iter: 0; batch classifier loss: 0.043499; batch adversarial loss: 0.503385\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017750; batch adversarial loss: 0.467265\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044222; batch adversarial loss: 0.475239\n",
      "epoch 156; iter: 0; batch classifier loss: 0.054224; batch adversarial loss: 0.492806\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016919; batch adversarial loss: 0.419107\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028001; batch adversarial loss: 0.425811\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049150; batch adversarial loss: 0.510039\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030121; batch adversarial loss: 0.396713\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015062; batch adversarial loss: 0.432202\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037196; batch adversarial loss: 0.432234\n",
      "epoch 163; iter: 0; batch classifier loss: 0.031854; batch adversarial loss: 0.420567\n",
      "epoch 164; iter: 0; batch classifier loss: 0.042002; batch adversarial loss: 0.424790\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023365; batch adversarial loss: 0.416597\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031286; batch adversarial loss: 0.495838\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036449; batch adversarial loss: 0.452008\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045113; batch adversarial loss: 0.379563\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026918; batch adversarial loss: 0.562007\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008108; batch adversarial loss: 0.439175\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036794; batch adversarial loss: 0.560794\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016581; batch adversarial loss: 0.517403\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028984; batch adversarial loss: 0.395210\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013966; batch adversarial loss: 0.424221\n",
      "epoch 175; iter: 0; batch classifier loss: 0.044076; batch adversarial loss: 0.486475\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023365; batch adversarial loss: 0.553952\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033291; batch adversarial loss: 0.587767\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012694; batch adversarial loss: 0.429239\n",
      "epoch 179; iter: 0; batch classifier loss: 0.051029; batch adversarial loss: 0.477786\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016277; batch adversarial loss: 0.468650\n",
      "epoch 181; iter: 0; batch classifier loss: 0.040853; batch adversarial loss: 0.490085\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032934; batch adversarial loss: 0.433778\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024952; batch adversarial loss: 0.555448\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029463; batch adversarial loss: 0.506142\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019698; batch adversarial loss: 0.373708\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013638; batch adversarial loss: 0.467783\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020148; batch adversarial loss: 0.476222\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024897; batch adversarial loss: 0.407146\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007499; batch adversarial loss: 0.404726\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020098; batch adversarial loss: 0.407378\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012500; batch adversarial loss: 0.468738\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031041; batch adversarial loss: 0.481371\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021886; batch adversarial loss: 0.515999\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010332; batch adversarial loss: 0.461741\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022244; batch adversarial loss: 0.530523\n",
      "epoch 196; iter: 0; batch classifier loss: 0.044068; batch adversarial loss: 0.525975\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019149; batch adversarial loss: 0.431304\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017186; batch adversarial loss: 0.382847\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010163; batch adversarial loss: 0.472869\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685420; batch adversarial loss: 0.875400\n",
      "epoch 1; iter: 0; batch classifier loss: 0.375237; batch adversarial loss: 0.909821\n",
      "epoch 2; iter: 0; batch classifier loss: 0.320356; batch adversarial loss: 0.836056\n",
      "epoch 3; iter: 0; batch classifier loss: 0.306390; batch adversarial loss: 0.758330\n",
      "epoch 4; iter: 0; batch classifier loss: 0.399456; batch adversarial loss: 0.755905\n",
      "epoch 5; iter: 0; batch classifier loss: 0.341284; batch adversarial loss: 0.677143\n",
      "epoch 6; iter: 0; batch classifier loss: 0.347971; batch adversarial loss: 0.646467\n",
      "epoch 7; iter: 0; batch classifier loss: 0.335414; batch adversarial loss: 0.639822\n",
      "epoch 8; iter: 0; batch classifier loss: 0.282974; batch adversarial loss: 0.596871\n",
      "epoch 9; iter: 0; batch classifier loss: 0.273792; batch adversarial loss: 0.610259\n",
      "epoch 10; iter: 0; batch classifier loss: 0.244404; batch adversarial loss: 0.564682\n",
      "epoch 11; iter: 0; batch classifier loss: 0.271157; batch adversarial loss: 0.548109\n",
      "epoch 12; iter: 0; batch classifier loss: 0.259870; batch adversarial loss: 0.513459\n",
      "epoch 13; iter: 0; batch classifier loss: 0.241695; batch adversarial loss: 0.492444\n",
      "epoch 14; iter: 0; batch classifier loss: 0.326294; batch adversarial loss: 0.489859\n",
      "epoch 15; iter: 0; batch classifier loss: 0.299395; batch adversarial loss: 0.488415\n",
      "epoch 16; iter: 0; batch classifier loss: 0.236192; batch adversarial loss: 0.476216\n",
      "epoch 17; iter: 0; batch classifier loss: 0.233050; batch adversarial loss: 0.448902\n",
      "epoch 18; iter: 0; batch classifier loss: 0.195047; batch adversarial loss: 0.429015\n",
      "epoch 19; iter: 0; batch classifier loss: 0.264432; batch adversarial loss: 0.429567\n",
      "epoch 20; iter: 0; batch classifier loss: 0.267086; batch adversarial loss: 0.389830\n",
      "epoch 21; iter: 0; batch classifier loss: 0.242710; batch adversarial loss: 0.419857\n",
      "epoch 22; iter: 0; batch classifier loss: 0.202589; batch adversarial loss: 0.407065\n",
      "epoch 23; iter: 0; batch classifier loss: 0.196381; batch adversarial loss: 0.478114\n",
      "epoch 24; iter: 0; batch classifier loss: 0.181429; batch adversarial loss: 0.447759\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174168; batch adversarial loss: 0.441900\n",
      "epoch 26; iter: 0; batch classifier loss: 0.188419; batch adversarial loss: 0.444610\n",
      "epoch 27; iter: 0; batch classifier loss: 0.136764; batch adversarial loss: 0.437905\n",
      "epoch 28; iter: 0; batch classifier loss: 0.167630; batch adversarial loss: 0.483747\n",
      "epoch 29; iter: 0; batch classifier loss: 0.172335; batch adversarial loss: 0.363284\n",
      "epoch 30; iter: 0; batch classifier loss: 0.169781; batch adversarial loss: 0.453461\n",
      "epoch 31; iter: 0; batch classifier loss: 0.171095; batch adversarial loss: 0.299405\n",
      "epoch 32; iter: 0; batch classifier loss: 0.203475; batch adversarial loss: 0.365960\n",
      "epoch 33; iter: 0; batch classifier loss: 0.144782; batch adversarial loss: 0.424000\n",
      "epoch 34; iter: 0; batch classifier loss: 0.149995; batch adversarial loss: 0.435473\n",
      "epoch 35; iter: 0; batch classifier loss: 0.179109; batch adversarial loss: 0.423525\n",
      "epoch 36; iter: 0; batch classifier loss: 0.161107; batch adversarial loss: 0.416940\n",
      "epoch 37; iter: 0; batch classifier loss: 0.215583; batch adversarial loss: 0.391044\n",
      "epoch 38; iter: 0; batch classifier loss: 0.104371; batch adversarial loss: 0.334128\n",
      "epoch 39; iter: 0; batch classifier loss: 0.121592; batch adversarial loss: 0.400234\n",
      "epoch 40; iter: 0; batch classifier loss: 0.112087; batch adversarial loss: 0.481479\n",
      "epoch 41; iter: 0; batch classifier loss: 0.118332; batch adversarial loss: 0.362240\n",
      "epoch 42; iter: 0; batch classifier loss: 0.166387; batch adversarial loss: 0.512543\n",
      "epoch 43; iter: 0; batch classifier loss: 0.131879; batch adversarial loss: 0.441965\n",
      "epoch 44; iter: 0; batch classifier loss: 0.090554; batch adversarial loss: 0.407997\n",
      "epoch 45; iter: 0; batch classifier loss: 0.114136; batch adversarial loss: 0.369787\n",
      "epoch 46; iter: 0; batch classifier loss: 0.138640; batch adversarial loss: 0.380638\n",
      "epoch 47; iter: 0; batch classifier loss: 0.138037; batch adversarial loss: 0.430453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.139956; batch adversarial loss: 0.409641\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101495; batch adversarial loss: 0.412906\n",
      "epoch 50; iter: 0; batch classifier loss: 0.127241; batch adversarial loss: 0.407182\n",
      "epoch 51; iter: 0; batch classifier loss: 0.062367; batch adversarial loss: 0.454367\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103415; batch adversarial loss: 0.402056\n",
      "epoch 53; iter: 0; batch classifier loss: 0.104133; batch adversarial loss: 0.432801\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095111; batch adversarial loss: 0.358852\n",
      "epoch 55; iter: 0; batch classifier loss: 0.115601; batch adversarial loss: 0.378609\n",
      "epoch 56; iter: 0; batch classifier loss: 0.095398; batch adversarial loss: 0.305325\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079670; batch adversarial loss: 0.354732\n",
      "epoch 58; iter: 0; batch classifier loss: 0.070469; batch adversarial loss: 0.423888\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072499; batch adversarial loss: 0.449644\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118835; batch adversarial loss: 0.421042\n",
      "epoch 61; iter: 0; batch classifier loss: 0.105313; batch adversarial loss: 0.448993\n",
      "epoch 62; iter: 0; batch classifier loss: 0.064229; batch adversarial loss: 0.422379\n",
      "epoch 63; iter: 0; batch classifier loss: 0.074929; batch adversarial loss: 0.399723\n",
      "epoch 64; iter: 0; batch classifier loss: 0.077435; batch adversarial loss: 0.442209\n",
      "epoch 65; iter: 0; batch classifier loss: 0.066066; batch adversarial loss: 0.386629\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068998; batch adversarial loss: 0.481259\n",
      "epoch 67; iter: 0; batch classifier loss: 0.081951; batch adversarial loss: 0.440432\n",
      "epoch 68; iter: 0; batch classifier loss: 0.097280; batch adversarial loss: 0.475661\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071254; batch adversarial loss: 0.404548\n",
      "epoch 70; iter: 0; batch classifier loss: 0.076465; batch adversarial loss: 0.478103\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063270; batch adversarial loss: 0.409426\n",
      "epoch 72; iter: 0; batch classifier loss: 0.089428; batch adversarial loss: 0.403880\n",
      "epoch 73; iter: 0; batch classifier loss: 0.050736; batch adversarial loss: 0.504135\n",
      "epoch 74; iter: 0; batch classifier loss: 0.064538; batch adversarial loss: 0.379114\n",
      "epoch 75; iter: 0; batch classifier loss: 0.062104; batch adversarial loss: 0.422996\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064441; batch adversarial loss: 0.470029\n",
      "epoch 77; iter: 0; batch classifier loss: 0.041798; batch adversarial loss: 0.497325\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071236; batch adversarial loss: 0.328480\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070124; batch adversarial loss: 0.409604\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060141; batch adversarial loss: 0.417283\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068282; batch adversarial loss: 0.383746\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060421; batch adversarial loss: 0.444002\n",
      "epoch 83; iter: 0; batch classifier loss: 0.094148; batch adversarial loss: 0.413858\n",
      "epoch 84; iter: 0; batch classifier loss: 0.027120; batch adversarial loss: 0.486826\n",
      "epoch 85; iter: 0; batch classifier loss: 0.041359; batch adversarial loss: 0.389698\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065922; batch adversarial loss: 0.414482\n",
      "epoch 87; iter: 0; batch classifier loss: 0.060568; batch adversarial loss: 0.475186\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041803; batch adversarial loss: 0.376090\n",
      "epoch 89; iter: 0; batch classifier loss: 0.062688; batch adversarial loss: 0.382058\n",
      "epoch 90; iter: 0; batch classifier loss: 0.069791; batch adversarial loss: 0.393696\n",
      "epoch 91; iter: 0; batch classifier loss: 0.040565; batch adversarial loss: 0.392859\n",
      "epoch 92; iter: 0; batch classifier loss: 0.076642; batch adversarial loss: 0.404068\n",
      "epoch 93; iter: 0; batch classifier loss: 0.049485; batch adversarial loss: 0.393220\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039710; batch adversarial loss: 0.393269\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057748; batch adversarial loss: 0.391032\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043659; batch adversarial loss: 0.492517\n",
      "epoch 97; iter: 0; batch classifier loss: 0.032399; batch adversarial loss: 0.420687\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054907; batch adversarial loss: 0.397919\n",
      "epoch 99; iter: 0; batch classifier loss: 0.081001; batch adversarial loss: 0.573734\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038871; batch adversarial loss: 0.389387\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055652; batch adversarial loss: 0.568440\n",
      "epoch 102; iter: 0; batch classifier loss: 0.027572; batch adversarial loss: 0.443106\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032347; batch adversarial loss: 0.514481\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056461; batch adversarial loss: 0.541057\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055171; batch adversarial loss: 0.455243\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053899; batch adversarial loss: 0.545212\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072465; batch adversarial loss: 0.464497\n",
      "epoch 108; iter: 0; batch classifier loss: 0.130164; batch adversarial loss: 0.537965\n",
      "epoch 109; iter: 0; batch classifier loss: 0.102101; batch adversarial loss: 0.513036\n",
      "epoch 110; iter: 0; batch classifier loss: 0.071520; batch adversarial loss: 0.452546\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045310; batch adversarial loss: 0.529864\n",
      "epoch 112; iter: 0; batch classifier loss: 0.122183; batch adversarial loss: 0.552133\n",
      "epoch 113; iter: 0; batch classifier loss: 0.074798; batch adversarial loss: 0.514027\n",
      "epoch 114; iter: 0; batch classifier loss: 0.079120; batch adversarial loss: 0.514941\n",
      "epoch 115; iter: 0; batch classifier loss: 0.137754; batch adversarial loss: 0.485852\n",
      "epoch 116; iter: 0; batch classifier loss: 0.074556; batch adversarial loss: 0.500266\n",
      "epoch 117; iter: 0; batch classifier loss: 0.082899; batch adversarial loss: 0.514316\n",
      "epoch 118; iter: 0; batch classifier loss: 0.081100; batch adversarial loss: 0.413664\n",
      "epoch 119; iter: 0; batch classifier loss: 0.097950; batch adversarial loss: 0.490523\n",
      "epoch 120; iter: 0; batch classifier loss: 0.113703; batch adversarial loss: 0.522548\n",
      "epoch 121; iter: 0; batch classifier loss: 0.122218; batch adversarial loss: 0.464887\n",
      "epoch 122; iter: 0; batch classifier loss: 0.141943; batch adversarial loss: 0.584359\n",
      "epoch 123; iter: 0; batch classifier loss: 0.126316; batch adversarial loss: 0.591653\n",
      "epoch 124; iter: 0; batch classifier loss: 0.169881; batch adversarial loss: 0.523277\n",
      "epoch 125; iter: 0; batch classifier loss: 0.150694; batch adversarial loss: 0.550389\n",
      "epoch 126; iter: 0; batch classifier loss: 0.108496; batch adversarial loss: 0.504830\n",
      "epoch 127; iter: 0; batch classifier loss: 0.173057; batch adversarial loss: 0.572138\n",
      "epoch 128; iter: 0; batch classifier loss: 0.115883; batch adversarial loss: 0.583143\n",
      "epoch 129; iter: 0; batch classifier loss: 0.094492; batch adversarial loss: 0.445988\n",
      "epoch 130; iter: 0; batch classifier loss: 0.165920; batch adversarial loss: 0.476794\n",
      "epoch 131; iter: 0; batch classifier loss: 0.126255; batch adversarial loss: 0.536219\n",
      "epoch 132; iter: 0; batch classifier loss: 0.129301; batch adversarial loss: 0.504752\n",
      "epoch 133; iter: 0; batch classifier loss: 0.092737; batch adversarial loss: 0.419379\n",
      "epoch 134; iter: 0; batch classifier loss: 0.099840; batch adversarial loss: 0.408552\n",
      "epoch 135; iter: 0; batch classifier loss: 0.095341; batch adversarial loss: 0.408853\n",
      "epoch 136; iter: 0; batch classifier loss: 0.105373; batch adversarial loss: 0.430815\n",
      "epoch 137; iter: 0; batch classifier loss: 0.132583; batch adversarial loss: 0.506002\n",
      "epoch 138; iter: 0; batch classifier loss: 0.078487; batch adversarial loss: 0.443270\n",
      "epoch 139; iter: 0; batch classifier loss: 0.131915; batch adversarial loss: 0.430133\n",
      "epoch 140; iter: 0; batch classifier loss: 0.103043; batch adversarial loss: 0.476558\n",
      "epoch 141; iter: 0; batch classifier loss: 0.100822; batch adversarial loss: 0.425146\n",
      "epoch 142; iter: 0; batch classifier loss: 0.127999; batch adversarial loss: 0.537291\n",
      "epoch 143; iter: 0; batch classifier loss: 0.089190; batch adversarial loss: 0.467402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.112080; batch adversarial loss: 0.440934\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031769; batch adversarial loss: 0.473068\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030043; batch adversarial loss: 0.332401\n",
      "epoch 147; iter: 0; batch classifier loss: 0.056726; batch adversarial loss: 0.361509\n",
      "epoch 148; iter: 0; batch classifier loss: 0.068419; batch adversarial loss: 0.423143\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038477; batch adversarial loss: 0.419721\n",
      "epoch 150; iter: 0; batch classifier loss: 0.073555; batch adversarial loss: 0.446968\n",
      "epoch 151; iter: 0; batch classifier loss: 0.045208; batch adversarial loss: 0.457252\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028492; batch adversarial loss: 0.390970\n",
      "epoch 153; iter: 0; batch classifier loss: 0.050166; batch adversarial loss: 0.457563\n",
      "epoch 154; iter: 0; batch classifier loss: 0.047442; batch adversarial loss: 0.348115\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020815; batch adversarial loss: 0.296237\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040756; batch adversarial loss: 0.446832\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027006; batch adversarial loss: 0.418645\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038469; batch adversarial loss: 0.402381\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029115; batch adversarial loss: 0.610938\n",
      "epoch 160; iter: 0; batch classifier loss: 0.082926; batch adversarial loss: 0.392190\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023258; batch adversarial loss: 0.460850\n",
      "epoch 162; iter: 0; batch classifier loss: 0.054085; batch adversarial loss: 0.426523\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020429; batch adversarial loss: 0.458439\n",
      "epoch 164; iter: 0; batch classifier loss: 0.055354; batch adversarial loss: 0.429707\n",
      "epoch 165; iter: 0; batch classifier loss: 0.065587; batch adversarial loss: 0.451577\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029475; batch adversarial loss: 0.512704\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034910; batch adversarial loss: 0.454413\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032422; batch adversarial loss: 0.421522\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040204; batch adversarial loss: 0.440293\n",
      "epoch 170; iter: 0; batch classifier loss: 0.069673; batch adversarial loss: 0.496653\n",
      "epoch 171; iter: 0; batch classifier loss: 0.034700; batch adversarial loss: 0.450851\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034280; batch adversarial loss: 0.495342\n",
      "epoch 173; iter: 0; batch classifier loss: 0.042678; batch adversarial loss: 0.450816\n",
      "epoch 174; iter: 0; batch classifier loss: 0.071939; batch adversarial loss: 0.351016\n",
      "epoch 175; iter: 0; batch classifier loss: 0.078770; batch adversarial loss: 0.517508\n",
      "epoch 176; iter: 0; batch classifier loss: 0.046341; batch adversarial loss: 0.447243\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046451; batch adversarial loss: 0.505223\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037194; batch adversarial loss: 0.362734\n",
      "epoch 179; iter: 0; batch classifier loss: 0.076261; batch adversarial loss: 0.476801\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034381; batch adversarial loss: 0.422771\n",
      "epoch 181; iter: 0; batch classifier loss: 0.051272; batch adversarial loss: 0.412242\n",
      "epoch 182; iter: 0; batch classifier loss: 0.067474; batch adversarial loss: 0.357810\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042014; batch adversarial loss: 0.486370\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037584; batch adversarial loss: 0.430571\n",
      "epoch 185; iter: 0; batch classifier loss: 0.039073; batch adversarial loss: 0.465717\n",
      "epoch 186; iter: 0; batch classifier loss: 0.107322; batch adversarial loss: 0.475548\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026916; batch adversarial loss: 0.497419\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034930; batch adversarial loss: 0.525056\n",
      "epoch 189; iter: 0; batch classifier loss: 0.069731; batch adversarial loss: 0.408608\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035218; batch adversarial loss: 0.445053\n",
      "epoch 191; iter: 0; batch classifier loss: 0.036970; batch adversarial loss: 0.481382\n",
      "epoch 192; iter: 0; batch classifier loss: 0.044710; batch adversarial loss: 0.449660\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035626; batch adversarial loss: 0.416978\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033230; batch adversarial loss: 0.400038\n",
      "epoch 195; iter: 0; batch classifier loss: 0.055009; batch adversarial loss: 0.327689\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026248; batch adversarial loss: 0.501579\n",
      "epoch 197; iter: 0; batch classifier loss: 0.075014; batch adversarial loss: 0.451603\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028279; batch adversarial loss: 0.491454\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026339; batch adversarial loss: 0.372129\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712617; batch adversarial loss: 0.782641\n",
      "epoch 1; iter: 0; batch classifier loss: 0.529361; batch adversarial loss: 0.734423\n",
      "epoch 2; iter: 0; batch classifier loss: 0.588143; batch adversarial loss: 0.674900\n",
      "epoch 3; iter: 0; batch classifier loss: 0.534572; batch adversarial loss: 0.638514\n",
      "epoch 4; iter: 0; batch classifier loss: 0.410305; batch adversarial loss: 0.593774\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343546; batch adversarial loss: 0.590534\n",
      "epoch 6; iter: 0; batch classifier loss: 0.336418; batch adversarial loss: 0.579185\n",
      "epoch 7; iter: 0; batch classifier loss: 0.362882; batch adversarial loss: 0.564503\n",
      "epoch 8; iter: 0; batch classifier loss: 0.363459; batch adversarial loss: 0.513323\n",
      "epoch 9; iter: 0; batch classifier loss: 0.398279; batch adversarial loss: 0.566629\n",
      "epoch 10; iter: 0; batch classifier loss: 0.320152; batch adversarial loss: 0.546025\n",
      "epoch 11; iter: 0; batch classifier loss: 0.364122; batch adversarial loss: 0.500100\n",
      "epoch 12; iter: 0; batch classifier loss: 0.364230; batch adversarial loss: 0.537954\n",
      "epoch 13; iter: 0; batch classifier loss: 0.305924; batch adversarial loss: 0.510945\n",
      "epoch 14; iter: 0; batch classifier loss: 0.390139; batch adversarial loss: 0.493252\n",
      "epoch 15; iter: 0; batch classifier loss: 0.376540; batch adversarial loss: 0.478033\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493301; batch adversarial loss: 0.465749\n",
      "epoch 17; iter: 0; batch classifier loss: 0.375370; batch adversarial loss: 0.530389\n",
      "epoch 18; iter: 0; batch classifier loss: 0.335761; batch adversarial loss: 0.475359\n",
      "epoch 19; iter: 0; batch classifier loss: 0.369909; batch adversarial loss: 0.489894\n",
      "epoch 20; iter: 0; batch classifier loss: 0.295933; batch adversarial loss: 0.441952\n",
      "epoch 21; iter: 0; batch classifier loss: 0.303172; batch adversarial loss: 0.442465\n",
      "epoch 22; iter: 0; batch classifier loss: 0.263181; batch adversarial loss: 0.503263\n",
      "epoch 23; iter: 0; batch classifier loss: 0.370438; batch adversarial loss: 0.411307\n",
      "epoch 24; iter: 0; batch classifier loss: 0.290867; batch adversarial loss: 0.465913\n",
      "epoch 25; iter: 0; batch classifier loss: 0.301901; batch adversarial loss: 0.391111\n",
      "epoch 26; iter: 0; batch classifier loss: 0.314854; batch adversarial loss: 0.481647\n",
      "epoch 27; iter: 0; batch classifier loss: 0.310169; batch adversarial loss: 0.432662\n",
      "epoch 28; iter: 0; batch classifier loss: 0.270971; batch adversarial loss: 0.489266\n",
      "epoch 29; iter: 0; batch classifier loss: 0.219341; batch adversarial loss: 0.415916\n",
      "epoch 30; iter: 0; batch classifier loss: 0.223892; batch adversarial loss: 0.506638\n",
      "epoch 31; iter: 0; batch classifier loss: 0.247719; batch adversarial loss: 0.477090\n",
      "epoch 32; iter: 0; batch classifier loss: 0.255190; batch adversarial loss: 0.459117\n",
      "epoch 33; iter: 0; batch classifier loss: 0.252338; batch adversarial loss: 0.496993\n",
      "epoch 34; iter: 0; batch classifier loss: 0.243638; batch adversarial loss: 0.420478\n",
      "epoch 35; iter: 0; batch classifier loss: 0.278411; batch adversarial loss: 0.467427\n",
      "epoch 36; iter: 0; batch classifier loss: 0.216128; batch adversarial loss: 0.500203\n",
      "epoch 37; iter: 0; batch classifier loss: 0.236153; batch adversarial loss: 0.535395\n",
      "epoch 38; iter: 0; batch classifier loss: 0.248813; batch adversarial loss: 0.425045\n",
      "epoch 39; iter: 0; batch classifier loss: 0.226722; batch adversarial loss: 0.337787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.213345; batch adversarial loss: 0.500210\n",
      "epoch 41; iter: 0; batch classifier loss: 0.277572; batch adversarial loss: 0.507952\n",
      "epoch 42; iter: 0; batch classifier loss: 0.224938; batch adversarial loss: 0.512656\n",
      "epoch 43; iter: 0; batch classifier loss: 0.290805; batch adversarial loss: 0.487821\n",
      "epoch 44; iter: 0; batch classifier loss: 0.204394; batch adversarial loss: 0.577079\n",
      "epoch 45; iter: 0; batch classifier loss: 0.178536; batch adversarial loss: 0.471362\n",
      "epoch 46; iter: 0; batch classifier loss: 0.241305; batch adversarial loss: 0.458508\n",
      "epoch 47; iter: 0; batch classifier loss: 0.196299; batch adversarial loss: 0.467565\n",
      "epoch 48; iter: 0; batch classifier loss: 0.237091; batch adversarial loss: 0.456720\n",
      "epoch 49; iter: 0; batch classifier loss: 0.151897; batch adversarial loss: 0.437364\n",
      "epoch 50; iter: 0; batch classifier loss: 0.220036; batch adversarial loss: 0.409243\n",
      "epoch 51; iter: 0; batch classifier loss: 0.246779; batch adversarial loss: 0.447535\n",
      "epoch 52; iter: 0; batch classifier loss: 0.183760; batch adversarial loss: 0.461522\n",
      "epoch 53; iter: 0; batch classifier loss: 0.153677; batch adversarial loss: 0.474710\n",
      "epoch 54; iter: 0; batch classifier loss: 0.176158; batch adversarial loss: 0.419107\n",
      "epoch 55; iter: 0; batch classifier loss: 0.226837; batch adversarial loss: 0.373064\n",
      "epoch 56; iter: 0; batch classifier loss: 0.313772; batch adversarial loss: 0.381998\n",
      "epoch 57; iter: 0; batch classifier loss: 0.167347; batch adversarial loss: 0.483426\n",
      "epoch 58; iter: 0; batch classifier loss: 0.147294; batch adversarial loss: 0.471573\n",
      "epoch 59; iter: 0; batch classifier loss: 0.214304; batch adversarial loss: 0.396454\n",
      "epoch 60; iter: 0; batch classifier loss: 0.275109; batch adversarial loss: 0.396407\n",
      "epoch 61; iter: 0; batch classifier loss: 0.187173; batch adversarial loss: 0.458978\n",
      "epoch 62; iter: 0; batch classifier loss: 0.144232; batch adversarial loss: 0.407780\n",
      "epoch 63; iter: 0; batch classifier loss: 0.106741; batch adversarial loss: 0.509535\n",
      "epoch 64; iter: 0; batch classifier loss: 0.227413; batch adversarial loss: 0.534424\n",
      "epoch 65; iter: 0; batch classifier loss: 0.254638; batch adversarial loss: 0.434534\n",
      "epoch 66; iter: 0; batch classifier loss: 0.163966; batch adversarial loss: 0.508518\n",
      "epoch 67; iter: 0; batch classifier loss: 0.209104; batch adversarial loss: 0.420996\n",
      "epoch 68; iter: 0; batch classifier loss: 0.195441; batch adversarial loss: 0.574216\n",
      "epoch 69; iter: 0; batch classifier loss: 0.170023; batch adversarial loss: 0.484341\n",
      "epoch 70; iter: 0; batch classifier loss: 0.161397; batch adversarial loss: 0.344411\n",
      "epoch 71; iter: 0; batch classifier loss: 0.204829; batch adversarial loss: 0.368619\n",
      "epoch 72; iter: 0; batch classifier loss: 0.282263; batch adversarial loss: 0.383074\n",
      "epoch 73; iter: 0; batch classifier loss: 0.160168; batch adversarial loss: 0.407738\n",
      "epoch 74; iter: 0; batch classifier loss: 0.169449; batch adversarial loss: 0.496711\n",
      "epoch 75; iter: 0; batch classifier loss: 0.181460; batch adversarial loss: 0.560411\n",
      "epoch 76; iter: 0; batch classifier loss: 0.207301; batch adversarial loss: 0.484165\n",
      "epoch 77; iter: 0; batch classifier loss: 0.104981; batch adversarial loss: 0.419836\n",
      "epoch 78; iter: 0; batch classifier loss: 0.129621; batch adversarial loss: 0.434868\n",
      "epoch 79; iter: 0; batch classifier loss: 0.188976; batch adversarial loss: 0.512421\n",
      "epoch 80; iter: 0; batch classifier loss: 0.194061; batch adversarial loss: 0.358186\n",
      "epoch 81; iter: 0; batch classifier loss: 0.149447; batch adversarial loss: 0.432945\n",
      "epoch 82; iter: 0; batch classifier loss: 0.171378; batch adversarial loss: 0.485239\n",
      "epoch 83; iter: 0; batch classifier loss: 0.180548; batch adversarial loss: 0.496560\n",
      "epoch 84; iter: 0; batch classifier loss: 0.164727; batch adversarial loss: 0.549034\n",
      "epoch 85; iter: 0; batch classifier loss: 0.142316; batch adversarial loss: 0.471517\n",
      "epoch 86; iter: 0; batch classifier loss: 0.159807; batch adversarial loss: 0.473548\n",
      "epoch 87; iter: 0; batch classifier loss: 0.176422; batch adversarial loss: 0.445189\n",
      "epoch 88; iter: 0; batch classifier loss: 0.290424; batch adversarial loss: 0.407848\n",
      "epoch 89; iter: 0; batch classifier loss: 0.237542; batch adversarial loss: 0.458473\n",
      "epoch 90; iter: 0; batch classifier loss: 0.235885; batch adversarial loss: 0.433477\n",
      "epoch 91; iter: 0; batch classifier loss: 0.177346; batch adversarial loss: 0.433842\n",
      "epoch 92; iter: 0; batch classifier loss: 0.216876; batch adversarial loss: 0.432539\n",
      "epoch 93; iter: 0; batch classifier loss: 0.207083; batch adversarial loss: 0.509491\n",
      "epoch 94; iter: 0; batch classifier loss: 0.190702; batch adversarial loss: 0.433745\n",
      "epoch 95; iter: 0; batch classifier loss: 0.177924; batch adversarial loss: 0.459402\n",
      "epoch 96; iter: 0; batch classifier loss: 0.153959; batch adversarial loss: 0.434360\n",
      "epoch 97; iter: 0; batch classifier loss: 0.184068; batch adversarial loss: 0.459260\n",
      "epoch 98; iter: 0; batch classifier loss: 0.232071; batch adversarial loss: 0.459131\n",
      "epoch 99; iter: 0; batch classifier loss: 0.158937; batch adversarial loss: 0.446179\n",
      "epoch 100; iter: 0; batch classifier loss: 0.096701; batch adversarial loss: 0.483601\n",
      "epoch 101; iter: 0; batch classifier loss: 0.085872; batch adversarial loss: 0.457000\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060234; batch adversarial loss: 0.418746\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072653; batch adversarial loss: 0.452434\n",
      "epoch 104; iter: 0; batch classifier loss: 0.067070; batch adversarial loss: 0.416779\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055076; batch adversarial loss: 0.390695\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045710; batch adversarial loss: 0.445357\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069311; batch adversarial loss: 0.480426\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044414; batch adversarial loss: 0.429810\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067113; batch adversarial loss: 0.389875\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067410; batch adversarial loss: 0.449617\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035430; batch adversarial loss: 0.467161\n",
      "epoch 112; iter: 0; batch classifier loss: 0.097391; batch adversarial loss: 0.436510\n",
      "epoch 113; iter: 0; batch classifier loss: 0.073671; batch adversarial loss: 0.376208\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049521; batch adversarial loss: 0.527882\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028691; batch adversarial loss: 0.352554\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046064; batch adversarial loss: 0.412951\n",
      "epoch 117; iter: 0; batch classifier loss: 0.068052; batch adversarial loss: 0.417644\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035897; batch adversarial loss: 0.399724\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032713; batch adversarial loss: 0.382433\n",
      "epoch 120; iter: 0; batch classifier loss: 0.064408; batch adversarial loss: 0.338916\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053880; batch adversarial loss: 0.467022\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031145; batch adversarial loss: 0.536350\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029327; batch adversarial loss: 0.463225\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019769; batch adversarial loss: 0.498796\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050772; batch adversarial loss: 0.482549\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050876; batch adversarial loss: 0.441852\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031105; batch adversarial loss: 0.430184\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047039; batch adversarial loss: 0.463702\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040676; batch adversarial loss: 0.412816\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036096; batch adversarial loss: 0.452420\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039446; batch adversarial loss: 0.456243\n",
      "epoch 132; iter: 0; batch classifier loss: 0.081184; batch adversarial loss: 0.405944\n",
      "epoch 133; iter: 0; batch classifier loss: 0.017805; batch adversarial loss: 0.417380\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053246; batch adversarial loss: 0.415599\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057263; batch adversarial loss: 0.478226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.029484; batch adversarial loss: 0.419126\n",
      "epoch 137; iter: 0; batch classifier loss: 0.055312; batch adversarial loss: 0.339225\n",
      "epoch 138; iter: 0; batch classifier loss: 0.079687; batch adversarial loss: 0.568236\n",
      "epoch 139; iter: 0; batch classifier loss: 0.060389; batch adversarial loss: 0.412334\n",
      "epoch 140; iter: 0; batch classifier loss: 0.049891; batch adversarial loss: 0.431303\n",
      "epoch 141; iter: 0; batch classifier loss: 0.012013; batch adversarial loss: 0.500275\n",
      "epoch 142; iter: 0; batch classifier loss: 0.084086; batch adversarial loss: 0.414896\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036608; batch adversarial loss: 0.406676\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032169; batch adversarial loss: 0.348861\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020375; batch adversarial loss: 0.422938\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037537; batch adversarial loss: 0.479546\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028174; batch adversarial loss: 0.414543\n",
      "epoch 148; iter: 0; batch classifier loss: 0.071736; batch adversarial loss: 0.434642\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018819; batch adversarial loss: 0.423523\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030350; batch adversarial loss: 0.491520\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036785; batch adversarial loss: 0.409832\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014150; batch adversarial loss: 0.463317\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035886; batch adversarial loss: 0.414743\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039002; batch adversarial loss: 0.409652\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027218; batch adversarial loss: 0.457412\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034883; batch adversarial loss: 0.441460\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039453; batch adversarial loss: 0.444109\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015426; batch adversarial loss: 0.415330\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045784; batch adversarial loss: 0.450534\n",
      "epoch 160; iter: 0; batch classifier loss: 0.040829; batch adversarial loss: 0.386635\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017193; batch adversarial loss: 0.395943\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009893; batch adversarial loss: 0.432993\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025189; batch adversarial loss: 0.487764\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020827; batch adversarial loss: 0.453580\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029179; batch adversarial loss: 0.545380\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028669; batch adversarial loss: 0.370073\n",
      "epoch 167; iter: 0; batch classifier loss: 0.040124; batch adversarial loss: 0.424534\n",
      "epoch 168; iter: 0; batch classifier loss: 0.006489; batch adversarial loss: 0.472153\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009911; batch adversarial loss: 0.467652\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032228; batch adversarial loss: 0.414615\n",
      "epoch 171; iter: 0; batch classifier loss: 0.059385; batch adversarial loss: 0.447825\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031278; batch adversarial loss: 0.566208\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014273; batch adversarial loss: 0.385450\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017985; batch adversarial loss: 0.406619\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022340; batch adversarial loss: 0.476011\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033424; batch adversarial loss: 0.453762\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016161; batch adversarial loss: 0.447450\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027929; batch adversarial loss: 0.514560\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026688; batch adversarial loss: 0.425783\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029205; batch adversarial loss: 0.392227\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010428; batch adversarial loss: 0.415281\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009522; batch adversarial loss: 0.444384\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031557; batch adversarial loss: 0.506196\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015484; batch adversarial loss: 0.479304\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012108; batch adversarial loss: 0.431567\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013515; batch adversarial loss: 0.478625\n",
      "epoch 187; iter: 0; batch classifier loss: 0.049040; batch adversarial loss: 0.458012\n",
      "epoch 188; iter: 0; batch classifier loss: 0.045467; batch adversarial loss: 0.437840\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021116; batch adversarial loss: 0.441219\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008416; batch adversarial loss: 0.421255\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013303; batch adversarial loss: 0.400006\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010691; batch adversarial loss: 0.503835\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015822; batch adversarial loss: 0.467908\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020641; batch adversarial loss: 0.479076\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012632; batch adversarial loss: 0.413545\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007103; batch adversarial loss: 0.425162\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045790; batch adversarial loss: 0.433962\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031580; batch adversarial loss: 0.422389\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012215; batch adversarial loss: 0.321972\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696532; batch adversarial loss: 0.739354\n",
      "epoch 1; iter: 0; batch classifier loss: 0.531539; batch adversarial loss: 0.710226\n",
      "epoch 2; iter: 0; batch classifier loss: 0.557031; batch adversarial loss: 0.673405\n",
      "epoch 3; iter: 0; batch classifier loss: 0.448225; batch adversarial loss: 0.602975\n",
      "epoch 4; iter: 0; batch classifier loss: 0.407854; batch adversarial loss: 0.586637\n",
      "epoch 5; iter: 0; batch classifier loss: 0.380649; batch adversarial loss: 0.580945\n",
      "epoch 6; iter: 0; batch classifier loss: 0.355177; batch adversarial loss: 0.569328\n",
      "epoch 7; iter: 0; batch classifier loss: 0.343753; batch adversarial loss: 0.550653\n",
      "epoch 8; iter: 0; batch classifier loss: 0.302725; batch adversarial loss: 0.533387\n",
      "epoch 9; iter: 0; batch classifier loss: 0.297949; batch adversarial loss: 0.541323\n",
      "epoch 10; iter: 0; batch classifier loss: 0.303716; batch adversarial loss: 0.548447\n",
      "epoch 11; iter: 0; batch classifier loss: 0.290384; batch adversarial loss: 0.524472\n",
      "epoch 12; iter: 0; batch classifier loss: 0.241523; batch adversarial loss: 0.509556\n",
      "epoch 13; iter: 0; batch classifier loss: 0.330176; batch adversarial loss: 0.493572\n",
      "epoch 14; iter: 0; batch classifier loss: 0.366714; batch adversarial loss: 0.454554\n",
      "epoch 15; iter: 0; batch classifier loss: 0.320866; batch adversarial loss: 0.505087\n",
      "epoch 16; iter: 0; batch classifier loss: 0.376522; batch adversarial loss: 0.487368\n",
      "epoch 17; iter: 0; batch classifier loss: 0.222428; batch adversarial loss: 0.514883\n",
      "epoch 18; iter: 0; batch classifier loss: 0.343145; batch adversarial loss: 0.553139\n",
      "epoch 19; iter: 0; batch classifier loss: 0.193576; batch adversarial loss: 0.542221\n",
      "epoch 20; iter: 0; batch classifier loss: 0.271280; batch adversarial loss: 0.420109\n",
      "epoch 21; iter: 0; batch classifier loss: 0.263391; batch adversarial loss: 0.526208\n",
      "epoch 22; iter: 0; batch classifier loss: 0.308288; batch adversarial loss: 0.511581\n",
      "epoch 23; iter: 0; batch classifier loss: 0.260903; batch adversarial loss: 0.487169\n",
      "epoch 24; iter: 0; batch classifier loss: 0.299149; batch adversarial loss: 0.538516\n",
      "epoch 25; iter: 0; batch classifier loss: 0.255807; batch adversarial loss: 0.494650\n",
      "epoch 26; iter: 0; batch classifier loss: 0.290872; batch adversarial loss: 0.443321\n",
      "epoch 27; iter: 0; batch classifier loss: 0.230291; batch adversarial loss: 0.460558\n",
      "epoch 28; iter: 0; batch classifier loss: 0.321460; batch adversarial loss: 0.414828\n",
      "epoch 29; iter: 0; batch classifier loss: 0.305653; batch adversarial loss: 0.440635\n",
      "epoch 30; iter: 0; batch classifier loss: 0.302011; batch adversarial loss: 0.453764\n",
      "epoch 31; iter: 0; batch classifier loss: 0.284858; batch adversarial loss: 0.469385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.246598; batch adversarial loss: 0.450887\n",
      "epoch 33; iter: 0; batch classifier loss: 0.242255; batch adversarial loss: 0.475195\n",
      "epoch 34; iter: 0; batch classifier loss: 0.200196; batch adversarial loss: 0.485829\n",
      "epoch 35; iter: 0; batch classifier loss: 0.215590; batch adversarial loss: 0.441579\n",
      "epoch 36; iter: 0; batch classifier loss: 0.316273; batch adversarial loss: 0.483883\n",
      "epoch 37; iter: 0; batch classifier loss: 0.226441; batch adversarial loss: 0.544391\n",
      "epoch 38; iter: 0; batch classifier loss: 0.243468; batch adversarial loss: 0.434525\n",
      "epoch 39; iter: 0; batch classifier loss: 0.184731; batch adversarial loss: 0.457354\n",
      "epoch 40; iter: 0; batch classifier loss: 0.179862; batch adversarial loss: 0.475686\n",
      "epoch 41; iter: 0; batch classifier loss: 0.173669; batch adversarial loss: 0.445967\n",
      "epoch 42; iter: 0; batch classifier loss: 0.212006; batch adversarial loss: 0.503226\n",
      "epoch 43; iter: 0; batch classifier loss: 0.252946; batch adversarial loss: 0.412412\n",
      "epoch 44; iter: 0; batch classifier loss: 0.294500; batch adversarial loss: 0.430541\n",
      "epoch 45; iter: 0; batch classifier loss: 0.249214; batch adversarial loss: 0.421138\n",
      "epoch 46; iter: 0; batch classifier loss: 0.247766; batch adversarial loss: 0.472402\n",
      "epoch 47; iter: 0; batch classifier loss: 0.175843; batch adversarial loss: 0.595435\n",
      "epoch 48; iter: 0; batch classifier loss: 0.230986; batch adversarial loss: 0.446453\n",
      "epoch 49; iter: 0; batch classifier loss: 0.264051; batch adversarial loss: 0.402811\n",
      "epoch 50; iter: 0; batch classifier loss: 0.219400; batch adversarial loss: 0.493658\n",
      "epoch 51; iter: 0; batch classifier loss: 0.214326; batch adversarial loss: 0.390106\n",
      "epoch 52; iter: 0; batch classifier loss: 0.196638; batch adversarial loss: 0.461535\n",
      "epoch 53; iter: 0; batch classifier loss: 0.184670; batch adversarial loss: 0.557227\n",
      "epoch 54; iter: 0; batch classifier loss: 0.216035; batch adversarial loss: 0.523108\n",
      "epoch 55; iter: 0; batch classifier loss: 0.316526; batch adversarial loss: 0.388702\n",
      "epoch 56; iter: 0; batch classifier loss: 0.200841; batch adversarial loss: 0.496562\n",
      "epoch 57; iter: 0; batch classifier loss: 0.193010; batch adversarial loss: 0.519307\n",
      "epoch 58; iter: 0; batch classifier loss: 0.280768; batch adversarial loss: 0.540188\n",
      "epoch 59; iter: 0; batch classifier loss: 0.260339; batch adversarial loss: 0.461233\n",
      "epoch 60; iter: 0; batch classifier loss: 0.162724; batch adversarial loss: 0.518941\n",
      "epoch 61; iter: 0; batch classifier loss: 0.279144; batch adversarial loss: 0.399207\n",
      "epoch 62; iter: 0; batch classifier loss: 0.161350; batch adversarial loss: 0.460226\n",
      "epoch 63; iter: 0; batch classifier loss: 0.192795; batch adversarial loss: 0.506840\n",
      "epoch 64; iter: 0; batch classifier loss: 0.165785; batch adversarial loss: 0.458626\n",
      "epoch 65; iter: 0; batch classifier loss: 0.128073; batch adversarial loss: 0.482480\n",
      "epoch 66; iter: 0; batch classifier loss: 0.283727; batch adversarial loss: 0.422916\n",
      "epoch 67; iter: 0; batch classifier loss: 0.174356; batch adversarial loss: 0.422908\n",
      "epoch 68; iter: 0; batch classifier loss: 0.244177; batch adversarial loss: 0.458406\n",
      "epoch 69; iter: 0; batch classifier loss: 0.243637; batch adversarial loss: 0.386802\n",
      "epoch 70; iter: 0; batch classifier loss: 0.175530; batch adversarial loss: 0.386571\n",
      "epoch 71; iter: 0; batch classifier loss: 0.187961; batch adversarial loss: 0.458881\n",
      "epoch 72; iter: 0; batch classifier loss: 0.173921; batch adversarial loss: 0.579054\n",
      "epoch 73; iter: 0; batch classifier loss: 0.116544; batch adversarial loss: 0.446544\n",
      "epoch 74; iter: 0; batch classifier loss: 0.171473; batch adversarial loss: 0.509217\n",
      "epoch 75; iter: 0; batch classifier loss: 0.224287; batch adversarial loss: 0.458566\n",
      "epoch 76; iter: 0; batch classifier loss: 0.169297; batch adversarial loss: 0.495104\n",
      "epoch 77; iter: 0; batch classifier loss: 0.094822; batch adversarial loss: 0.483600\n",
      "epoch 78; iter: 0; batch classifier loss: 0.078083; batch adversarial loss: 0.506140\n",
      "epoch 79; iter: 0; batch classifier loss: 0.096705; batch adversarial loss: 0.421922\n",
      "epoch 80; iter: 0; batch classifier loss: 0.128045; batch adversarial loss: 0.457524\n",
      "epoch 81; iter: 0; batch classifier loss: 0.160846; batch adversarial loss: 0.380857\n",
      "epoch 82; iter: 0; batch classifier loss: 0.186548; batch adversarial loss: 0.557084\n",
      "epoch 83; iter: 0; batch classifier loss: 0.157820; batch adversarial loss: 0.443907\n",
      "epoch 84; iter: 0; batch classifier loss: 0.132749; batch adversarial loss: 0.422383\n",
      "epoch 85; iter: 0; batch classifier loss: 0.139053; batch adversarial loss: 0.435680\n",
      "epoch 86; iter: 0; batch classifier loss: 0.129481; batch adversarial loss: 0.562606\n",
      "epoch 87; iter: 0; batch classifier loss: 0.137779; batch adversarial loss: 0.465566\n",
      "epoch 88; iter: 0; batch classifier loss: 0.145379; batch adversarial loss: 0.390982\n",
      "epoch 89; iter: 0; batch classifier loss: 0.139068; batch adversarial loss: 0.407380\n",
      "epoch 90; iter: 0; batch classifier loss: 0.149536; batch adversarial loss: 0.512515\n",
      "epoch 91; iter: 0; batch classifier loss: 0.108958; batch adversarial loss: 0.412201\n",
      "epoch 92; iter: 0; batch classifier loss: 0.135360; batch adversarial loss: 0.401084\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061743; batch adversarial loss: 0.459471\n",
      "epoch 94; iter: 0; batch classifier loss: 0.086515; batch adversarial loss: 0.579802\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058741; batch adversarial loss: 0.446355\n",
      "epoch 96; iter: 0; batch classifier loss: 0.110109; batch adversarial loss: 0.484978\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073187; batch adversarial loss: 0.584892\n",
      "epoch 98; iter: 0; batch classifier loss: 0.107508; batch adversarial loss: 0.478963\n",
      "epoch 99; iter: 0; batch classifier loss: 0.095422; batch adversarial loss: 0.399319\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048068; batch adversarial loss: 0.547293\n",
      "epoch 101; iter: 0; batch classifier loss: 0.089429; batch adversarial loss: 0.445166\n",
      "epoch 102; iter: 0; batch classifier loss: 0.078761; batch adversarial loss: 0.458523\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049138; batch adversarial loss: 0.547382\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045475; batch adversarial loss: 0.451758\n",
      "epoch 105; iter: 0; batch classifier loss: 0.094211; batch adversarial loss: 0.502035\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071977; batch adversarial loss: 0.566477\n",
      "epoch 107; iter: 0; batch classifier loss: 0.073844; batch adversarial loss: 0.493396\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046471; batch adversarial loss: 0.535248\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048843; batch adversarial loss: 0.422324\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028997; batch adversarial loss: 0.424056\n",
      "epoch 111; iter: 0; batch classifier loss: 0.038938; batch adversarial loss: 0.444024\n",
      "epoch 112; iter: 0; batch classifier loss: 0.069027; batch adversarial loss: 0.452644\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038952; batch adversarial loss: 0.411033\n",
      "epoch 114; iter: 0; batch classifier loss: 0.059083; batch adversarial loss: 0.403981\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033295; batch adversarial loss: 0.502311\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029593; batch adversarial loss: 0.398582\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023520; batch adversarial loss: 0.453909\n",
      "epoch 118; iter: 0; batch classifier loss: 0.064321; batch adversarial loss: 0.461155\n",
      "epoch 119; iter: 0; batch classifier loss: 0.070071; batch adversarial loss: 0.413014\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025540; batch adversarial loss: 0.400185\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044826; batch adversarial loss: 0.478749\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046476; batch adversarial loss: 0.525114\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042005; batch adversarial loss: 0.462576\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035561; batch adversarial loss: 0.527355\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035382; batch adversarial loss: 0.453836\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045625; batch adversarial loss: 0.411149\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027396; batch adversarial loss: 0.558789\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035638; batch adversarial loss: 0.485357\n",
      "epoch 129; iter: 0; batch classifier loss: 0.014266; batch adversarial loss: 0.473590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.025699; batch adversarial loss: 0.424732\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031077; batch adversarial loss: 0.521065\n",
      "epoch 132; iter: 0; batch classifier loss: 0.017638; batch adversarial loss: 0.460413\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026931; batch adversarial loss: 0.451062\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016023; batch adversarial loss: 0.510001\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041937; batch adversarial loss: 0.565746\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040106; batch adversarial loss: 0.466266\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025629; batch adversarial loss: 0.532104\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045719; batch adversarial loss: 0.448354\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025346; batch adversarial loss: 0.481900\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026302; batch adversarial loss: 0.471812\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018738; batch adversarial loss: 0.474836\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017554; batch adversarial loss: 0.396629\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011507; batch adversarial loss: 0.436616\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020237; batch adversarial loss: 0.409015\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017079; batch adversarial loss: 0.485068\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020259; batch adversarial loss: 0.366751\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034508; batch adversarial loss: 0.469286\n",
      "epoch 148; iter: 0; batch classifier loss: 0.037277; batch adversarial loss: 0.486227\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017185; batch adversarial loss: 0.433367\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013883; batch adversarial loss: 0.491944\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020151; batch adversarial loss: 0.555476\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013178; batch adversarial loss: 0.418600\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015708; batch adversarial loss: 0.488983\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043760; batch adversarial loss: 0.375664\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025577; batch adversarial loss: 0.401778\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044877; batch adversarial loss: 0.432029\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023587; batch adversarial loss: 0.375769\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018609; batch adversarial loss: 0.487161\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012381; batch adversarial loss: 0.393398\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023333; batch adversarial loss: 0.477780\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014839; batch adversarial loss: 0.436241\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010056; batch adversarial loss: 0.507796\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013073; batch adversarial loss: 0.536445\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019328; batch adversarial loss: 0.451451\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016918; batch adversarial loss: 0.387450\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010340; batch adversarial loss: 0.462560\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026066; batch adversarial loss: 0.392810\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010356; batch adversarial loss: 0.482505\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021744; batch adversarial loss: 0.390517\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016011; batch adversarial loss: 0.499691\n",
      "epoch 171; iter: 0; batch classifier loss: 0.005434; batch adversarial loss: 0.454164\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013751; batch adversarial loss: 0.454215\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019557; batch adversarial loss: 0.460049\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024700; batch adversarial loss: 0.501523\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008954; batch adversarial loss: 0.519245\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021903; batch adversarial loss: 0.401028\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011345; batch adversarial loss: 0.545665\n",
      "epoch 178; iter: 0; batch classifier loss: 0.005202; batch adversarial loss: 0.398912\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025997; batch adversarial loss: 0.540662\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031633; batch adversarial loss: 0.460096\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021527; batch adversarial loss: 0.470672\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008519; batch adversarial loss: 0.531604\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010465; batch adversarial loss: 0.503908\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023420; batch adversarial loss: 0.486424\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015008; batch adversarial loss: 0.448866\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035542; batch adversarial loss: 0.464966\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015458; batch adversarial loss: 0.490030\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018121; batch adversarial loss: 0.489972\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017311; batch adversarial loss: 0.493258\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016979; batch adversarial loss: 0.453392\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024665; batch adversarial loss: 0.432365\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006195; batch adversarial loss: 0.485737\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012917; batch adversarial loss: 0.475654\n",
      "epoch 194; iter: 0; batch classifier loss: 0.038334; batch adversarial loss: 0.434270\n",
      "epoch 195; iter: 0; batch classifier loss: 0.007376; batch adversarial loss: 0.551163\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006701; batch adversarial loss: 0.401863\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010299; batch adversarial loss: 0.426836\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006637; batch adversarial loss: 0.490953\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032003; batch adversarial loss: 0.534912\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685555; batch adversarial loss: 0.695068\n",
      "epoch 1; iter: 0; batch classifier loss: 0.578457; batch adversarial loss: 0.665473\n",
      "epoch 2; iter: 0; batch classifier loss: 0.464757; batch adversarial loss: 0.642309\n",
      "epoch 3; iter: 0; batch classifier loss: 0.530039; batch adversarial loss: 0.619824\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598214; batch adversarial loss: 0.587383\n",
      "epoch 5; iter: 0; batch classifier loss: 0.650283; batch adversarial loss: 0.595292\n",
      "epoch 6; iter: 0; batch classifier loss: 0.502500; batch adversarial loss: 0.595059\n",
      "epoch 7; iter: 0; batch classifier loss: 0.465563; batch adversarial loss: 0.566885\n",
      "epoch 8; iter: 0; batch classifier loss: 0.420944; batch adversarial loss: 0.535712\n",
      "epoch 9; iter: 0; batch classifier loss: 0.394549; batch adversarial loss: 0.512033\n",
      "epoch 10; iter: 0; batch classifier loss: 0.473942; batch adversarial loss: 0.478239\n",
      "epoch 11; iter: 0; batch classifier loss: 0.481211; batch adversarial loss: 0.491608\n",
      "epoch 12; iter: 0; batch classifier loss: 0.449034; batch adversarial loss: 0.483473\n",
      "epoch 13; iter: 0; batch classifier loss: 0.372543; batch adversarial loss: 0.531832\n",
      "epoch 14; iter: 0; batch classifier loss: 0.391241; batch adversarial loss: 0.516220\n",
      "epoch 15; iter: 0; batch classifier loss: 0.417619; batch adversarial loss: 0.511619\n",
      "epoch 16; iter: 0; batch classifier loss: 0.380491; batch adversarial loss: 0.455497\n",
      "epoch 17; iter: 0; batch classifier loss: 0.427377; batch adversarial loss: 0.465313\n",
      "epoch 18; iter: 0; batch classifier loss: 0.307669; batch adversarial loss: 0.466864\n",
      "epoch 19; iter: 0; batch classifier loss: 0.313514; batch adversarial loss: 0.505896\n",
      "epoch 20; iter: 0; batch classifier loss: 0.293879; batch adversarial loss: 0.495736\n",
      "epoch 21; iter: 0; batch classifier loss: 0.325388; batch adversarial loss: 0.482080\n",
      "epoch 22; iter: 0; batch classifier loss: 0.328459; batch adversarial loss: 0.439518\n",
      "epoch 23; iter: 0; batch classifier loss: 0.289569; batch adversarial loss: 0.455861\n",
      "epoch 24; iter: 0; batch classifier loss: 0.293300; batch adversarial loss: 0.476627\n",
      "epoch 25; iter: 0; batch classifier loss: 0.317811; batch adversarial loss: 0.450520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.266548; batch adversarial loss: 0.460317\n",
      "epoch 27; iter: 0; batch classifier loss: 0.248496; batch adversarial loss: 0.374847\n",
      "epoch 28; iter: 0; batch classifier loss: 0.231270; batch adversarial loss: 0.472663\n",
      "epoch 29; iter: 0; batch classifier loss: 0.318336; batch adversarial loss: 0.454524\n",
      "epoch 30; iter: 0; batch classifier loss: 0.214170; batch adversarial loss: 0.379455\n",
      "epoch 31; iter: 0; batch classifier loss: 0.334237; batch adversarial loss: 0.447597\n",
      "epoch 32; iter: 0; batch classifier loss: 0.301643; batch adversarial loss: 0.460825\n",
      "epoch 33; iter: 0; batch classifier loss: 0.293224; batch adversarial loss: 0.472035\n",
      "epoch 34; iter: 0; batch classifier loss: 0.278456; batch adversarial loss: 0.408842\n",
      "epoch 35; iter: 0; batch classifier loss: 0.305136; batch adversarial loss: 0.562362\n",
      "epoch 36; iter: 0; batch classifier loss: 0.343132; batch adversarial loss: 0.433003\n",
      "epoch 37; iter: 0; batch classifier loss: 0.292655; batch adversarial loss: 0.454619\n",
      "epoch 38; iter: 0; batch classifier loss: 0.223094; batch adversarial loss: 0.389251\n",
      "epoch 39; iter: 0; batch classifier loss: 0.354737; batch adversarial loss: 0.468683\n",
      "epoch 40; iter: 0; batch classifier loss: 0.235929; batch adversarial loss: 0.342759\n",
      "epoch 41; iter: 0; batch classifier loss: 0.240246; batch adversarial loss: 0.401227\n",
      "epoch 42; iter: 0; batch classifier loss: 0.255676; batch adversarial loss: 0.449114\n",
      "epoch 43; iter: 0; batch classifier loss: 0.202150; batch adversarial loss: 0.460256\n",
      "epoch 44; iter: 0; batch classifier loss: 0.170190; batch adversarial loss: 0.411115\n",
      "epoch 45; iter: 0; batch classifier loss: 0.167505; batch adversarial loss: 0.460044\n",
      "epoch 46; iter: 0; batch classifier loss: 0.234455; batch adversarial loss: 0.375350\n",
      "epoch 47; iter: 0; batch classifier loss: 0.200733; batch adversarial loss: 0.445948\n",
      "epoch 48; iter: 0; batch classifier loss: 0.172261; batch adversarial loss: 0.484481\n",
      "epoch 49; iter: 0; batch classifier loss: 0.294825; batch adversarial loss: 0.446909\n",
      "epoch 50; iter: 0; batch classifier loss: 0.175046; batch adversarial loss: 0.496168\n",
      "epoch 51; iter: 0; batch classifier loss: 0.193358; batch adversarial loss: 0.409752\n",
      "epoch 52; iter: 0; batch classifier loss: 0.137093; batch adversarial loss: 0.347186\n",
      "epoch 53; iter: 0; batch classifier loss: 0.173874; batch adversarial loss: 0.383970\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114597; batch adversarial loss: 0.482496\n",
      "epoch 55; iter: 0; batch classifier loss: 0.260709; batch adversarial loss: 0.520177\n",
      "epoch 56; iter: 0; batch classifier loss: 0.140488; batch adversarial loss: 0.483186\n",
      "epoch 57; iter: 0; batch classifier loss: 0.172368; batch adversarial loss: 0.307053\n",
      "epoch 58; iter: 0; batch classifier loss: 0.207231; batch adversarial loss: 0.444038\n",
      "epoch 59; iter: 0; batch classifier loss: 0.242145; batch adversarial loss: 0.495144\n",
      "epoch 60; iter: 0; batch classifier loss: 0.208534; batch adversarial loss: 0.433385\n",
      "epoch 61; iter: 0; batch classifier loss: 0.256748; batch adversarial loss: 0.445877\n",
      "epoch 62; iter: 0; batch classifier loss: 0.170957; batch adversarial loss: 0.496896\n",
      "epoch 63; iter: 0; batch classifier loss: 0.232665; batch adversarial loss: 0.446677\n",
      "epoch 64; iter: 0; batch classifier loss: 0.255569; batch adversarial loss: 0.521586\n",
      "epoch 65; iter: 0; batch classifier loss: 0.183473; batch adversarial loss: 0.559686\n",
      "epoch 66; iter: 0; batch classifier loss: 0.272309; batch adversarial loss: 0.420887\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107787; batch adversarial loss: 0.496560\n",
      "epoch 68; iter: 0; batch classifier loss: 0.097582; batch adversarial loss: 0.434268\n",
      "epoch 69; iter: 0; batch classifier loss: 0.092411; batch adversarial loss: 0.405217\n",
      "epoch 70; iter: 0; batch classifier loss: 0.069946; batch adversarial loss: 0.508900\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104673; batch adversarial loss: 0.388061\n",
      "epoch 72; iter: 0; batch classifier loss: 0.163185; batch adversarial loss: 0.407724\n",
      "epoch 73; iter: 0; batch classifier loss: 0.156281; batch adversarial loss: 0.497722\n",
      "epoch 74; iter: 0; batch classifier loss: 0.152695; batch adversarial loss: 0.605532\n",
      "epoch 75; iter: 0; batch classifier loss: 0.173549; batch adversarial loss: 0.469121\n",
      "epoch 76; iter: 0; batch classifier loss: 0.176389; batch adversarial loss: 0.587739\n",
      "epoch 77; iter: 0; batch classifier loss: 0.175402; batch adversarial loss: 0.411922\n",
      "epoch 78; iter: 0; batch classifier loss: 0.115940; batch adversarial loss: 0.370167\n",
      "epoch 79; iter: 0; batch classifier loss: 0.183007; batch adversarial loss: 0.405296\n",
      "epoch 80; iter: 0; batch classifier loss: 0.167357; batch adversarial loss: 0.435264\n",
      "epoch 81; iter: 0; batch classifier loss: 0.165945; batch adversarial loss: 0.552047\n",
      "epoch 82; iter: 0; batch classifier loss: 0.180170; batch adversarial loss: 0.371123\n",
      "epoch 83; iter: 0; batch classifier loss: 0.123852; batch adversarial loss: 0.449224\n",
      "epoch 84; iter: 0; batch classifier loss: 0.151395; batch adversarial loss: 0.405188\n",
      "epoch 85; iter: 0; batch classifier loss: 0.203406; batch adversarial loss: 0.433140\n",
      "epoch 86; iter: 0; batch classifier loss: 0.106592; batch adversarial loss: 0.515806\n",
      "epoch 87; iter: 0; batch classifier loss: 0.127733; batch adversarial loss: 0.394305\n",
      "epoch 88; iter: 0; batch classifier loss: 0.111296; batch adversarial loss: 0.504014\n",
      "epoch 89; iter: 0; batch classifier loss: 0.120265; batch adversarial loss: 0.355137\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065700; batch adversarial loss: 0.428925\n",
      "epoch 91; iter: 0; batch classifier loss: 0.116198; batch adversarial loss: 0.407489\n",
      "epoch 92; iter: 0; batch classifier loss: 0.106097; batch adversarial loss: 0.442719\n",
      "epoch 93; iter: 0; batch classifier loss: 0.047616; batch adversarial loss: 0.386037\n",
      "epoch 94; iter: 0; batch classifier loss: 0.059069; batch adversarial loss: 0.424056\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047531; batch adversarial loss: 0.429913\n",
      "epoch 96; iter: 0; batch classifier loss: 0.060794; batch adversarial loss: 0.437274\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077739; batch adversarial loss: 0.420094\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036565; batch adversarial loss: 0.412969\n",
      "epoch 99; iter: 0; batch classifier loss: 0.088185; batch adversarial loss: 0.524229\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050203; batch adversarial loss: 0.444177\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050113; batch adversarial loss: 0.400975\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047384; batch adversarial loss: 0.386982\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041034; batch adversarial loss: 0.504585\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071835; batch adversarial loss: 0.406468\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034800; batch adversarial loss: 0.436897\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059103; batch adversarial loss: 0.457434\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058264; batch adversarial loss: 0.404053\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039013; batch adversarial loss: 0.478382\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038070; batch adversarial loss: 0.549115\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050320; batch adversarial loss: 0.365347\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059538; batch adversarial loss: 0.480824\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034191; batch adversarial loss: 0.441194\n",
      "epoch 113; iter: 0; batch classifier loss: 0.017123; batch adversarial loss: 0.372166\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051150; batch adversarial loss: 0.360152\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042631; batch adversarial loss: 0.400887\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035842; batch adversarial loss: 0.428538\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042497; batch adversarial loss: 0.443601\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056211; batch adversarial loss: 0.567669\n",
      "epoch 119; iter: 0; batch classifier loss: 0.061900; batch adversarial loss: 0.425522\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046399; batch adversarial loss: 0.388389\n",
      "epoch 121; iter: 0; batch classifier loss: 0.022521; batch adversarial loss: 0.481425\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025923; batch adversarial loss: 0.497708\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031981; batch adversarial loss: 0.533753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.024921; batch adversarial loss: 0.574909\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043488; batch adversarial loss: 0.421301\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022015; batch adversarial loss: 0.442934\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019642; batch adversarial loss: 0.501736\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041070; batch adversarial loss: 0.513041\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041556; batch adversarial loss: 0.463243\n",
      "epoch 130; iter: 0; batch classifier loss: 0.054810; batch adversarial loss: 0.356648\n",
      "epoch 131; iter: 0; batch classifier loss: 0.061388; batch adversarial loss: 0.441599\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047740; batch adversarial loss: 0.359772\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037391; batch adversarial loss: 0.508617\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036301; batch adversarial loss: 0.442801\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038784; batch adversarial loss: 0.469116\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019117; batch adversarial loss: 0.384003\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026786; batch adversarial loss: 0.320908\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031526; batch adversarial loss: 0.514260\n",
      "epoch 139; iter: 0; batch classifier loss: 0.011726; batch adversarial loss: 0.502505\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029903; batch adversarial loss: 0.473607\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017448; batch adversarial loss: 0.439690\n",
      "epoch 142; iter: 0; batch classifier loss: 0.064223; batch adversarial loss: 0.458157\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028186; batch adversarial loss: 0.418410\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030649; batch adversarial loss: 0.378849\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030898; batch adversarial loss: 0.414157\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041029; batch adversarial loss: 0.398782\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023364; batch adversarial loss: 0.534990\n",
      "epoch 148; iter: 0; batch classifier loss: 0.043242; batch adversarial loss: 0.464836\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029800; batch adversarial loss: 0.390338\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033131; batch adversarial loss: 0.556320\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031019; batch adversarial loss: 0.423036\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037801; batch adversarial loss: 0.475904\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040003; batch adversarial loss: 0.438372\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025489; batch adversarial loss: 0.443993\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020591; batch adversarial loss: 0.499422\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038203; batch adversarial loss: 0.498313\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031264; batch adversarial loss: 0.444391\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018230; batch adversarial loss: 0.491928\n",
      "epoch 159; iter: 0; batch classifier loss: 0.066178; batch adversarial loss: 0.329215\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030691; batch adversarial loss: 0.406198\n",
      "epoch 161; iter: 0; batch classifier loss: 0.061720; batch adversarial loss: 0.458997\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016238; batch adversarial loss: 0.439873\n",
      "epoch 163; iter: 0; batch classifier loss: 0.005984; batch adversarial loss: 0.455542\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020209; batch adversarial loss: 0.406080\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036613; batch adversarial loss: 0.366743\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026003; batch adversarial loss: 0.468089\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012555; batch adversarial loss: 0.467280\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029111; batch adversarial loss: 0.353827\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020202; batch adversarial loss: 0.348585\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012357; batch adversarial loss: 0.339926\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015265; batch adversarial loss: 0.484130\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012077; batch adversarial loss: 0.639380\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012992; batch adversarial loss: 0.499657\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008721; batch adversarial loss: 0.517466\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038079; batch adversarial loss: 0.429427\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009507; batch adversarial loss: 0.380471\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012118; batch adversarial loss: 0.350688\n",
      "epoch 178; iter: 0; batch classifier loss: 0.055560; batch adversarial loss: 0.435940\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029521; batch adversarial loss: 0.345465\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011218; batch adversarial loss: 0.434638\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008783; batch adversarial loss: 0.406435\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019132; batch adversarial loss: 0.523011\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017037; batch adversarial loss: 0.430931\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012332; batch adversarial loss: 0.348899\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014494; batch adversarial loss: 0.423511\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009875; batch adversarial loss: 0.446396\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028967; batch adversarial loss: 0.438827\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010189; batch adversarial loss: 0.463043\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020647; batch adversarial loss: 0.424282\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006194; batch adversarial loss: 0.488968\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014302; batch adversarial loss: 0.493928\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010204; batch adversarial loss: 0.523651\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007058; batch adversarial loss: 0.498147\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017773; batch adversarial loss: 0.318995\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019267; batch adversarial loss: 0.328330\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008601; batch adversarial loss: 0.455125\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007083; batch adversarial loss: 0.559357\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020564; batch adversarial loss: 0.350882\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010878; batch adversarial loss: 0.474290\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672454; batch adversarial loss: 0.519951\n",
      "epoch 1; iter: 0; batch classifier loss: 0.445434; batch adversarial loss: 0.582014\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396309; batch adversarial loss: 0.611765\n",
      "epoch 3; iter: 0; batch classifier loss: 0.461572; batch adversarial loss: 0.603757\n",
      "epoch 4; iter: 0; batch classifier loss: 0.432125; batch adversarial loss: 0.586142\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387242; batch adversarial loss: 0.586370\n",
      "epoch 6; iter: 0; batch classifier loss: 0.438179; batch adversarial loss: 0.544155\n",
      "epoch 7; iter: 0; batch classifier loss: 0.342147; batch adversarial loss: 0.581369\n",
      "epoch 8; iter: 0; batch classifier loss: 0.444611; batch adversarial loss: 0.566628\n",
      "epoch 9; iter: 0; batch classifier loss: 0.466474; batch adversarial loss: 0.601806\n",
      "epoch 10; iter: 0; batch classifier loss: 0.386134; batch adversarial loss: 0.504732\n",
      "epoch 11; iter: 0; batch classifier loss: 0.588645; batch adversarial loss: 0.513543\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553972; batch adversarial loss: 0.452237\n",
      "epoch 13; iter: 0; batch classifier loss: 0.585994; batch adversarial loss: 0.485696\n",
      "epoch 14; iter: 0; batch classifier loss: 0.423301; batch adversarial loss: 0.505343\n",
      "epoch 15; iter: 0; batch classifier loss: 0.325514; batch adversarial loss: 0.499577\n",
      "epoch 16; iter: 0; batch classifier loss: 0.292137; batch adversarial loss: 0.480268\n",
      "epoch 17; iter: 0; batch classifier loss: 0.253961; batch adversarial loss: 0.422055\n",
      "epoch 18; iter: 0; batch classifier loss: 0.268529; batch adversarial loss: 0.494192\n",
      "epoch 19; iter: 0; batch classifier loss: 0.188797; batch adversarial loss: 0.438212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.175696; batch adversarial loss: 0.473130\n",
      "epoch 21; iter: 0; batch classifier loss: 0.174110; batch adversarial loss: 0.459763\n",
      "epoch 22; iter: 0; batch classifier loss: 0.155575; batch adversarial loss: 0.443582\n",
      "epoch 23; iter: 0; batch classifier loss: 0.157780; batch adversarial loss: 0.534872\n",
      "epoch 24; iter: 0; batch classifier loss: 0.196436; batch adversarial loss: 0.463582\n",
      "epoch 25; iter: 0; batch classifier loss: 0.183065; batch adversarial loss: 0.487058\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193940; batch adversarial loss: 0.493776\n",
      "epoch 27; iter: 0; batch classifier loss: 0.178123; batch adversarial loss: 0.469215\n",
      "epoch 28; iter: 0; batch classifier loss: 0.180452; batch adversarial loss: 0.433984\n",
      "epoch 29; iter: 0; batch classifier loss: 0.171394; batch adversarial loss: 0.530359\n",
      "epoch 30; iter: 0; batch classifier loss: 0.116403; batch adversarial loss: 0.503924\n",
      "epoch 31; iter: 0; batch classifier loss: 0.167682; batch adversarial loss: 0.469103\n",
      "epoch 32; iter: 0; batch classifier loss: 0.159405; batch adversarial loss: 0.452847\n",
      "epoch 33; iter: 0; batch classifier loss: 0.119812; batch adversarial loss: 0.494752\n",
      "epoch 34; iter: 0; batch classifier loss: 0.138423; batch adversarial loss: 0.505811\n",
      "epoch 35; iter: 0; batch classifier loss: 0.065945; batch adversarial loss: 0.465330\n",
      "epoch 36; iter: 0; batch classifier loss: 0.139616; batch adversarial loss: 0.460615\n",
      "epoch 37; iter: 0; batch classifier loss: 0.117548; batch adversarial loss: 0.499929\n",
      "epoch 38; iter: 0; batch classifier loss: 0.140197; batch adversarial loss: 0.459858\n",
      "epoch 39; iter: 0; batch classifier loss: 0.196800; batch adversarial loss: 0.436219\n",
      "epoch 40; iter: 0; batch classifier loss: 0.134292; batch adversarial loss: 0.329248\n",
      "epoch 41; iter: 0; batch classifier loss: 0.090078; batch adversarial loss: 0.513865\n",
      "epoch 42; iter: 0; batch classifier loss: 0.094795; batch adversarial loss: 0.453030\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150106; batch adversarial loss: 0.395823\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123689; batch adversarial loss: 0.519477\n",
      "epoch 45; iter: 0; batch classifier loss: 0.123882; batch adversarial loss: 0.408582\n",
      "epoch 46; iter: 0; batch classifier loss: 0.100333; batch adversarial loss: 0.400558\n",
      "epoch 47; iter: 0; batch classifier loss: 0.117796; batch adversarial loss: 0.399583\n",
      "epoch 48; iter: 0; batch classifier loss: 0.156052; batch adversarial loss: 0.369348\n",
      "epoch 49; iter: 0; batch classifier loss: 0.092986; batch adversarial loss: 0.587520\n",
      "epoch 50; iter: 0; batch classifier loss: 0.109253; batch adversarial loss: 0.456124\n",
      "epoch 51; iter: 0; batch classifier loss: 0.151139; batch adversarial loss: 0.487725\n",
      "epoch 52; iter: 0; batch classifier loss: 0.125398; batch adversarial loss: 0.473662\n",
      "epoch 53; iter: 0; batch classifier loss: 0.104672; batch adversarial loss: 0.486793\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112243; batch adversarial loss: 0.476518\n",
      "epoch 55; iter: 0; batch classifier loss: 0.123404; batch adversarial loss: 0.515950\n",
      "epoch 56; iter: 0; batch classifier loss: 0.147792; batch adversarial loss: 0.386968\n",
      "epoch 57; iter: 0; batch classifier loss: 0.121521; batch adversarial loss: 0.438418\n",
      "epoch 58; iter: 0; batch classifier loss: 0.114731; batch adversarial loss: 0.459087\n",
      "epoch 59; iter: 0; batch classifier loss: 0.135372; batch adversarial loss: 0.490769\n",
      "epoch 60; iter: 0; batch classifier loss: 0.135352; batch adversarial loss: 0.388538\n",
      "epoch 61; iter: 0; batch classifier loss: 0.126471; batch adversarial loss: 0.530645\n",
      "epoch 62; iter: 0; batch classifier loss: 0.124262; batch adversarial loss: 0.472084\n",
      "epoch 63; iter: 0; batch classifier loss: 0.136790; batch adversarial loss: 0.448191\n",
      "epoch 64; iter: 0; batch classifier loss: 0.101885; batch adversarial loss: 0.473814\n",
      "epoch 65; iter: 0; batch classifier loss: 0.103514; batch adversarial loss: 0.432210\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078036; batch adversarial loss: 0.448347\n",
      "epoch 67; iter: 0; batch classifier loss: 0.149014; batch adversarial loss: 0.487735\n",
      "epoch 68; iter: 0; batch classifier loss: 0.161247; batch adversarial loss: 0.434634\n",
      "epoch 69; iter: 0; batch classifier loss: 0.101674; batch adversarial loss: 0.528620\n",
      "epoch 70; iter: 0; batch classifier loss: 0.142463; batch adversarial loss: 0.467106\n",
      "epoch 71; iter: 0; batch classifier loss: 0.111626; batch adversarial loss: 0.434436\n",
      "epoch 72; iter: 0; batch classifier loss: 0.118052; batch adversarial loss: 0.509688\n",
      "epoch 73; iter: 0; batch classifier loss: 0.208961; batch adversarial loss: 0.459008\n",
      "epoch 74; iter: 0; batch classifier loss: 0.132026; batch adversarial loss: 0.484256\n",
      "epoch 75; iter: 0; batch classifier loss: 0.181650; batch adversarial loss: 0.494230\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081889; batch adversarial loss: 0.428421\n",
      "epoch 77; iter: 0; batch classifier loss: 0.111389; batch adversarial loss: 0.392201\n",
      "epoch 78; iter: 0; batch classifier loss: 0.105317; batch adversarial loss: 0.561685\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076967; batch adversarial loss: 0.580405\n",
      "epoch 80; iter: 0; batch classifier loss: 0.109137; batch adversarial loss: 0.489136\n",
      "epoch 81; iter: 0; batch classifier loss: 0.105140; batch adversarial loss: 0.419533\n",
      "epoch 82; iter: 0; batch classifier loss: 0.175641; batch adversarial loss: 0.506564\n",
      "epoch 83; iter: 0; batch classifier loss: 0.118707; batch adversarial loss: 0.348845\n",
      "epoch 84; iter: 0; batch classifier loss: 0.108232; batch adversarial loss: 0.465745\n",
      "epoch 85; iter: 0; batch classifier loss: 0.149398; batch adversarial loss: 0.472292\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083694; batch adversarial loss: 0.467928\n",
      "epoch 87; iter: 0; batch classifier loss: 0.119366; batch adversarial loss: 0.485093\n",
      "epoch 88; iter: 0; batch classifier loss: 0.130281; batch adversarial loss: 0.430515\n",
      "epoch 89; iter: 0; batch classifier loss: 0.083457; batch adversarial loss: 0.519629\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053832; batch adversarial loss: 0.360986\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074693; batch adversarial loss: 0.541287\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060542; batch adversarial loss: 0.465294\n",
      "epoch 93; iter: 0; batch classifier loss: 0.082054; batch adversarial loss: 0.450804\n",
      "epoch 94; iter: 0; batch classifier loss: 0.100721; batch adversarial loss: 0.349142\n",
      "epoch 95; iter: 0; batch classifier loss: 0.089952; batch adversarial loss: 0.426026\n",
      "epoch 96; iter: 0; batch classifier loss: 0.110993; batch adversarial loss: 0.418841\n",
      "epoch 97; iter: 0; batch classifier loss: 0.100687; batch adversarial loss: 0.396196\n",
      "epoch 98; iter: 0; batch classifier loss: 0.066106; batch adversarial loss: 0.487150\n",
      "epoch 99; iter: 0; batch classifier loss: 0.075275; batch adversarial loss: 0.490061\n",
      "epoch 100; iter: 0; batch classifier loss: 0.087846; batch adversarial loss: 0.502479\n",
      "epoch 101; iter: 0; batch classifier loss: 0.087519; batch adversarial loss: 0.453017\n",
      "epoch 102; iter: 0; batch classifier loss: 0.088175; batch adversarial loss: 0.398877\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072961; batch adversarial loss: 0.326701\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056780; batch adversarial loss: 0.483248\n",
      "epoch 105; iter: 0; batch classifier loss: 0.074301; batch adversarial loss: 0.377024\n",
      "epoch 106; iter: 0; batch classifier loss: 0.082989; batch adversarial loss: 0.435721\n",
      "epoch 107; iter: 0; batch classifier loss: 0.080570; batch adversarial loss: 0.458240\n",
      "epoch 108; iter: 0; batch classifier loss: 0.070509; batch adversarial loss: 0.498924\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042037; batch adversarial loss: 0.393717\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044023; batch adversarial loss: 0.424226\n",
      "epoch 111; iter: 0; batch classifier loss: 0.038345; batch adversarial loss: 0.539377\n",
      "epoch 112; iter: 0; batch classifier loss: 0.066105; batch adversarial loss: 0.460058\n",
      "epoch 113; iter: 0; batch classifier loss: 0.086008; batch adversarial loss: 0.526763\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043614; batch adversarial loss: 0.441769\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035566; batch adversarial loss: 0.380725\n",
      "epoch 116; iter: 0; batch classifier loss: 0.075415; batch adversarial loss: 0.431523\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043263; batch adversarial loss: 0.472811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.053156; batch adversarial loss: 0.531276\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065910; batch adversarial loss: 0.428349\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038593; batch adversarial loss: 0.444534\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047293; batch adversarial loss: 0.461352\n",
      "epoch 122; iter: 0; batch classifier loss: 0.057465; batch adversarial loss: 0.521226\n",
      "epoch 123; iter: 0; batch classifier loss: 0.063414; batch adversarial loss: 0.431474\n",
      "epoch 124; iter: 0; batch classifier loss: 0.047556; batch adversarial loss: 0.521457\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050446; batch adversarial loss: 0.515622\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063712; batch adversarial loss: 0.491187\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023893; batch adversarial loss: 0.436143\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052264; batch adversarial loss: 0.415074\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021752; batch adversarial loss: 0.519616\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028333; batch adversarial loss: 0.447808\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044930; batch adversarial loss: 0.513502\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053588; batch adversarial loss: 0.489419\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031878; batch adversarial loss: 0.509807\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023562; batch adversarial loss: 0.464052\n",
      "epoch 135; iter: 0; batch classifier loss: 0.056327; batch adversarial loss: 0.383999\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031491; batch adversarial loss: 0.421225\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030315; batch adversarial loss: 0.344655\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039764; batch adversarial loss: 0.515355\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045943; batch adversarial loss: 0.408963\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051423; batch adversarial loss: 0.457089\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029014; batch adversarial loss: 0.482743\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033325; batch adversarial loss: 0.410199\n",
      "epoch 143; iter: 0; batch classifier loss: 0.063936; batch adversarial loss: 0.388572\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016936; batch adversarial loss: 0.426466\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046402; batch adversarial loss: 0.450242\n",
      "epoch 146; iter: 0; batch classifier loss: 0.054695; batch adversarial loss: 0.448855\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024110; batch adversarial loss: 0.441352\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039985; batch adversarial loss: 0.449311\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032239; batch adversarial loss: 0.551354\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039390; batch adversarial loss: 0.487197\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032927; batch adversarial loss: 0.480834\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017715; batch adversarial loss: 0.428934\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021671; batch adversarial loss: 0.488395\n",
      "epoch 154; iter: 0; batch classifier loss: 0.051270; batch adversarial loss: 0.475899\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025030; batch adversarial loss: 0.420909\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043893; batch adversarial loss: 0.439697\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032891; batch adversarial loss: 0.490103\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021006; batch adversarial loss: 0.408384\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027373; batch adversarial loss: 0.466164\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014894; batch adversarial loss: 0.426917\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016717; batch adversarial loss: 0.563083\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028526; batch adversarial loss: 0.416957\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036723; batch adversarial loss: 0.481379\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033798; batch adversarial loss: 0.359262\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035612; batch adversarial loss: 0.414299\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040083; batch adversarial loss: 0.456963\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019289; batch adversarial loss: 0.532843\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031018; batch adversarial loss: 0.410303\n",
      "epoch 169; iter: 0; batch classifier loss: 0.005743; batch adversarial loss: 0.542164\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008871; batch adversarial loss: 0.398969\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024439; batch adversarial loss: 0.492027\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005588; batch adversarial loss: 0.472978\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017315; batch adversarial loss: 0.553957\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015878; batch adversarial loss: 0.432342\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021236; batch adversarial loss: 0.444980\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022450; batch adversarial loss: 0.430914\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020533; batch adversarial loss: 0.388895\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007073; batch adversarial loss: 0.379199\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031606; batch adversarial loss: 0.497543\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016100; batch adversarial loss: 0.510061\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023854; batch adversarial loss: 0.439828\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010855; batch adversarial loss: 0.532579\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029679; batch adversarial loss: 0.471511\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014627; batch adversarial loss: 0.442260\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012099; batch adversarial loss: 0.397195\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019023; batch adversarial loss: 0.342145\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011022; batch adversarial loss: 0.449473\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032459; batch adversarial loss: 0.367602\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028152; batch adversarial loss: 0.549833\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018297; batch adversarial loss: 0.490013\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024417; batch adversarial loss: 0.405346\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030436; batch adversarial loss: 0.475062\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016476; batch adversarial loss: 0.405033\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030614; batch adversarial loss: 0.337628\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010956; batch adversarial loss: 0.538411\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028043; batch adversarial loss: 0.482515\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015057; batch adversarial loss: 0.470134\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020308; batch adversarial loss: 0.477033\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021182; batch adversarial loss: 0.432220\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671933; batch adversarial loss: 0.721413\n",
      "epoch 1; iter: 0; batch classifier loss: 0.449177; batch adversarial loss: 0.650053\n",
      "epoch 2; iter: 0; batch classifier loss: 0.497410; batch adversarial loss: 0.623031\n",
      "epoch 3; iter: 0; batch classifier loss: 0.406112; batch adversarial loss: 0.583951\n",
      "epoch 4; iter: 0; batch classifier loss: 0.372108; batch adversarial loss: 0.584921\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387937; batch adversarial loss: 0.577547\n",
      "epoch 6; iter: 0; batch classifier loss: 0.357665; batch adversarial loss: 0.547617\n",
      "epoch 7; iter: 0; batch classifier loss: 0.334511; batch adversarial loss: 0.551121\n",
      "epoch 8; iter: 0; batch classifier loss: 0.340219; batch adversarial loss: 0.564084\n",
      "epoch 9; iter: 0; batch classifier loss: 0.400839; batch adversarial loss: 0.583892\n",
      "epoch 10; iter: 0; batch classifier loss: 0.413584; batch adversarial loss: 0.553213\n",
      "epoch 11; iter: 0; batch classifier loss: 0.344057; batch adversarial loss: 0.526142\n",
      "epoch 12; iter: 0; batch classifier loss: 0.353134; batch adversarial loss: 0.579251\n",
      "epoch 13; iter: 0; batch classifier loss: 0.293288; batch adversarial loss: 0.465983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.316481; batch adversarial loss: 0.507934\n",
      "epoch 15; iter: 0; batch classifier loss: 0.362451; batch adversarial loss: 0.505522\n",
      "epoch 16; iter: 0; batch classifier loss: 0.360429; batch adversarial loss: 0.496569\n",
      "epoch 17; iter: 0; batch classifier loss: 0.363657; batch adversarial loss: 0.494149\n",
      "epoch 18; iter: 0; batch classifier loss: 0.288053; batch adversarial loss: 0.563020\n",
      "epoch 19; iter: 0; batch classifier loss: 0.310786; batch adversarial loss: 0.432525\n",
      "epoch 20; iter: 0; batch classifier loss: 0.317320; batch adversarial loss: 0.520888\n",
      "epoch 21; iter: 0; batch classifier loss: 0.272787; batch adversarial loss: 0.473392\n",
      "epoch 22; iter: 0; batch classifier loss: 0.339424; batch adversarial loss: 0.417700\n",
      "epoch 23; iter: 0; batch classifier loss: 0.248134; batch adversarial loss: 0.430797\n",
      "epoch 24; iter: 0; batch classifier loss: 0.414142; batch adversarial loss: 0.375811\n",
      "epoch 25; iter: 0; batch classifier loss: 0.257220; batch adversarial loss: 0.548735\n",
      "epoch 26; iter: 0; batch classifier loss: 0.259253; batch adversarial loss: 0.478863\n",
      "epoch 27; iter: 0; batch classifier loss: 0.241674; batch adversarial loss: 0.524578\n",
      "epoch 28; iter: 0; batch classifier loss: 0.285128; batch adversarial loss: 0.405296\n",
      "epoch 29; iter: 0; batch classifier loss: 0.265247; batch adversarial loss: 0.416576\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205386; batch adversarial loss: 0.489973\n",
      "epoch 31; iter: 0; batch classifier loss: 0.281084; batch adversarial loss: 0.455657\n",
      "epoch 32; iter: 0; batch classifier loss: 0.230318; batch adversarial loss: 0.505641\n",
      "epoch 33; iter: 0; batch classifier loss: 0.210709; batch adversarial loss: 0.510541\n",
      "epoch 34; iter: 0; batch classifier loss: 0.265662; batch adversarial loss: 0.518526\n",
      "epoch 35; iter: 0; batch classifier loss: 0.289116; batch adversarial loss: 0.423450\n",
      "epoch 36; iter: 0; batch classifier loss: 0.206625; batch adversarial loss: 0.510710\n",
      "epoch 37; iter: 0; batch classifier loss: 0.222821; batch adversarial loss: 0.403187\n",
      "epoch 38; iter: 0; batch classifier loss: 0.270918; batch adversarial loss: 0.472820\n",
      "epoch 39; iter: 0; batch classifier loss: 0.267902; batch adversarial loss: 0.385875\n",
      "epoch 40; iter: 0; batch classifier loss: 0.249999; batch adversarial loss: 0.492000\n",
      "epoch 41; iter: 0; batch classifier loss: 0.258292; batch adversarial loss: 0.469112\n",
      "epoch 42; iter: 0; batch classifier loss: 0.266095; batch adversarial loss: 0.370628\n",
      "epoch 43; iter: 0; batch classifier loss: 0.276421; batch adversarial loss: 0.550982\n",
      "epoch 44; iter: 0; batch classifier loss: 0.232097; batch adversarial loss: 0.457003\n",
      "epoch 45; iter: 0; batch classifier loss: 0.221053; batch adversarial loss: 0.443586\n",
      "epoch 46; iter: 0; batch classifier loss: 0.244012; batch adversarial loss: 0.445039\n",
      "epoch 47; iter: 0; batch classifier loss: 0.250589; batch adversarial loss: 0.485953\n",
      "epoch 48; iter: 0; batch classifier loss: 0.287429; batch adversarial loss: 0.420682\n",
      "epoch 49; iter: 0; batch classifier loss: 0.212193; batch adversarial loss: 0.446018\n",
      "epoch 50; iter: 0; batch classifier loss: 0.379558; batch adversarial loss: 0.434959\n",
      "epoch 51; iter: 0; batch classifier loss: 0.221657; batch adversarial loss: 0.579494\n",
      "epoch 52; iter: 0; batch classifier loss: 0.274747; batch adversarial loss: 0.337941\n",
      "epoch 53; iter: 0; batch classifier loss: 0.149459; batch adversarial loss: 0.580089\n",
      "epoch 54; iter: 0; batch classifier loss: 0.123276; batch adversarial loss: 0.312091\n",
      "epoch 55; iter: 0; batch classifier loss: 0.132355; batch adversarial loss: 0.398042\n",
      "epoch 56; iter: 0; batch classifier loss: 0.164371; batch adversarial loss: 0.418617\n",
      "epoch 57; iter: 0; batch classifier loss: 0.259893; batch adversarial loss: 0.496709\n",
      "epoch 58; iter: 0; batch classifier loss: 0.151034; batch adversarial loss: 0.411778\n",
      "epoch 59; iter: 0; batch classifier loss: 0.240828; batch adversarial loss: 0.483694\n",
      "epoch 60; iter: 0; batch classifier loss: 0.222695; batch adversarial loss: 0.373223\n",
      "epoch 61; iter: 0; batch classifier loss: 0.222636; batch adversarial loss: 0.482653\n",
      "epoch 62; iter: 0; batch classifier loss: 0.216194; batch adversarial loss: 0.456904\n",
      "epoch 63; iter: 0; batch classifier loss: 0.169730; batch adversarial loss: 0.472760\n",
      "epoch 64; iter: 0; batch classifier loss: 0.210442; batch adversarial loss: 0.507846\n",
      "epoch 65; iter: 0; batch classifier loss: 0.260980; batch adversarial loss: 0.446271\n",
      "epoch 66; iter: 0; batch classifier loss: 0.140816; batch adversarial loss: 0.482968\n",
      "epoch 67; iter: 0; batch classifier loss: 0.076946; batch adversarial loss: 0.342673\n",
      "epoch 68; iter: 0; batch classifier loss: 0.139894; batch adversarial loss: 0.505743\n",
      "epoch 69; iter: 0; batch classifier loss: 0.297084; batch adversarial loss: 0.471066\n",
      "epoch 70; iter: 0; batch classifier loss: 0.259564; batch adversarial loss: 0.424088\n",
      "epoch 71; iter: 0; batch classifier loss: 0.200528; batch adversarial loss: 0.397873\n",
      "epoch 72; iter: 0; batch classifier loss: 0.168157; batch adversarial loss: 0.634290\n",
      "epoch 73; iter: 0; batch classifier loss: 0.235634; batch adversarial loss: 0.533130\n",
      "epoch 74; iter: 0; batch classifier loss: 0.192809; batch adversarial loss: 0.494369\n",
      "epoch 75; iter: 0; batch classifier loss: 0.213996; batch adversarial loss: 0.419808\n",
      "epoch 76; iter: 0; batch classifier loss: 0.171809; batch adversarial loss: 0.558025\n",
      "epoch 77; iter: 0; batch classifier loss: 0.191309; batch adversarial loss: 0.346969\n",
      "epoch 78; iter: 0; batch classifier loss: 0.292932; batch adversarial loss: 0.471467\n",
      "epoch 79; iter: 0; batch classifier loss: 0.088724; batch adversarial loss: 0.458665\n",
      "epoch 80; iter: 0; batch classifier loss: 0.179727; batch adversarial loss: 0.446019\n",
      "epoch 81; iter: 0; batch classifier loss: 0.228220; batch adversarial loss: 0.421809\n",
      "epoch 82; iter: 0; batch classifier loss: 0.079171; batch adversarial loss: 0.383040\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086586; batch adversarial loss: 0.444017\n",
      "epoch 84; iter: 0; batch classifier loss: 0.076163; batch adversarial loss: 0.389197\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070503; batch adversarial loss: 0.428118\n",
      "epoch 86; iter: 0; batch classifier loss: 0.034408; batch adversarial loss: 0.519299\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046466; batch adversarial loss: 0.476910\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057006; batch adversarial loss: 0.476711\n",
      "epoch 89; iter: 0; batch classifier loss: 0.077298; batch adversarial loss: 0.503587\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075113; batch adversarial loss: 0.405693\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060848; batch adversarial loss: 0.451050\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057184; batch adversarial loss: 0.489441\n",
      "epoch 93; iter: 0; batch classifier loss: 0.066840; batch adversarial loss: 0.469507\n",
      "epoch 94; iter: 0; batch classifier loss: 0.087913; batch adversarial loss: 0.391837\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053086; batch adversarial loss: 0.450362\n",
      "epoch 96; iter: 0; batch classifier loss: 0.085384; batch adversarial loss: 0.455164\n",
      "epoch 97; iter: 0; batch classifier loss: 0.034970; batch adversarial loss: 0.431472\n",
      "epoch 98; iter: 0; batch classifier loss: 0.113687; batch adversarial loss: 0.474428\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067698; batch adversarial loss: 0.397365\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075978; batch adversarial loss: 0.441822\n",
      "epoch 101; iter: 0; batch classifier loss: 0.034315; batch adversarial loss: 0.453165\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042458; batch adversarial loss: 0.493560\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045015; batch adversarial loss: 0.485211\n",
      "epoch 104; iter: 0; batch classifier loss: 0.029797; batch adversarial loss: 0.454585\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052111; batch adversarial loss: 0.438295\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052138; batch adversarial loss: 0.571905\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039436; batch adversarial loss: 0.425859\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039117; batch adversarial loss: 0.446322\n",
      "epoch 109; iter: 0; batch classifier loss: 0.017661; batch adversarial loss: 0.418958\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036679; batch adversarial loss: 0.555349\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049662; batch adversarial loss: 0.483993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.043314; batch adversarial loss: 0.497015\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052918; batch adversarial loss: 0.436006\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029833; batch adversarial loss: 0.533585\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051520; batch adversarial loss: 0.412278\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048366; batch adversarial loss: 0.399154\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046819; batch adversarial loss: 0.464211\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025827; batch adversarial loss: 0.440134\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059663; batch adversarial loss: 0.448413\n",
      "epoch 120; iter: 0; batch classifier loss: 0.073107; batch adversarial loss: 0.480527\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047863; batch adversarial loss: 0.419088\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059916; batch adversarial loss: 0.372551\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042618; batch adversarial loss: 0.426221\n",
      "epoch 124; iter: 0; batch classifier loss: 0.034846; batch adversarial loss: 0.328020\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034945; batch adversarial loss: 0.565279\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027986; batch adversarial loss: 0.384100\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030652; batch adversarial loss: 0.384801\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041535; batch adversarial loss: 0.395334\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022888; batch adversarial loss: 0.460174\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036944; batch adversarial loss: 0.349872\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038306; batch adversarial loss: 0.373578\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040910; batch adversarial loss: 0.506345\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014162; batch adversarial loss: 0.425211\n",
      "epoch 134; iter: 0; batch classifier loss: 0.009375; batch adversarial loss: 0.435186\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031317; batch adversarial loss: 0.418922\n",
      "epoch 136; iter: 0; batch classifier loss: 0.011197; batch adversarial loss: 0.431789\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031719; batch adversarial loss: 0.428136\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011983; batch adversarial loss: 0.457087\n",
      "epoch 139; iter: 0; batch classifier loss: 0.011937; batch adversarial loss: 0.449346\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013454; batch adversarial loss: 0.465214\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016050; batch adversarial loss: 0.576398\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028520; batch adversarial loss: 0.431289\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014328; batch adversarial loss: 0.417351\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033525; batch adversarial loss: 0.463589\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013767; batch adversarial loss: 0.440334\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024976; batch adversarial loss: 0.442794\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030694; batch adversarial loss: 0.484743\n",
      "epoch 148; iter: 0; batch classifier loss: 0.011388; batch adversarial loss: 0.490512\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020325; batch adversarial loss: 0.350464\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052185; batch adversarial loss: 0.460334\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022254; batch adversarial loss: 0.550615\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033494; batch adversarial loss: 0.444848\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014970; batch adversarial loss: 0.452335\n",
      "epoch 154; iter: 0; batch classifier loss: 0.007523; batch adversarial loss: 0.440613\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024868; batch adversarial loss: 0.451420\n",
      "epoch 156; iter: 0; batch classifier loss: 0.010370; batch adversarial loss: 0.509386\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025460; batch adversarial loss: 0.376742\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022195; batch adversarial loss: 0.446601\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022294; batch adversarial loss: 0.383568\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009376; batch adversarial loss: 0.418279\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016799; batch adversarial loss: 0.509640\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031025; batch adversarial loss: 0.489588\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010356; batch adversarial loss: 0.459691\n",
      "epoch 164; iter: 0; batch classifier loss: 0.005822; batch adversarial loss: 0.473658\n",
      "epoch 165; iter: 0; batch classifier loss: 0.005789; batch adversarial loss: 0.408700\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010160; batch adversarial loss: 0.476518\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007884; batch adversarial loss: 0.486904\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025657; batch adversarial loss: 0.410163\n",
      "epoch 169; iter: 0; batch classifier loss: 0.039974; batch adversarial loss: 0.459140\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023765; batch adversarial loss: 0.524677\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014839; batch adversarial loss: 0.468144\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007206; batch adversarial loss: 0.458597\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013010; batch adversarial loss: 0.428924\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019043; batch adversarial loss: 0.413920\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026360; batch adversarial loss: 0.382540\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011803; batch adversarial loss: 0.463367\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030545; batch adversarial loss: 0.414057\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027554; batch adversarial loss: 0.452299\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034501; batch adversarial loss: 0.504096\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012074; batch adversarial loss: 0.418109\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020763; batch adversarial loss: 0.484586\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013553; batch adversarial loss: 0.492200\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020823; batch adversarial loss: 0.410181\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018295; batch adversarial loss: 0.397268\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027455; batch adversarial loss: 0.454023\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012767; batch adversarial loss: 0.486752\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005064; batch adversarial loss: 0.485187\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033616; batch adversarial loss: 0.422687\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004757; batch adversarial loss: 0.362313\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020116; batch adversarial loss: 0.397190\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009476; batch adversarial loss: 0.370570\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014929; batch adversarial loss: 0.539623\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017452; batch adversarial loss: 0.454779\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016184; batch adversarial loss: 0.497642\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004139; batch adversarial loss: 0.443940\n",
      "epoch 196; iter: 0; batch classifier loss: 0.035866; batch adversarial loss: 0.400630\n",
      "epoch 197; iter: 0; batch classifier loss: 0.041772; batch adversarial loss: 0.430390\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008087; batch adversarial loss: 0.519750\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018486; batch adversarial loss: 0.495372\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700908; batch adversarial loss: 0.629304\n",
      "epoch 1; iter: 0; batch classifier loss: 0.467040; batch adversarial loss: 0.647507\n",
      "epoch 2; iter: 0; batch classifier loss: 0.429019; batch adversarial loss: 0.590874\n",
      "epoch 3; iter: 0; batch classifier loss: 0.335208; batch adversarial loss: 0.572850\n",
      "epoch 4; iter: 0; batch classifier loss: 0.382410; batch adversarial loss: 0.525583\n",
      "epoch 5; iter: 0; batch classifier loss: 0.290416; batch adversarial loss: 0.509469\n",
      "epoch 6; iter: 0; batch classifier loss: 0.245612; batch adversarial loss: 0.502879\n",
      "epoch 7; iter: 0; batch classifier loss: 0.230924; batch adversarial loss: 0.513969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.219002; batch adversarial loss: 0.481478\n",
      "epoch 9; iter: 0; batch classifier loss: 0.255849; batch adversarial loss: 0.507459\n",
      "epoch 10; iter: 0; batch classifier loss: 0.260414; batch adversarial loss: 0.464365\n",
      "epoch 11; iter: 0; batch classifier loss: 0.227834; batch adversarial loss: 0.527399\n",
      "epoch 12; iter: 0; batch classifier loss: 0.247282; batch adversarial loss: 0.455810\n",
      "epoch 13; iter: 0; batch classifier loss: 0.198124; batch adversarial loss: 0.461543\n",
      "epoch 14; iter: 0; batch classifier loss: 0.198934; batch adversarial loss: 0.443123\n",
      "epoch 15; iter: 0; batch classifier loss: 0.231473; batch adversarial loss: 0.548030\n",
      "epoch 16; iter: 0; batch classifier loss: 0.198687; batch adversarial loss: 0.501484\n",
      "epoch 17; iter: 0; batch classifier loss: 0.231354; batch adversarial loss: 0.535690\n",
      "epoch 18; iter: 0; batch classifier loss: 0.178259; batch adversarial loss: 0.457578\n",
      "epoch 19; iter: 0; batch classifier loss: 0.166014; batch adversarial loss: 0.423142\n",
      "epoch 20; iter: 0; batch classifier loss: 0.199396; batch adversarial loss: 0.546575\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202109; batch adversarial loss: 0.547435\n",
      "epoch 22; iter: 0; batch classifier loss: 0.152309; batch adversarial loss: 0.473450\n",
      "epoch 23; iter: 0; batch classifier loss: 0.281787; batch adversarial loss: 0.496290\n",
      "epoch 24; iter: 0; batch classifier loss: 0.173116; batch adversarial loss: 0.436632\n",
      "epoch 25; iter: 0; batch classifier loss: 0.248343; batch adversarial loss: 0.533351\n",
      "epoch 26; iter: 0; batch classifier loss: 0.217655; batch adversarial loss: 0.481117\n",
      "epoch 27; iter: 0; batch classifier loss: 0.227048; batch adversarial loss: 0.426749\n",
      "epoch 28; iter: 0; batch classifier loss: 0.230347; batch adversarial loss: 0.431477\n",
      "epoch 29; iter: 0; batch classifier loss: 0.272925; batch adversarial loss: 0.473470\n",
      "epoch 30; iter: 0; batch classifier loss: 0.302984; batch adversarial loss: 0.452843\n",
      "epoch 31; iter: 0; batch classifier loss: 0.170553; batch adversarial loss: 0.441964\n",
      "epoch 32; iter: 0; batch classifier loss: 0.099748; batch adversarial loss: 0.499403\n",
      "epoch 33; iter: 0; batch classifier loss: 0.126674; batch adversarial loss: 0.445130\n",
      "epoch 34; iter: 0; batch classifier loss: 0.094209; batch adversarial loss: 0.485319\n",
      "epoch 35; iter: 0; batch classifier loss: 0.120353; batch adversarial loss: 0.474529\n",
      "epoch 36; iter: 0; batch classifier loss: 0.122501; batch adversarial loss: 0.402255\n",
      "epoch 37; iter: 0; batch classifier loss: 0.164785; batch adversarial loss: 0.485256\n",
      "epoch 38; iter: 0; batch classifier loss: 0.079197; batch adversarial loss: 0.455889\n",
      "epoch 39; iter: 0; batch classifier loss: 0.088542; batch adversarial loss: 0.471773\n",
      "epoch 40; iter: 0; batch classifier loss: 0.077431; batch adversarial loss: 0.450870\n",
      "epoch 41; iter: 0; batch classifier loss: 0.087174; batch adversarial loss: 0.339662\n",
      "epoch 42; iter: 0; batch classifier loss: 0.049167; batch adversarial loss: 0.435007\n",
      "epoch 43; iter: 0; batch classifier loss: 0.112503; batch adversarial loss: 0.410766\n",
      "epoch 44; iter: 0; batch classifier loss: 0.073948; batch adversarial loss: 0.427361\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091045; batch adversarial loss: 0.476509\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117806; batch adversarial loss: 0.371300\n",
      "epoch 47; iter: 0; batch classifier loss: 0.062939; batch adversarial loss: 0.501023\n",
      "epoch 48; iter: 0; batch classifier loss: 0.134779; batch adversarial loss: 0.415842\n",
      "epoch 49; iter: 0; batch classifier loss: 0.056585; batch adversarial loss: 0.495244\n",
      "epoch 50; iter: 0; batch classifier loss: 0.041312; batch adversarial loss: 0.480922\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073673; batch adversarial loss: 0.445958\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082846; batch adversarial loss: 0.484158\n",
      "epoch 53; iter: 0; batch classifier loss: 0.057104; batch adversarial loss: 0.518469\n",
      "epoch 54; iter: 0; batch classifier loss: 0.069250; batch adversarial loss: 0.432748\n",
      "epoch 55; iter: 0; batch classifier loss: 0.075900; batch adversarial loss: 0.468717\n",
      "epoch 56; iter: 0; batch classifier loss: 0.116856; batch adversarial loss: 0.396529\n",
      "epoch 57; iter: 0; batch classifier loss: 0.049949; batch adversarial loss: 0.498712\n",
      "epoch 58; iter: 0; batch classifier loss: 0.035528; batch adversarial loss: 0.527225\n",
      "epoch 59; iter: 0; batch classifier loss: 0.096295; batch adversarial loss: 0.515388\n",
      "epoch 60; iter: 0; batch classifier loss: 0.038069; batch adversarial loss: 0.597127\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103289; batch adversarial loss: 0.505825\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101566; batch adversarial loss: 0.401648\n",
      "epoch 63; iter: 0; batch classifier loss: 0.055400; batch adversarial loss: 0.416582\n",
      "epoch 64; iter: 0; batch classifier loss: 0.036219; batch adversarial loss: 0.417890\n",
      "epoch 65; iter: 0; batch classifier loss: 0.062928; batch adversarial loss: 0.457036\n",
      "epoch 66; iter: 0; batch classifier loss: 0.064672; batch adversarial loss: 0.558248\n",
      "epoch 67; iter: 0; batch classifier loss: 0.065147; batch adversarial loss: 0.394730\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070834; batch adversarial loss: 0.587053\n",
      "epoch 69; iter: 0; batch classifier loss: 0.048987; batch adversarial loss: 0.517111\n",
      "epoch 70; iter: 0; batch classifier loss: 0.062502; batch adversarial loss: 0.503570\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089229; batch adversarial loss: 0.481770\n",
      "epoch 72; iter: 0; batch classifier loss: 0.024200; batch adversarial loss: 0.402459\n",
      "epoch 73; iter: 0; batch classifier loss: 0.137695; batch adversarial loss: 0.384296\n",
      "epoch 74; iter: 0; batch classifier loss: 0.072612; batch adversarial loss: 0.443993\n",
      "epoch 75; iter: 0; batch classifier loss: 0.051896; batch adversarial loss: 0.532043\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058778; batch adversarial loss: 0.443177\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045189; batch adversarial loss: 0.485613\n",
      "epoch 78; iter: 0; batch classifier loss: 0.038027; batch adversarial loss: 0.443160\n",
      "epoch 79; iter: 0; batch classifier loss: 0.046902; batch adversarial loss: 0.470264\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078136; batch adversarial loss: 0.481524\n",
      "epoch 81; iter: 0; batch classifier loss: 0.053339; batch adversarial loss: 0.498198\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060646; batch adversarial loss: 0.432590\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079644; batch adversarial loss: 0.408952\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062463; batch adversarial loss: 0.526185\n",
      "epoch 85; iter: 0; batch classifier loss: 0.085857; batch adversarial loss: 0.475159\n",
      "epoch 86; iter: 0; batch classifier loss: 0.085735; batch adversarial loss: 0.468513\n",
      "epoch 87; iter: 0; batch classifier loss: 0.038903; batch adversarial loss: 0.445022\n",
      "epoch 88; iter: 0; batch classifier loss: 0.035000; batch adversarial loss: 0.402195\n",
      "epoch 89; iter: 0; batch classifier loss: 0.077407; batch adversarial loss: 0.461667\n",
      "epoch 90; iter: 0; batch classifier loss: 0.080093; batch adversarial loss: 0.491567\n",
      "epoch 91; iter: 0; batch classifier loss: 0.034544; batch adversarial loss: 0.409346\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060559; batch adversarial loss: 0.411720\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067066; batch adversarial loss: 0.533886\n",
      "epoch 94; iter: 0; batch classifier loss: 0.092282; batch adversarial loss: 0.438669\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080272; batch adversarial loss: 0.345323\n",
      "epoch 96; iter: 0; batch classifier loss: 0.079897; batch adversarial loss: 0.442909\n",
      "epoch 97; iter: 0; batch classifier loss: 0.105763; batch adversarial loss: 0.419789\n",
      "epoch 98; iter: 0; batch classifier loss: 0.105896; batch adversarial loss: 0.409549\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043482; batch adversarial loss: 0.462908\n",
      "epoch 100; iter: 0; batch classifier loss: 0.093700; batch adversarial loss: 0.443594\n",
      "epoch 101; iter: 0; batch classifier loss: 0.073013; batch adversarial loss: 0.457187\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048279; batch adversarial loss: 0.587194\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057227; batch adversarial loss: 0.402552\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063259; batch adversarial loss: 0.484609\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058452; batch adversarial loss: 0.513757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.044878; batch adversarial loss: 0.496427\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048858; batch adversarial loss: 0.499480\n",
      "epoch 108; iter: 0; batch classifier loss: 0.021192; batch adversarial loss: 0.543114\n",
      "epoch 109; iter: 0; batch classifier loss: 0.035727; batch adversarial loss: 0.515188\n",
      "epoch 110; iter: 0; batch classifier loss: 0.075521; batch adversarial loss: 0.418474\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054152; batch adversarial loss: 0.487361\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057267; batch adversarial loss: 0.406194\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025947; batch adversarial loss: 0.425549\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046585; batch adversarial loss: 0.466220\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033979; batch adversarial loss: 0.513145\n",
      "epoch 116; iter: 0; batch classifier loss: 0.031422; batch adversarial loss: 0.558619\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048792; batch adversarial loss: 0.508163\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033190; batch adversarial loss: 0.329616\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045085; batch adversarial loss: 0.476370\n",
      "epoch 120; iter: 0; batch classifier loss: 0.069187; batch adversarial loss: 0.514219\n",
      "epoch 121; iter: 0; batch classifier loss: 0.062502; batch adversarial loss: 0.464862\n",
      "epoch 122; iter: 0; batch classifier loss: 0.054776; batch adversarial loss: 0.447522\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027128; batch adversarial loss: 0.450669\n",
      "epoch 124; iter: 0; batch classifier loss: 0.061858; batch adversarial loss: 0.408935\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041610; batch adversarial loss: 0.409819\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046265; batch adversarial loss: 0.386283\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024320; batch adversarial loss: 0.404800\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034657; batch adversarial loss: 0.454477\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025526; batch adversarial loss: 0.440961\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024626; batch adversarial loss: 0.481634\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015899; batch adversarial loss: 0.477095\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025689; batch adversarial loss: 0.491463\n",
      "epoch 133; iter: 0; batch classifier loss: 0.069145; batch adversarial loss: 0.431883\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034436; batch adversarial loss: 0.488456\n",
      "epoch 135; iter: 0; batch classifier loss: 0.088699; batch adversarial loss: 0.519240\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036072; batch adversarial loss: 0.420041\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042097; batch adversarial loss: 0.369959\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031056; batch adversarial loss: 0.477123\n",
      "epoch 139; iter: 0; batch classifier loss: 0.055088; batch adversarial loss: 0.539147\n",
      "epoch 140; iter: 0; batch classifier loss: 0.057636; batch adversarial loss: 0.472338\n",
      "epoch 141; iter: 0; batch classifier loss: 0.055411; batch adversarial loss: 0.450789\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032743; batch adversarial loss: 0.485046\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020465; batch adversarial loss: 0.426003\n",
      "epoch 144; iter: 0; batch classifier loss: 0.092955; batch adversarial loss: 0.491143\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029820; batch adversarial loss: 0.373789\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023605; batch adversarial loss: 0.355780\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021067; batch adversarial loss: 0.433159\n",
      "epoch 148; iter: 0; batch classifier loss: 0.051446; batch adversarial loss: 0.414341\n",
      "epoch 149; iter: 0; batch classifier loss: 0.049062; batch adversarial loss: 0.500771\n",
      "epoch 150; iter: 0; batch classifier loss: 0.058372; batch adversarial loss: 0.443678\n",
      "epoch 151; iter: 0; batch classifier loss: 0.051194; batch adversarial loss: 0.401637\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035866; batch adversarial loss: 0.395820\n",
      "epoch 153; iter: 0; batch classifier loss: 0.080967; batch adversarial loss: 0.569081\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028058; batch adversarial loss: 0.458300\n",
      "epoch 155; iter: 0; batch classifier loss: 0.039714; batch adversarial loss: 0.442378\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050979; batch adversarial loss: 0.514145\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042633; batch adversarial loss: 0.527911\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009206; batch adversarial loss: 0.418675\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045387; batch adversarial loss: 0.430956\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036158; batch adversarial loss: 0.477719\n",
      "epoch 161; iter: 0; batch classifier loss: 0.052168; batch adversarial loss: 0.494373\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036322; batch adversarial loss: 0.446027\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014998; batch adversarial loss: 0.418749\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024014; batch adversarial loss: 0.432816\n",
      "epoch 165; iter: 0; batch classifier loss: 0.076215; batch adversarial loss: 0.396777\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032014; batch adversarial loss: 0.386264\n",
      "epoch 167; iter: 0; batch classifier loss: 0.073108; batch adversarial loss: 0.461297\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035547; batch adversarial loss: 0.417849\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019740; batch adversarial loss: 0.499138\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037657; batch adversarial loss: 0.498487\n",
      "epoch 171; iter: 0; batch classifier loss: 0.045656; batch adversarial loss: 0.522195\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025044; batch adversarial loss: 0.369816\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026959; batch adversarial loss: 0.420568\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008811; batch adversarial loss: 0.481739\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030430; batch adversarial loss: 0.434105\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020246; batch adversarial loss: 0.487332\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026581; batch adversarial loss: 0.495800\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010031; batch adversarial loss: 0.478837\n",
      "epoch 179; iter: 0; batch classifier loss: 0.046245; batch adversarial loss: 0.378190\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015332; batch adversarial loss: 0.367985\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015596; batch adversarial loss: 0.477286\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021033; batch adversarial loss: 0.407662\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030667; batch adversarial loss: 0.436452\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031305; batch adversarial loss: 0.557730\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019348; batch adversarial loss: 0.381234\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026217; batch adversarial loss: 0.545878\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023516; batch adversarial loss: 0.567487\n",
      "epoch 188; iter: 0; batch classifier loss: 0.046041; batch adversarial loss: 0.437303\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029021; batch adversarial loss: 0.404733\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006107; batch adversarial loss: 0.423660\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026906; batch adversarial loss: 0.474383\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014489; batch adversarial loss: 0.386512\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022272; batch adversarial loss: 0.375904\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012340; batch adversarial loss: 0.386523\n",
      "epoch 195; iter: 0; batch classifier loss: 0.038139; batch adversarial loss: 0.419561\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032860; batch adversarial loss: 0.358178\n",
      "epoch 197; iter: 0; batch classifier loss: 0.063169; batch adversarial loss: 0.441940\n",
      "epoch 198; iter: 0; batch classifier loss: 0.065495; batch adversarial loss: 0.521172\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028563; batch adversarial loss: 0.400569\n",
      "epoch 0; iter: 0; batch classifier loss: 0.662274; batch adversarial loss: 0.544646\n",
      "epoch 1; iter: 0; batch classifier loss: 0.372991; batch adversarial loss: 0.633065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.363124; batch adversarial loss: 0.584175\n",
      "epoch 3; iter: 0; batch classifier loss: 0.398109; batch adversarial loss: 0.596484\n",
      "epoch 4; iter: 0; batch classifier loss: 0.397185; batch adversarial loss: 0.613547\n",
      "epoch 5; iter: 0; batch classifier loss: 0.392175; batch adversarial loss: 0.501058\n",
      "epoch 6; iter: 0; batch classifier loss: 0.430671; batch adversarial loss: 0.625190\n",
      "epoch 7; iter: 0; batch classifier loss: 0.388517; batch adversarial loss: 0.583628\n",
      "epoch 8; iter: 0; batch classifier loss: 0.475533; batch adversarial loss: 0.579114\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537980; batch adversarial loss: 0.557960\n",
      "epoch 10; iter: 0; batch classifier loss: 0.650306; batch adversarial loss: 0.578431\n",
      "epoch 11; iter: 0; batch classifier loss: 0.515867; batch adversarial loss: 0.509540\n",
      "epoch 12; iter: 0; batch classifier loss: 0.368724; batch adversarial loss: 0.551732\n",
      "epoch 13; iter: 0; batch classifier loss: 0.329926; batch adversarial loss: 0.457746\n",
      "epoch 14; iter: 0; batch classifier loss: 0.299080; batch adversarial loss: 0.485816\n",
      "epoch 15; iter: 0; batch classifier loss: 0.298486; batch adversarial loss: 0.472541\n",
      "epoch 16; iter: 0; batch classifier loss: 0.228600; batch adversarial loss: 0.474631\n",
      "epoch 17; iter: 0; batch classifier loss: 0.195068; batch adversarial loss: 0.489584\n",
      "epoch 18; iter: 0; batch classifier loss: 0.257961; batch adversarial loss: 0.484099\n",
      "epoch 19; iter: 0; batch classifier loss: 0.214936; batch adversarial loss: 0.369509\n",
      "epoch 20; iter: 0; batch classifier loss: 0.181520; batch adversarial loss: 0.530409\n",
      "epoch 21; iter: 0; batch classifier loss: 0.165715; batch adversarial loss: 0.476039\n",
      "epoch 22; iter: 0; batch classifier loss: 0.222059; batch adversarial loss: 0.485613\n",
      "epoch 23; iter: 0; batch classifier loss: 0.180992; batch adversarial loss: 0.462299\n",
      "epoch 24; iter: 0; batch classifier loss: 0.181787; batch adversarial loss: 0.523827\n",
      "epoch 25; iter: 0; batch classifier loss: 0.182101; batch adversarial loss: 0.437166\n",
      "epoch 26; iter: 0; batch classifier loss: 0.131939; batch adversarial loss: 0.466034\n",
      "epoch 27; iter: 0; batch classifier loss: 0.128375; batch adversarial loss: 0.456073\n",
      "epoch 28; iter: 0; batch classifier loss: 0.138498; batch adversarial loss: 0.372145\n",
      "epoch 29; iter: 0; batch classifier loss: 0.082682; batch adversarial loss: 0.423199\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138639; batch adversarial loss: 0.437215\n",
      "epoch 31; iter: 0; batch classifier loss: 0.154063; batch adversarial loss: 0.494662\n",
      "epoch 32; iter: 0; batch classifier loss: 0.177932; batch adversarial loss: 0.475823\n",
      "epoch 33; iter: 0; batch classifier loss: 0.138214; batch adversarial loss: 0.340029\n",
      "epoch 34; iter: 0; batch classifier loss: 0.088962; batch adversarial loss: 0.410211\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137548; batch adversarial loss: 0.407591\n",
      "epoch 36; iter: 0; batch classifier loss: 0.127592; batch adversarial loss: 0.462265\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111222; batch adversarial loss: 0.416767\n",
      "epoch 38; iter: 0; batch classifier loss: 0.113966; batch adversarial loss: 0.440931\n",
      "epoch 39; iter: 0; batch classifier loss: 0.147238; batch adversarial loss: 0.409304\n",
      "epoch 40; iter: 0; batch classifier loss: 0.084566; batch adversarial loss: 0.602221\n",
      "epoch 41; iter: 0; batch classifier loss: 0.069527; batch adversarial loss: 0.466114\n",
      "epoch 42; iter: 0; batch classifier loss: 0.079394; batch adversarial loss: 0.427426\n",
      "epoch 43; iter: 0; batch classifier loss: 0.096583; batch adversarial loss: 0.432915\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136008; batch adversarial loss: 0.416653\n",
      "epoch 45; iter: 0; batch classifier loss: 0.070220; batch adversarial loss: 0.455446\n",
      "epoch 46; iter: 0; batch classifier loss: 0.079018; batch adversarial loss: 0.493965\n",
      "epoch 47; iter: 0; batch classifier loss: 0.120086; batch adversarial loss: 0.522440\n",
      "epoch 48; iter: 0; batch classifier loss: 0.102604; batch adversarial loss: 0.406117\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074230; batch adversarial loss: 0.381420\n",
      "epoch 50; iter: 0; batch classifier loss: 0.101656; batch adversarial loss: 0.528908\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083850; batch adversarial loss: 0.406307\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089876; batch adversarial loss: 0.496549\n",
      "epoch 53; iter: 0; batch classifier loss: 0.085053; batch adversarial loss: 0.438062\n",
      "epoch 54; iter: 0; batch classifier loss: 0.125816; batch adversarial loss: 0.380953\n",
      "epoch 55; iter: 0; batch classifier loss: 0.111177; batch adversarial loss: 0.448555\n",
      "epoch 56; iter: 0; batch classifier loss: 0.116501; batch adversarial loss: 0.433881\n",
      "epoch 57; iter: 0; batch classifier loss: 0.069365; batch adversarial loss: 0.417767\n",
      "epoch 58; iter: 0; batch classifier loss: 0.099288; batch adversarial loss: 0.404673\n",
      "epoch 59; iter: 0; batch classifier loss: 0.092359; batch adversarial loss: 0.452091\n",
      "epoch 60; iter: 0; batch classifier loss: 0.054415; batch adversarial loss: 0.426022\n",
      "epoch 61; iter: 0; batch classifier loss: 0.098181; batch adversarial loss: 0.434916\n",
      "epoch 62; iter: 0; batch classifier loss: 0.067286; batch adversarial loss: 0.505012\n",
      "epoch 63; iter: 0; batch classifier loss: 0.068708; batch adversarial loss: 0.457511\n",
      "epoch 64; iter: 0; batch classifier loss: 0.066824; batch adversarial loss: 0.448521\n",
      "epoch 65; iter: 0; batch classifier loss: 0.111551; batch adversarial loss: 0.456014\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092918; batch adversarial loss: 0.429018\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061590; batch adversarial loss: 0.491500\n",
      "epoch 68; iter: 0; batch classifier loss: 0.091825; batch adversarial loss: 0.415419\n",
      "epoch 69; iter: 0; batch classifier loss: 0.077586; batch adversarial loss: 0.456595\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066680; batch adversarial loss: 0.544170\n",
      "epoch 71; iter: 0; batch classifier loss: 0.082468; batch adversarial loss: 0.374688\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082530; batch adversarial loss: 0.481598\n",
      "epoch 73; iter: 0; batch classifier loss: 0.028776; batch adversarial loss: 0.463068\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053035; batch adversarial loss: 0.412194\n",
      "epoch 75; iter: 0; batch classifier loss: 0.066223; batch adversarial loss: 0.455062\n",
      "epoch 76; iter: 0; batch classifier loss: 0.046952; batch adversarial loss: 0.414683\n",
      "epoch 77; iter: 0; batch classifier loss: 0.079454; batch adversarial loss: 0.464136\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075300; batch adversarial loss: 0.342106\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074223; batch adversarial loss: 0.485318\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060252; batch adversarial loss: 0.514724\n",
      "epoch 81; iter: 0; batch classifier loss: 0.091807; batch adversarial loss: 0.424831\n",
      "epoch 82; iter: 0; batch classifier loss: 0.080893; batch adversarial loss: 0.366879\n",
      "epoch 83; iter: 0; batch classifier loss: 0.047696; batch adversarial loss: 0.451068\n",
      "epoch 84; iter: 0; batch classifier loss: 0.081825; batch adversarial loss: 0.414849\n",
      "epoch 85; iter: 0; batch classifier loss: 0.045192; batch adversarial loss: 0.499680\n",
      "epoch 86; iter: 0; batch classifier loss: 0.044384; batch adversarial loss: 0.432525\n",
      "epoch 87; iter: 0; batch classifier loss: 0.075670; batch adversarial loss: 0.497480\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063914; batch adversarial loss: 0.343193\n",
      "epoch 89; iter: 0; batch classifier loss: 0.055990; batch adversarial loss: 0.399171\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067030; batch adversarial loss: 0.509414\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067769; batch adversarial loss: 0.453175\n",
      "epoch 92; iter: 0; batch classifier loss: 0.059117; batch adversarial loss: 0.455519\n",
      "epoch 93; iter: 0; batch classifier loss: 0.057332; batch adversarial loss: 0.538521\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044095; batch adversarial loss: 0.313379\n",
      "epoch 95; iter: 0; batch classifier loss: 0.069186; batch adversarial loss: 0.497954\n",
      "epoch 96; iter: 0; batch classifier loss: 0.081671; batch adversarial loss: 0.348548\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066924; batch adversarial loss: 0.403398\n",
      "epoch 98; iter: 0; batch classifier loss: 0.070392; batch adversarial loss: 0.450065\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059468; batch adversarial loss: 0.433969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.078332; batch adversarial loss: 0.472532\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071257; batch adversarial loss: 0.451172\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036389; batch adversarial loss: 0.470339\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062660; batch adversarial loss: 0.497764\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056912; batch adversarial loss: 0.427226\n",
      "epoch 105; iter: 0; batch classifier loss: 0.026625; batch adversarial loss: 0.417277\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067681; batch adversarial loss: 0.477545\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056004; batch adversarial loss: 0.420740\n",
      "epoch 108; iter: 0; batch classifier loss: 0.023911; batch adversarial loss: 0.423281\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053075; batch adversarial loss: 0.502058\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059290; batch adversarial loss: 0.479857\n",
      "epoch 111; iter: 0; batch classifier loss: 0.109992; batch adversarial loss: 0.441398\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059665; batch adversarial loss: 0.423269\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040674; batch adversarial loss: 0.513354\n",
      "epoch 114; iter: 0; batch classifier loss: 0.031869; batch adversarial loss: 0.499233\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031953; batch adversarial loss: 0.450187\n",
      "epoch 116; iter: 0; batch classifier loss: 0.061564; batch adversarial loss: 0.413991\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051899; batch adversarial loss: 0.488950\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025697; batch adversarial loss: 0.442226\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053537; batch adversarial loss: 0.444901\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034772; batch adversarial loss: 0.549894\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027652; batch adversarial loss: 0.446601\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046106; batch adversarial loss: 0.559341\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027258; batch adversarial loss: 0.441574\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054467; batch adversarial loss: 0.406680\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049798; batch adversarial loss: 0.533078\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043067; batch adversarial loss: 0.412285\n",
      "epoch 127; iter: 0; batch classifier loss: 0.055610; batch adversarial loss: 0.416197\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035569; batch adversarial loss: 0.492470\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025497; batch adversarial loss: 0.475552\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047651; batch adversarial loss: 0.338027\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024486; batch adversarial loss: 0.458296\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019363; batch adversarial loss: 0.402309\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030000; batch adversarial loss: 0.424420\n",
      "epoch 134; iter: 0; batch classifier loss: 0.014431; batch adversarial loss: 0.495738\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020676; batch adversarial loss: 0.424851\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041939; batch adversarial loss: 0.368700\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026466; batch adversarial loss: 0.436285\n",
      "epoch 138; iter: 0; batch classifier loss: 0.051567; batch adversarial loss: 0.476684\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033135; batch adversarial loss: 0.478690\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053802; batch adversarial loss: 0.405894\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025268; batch adversarial loss: 0.390749\n",
      "epoch 142; iter: 0; batch classifier loss: 0.062846; batch adversarial loss: 0.375210\n",
      "epoch 143; iter: 0; batch classifier loss: 0.045043; batch adversarial loss: 0.433451\n",
      "epoch 144; iter: 0; batch classifier loss: 0.060447; batch adversarial loss: 0.414156\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046768; batch adversarial loss: 0.394787\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016902; batch adversarial loss: 0.404668\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022963; batch adversarial loss: 0.386738\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027947; batch adversarial loss: 0.425081\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044502; batch adversarial loss: 0.392374\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019168; batch adversarial loss: 0.530963\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043420; batch adversarial loss: 0.465607\n",
      "epoch 152; iter: 0; batch classifier loss: 0.047228; batch adversarial loss: 0.472793\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036065; batch adversarial loss: 0.478045\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035414; batch adversarial loss: 0.363672\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049256; batch adversarial loss: 0.441494\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040917; batch adversarial loss: 0.408480\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030809; batch adversarial loss: 0.440763\n",
      "epoch 158; iter: 0; batch classifier loss: 0.067706; batch adversarial loss: 0.582095\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029166; batch adversarial loss: 0.484163\n",
      "epoch 160; iter: 0; batch classifier loss: 0.006784; batch adversarial loss: 0.430539\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020092; batch adversarial loss: 0.510103\n",
      "epoch 162; iter: 0; batch classifier loss: 0.049115; batch adversarial loss: 0.410251\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024414; batch adversarial loss: 0.413520\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038047; batch adversarial loss: 0.415647\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033655; batch adversarial loss: 0.377989\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023936; batch adversarial loss: 0.506656\n",
      "epoch 167; iter: 0; batch classifier loss: 0.044895; batch adversarial loss: 0.394746\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045985; batch adversarial loss: 0.425108\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009638; batch adversarial loss: 0.512549\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027221; batch adversarial loss: 0.442141\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025667; batch adversarial loss: 0.508641\n",
      "epoch 172; iter: 0; batch classifier loss: 0.067471; batch adversarial loss: 0.452457\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025642; batch adversarial loss: 0.424502\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029499; batch adversarial loss: 0.477959\n",
      "epoch 175; iter: 0; batch classifier loss: 0.057334; batch adversarial loss: 0.467062\n",
      "epoch 176; iter: 0; batch classifier loss: 0.047850; batch adversarial loss: 0.377270\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015073; batch adversarial loss: 0.424236\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015236; batch adversarial loss: 0.416789\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034064; batch adversarial loss: 0.351512\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015335; batch adversarial loss: 0.361674\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014960; batch adversarial loss: 0.375541\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028240; batch adversarial loss: 0.378725\n",
      "epoch 183; iter: 0; batch classifier loss: 0.047026; batch adversarial loss: 0.475225\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025822; batch adversarial loss: 0.518728\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015481; batch adversarial loss: 0.517594\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011727; batch adversarial loss: 0.439231\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015655; batch adversarial loss: 0.545284\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040931; batch adversarial loss: 0.481010\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031442; batch adversarial loss: 0.512483\n",
      "epoch 190; iter: 0; batch classifier loss: 0.047211; batch adversarial loss: 0.381392\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018660; batch adversarial loss: 0.416384\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018291; batch adversarial loss: 0.500350\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032048; batch adversarial loss: 0.377956\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035698; batch adversarial loss: 0.458720\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015068; batch adversarial loss: 0.469450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.026905; batch adversarial loss: 0.528444\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034952; batch adversarial loss: 0.455548\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014126; batch adversarial loss: 0.583104\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013154; batch adversarial loss: 0.358719\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700433; batch adversarial loss: 0.791791\n",
      "epoch 1; iter: 0; batch classifier loss: 0.446281; batch adversarial loss: 0.748778\n",
      "epoch 2; iter: 0; batch classifier loss: 0.406502; batch adversarial loss: 0.710454\n",
      "epoch 3; iter: 0; batch classifier loss: 0.376559; batch adversarial loss: 0.667564\n",
      "epoch 4; iter: 0; batch classifier loss: 0.406311; batch adversarial loss: 0.647615\n",
      "epoch 5; iter: 0; batch classifier loss: 0.375107; batch adversarial loss: 0.622303\n",
      "epoch 6; iter: 0; batch classifier loss: 0.252145; batch adversarial loss: 0.582544\n",
      "epoch 7; iter: 0; batch classifier loss: 0.235172; batch adversarial loss: 0.563913\n",
      "epoch 8; iter: 0; batch classifier loss: 0.322415; batch adversarial loss: 0.528004\n",
      "epoch 9; iter: 0; batch classifier loss: 0.349971; batch adversarial loss: 0.510159\n",
      "epoch 10; iter: 0; batch classifier loss: 0.300828; batch adversarial loss: 0.487135\n",
      "epoch 11; iter: 0; batch classifier loss: 0.248580; batch adversarial loss: 0.472243\n",
      "epoch 12; iter: 0; batch classifier loss: 0.232673; batch adversarial loss: 0.476698\n",
      "epoch 13; iter: 0; batch classifier loss: 0.228905; batch adversarial loss: 0.432309\n",
      "epoch 14; iter: 0; batch classifier loss: 0.223569; batch adversarial loss: 0.421965\n",
      "epoch 15; iter: 0; batch classifier loss: 0.226432; batch adversarial loss: 0.436133\n",
      "epoch 16; iter: 0; batch classifier loss: 0.211466; batch adversarial loss: 0.444906\n",
      "epoch 17; iter: 0; batch classifier loss: 0.211613; batch adversarial loss: 0.438907\n",
      "epoch 18; iter: 0; batch classifier loss: 0.225186; batch adversarial loss: 0.461257\n",
      "epoch 19; iter: 0; batch classifier loss: 0.180805; batch adversarial loss: 0.402664\n",
      "epoch 20; iter: 0; batch classifier loss: 0.233667; batch adversarial loss: 0.384500\n",
      "epoch 21; iter: 0; batch classifier loss: 0.182188; batch adversarial loss: 0.441809\n",
      "epoch 22; iter: 0; batch classifier loss: 0.230591; batch adversarial loss: 0.492505\n",
      "epoch 23; iter: 0; batch classifier loss: 0.190249; batch adversarial loss: 0.439700\n",
      "epoch 24; iter: 0; batch classifier loss: 0.220757; batch adversarial loss: 0.407706\n",
      "epoch 25; iter: 0; batch classifier loss: 0.182593; batch adversarial loss: 0.451064\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187785; batch adversarial loss: 0.466239\n",
      "epoch 27; iter: 0; batch classifier loss: 0.121897; batch adversarial loss: 0.467772\n",
      "epoch 28; iter: 0; batch classifier loss: 0.205242; batch adversarial loss: 0.399083\n",
      "epoch 29; iter: 0; batch classifier loss: 0.135634; batch adversarial loss: 0.345077\n",
      "epoch 30; iter: 0; batch classifier loss: 0.130376; batch adversarial loss: 0.340650\n",
      "epoch 31; iter: 0; batch classifier loss: 0.101944; batch adversarial loss: 0.429504\n",
      "epoch 32; iter: 0; batch classifier loss: 0.121739; batch adversarial loss: 0.317863\n",
      "epoch 33; iter: 0; batch classifier loss: 0.158937; batch adversarial loss: 0.349646\n",
      "epoch 34; iter: 0; batch classifier loss: 0.111465; batch adversarial loss: 0.467904\n",
      "epoch 35; iter: 0; batch classifier loss: 0.121962; batch adversarial loss: 0.343980\n",
      "epoch 36; iter: 0; batch classifier loss: 0.117253; batch adversarial loss: 0.372765\n",
      "epoch 37; iter: 0; batch classifier loss: 0.131639; batch adversarial loss: 0.404093\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148406; batch adversarial loss: 0.460162\n",
      "epoch 39; iter: 0; batch classifier loss: 0.140341; batch adversarial loss: 0.424315\n",
      "epoch 40; iter: 0; batch classifier loss: 0.107500; batch adversarial loss: 0.442623\n",
      "epoch 41; iter: 0; batch classifier loss: 0.102624; batch adversarial loss: 0.367525\n",
      "epoch 42; iter: 0; batch classifier loss: 0.112714; batch adversarial loss: 0.428853\n",
      "epoch 43; iter: 0; batch classifier loss: 0.120306; batch adversarial loss: 0.375410\n",
      "epoch 44; iter: 0; batch classifier loss: 0.113969; batch adversarial loss: 0.406535\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099198; batch adversarial loss: 0.425531\n",
      "epoch 46; iter: 0; batch classifier loss: 0.111839; batch adversarial loss: 0.385297\n",
      "epoch 47; iter: 0; batch classifier loss: 0.189261; batch adversarial loss: 0.339006\n",
      "epoch 48; iter: 0; batch classifier loss: 0.076324; batch adversarial loss: 0.370968\n",
      "epoch 49; iter: 0; batch classifier loss: 0.162399; batch adversarial loss: 0.481398\n",
      "epoch 50; iter: 0; batch classifier loss: 0.101750; batch adversarial loss: 0.472751\n",
      "epoch 51; iter: 0; batch classifier loss: 0.072238; batch adversarial loss: 0.422847\n",
      "epoch 52; iter: 0; batch classifier loss: 0.117001; batch adversarial loss: 0.451146\n",
      "epoch 53; iter: 0; batch classifier loss: 0.080477; batch adversarial loss: 0.499207\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108394; batch adversarial loss: 0.401737\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084042; batch adversarial loss: 0.404389\n",
      "epoch 56; iter: 0; batch classifier loss: 0.092823; batch adversarial loss: 0.506814\n",
      "epoch 57; iter: 0; batch classifier loss: 0.059744; batch adversarial loss: 0.424439\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080749; batch adversarial loss: 0.461651\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102684; batch adversarial loss: 0.422828\n",
      "epoch 60; iter: 0; batch classifier loss: 0.060038; batch adversarial loss: 0.367931\n",
      "epoch 61; iter: 0; batch classifier loss: 0.121322; batch adversarial loss: 0.355049\n",
      "epoch 62; iter: 0; batch classifier loss: 0.073234; batch adversarial loss: 0.439020\n",
      "epoch 63; iter: 0; batch classifier loss: 0.060071; batch adversarial loss: 0.457093\n",
      "epoch 64; iter: 0; batch classifier loss: 0.086637; batch adversarial loss: 0.409522\n",
      "epoch 65; iter: 0; batch classifier loss: 0.076534; batch adversarial loss: 0.387487\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092480; batch adversarial loss: 0.437483\n",
      "epoch 67; iter: 0; batch classifier loss: 0.043725; batch adversarial loss: 0.447607\n",
      "epoch 68; iter: 0; batch classifier loss: 0.057299; batch adversarial loss: 0.359143\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075755; batch adversarial loss: 0.433828\n",
      "epoch 70; iter: 0; batch classifier loss: 0.053389; batch adversarial loss: 0.312622\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115910; batch adversarial loss: 0.551094\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074904; batch adversarial loss: 0.436291\n",
      "epoch 73; iter: 0; batch classifier loss: 0.050389; batch adversarial loss: 0.441444\n",
      "epoch 74; iter: 0; batch classifier loss: 0.046461; batch adversarial loss: 0.436332\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075227; batch adversarial loss: 0.407013\n",
      "epoch 76; iter: 0; batch classifier loss: 0.101237; batch adversarial loss: 0.392980\n",
      "epoch 77; iter: 0; batch classifier loss: 0.078215; batch adversarial loss: 0.397777\n",
      "epoch 78; iter: 0; batch classifier loss: 0.045889; batch adversarial loss: 0.349474\n",
      "epoch 79; iter: 0; batch classifier loss: 0.058290; batch adversarial loss: 0.364245\n",
      "epoch 80; iter: 0; batch classifier loss: 0.077113; batch adversarial loss: 0.379443\n",
      "epoch 81; iter: 0; batch classifier loss: 0.046988; batch adversarial loss: 0.417042\n",
      "epoch 82; iter: 0; batch classifier loss: 0.068020; batch adversarial loss: 0.491499\n",
      "epoch 83; iter: 0; batch classifier loss: 0.055509; batch adversarial loss: 0.360205\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052425; batch adversarial loss: 0.403732\n",
      "epoch 85; iter: 0; batch classifier loss: 0.058681; batch adversarial loss: 0.436659\n",
      "epoch 86; iter: 0; batch classifier loss: 0.056090; batch adversarial loss: 0.450044\n",
      "epoch 87; iter: 0; batch classifier loss: 0.058162; batch adversarial loss: 0.369818\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078147; batch adversarial loss: 0.461663\n",
      "epoch 89; iter: 0; batch classifier loss: 0.041525; batch adversarial loss: 0.450341\n",
      "epoch 90; iter: 0; batch classifier loss: 0.086603; batch adversarial loss: 0.521401\n",
      "epoch 91; iter: 0; batch classifier loss: 0.080212; batch adversarial loss: 0.479478\n",
      "epoch 92; iter: 0; batch classifier loss: 0.032488; batch adversarial loss: 0.412156\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069063; batch adversarial loss: 0.405056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.069518; batch adversarial loss: 0.379026\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048878; batch adversarial loss: 0.489073\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041553; batch adversarial loss: 0.432125\n",
      "epoch 97; iter: 0; batch classifier loss: 0.036182; batch adversarial loss: 0.372352\n",
      "epoch 98; iter: 0; batch classifier loss: 0.057148; batch adversarial loss: 0.429986\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039514; batch adversarial loss: 0.493508\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061648; batch adversarial loss: 0.399663\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070694; batch adversarial loss: 0.392857\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046060; batch adversarial loss: 0.323936\n",
      "epoch 103; iter: 0; batch classifier loss: 0.073029; batch adversarial loss: 0.444492\n",
      "epoch 104; iter: 0; batch classifier loss: 0.090722; batch adversarial loss: 0.458893\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058217; batch adversarial loss: 0.366045\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044300; batch adversarial loss: 0.528862\n",
      "epoch 107; iter: 0; batch classifier loss: 0.095429; batch adversarial loss: 0.457964\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049558; batch adversarial loss: 0.473281\n",
      "epoch 109; iter: 0; batch classifier loss: 0.076726; batch adversarial loss: 0.457700\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058675; batch adversarial loss: 0.479729\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051885; batch adversarial loss: 0.440653\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059501; batch adversarial loss: 0.437002\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041473; batch adversarial loss: 0.382706\n",
      "epoch 114; iter: 0; batch classifier loss: 0.072462; batch adversarial loss: 0.401189\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045180; batch adversarial loss: 0.422509\n",
      "epoch 116; iter: 0; batch classifier loss: 0.070012; batch adversarial loss: 0.541415\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051761; batch adversarial loss: 0.374977\n",
      "epoch 118; iter: 0; batch classifier loss: 0.061216; batch adversarial loss: 0.413465\n",
      "epoch 119; iter: 0; batch classifier loss: 0.061156; batch adversarial loss: 0.413955\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048675; batch adversarial loss: 0.397418\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040988; batch adversarial loss: 0.433707\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037288; batch adversarial loss: 0.405207\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055915; batch adversarial loss: 0.464564\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054715; batch adversarial loss: 0.368869\n",
      "epoch 125; iter: 0; batch classifier loss: 0.069187; batch adversarial loss: 0.309063\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048320; batch adversarial loss: 0.437880\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030267; batch adversarial loss: 0.413116\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052728; batch adversarial loss: 0.453330\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029132; batch adversarial loss: 0.491721\n",
      "epoch 130; iter: 0; batch classifier loss: 0.049289; batch adversarial loss: 0.444576\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050113; batch adversarial loss: 0.394265\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058737; batch adversarial loss: 0.452004\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030141; batch adversarial loss: 0.508426\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048181; batch adversarial loss: 0.486770\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027377; batch adversarial loss: 0.450438\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031974; batch adversarial loss: 0.433006\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025420; batch adversarial loss: 0.405924\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056830; batch adversarial loss: 0.489069\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043490; batch adversarial loss: 0.470028\n",
      "epoch 140; iter: 0; batch classifier loss: 0.010423; batch adversarial loss: 0.454251\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028339; batch adversarial loss: 0.472262\n",
      "epoch 142; iter: 0; batch classifier loss: 0.068872; batch adversarial loss: 0.411767\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018845; batch adversarial loss: 0.374205\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016805; batch adversarial loss: 0.364125\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038472; batch adversarial loss: 0.493672\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023659; batch adversarial loss: 0.418145\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022206; batch adversarial loss: 0.481666\n",
      "epoch 148; iter: 0; batch classifier loss: 0.052618; batch adversarial loss: 0.450655\n",
      "epoch 149; iter: 0; batch classifier loss: 0.054165; batch adversarial loss: 0.513067\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022402; batch adversarial loss: 0.490470\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035080; batch adversarial loss: 0.421196\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042296; batch adversarial loss: 0.424250\n",
      "epoch 153; iter: 0; batch classifier loss: 0.043141; batch adversarial loss: 0.516877\n",
      "epoch 154; iter: 0; batch classifier loss: 0.066208; batch adversarial loss: 0.595139\n",
      "epoch 155; iter: 0; batch classifier loss: 0.070509; batch adversarial loss: 0.468252\n",
      "epoch 156; iter: 0; batch classifier loss: 0.085229; batch adversarial loss: 0.531277\n",
      "epoch 157; iter: 0; batch classifier loss: 0.069088; batch adversarial loss: 0.592589\n",
      "epoch 158; iter: 0; batch classifier loss: 0.070920; batch adversarial loss: 0.510807\n",
      "epoch 159; iter: 0; batch classifier loss: 0.111609; batch adversarial loss: 0.620098\n",
      "epoch 160; iter: 0; batch classifier loss: 0.075224; batch adversarial loss: 0.658685\n",
      "epoch 161; iter: 0; batch classifier loss: 0.114143; batch adversarial loss: 0.631638\n",
      "epoch 162; iter: 0; batch classifier loss: 0.253094; batch adversarial loss: 0.799755\n",
      "epoch 163; iter: 0; batch classifier loss: 0.109422; batch adversarial loss: 0.579625\n",
      "epoch 164; iter: 0; batch classifier loss: 0.163428; batch adversarial loss: 0.734878\n",
      "epoch 165; iter: 0; batch classifier loss: 0.164470; batch adversarial loss: 0.595715\n",
      "epoch 166; iter: 0; batch classifier loss: 0.217169; batch adversarial loss: 0.754918\n",
      "epoch 167; iter: 0; batch classifier loss: 0.194962; batch adversarial loss: 0.630647\n",
      "epoch 168; iter: 0; batch classifier loss: 0.146471; batch adversarial loss: 0.571458\n",
      "epoch 169; iter: 0; batch classifier loss: 0.254010; batch adversarial loss: 0.849276\n",
      "epoch 170; iter: 0; batch classifier loss: 0.209659; batch adversarial loss: 0.727220\n",
      "epoch 171; iter: 0; batch classifier loss: 0.188843; batch adversarial loss: 0.664517\n",
      "epoch 172; iter: 0; batch classifier loss: 0.117518; batch adversarial loss: 0.499555\n",
      "epoch 173; iter: 0; batch classifier loss: 0.180735; batch adversarial loss: 0.573015\n",
      "epoch 174; iter: 0; batch classifier loss: 0.154094; batch adversarial loss: 0.546281\n",
      "epoch 175; iter: 0; batch classifier loss: 0.070162; batch adversarial loss: 0.509235\n",
      "epoch 176; iter: 0; batch classifier loss: 0.154209; batch adversarial loss: 0.683803\n",
      "epoch 177; iter: 0; batch classifier loss: 0.139072; batch adversarial loss: 0.612154\n",
      "epoch 178; iter: 0; batch classifier loss: 0.127952; batch adversarial loss: 0.563885\n",
      "epoch 179; iter: 0; batch classifier loss: 0.177452; batch adversarial loss: 0.652082\n",
      "epoch 180; iter: 0; batch classifier loss: 0.138624; batch adversarial loss: 0.492005\n",
      "epoch 181; iter: 0; batch classifier loss: 0.144229; batch adversarial loss: 0.495252\n",
      "epoch 182; iter: 0; batch classifier loss: 0.146262; batch adversarial loss: 0.531960\n",
      "epoch 183; iter: 0; batch classifier loss: 0.103018; batch adversarial loss: 0.498776\n",
      "epoch 184; iter: 0; batch classifier loss: 0.110254; batch adversarial loss: 0.550772\n",
      "epoch 185; iter: 0; batch classifier loss: 0.109655; batch adversarial loss: 0.476006\n",
      "epoch 186; iter: 0; batch classifier loss: 0.145626; batch adversarial loss: 0.475795\n",
      "epoch 187; iter: 0; batch classifier loss: 0.142103; batch adversarial loss: 0.563339\n",
      "epoch 188; iter: 0; batch classifier loss: 0.179751; batch adversarial loss: 0.640120\n",
      "epoch 189; iter: 0; batch classifier loss: 0.108295; batch adversarial loss: 0.489012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.062028; batch adversarial loss: 0.442154\n",
      "epoch 191; iter: 0; batch classifier loss: 0.138247; batch adversarial loss: 0.560915\n",
      "epoch 192; iter: 0; batch classifier loss: 0.136718; batch adversarial loss: 0.546369\n",
      "epoch 193; iter: 0; batch classifier loss: 0.097289; batch adversarial loss: 0.374168\n",
      "epoch 194; iter: 0; batch classifier loss: 0.099733; batch adversarial loss: 0.489357\n",
      "epoch 195; iter: 0; batch classifier loss: 0.119089; batch adversarial loss: 0.491072\n",
      "epoch 196; iter: 0; batch classifier loss: 0.126759; batch adversarial loss: 0.435028\n",
      "epoch 197; iter: 0; batch classifier loss: 0.164948; batch adversarial loss: 0.576273\n",
      "epoch 198; iter: 0; batch classifier loss: 0.093025; batch adversarial loss: 0.412354\n",
      "epoch 199; iter: 0; batch classifier loss: 0.086503; batch adversarial loss: 0.407248\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697418; batch adversarial loss: 0.736797\n",
      "epoch 1; iter: 0; batch classifier loss: 0.480714; batch adversarial loss: 0.685821\n",
      "epoch 2; iter: 0; batch classifier loss: 0.400961; batch adversarial loss: 0.626290\n",
      "epoch 3; iter: 0; batch classifier loss: 0.439959; batch adversarial loss: 0.612470\n",
      "epoch 4; iter: 0; batch classifier loss: 0.372659; batch adversarial loss: 0.585564\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387302; batch adversarial loss: 0.565402\n",
      "epoch 6; iter: 0; batch classifier loss: 0.325440; batch adversarial loss: 0.568562\n",
      "epoch 7; iter: 0; batch classifier loss: 0.285963; batch adversarial loss: 0.529841\n",
      "epoch 8; iter: 0; batch classifier loss: 0.297997; batch adversarial loss: 0.487613\n",
      "epoch 9; iter: 0; batch classifier loss: 0.237148; batch adversarial loss: 0.555095\n",
      "epoch 10; iter: 0; batch classifier loss: 0.303478; batch adversarial loss: 0.584239\n",
      "epoch 11; iter: 0; batch classifier loss: 0.306692; batch adversarial loss: 0.532198\n",
      "epoch 12; iter: 0; batch classifier loss: 0.363114; batch adversarial loss: 0.472098\n",
      "epoch 13; iter: 0; batch classifier loss: 0.264753; batch adversarial loss: 0.488163\n",
      "epoch 14; iter: 0; batch classifier loss: 0.405055; batch adversarial loss: 0.474075\n",
      "epoch 15; iter: 0; batch classifier loss: 0.261415; batch adversarial loss: 0.479478\n",
      "epoch 16; iter: 0; batch classifier loss: 0.293323; batch adversarial loss: 0.490019\n",
      "epoch 17; iter: 0; batch classifier loss: 0.258408; batch adversarial loss: 0.479508\n",
      "epoch 18; iter: 0; batch classifier loss: 0.317333; batch adversarial loss: 0.487091\n",
      "epoch 19; iter: 0; batch classifier loss: 0.281338; batch adversarial loss: 0.449896\n",
      "epoch 20; iter: 0; batch classifier loss: 0.237083; batch adversarial loss: 0.561485\n",
      "epoch 21; iter: 0; batch classifier loss: 0.287661; batch adversarial loss: 0.405471\n",
      "epoch 22; iter: 0; batch classifier loss: 0.254007; batch adversarial loss: 0.482024\n",
      "epoch 23; iter: 0; batch classifier loss: 0.243144; batch adversarial loss: 0.446672\n",
      "epoch 24; iter: 0; batch classifier loss: 0.186342; batch adversarial loss: 0.480196\n",
      "epoch 25; iter: 0; batch classifier loss: 0.240715; batch adversarial loss: 0.475018\n",
      "epoch 26; iter: 0; batch classifier loss: 0.262224; batch adversarial loss: 0.407031\n",
      "epoch 27; iter: 0; batch classifier loss: 0.234508; batch adversarial loss: 0.433961\n",
      "epoch 28; iter: 0; batch classifier loss: 0.209904; batch adversarial loss: 0.468879\n",
      "epoch 29; iter: 0; batch classifier loss: 0.166768; batch adversarial loss: 0.446171\n",
      "epoch 30; iter: 0; batch classifier loss: 0.213890; batch adversarial loss: 0.406217\n",
      "epoch 31; iter: 0; batch classifier loss: 0.179272; batch adversarial loss: 0.434908\n",
      "epoch 32; iter: 0; batch classifier loss: 0.164347; batch adversarial loss: 0.424465\n",
      "epoch 33; iter: 0; batch classifier loss: 0.152043; batch adversarial loss: 0.505668\n",
      "epoch 34; iter: 0; batch classifier loss: 0.117617; batch adversarial loss: 0.593228\n",
      "epoch 35; iter: 0; batch classifier loss: 0.194660; batch adversarial loss: 0.422993\n",
      "epoch 36; iter: 0; batch classifier loss: 0.186042; batch adversarial loss: 0.477670\n",
      "epoch 37; iter: 0; batch classifier loss: 0.218050; batch adversarial loss: 0.484943\n",
      "epoch 38; iter: 0; batch classifier loss: 0.203260; batch adversarial loss: 0.470767\n",
      "epoch 39; iter: 0; batch classifier loss: 0.149222; batch adversarial loss: 0.498736\n",
      "epoch 40; iter: 0; batch classifier loss: 0.177922; batch adversarial loss: 0.514577\n",
      "epoch 41; iter: 0; batch classifier loss: 0.113368; batch adversarial loss: 0.569308\n",
      "epoch 42; iter: 0; batch classifier loss: 0.175733; batch adversarial loss: 0.462504\n",
      "epoch 43; iter: 0; batch classifier loss: 0.174551; batch adversarial loss: 0.432941\n",
      "epoch 44; iter: 0; batch classifier loss: 0.104025; batch adversarial loss: 0.452098\n",
      "epoch 45; iter: 0; batch classifier loss: 0.170020; batch adversarial loss: 0.406907\n",
      "epoch 46; iter: 0; batch classifier loss: 0.146547; batch adversarial loss: 0.519296\n",
      "epoch 47; iter: 0; batch classifier loss: 0.168199; batch adversarial loss: 0.513074\n",
      "epoch 48; iter: 0; batch classifier loss: 0.190068; batch adversarial loss: 0.404707\n",
      "epoch 49; iter: 0; batch classifier loss: 0.214080; batch adversarial loss: 0.494904\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098747; batch adversarial loss: 0.407859\n",
      "epoch 51; iter: 0; batch classifier loss: 0.145319; batch adversarial loss: 0.453736\n",
      "epoch 52; iter: 0; batch classifier loss: 0.188411; batch adversarial loss: 0.398631\n",
      "epoch 53; iter: 0; batch classifier loss: 0.147945; batch adversarial loss: 0.470497\n",
      "epoch 54; iter: 0; batch classifier loss: 0.123230; batch adversarial loss: 0.373101\n",
      "epoch 55; iter: 0; batch classifier loss: 0.167237; batch adversarial loss: 0.361999\n",
      "epoch 56; iter: 0; batch classifier loss: 0.145093; batch adversarial loss: 0.496763\n",
      "epoch 57; iter: 0; batch classifier loss: 0.088001; batch adversarial loss: 0.433975\n",
      "epoch 58; iter: 0; batch classifier loss: 0.128894; batch adversarial loss: 0.508573\n",
      "epoch 59; iter: 0; batch classifier loss: 0.110045; batch adversarial loss: 0.431278\n",
      "epoch 60; iter: 0; batch classifier loss: 0.124108; batch adversarial loss: 0.503635\n",
      "epoch 61; iter: 0; batch classifier loss: 0.134107; batch adversarial loss: 0.433924\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101636; batch adversarial loss: 0.501665\n",
      "epoch 63; iter: 0; batch classifier loss: 0.112107; batch adversarial loss: 0.435008\n",
      "epoch 64; iter: 0; batch classifier loss: 0.115023; batch adversarial loss: 0.516586\n",
      "epoch 65; iter: 0; batch classifier loss: 0.187832; batch adversarial loss: 0.392224\n",
      "epoch 66; iter: 0; batch classifier loss: 0.108421; batch adversarial loss: 0.458065\n",
      "epoch 67; iter: 0; batch classifier loss: 0.148100; batch adversarial loss: 0.448606\n",
      "epoch 68; iter: 0; batch classifier loss: 0.093603; batch adversarial loss: 0.433654\n",
      "epoch 69; iter: 0; batch classifier loss: 0.121467; batch adversarial loss: 0.499970\n",
      "epoch 70; iter: 0; batch classifier loss: 0.112845; batch adversarial loss: 0.396101\n",
      "epoch 71; iter: 0; batch classifier loss: 0.121157; batch adversarial loss: 0.534630\n",
      "epoch 72; iter: 0; batch classifier loss: 0.117070; batch adversarial loss: 0.446301\n",
      "epoch 73; iter: 0; batch classifier loss: 0.110234; batch adversarial loss: 0.429348\n",
      "epoch 74; iter: 0; batch classifier loss: 0.123344; batch adversarial loss: 0.480988\n",
      "epoch 75; iter: 0; batch classifier loss: 0.109621; batch adversarial loss: 0.462929\n",
      "epoch 76; iter: 0; batch classifier loss: 0.151329; batch adversarial loss: 0.436058\n",
      "epoch 77; iter: 0; batch classifier loss: 0.092600; batch adversarial loss: 0.511125\n",
      "epoch 78; iter: 0; batch classifier loss: 0.096858; batch adversarial loss: 0.588222\n",
      "epoch 79; iter: 0; batch classifier loss: 0.106094; batch adversarial loss: 0.422253\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075071; batch adversarial loss: 0.415117\n",
      "epoch 81; iter: 0; batch classifier loss: 0.043006; batch adversarial loss: 0.440825\n",
      "epoch 82; iter: 0; batch classifier loss: 0.111316; batch adversarial loss: 0.344162\n",
      "epoch 83; iter: 0; batch classifier loss: 0.112859; batch adversarial loss: 0.422186\n",
      "epoch 84; iter: 0; batch classifier loss: 0.155330; batch adversarial loss: 0.442848\n",
      "epoch 85; iter: 0; batch classifier loss: 0.120186; batch adversarial loss: 0.475242\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089586; batch adversarial loss: 0.513995\n",
      "epoch 87; iter: 0; batch classifier loss: 0.070838; batch adversarial loss: 0.547286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.084734; batch adversarial loss: 0.398799\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053304; batch adversarial loss: 0.501420\n",
      "epoch 90; iter: 0; batch classifier loss: 0.071170; batch adversarial loss: 0.349409\n",
      "epoch 91; iter: 0; batch classifier loss: 0.090978; batch adversarial loss: 0.361433\n",
      "epoch 92; iter: 0; batch classifier loss: 0.085094; batch adversarial loss: 0.468166\n",
      "epoch 93; iter: 0; batch classifier loss: 0.084424; batch adversarial loss: 0.517185\n",
      "epoch 94; iter: 0; batch classifier loss: 0.067780; batch adversarial loss: 0.422487\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064073; batch adversarial loss: 0.537680\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046354; batch adversarial loss: 0.403897\n",
      "epoch 97; iter: 0; batch classifier loss: 0.067049; batch adversarial loss: 0.467171\n",
      "epoch 98; iter: 0; batch classifier loss: 0.075575; batch adversarial loss: 0.471669\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050508; batch adversarial loss: 0.440918\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066589; batch adversarial loss: 0.391442\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071586; batch adversarial loss: 0.361583\n",
      "epoch 102; iter: 0; batch classifier loss: 0.064197; batch adversarial loss: 0.441592\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036106; batch adversarial loss: 0.463851\n",
      "epoch 104; iter: 0; batch classifier loss: 0.072280; batch adversarial loss: 0.449629\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056931; batch adversarial loss: 0.517630\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034680; batch adversarial loss: 0.443715\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049135; batch adversarial loss: 0.477193\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037418; batch adversarial loss: 0.375030\n",
      "epoch 109; iter: 0; batch classifier loss: 0.031312; batch adversarial loss: 0.496718\n",
      "epoch 110; iter: 0; batch classifier loss: 0.056136; batch adversarial loss: 0.382624\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032963; batch adversarial loss: 0.527143\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045018; batch adversarial loss: 0.431427\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047142; batch adversarial loss: 0.423959\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044891; batch adversarial loss: 0.452702\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034915; batch adversarial loss: 0.450199\n",
      "epoch 116; iter: 0; batch classifier loss: 0.093754; batch adversarial loss: 0.423908\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052147; batch adversarial loss: 0.408156\n",
      "epoch 118; iter: 0; batch classifier loss: 0.075664; batch adversarial loss: 0.492119\n",
      "epoch 119; iter: 0; batch classifier loss: 0.075257; batch adversarial loss: 0.418641\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036022; batch adversarial loss: 0.496844\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029870; batch adversarial loss: 0.426973\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052287; batch adversarial loss: 0.394413\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051041; batch adversarial loss: 0.373531\n",
      "epoch 124; iter: 0; batch classifier loss: 0.008797; batch adversarial loss: 0.427307\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027532; batch adversarial loss: 0.507344\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043298; batch adversarial loss: 0.498499\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045155; batch adversarial loss: 0.485681\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028028; batch adversarial loss: 0.501752\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018599; batch adversarial loss: 0.486014\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044612; batch adversarial loss: 0.432089\n",
      "epoch 131; iter: 0; batch classifier loss: 0.014289; batch adversarial loss: 0.360434\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058478; batch adversarial loss: 0.481708\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040661; batch adversarial loss: 0.472691\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026616; batch adversarial loss: 0.500866\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014620; batch adversarial loss: 0.469494\n",
      "epoch 136; iter: 0; batch classifier loss: 0.015495; batch adversarial loss: 0.493617\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015620; batch adversarial loss: 0.417869\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013967; batch adversarial loss: 0.652123\n",
      "epoch 139; iter: 0; batch classifier loss: 0.062121; batch adversarial loss: 0.444255\n",
      "epoch 140; iter: 0; batch classifier loss: 0.049477; batch adversarial loss: 0.537873\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052682; batch adversarial loss: 0.489531\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035558; batch adversarial loss: 0.424335\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014640; batch adversarial loss: 0.524100\n",
      "epoch 144; iter: 0; batch classifier loss: 0.054016; batch adversarial loss: 0.389508\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022626; batch adversarial loss: 0.446693\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023773; batch adversarial loss: 0.539574\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027456; batch adversarial loss: 0.451044\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027379; batch adversarial loss: 0.397600\n",
      "epoch 149; iter: 0; batch classifier loss: 0.010916; batch adversarial loss: 0.517789\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013675; batch adversarial loss: 0.363339\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025518; batch adversarial loss: 0.417818\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011733; batch adversarial loss: 0.508562\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028150; batch adversarial loss: 0.409611\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030623; batch adversarial loss: 0.506021\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017960; batch adversarial loss: 0.473685\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017082; batch adversarial loss: 0.421934\n",
      "epoch 157; iter: 0; batch classifier loss: 0.055338; batch adversarial loss: 0.357574\n",
      "epoch 158; iter: 0; batch classifier loss: 0.007899; batch adversarial loss: 0.398844\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018990; batch adversarial loss: 0.464651\n",
      "epoch 160; iter: 0; batch classifier loss: 0.040179; batch adversarial loss: 0.459944\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040187; batch adversarial loss: 0.427677\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018163; batch adversarial loss: 0.459780\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022456; batch adversarial loss: 0.521740\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029171; batch adversarial loss: 0.481116\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027744; batch adversarial loss: 0.432010\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013708; batch adversarial loss: 0.481646\n",
      "epoch 167; iter: 0; batch classifier loss: 0.043878; batch adversarial loss: 0.479018\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007956; batch adversarial loss: 0.488269\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014015; batch adversarial loss: 0.425198\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008035; batch adversarial loss: 0.451752\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033768; batch adversarial loss: 0.580670\n",
      "epoch 172; iter: 0; batch classifier loss: 0.047180; batch adversarial loss: 0.451862\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007191; batch adversarial loss: 0.387759\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029094; batch adversarial loss: 0.513843\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008764; batch adversarial loss: 0.446209\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007357; batch adversarial loss: 0.357985\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030636; batch adversarial loss: 0.346219\n",
      "epoch 178; iter: 0; batch classifier loss: 0.060648; batch adversarial loss: 0.472391\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017349; batch adversarial loss: 0.510358\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028187; batch adversarial loss: 0.379065\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037152; batch adversarial loss: 0.402539\n",
      "epoch 182; iter: 0; batch classifier loss: 0.070972; batch adversarial loss: 0.541609\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017220; batch adversarial loss: 0.420711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.007056; batch adversarial loss: 0.487632\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028787; batch adversarial loss: 0.457734\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016145; batch adversarial loss: 0.373664\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019324; batch adversarial loss: 0.472263\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008634; batch adversarial loss: 0.371149\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010740; batch adversarial loss: 0.391520\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007280; batch adversarial loss: 0.508175\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011452; batch adversarial loss: 0.492364\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032313; batch adversarial loss: 0.460958\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032726; batch adversarial loss: 0.471558\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025423; batch adversarial loss: 0.410957\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030931; batch adversarial loss: 0.484261\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022101; batch adversarial loss: 0.380406\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024104; batch adversarial loss: 0.419073\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022109; batch adversarial loss: 0.466320\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022526; batch adversarial loss: 0.410874\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679211; batch adversarial loss: 0.681117\n",
      "epoch 1; iter: 0; batch classifier loss: 0.486277; batch adversarial loss: 0.679845\n",
      "epoch 2; iter: 0; batch classifier loss: 0.387218; batch adversarial loss: 0.625720\n",
      "epoch 3; iter: 0; batch classifier loss: 0.445995; batch adversarial loss: 0.570388\n",
      "epoch 4; iter: 0; batch classifier loss: 0.340596; batch adversarial loss: 0.575744\n",
      "epoch 5; iter: 0; batch classifier loss: 0.279929; batch adversarial loss: 0.542403\n",
      "epoch 6; iter: 0; batch classifier loss: 0.240583; batch adversarial loss: 0.529486\n",
      "epoch 7; iter: 0; batch classifier loss: 0.227862; batch adversarial loss: 0.538588\n",
      "epoch 8; iter: 0; batch classifier loss: 0.235903; batch adversarial loss: 0.495892\n",
      "epoch 9; iter: 0; batch classifier loss: 0.192558; batch adversarial loss: 0.506261\n",
      "epoch 10; iter: 0; batch classifier loss: 0.245299; batch adversarial loss: 0.518312\n",
      "epoch 11; iter: 0; batch classifier loss: 0.247140; batch adversarial loss: 0.465160\n",
      "epoch 12; iter: 0; batch classifier loss: 0.151355; batch adversarial loss: 0.533038\n",
      "epoch 13; iter: 0; batch classifier loss: 0.170539; batch adversarial loss: 0.541365\n",
      "epoch 14; iter: 0; batch classifier loss: 0.144406; batch adversarial loss: 0.456380\n",
      "epoch 15; iter: 0; batch classifier loss: 0.111860; batch adversarial loss: 0.472493\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227261; batch adversarial loss: 0.578336\n",
      "epoch 17; iter: 0; batch classifier loss: 0.157277; batch adversarial loss: 0.450178\n",
      "epoch 18; iter: 0; batch classifier loss: 0.136285; batch adversarial loss: 0.502412\n",
      "epoch 19; iter: 0; batch classifier loss: 0.183309; batch adversarial loss: 0.411992\n",
      "epoch 20; iter: 0; batch classifier loss: 0.129988; batch adversarial loss: 0.471550\n",
      "epoch 21; iter: 0; batch classifier loss: 0.196584; batch adversarial loss: 0.506744\n",
      "epoch 22; iter: 0; batch classifier loss: 0.130812; batch adversarial loss: 0.493379\n",
      "epoch 23; iter: 0; batch classifier loss: 0.139584; batch adversarial loss: 0.384087\n",
      "epoch 24; iter: 0; batch classifier loss: 0.161673; batch adversarial loss: 0.418675\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177621; batch adversarial loss: 0.529622\n",
      "epoch 26; iter: 0; batch classifier loss: 0.203606; batch adversarial loss: 0.470462\n",
      "epoch 27; iter: 0; batch classifier loss: 0.184161; batch adversarial loss: 0.498808\n",
      "epoch 28; iter: 0; batch classifier loss: 0.141378; batch adversarial loss: 0.475403\n",
      "epoch 29; iter: 0; batch classifier loss: 0.236911; batch adversarial loss: 0.472693\n",
      "epoch 30; iter: 0; batch classifier loss: 0.198078; batch adversarial loss: 0.493635\n",
      "epoch 31; iter: 0; batch classifier loss: 0.282043; batch adversarial loss: 0.446266\n",
      "epoch 32; iter: 0; batch classifier loss: 0.256131; batch adversarial loss: 0.476599\n",
      "epoch 33; iter: 0; batch classifier loss: 0.263222; batch adversarial loss: 0.477877\n",
      "epoch 34; iter: 0; batch classifier loss: 0.176542; batch adversarial loss: 0.463859\n",
      "epoch 35; iter: 0; batch classifier loss: 0.099110; batch adversarial loss: 0.441751\n",
      "epoch 36; iter: 0; batch classifier loss: 0.118292; batch adversarial loss: 0.456816\n",
      "epoch 37; iter: 0; batch classifier loss: 0.108502; batch adversarial loss: 0.487699\n",
      "epoch 38; iter: 0; batch classifier loss: 0.087919; batch adversarial loss: 0.457643\n",
      "epoch 39; iter: 0; batch classifier loss: 0.115232; batch adversarial loss: 0.327665\n",
      "epoch 40; iter: 0; batch classifier loss: 0.057273; batch adversarial loss: 0.542526\n",
      "epoch 41; iter: 0; batch classifier loss: 0.107333; batch adversarial loss: 0.489151\n",
      "epoch 42; iter: 0; batch classifier loss: 0.098567; batch adversarial loss: 0.483666\n",
      "epoch 43; iter: 0; batch classifier loss: 0.071167; batch adversarial loss: 0.438659\n",
      "epoch 44; iter: 0; batch classifier loss: 0.114143; batch adversarial loss: 0.478307\n",
      "epoch 45; iter: 0; batch classifier loss: 0.055379; batch adversarial loss: 0.342152\n",
      "epoch 46; iter: 0; batch classifier loss: 0.054119; batch adversarial loss: 0.523280\n",
      "epoch 47; iter: 0; batch classifier loss: 0.060027; batch adversarial loss: 0.403187\n",
      "epoch 48; iter: 0; batch classifier loss: 0.050788; batch adversarial loss: 0.472054\n",
      "epoch 49; iter: 0; batch classifier loss: 0.092719; batch adversarial loss: 0.419501\n",
      "epoch 50; iter: 0; batch classifier loss: 0.052125; batch adversarial loss: 0.389440\n",
      "epoch 51; iter: 0; batch classifier loss: 0.084223; batch adversarial loss: 0.377135\n",
      "epoch 52; iter: 0; batch classifier loss: 0.094984; batch adversarial loss: 0.430561\n",
      "epoch 53; iter: 0; batch classifier loss: 0.111062; batch adversarial loss: 0.395273\n",
      "epoch 54; iter: 0; batch classifier loss: 0.088022; batch adversarial loss: 0.466036\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079673; batch adversarial loss: 0.522138\n",
      "epoch 56; iter: 0; batch classifier loss: 0.060950; batch adversarial loss: 0.388204\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061910; batch adversarial loss: 0.350097\n",
      "epoch 58; iter: 0; batch classifier loss: 0.065150; batch adversarial loss: 0.445411\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072807; batch adversarial loss: 0.483712\n",
      "epoch 60; iter: 0; batch classifier loss: 0.106139; batch adversarial loss: 0.483794\n",
      "epoch 61; iter: 0; batch classifier loss: 0.048958; batch adversarial loss: 0.479192\n",
      "epoch 62; iter: 0; batch classifier loss: 0.106915; batch adversarial loss: 0.330857\n",
      "epoch 63; iter: 0; batch classifier loss: 0.056012; batch adversarial loss: 0.574588\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080399; batch adversarial loss: 0.408666\n",
      "epoch 65; iter: 0; batch classifier loss: 0.076608; batch adversarial loss: 0.488923\n",
      "epoch 66; iter: 0; batch classifier loss: 0.067409; batch adversarial loss: 0.442294\n",
      "epoch 67; iter: 0; batch classifier loss: 0.046931; batch adversarial loss: 0.329630\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076388; batch adversarial loss: 0.352442\n",
      "epoch 69; iter: 0; batch classifier loss: 0.115323; batch adversarial loss: 0.499027\n",
      "epoch 70; iter: 0; batch classifier loss: 0.122966; batch adversarial loss: 0.415204\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073815; batch adversarial loss: 0.421499\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071866; batch adversarial loss: 0.462153\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062777; batch adversarial loss: 0.486524\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101919; batch adversarial loss: 0.358765\n",
      "epoch 75; iter: 0; batch classifier loss: 0.052345; batch adversarial loss: 0.410265\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055118; batch adversarial loss: 0.399779\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056049; batch adversarial loss: 0.466505\n",
      "epoch 78; iter: 0; batch classifier loss: 0.057125; batch adversarial loss: 0.489517\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072585; batch adversarial loss: 0.364361\n",
      "epoch 80; iter: 0; batch classifier loss: 0.050612; batch adversarial loss: 0.445508\n",
      "epoch 81; iter: 0; batch classifier loss: 0.029062; batch adversarial loss: 0.413151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.029890; batch adversarial loss: 0.454057\n",
      "epoch 83; iter: 0; batch classifier loss: 0.050101; batch adversarial loss: 0.484275\n",
      "epoch 84; iter: 0; batch classifier loss: 0.044354; batch adversarial loss: 0.477221\n",
      "epoch 85; iter: 0; batch classifier loss: 0.035131; batch adversarial loss: 0.489491\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052190; batch adversarial loss: 0.435926\n",
      "epoch 87; iter: 0; batch classifier loss: 0.095378; batch adversarial loss: 0.433922\n",
      "epoch 88; iter: 0; batch classifier loss: 0.032286; batch adversarial loss: 0.496471\n",
      "epoch 89; iter: 0; batch classifier loss: 0.061065; batch adversarial loss: 0.407704\n",
      "epoch 90; iter: 0; batch classifier loss: 0.037680; batch adversarial loss: 0.389135\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063421; batch adversarial loss: 0.507790\n",
      "epoch 92; iter: 0; batch classifier loss: 0.047558; batch adversarial loss: 0.378199\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061747; batch adversarial loss: 0.468077\n",
      "epoch 94; iter: 0; batch classifier loss: 0.019594; batch adversarial loss: 0.460885\n",
      "epoch 95; iter: 0; batch classifier loss: 0.072713; batch adversarial loss: 0.453155\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044747; batch adversarial loss: 0.498122\n",
      "epoch 97; iter: 0; batch classifier loss: 0.045462; batch adversarial loss: 0.480024\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074748; batch adversarial loss: 0.499737\n",
      "epoch 99; iter: 0; batch classifier loss: 0.030162; batch adversarial loss: 0.436475\n",
      "epoch 100; iter: 0; batch classifier loss: 0.042868; batch adversarial loss: 0.493029\n",
      "epoch 101; iter: 0; batch classifier loss: 0.069255; batch adversarial loss: 0.317512\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032076; batch adversarial loss: 0.461982\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038580; batch adversarial loss: 0.426970\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060115; batch adversarial loss: 0.431110\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058711; batch adversarial loss: 0.516399\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035121; batch adversarial loss: 0.451667\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032231; batch adversarial loss: 0.433619\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030552; batch adversarial loss: 0.428086\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038351; batch adversarial loss: 0.510443\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051349; batch adversarial loss: 0.380965\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053551; batch adversarial loss: 0.463432\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024252; batch adversarial loss: 0.377067\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037546; batch adversarial loss: 0.499678\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035701; batch adversarial loss: 0.410252\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024422; batch adversarial loss: 0.612025\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053680; batch adversarial loss: 0.363479\n",
      "epoch 117; iter: 0; batch classifier loss: 0.020170; batch adversarial loss: 0.493281\n",
      "epoch 118; iter: 0; batch classifier loss: 0.081658; batch adversarial loss: 0.508655\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043966; batch adversarial loss: 0.470887\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031720; batch adversarial loss: 0.376288\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029874; batch adversarial loss: 0.444606\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067637; batch adversarial loss: 0.460029\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064524; batch adversarial loss: 0.463547\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067639; batch adversarial loss: 0.469133\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044557; batch adversarial loss: 0.471897\n",
      "epoch 126; iter: 0; batch classifier loss: 0.014178; batch adversarial loss: 0.446388\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036555; batch adversarial loss: 0.495449\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018763; batch adversarial loss: 0.401361\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038268; batch adversarial loss: 0.414461\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016260; batch adversarial loss: 0.417756\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039310; batch adversarial loss: 0.451442\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023112; batch adversarial loss: 0.358201\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020023; batch adversarial loss: 0.394914\n",
      "epoch 134; iter: 0; batch classifier loss: 0.008068; batch adversarial loss: 0.578320\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051251; batch adversarial loss: 0.400549\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023715; batch adversarial loss: 0.557729\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015459; batch adversarial loss: 0.369738\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032248; batch adversarial loss: 0.398992\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016571; batch adversarial loss: 0.433778\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033947; batch adversarial loss: 0.394682\n",
      "epoch 141; iter: 0; batch classifier loss: 0.013188; batch adversarial loss: 0.519978\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020384; batch adversarial loss: 0.463097\n",
      "epoch 143; iter: 0; batch classifier loss: 0.045979; batch adversarial loss: 0.327853\n",
      "epoch 144; iter: 0; batch classifier loss: 0.050236; batch adversarial loss: 0.471552\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025599; batch adversarial loss: 0.566069\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019826; batch adversarial loss: 0.465427\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020436; batch adversarial loss: 0.468132\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039492; batch adversarial loss: 0.356279\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053498; batch adversarial loss: 0.472394\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028626; batch adversarial loss: 0.321749\n",
      "epoch 151; iter: 0; batch classifier loss: 0.100639; batch adversarial loss: 0.453516\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021626; batch adversarial loss: 0.448597\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012227; batch adversarial loss: 0.504297\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041335; batch adversarial loss: 0.494742\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019698; batch adversarial loss: 0.446174\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015334; batch adversarial loss: 0.473205\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012483; batch adversarial loss: 0.411184\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012997; batch adversarial loss: 0.438066\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035742; batch adversarial loss: 0.488677\n",
      "epoch 160; iter: 0; batch classifier loss: 0.045826; batch adversarial loss: 0.428440\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014452; batch adversarial loss: 0.409404\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019025; batch adversarial loss: 0.417022\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018175; batch adversarial loss: 0.387803\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026441; batch adversarial loss: 0.514614\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015104; batch adversarial loss: 0.407670\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019609; batch adversarial loss: 0.509187\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014281; batch adversarial loss: 0.442732\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024809; batch adversarial loss: 0.425242\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023309; batch adversarial loss: 0.548151\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034137; batch adversarial loss: 0.402772\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036950; batch adversarial loss: 0.577663\n",
      "epoch 172; iter: 0; batch classifier loss: 0.006841; batch adversarial loss: 0.398350\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027189; batch adversarial loss: 0.500952\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038052; batch adversarial loss: 0.373509\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034270; batch adversarial loss: 0.433888\n",
      "epoch 176; iter: 0; batch classifier loss: 0.048151; batch adversarial loss: 0.455269\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028483; batch adversarial loss: 0.436823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.011292; batch adversarial loss: 0.409719\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015015; batch adversarial loss: 0.408762\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018959; batch adversarial loss: 0.470400\n",
      "epoch 181; iter: 0; batch classifier loss: 0.049569; batch adversarial loss: 0.470093\n",
      "epoch 182; iter: 0; batch classifier loss: 0.035607; batch adversarial loss: 0.441954\n",
      "epoch 183; iter: 0; batch classifier loss: 0.059939; batch adversarial loss: 0.443004\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013892; batch adversarial loss: 0.421827\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028113; batch adversarial loss: 0.510958\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014221; batch adversarial loss: 0.453417\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027262; batch adversarial loss: 0.374596\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017890; batch adversarial loss: 0.479652\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021779; batch adversarial loss: 0.434744\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015617; batch adversarial loss: 0.430661\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006891; batch adversarial loss: 0.453554\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009433; batch adversarial loss: 0.448486\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025924; batch adversarial loss: 0.445721\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025683; batch adversarial loss: 0.506595\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022397; batch adversarial loss: 0.512080\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026789; batch adversarial loss: 0.372024\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016150; batch adversarial loss: 0.495397\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031298; batch adversarial loss: 0.409609\n",
      "epoch 199; iter: 0; batch classifier loss: 0.053492; batch adversarial loss: 0.479182\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691048; batch adversarial loss: 0.638146\n",
      "epoch 1; iter: 0; batch classifier loss: 0.403476; batch adversarial loss: 0.628847\n",
      "epoch 2; iter: 0; batch classifier loss: 0.374468; batch adversarial loss: 0.620459\n",
      "epoch 3; iter: 0; batch classifier loss: 0.343490; batch adversarial loss: 0.572798\n",
      "epoch 4; iter: 0; batch classifier loss: 0.355360; batch adversarial loss: 0.550507\n",
      "epoch 5; iter: 0; batch classifier loss: 0.317502; batch adversarial loss: 0.552078\n",
      "epoch 6; iter: 0; batch classifier loss: 0.280842; batch adversarial loss: 0.559454\n",
      "epoch 7; iter: 0; batch classifier loss: 0.254737; batch adversarial loss: 0.591532\n",
      "epoch 8; iter: 0; batch classifier loss: 0.293026; batch adversarial loss: 0.523107\n",
      "epoch 9; iter: 0; batch classifier loss: 0.292777; batch adversarial loss: 0.517098\n",
      "epoch 10; iter: 0; batch classifier loss: 0.359150; batch adversarial loss: 0.511136\n",
      "epoch 11; iter: 0; batch classifier loss: 0.227383; batch adversarial loss: 0.537910\n",
      "epoch 12; iter: 0; batch classifier loss: 0.293885; batch adversarial loss: 0.516504\n",
      "epoch 13; iter: 0; batch classifier loss: 0.311942; batch adversarial loss: 0.565062\n",
      "epoch 14; iter: 0; batch classifier loss: 0.390286; batch adversarial loss: 0.537051\n",
      "epoch 15; iter: 0; batch classifier loss: 0.430923; batch adversarial loss: 0.471572\n",
      "epoch 16; iter: 0; batch classifier loss: 0.460275; batch adversarial loss: 0.500963\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504310; batch adversarial loss: 0.523643\n",
      "epoch 18; iter: 0; batch classifier loss: 0.378307; batch adversarial loss: 0.535272\n",
      "epoch 19; iter: 0; batch classifier loss: 0.243649; batch adversarial loss: 0.514654\n",
      "epoch 20; iter: 0; batch classifier loss: 0.271726; batch adversarial loss: 0.457453\n",
      "epoch 21; iter: 0; batch classifier loss: 0.165090; batch adversarial loss: 0.494331\n",
      "epoch 22; iter: 0; batch classifier loss: 0.203029; batch adversarial loss: 0.508256\n",
      "epoch 23; iter: 0; batch classifier loss: 0.175970; batch adversarial loss: 0.462118\n",
      "epoch 24; iter: 0; batch classifier loss: 0.164381; batch adversarial loss: 0.489417\n",
      "epoch 25; iter: 0; batch classifier loss: 0.151896; batch adversarial loss: 0.472756\n",
      "epoch 26; iter: 0; batch classifier loss: 0.125000; batch adversarial loss: 0.417947\n",
      "epoch 27; iter: 0; batch classifier loss: 0.140250; batch adversarial loss: 0.534356\n",
      "epoch 28; iter: 0; batch classifier loss: 0.152538; batch adversarial loss: 0.470254\n",
      "epoch 29; iter: 0; batch classifier loss: 0.152509; batch adversarial loss: 0.440640\n",
      "epoch 30; iter: 0; batch classifier loss: 0.183741; batch adversarial loss: 0.450837\n",
      "epoch 31; iter: 0; batch classifier loss: 0.174746; batch adversarial loss: 0.522210\n",
      "epoch 32; iter: 0; batch classifier loss: 0.147184; batch adversarial loss: 0.400439\n",
      "epoch 33; iter: 0; batch classifier loss: 0.170899; batch adversarial loss: 0.493270\n",
      "epoch 34; iter: 0; batch classifier loss: 0.125795; batch adversarial loss: 0.440121\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148028; batch adversarial loss: 0.479952\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102042; batch adversarial loss: 0.507688\n",
      "epoch 37; iter: 0; batch classifier loss: 0.138568; batch adversarial loss: 0.443065\n",
      "epoch 38; iter: 0; batch classifier loss: 0.144922; batch adversarial loss: 0.533961\n",
      "epoch 39; iter: 0; batch classifier loss: 0.167096; batch adversarial loss: 0.463716\n",
      "epoch 40; iter: 0; batch classifier loss: 0.181409; batch adversarial loss: 0.506440\n",
      "epoch 41; iter: 0; batch classifier loss: 0.113047; batch adversarial loss: 0.345383\n",
      "epoch 42; iter: 0; batch classifier loss: 0.142097; batch adversarial loss: 0.492262\n",
      "epoch 43; iter: 0; batch classifier loss: 0.164482; batch adversarial loss: 0.435363\n",
      "epoch 44; iter: 0; batch classifier loss: 0.111965; batch adversarial loss: 0.488965\n",
      "epoch 45; iter: 0; batch classifier loss: 0.120155; batch adversarial loss: 0.602598\n",
      "epoch 46; iter: 0; batch classifier loss: 0.073973; batch adversarial loss: 0.391100\n",
      "epoch 47; iter: 0; batch classifier loss: 0.068044; batch adversarial loss: 0.458502\n",
      "epoch 48; iter: 0; batch classifier loss: 0.145087; batch adversarial loss: 0.412655\n",
      "epoch 49; iter: 0; batch classifier loss: 0.121364; batch adversarial loss: 0.473140\n",
      "epoch 50; iter: 0; batch classifier loss: 0.119408; batch adversarial loss: 0.467167\n",
      "epoch 51; iter: 0; batch classifier loss: 0.101615; batch adversarial loss: 0.333048\n",
      "epoch 52; iter: 0; batch classifier loss: 0.090561; batch adversarial loss: 0.451892\n",
      "epoch 53; iter: 0; batch classifier loss: 0.110676; batch adversarial loss: 0.402864\n",
      "epoch 54; iter: 0; batch classifier loss: 0.117442; batch adversarial loss: 0.441855\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122534; batch adversarial loss: 0.511912\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102978; batch adversarial loss: 0.461550\n",
      "epoch 57; iter: 0; batch classifier loss: 0.108232; batch adversarial loss: 0.528829\n",
      "epoch 58; iter: 0; batch classifier loss: 0.074897; batch adversarial loss: 0.452431\n",
      "epoch 59; iter: 0; batch classifier loss: 0.113797; batch adversarial loss: 0.547514\n",
      "epoch 60; iter: 0; batch classifier loss: 0.115722; batch adversarial loss: 0.407849\n",
      "epoch 61; iter: 0; batch classifier loss: 0.120864; batch adversarial loss: 0.575688\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092511; batch adversarial loss: 0.393776\n",
      "epoch 63; iter: 0; batch classifier loss: 0.117885; batch adversarial loss: 0.470113\n",
      "epoch 64; iter: 0; batch classifier loss: 0.139448; batch adversarial loss: 0.552126\n",
      "epoch 65; iter: 0; batch classifier loss: 0.117540; batch adversarial loss: 0.412216\n",
      "epoch 66; iter: 0; batch classifier loss: 0.128814; batch adversarial loss: 0.482979\n",
      "epoch 67; iter: 0; batch classifier loss: 0.083203; batch adversarial loss: 0.438940\n",
      "epoch 68; iter: 0; batch classifier loss: 0.072714; batch adversarial loss: 0.376249\n",
      "epoch 69; iter: 0; batch classifier loss: 0.109216; batch adversarial loss: 0.375803\n",
      "epoch 70; iter: 0; batch classifier loss: 0.068300; batch adversarial loss: 0.518269\n",
      "epoch 71; iter: 0; batch classifier loss: 0.110779; batch adversarial loss: 0.414132\n",
      "epoch 72; iter: 0; batch classifier loss: 0.081817; batch adversarial loss: 0.482246\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085081; batch adversarial loss: 0.511564\n",
      "epoch 74; iter: 0; batch classifier loss: 0.151157; batch adversarial loss: 0.423698\n",
      "epoch 75; iter: 0; batch classifier loss: 0.087247; batch adversarial loss: 0.427126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.118036; batch adversarial loss: 0.439910\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084089; batch adversarial loss: 0.443022\n",
      "epoch 78; iter: 0; batch classifier loss: 0.044346; batch adversarial loss: 0.464434\n",
      "epoch 79; iter: 0; batch classifier loss: 0.099829; batch adversarial loss: 0.446958\n",
      "epoch 80; iter: 0; batch classifier loss: 0.063800; batch adversarial loss: 0.531448\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073272; batch adversarial loss: 0.437839\n",
      "epoch 82; iter: 0; batch classifier loss: 0.048769; batch adversarial loss: 0.461442\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081185; batch adversarial loss: 0.562752\n",
      "epoch 84; iter: 0; batch classifier loss: 0.073056; batch adversarial loss: 0.491459\n",
      "epoch 85; iter: 0; batch classifier loss: 0.079410; batch adversarial loss: 0.401223\n",
      "epoch 86; iter: 0; batch classifier loss: 0.093340; batch adversarial loss: 0.470472\n",
      "epoch 87; iter: 0; batch classifier loss: 0.102318; batch adversarial loss: 0.505987\n",
      "epoch 88; iter: 0; batch classifier loss: 0.119694; batch adversarial loss: 0.384105\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054949; batch adversarial loss: 0.520866\n",
      "epoch 90; iter: 0; batch classifier loss: 0.082809; batch adversarial loss: 0.420408\n",
      "epoch 91; iter: 0; batch classifier loss: 0.080292; batch adversarial loss: 0.369648\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063305; batch adversarial loss: 0.478271\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051743; batch adversarial loss: 0.472459\n",
      "epoch 94; iter: 0; batch classifier loss: 0.090354; batch adversarial loss: 0.419242\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068361; batch adversarial loss: 0.451239\n",
      "epoch 96; iter: 0; batch classifier loss: 0.071499; batch adversarial loss: 0.445685\n",
      "epoch 97; iter: 0; batch classifier loss: 0.035718; batch adversarial loss: 0.477400\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056984; batch adversarial loss: 0.564422\n",
      "epoch 99; iter: 0; batch classifier loss: 0.091868; batch adversarial loss: 0.487713\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036156; batch adversarial loss: 0.407871\n",
      "epoch 101; iter: 0; batch classifier loss: 0.074270; batch adversarial loss: 0.384532\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056386; batch adversarial loss: 0.466126\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047292; batch adversarial loss: 0.383533\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045439; batch adversarial loss: 0.420942\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060041; batch adversarial loss: 0.502781\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054663; batch adversarial loss: 0.530925\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061805; batch adversarial loss: 0.418020\n",
      "epoch 108; iter: 0; batch classifier loss: 0.083452; batch adversarial loss: 0.516575\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027234; batch adversarial loss: 0.500289\n",
      "epoch 110; iter: 0; batch classifier loss: 0.088920; batch adversarial loss: 0.558177\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059620; batch adversarial loss: 0.480154\n",
      "epoch 112; iter: 0; batch classifier loss: 0.066289; batch adversarial loss: 0.469184\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069293; batch adversarial loss: 0.413033\n",
      "epoch 114; iter: 0; batch classifier loss: 0.058751; batch adversarial loss: 0.460969\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041526; batch adversarial loss: 0.466223\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046796; batch adversarial loss: 0.474475\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045890; batch adversarial loss: 0.481369\n",
      "epoch 118; iter: 0; batch classifier loss: 0.089201; batch adversarial loss: 0.426164\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046459; batch adversarial loss: 0.540106\n",
      "epoch 120; iter: 0; batch classifier loss: 0.076573; batch adversarial loss: 0.415302\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044520; batch adversarial loss: 0.474965\n",
      "epoch 122; iter: 0; batch classifier loss: 0.013749; batch adversarial loss: 0.471366\n",
      "epoch 123; iter: 0; batch classifier loss: 0.079918; batch adversarial loss: 0.493443\n",
      "epoch 124; iter: 0; batch classifier loss: 0.077628; batch adversarial loss: 0.441790\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044136; batch adversarial loss: 0.508772\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038569; batch adversarial loss: 0.490694\n",
      "epoch 127; iter: 0; batch classifier loss: 0.065782; batch adversarial loss: 0.531067\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037769; batch adversarial loss: 0.465107\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042113; batch adversarial loss: 0.525519\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059599; batch adversarial loss: 0.476664\n",
      "epoch 131; iter: 0; batch classifier loss: 0.067885; batch adversarial loss: 0.428998\n",
      "epoch 132; iter: 0; batch classifier loss: 0.049838; batch adversarial loss: 0.492032\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025426; batch adversarial loss: 0.483403\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015537; batch adversarial loss: 0.454626\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028138; batch adversarial loss: 0.413539\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044726; batch adversarial loss: 0.400421\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039946; batch adversarial loss: 0.500888\n",
      "epoch 138; iter: 0; batch classifier loss: 0.064959; batch adversarial loss: 0.439658\n",
      "epoch 139; iter: 0; batch classifier loss: 0.054980; batch adversarial loss: 0.456508\n",
      "epoch 140; iter: 0; batch classifier loss: 0.092932; batch adversarial loss: 0.426376\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032692; batch adversarial loss: 0.379550\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023637; batch adversarial loss: 0.414792\n",
      "epoch 143; iter: 0; batch classifier loss: 0.038206; batch adversarial loss: 0.530507\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032692; batch adversarial loss: 0.531908\n",
      "epoch 145; iter: 0; batch classifier loss: 0.078120; batch adversarial loss: 0.502001\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030155; batch adversarial loss: 0.439055\n",
      "epoch 147; iter: 0; batch classifier loss: 0.066770; batch adversarial loss: 0.475465\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045652; batch adversarial loss: 0.476245\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027240; batch adversarial loss: 0.471351\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023576; batch adversarial loss: 0.499689\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036550; batch adversarial loss: 0.486755\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015731; batch adversarial loss: 0.397924\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019944; batch adversarial loss: 0.526615\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021949; batch adversarial loss: 0.414636\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020291; batch adversarial loss: 0.489211\n",
      "epoch 156; iter: 0; batch classifier loss: 0.067746; batch adversarial loss: 0.410913\n",
      "epoch 157; iter: 0; batch classifier loss: 0.079621; batch adversarial loss: 0.441637\n",
      "epoch 158; iter: 0; batch classifier loss: 0.070014; batch adversarial loss: 0.333254\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020334; batch adversarial loss: 0.599712\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020538; batch adversarial loss: 0.508020\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042464; batch adversarial loss: 0.373130\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021252; batch adversarial loss: 0.466735\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024194; batch adversarial loss: 0.538849\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015952; batch adversarial loss: 0.415603\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040748; batch adversarial loss: 0.546066\n",
      "epoch 166; iter: 0; batch classifier loss: 0.044799; batch adversarial loss: 0.487279\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030269; batch adversarial loss: 0.470185\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026173; batch adversarial loss: 0.424875\n",
      "epoch 169; iter: 0; batch classifier loss: 0.051729; batch adversarial loss: 0.502993\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039460; batch adversarial loss: 0.543061\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024880; batch adversarial loss: 0.424728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.021746; batch adversarial loss: 0.476554\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028295; batch adversarial loss: 0.514001\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015961; batch adversarial loss: 0.483622\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020589; batch adversarial loss: 0.482442\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023233; batch adversarial loss: 0.442920\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027080; batch adversarial loss: 0.499802\n",
      "epoch 178; iter: 0; batch classifier loss: 0.069183; batch adversarial loss: 0.464986\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010971; batch adversarial loss: 0.429718\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027342; batch adversarial loss: 0.431213\n",
      "epoch 181; iter: 0; batch classifier loss: 0.004483; batch adversarial loss: 0.418589\n",
      "epoch 182; iter: 0; batch classifier loss: 0.051942; batch adversarial loss: 0.453432\n",
      "epoch 183; iter: 0; batch classifier loss: 0.039242; batch adversarial loss: 0.542293\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032260; batch adversarial loss: 0.447690\n",
      "epoch 185; iter: 0; batch classifier loss: 0.043944; batch adversarial loss: 0.463820\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016546; batch adversarial loss: 0.431601\n",
      "epoch 187; iter: 0; batch classifier loss: 0.048806; batch adversarial loss: 0.486532\n",
      "epoch 188; iter: 0; batch classifier loss: 0.052308; batch adversarial loss: 0.415882\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034953; batch adversarial loss: 0.383489\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026845; batch adversarial loss: 0.503651\n",
      "epoch 191; iter: 0; batch classifier loss: 0.057353; batch adversarial loss: 0.405221\n",
      "epoch 192; iter: 0; batch classifier loss: 0.064729; batch adversarial loss: 0.443983\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037074; batch adversarial loss: 0.654106\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021837; batch adversarial loss: 0.534812\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010377; batch adversarial loss: 0.417058\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011411; batch adversarial loss: 0.491419\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009627; batch adversarial loss: 0.490432\n",
      "epoch 198; iter: 0; batch classifier loss: 0.040590; batch adversarial loss: 0.504758\n",
      "epoch 199; iter: 0; batch classifier loss: 0.048587; batch adversarial loss: 0.428561\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693650; batch adversarial loss: 0.914724\n",
      "epoch 1; iter: 0; batch classifier loss: 0.555622; batch adversarial loss: 0.890960\n",
      "epoch 2; iter: 0; batch classifier loss: 0.865276; batch adversarial loss: 0.946281\n",
      "epoch 3; iter: 0; batch classifier loss: 1.078318; batch adversarial loss: 0.885993\n",
      "epoch 4; iter: 0; batch classifier loss: 0.950302; batch adversarial loss: 0.771503\n",
      "epoch 5; iter: 0; batch classifier loss: 0.947932; batch adversarial loss: 0.693249\n",
      "epoch 6; iter: 0; batch classifier loss: 0.866390; batch adversarial loss: 0.656906\n",
      "epoch 7; iter: 0; batch classifier loss: 0.610997; batch adversarial loss: 0.596517\n",
      "epoch 8; iter: 0; batch classifier loss: 0.414036; batch adversarial loss: 0.573735\n",
      "epoch 9; iter: 0; batch classifier loss: 0.429568; batch adversarial loss: 0.537147\n",
      "epoch 10; iter: 0; batch classifier loss: 0.334849; batch adversarial loss: 0.517391\n",
      "epoch 11; iter: 0; batch classifier loss: 0.337062; batch adversarial loss: 0.526514\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251493; batch adversarial loss: 0.560617\n",
      "epoch 13; iter: 0; batch classifier loss: 0.337061; batch adversarial loss: 0.504556\n",
      "epoch 14; iter: 0; batch classifier loss: 0.300041; batch adversarial loss: 0.522087\n",
      "epoch 15; iter: 0; batch classifier loss: 0.258032; batch adversarial loss: 0.500974\n",
      "epoch 16; iter: 0; batch classifier loss: 0.331278; batch adversarial loss: 0.504491\n",
      "epoch 17; iter: 0; batch classifier loss: 0.366353; batch adversarial loss: 0.504633\n",
      "epoch 18; iter: 0; batch classifier loss: 0.327520; batch adversarial loss: 0.477169\n",
      "epoch 19; iter: 0; batch classifier loss: 0.277743; batch adversarial loss: 0.497008\n",
      "epoch 20; iter: 0; batch classifier loss: 0.283457; batch adversarial loss: 0.484816\n",
      "epoch 21; iter: 0; batch classifier loss: 0.291764; batch adversarial loss: 0.450572\n",
      "epoch 22; iter: 0; batch classifier loss: 0.247792; batch adversarial loss: 0.533920\n",
      "epoch 23; iter: 0; batch classifier loss: 0.335832; batch adversarial loss: 0.441205\n",
      "epoch 24; iter: 0; batch classifier loss: 0.276106; batch adversarial loss: 0.481132\n",
      "epoch 25; iter: 0; batch classifier loss: 0.276265; batch adversarial loss: 0.468023\n",
      "epoch 26; iter: 0; batch classifier loss: 0.244803; batch adversarial loss: 0.512422\n",
      "epoch 27; iter: 0; batch classifier loss: 0.308534; batch adversarial loss: 0.385725\n",
      "epoch 28; iter: 0; batch classifier loss: 0.276870; batch adversarial loss: 0.453235\n",
      "epoch 29; iter: 0; batch classifier loss: 0.266005; batch adversarial loss: 0.491974\n",
      "epoch 30; iter: 0; batch classifier loss: 0.211439; batch adversarial loss: 0.555071\n",
      "epoch 31; iter: 0; batch classifier loss: 0.328455; batch adversarial loss: 0.456900\n",
      "epoch 32; iter: 0; batch classifier loss: 0.189131; batch adversarial loss: 0.545632\n",
      "epoch 33; iter: 0; batch classifier loss: 0.341907; batch adversarial loss: 0.446220\n",
      "epoch 34; iter: 0; batch classifier loss: 0.239620; batch adversarial loss: 0.460613\n",
      "epoch 35; iter: 0; batch classifier loss: 0.297023; batch adversarial loss: 0.520740\n",
      "epoch 36; iter: 0; batch classifier loss: 0.223773; batch adversarial loss: 0.478493\n",
      "epoch 37; iter: 0; batch classifier loss: 0.262286; batch adversarial loss: 0.370567\n",
      "epoch 38; iter: 0; batch classifier loss: 0.308804; batch adversarial loss: 0.446175\n",
      "epoch 39; iter: 0; batch classifier loss: 0.294589; batch adversarial loss: 0.454892\n",
      "epoch 40; iter: 0; batch classifier loss: 0.222060; batch adversarial loss: 0.427560\n",
      "epoch 41; iter: 0; batch classifier loss: 0.217116; batch adversarial loss: 0.457702\n",
      "epoch 42; iter: 0; batch classifier loss: 0.334176; batch adversarial loss: 0.385070\n",
      "epoch 43; iter: 0; batch classifier loss: 0.191542; batch adversarial loss: 0.433658\n",
      "epoch 44; iter: 0; batch classifier loss: 0.301461; batch adversarial loss: 0.421558\n",
      "epoch 45; iter: 0; batch classifier loss: 0.336865; batch adversarial loss: 0.430504\n",
      "epoch 46; iter: 0; batch classifier loss: 0.191900; batch adversarial loss: 0.509452\n",
      "epoch 47; iter: 0; batch classifier loss: 0.249851; batch adversarial loss: 0.399375\n",
      "epoch 48; iter: 0; batch classifier loss: 0.258675; batch adversarial loss: 0.510265\n",
      "epoch 49; iter: 0; batch classifier loss: 0.235544; batch adversarial loss: 0.437604\n",
      "epoch 50; iter: 0; batch classifier loss: 0.204635; batch adversarial loss: 0.447086\n",
      "epoch 51; iter: 0; batch classifier loss: 0.228166; batch adversarial loss: 0.378327\n",
      "epoch 52; iter: 0; batch classifier loss: 0.136101; batch adversarial loss: 0.486858\n",
      "epoch 53; iter: 0; batch classifier loss: 0.259665; batch adversarial loss: 0.479734\n",
      "epoch 54; iter: 0; batch classifier loss: 0.198656; batch adversarial loss: 0.363348\n",
      "epoch 55; iter: 0; batch classifier loss: 0.179644; batch adversarial loss: 0.499310\n",
      "epoch 56; iter: 0; batch classifier loss: 0.225753; batch adversarial loss: 0.470218\n",
      "epoch 57; iter: 0; batch classifier loss: 0.216846; batch adversarial loss: 0.598256\n",
      "epoch 58; iter: 0; batch classifier loss: 0.179554; batch adversarial loss: 0.509005\n",
      "epoch 59; iter: 0; batch classifier loss: 0.215068; batch adversarial loss: 0.382067\n",
      "epoch 60; iter: 0; batch classifier loss: 0.215648; batch adversarial loss: 0.475032\n",
      "epoch 61; iter: 0; batch classifier loss: 0.271706; batch adversarial loss: 0.419492\n",
      "epoch 62; iter: 0; batch classifier loss: 0.177285; batch adversarial loss: 0.508104\n",
      "epoch 63; iter: 0; batch classifier loss: 0.204903; batch adversarial loss: 0.522684\n",
      "epoch 64; iter: 0; batch classifier loss: 0.221367; batch adversarial loss: 0.355849\n",
      "epoch 65; iter: 0; batch classifier loss: 0.274754; batch adversarial loss: 0.471271\n",
      "epoch 66; iter: 0; batch classifier loss: 0.219526; batch adversarial loss: 0.446215\n",
      "epoch 67; iter: 0; batch classifier loss: 0.143620; batch adversarial loss: 0.420151\n",
      "epoch 68; iter: 0; batch classifier loss: 0.243094; batch adversarial loss: 0.407229\n",
      "epoch 69; iter: 0; batch classifier loss: 0.186891; batch adversarial loss: 0.497296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.171831; batch adversarial loss: 0.345620\n",
      "epoch 71; iter: 0; batch classifier loss: 0.166159; batch adversarial loss: 0.522378\n",
      "epoch 72; iter: 0; batch classifier loss: 0.220451; batch adversarial loss: 0.395676\n",
      "epoch 73; iter: 0; batch classifier loss: 0.227902; batch adversarial loss: 0.471777\n",
      "epoch 74; iter: 0; batch classifier loss: 0.148570; batch adversarial loss: 0.459095\n",
      "epoch 75; iter: 0; batch classifier loss: 0.119029; batch adversarial loss: 0.470136\n",
      "epoch 76; iter: 0; batch classifier loss: 0.115043; batch adversarial loss: 0.405515\n",
      "epoch 77; iter: 0; batch classifier loss: 0.088748; batch adversarial loss: 0.404567\n",
      "epoch 78; iter: 0; batch classifier loss: 0.166524; batch adversarial loss: 0.407652\n",
      "epoch 79; iter: 0; batch classifier loss: 0.294048; batch adversarial loss: 0.420205\n",
      "epoch 80; iter: 0; batch classifier loss: 0.162493; batch adversarial loss: 0.384212\n",
      "epoch 81; iter: 0; batch classifier loss: 0.226557; batch adversarial loss: 0.433197\n",
      "epoch 82; iter: 0; batch classifier loss: 0.189550; batch adversarial loss: 0.408043\n",
      "epoch 83; iter: 0; batch classifier loss: 0.141681; batch adversarial loss: 0.433610\n",
      "epoch 84; iter: 0; batch classifier loss: 0.223644; batch adversarial loss: 0.446009\n",
      "epoch 85; iter: 0; batch classifier loss: 0.183987; batch adversarial loss: 0.447147\n",
      "epoch 86; iter: 0; batch classifier loss: 0.142035; batch adversarial loss: 0.331365\n",
      "epoch 87; iter: 0; batch classifier loss: 0.091481; batch adversarial loss: 0.369277\n",
      "epoch 88; iter: 0; batch classifier loss: 0.085797; batch adversarial loss: 0.445726\n",
      "epoch 89; iter: 0; batch classifier loss: 0.070526; batch adversarial loss: 0.511542\n",
      "epoch 90; iter: 0; batch classifier loss: 0.095123; batch adversarial loss: 0.498961\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066348; batch adversarial loss: 0.389706\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050207; batch adversarial loss: 0.518323\n",
      "epoch 93; iter: 0; batch classifier loss: 0.076384; batch adversarial loss: 0.394025\n",
      "epoch 94; iter: 0; batch classifier loss: 0.098748; batch adversarial loss: 0.403999\n",
      "epoch 95; iter: 0; batch classifier loss: 0.121139; batch adversarial loss: 0.467814\n",
      "epoch 96; iter: 0; batch classifier loss: 0.072515; batch adversarial loss: 0.375978\n",
      "epoch 97; iter: 0; batch classifier loss: 0.116435; batch adversarial loss: 0.493549\n",
      "epoch 98; iter: 0; batch classifier loss: 0.083424; batch adversarial loss: 0.409337\n",
      "epoch 99; iter: 0; batch classifier loss: 0.106085; batch adversarial loss: 0.447288\n",
      "epoch 100; iter: 0; batch classifier loss: 0.086209; batch adversarial loss: 0.443455\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063082; batch adversarial loss: 0.574128\n",
      "epoch 102; iter: 0; batch classifier loss: 0.070913; batch adversarial loss: 0.411641\n",
      "epoch 103; iter: 0; batch classifier loss: 0.094932; batch adversarial loss: 0.457389\n",
      "epoch 104; iter: 0; batch classifier loss: 0.093294; batch adversarial loss: 0.485788\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050934; batch adversarial loss: 0.437755\n",
      "epoch 106; iter: 0; batch classifier loss: 0.122229; batch adversarial loss: 0.478140\n",
      "epoch 107; iter: 0; batch classifier loss: 0.085095; batch adversarial loss: 0.473276\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059266; batch adversarial loss: 0.372283\n",
      "epoch 109; iter: 0; batch classifier loss: 0.070083; batch adversarial loss: 0.357187\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069311; batch adversarial loss: 0.531625\n",
      "epoch 111; iter: 0; batch classifier loss: 0.090674; batch adversarial loss: 0.424945\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052035; batch adversarial loss: 0.420461\n",
      "epoch 113; iter: 0; batch classifier loss: 0.095479; batch adversarial loss: 0.371717\n",
      "epoch 114; iter: 0; batch classifier loss: 0.069603; batch adversarial loss: 0.460812\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065455; batch adversarial loss: 0.430419\n",
      "epoch 116; iter: 0; batch classifier loss: 0.099768; batch adversarial loss: 0.547794\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036235; batch adversarial loss: 0.470099\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051823; batch adversarial loss: 0.474508\n",
      "epoch 119; iter: 0; batch classifier loss: 0.061027; batch adversarial loss: 0.463144\n",
      "epoch 120; iter: 0; batch classifier loss: 0.063449; batch adversarial loss: 0.448157\n",
      "epoch 121; iter: 0; batch classifier loss: 0.068975; batch adversarial loss: 0.385934\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049356; batch adversarial loss: 0.410603\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045622; batch adversarial loss: 0.416532\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038750; batch adversarial loss: 0.502036\n",
      "epoch 125; iter: 0; batch classifier loss: 0.064926; batch adversarial loss: 0.315721\n",
      "epoch 126; iter: 0; batch classifier loss: 0.065038; batch adversarial loss: 0.389921\n",
      "epoch 127; iter: 0; batch classifier loss: 0.057566; batch adversarial loss: 0.347605\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035418; batch adversarial loss: 0.454583\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051745; batch adversarial loss: 0.496743\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043567; batch adversarial loss: 0.465860\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028182; batch adversarial loss: 0.368347\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033562; batch adversarial loss: 0.520042\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021385; batch adversarial loss: 0.417165\n",
      "epoch 134; iter: 0; batch classifier loss: 0.067275; batch adversarial loss: 0.428686\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044006; batch adversarial loss: 0.442740\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029416; batch adversarial loss: 0.478721\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018202; batch adversarial loss: 0.428539\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020739; batch adversarial loss: 0.519825\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041778; batch adversarial loss: 0.454617\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037264; batch adversarial loss: 0.446544\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033271; batch adversarial loss: 0.488011\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042805; batch adversarial loss: 0.451057\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034087; batch adversarial loss: 0.524128\n",
      "epoch 144; iter: 0; batch classifier loss: 0.061417; batch adversarial loss: 0.436798\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022033; batch adversarial loss: 0.461415\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026243; batch adversarial loss: 0.404671\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018203; batch adversarial loss: 0.476614\n",
      "epoch 148; iter: 0; batch classifier loss: 0.043332; batch adversarial loss: 0.362539\n",
      "epoch 149; iter: 0; batch classifier loss: 0.073737; batch adversarial loss: 0.344843\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039567; batch adversarial loss: 0.478612\n",
      "epoch 151; iter: 0; batch classifier loss: 0.006339; batch adversarial loss: 0.442785\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013102; batch adversarial loss: 0.454709\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022495; batch adversarial loss: 0.393937\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011696; batch adversarial loss: 0.462964\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020318; batch adversarial loss: 0.400467\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033289; batch adversarial loss: 0.408059\n",
      "epoch 157; iter: 0; batch classifier loss: 0.043226; batch adversarial loss: 0.435924\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029480; batch adversarial loss: 0.484311\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017300; batch adversarial loss: 0.466270\n",
      "epoch 160; iter: 0; batch classifier loss: 0.049558; batch adversarial loss: 0.373109\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026522; batch adversarial loss: 0.438175\n",
      "epoch 162; iter: 0; batch classifier loss: 0.006455; batch adversarial loss: 0.470440\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012851; batch adversarial loss: 0.445485\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026208; batch adversarial loss: 0.475679\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024138; batch adversarial loss: 0.434769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.022795; batch adversarial loss: 0.494364\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011971; batch adversarial loss: 0.547799\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011106; batch adversarial loss: 0.512000\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033641; batch adversarial loss: 0.483140\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012011; batch adversarial loss: 0.350586\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015231; batch adversarial loss: 0.550183\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020780; batch adversarial loss: 0.448762\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010074; batch adversarial loss: 0.520507\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018347; batch adversarial loss: 0.488371\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028527; batch adversarial loss: 0.452772\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007838; batch adversarial loss: 0.416350\n",
      "epoch 177; iter: 0; batch classifier loss: 0.005958; batch adversarial loss: 0.530645\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015879; batch adversarial loss: 0.393922\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010887; batch adversarial loss: 0.419130\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030641; batch adversarial loss: 0.412187\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020396; batch adversarial loss: 0.439121\n",
      "epoch 182; iter: 0; batch classifier loss: 0.004631; batch adversarial loss: 0.473621\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019830; batch adversarial loss: 0.370858\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027192; batch adversarial loss: 0.422576\n",
      "epoch 185; iter: 0; batch classifier loss: 0.004393; batch adversarial loss: 0.431704\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027504; batch adversarial loss: 0.450225\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011700; batch adversarial loss: 0.405274\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013827; batch adversarial loss: 0.386842\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008198; batch adversarial loss: 0.384020\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017689; batch adversarial loss: 0.377973\n",
      "epoch 191; iter: 0; batch classifier loss: 0.003330; batch adversarial loss: 0.442544\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008178; batch adversarial loss: 0.435006\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011905; batch adversarial loss: 0.374941\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009119; batch adversarial loss: 0.428532\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004919; batch adversarial loss: 0.451901\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022778; batch adversarial loss: 0.390539\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013124; batch adversarial loss: 0.409614\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003718; batch adversarial loss: 0.483579\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005903; batch adversarial loss: 0.509110\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693607; batch adversarial loss: 0.604169\n",
      "epoch 1; iter: 0; batch classifier loss: 0.523976; batch adversarial loss: 0.642790\n",
      "epoch 2; iter: 0; batch classifier loss: 0.377539; batch adversarial loss: 0.613227\n",
      "epoch 3; iter: 0; batch classifier loss: 0.471019; batch adversarial loss: 0.614237\n",
      "epoch 4; iter: 0; batch classifier loss: 0.455069; batch adversarial loss: 0.566178\n",
      "epoch 5; iter: 0; batch classifier loss: 0.497571; batch adversarial loss: 0.615170\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575734; batch adversarial loss: 0.662097\n",
      "epoch 7; iter: 0; batch classifier loss: 0.519961; batch adversarial loss: 0.577417\n",
      "epoch 8; iter: 0; batch classifier loss: 0.445469; batch adversarial loss: 0.563649\n",
      "epoch 9; iter: 0; batch classifier loss: 0.438593; batch adversarial loss: 0.492101\n",
      "epoch 10; iter: 0; batch classifier loss: 0.398012; batch adversarial loss: 0.495527\n",
      "epoch 11; iter: 0; batch classifier loss: 0.381975; batch adversarial loss: 0.490159\n",
      "epoch 12; iter: 0; batch classifier loss: 0.281076; batch adversarial loss: 0.451015\n",
      "epoch 13; iter: 0; batch classifier loss: 0.339200; batch adversarial loss: 0.494596\n",
      "epoch 14; iter: 0; batch classifier loss: 0.278247; batch adversarial loss: 0.554372\n",
      "epoch 15; iter: 0; batch classifier loss: 0.191114; batch adversarial loss: 0.490147\n",
      "epoch 16; iter: 0; batch classifier loss: 0.210268; batch adversarial loss: 0.460406\n",
      "epoch 17; iter: 0; batch classifier loss: 0.239075; batch adversarial loss: 0.388281\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246020; batch adversarial loss: 0.465232\n",
      "epoch 19; iter: 0; batch classifier loss: 0.259034; batch adversarial loss: 0.424375\n",
      "epoch 20; iter: 0; batch classifier loss: 0.232699; batch adversarial loss: 0.438570\n",
      "epoch 21; iter: 0; batch classifier loss: 0.155464; batch adversarial loss: 0.437039\n",
      "epoch 22; iter: 0; batch classifier loss: 0.216785; batch adversarial loss: 0.406526\n",
      "epoch 23; iter: 0; batch classifier loss: 0.173161; batch adversarial loss: 0.483750\n",
      "epoch 24; iter: 0; batch classifier loss: 0.131529; batch adversarial loss: 0.498675\n",
      "epoch 25; iter: 0; batch classifier loss: 0.150880; batch adversarial loss: 0.470534\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176754; batch adversarial loss: 0.371914\n",
      "epoch 27; iter: 0; batch classifier loss: 0.198689; batch adversarial loss: 0.413554\n",
      "epoch 28; iter: 0; batch classifier loss: 0.216368; batch adversarial loss: 0.374254\n",
      "epoch 29; iter: 0; batch classifier loss: 0.137087; batch adversarial loss: 0.381598\n",
      "epoch 30; iter: 0; batch classifier loss: 0.162825; batch adversarial loss: 0.434465\n",
      "epoch 31; iter: 0; batch classifier loss: 0.176831; batch adversarial loss: 0.456512\n",
      "epoch 32; iter: 0; batch classifier loss: 0.202237; batch adversarial loss: 0.460543\n",
      "epoch 33; iter: 0; batch classifier loss: 0.150720; batch adversarial loss: 0.467390\n",
      "epoch 34; iter: 0; batch classifier loss: 0.222878; batch adversarial loss: 0.453620\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148918; batch adversarial loss: 0.457926\n",
      "epoch 36; iter: 0; batch classifier loss: 0.123231; batch adversarial loss: 0.498483\n",
      "epoch 37; iter: 0; batch classifier loss: 0.171692; batch adversarial loss: 0.418089\n",
      "epoch 38; iter: 0; batch classifier loss: 0.152670; batch adversarial loss: 0.429416\n",
      "epoch 39; iter: 0; batch classifier loss: 0.130036; batch adversarial loss: 0.460046\n",
      "epoch 40; iter: 0; batch classifier loss: 0.080756; batch adversarial loss: 0.486155\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123339; batch adversarial loss: 0.488697\n",
      "epoch 42; iter: 0; batch classifier loss: 0.126620; batch adversarial loss: 0.468175\n",
      "epoch 43; iter: 0; batch classifier loss: 0.131988; batch adversarial loss: 0.516629\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101663; batch adversarial loss: 0.564035\n",
      "epoch 45; iter: 0; batch classifier loss: 0.121147; batch adversarial loss: 0.468469\n",
      "epoch 46; iter: 0; batch classifier loss: 0.134523; batch adversarial loss: 0.388127\n",
      "epoch 47; iter: 0; batch classifier loss: 0.094384; batch adversarial loss: 0.406643\n",
      "epoch 48; iter: 0; batch classifier loss: 0.141770; batch adversarial loss: 0.371408\n",
      "epoch 49; iter: 0; batch classifier loss: 0.129297; batch adversarial loss: 0.431499\n",
      "epoch 50; iter: 0; batch classifier loss: 0.109256; batch adversarial loss: 0.465004\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081915; batch adversarial loss: 0.447081\n",
      "epoch 52; iter: 0; batch classifier loss: 0.156307; batch adversarial loss: 0.419958\n",
      "epoch 53; iter: 0; batch classifier loss: 0.170238; batch adversarial loss: 0.468697\n",
      "epoch 54; iter: 0; batch classifier loss: 0.177307; batch adversarial loss: 0.426852\n",
      "epoch 55; iter: 0; batch classifier loss: 0.109707; batch adversarial loss: 0.541625\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119940; batch adversarial loss: 0.428401\n",
      "epoch 57; iter: 0; batch classifier loss: 0.128712; batch adversarial loss: 0.456645\n",
      "epoch 58; iter: 0; batch classifier loss: 0.104760; batch adversarial loss: 0.379503\n",
      "epoch 59; iter: 0; batch classifier loss: 0.120688; batch adversarial loss: 0.393164\n",
      "epoch 60; iter: 0; batch classifier loss: 0.110024; batch adversarial loss: 0.571977\n",
      "epoch 61; iter: 0; batch classifier loss: 0.051583; batch adversarial loss: 0.454799\n",
      "epoch 62; iter: 0; batch classifier loss: 0.149006; batch adversarial loss: 0.450053\n",
      "epoch 63; iter: 0; batch classifier loss: 0.090609; batch adversarial loss: 0.540222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.117676; batch adversarial loss: 0.380363\n",
      "epoch 65; iter: 0; batch classifier loss: 0.102135; batch adversarial loss: 0.457374\n",
      "epoch 66; iter: 0; batch classifier loss: 0.110227; batch adversarial loss: 0.373151\n",
      "epoch 67; iter: 0; batch classifier loss: 0.064124; batch adversarial loss: 0.462105\n",
      "epoch 68; iter: 0; batch classifier loss: 0.087378; batch adversarial loss: 0.452214\n",
      "epoch 69; iter: 0; batch classifier loss: 0.144190; batch adversarial loss: 0.378927\n",
      "epoch 70; iter: 0; batch classifier loss: 0.122255; batch adversarial loss: 0.467798\n",
      "epoch 71; iter: 0; batch classifier loss: 0.099751; batch adversarial loss: 0.495752\n",
      "epoch 72; iter: 0; batch classifier loss: 0.090342; batch adversarial loss: 0.528850\n",
      "epoch 73; iter: 0; batch classifier loss: 0.091473; batch adversarial loss: 0.544958\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079838; batch adversarial loss: 0.526244\n",
      "epoch 75; iter: 0; batch classifier loss: 0.092833; batch adversarial loss: 0.394071\n",
      "epoch 76; iter: 0; batch classifier loss: 0.124977; batch adversarial loss: 0.483307\n",
      "epoch 77; iter: 0; batch classifier loss: 0.118646; batch adversarial loss: 0.477951\n",
      "epoch 78; iter: 0; batch classifier loss: 0.110698; batch adversarial loss: 0.380050\n",
      "epoch 79; iter: 0; batch classifier loss: 0.125640; batch adversarial loss: 0.449988\n",
      "epoch 80; iter: 0; batch classifier loss: 0.094732; batch adversarial loss: 0.406700\n",
      "epoch 81; iter: 0; batch classifier loss: 0.116028; batch adversarial loss: 0.378489\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083876; batch adversarial loss: 0.472324\n",
      "epoch 83; iter: 0; batch classifier loss: 0.143704; batch adversarial loss: 0.463646\n",
      "epoch 84; iter: 0; batch classifier loss: 0.074829; batch adversarial loss: 0.477461\n",
      "epoch 85; iter: 0; batch classifier loss: 0.125429; batch adversarial loss: 0.401611\n",
      "epoch 86; iter: 0; batch classifier loss: 0.090119; batch adversarial loss: 0.427141\n",
      "epoch 87; iter: 0; batch classifier loss: 0.092650; batch adversarial loss: 0.436022\n",
      "epoch 88; iter: 0; batch classifier loss: 0.153029; batch adversarial loss: 0.329097\n",
      "epoch 89; iter: 0; batch classifier loss: 0.076661; batch adversarial loss: 0.504051\n",
      "epoch 90; iter: 0; batch classifier loss: 0.117064; batch adversarial loss: 0.477171\n",
      "epoch 91; iter: 0; batch classifier loss: 0.142271; batch adversarial loss: 0.422116\n",
      "epoch 92; iter: 0; batch classifier loss: 0.128779; batch adversarial loss: 0.525071\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072077; batch adversarial loss: 0.510569\n",
      "epoch 94; iter: 0; batch classifier loss: 0.078515; batch adversarial loss: 0.501267\n",
      "epoch 95; iter: 0; batch classifier loss: 0.083230; batch adversarial loss: 0.426599\n",
      "epoch 96; iter: 0; batch classifier loss: 0.124997; batch adversarial loss: 0.394108\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060326; batch adversarial loss: 0.521146\n",
      "epoch 98; iter: 0; batch classifier loss: 0.082279; batch adversarial loss: 0.492409\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052444; batch adversarial loss: 0.515942\n",
      "epoch 100; iter: 0; batch classifier loss: 0.076153; batch adversarial loss: 0.493295\n",
      "epoch 101; iter: 0; batch classifier loss: 0.088912; batch adversarial loss: 0.553032\n",
      "epoch 102; iter: 0; batch classifier loss: 0.082181; batch adversarial loss: 0.435627\n",
      "epoch 103; iter: 0; batch classifier loss: 0.094343; batch adversarial loss: 0.425906\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071521; batch adversarial loss: 0.428742\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057093; batch adversarial loss: 0.428852\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045193; batch adversarial loss: 0.544937\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059920; batch adversarial loss: 0.480632\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045143; batch adversarial loss: 0.541887\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067030; batch adversarial loss: 0.475578\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048237; batch adversarial loss: 0.461718\n",
      "epoch 111; iter: 0; batch classifier loss: 0.052473; batch adversarial loss: 0.550893\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063181; batch adversarial loss: 0.376797\n",
      "epoch 113; iter: 0; batch classifier loss: 0.084838; batch adversarial loss: 0.475567\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029989; batch adversarial loss: 0.458015\n",
      "epoch 115; iter: 0; batch classifier loss: 0.055041; batch adversarial loss: 0.408493\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042955; batch adversarial loss: 0.387045\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067164; batch adversarial loss: 0.385986\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045322; batch adversarial loss: 0.447910\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054098; batch adversarial loss: 0.554200\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028413; batch adversarial loss: 0.401131\n",
      "epoch 121; iter: 0; batch classifier loss: 0.066188; batch adversarial loss: 0.445802\n",
      "epoch 122; iter: 0; batch classifier loss: 0.055598; batch adversarial loss: 0.377464\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048134; batch adversarial loss: 0.539876\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033873; batch adversarial loss: 0.522070\n",
      "epoch 125; iter: 0; batch classifier loss: 0.024567; batch adversarial loss: 0.418022\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039087; batch adversarial loss: 0.439817\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044114; batch adversarial loss: 0.494165\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028942; batch adversarial loss: 0.438314\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035469; batch adversarial loss: 0.476322\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032985; batch adversarial loss: 0.502353\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047625; batch adversarial loss: 0.491581\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026597; batch adversarial loss: 0.416271\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052567; batch adversarial loss: 0.413876\n",
      "epoch 134; iter: 0; batch classifier loss: 0.125271; batch adversarial loss: 0.470338\n",
      "epoch 135; iter: 0; batch classifier loss: 0.062671; batch adversarial loss: 0.419827\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049884; batch adversarial loss: 0.449180\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031998; batch adversarial loss: 0.419728\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022540; batch adversarial loss: 0.445477\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025271; batch adversarial loss: 0.439103\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025646; batch adversarial loss: 0.419696\n",
      "epoch 141; iter: 0; batch classifier loss: 0.014425; batch adversarial loss: 0.397875\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034539; batch adversarial loss: 0.478606\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025643; batch adversarial loss: 0.444443\n",
      "epoch 144; iter: 0; batch classifier loss: 0.023040; batch adversarial loss: 0.582864\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029553; batch adversarial loss: 0.489339\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048140; batch adversarial loss: 0.423859\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010136; batch adversarial loss: 0.447682\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045051; batch adversarial loss: 0.361650\n",
      "epoch 149; iter: 0; batch classifier loss: 0.050370; batch adversarial loss: 0.385150\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021347; batch adversarial loss: 0.513497\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025866; batch adversarial loss: 0.513685\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023016; batch adversarial loss: 0.423738\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008915; batch adversarial loss: 0.433192\n",
      "epoch 154; iter: 0; batch classifier loss: 0.006940; batch adversarial loss: 0.506442\n",
      "epoch 155; iter: 0; batch classifier loss: 0.053675; batch adversarial loss: 0.454740\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035574; batch adversarial loss: 0.457727\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031782; batch adversarial loss: 0.438024\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037691; batch adversarial loss: 0.489294\n",
      "epoch 159; iter: 0; batch classifier loss: 0.053181; batch adversarial loss: 0.487484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.054886; batch adversarial loss: 0.397319\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031959; batch adversarial loss: 0.418162\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016913; batch adversarial loss: 0.435596\n",
      "epoch 163; iter: 0; batch classifier loss: 0.043431; batch adversarial loss: 0.445602\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036343; batch adversarial loss: 0.352708\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022719; batch adversarial loss: 0.320381\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016567; batch adversarial loss: 0.380600\n",
      "epoch 167; iter: 0; batch classifier loss: 0.071511; batch adversarial loss: 0.513428\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023172; batch adversarial loss: 0.460245\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033375; batch adversarial loss: 0.441864\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031930; batch adversarial loss: 0.473065\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007380; batch adversarial loss: 0.480201\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028125; batch adversarial loss: 0.455385\n",
      "epoch 173; iter: 0; batch classifier loss: 0.059572; batch adversarial loss: 0.512432\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018790; batch adversarial loss: 0.514848\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010426; batch adversarial loss: 0.454794\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008916; batch adversarial loss: 0.367289\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016302; batch adversarial loss: 0.422963\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011882; batch adversarial loss: 0.504396\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037153; batch adversarial loss: 0.394125\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021489; batch adversarial loss: 0.473375\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015642; batch adversarial loss: 0.473425\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014879; batch adversarial loss: 0.485853\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011062; batch adversarial loss: 0.495839\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010179; batch adversarial loss: 0.381121\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008851; batch adversarial loss: 0.395193\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005705; batch adversarial loss: 0.421463\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015616; batch adversarial loss: 0.486111\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022941; batch adversarial loss: 0.422588\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016488; batch adversarial loss: 0.502498\n",
      "epoch 190; iter: 0; batch classifier loss: 0.003909; batch adversarial loss: 0.452260\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015368; batch adversarial loss: 0.453348\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008127; batch adversarial loss: 0.502361\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013599; batch adversarial loss: 0.358294\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017481; batch adversarial loss: 0.475604\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006811; batch adversarial loss: 0.502459\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006979; batch adversarial loss: 0.415673\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013708; batch adversarial loss: 0.451243\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008435; batch adversarial loss: 0.406258\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024031; batch adversarial loss: 0.413705\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681570; batch adversarial loss: 0.752968\n",
      "epoch 1; iter: 0; batch classifier loss: 0.459634; batch adversarial loss: 0.722262\n",
      "epoch 2; iter: 0; batch classifier loss: 0.361046; batch adversarial loss: 0.690246\n",
      "epoch 3; iter: 0; batch classifier loss: 0.423143; batch adversarial loss: 0.658621\n",
      "epoch 4; iter: 0; batch classifier loss: 0.346102; batch adversarial loss: 0.650108\n",
      "epoch 5; iter: 0; batch classifier loss: 0.402773; batch adversarial loss: 0.592318\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331104; batch adversarial loss: 0.569591\n",
      "epoch 7; iter: 0; batch classifier loss: 0.255451; batch adversarial loss: 0.526927\n",
      "epoch 8; iter: 0; batch classifier loss: 0.277385; batch adversarial loss: 0.512627\n",
      "epoch 9; iter: 0; batch classifier loss: 0.302392; batch adversarial loss: 0.490252\n",
      "epoch 10; iter: 0; batch classifier loss: 0.281817; batch adversarial loss: 0.485461\n",
      "epoch 11; iter: 0; batch classifier loss: 0.243787; batch adversarial loss: 0.446923\n",
      "epoch 12; iter: 0; batch classifier loss: 0.230935; batch adversarial loss: 0.454862\n",
      "epoch 13; iter: 0; batch classifier loss: 0.346367; batch adversarial loss: 0.411161\n",
      "epoch 14; iter: 0; batch classifier loss: 0.230677; batch adversarial loss: 0.414931\n",
      "epoch 15; iter: 0; batch classifier loss: 0.211767; batch adversarial loss: 0.379675\n",
      "epoch 16; iter: 0; batch classifier loss: 0.191903; batch adversarial loss: 0.443296\n",
      "epoch 17; iter: 0; batch classifier loss: 0.224936; batch adversarial loss: 0.394234\n",
      "epoch 18; iter: 0; batch classifier loss: 0.173960; batch adversarial loss: 0.428869\n",
      "epoch 19; iter: 0; batch classifier loss: 0.221200; batch adversarial loss: 0.408329\n",
      "epoch 20; iter: 0; batch classifier loss: 0.194333; batch adversarial loss: 0.465465\n",
      "epoch 21; iter: 0; batch classifier loss: 0.183431; batch adversarial loss: 0.378920\n",
      "epoch 22; iter: 0; batch classifier loss: 0.181153; batch adversarial loss: 0.490304\n",
      "epoch 23; iter: 0; batch classifier loss: 0.200620; batch adversarial loss: 0.362617\n",
      "epoch 24; iter: 0; batch classifier loss: 0.218029; batch adversarial loss: 0.391717\n",
      "epoch 25; iter: 0; batch classifier loss: 0.210011; batch adversarial loss: 0.470751\n",
      "epoch 26; iter: 0; batch classifier loss: 0.153960; batch adversarial loss: 0.335200\n",
      "epoch 27; iter: 0; batch classifier loss: 0.183758; batch adversarial loss: 0.427906\n",
      "epoch 28; iter: 0; batch classifier loss: 0.124162; batch adversarial loss: 0.366662\n",
      "epoch 29; iter: 0; batch classifier loss: 0.187668; batch adversarial loss: 0.418232\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138091; batch adversarial loss: 0.433984\n",
      "epoch 31; iter: 0; batch classifier loss: 0.165307; batch adversarial loss: 0.411338\n",
      "epoch 32; iter: 0; batch classifier loss: 0.131663; batch adversarial loss: 0.315123\n",
      "epoch 33; iter: 0; batch classifier loss: 0.152283; batch adversarial loss: 0.436188\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142585; batch adversarial loss: 0.381328\n",
      "epoch 35; iter: 0; batch classifier loss: 0.111593; batch adversarial loss: 0.415738\n",
      "epoch 36; iter: 0; batch classifier loss: 0.136279; batch adversarial loss: 0.352306\n",
      "epoch 37; iter: 0; batch classifier loss: 0.124103; batch adversarial loss: 0.403980\n",
      "epoch 38; iter: 0; batch classifier loss: 0.122152; batch adversarial loss: 0.379554\n",
      "epoch 39; iter: 0; batch classifier loss: 0.098138; batch adversarial loss: 0.351239\n",
      "epoch 40; iter: 0; batch classifier loss: 0.083148; batch adversarial loss: 0.415539\n",
      "epoch 41; iter: 0; batch classifier loss: 0.108060; batch adversarial loss: 0.350949\n",
      "epoch 42; iter: 0; batch classifier loss: 0.078297; batch adversarial loss: 0.481979\n",
      "epoch 43; iter: 0; batch classifier loss: 0.091161; batch adversarial loss: 0.326414\n",
      "epoch 44; iter: 0; batch classifier loss: 0.113087; batch adversarial loss: 0.485379\n",
      "epoch 45; iter: 0; batch classifier loss: 0.112035; batch adversarial loss: 0.476051\n",
      "epoch 46; iter: 0; batch classifier loss: 0.161182; batch adversarial loss: 0.419424\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119619; batch adversarial loss: 0.412816\n",
      "epoch 48; iter: 0; batch classifier loss: 0.088122; batch adversarial loss: 0.408141\n",
      "epoch 49; iter: 0; batch classifier loss: 0.126709; batch adversarial loss: 0.404707\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108364; batch adversarial loss: 0.424886\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092105; batch adversarial loss: 0.343311\n",
      "epoch 52; iter: 0; batch classifier loss: 0.067018; batch adversarial loss: 0.472755\n",
      "epoch 53; iter: 0; batch classifier loss: 0.112135; batch adversarial loss: 0.443980\n",
      "epoch 54; iter: 0; batch classifier loss: 0.137133; batch adversarial loss: 0.374279\n",
      "epoch 55; iter: 0; batch classifier loss: 0.103341; batch adversarial loss: 0.461704\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119071; batch adversarial loss: 0.414176\n",
      "epoch 57; iter: 0; batch classifier loss: 0.125044; batch adversarial loss: 0.403118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.070874; batch adversarial loss: 0.413791\n",
      "epoch 59; iter: 0; batch classifier loss: 0.118054; batch adversarial loss: 0.405437\n",
      "epoch 60; iter: 0; batch classifier loss: 0.070455; batch adversarial loss: 0.436038\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093455; batch adversarial loss: 0.368633\n",
      "epoch 62; iter: 0; batch classifier loss: 0.083834; batch adversarial loss: 0.407458\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070296; batch adversarial loss: 0.434676\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076681; batch adversarial loss: 0.527385\n",
      "epoch 65; iter: 0; batch classifier loss: 0.063668; batch adversarial loss: 0.340808\n",
      "epoch 66; iter: 0; batch classifier loss: 0.093709; batch adversarial loss: 0.469498\n",
      "epoch 67; iter: 0; batch classifier loss: 0.048850; batch adversarial loss: 0.421059\n",
      "epoch 68; iter: 0; batch classifier loss: 0.102461; batch adversarial loss: 0.391829\n",
      "epoch 69; iter: 0; batch classifier loss: 0.049817; batch adversarial loss: 0.350724\n",
      "epoch 70; iter: 0; batch classifier loss: 0.063725; batch adversarial loss: 0.340032\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058882; batch adversarial loss: 0.376402\n",
      "epoch 72; iter: 0; batch classifier loss: 0.065634; batch adversarial loss: 0.373272\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047442; batch adversarial loss: 0.485233\n",
      "epoch 74; iter: 0; batch classifier loss: 0.051904; batch adversarial loss: 0.402291\n",
      "epoch 75; iter: 0; batch classifier loss: 0.045670; batch adversarial loss: 0.342182\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069139; batch adversarial loss: 0.481860\n",
      "epoch 77; iter: 0; batch classifier loss: 0.037165; batch adversarial loss: 0.461234\n",
      "epoch 78; iter: 0; batch classifier loss: 0.081507; batch adversarial loss: 0.467342\n",
      "epoch 79; iter: 0; batch classifier loss: 0.047979; batch adversarial loss: 0.414498\n",
      "epoch 80; iter: 0; batch classifier loss: 0.065550; batch adversarial loss: 0.386656\n",
      "epoch 81; iter: 0; batch classifier loss: 0.078524; batch adversarial loss: 0.453448\n",
      "epoch 82; iter: 0; batch classifier loss: 0.108247; batch adversarial loss: 0.359332\n",
      "epoch 83; iter: 0; batch classifier loss: 0.052020; batch adversarial loss: 0.432247\n",
      "epoch 84; iter: 0; batch classifier loss: 0.071050; batch adversarial loss: 0.459619\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070094; batch adversarial loss: 0.409621\n",
      "epoch 86; iter: 0; batch classifier loss: 0.101390; batch adversarial loss: 0.383770\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072630; batch adversarial loss: 0.455010\n",
      "epoch 88; iter: 0; batch classifier loss: 0.068692; batch adversarial loss: 0.408334\n",
      "epoch 89; iter: 0; batch classifier loss: 0.077268; batch adversarial loss: 0.349465\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048138; batch adversarial loss: 0.392687\n",
      "epoch 91; iter: 0; batch classifier loss: 0.036692; batch adversarial loss: 0.391316\n",
      "epoch 92; iter: 0; batch classifier loss: 0.094628; batch adversarial loss: 0.394946\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046441; batch adversarial loss: 0.351809\n",
      "epoch 94; iter: 0; batch classifier loss: 0.082219; batch adversarial loss: 0.378423\n",
      "epoch 95; iter: 0; batch classifier loss: 0.040186; batch adversarial loss: 0.371456\n",
      "epoch 96; iter: 0; batch classifier loss: 0.032943; batch adversarial loss: 0.368461\n",
      "epoch 97; iter: 0; batch classifier loss: 0.080866; batch adversarial loss: 0.437071\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059424; batch adversarial loss: 0.465688\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063921; batch adversarial loss: 0.463531\n",
      "epoch 100; iter: 0; batch classifier loss: 0.063972; batch adversarial loss: 0.371528\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051309; batch adversarial loss: 0.363590\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032320; batch adversarial loss: 0.446619\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066912; batch adversarial loss: 0.433278\n",
      "epoch 104; iter: 0; batch classifier loss: 0.081168; batch adversarial loss: 0.439031\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037818; batch adversarial loss: 0.330230\n",
      "epoch 106; iter: 0; batch classifier loss: 0.072950; batch adversarial loss: 0.401449\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028729; batch adversarial loss: 0.322973\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030553; batch adversarial loss: 0.550385\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047941; batch adversarial loss: 0.382092\n",
      "epoch 110; iter: 0; batch classifier loss: 0.080770; batch adversarial loss: 0.334537\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045655; batch adversarial loss: 0.451345\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033186; batch adversarial loss: 0.402390\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033877; batch adversarial loss: 0.416712\n",
      "epoch 114; iter: 0; batch classifier loss: 0.024973; batch adversarial loss: 0.421161\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053155; batch adversarial loss: 0.399322\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028961; batch adversarial loss: 0.407603\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033309; batch adversarial loss: 0.426478\n",
      "epoch 118; iter: 0; batch classifier loss: 0.055593; batch adversarial loss: 0.450611\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025548; batch adversarial loss: 0.342216\n",
      "epoch 120; iter: 0; batch classifier loss: 0.021990; batch adversarial loss: 0.531211\n",
      "epoch 121; iter: 0; batch classifier loss: 0.020390; batch adversarial loss: 0.476509\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039842; batch adversarial loss: 0.506106\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037966; batch adversarial loss: 0.556152\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048190; batch adversarial loss: 0.399402\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044371; batch adversarial loss: 0.329974\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025721; batch adversarial loss: 0.360807\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046895; batch adversarial loss: 0.471937\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037051; batch adversarial loss: 0.433769\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017810; batch adversarial loss: 0.449266\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037735; batch adversarial loss: 0.421999\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021446; batch adversarial loss: 0.427503\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023139; batch adversarial loss: 0.429067\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034081; batch adversarial loss: 0.519184\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016980; batch adversarial loss: 0.426915\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031704; batch adversarial loss: 0.360711\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041827; batch adversarial loss: 0.474451\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020028; batch adversarial loss: 0.372259\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045262; batch adversarial loss: 0.540344\n",
      "epoch 139; iter: 0; batch classifier loss: 0.053461; batch adversarial loss: 0.476302\n",
      "epoch 140; iter: 0; batch classifier loss: 0.080424; batch adversarial loss: 0.551504\n",
      "epoch 141; iter: 0; batch classifier loss: 0.072035; batch adversarial loss: 0.604722\n",
      "epoch 142; iter: 0; batch classifier loss: 0.152132; batch adversarial loss: 0.765793\n",
      "epoch 143; iter: 0; batch classifier loss: 0.071606; batch adversarial loss: 0.477284\n",
      "epoch 144; iter: 0; batch classifier loss: 0.078772; batch adversarial loss: 0.655411\n",
      "epoch 145; iter: 0; batch classifier loss: 0.113571; batch adversarial loss: 0.524756\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045986; batch adversarial loss: 0.519059\n",
      "epoch 147; iter: 0; batch classifier loss: 0.118995; batch adversarial loss: 0.697962\n",
      "epoch 148; iter: 0; batch classifier loss: 0.086539; batch adversarial loss: 0.560384\n",
      "epoch 149; iter: 0; batch classifier loss: 0.105190; batch adversarial loss: 0.574581\n",
      "epoch 150; iter: 0; batch classifier loss: 0.111139; batch adversarial loss: 0.689441\n",
      "epoch 151; iter: 0; batch classifier loss: 0.137471; batch adversarial loss: 0.650677\n",
      "epoch 152; iter: 0; batch classifier loss: 0.198344; batch adversarial loss: 0.672518\n",
      "epoch 153; iter: 0; batch classifier loss: 0.214249; batch adversarial loss: 0.806357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.107359; batch adversarial loss: 0.602130\n",
      "epoch 155; iter: 0; batch classifier loss: 0.219501; batch adversarial loss: 0.677062\n",
      "epoch 156; iter: 0; batch classifier loss: 0.163618; batch adversarial loss: 0.675746\n",
      "epoch 157; iter: 0; batch classifier loss: 0.117119; batch adversarial loss: 0.627235\n",
      "epoch 158; iter: 0; batch classifier loss: 0.144803; batch adversarial loss: 0.615873\n",
      "epoch 159; iter: 0; batch classifier loss: 0.080099; batch adversarial loss: 0.595291\n",
      "epoch 160; iter: 0; batch classifier loss: 0.094989; batch adversarial loss: 0.483152\n",
      "epoch 161; iter: 0; batch classifier loss: 0.178984; batch adversarial loss: 0.583487\n",
      "epoch 162; iter: 0; batch classifier loss: 0.141830; batch adversarial loss: 0.575305\n",
      "epoch 163; iter: 0; batch classifier loss: 0.084355; batch adversarial loss: 0.456901\n",
      "epoch 164; iter: 0; batch classifier loss: 0.173109; batch adversarial loss: 0.656841\n",
      "epoch 165; iter: 0; batch classifier loss: 0.186746; batch adversarial loss: 0.655106\n",
      "epoch 166; iter: 0; batch classifier loss: 0.233963; batch adversarial loss: 0.649036\n",
      "epoch 167; iter: 0; batch classifier loss: 0.159905; batch adversarial loss: 0.534456\n",
      "epoch 168; iter: 0; batch classifier loss: 0.160608; batch adversarial loss: 0.522654\n",
      "epoch 169; iter: 0; batch classifier loss: 0.195168; batch adversarial loss: 0.591343\n",
      "epoch 170; iter: 0; batch classifier loss: 0.143122; batch adversarial loss: 0.534460\n",
      "epoch 171; iter: 0; batch classifier loss: 0.136987; batch adversarial loss: 0.485211\n",
      "epoch 172; iter: 0; batch classifier loss: 0.185590; batch adversarial loss: 0.572140\n",
      "epoch 173; iter: 0; batch classifier loss: 0.118943; batch adversarial loss: 0.423437\n",
      "epoch 174; iter: 0; batch classifier loss: 0.115652; batch adversarial loss: 0.453747\n",
      "epoch 175; iter: 0; batch classifier loss: 0.171085; batch adversarial loss: 0.548078\n",
      "epoch 176; iter: 0; batch classifier loss: 0.183933; batch adversarial loss: 0.595574\n",
      "epoch 177; iter: 0; batch classifier loss: 0.105232; batch adversarial loss: 0.491900\n",
      "epoch 178; iter: 0; batch classifier loss: 0.117651; batch adversarial loss: 0.498943\n",
      "epoch 179; iter: 0; batch classifier loss: 0.136216; batch adversarial loss: 0.503310\n",
      "epoch 180; iter: 0; batch classifier loss: 0.111235; batch adversarial loss: 0.469627\n",
      "epoch 181; iter: 0; batch classifier loss: 0.075682; batch adversarial loss: 0.430244\n",
      "epoch 182; iter: 0; batch classifier loss: 0.101038; batch adversarial loss: 0.464403\n",
      "epoch 183; iter: 0; batch classifier loss: 0.071563; batch adversarial loss: 0.412277\n",
      "epoch 184; iter: 0; batch classifier loss: 0.101561; batch adversarial loss: 0.416383\n",
      "epoch 185; iter: 0; batch classifier loss: 0.092997; batch adversarial loss: 0.448814\n",
      "epoch 186; iter: 0; batch classifier loss: 0.130870; batch adversarial loss: 0.412685\n",
      "epoch 187; iter: 0; batch classifier loss: 0.110908; batch adversarial loss: 0.471146\n",
      "epoch 188; iter: 0; batch classifier loss: 0.062295; batch adversarial loss: 0.386843\n",
      "epoch 189; iter: 0; batch classifier loss: 0.147546; batch adversarial loss: 0.512766\n",
      "epoch 190; iter: 0; batch classifier loss: 0.063177; batch adversarial loss: 0.499271\n",
      "epoch 191; iter: 0; batch classifier loss: 0.054908; batch adversarial loss: 0.474448\n",
      "epoch 192; iter: 0; batch classifier loss: 0.043387; batch adversarial loss: 0.441375\n",
      "epoch 193; iter: 0; batch classifier loss: 0.044167; batch adversarial loss: 0.400866\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017833; batch adversarial loss: 0.482147\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022366; batch adversarial loss: 0.417757\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013948; batch adversarial loss: 0.382796\n",
      "epoch 197; iter: 0; batch classifier loss: 0.064975; batch adversarial loss: 0.435299\n",
      "epoch 198; iter: 0; batch classifier loss: 0.036903; batch adversarial loss: 0.418968\n",
      "epoch 199; iter: 0; batch classifier loss: 0.036445; batch adversarial loss: 0.473648\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713639; batch adversarial loss: 0.467744\n",
      "epoch 1; iter: 0; batch classifier loss: 0.412746; batch adversarial loss: 0.586709\n",
      "epoch 2; iter: 0; batch classifier loss: 0.370596; batch adversarial loss: 0.532624\n",
      "epoch 3; iter: 0; batch classifier loss: 0.357744; batch adversarial loss: 0.552834\n",
      "epoch 4; iter: 0; batch classifier loss: 0.362037; batch adversarial loss: 0.559780\n",
      "epoch 5; iter: 0; batch classifier loss: 0.373936; batch adversarial loss: 0.492730\n",
      "epoch 6; iter: 0; batch classifier loss: 0.316931; batch adversarial loss: 0.568753\n",
      "epoch 7; iter: 0; batch classifier loss: 0.321695; batch adversarial loss: 0.476131\n",
      "epoch 8; iter: 0; batch classifier loss: 0.329418; batch adversarial loss: 0.549046\n",
      "epoch 9; iter: 0; batch classifier loss: 0.340168; batch adversarial loss: 0.567961\n",
      "epoch 10; iter: 0; batch classifier loss: 0.338664; batch adversarial loss: 0.497337\n",
      "epoch 11; iter: 0; batch classifier loss: 0.405264; batch adversarial loss: 0.582206\n",
      "epoch 12; iter: 0; batch classifier loss: 0.508077; batch adversarial loss: 0.565886\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522243; batch adversarial loss: 0.527326\n",
      "epoch 14; iter: 0; batch classifier loss: 0.435559; batch adversarial loss: 0.540464\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525977; batch adversarial loss: 0.501817\n",
      "epoch 16; iter: 0; batch classifier loss: 0.622150; batch adversarial loss: 0.519033\n",
      "epoch 17; iter: 0; batch classifier loss: 0.403073; batch adversarial loss: 0.431880\n",
      "epoch 18; iter: 0; batch classifier loss: 0.323999; batch adversarial loss: 0.413734\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261356; batch adversarial loss: 0.441721\n",
      "epoch 20; iter: 0; batch classifier loss: 0.221306; batch adversarial loss: 0.470700\n",
      "epoch 21; iter: 0; batch classifier loss: 0.189773; batch adversarial loss: 0.472580\n",
      "epoch 22; iter: 0; batch classifier loss: 0.144077; batch adversarial loss: 0.461023\n",
      "epoch 23; iter: 0; batch classifier loss: 0.141777; batch adversarial loss: 0.540638\n",
      "epoch 24; iter: 0; batch classifier loss: 0.163835; batch adversarial loss: 0.423781\n",
      "epoch 25; iter: 0; batch classifier loss: 0.166092; batch adversarial loss: 0.389078\n",
      "epoch 26; iter: 0; batch classifier loss: 0.149504; batch adversarial loss: 0.435470\n",
      "epoch 27; iter: 0; batch classifier loss: 0.139232; batch adversarial loss: 0.502510\n",
      "epoch 28; iter: 0; batch classifier loss: 0.128111; batch adversarial loss: 0.517815\n",
      "epoch 29; iter: 0; batch classifier loss: 0.134046; batch adversarial loss: 0.463181\n",
      "epoch 30; iter: 0; batch classifier loss: 0.128439; batch adversarial loss: 0.376073\n",
      "epoch 31; iter: 0; batch classifier loss: 0.129691; batch adversarial loss: 0.483798\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181953; batch adversarial loss: 0.420845\n",
      "epoch 33; iter: 0; batch classifier loss: 0.177151; batch adversarial loss: 0.371059\n",
      "epoch 34; iter: 0; batch classifier loss: 0.110452; batch adversarial loss: 0.442029\n",
      "epoch 35; iter: 0; batch classifier loss: 0.124347; batch adversarial loss: 0.454429\n",
      "epoch 36; iter: 0; batch classifier loss: 0.135433; batch adversarial loss: 0.428032\n",
      "epoch 37; iter: 0; batch classifier loss: 0.161968; batch adversarial loss: 0.413911\n",
      "epoch 38; iter: 0; batch classifier loss: 0.101061; batch adversarial loss: 0.523669\n",
      "epoch 39; iter: 0; batch classifier loss: 0.113319; batch adversarial loss: 0.328650\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116487; batch adversarial loss: 0.507340\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106359; batch adversarial loss: 0.388585\n",
      "epoch 42; iter: 0; batch classifier loss: 0.124961; batch adversarial loss: 0.492779\n",
      "epoch 43; iter: 0; batch classifier loss: 0.096661; batch adversarial loss: 0.476457\n",
      "epoch 44; iter: 0; batch classifier loss: 0.086240; batch adversarial loss: 0.490017\n",
      "epoch 45; iter: 0; batch classifier loss: 0.070914; batch adversarial loss: 0.435270\n",
      "epoch 46; iter: 0; batch classifier loss: 0.114556; batch adversarial loss: 0.417615\n",
      "epoch 47; iter: 0; batch classifier loss: 0.076035; batch adversarial loss: 0.450618\n",
      "epoch 48; iter: 0; batch classifier loss: 0.117437; batch adversarial loss: 0.451671\n",
      "epoch 49; iter: 0; batch classifier loss: 0.120787; batch adversarial loss: 0.400181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.080894; batch adversarial loss: 0.428417\n",
      "epoch 51; iter: 0; batch classifier loss: 0.079625; batch adversarial loss: 0.502254\n",
      "epoch 52; iter: 0; batch classifier loss: 0.083859; batch adversarial loss: 0.530008\n",
      "epoch 53; iter: 0; batch classifier loss: 0.097475; batch adversarial loss: 0.608099\n",
      "epoch 54; iter: 0; batch classifier loss: 0.059225; batch adversarial loss: 0.433222\n",
      "epoch 55; iter: 0; batch classifier loss: 0.083489; batch adversarial loss: 0.437154\n",
      "epoch 56; iter: 0; batch classifier loss: 0.052486; batch adversarial loss: 0.529203\n",
      "epoch 57; iter: 0; batch classifier loss: 0.109314; batch adversarial loss: 0.538594\n",
      "epoch 58; iter: 0; batch classifier loss: 0.100806; batch adversarial loss: 0.510771\n",
      "epoch 59; iter: 0; batch classifier loss: 0.071088; batch adversarial loss: 0.481098\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095302; batch adversarial loss: 0.416869\n",
      "epoch 61; iter: 0; batch classifier loss: 0.055860; batch adversarial loss: 0.480233\n",
      "epoch 62; iter: 0; batch classifier loss: 0.067232; batch adversarial loss: 0.507730\n",
      "epoch 63; iter: 0; batch classifier loss: 0.079235; batch adversarial loss: 0.502246\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084787; batch adversarial loss: 0.410567\n",
      "epoch 65; iter: 0; batch classifier loss: 0.057109; batch adversarial loss: 0.423982\n",
      "epoch 66; iter: 0; batch classifier loss: 0.135903; batch adversarial loss: 0.370780\n",
      "epoch 67; iter: 0; batch classifier loss: 0.115901; batch adversarial loss: 0.464388\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096615; batch adversarial loss: 0.494151\n",
      "epoch 69; iter: 0; batch classifier loss: 0.125081; batch adversarial loss: 0.352876\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067705; batch adversarial loss: 0.456580\n",
      "epoch 71; iter: 0; batch classifier loss: 0.097218; batch adversarial loss: 0.403501\n",
      "epoch 72; iter: 0; batch classifier loss: 0.066049; batch adversarial loss: 0.454734\n",
      "epoch 73; iter: 0; batch classifier loss: 0.095034; batch adversarial loss: 0.476064\n",
      "epoch 74; iter: 0; batch classifier loss: 0.030226; batch adversarial loss: 0.508323\n",
      "epoch 75; iter: 0; batch classifier loss: 0.043281; batch adversarial loss: 0.415819\n",
      "epoch 76; iter: 0; batch classifier loss: 0.098873; batch adversarial loss: 0.434280\n",
      "epoch 77; iter: 0; batch classifier loss: 0.060118; batch adversarial loss: 0.459822\n",
      "epoch 78; iter: 0; batch classifier loss: 0.086231; batch adversarial loss: 0.524635\n",
      "epoch 79; iter: 0; batch classifier loss: 0.081918; batch adversarial loss: 0.363450\n",
      "epoch 80; iter: 0; batch classifier loss: 0.072569; batch adversarial loss: 0.470099\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079494; batch adversarial loss: 0.461949\n",
      "epoch 82; iter: 0; batch classifier loss: 0.133224; batch adversarial loss: 0.484476\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064218; batch adversarial loss: 0.385617\n",
      "epoch 84; iter: 0; batch classifier loss: 0.076623; batch adversarial loss: 0.505669\n",
      "epoch 85; iter: 0; batch classifier loss: 0.093276; batch adversarial loss: 0.458915\n",
      "epoch 86; iter: 0; batch classifier loss: 0.087034; batch adversarial loss: 0.435113\n",
      "epoch 87; iter: 0; batch classifier loss: 0.081698; batch adversarial loss: 0.508694\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078732; batch adversarial loss: 0.464195\n",
      "epoch 89; iter: 0; batch classifier loss: 0.100668; batch adversarial loss: 0.446772\n",
      "epoch 90; iter: 0; batch classifier loss: 0.040716; batch adversarial loss: 0.479319\n",
      "epoch 91; iter: 0; batch classifier loss: 0.095458; batch adversarial loss: 0.511179\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051451; batch adversarial loss: 0.414763\n",
      "epoch 93; iter: 0; batch classifier loss: 0.035940; batch adversarial loss: 0.461825\n",
      "epoch 94; iter: 0; batch classifier loss: 0.085444; batch adversarial loss: 0.486736\n",
      "epoch 95; iter: 0; batch classifier loss: 0.065347; batch adversarial loss: 0.360762\n",
      "epoch 96; iter: 0; batch classifier loss: 0.069030; batch adversarial loss: 0.487444\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048005; batch adversarial loss: 0.465250\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055715; batch adversarial loss: 0.412559\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041653; batch adversarial loss: 0.393104\n",
      "epoch 100; iter: 0; batch classifier loss: 0.073406; batch adversarial loss: 0.421166\n",
      "epoch 101; iter: 0; batch classifier loss: 0.045428; batch adversarial loss: 0.534324\n",
      "epoch 102; iter: 0; batch classifier loss: 0.070879; batch adversarial loss: 0.428701\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052352; batch adversarial loss: 0.400011\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062567; batch adversarial loss: 0.410717\n",
      "epoch 105; iter: 0; batch classifier loss: 0.024670; batch adversarial loss: 0.431281\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045079; batch adversarial loss: 0.422703\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032207; batch adversarial loss: 0.547537\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057976; batch adversarial loss: 0.470155\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036849; batch adversarial loss: 0.414944\n",
      "epoch 110; iter: 0; batch classifier loss: 0.077997; batch adversarial loss: 0.384325\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035486; batch adversarial loss: 0.363802\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047077; batch adversarial loss: 0.502951\n",
      "epoch 113; iter: 0; batch classifier loss: 0.022195; batch adversarial loss: 0.398670\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061780; batch adversarial loss: 0.450285\n",
      "epoch 115; iter: 0; batch classifier loss: 0.056524; batch adversarial loss: 0.554507\n",
      "epoch 116; iter: 0; batch classifier loss: 0.076707; batch adversarial loss: 0.463921\n",
      "epoch 117; iter: 0; batch classifier loss: 0.069861; batch adversarial loss: 0.407637\n",
      "epoch 118; iter: 0; batch classifier loss: 0.058195; batch adversarial loss: 0.471331\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065172; batch adversarial loss: 0.388101\n",
      "epoch 120; iter: 0; batch classifier loss: 0.085052; batch adversarial loss: 0.443784\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036412; batch adversarial loss: 0.414737\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030336; batch adversarial loss: 0.340321\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027771; batch adversarial loss: 0.403862\n",
      "epoch 124; iter: 0; batch classifier loss: 0.056070; batch adversarial loss: 0.391039\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041299; batch adversarial loss: 0.406247\n",
      "epoch 126; iter: 0; batch classifier loss: 0.049007; batch adversarial loss: 0.499646\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034277; batch adversarial loss: 0.398082\n",
      "epoch 128; iter: 0; batch classifier loss: 0.065489; batch adversarial loss: 0.479693\n",
      "epoch 129; iter: 0; batch classifier loss: 0.052756; batch adversarial loss: 0.327487\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056704; batch adversarial loss: 0.512118\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038541; batch adversarial loss: 0.438008\n",
      "epoch 132; iter: 0; batch classifier loss: 0.060705; batch adversarial loss: 0.401263\n",
      "epoch 133; iter: 0; batch classifier loss: 0.055650; batch adversarial loss: 0.575954\n",
      "epoch 134; iter: 0; batch classifier loss: 0.081546; batch adversarial loss: 0.442665\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026053; batch adversarial loss: 0.517905\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040155; batch adversarial loss: 0.457828\n",
      "epoch 137; iter: 0; batch classifier loss: 0.070542; batch adversarial loss: 0.391854\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023214; batch adversarial loss: 0.534146\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013723; batch adversarial loss: 0.414812\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038987; batch adversarial loss: 0.444513\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031891; batch adversarial loss: 0.439556\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022500; batch adversarial loss: 0.466191\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040616; batch adversarial loss: 0.442705\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032658; batch adversarial loss: 0.451034\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040689; batch adversarial loss: 0.475991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.049540; batch adversarial loss: 0.472304\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022331; batch adversarial loss: 0.396296\n",
      "epoch 148; iter: 0; batch classifier loss: 0.008362; batch adversarial loss: 0.412365\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024505; batch adversarial loss: 0.414968\n",
      "epoch 150; iter: 0; batch classifier loss: 0.041034; batch adversarial loss: 0.385482\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013019; batch adversarial loss: 0.435846\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044528; batch adversarial loss: 0.444793\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042203; batch adversarial loss: 0.435054\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041390; batch adversarial loss: 0.379790\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042448; batch adversarial loss: 0.406098\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013502; batch adversarial loss: 0.441737\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023435; batch adversarial loss: 0.394349\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020413; batch adversarial loss: 0.462127\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022879; batch adversarial loss: 0.516896\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014683; batch adversarial loss: 0.387638\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026184; batch adversarial loss: 0.464706\n",
      "epoch 162; iter: 0; batch classifier loss: 0.054208; batch adversarial loss: 0.465339\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014052; batch adversarial loss: 0.445451\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020193; batch adversarial loss: 0.420032\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023260; batch adversarial loss: 0.393606\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036376; batch adversarial loss: 0.459947\n",
      "epoch 167; iter: 0; batch classifier loss: 0.027155; batch adversarial loss: 0.460214\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036160; batch adversarial loss: 0.490221\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040333; batch adversarial loss: 0.428286\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014407; batch adversarial loss: 0.533988\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040288; batch adversarial loss: 0.353831\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022442; batch adversarial loss: 0.421948\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019207; batch adversarial loss: 0.389470\n",
      "epoch 174; iter: 0; batch classifier loss: 0.045332; batch adversarial loss: 0.404986\n",
      "epoch 175; iter: 0; batch classifier loss: 0.047570; batch adversarial loss: 0.495059\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023131; batch adversarial loss: 0.451279\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037059; batch adversarial loss: 0.457541\n",
      "epoch 178; iter: 0; batch classifier loss: 0.047859; batch adversarial loss: 0.468210\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024635; batch adversarial loss: 0.441247\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017351; batch adversarial loss: 0.347881\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037587; batch adversarial loss: 0.405799\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023598; batch adversarial loss: 0.417771\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030288; batch adversarial loss: 0.437291\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014303; batch adversarial loss: 0.403135\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011289; batch adversarial loss: 0.429728\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009603; batch adversarial loss: 0.431083\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016641; batch adversarial loss: 0.455339\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012381; batch adversarial loss: 0.416927\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029680; batch adversarial loss: 0.365485\n",
      "epoch 190; iter: 0; batch classifier loss: 0.050737; batch adversarial loss: 0.397545\n",
      "epoch 191; iter: 0; batch classifier loss: 0.047190; batch adversarial loss: 0.348882\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014148; batch adversarial loss: 0.458788\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012693; batch adversarial loss: 0.434368\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006692; batch adversarial loss: 0.454836\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019216; batch adversarial loss: 0.449977\n",
      "epoch 196; iter: 0; batch classifier loss: 0.054226; batch adversarial loss: 0.448648\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012584; batch adversarial loss: 0.486855\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037577; batch adversarial loss: 0.480886\n",
      "epoch 199; iter: 0; batch classifier loss: 0.003794; batch adversarial loss: 0.384739\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699776; batch adversarial loss: 0.772552\n",
      "epoch 1; iter: 0; batch classifier loss: 0.468792; batch adversarial loss: 0.743382\n",
      "epoch 2; iter: 0; batch classifier loss: 0.412385; batch adversarial loss: 0.785903\n",
      "epoch 3; iter: 0; batch classifier loss: 0.334288; batch adversarial loss: 0.730523\n",
      "epoch 4; iter: 0; batch classifier loss: 0.344147; batch adversarial loss: 0.673374\n",
      "epoch 5; iter: 0; batch classifier loss: 0.355759; batch adversarial loss: 0.658469\n",
      "epoch 6; iter: 0; batch classifier loss: 0.289542; batch adversarial loss: 0.645317\n",
      "epoch 7; iter: 0; batch classifier loss: 0.330688; batch adversarial loss: 0.609642\n",
      "epoch 8; iter: 0; batch classifier loss: 0.300110; batch adversarial loss: 0.580507\n",
      "epoch 9; iter: 0; batch classifier loss: 0.314687; batch adversarial loss: 0.555342\n",
      "epoch 10; iter: 0; batch classifier loss: 0.287445; batch adversarial loss: 0.497914\n",
      "epoch 11; iter: 0; batch classifier loss: 0.245359; batch adversarial loss: 0.486532\n",
      "epoch 12; iter: 0; batch classifier loss: 0.255533; batch adversarial loss: 0.446501\n",
      "epoch 13; iter: 0; batch classifier loss: 0.268222; batch adversarial loss: 0.427482\n",
      "epoch 14; iter: 0; batch classifier loss: 0.204303; batch adversarial loss: 0.450507\n",
      "epoch 15; iter: 0; batch classifier loss: 0.231401; batch adversarial loss: 0.444749\n",
      "epoch 16; iter: 0; batch classifier loss: 0.170053; batch adversarial loss: 0.434553\n",
      "epoch 17; iter: 0; batch classifier loss: 0.198501; batch adversarial loss: 0.486451\n",
      "epoch 18; iter: 0; batch classifier loss: 0.191691; batch adversarial loss: 0.389600\n",
      "epoch 19; iter: 0; batch classifier loss: 0.151550; batch adversarial loss: 0.413263\n",
      "epoch 20; iter: 0; batch classifier loss: 0.163133; batch adversarial loss: 0.442970\n",
      "epoch 21; iter: 0; batch classifier loss: 0.193798; batch adversarial loss: 0.340069\n",
      "epoch 22; iter: 0; batch classifier loss: 0.182535; batch adversarial loss: 0.425530\n",
      "epoch 23; iter: 0; batch classifier loss: 0.190187; batch adversarial loss: 0.405214\n",
      "epoch 24; iter: 0; batch classifier loss: 0.216828; batch adversarial loss: 0.460167\n",
      "epoch 25; iter: 0; batch classifier loss: 0.123741; batch adversarial loss: 0.385146\n",
      "epoch 26; iter: 0; batch classifier loss: 0.148793; batch adversarial loss: 0.459653\n",
      "epoch 27; iter: 0; batch classifier loss: 0.157921; batch adversarial loss: 0.474104\n",
      "epoch 28; iter: 0; batch classifier loss: 0.130856; batch adversarial loss: 0.398885\n",
      "epoch 29; iter: 0; batch classifier loss: 0.156983; batch adversarial loss: 0.415406\n",
      "epoch 30; iter: 0; batch classifier loss: 0.158947; batch adversarial loss: 0.420834\n",
      "epoch 31; iter: 0; batch classifier loss: 0.141467; batch adversarial loss: 0.414538\n",
      "epoch 32; iter: 0; batch classifier loss: 0.190765; batch adversarial loss: 0.356031\n",
      "epoch 33; iter: 0; batch classifier loss: 0.089477; batch adversarial loss: 0.444808\n",
      "epoch 34; iter: 0; batch classifier loss: 0.155774; batch adversarial loss: 0.371910\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125356; batch adversarial loss: 0.446618\n",
      "epoch 36; iter: 0; batch classifier loss: 0.123996; batch adversarial loss: 0.351536\n",
      "epoch 37; iter: 0; batch classifier loss: 0.120717; batch adversarial loss: 0.439902\n",
      "epoch 38; iter: 0; batch classifier loss: 0.173649; batch adversarial loss: 0.441986\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106430; batch adversarial loss: 0.316542\n",
      "epoch 40; iter: 0; batch classifier loss: 0.111699; batch adversarial loss: 0.444646\n",
      "epoch 41; iter: 0; batch classifier loss: 0.120220; batch adversarial loss: 0.471846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.127761; batch adversarial loss: 0.363552\n",
      "epoch 43; iter: 0; batch classifier loss: 0.101702; batch adversarial loss: 0.402146\n",
      "epoch 44; iter: 0; batch classifier loss: 0.110980; batch adversarial loss: 0.401467\n",
      "epoch 45; iter: 0; batch classifier loss: 0.100506; batch adversarial loss: 0.440670\n",
      "epoch 46; iter: 0; batch classifier loss: 0.145667; batch adversarial loss: 0.492729\n",
      "epoch 47; iter: 0; batch classifier loss: 0.090413; batch adversarial loss: 0.372092\n",
      "epoch 48; iter: 0; batch classifier loss: 0.093296; batch adversarial loss: 0.438231\n",
      "epoch 49; iter: 0; batch classifier loss: 0.111074; batch adversarial loss: 0.455837\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091788; batch adversarial loss: 0.401279\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083748; batch adversarial loss: 0.409215\n",
      "epoch 52; iter: 0; batch classifier loss: 0.075484; batch adversarial loss: 0.391525\n",
      "epoch 53; iter: 0; batch classifier loss: 0.087337; batch adversarial loss: 0.419643\n",
      "epoch 54; iter: 0; batch classifier loss: 0.082061; batch adversarial loss: 0.401303\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089710; batch adversarial loss: 0.409897\n",
      "epoch 56; iter: 0; batch classifier loss: 0.140261; batch adversarial loss: 0.404117\n",
      "epoch 57; iter: 0; batch classifier loss: 0.108210; batch adversarial loss: 0.450097\n",
      "epoch 58; iter: 0; batch classifier loss: 0.108776; batch adversarial loss: 0.394702\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084013; batch adversarial loss: 0.407789\n",
      "epoch 60; iter: 0; batch classifier loss: 0.052655; batch adversarial loss: 0.480358\n",
      "epoch 61; iter: 0; batch classifier loss: 0.077277; batch adversarial loss: 0.450563\n",
      "epoch 62; iter: 0; batch classifier loss: 0.114329; batch adversarial loss: 0.432640\n",
      "epoch 63; iter: 0; batch classifier loss: 0.082609; batch adversarial loss: 0.367562\n",
      "epoch 64; iter: 0; batch classifier loss: 0.114911; batch adversarial loss: 0.422256\n",
      "epoch 65; iter: 0; batch classifier loss: 0.054940; batch adversarial loss: 0.419822\n",
      "epoch 66; iter: 0; batch classifier loss: 0.058237; batch adversarial loss: 0.347315\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061773; batch adversarial loss: 0.340374\n",
      "epoch 68; iter: 0; batch classifier loss: 0.062650; batch adversarial loss: 0.529461\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061337; batch adversarial loss: 0.368242\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066115; batch adversarial loss: 0.428176\n",
      "epoch 71; iter: 0; batch classifier loss: 0.056745; batch adversarial loss: 0.501845\n",
      "epoch 72; iter: 0; batch classifier loss: 0.043319; batch adversarial loss: 0.410077\n",
      "epoch 73; iter: 0; batch classifier loss: 0.055352; batch adversarial loss: 0.402990\n",
      "epoch 74; iter: 0; batch classifier loss: 0.061307; batch adversarial loss: 0.465358\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075755; batch adversarial loss: 0.447965\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060756; batch adversarial loss: 0.462757\n",
      "epoch 77; iter: 0; batch classifier loss: 0.083993; batch adversarial loss: 0.384135\n",
      "epoch 78; iter: 0; batch classifier loss: 0.043891; batch adversarial loss: 0.428615\n",
      "epoch 79; iter: 0; batch classifier loss: 0.031138; batch adversarial loss: 0.586552\n",
      "epoch 80; iter: 0; batch classifier loss: 0.047211; batch adversarial loss: 0.481501\n",
      "epoch 81; iter: 0; batch classifier loss: 0.036100; batch adversarial loss: 0.490259\n",
      "epoch 82; iter: 0; batch classifier loss: 0.036407; batch adversarial loss: 0.483562\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059707; batch adversarial loss: 0.490180\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046268; batch adversarial loss: 0.458749\n",
      "epoch 85; iter: 0; batch classifier loss: 0.097172; batch adversarial loss: 0.692272\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069943; batch adversarial loss: 0.428870\n",
      "epoch 87; iter: 0; batch classifier loss: 0.145596; batch adversarial loss: 0.703798\n",
      "epoch 88; iter: 0; batch classifier loss: 0.156980; batch adversarial loss: 0.513624\n",
      "epoch 89; iter: 0; batch classifier loss: 0.163027; batch adversarial loss: 0.580480\n",
      "epoch 90; iter: 0; batch classifier loss: 0.141203; batch adversarial loss: 0.639100\n",
      "epoch 91; iter: 0; batch classifier loss: 0.165656; batch adversarial loss: 0.680019\n",
      "epoch 92; iter: 0; batch classifier loss: 0.143178; batch adversarial loss: 0.648143\n",
      "epoch 93; iter: 0; batch classifier loss: 0.079825; batch adversarial loss: 0.514771\n",
      "epoch 94; iter: 0; batch classifier loss: 0.142709; batch adversarial loss: 0.591814\n",
      "epoch 95; iter: 0; batch classifier loss: 0.122763; batch adversarial loss: 0.546515\n",
      "epoch 96; iter: 0; batch classifier loss: 0.103429; batch adversarial loss: 0.520612\n",
      "epoch 97; iter: 0; batch classifier loss: 0.101867; batch adversarial loss: 0.398332\n",
      "epoch 98; iter: 0; batch classifier loss: 0.133331; batch adversarial loss: 0.565978\n",
      "epoch 99; iter: 0; batch classifier loss: 0.098522; batch adversarial loss: 0.452122\n",
      "epoch 100; iter: 0; batch classifier loss: 0.198754; batch adversarial loss: 0.571801\n",
      "epoch 101; iter: 0; batch classifier loss: 0.171457; batch adversarial loss: 0.517483\n",
      "epoch 102; iter: 0; batch classifier loss: 0.161486; batch adversarial loss: 0.515926\n",
      "epoch 103; iter: 0; batch classifier loss: 0.193693; batch adversarial loss: 0.615547\n",
      "epoch 104; iter: 0; batch classifier loss: 0.117142; batch adversarial loss: 0.529717\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056844; batch adversarial loss: 0.419650\n",
      "epoch 106; iter: 0; batch classifier loss: 0.141103; batch adversarial loss: 0.419520\n",
      "epoch 107; iter: 0; batch classifier loss: 0.110578; batch adversarial loss: 0.493423\n",
      "epoch 108; iter: 0; batch classifier loss: 0.115522; batch adversarial loss: 0.479738\n",
      "epoch 109; iter: 0; batch classifier loss: 0.162657; batch adversarial loss: 0.499703\n",
      "epoch 110; iter: 0; batch classifier loss: 0.139311; batch adversarial loss: 0.390928\n",
      "epoch 111; iter: 0; batch classifier loss: 0.215171; batch adversarial loss: 0.529804\n",
      "epoch 112; iter: 0; batch classifier loss: 0.129669; batch adversarial loss: 0.433800\n",
      "epoch 113; iter: 0; batch classifier loss: 0.109370; batch adversarial loss: 0.447337\n",
      "epoch 114; iter: 0; batch classifier loss: 0.090787; batch adversarial loss: 0.454393\n",
      "epoch 115; iter: 0; batch classifier loss: 0.105817; batch adversarial loss: 0.439620\n",
      "epoch 116; iter: 0; batch classifier loss: 0.117819; batch adversarial loss: 0.573734\n",
      "epoch 117; iter: 0; batch classifier loss: 0.117653; batch adversarial loss: 0.424898\n",
      "epoch 118; iter: 0; batch classifier loss: 0.123275; batch adversarial loss: 0.434726\n",
      "epoch 119; iter: 0; batch classifier loss: 0.075020; batch adversarial loss: 0.505601\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028577; batch adversarial loss: 0.470123\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041447; batch adversarial loss: 0.445986\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030939; batch adversarial loss: 0.448710\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045052; batch adversarial loss: 0.580846\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044678; batch adversarial loss: 0.483427\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051031; batch adversarial loss: 0.326669\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021196; batch adversarial loss: 0.382125\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026410; batch adversarial loss: 0.415331\n",
      "epoch 128; iter: 0; batch classifier loss: 0.084018; batch adversarial loss: 0.311528\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042688; batch adversarial loss: 0.370072\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040895; batch adversarial loss: 0.368696\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029451; batch adversarial loss: 0.405342\n",
      "epoch 132; iter: 0; batch classifier loss: 0.089658; batch adversarial loss: 0.416303\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038401; batch adversarial loss: 0.451541\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018398; batch adversarial loss: 0.419218\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038763; batch adversarial loss: 0.452853\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037891; batch adversarial loss: 0.521322\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036531; batch adversarial loss: 0.442604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.050006; batch adversarial loss: 0.383469\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033559; batch adversarial loss: 0.515355\n",
      "epoch 140; iter: 0; batch classifier loss: 0.052797; batch adversarial loss: 0.437563\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048656; batch adversarial loss: 0.485028\n",
      "epoch 142; iter: 0; batch classifier loss: 0.054070; batch adversarial loss: 0.443846\n",
      "epoch 143; iter: 0; batch classifier loss: 0.061356; batch adversarial loss: 0.438153\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029305; batch adversarial loss: 0.444604\n",
      "epoch 145; iter: 0; batch classifier loss: 0.111182; batch adversarial loss: 0.389371\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031660; batch adversarial loss: 0.460513\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040629; batch adversarial loss: 0.412713\n",
      "epoch 148; iter: 0; batch classifier loss: 0.070042; batch adversarial loss: 0.521630\n",
      "epoch 149; iter: 0; batch classifier loss: 0.059709; batch adversarial loss: 0.307184\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025385; batch adversarial loss: 0.459736\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023500; batch adversarial loss: 0.507539\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027611; batch adversarial loss: 0.562347\n",
      "epoch 153; iter: 0; batch classifier loss: 0.069588; batch adversarial loss: 0.441999\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019204; batch adversarial loss: 0.464043\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037991; batch adversarial loss: 0.449344\n",
      "epoch 156; iter: 0; batch classifier loss: 0.047168; batch adversarial loss: 0.485483\n",
      "epoch 157; iter: 0; batch classifier loss: 0.050423; batch adversarial loss: 0.471752\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038622; batch adversarial loss: 0.416212\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029597; batch adversarial loss: 0.499942\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028279; batch adversarial loss: 0.506302\n",
      "epoch 161; iter: 0; batch classifier loss: 0.047545; batch adversarial loss: 0.456812\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046985; batch adversarial loss: 0.457778\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024542; batch adversarial loss: 0.503655\n",
      "epoch 164; iter: 0; batch classifier loss: 0.080131; batch adversarial loss: 0.467771\n",
      "epoch 165; iter: 0; batch classifier loss: 0.106458; batch adversarial loss: 0.438099\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030493; batch adversarial loss: 0.460115\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034045; batch adversarial loss: 0.455791\n",
      "epoch 168; iter: 0; batch classifier loss: 0.047297; batch adversarial loss: 0.445254\n",
      "epoch 169; iter: 0; batch classifier loss: 0.042406; batch adversarial loss: 0.470258\n",
      "epoch 170; iter: 0; batch classifier loss: 0.041066; batch adversarial loss: 0.468737\n",
      "epoch 171; iter: 0; batch classifier loss: 0.057082; batch adversarial loss: 0.328347\n",
      "epoch 172; iter: 0; batch classifier loss: 0.045994; batch adversarial loss: 0.481171\n",
      "epoch 173; iter: 0; batch classifier loss: 0.068723; batch adversarial loss: 0.468054\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032914; batch adversarial loss: 0.551638\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039699; batch adversarial loss: 0.482067\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008395; batch adversarial loss: 0.438469\n",
      "epoch 177; iter: 0; batch classifier loss: 0.069154; batch adversarial loss: 0.402454\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012256; batch adversarial loss: 0.526198\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034299; batch adversarial loss: 0.530007\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040674; batch adversarial loss: 0.485705\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037550; batch adversarial loss: 0.425641\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010773; batch adversarial loss: 0.480080\n",
      "epoch 183; iter: 0; batch classifier loss: 0.049495; batch adversarial loss: 0.499727\n",
      "epoch 184; iter: 0; batch classifier loss: 0.079151; batch adversarial loss: 0.381811\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013714; batch adversarial loss: 0.427101\n",
      "epoch 186; iter: 0; batch classifier loss: 0.042629; batch adversarial loss: 0.353566\n",
      "epoch 187; iter: 0; batch classifier loss: 0.041364; batch adversarial loss: 0.404595\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028759; batch adversarial loss: 0.412872\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015692; batch adversarial loss: 0.471109\n",
      "epoch 190; iter: 0; batch classifier loss: 0.039760; batch adversarial loss: 0.338426\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031852; batch adversarial loss: 0.414626\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022506; batch adversarial loss: 0.473791\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012046; batch adversarial loss: 0.330337\n",
      "epoch 194; iter: 0; batch classifier loss: 0.050886; batch adversarial loss: 0.397585\n",
      "epoch 195; iter: 0; batch classifier loss: 0.032590; batch adversarial loss: 0.500694\n",
      "epoch 196; iter: 0; batch classifier loss: 0.063166; batch adversarial loss: 0.414293\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027091; batch adversarial loss: 0.376202\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025152; batch adversarial loss: 0.358363\n",
      "epoch 199; iter: 0; batch classifier loss: 0.038264; batch adversarial loss: 0.384678\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725413; batch adversarial loss: 0.544272\n",
      "epoch 1; iter: 0; batch classifier loss: 0.465151; batch adversarial loss: 0.592353\n",
      "epoch 2; iter: 0; batch classifier loss: 0.332244; batch adversarial loss: 0.584627\n",
      "epoch 3; iter: 0; batch classifier loss: 0.360379; batch adversarial loss: 0.550485\n",
      "epoch 4; iter: 0; batch classifier loss: 0.270736; batch adversarial loss: 0.550343\n",
      "epoch 5; iter: 0; batch classifier loss: 0.279188; batch adversarial loss: 0.502829\n",
      "epoch 6; iter: 0; batch classifier loss: 0.293318; batch adversarial loss: 0.503856\n",
      "epoch 7; iter: 0; batch classifier loss: 0.242407; batch adversarial loss: 0.505832\n",
      "epoch 8; iter: 0; batch classifier loss: 0.247009; batch adversarial loss: 0.521479\n",
      "epoch 9; iter: 0; batch classifier loss: 0.338932; batch adversarial loss: 0.483776\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269261; batch adversarial loss: 0.530547\n",
      "epoch 11; iter: 0; batch classifier loss: 0.257286; batch adversarial loss: 0.463398\n",
      "epoch 12; iter: 0; batch classifier loss: 0.305016; batch adversarial loss: 0.527618\n",
      "epoch 13; iter: 0; batch classifier loss: 0.222219; batch adversarial loss: 0.545768\n",
      "epoch 14; iter: 0; batch classifier loss: 0.223520; batch adversarial loss: 0.500679\n",
      "epoch 15; iter: 0; batch classifier loss: 0.217172; batch adversarial loss: 0.538434\n",
      "epoch 16; iter: 0; batch classifier loss: 0.220208; batch adversarial loss: 0.537144\n",
      "epoch 17; iter: 0; batch classifier loss: 0.247889; batch adversarial loss: 0.483064\n",
      "epoch 18; iter: 0; batch classifier loss: 0.260290; batch adversarial loss: 0.557255\n",
      "epoch 19; iter: 0; batch classifier loss: 0.185493; batch adversarial loss: 0.534170\n",
      "epoch 20; iter: 0; batch classifier loss: 0.170095; batch adversarial loss: 0.444745\n",
      "epoch 21; iter: 0; batch classifier loss: 0.309125; batch adversarial loss: 0.609363\n",
      "epoch 22; iter: 0; batch classifier loss: 0.258625; batch adversarial loss: 0.476929\n",
      "epoch 23; iter: 0; batch classifier loss: 0.232690; batch adversarial loss: 0.493152\n",
      "epoch 24; iter: 0; batch classifier loss: 0.265193; batch adversarial loss: 0.503033\n",
      "epoch 25; iter: 0; batch classifier loss: 0.323691; batch adversarial loss: 0.486281\n",
      "epoch 26; iter: 0; batch classifier loss: 0.348831; batch adversarial loss: 0.521201\n",
      "epoch 27; iter: 0; batch classifier loss: 0.391442; batch adversarial loss: 0.452738\n",
      "epoch 28; iter: 0; batch classifier loss: 0.127077; batch adversarial loss: 0.465059\n",
      "epoch 29; iter: 0; batch classifier loss: 0.113925; batch adversarial loss: 0.435312\n",
      "epoch 30; iter: 0; batch classifier loss: 0.118076; batch adversarial loss: 0.444972\n",
      "epoch 31; iter: 0; batch classifier loss: 0.112742; batch adversarial loss: 0.409143\n",
      "epoch 32; iter: 0; batch classifier loss: 0.125538; batch adversarial loss: 0.454365\n",
      "epoch 33; iter: 0; batch classifier loss: 0.148667; batch adversarial loss: 0.438117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.086685; batch adversarial loss: 0.422101\n",
      "epoch 35; iter: 0; batch classifier loss: 0.124420; batch adversarial loss: 0.388889\n",
      "epoch 36; iter: 0; batch classifier loss: 0.093393; batch adversarial loss: 0.400307\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111204; batch adversarial loss: 0.452858\n",
      "epoch 38; iter: 0; batch classifier loss: 0.082146; batch adversarial loss: 0.529845\n",
      "epoch 39; iter: 0; batch classifier loss: 0.099986; batch adversarial loss: 0.481833\n",
      "epoch 40; iter: 0; batch classifier loss: 0.072766; batch adversarial loss: 0.511212\n",
      "epoch 41; iter: 0; batch classifier loss: 0.110351; batch adversarial loss: 0.497610\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110841; batch adversarial loss: 0.402051\n",
      "epoch 43; iter: 0; batch classifier loss: 0.100576; batch adversarial loss: 0.425849\n",
      "epoch 44; iter: 0; batch classifier loss: 0.057081; batch adversarial loss: 0.529719\n",
      "epoch 45; iter: 0; batch classifier loss: 0.070726; batch adversarial loss: 0.469979\n",
      "epoch 46; iter: 0; batch classifier loss: 0.087615; batch adversarial loss: 0.413808\n",
      "epoch 47; iter: 0; batch classifier loss: 0.063547; batch adversarial loss: 0.502442\n",
      "epoch 48; iter: 0; batch classifier loss: 0.071834; batch adversarial loss: 0.524988\n",
      "epoch 49; iter: 0; batch classifier loss: 0.046525; batch adversarial loss: 0.550739\n",
      "epoch 50; iter: 0; batch classifier loss: 0.056985; batch adversarial loss: 0.415461\n",
      "epoch 51; iter: 0; batch classifier loss: 0.082034; batch adversarial loss: 0.383752\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096648; batch adversarial loss: 0.530025\n",
      "epoch 53; iter: 0; batch classifier loss: 0.069339; batch adversarial loss: 0.391247\n",
      "epoch 54; iter: 0; batch classifier loss: 0.041483; batch adversarial loss: 0.479934\n",
      "epoch 55; iter: 0; batch classifier loss: 0.085398; batch adversarial loss: 0.391336\n",
      "epoch 56; iter: 0; batch classifier loss: 0.049124; batch adversarial loss: 0.378420\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073127; batch adversarial loss: 0.467814\n",
      "epoch 58; iter: 0; batch classifier loss: 0.118574; batch adversarial loss: 0.417582\n",
      "epoch 59; iter: 0; batch classifier loss: 0.119195; batch adversarial loss: 0.464976\n",
      "epoch 60; iter: 0; batch classifier loss: 0.066076; batch adversarial loss: 0.423081\n",
      "epoch 61; iter: 0; batch classifier loss: 0.072336; batch adversarial loss: 0.424629\n",
      "epoch 62; iter: 0; batch classifier loss: 0.071645; batch adversarial loss: 0.471080\n",
      "epoch 63; iter: 0; batch classifier loss: 0.079156; batch adversarial loss: 0.462098\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073897; batch adversarial loss: 0.433393\n",
      "epoch 65; iter: 0; batch classifier loss: 0.073596; batch adversarial loss: 0.472725\n",
      "epoch 66; iter: 0; batch classifier loss: 0.071601; batch adversarial loss: 0.502140\n",
      "epoch 67; iter: 0; batch classifier loss: 0.113743; batch adversarial loss: 0.370865\n",
      "epoch 68; iter: 0; batch classifier loss: 0.057533; batch adversarial loss: 0.489935\n",
      "epoch 69; iter: 0; batch classifier loss: 0.063954; batch adversarial loss: 0.405909\n",
      "epoch 70; iter: 0; batch classifier loss: 0.053775; batch adversarial loss: 0.488714\n",
      "epoch 71; iter: 0; batch classifier loss: 0.044373; batch adversarial loss: 0.424824\n",
      "epoch 72; iter: 0; batch classifier loss: 0.075766; batch adversarial loss: 0.430577\n",
      "epoch 73; iter: 0; batch classifier loss: 0.060923; batch adversarial loss: 0.561041\n",
      "epoch 74; iter: 0; batch classifier loss: 0.073173; batch adversarial loss: 0.405470\n",
      "epoch 75; iter: 0; batch classifier loss: 0.051244; batch adversarial loss: 0.541026\n",
      "epoch 76; iter: 0; batch classifier loss: 0.039272; batch adversarial loss: 0.479037\n",
      "epoch 77; iter: 0; batch classifier loss: 0.040669; batch adversarial loss: 0.447955\n",
      "epoch 78; iter: 0; batch classifier loss: 0.042920; batch adversarial loss: 0.450245\n",
      "epoch 79; iter: 0; batch classifier loss: 0.036040; batch adversarial loss: 0.410617\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067638; batch adversarial loss: 0.413548\n",
      "epoch 81; iter: 0; batch classifier loss: 0.056987; batch adversarial loss: 0.495590\n",
      "epoch 82; iter: 0; batch classifier loss: 0.094808; batch adversarial loss: 0.422743\n",
      "epoch 83; iter: 0; batch classifier loss: 0.075445; batch adversarial loss: 0.431821\n",
      "epoch 84; iter: 0; batch classifier loss: 0.043671; batch adversarial loss: 0.480768\n",
      "epoch 85; iter: 0; batch classifier loss: 0.048291; batch adversarial loss: 0.533895\n",
      "epoch 86; iter: 0; batch classifier loss: 0.082112; batch adversarial loss: 0.455540\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048719; batch adversarial loss: 0.542478\n",
      "epoch 88; iter: 0; batch classifier loss: 0.028442; batch adversarial loss: 0.506170\n",
      "epoch 89; iter: 0; batch classifier loss: 0.064098; batch adversarial loss: 0.454285\n",
      "epoch 90; iter: 0; batch classifier loss: 0.044418; batch adversarial loss: 0.434901\n",
      "epoch 91; iter: 0; batch classifier loss: 0.071237; batch adversarial loss: 0.431813\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057749; batch adversarial loss: 0.415769\n",
      "epoch 93; iter: 0; batch classifier loss: 0.075029; batch adversarial loss: 0.451896\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066554; batch adversarial loss: 0.414012\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066510; batch adversarial loss: 0.546520\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063492; batch adversarial loss: 0.436960\n",
      "epoch 97; iter: 0; batch classifier loss: 0.080046; batch adversarial loss: 0.443582\n",
      "epoch 98; iter: 0; batch classifier loss: 0.040694; batch adversarial loss: 0.414135\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045875; batch adversarial loss: 0.480545\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048470; batch adversarial loss: 0.567798\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055647; batch adversarial loss: 0.508008\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032660; batch adversarial loss: 0.486659\n",
      "epoch 103; iter: 0; batch classifier loss: 0.089062; batch adversarial loss: 0.472469\n",
      "epoch 104; iter: 0; batch classifier loss: 0.090587; batch adversarial loss: 0.438730\n",
      "epoch 105; iter: 0; batch classifier loss: 0.063643; batch adversarial loss: 0.481913\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039049; batch adversarial loss: 0.380840\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063596; batch adversarial loss: 0.534984\n",
      "epoch 108; iter: 0; batch classifier loss: 0.026766; batch adversarial loss: 0.538170\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043892; batch adversarial loss: 0.456726\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069131; batch adversarial loss: 0.531115\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033682; batch adversarial loss: 0.536594\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057479; batch adversarial loss: 0.435175\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039502; batch adversarial loss: 0.422877\n",
      "epoch 114; iter: 0; batch classifier loss: 0.064442; batch adversarial loss: 0.401892\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070143; batch adversarial loss: 0.521000\n",
      "epoch 116; iter: 0; batch classifier loss: 0.080186; batch adversarial loss: 0.427190\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041271; batch adversarial loss: 0.415594\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045233; batch adversarial loss: 0.383745\n",
      "epoch 119; iter: 0; batch classifier loss: 0.081436; batch adversarial loss: 0.413785\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032085; batch adversarial loss: 0.426572\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053570; batch adversarial loss: 0.472480\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066366; batch adversarial loss: 0.508878\n",
      "epoch 123; iter: 0; batch classifier loss: 0.071605; batch adversarial loss: 0.452923\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041570; batch adversarial loss: 0.458319\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035128; batch adversarial loss: 0.355559\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030338; batch adversarial loss: 0.371736\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043342; batch adversarial loss: 0.437890\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017867; batch adversarial loss: 0.448974\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020572; batch adversarial loss: 0.466023\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035424; batch adversarial loss: 0.402716\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035914; batch adversarial loss: 0.378050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.055362; batch adversarial loss: 0.443752\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043599; batch adversarial loss: 0.390519\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026219; batch adversarial loss: 0.454419\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035533; batch adversarial loss: 0.440811\n",
      "epoch 136; iter: 0; batch classifier loss: 0.046736; batch adversarial loss: 0.461005\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034449; batch adversarial loss: 0.430269\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040344; batch adversarial loss: 0.421805\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030431; batch adversarial loss: 0.419931\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029165; batch adversarial loss: 0.549190\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030971; batch adversarial loss: 0.418453\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041011; batch adversarial loss: 0.528679\n",
      "epoch 143; iter: 0; batch classifier loss: 0.017541; batch adversarial loss: 0.418857\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018704; batch adversarial loss: 0.402133\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040731; batch adversarial loss: 0.386308\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021774; batch adversarial loss: 0.505326\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013127; batch adversarial loss: 0.442903\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027998; batch adversarial loss: 0.360810\n",
      "epoch 149; iter: 0; batch classifier loss: 0.050841; batch adversarial loss: 0.410746\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012368; batch adversarial loss: 0.470751\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031356; batch adversarial loss: 0.374865\n",
      "epoch 152; iter: 0; batch classifier loss: 0.043239; batch adversarial loss: 0.405423\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017673; batch adversarial loss: 0.420657\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043884; batch adversarial loss: 0.490080\n",
      "epoch 155; iter: 0; batch classifier loss: 0.051632; batch adversarial loss: 0.478644\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013491; batch adversarial loss: 0.509851\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029682; batch adversarial loss: 0.383395\n",
      "epoch 158; iter: 0; batch classifier loss: 0.046413; batch adversarial loss: 0.370475\n",
      "epoch 159; iter: 0; batch classifier loss: 0.007876; batch adversarial loss: 0.503530\n",
      "epoch 160; iter: 0; batch classifier loss: 0.040086; batch adversarial loss: 0.482885\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029278; batch adversarial loss: 0.442491\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031869; batch adversarial loss: 0.471505\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025354; batch adversarial loss: 0.428637\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026021; batch adversarial loss: 0.397522\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040448; batch adversarial loss: 0.455049\n",
      "epoch 166; iter: 0; batch classifier loss: 0.054743; batch adversarial loss: 0.386664\n",
      "epoch 167; iter: 0; batch classifier loss: 0.040543; batch adversarial loss: 0.440719\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019390; batch adversarial loss: 0.509869\n",
      "epoch 169; iter: 0; batch classifier loss: 0.039530; batch adversarial loss: 0.383732\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038853; batch adversarial loss: 0.462255\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040858; batch adversarial loss: 0.433236\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021179; batch adversarial loss: 0.466933\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022059; batch adversarial loss: 0.476243\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015287; batch adversarial loss: 0.544909\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008428; batch adversarial loss: 0.511789\n",
      "epoch 176; iter: 0; batch classifier loss: 0.006084; batch adversarial loss: 0.527453\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034964; batch adversarial loss: 0.458217\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027398; batch adversarial loss: 0.482267\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014888; batch adversarial loss: 0.377836\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029975; batch adversarial loss: 0.458947\n",
      "epoch 181; iter: 0; batch classifier loss: 0.031744; batch adversarial loss: 0.404870\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025823; batch adversarial loss: 0.365564\n",
      "epoch 183; iter: 0; batch classifier loss: 0.051574; batch adversarial loss: 0.389153\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026980; batch adversarial loss: 0.479059\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038204; batch adversarial loss: 0.415657\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008109; batch adversarial loss: 0.457076\n",
      "epoch 187; iter: 0; batch classifier loss: 0.056411; batch adversarial loss: 0.542515\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028173; batch adversarial loss: 0.379238\n",
      "epoch 189; iter: 0; batch classifier loss: 0.043555; batch adversarial loss: 0.382995\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009854; batch adversarial loss: 0.477733\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025140; batch adversarial loss: 0.485301\n",
      "epoch 192; iter: 0; batch classifier loss: 0.003621; batch adversarial loss: 0.426607\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017865; batch adversarial loss: 0.367648\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028961; batch adversarial loss: 0.483202\n",
      "epoch 195; iter: 0; batch classifier loss: 0.040304; batch adversarial loss: 0.393204\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007047; batch adversarial loss: 0.472055\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011355; batch adversarial loss: 0.529803\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020914; batch adversarial loss: 0.514498\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018662; batch adversarial loss: 0.460003\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711501; batch adversarial loss: 1.035563\n",
      "epoch 1; iter: 0; batch classifier loss: 0.835237; batch adversarial loss: 1.297188\n",
      "epoch 2; iter: 0; batch classifier loss: 1.026771; batch adversarial loss: 1.220237\n",
      "epoch 3; iter: 0; batch classifier loss: 1.135962; batch adversarial loss: 1.153405\n",
      "epoch 4; iter: 0; batch classifier loss: 1.261752; batch adversarial loss: 1.105387\n",
      "epoch 5; iter: 0; batch classifier loss: 1.114633; batch adversarial loss: 0.943049\n",
      "epoch 6; iter: 0; batch classifier loss: 0.966392; batch adversarial loss: 0.858577\n",
      "epoch 7; iter: 0; batch classifier loss: 0.927402; batch adversarial loss: 0.781422\n",
      "epoch 8; iter: 0; batch classifier loss: 0.860054; batch adversarial loss: 0.699967\n",
      "epoch 9; iter: 0; batch classifier loss: 0.739066; batch adversarial loss: 0.703050\n",
      "epoch 10; iter: 0; batch classifier loss: 0.621721; batch adversarial loss: 0.575515\n",
      "epoch 11; iter: 0; batch classifier loss: 0.630010; batch adversarial loss: 0.587019\n",
      "epoch 12; iter: 0; batch classifier loss: 0.534036; batch adversarial loss: 0.564156\n",
      "epoch 13; iter: 0; batch classifier loss: 0.451981; batch adversarial loss: 0.518455\n",
      "epoch 14; iter: 0; batch classifier loss: 0.349127; batch adversarial loss: 0.505005\n",
      "epoch 15; iter: 0; batch classifier loss: 0.363540; batch adversarial loss: 0.559213\n",
      "epoch 16; iter: 0; batch classifier loss: 0.244809; batch adversarial loss: 0.561082\n",
      "epoch 17; iter: 0; batch classifier loss: 0.273932; batch adversarial loss: 0.488227\n",
      "epoch 18; iter: 0; batch classifier loss: 0.273298; batch adversarial loss: 0.501042\n",
      "epoch 19; iter: 0; batch classifier loss: 0.228074; batch adversarial loss: 0.518596\n",
      "epoch 20; iter: 0; batch classifier loss: 0.283439; batch adversarial loss: 0.501435\n",
      "epoch 21; iter: 0; batch classifier loss: 0.184190; batch adversarial loss: 0.458181\n",
      "epoch 22; iter: 0; batch classifier loss: 0.259844; batch adversarial loss: 0.521074\n",
      "epoch 23; iter: 0; batch classifier loss: 0.213830; batch adversarial loss: 0.489255\n",
      "epoch 24; iter: 0; batch classifier loss: 0.261881; batch adversarial loss: 0.494123\n",
      "epoch 25; iter: 0; batch classifier loss: 0.235508; batch adversarial loss: 0.508398\n",
      "epoch 26; iter: 0; batch classifier loss: 0.258331; batch adversarial loss: 0.447281\n",
      "epoch 27; iter: 0; batch classifier loss: 0.164257; batch adversarial loss: 0.461362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.354271; batch adversarial loss: 0.430754\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210252; batch adversarial loss: 0.535071\n",
      "epoch 30; iter: 0; batch classifier loss: 0.173353; batch adversarial loss: 0.470551\n",
      "epoch 31; iter: 0; batch classifier loss: 0.238857; batch adversarial loss: 0.470174\n",
      "epoch 32; iter: 0; batch classifier loss: 0.204939; batch adversarial loss: 0.430573\n",
      "epoch 33; iter: 0; batch classifier loss: 0.147261; batch adversarial loss: 0.512082\n",
      "epoch 34; iter: 0; batch classifier loss: 0.186065; batch adversarial loss: 0.447387\n",
      "epoch 35; iter: 0; batch classifier loss: 0.236157; batch adversarial loss: 0.416045\n",
      "epoch 36; iter: 0; batch classifier loss: 0.217532; batch adversarial loss: 0.431674\n",
      "epoch 37; iter: 0; batch classifier loss: 0.170162; batch adversarial loss: 0.385908\n",
      "epoch 38; iter: 0; batch classifier loss: 0.235914; batch adversarial loss: 0.525289\n",
      "epoch 39; iter: 0; batch classifier loss: 0.195782; batch adversarial loss: 0.546281\n",
      "epoch 40; iter: 0; batch classifier loss: 0.163211; batch adversarial loss: 0.517762\n",
      "epoch 41; iter: 0; batch classifier loss: 0.146490; batch adversarial loss: 0.509028\n",
      "epoch 42; iter: 0; batch classifier loss: 0.178830; batch adversarial loss: 0.490184\n",
      "epoch 43; iter: 0; batch classifier loss: 0.155181; batch adversarial loss: 0.447034\n",
      "epoch 44; iter: 0; batch classifier loss: 0.148703; batch adversarial loss: 0.508869\n",
      "epoch 45; iter: 0; batch classifier loss: 0.151407; batch adversarial loss: 0.449870\n",
      "epoch 46; iter: 0; batch classifier loss: 0.134765; batch adversarial loss: 0.504452\n",
      "epoch 47; iter: 0; batch classifier loss: 0.178185; batch adversarial loss: 0.482398\n",
      "epoch 48; iter: 0; batch classifier loss: 0.148370; batch adversarial loss: 0.613936\n",
      "epoch 49; iter: 0; batch classifier loss: 0.181636; batch adversarial loss: 0.496504\n",
      "epoch 50; iter: 0; batch classifier loss: 0.119065; batch adversarial loss: 0.461863\n",
      "epoch 51; iter: 0; batch classifier loss: 0.139716; batch adversarial loss: 0.356040\n",
      "epoch 52; iter: 0; batch classifier loss: 0.183279; batch adversarial loss: 0.392161\n",
      "epoch 53; iter: 0; batch classifier loss: 0.199119; batch adversarial loss: 0.505378\n",
      "epoch 54; iter: 0; batch classifier loss: 0.128537; batch adversarial loss: 0.466181\n",
      "epoch 55; iter: 0; batch classifier loss: 0.160214; batch adversarial loss: 0.443440\n",
      "epoch 56; iter: 0; batch classifier loss: 0.180063; batch adversarial loss: 0.414608\n",
      "epoch 57; iter: 0; batch classifier loss: 0.127094; batch adversarial loss: 0.463592\n",
      "epoch 58; iter: 0; batch classifier loss: 0.127975; batch adversarial loss: 0.489425\n",
      "epoch 59; iter: 0; batch classifier loss: 0.160768; batch adversarial loss: 0.527688\n",
      "epoch 60; iter: 0; batch classifier loss: 0.166603; batch adversarial loss: 0.438175\n",
      "epoch 61; iter: 0; batch classifier loss: 0.119228; batch adversarial loss: 0.470129\n",
      "epoch 62; iter: 0; batch classifier loss: 0.121527; batch adversarial loss: 0.526739\n",
      "epoch 63; iter: 0; batch classifier loss: 0.167985; batch adversarial loss: 0.380160\n",
      "epoch 64; iter: 0; batch classifier loss: 0.154299; batch adversarial loss: 0.538668\n",
      "epoch 65; iter: 0; batch classifier loss: 0.144729; batch adversarial loss: 0.488947\n",
      "epoch 66; iter: 0; batch classifier loss: 0.158524; batch adversarial loss: 0.420199\n",
      "epoch 67; iter: 0; batch classifier loss: 0.143071; batch adversarial loss: 0.487227\n",
      "epoch 68; iter: 0; batch classifier loss: 0.109584; batch adversarial loss: 0.504080\n",
      "epoch 69; iter: 0; batch classifier loss: 0.155288; batch adversarial loss: 0.416856\n",
      "epoch 70; iter: 0; batch classifier loss: 0.144662; batch adversarial loss: 0.442665\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115606; batch adversarial loss: 0.463853\n",
      "epoch 72; iter: 0; batch classifier loss: 0.107191; batch adversarial loss: 0.479954\n",
      "epoch 73; iter: 0; batch classifier loss: 0.110729; batch adversarial loss: 0.458257\n",
      "epoch 74; iter: 0; batch classifier loss: 0.144203; batch adversarial loss: 0.449539\n",
      "epoch 75; iter: 0; batch classifier loss: 0.145397; batch adversarial loss: 0.394633\n",
      "epoch 76; iter: 0; batch classifier loss: 0.156108; batch adversarial loss: 0.427064\n",
      "epoch 77; iter: 0; batch classifier loss: 0.127479; batch adversarial loss: 0.488910\n",
      "epoch 78; iter: 0; batch classifier loss: 0.128348; batch adversarial loss: 0.394214\n",
      "epoch 79; iter: 0; batch classifier loss: 0.174084; batch adversarial loss: 0.457360\n",
      "epoch 80; iter: 0; batch classifier loss: 0.091706; batch adversarial loss: 0.391629\n",
      "epoch 81; iter: 0; batch classifier loss: 0.129353; batch adversarial loss: 0.414912\n",
      "epoch 82; iter: 0; batch classifier loss: 0.127682; batch adversarial loss: 0.413366\n",
      "epoch 83; iter: 0; batch classifier loss: 0.128807; batch adversarial loss: 0.473170\n",
      "epoch 84; iter: 0; batch classifier loss: 0.141033; batch adversarial loss: 0.463725\n",
      "epoch 85; iter: 0; batch classifier loss: 0.099455; batch adversarial loss: 0.446737\n",
      "epoch 86; iter: 0; batch classifier loss: 0.119212; batch adversarial loss: 0.447344\n",
      "epoch 87; iter: 0; batch classifier loss: 0.103810; batch adversarial loss: 0.480677\n",
      "epoch 88; iter: 0; batch classifier loss: 0.138515; batch adversarial loss: 0.441971\n",
      "epoch 89; iter: 0; batch classifier loss: 0.113886; batch adversarial loss: 0.471796\n",
      "epoch 90; iter: 0; batch classifier loss: 0.130192; batch adversarial loss: 0.459374\n",
      "epoch 91; iter: 0; batch classifier loss: 0.088515; batch adversarial loss: 0.445881\n",
      "epoch 92; iter: 0; batch classifier loss: 0.111054; batch adversarial loss: 0.435946\n",
      "epoch 93; iter: 0; batch classifier loss: 0.138870; batch adversarial loss: 0.497952\n",
      "epoch 94; iter: 0; batch classifier loss: 0.154370; batch adversarial loss: 0.420943\n",
      "epoch 95; iter: 0; batch classifier loss: 0.116937; batch adversarial loss: 0.470865\n",
      "epoch 96; iter: 0; batch classifier loss: 0.150532; batch adversarial loss: 0.507240\n",
      "epoch 97; iter: 0; batch classifier loss: 0.132488; batch adversarial loss: 0.433021\n",
      "epoch 98; iter: 0; batch classifier loss: 0.103974; batch adversarial loss: 0.541811\n",
      "epoch 99; iter: 0; batch classifier loss: 0.111457; batch adversarial loss: 0.402593\n",
      "epoch 100; iter: 0; batch classifier loss: 0.129163; batch adversarial loss: 0.456106\n",
      "epoch 101; iter: 0; batch classifier loss: 0.178556; batch adversarial loss: 0.525579\n",
      "epoch 102; iter: 0; batch classifier loss: 0.193958; batch adversarial loss: 0.403873\n",
      "epoch 103; iter: 0; batch classifier loss: 0.131184; batch adversarial loss: 0.487010\n",
      "epoch 104; iter: 0; batch classifier loss: 0.139158; batch adversarial loss: 0.370991\n",
      "epoch 105; iter: 0; batch classifier loss: 0.134115; batch adversarial loss: 0.496066\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068330; batch adversarial loss: 0.457165\n",
      "epoch 107; iter: 0; batch classifier loss: 0.097510; batch adversarial loss: 0.457774\n",
      "epoch 108; iter: 0; batch classifier loss: 0.094554; batch adversarial loss: 0.434916\n",
      "epoch 109; iter: 0; batch classifier loss: 0.091531; batch adversarial loss: 0.471975\n",
      "epoch 110; iter: 0; batch classifier loss: 0.100530; batch adversarial loss: 0.433066\n",
      "epoch 111; iter: 0; batch classifier loss: 0.122073; batch adversarial loss: 0.397302\n",
      "epoch 112; iter: 0; batch classifier loss: 0.120541; batch adversarial loss: 0.439181\n",
      "epoch 113; iter: 0; batch classifier loss: 0.132191; batch adversarial loss: 0.436937\n",
      "epoch 114; iter: 0; batch classifier loss: 0.131570; batch adversarial loss: 0.496395\n",
      "epoch 115; iter: 0; batch classifier loss: 0.107737; batch adversarial loss: 0.430303\n",
      "epoch 116; iter: 0; batch classifier loss: 0.119204; batch adversarial loss: 0.441051\n",
      "epoch 117; iter: 0; batch classifier loss: 0.091447; batch adversarial loss: 0.439546\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056451; batch adversarial loss: 0.466059\n",
      "epoch 119; iter: 0; batch classifier loss: 0.185211; batch adversarial loss: 0.396933\n",
      "epoch 120; iter: 0; batch classifier loss: 0.096722; batch adversarial loss: 0.470055\n",
      "epoch 121; iter: 0; batch classifier loss: 0.118928; batch adversarial loss: 0.406232\n",
      "epoch 122; iter: 0; batch classifier loss: 0.080698; batch adversarial loss: 0.385405\n",
      "epoch 123; iter: 0; batch classifier loss: 0.133411; batch adversarial loss: 0.457840\n",
      "epoch 124; iter: 0; batch classifier loss: 0.066866; batch adversarial loss: 0.556675\n",
      "epoch 125; iter: 0; batch classifier loss: 0.136773; batch adversarial loss: 0.454381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.071165; batch adversarial loss: 0.482607\n",
      "epoch 127; iter: 0; batch classifier loss: 0.101672; batch adversarial loss: 0.440102\n",
      "epoch 128; iter: 0; batch classifier loss: 0.081006; batch adversarial loss: 0.514312\n",
      "epoch 129; iter: 0; batch classifier loss: 0.106914; batch adversarial loss: 0.388412\n",
      "epoch 130; iter: 0; batch classifier loss: 0.075339; batch adversarial loss: 0.362453\n",
      "epoch 131; iter: 0; batch classifier loss: 0.095018; batch adversarial loss: 0.460890\n",
      "epoch 132; iter: 0; batch classifier loss: 0.089057; batch adversarial loss: 0.453333\n",
      "epoch 133; iter: 0; batch classifier loss: 0.101660; batch adversarial loss: 0.426585\n",
      "epoch 134; iter: 0; batch classifier loss: 0.086406; batch adversarial loss: 0.444424\n",
      "epoch 135; iter: 0; batch classifier loss: 0.099035; batch adversarial loss: 0.425196\n",
      "epoch 136; iter: 0; batch classifier loss: 0.086053; batch adversarial loss: 0.408139\n",
      "epoch 137; iter: 0; batch classifier loss: 0.104491; batch adversarial loss: 0.506143\n",
      "epoch 138; iter: 0; batch classifier loss: 0.091233; batch adversarial loss: 0.481323\n",
      "epoch 139; iter: 0; batch classifier loss: 0.133444; batch adversarial loss: 0.519996\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051791; batch adversarial loss: 0.505520\n",
      "epoch 141; iter: 0; batch classifier loss: 0.059896; batch adversarial loss: 0.481584\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045390; batch adversarial loss: 0.504579\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039146; batch adversarial loss: 0.456881\n",
      "epoch 144; iter: 0; batch classifier loss: 0.114422; batch adversarial loss: 0.478711\n",
      "epoch 145; iter: 0; batch classifier loss: 0.098553; batch adversarial loss: 0.475764\n",
      "epoch 146; iter: 0; batch classifier loss: 0.081186; batch adversarial loss: 0.400154\n",
      "epoch 147; iter: 0; batch classifier loss: 0.098001; batch adversarial loss: 0.424691\n",
      "epoch 148; iter: 0; batch classifier loss: 0.072373; batch adversarial loss: 0.440989\n",
      "epoch 149; iter: 0; batch classifier loss: 0.101808; batch adversarial loss: 0.431650\n",
      "epoch 150; iter: 0; batch classifier loss: 0.087077; batch adversarial loss: 0.375655\n",
      "epoch 151; iter: 0; batch classifier loss: 0.078736; batch adversarial loss: 0.455500\n",
      "epoch 152; iter: 0; batch classifier loss: 0.096154; batch adversarial loss: 0.366484\n",
      "epoch 153; iter: 0; batch classifier loss: 0.102248; batch adversarial loss: 0.441903\n",
      "epoch 154; iter: 0; batch classifier loss: 0.113030; batch adversarial loss: 0.466426\n",
      "epoch 155; iter: 0; batch classifier loss: 0.071287; batch adversarial loss: 0.496882\n",
      "epoch 156; iter: 0; batch classifier loss: 0.091605; batch adversarial loss: 0.492257\n",
      "epoch 157; iter: 0; batch classifier loss: 0.074572; batch adversarial loss: 0.530703\n",
      "epoch 158; iter: 0; batch classifier loss: 0.075327; batch adversarial loss: 0.446088\n",
      "epoch 159; iter: 0; batch classifier loss: 0.072701; batch adversarial loss: 0.452517\n",
      "epoch 160; iter: 0; batch classifier loss: 0.071729; batch adversarial loss: 0.439987\n",
      "epoch 161; iter: 0; batch classifier loss: 0.081077; batch adversarial loss: 0.500449\n",
      "epoch 162; iter: 0; batch classifier loss: 0.121107; batch adversarial loss: 0.477191\n",
      "epoch 163; iter: 0; batch classifier loss: 0.129386; batch adversarial loss: 0.549080\n",
      "epoch 164; iter: 0; batch classifier loss: 0.145024; batch adversarial loss: 0.527097\n",
      "epoch 165; iter: 0; batch classifier loss: 0.099656; batch adversarial loss: 0.478475\n",
      "epoch 166; iter: 0; batch classifier loss: 0.167419; batch adversarial loss: 0.426010\n",
      "epoch 167; iter: 0; batch classifier loss: 0.181038; batch adversarial loss: 0.469720\n",
      "epoch 168; iter: 0; batch classifier loss: 0.149549; batch adversarial loss: 0.483255\n",
      "epoch 169; iter: 0; batch classifier loss: 0.173165; batch adversarial loss: 0.413699\n",
      "epoch 170; iter: 0; batch classifier loss: 0.102697; batch adversarial loss: 0.483988\n",
      "epoch 171; iter: 0; batch classifier loss: 0.159306; batch adversarial loss: 0.407776\n",
      "epoch 172; iter: 0; batch classifier loss: 0.120570; batch adversarial loss: 0.472258\n",
      "epoch 173; iter: 0; batch classifier loss: 0.143516; batch adversarial loss: 0.541522\n",
      "epoch 174; iter: 0; batch classifier loss: 0.335913; batch adversarial loss: 0.380092\n",
      "epoch 175; iter: 0; batch classifier loss: 0.127205; batch adversarial loss: 0.513855\n",
      "epoch 176; iter: 0; batch classifier loss: 0.194771; batch adversarial loss: 0.519581\n",
      "epoch 177; iter: 0; batch classifier loss: 0.172680; batch adversarial loss: 0.445484\n",
      "epoch 178; iter: 0; batch classifier loss: 0.207870; batch adversarial loss: 0.433306\n",
      "epoch 179; iter: 0; batch classifier loss: 0.153924; batch adversarial loss: 0.359647\n",
      "epoch 180; iter: 0; batch classifier loss: 0.238475; batch adversarial loss: 0.459645\n",
      "epoch 181; iter: 0; batch classifier loss: 0.203147; batch adversarial loss: 0.521342\n",
      "epoch 182; iter: 0; batch classifier loss: 0.292695; batch adversarial loss: 0.527766\n",
      "epoch 183; iter: 0; batch classifier loss: 0.312633; batch adversarial loss: 0.514140\n",
      "epoch 184; iter: 0; batch classifier loss: 0.199429; batch adversarial loss: 0.482910\n",
      "epoch 185; iter: 0; batch classifier loss: 0.260386; batch adversarial loss: 0.456910\n",
      "epoch 186; iter: 0; batch classifier loss: 0.177429; batch adversarial loss: 0.485215\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334202; batch adversarial loss: 0.469301\n",
      "epoch 188; iter: 0; batch classifier loss: 0.189184; batch adversarial loss: 0.421131\n",
      "epoch 189; iter: 0; batch classifier loss: 0.213170; batch adversarial loss: 0.468626\n",
      "epoch 190; iter: 0; batch classifier loss: 0.221266; batch adversarial loss: 0.403223\n",
      "epoch 191; iter: 0; batch classifier loss: 0.220061; batch adversarial loss: 0.507147\n",
      "epoch 192; iter: 0; batch classifier loss: 0.210445; batch adversarial loss: 0.593381\n",
      "epoch 193; iter: 0; batch classifier loss: 0.245055; batch adversarial loss: 0.484028\n",
      "epoch 194; iter: 0; batch classifier loss: 0.210174; batch adversarial loss: 0.412176\n",
      "epoch 195; iter: 0; batch classifier loss: 0.193464; batch adversarial loss: 0.470606\n",
      "epoch 196; iter: 0; batch classifier loss: 0.253734; batch adversarial loss: 0.410401\n",
      "epoch 197; iter: 0; batch classifier loss: 0.228410; batch adversarial loss: 0.507131\n",
      "epoch 198; iter: 0; batch classifier loss: 0.219308; batch adversarial loss: 0.386083\n",
      "epoch 199; iter: 0; batch classifier loss: 0.120870; batch adversarial loss: 0.385782\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725852; batch adversarial loss: 0.616015\n",
      "epoch 1; iter: 0; batch classifier loss: 0.370295; batch adversarial loss: 0.582526\n",
      "epoch 2; iter: 0; batch classifier loss: 0.311986; batch adversarial loss: 0.594799\n",
      "epoch 3; iter: 0; batch classifier loss: 0.391420; batch adversarial loss: 0.582715\n",
      "epoch 4; iter: 0; batch classifier loss: 0.360080; batch adversarial loss: 0.577303\n",
      "epoch 5; iter: 0; batch classifier loss: 0.302216; batch adversarial loss: 0.561390\n",
      "epoch 6; iter: 0; batch classifier loss: 0.283233; batch adversarial loss: 0.537965\n",
      "epoch 7; iter: 0; batch classifier loss: 0.345308; batch adversarial loss: 0.552229\n",
      "epoch 8; iter: 0; batch classifier loss: 0.378687; batch adversarial loss: 0.496941\n",
      "epoch 9; iter: 0; batch classifier loss: 0.321364; batch adversarial loss: 0.485939\n",
      "epoch 10; iter: 0; batch classifier loss: 0.279555; batch adversarial loss: 0.524528\n",
      "epoch 11; iter: 0; batch classifier loss: 0.278000; batch adversarial loss: 0.508619\n",
      "epoch 12; iter: 0; batch classifier loss: 0.368132; batch adversarial loss: 0.522775\n",
      "epoch 13; iter: 0; batch classifier loss: 0.385815; batch adversarial loss: 0.524443\n",
      "epoch 14; iter: 0; batch classifier loss: 0.591717; batch adversarial loss: 0.515556\n",
      "epoch 15; iter: 0; batch classifier loss: 0.608449; batch adversarial loss: 0.541271\n",
      "epoch 16; iter: 0; batch classifier loss: 0.349420; batch adversarial loss: 0.551661\n",
      "epoch 17; iter: 0; batch classifier loss: 0.332783; batch adversarial loss: 0.445029\n",
      "epoch 18; iter: 0; batch classifier loss: 0.284611; batch adversarial loss: 0.468980\n",
      "epoch 19; iter: 0; batch classifier loss: 0.214891; batch adversarial loss: 0.535246\n",
      "epoch 20; iter: 0; batch classifier loss: 0.231164; batch adversarial loss: 0.450042\n",
      "epoch 21; iter: 0; batch classifier loss: 0.243035; batch adversarial loss: 0.425050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.254443; batch adversarial loss: 0.449631\n",
      "epoch 23; iter: 0; batch classifier loss: 0.262784; batch adversarial loss: 0.475279\n",
      "epoch 24; iter: 0; batch classifier loss: 0.214706; batch adversarial loss: 0.459667\n",
      "epoch 25; iter: 0; batch classifier loss: 0.233302; batch adversarial loss: 0.385090\n",
      "epoch 26; iter: 0; batch classifier loss: 0.206324; batch adversarial loss: 0.416803\n",
      "epoch 27; iter: 0; batch classifier loss: 0.189985; batch adversarial loss: 0.363171\n",
      "epoch 28; iter: 0; batch classifier loss: 0.145428; batch adversarial loss: 0.405471\n",
      "epoch 29; iter: 0; batch classifier loss: 0.165455; batch adversarial loss: 0.386124\n",
      "epoch 30; iter: 0; batch classifier loss: 0.230658; batch adversarial loss: 0.448235\n",
      "epoch 31; iter: 0; batch classifier loss: 0.174657; batch adversarial loss: 0.541255\n",
      "epoch 32; iter: 0; batch classifier loss: 0.177782; batch adversarial loss: 0.468293\n",
      "epoch 33; iter: 0; batch classifier loss: 0.133308; batch adversarial loss: 0.373292\n",
      "epoch 34; iter: 0; batch classifier loss: 0.076570; batch adversarial loss: 0.480136\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130406; batch adversarial loss: 0.463344\n",
      "epoch 36; iter: 0; batch classifier loss: 0.139082; batch adversarial loss: 0.486091\n",
      "epoch 37; iter: 0; batch classifier loss: 0.092194; batch adversarial loss: 0.421697\n",
      "epoch 38; iter: 0; batch classifier loss: 0.125797; batch adversarial loss: 0.446297\n",
      "epoch 39; iter: 0; batch classifier loss: 0.151748; batch adversarial loss: 0.446582\n",
      "epoch 40; iter: 0; batch classifier loss: 0.121996; batch adversarial loss: 0.416467\n",
      "epoch 41; iter: 0; batch classifier loss: 0.141085; batch adversarial loss: 0.390555\n",
      "epoch 42; iter: 0; batch classifier loss: 0.125285; batch adversarial loss: 0.429912\n",
      "epoch 43; iter: 0; batch classifier loss: 0.138016; batch adversarial loss: 0.481843\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123568; batch adversarial loss: 0.413856\n",
      "epoch 45; iter: 0; batch classifier loss: 0.129914; batch adversarial loss: 0.470986\n",
      "epoch 46; iter: 0; batch classifier loss: 0.105285; batch adversarial loss: 0.467476\n",
      "epoch 47; iter: 0; batch classifier loss: 0.094946; batch adversarial loss: 0.380452\n",
      "epoch 48; iter: 0; batch classifier loss: 0.069715; batch adversarial loss: 0.426168\n",
      "epoch 49; iter: 0; batch classifier loss: 0.146038; batch adversarial loss: 0.391580\n",
      "epoch 50; iter: 0; batch classifier loss: 0.116789; batch adversarial loss: 0.522101\n",
      "epoch 51; iter: 0; batch classifier loss: 0.111782; batch adversarial loss: 0.368652\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100394; batch adversarial loss: 0.447148\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094005; batch adversarial loss: 0.506329\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116073; batch adversarial loss: 0.542432\n",
      "epoch 55; iter: 0; batch classifier loss: 0.108259; batch adversarial loss: 0.472207\n",
      "epoch 56; iter: 0; batch classifier loss: 0.076991; batch adversarial loss: 0.389711\n",
      "epoch 57; iter: 0; batch classifier loss: 0.110344; batch adversarial loss: 0.395735\n",
      "epoch 58; iter: 0; batch classifier loss: 0.094093; batch adversarial loss: 0.511880\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081224; batch adversarial loss: 0.495555\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065381; batch adversarial loss: 0.413174\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078255; batch adversarial loss: 0.551929\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108523; batch adversarial loss: 0.463470\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089055; batch adversarial loss: 0.466280\n",
      "epoch 64; iter: 0; batch classifier loss: 0.089700; batch adversarial loss: 0.448737\n",
      "epoch 65; iter: 0; batch classifier loss: 0.120322; batch adversarial loss: 0.477030\n",
      "epoch 66; iter: 0; batch classifier loss: 0.052492; batch adversarial loss: 0.403941\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069077; batch adversarial loss: 0.428618\n",
      "epoch 68; iter: 0; batch classifier loss: 0.058661; batch adversarial loss: 0.543185\n",
      "epoch 69; iter: 0; batch classifier loss: 0.090286; batch adversarial loss: 0.346794\n",
      "epoch 70; iter: 0; batch classifier loss: 0.106609; batch adversarial loss: 0.480832\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063997; batch adversarial loss: 0.479181\n",
      "epoch 72; iter: 0; batch classifier loss: 0.128349; batch adversarial loss: 0.453132\n",
      "epoch 73; iter: 0; batch classifier loss: 0.126780; batch adversarial loss: 0.392125\n",
      "epoch 74; iter: 0; batch classifier loss: 0.093481; batch adversarial loss: 0.371579\n",
      "epoch 75; iter: 0; batch classifier loss: 0.079964; batch adversarial loss: 0.475443\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081507; batch adversarial loss: 0.438145\n",
      "epoch 77; iter: 0; batch classifier loss: 0.100913; batch adversarial loss: 0.361563\n",
      "epoch 78; iter: 0; batch classifier loss: 0.045288; batch adversarial loss: 0.489985\n",
      "epoch 79; iter: 0; batch classifier loss: 0.087554; batch adversarial loss: 0.438196\n",
      "epoch 80; iter: 0; batch classifier loss: 0.044513; batch adversarial loss: 0.483574\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081420; batch adversarial loss: 0.423234\n",
      "epoch 82; iter: 0; batch classifier loss: 0.086976; batch adversarial loss: 0.405280\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059816; batch adversarial loss: 0.441022\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046344; batch adversarial loss: 0.526041\n",
      "epoch 85; iter: 0; batch classifier loss: 0.043486; batch adversarial loss: 0.472237\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064239; batch adversarial loss: 0.471838\n",
      "epoch 87; iter: 0; batch classifier loss: 0.037076; batch adversarial loss: 0.466567\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041883; batch adversarial loss: 0.435898\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080945; batch adversarial loss: 0.500725\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062532; batch adversarial loss: 0.477375\n",
      "epoch 91; iter: 0; batch classifier loss: 0.065112; batch adversarial loss: 0.350226\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048994; batch adversarial loss: 0.389170\n",
      "epoch 93; iter: 0; batch classifier loss: 0.042064; batch adversarial loss: 0.499649\n",
      "epoch 94; iter: 0; batch classifier loss: 0.063438; batch adversarial loss: 0.461111\n",
      "epoch 95; iter: 0; batch classifier loss: 0.059242; batch adversarial loss: 0.478374\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037044; batch adversarial loss: 0.481517\n",
      "epoch 97; iter: 0; batch classifier loss: 0.031595; batch adversarial loss: 0.469475\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044215; batch adversarial loss: 0.501007\n",
      "epoch 99; iter: 0; batch classifier loss: 0.034928; batch adversarial loss: 0.420838\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066627; batch adversarial loss: 0.456943\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049591; batch adversarial loss: 0.486471\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044655; batch adversarial loss: 0.409628\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045737; batch adversarial loss: 0.463586\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043862; batch adversarial loss: 0.407075\n",
      "epoch 105; iter: 0; batch classifier loss: 0.027691; batch adversarial loss: 0.334578\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044737; batch adversarial loss: 0.429723\n",
      "epoch 107; iter: 0; batch classifier loss: 0.029804; batch adversarial loss: 0.432160\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049312; batch adversarial loss: 0.384934\n",
      "epoch 109; iter: 0; batch classifier loss: 0.052494; batch adversarial loss: 0.397203\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033412; batch adversarial loss: 0.478941\n",
      "epoch 111; iter: 0; batch classifier loss: 0.015705; batch adversarial loss: 0.451376\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027549; batch adversarial loss: 0.477096\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055883; batch adversarial loss: 0.389790\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052721; batch adversarial loss: 0.472379\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050514; batch adversarial loss: 0.518519\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034233; batch adversarial loss: 0.404670\n",
      "epoch 117; iter: 0; batch classifier loss: 0.017119; batch adversarial loss: 0.551870\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039772; batch adversarial loss: 0.536926\n",
      "epoch 119; iter: 0; batch classifier loss: 0.060399; batch adversarial loss: 0.453693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.018826; batch adversarial loss: 0.529018\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051297; batch adversarial loss: 0.434810\n",
      "epoch 122; iter: 0; batch classifier loss: 0.047765; batch adversarial loss: 0.475285\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038510; batch adversarial loss: 0.485095\n",
      "epoch 124; iter: 0; batch classifier loss: 0.017940; batch adversarial loss: 0.454316\n",
      "epoch 125; iter: 0; batch classifier loss: 0.016055; batch adversarial loss: 0.474628\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047873; batch adversarial loss: 0.328388\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045214; batch adversarial loss: 0.470794\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027555; batch adversarial loss: 0.415270\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027623; batch adversarial loss: 0.434265\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046479; batch adversarial loss: 0.400266\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029448; batch adversarial loss: 0.452750\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043916; batch adversarial loss: 0.423388\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042134; batch adversarial loss: 0.423796\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030636; batch adversarial loss: 0.459345\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011133; batch adversarial loss: 0.539143\n",
      "epoch 136; iter: 0; batch classifier loss: 0.008529; batch adversarial loss: 0.418036\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024926; batch adversarial loss: 0.534984\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036705; batch adversarial loss: 0.431385\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023679; batch adversarial loss: 0.511745\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022891; batch adversarial loss: 0.375093\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028828; batch adversarial loss: 0.411383\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020796; batch adversarial loss: 0.477380\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013675; batch adversarial loss: 0.482032\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037505; batch adversarial loss: 0.530552\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035124; batch adversarial loss: 0.446717\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019193; batch adversarial loss: 0.403397\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033460; batch adversarial loss: 0.540408\n",
      "epoch 148; iter: 0; batch classifier loss: 0.052396; batch adversarial loss: 0.482720\n",
      "epoch 149; iter: 0; batch classifier loss: 0.006478; batch adversarial loss: 0.496902\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039698; batch adversarial loss: 0.493548\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016082; batch adversarial loss: 0.425083\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033326; batch adversarial loss: 0.509540\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035238; batch adversarial loss: 0.474595\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040560; batch adversarial loss: 0.416153\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019246; batch adversarial loss: 0.560494\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028528; batch adversarial loss: 0.471736\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023700; batch adversarial loss: 0.483371\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018933; batch adversarial loss: 0.562190\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030907; batch adversarial loss: 0.508340\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014689; batch adversarial loss: 0.335262\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035688; batch adversarial loss: 0.439084\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016950; batch adversarial loss: 0.421896\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034520; batch adversarial loss: 0.435304\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020859; batch adversarial loss: 0.446309\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019561; batch adversarial loss: 0.484130\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026757; batch adversarial loss: 0.432694\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016681; batch adversarial loss: 0.552512\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010738; batch adversarial loss: 0.476942\n",
      "epoch 169; iter: 0; batch classifier loss: 0.048243; batch adversarial loss: 0.451617\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016062; batch adversarial loss: 0.394145\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036053; batch adversarial loss: 0.435921\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027938; batch adversarial loss: 0.445158\n",
      "epoch 173; iter: 0; batch classifier loss: 0.047592; batch adversarial loss: 0.497237\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025296; batch adversarial loss: 0.446975\n",
      "epoch 175; iter: 0; batch classifier loss: 0.003432; batch adversarial loss: 0.500185\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028396; batch adversarial loss: 0.432195\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030029; batch adversarial loss: 0.506998\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014674; batch adversarial loss: 0.498672\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014057; batch adversarial loss: 0.348258\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018046; batch adversarial loss: 0.426012\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032799; batch adversarial loss: 0.444567\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008961; batch adversarial loss: 0.451760\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034277; batch adversarial loss: 0.452020\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013301; batch adversarial loss: 0.485015\n",
      "epoch 185; iter: 0; batch classifier loss: 0.054555; batch adversarial loss: 0.455435\n",
      "epoch 186; iter: 0; batch classifier loss: 0.037740; batch adversarial loss: 0.481800\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006615; batch adversarial loss: 0.469681\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022180; batch adversarial loss: 0.406482\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022141; batch adversarial loss: 0.431776\n",
      "epoch 190; iter: 0; batch classifier loss: 0.080693; batch adversarial loss: 0.422204\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012285; batch adversarial loss: 0.457237\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026783; batch adversarial loss: 0.480154\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016653; batch adversarial loss: 0.354034\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008718; batch adversarial loss: 0.500892\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012585; batch adversarial loss: 0.551875\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023659; batch adversarial loss: 0.483619\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007890; batch adversarial loss: 0.454950\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008918; batch adversarial loss: 0.383197\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018685; batch adversarial loss: 0.413858\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708434; batch adversarial loss: 0.963359\n",
      "epoch 1; iter: 0; batch classifier loss: 0.593590; batch adversarial loss: 0.993125\n",
      "epoch 2; iter: 0; batch classifier loss: 0.887191; batch adversarial loss: 1.071779\n",
      "epoch 3; iter: 0; batch classifier loss: 1.075788; batch adversarial loss: 1.010025\n",
      "epoch 4; iter: 0; batch classifier loss: 1.105804; batch adversarial loss: 0.915036\n",
      "epoch 5; iter: 0; batch classifier loss: 1.055320; batch adversarial loss: 0.861406\n",
      "epoch 6; iter: 0; batch classifier loss: 0.988763; batch adversarial loss: 0.760484\n",
      "epoch 7; iter: 0; batch classifier loss: 0.909050; batch adversarial loss: 0.705072\n",
      "epoch 8; iter: 0; batch classifier loss: 0.733382; batch adversarial loss: 0.666305\n",
      "epoch 9; iter: 0; batch classifier loss: 0.584014; batch adversarial loss: 0.581316\n",
      "epoch 10; iter: 0; batch classifier loss: 0.468731; batch adversarial loss: 0.519024\n",
      "epoch 11; iter: 0; batch classifier loss: 0.363198; batch adversarial loss: 0.534382\n",
      "epoch 12; iter: 0; batch classifier loss: 0.385006; batch adversarial loss: 0.497102\n",
      "epoch 13; iter: 0; batch classifier loss: 0.312026; batch adversarial loss: 0.504812\n",
      "epoch 14; iter: 0; batch classifier loss: 0.273907; batch adversarial loss: 0.474567\n",
      "epoch 15; iter: 0; batch classifier loss: 0.241709; batch adversarial loss: 0.508831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.240566; batch adversarial loss: 0.482011\n",
      "epoch 17; iter: 0; batch classifier loss: 0.277360; batch adversarial loss: 0.536258\n",
      "epoch 18; iter: 0; batch classifier loss: 0.249590; batch adversarial loss: 0.497019\n",
      "epoch 19; iter: 0; batch classifier loss: 0.206990; batch adversarial loss: 0.504718\n",
      "epoch 20; iter: 0; batch classifier loss: 0.183644; batch adversarial loss: 0.475033\n",
      "epoch 21; iter: 0; batch classifier loss: 0.243676; batch adversarial loss: 0.403166\n",
      "epoch 22; iter: 0; batch classifier loss: 0.199756; batch adversarial loss: 0.534514\n",
      "epoch 23; iter: 0; batch classifier loss: 0.202700; batch adversarial loss: 0.505804\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199634; batch adversarial loss: 0.502212\n",
      "epoch 25; iter: 0; batch classifier loss: 0.197496; batch adversarial loss: 0.402003\n",
      "epoch 26; iter: 0; batch classifier loss: 0.183690; batch adversarial loss: 0.531252\n",
      "epoch 27; iter: 0; batch classifier loss: 0.215091; batch adversarial loss: 0.427773\n",
      "epoch 28; iter: 0; batch classifier loss: 0.119455; batch adversarial loss: 0.506441\n",
      "epoch 29; iter: 0; batch classifier loss: 0.156948; batch adversarial loss: 0.488952\n",
      "epoch 30; iter: 0; batch classifier loss: 0.186563; batch adversarial loss: 0.485712\n",
      "epoch 31; iter: 0; batch classifier loss: 0.198561; batch adversarial loss: 0.497676\n",
      "epoch 32; iter: 0; batch classifier loss: 0.156383; batch adversarial loss: 0.483930\n",
      "epoch 33; iter: 0; batch classifier loss: 0.254145; batch adversarial loss: 0.441385\n",
      "epoch 34; iter: 0; batch classifier loss: 0.157289; batch adversarial loss: 0.509912\n",
      "epoch 35; iter: 0; batch classifier loss: 0.146632; batch adversarial loss: 0.481070\n",
      "epoch 36; iter: 0; batch classifier loss: 0.142832; batch adversarial loss: 0.494548\n",
      "epoch 37; iter: 0; batch classifier loss: 0.171884; batch adversarial loss: 0.426511\n",
      "epoch 38; iter: 0; batch classifier loss: 0.165869; batch adversarial loss: 0.535348\n",
      "epoch 39; iter: 0; batch classifier loss: 0.151427; batch adversarial loss: 0.407415\n",
      "epoch 40; iter: 0; batch classifier loss: 0.117091; batch adversarial loss: 0.500249\n",
      "epoch 41; iter: 0; batch classifier loss: 0.135566; batch adversarial loss: 0.537724\n",
      "epoch 42; iter: 0; batch classifier loss: 0.151917; batch adversarial loss: 0.437296\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150526; batch adversarial loss: 0.478662\n",
      "epoch 44; iter: 0; batch classifier loss: 0.139202; batch adversarial loss: 0.414672\n",
      "epoch 45; iter: 0; batch classifier loss: 0.111378; batch adversarial loss: 0.424919\n",
      "epoch 46; iter: 0; batch classifier loss: 0.155969; batch adversarial loss: 0.438488\n",
      "epoch 47; iter: 0; batch classifier loss: 0.160817; batch adversarial loss: 0.491787\n",
      "epoch 48; iter: 0; batch classifier loss: 0.191273; batch adversarial loss: 0.474402\n",
      "epoch 49; iter: 0; batch classifier loss: 0.146449; batch adversarial loss: 0.490674\n",
      "epoch 50; iter: 0; batch classifier loss: 0.148538; batch adversarial loss: 0.471759\n",
      "epoch 51; iter: 0; batch classifier loss: 0.160053; batch adversarial loss: 0.466148\n",
      "epoch 52; iter: 0; batch classifier loss: 0.142492; batch adversarial loss: 0.495572\n",
      "epoch 53; iter: 0; batch classifier loss: 0.108410; batch adversarial loss: 0.464642\n",
      "epoch 54; iter: 0; batch classifier loss: 0.084799; batch adversarial loss: 0.468092\n",
      "epoch 55; iter: 0; batch classifier loss: 0.126009; batch adversarial loss: 0.473537\n",
      "epoch 56; iter: 0; batch classifier loss: 0.149433; batch adversarial loss: 0.484762\n",
      "epoch 57; iter: 0; batch classifier loss: 0.093479; batch adversarial loss: 0.509454\n",
      "epoch 58; iter: 0; batch classifier loss: 0.123267; batch adversarial loss: 0.485590\n",
      "epoch 59; iter: 0; batch classifier loss: 0.071009; batch adversarial loss: 0.407714\n",
      "epoch 60; iter: 0; batch classifier loss: 0.096953; batch adversarial loss: 0.460585\n",
      "epoch 61; iter: 0; batch classifier loss: 0.133857; batch adversarial loss: 0.502154\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078209; batch adversarial loss: 0.453133\n",
      "epoch 63; iter: 0; batch classifier loss: 0.128008; batch adversarial loss: 0.388266\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098181; batch adversarial loss: 0.529151\n",
      "epoch 65; iter: 0; batch classifier loss: 0.120861; batch adversarial loss: 0.407086\n",
      "epoch 66; iter: 0; batch classifier loss: 0.151980; batch adversarial loss: 0.410452\n",
      "epoch 67; iter: 0; batch classifier loss: 0.092796; batch adversarial loss: 0.468313\n",
      "epoch 68; iter: 0; batch classifier loss: 0.083050; batch adversarial loss: 0.362385\n",
      "epoch 69; iter: 0; batch classifier loss: 0.111015; batch adversarial loss: 0.436934\n",
      "epoch 70; iter: 0; batch classifier loss: 0.120626; batch adversarial loss: 0.468246\n",
      "epoch 71; iter: 0; batch classifier loss: 0.096129; batch adversarial loss: 0.407522\n",
      "epoch 72; iter: 0; batch classifier loss: 0.095693; batch adversarial loss: 0.468117\n",
      "epoch 73; iter: 0; batch classifier loss: 0.064730; batch adversarial loss: 0.468528\n",
      "epoch 74; iter: 0; batch classifier loss: 0.047640; batch adversarial loss: 0.486031\n",
      "epoch 75; iter: 0; batch classifier loss: 0.095580; batch adversarial loss: 0.434706\n",
      "epoch 76; iter: 0; batch classifier loss: 0.098582; batch adversarial loss: 0.517894\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067182; batch adversarial loss: 0.620612\n",
      "epoch 78; iter: 0; batch classifier loss: 0.092740; batch adversarial loss: 0.504931\n",
      "epoch 79; iter: 0; batch classifier loss: 0.110738; batch adversarial loss: 0.557323\n",
      "epoch 80; iter: 0; batch classifier loss: 0.107327; batch adversarial loss: 0.440892\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067736; batch adversarial loss: 0.451098\n",
      "epoch 82; iter: 0; batch classifier loss: 0.123530; batch adversarial loss: 0.484883\n",
      "epoch 83; iter: 0; batch classifier loss: 0.119727; batch adversarial loss: 0.431128\n",
      "epoch 84; iter: 0; batch classifier loss: 0.104472; batch adversarial loss: 0.411918\n",
      "epoch 85; iter: 0; batch classifier loss: 0.109985; batch adversarial loss: 0.510797\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073993; batch adversarial loss: 0.391026\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072793; batch adversarial loss: 0.392807\n",
      "epoch 88; iter: 0; batch classifier loss: 0.118825; batch adversarial loss: 0.462539\n",
      "epoch 89; iter: 0; batch classifier loss: 0.117095; batch adversarial loss: 0.525462\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068193; batch adversarial loss: 0.413163\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062412; batch adversarial loss: 0.538220\n",
      "epoch 92; iter: 0; batch classifier loss: 0.105928; batch adversarial loss: 0.529892\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053710; batch adversarial loss: 0.459937\n",
      "epoch 94; iter: 0; batch classifier loss: 0.073631; batch adversarial loss: 0.493661\n",
      "epoch 95; iter: 0; batch classifier loss: 0.069441; batch adversarial loss: 0.388758\n",
      "epoch 96; iter: 0; batch classifier loss: 0.091633; batch adversarial loss: 0.453307\n",
      "epoch 97; iter: 0; batch classifier loss: 0.105608; batch adversarial loss: 0.391342\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044914; batch adversarial loss: 0.472130\n",
      "epoch 99; iter: 0; batch classifier loss: 0.105539; batch adversarial loss: 0.445977\n",
      "epoch 100; iter: 0; batch classifier loss: 0.111828; batch adversarial loss: 0.529873\n",
      "epoch 101; iter: 0; batch classifier loss: 0.124210; batch adversarial loss: 0.460954\n",
      "epoch 102; iter: 0; batch classifier loss: 0.112153; batch adversarial loss: 0.491005\n",
      "epoch 103; iter: 0; batch classifier loss: 0.087716; batch adversarial loss: 0.436699\n",
      "epoch 104; iter: 0; batch classifier loss: 0.142847; batch adversarial loss: 0.372716\n",
      "epoch 105; iter: 0; batch classifier loss: 0.102748; batch adversarial loss: 0.520009\n",
      "epoch 106; iter: 0; batch classifier loss: 0.096006; batch adversarial loss: 0.475026\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062285; batch adversarial loss: 0.456376\n",
      "epoch 108; iter: 0; batch classifier loss: 0.066661; batch adversarial loss: 0.449963\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059246; batch adversarial loss: 0.468337\n",
      "epoch 110; iter: 0; batch classifier loss: 0.115019; batch adversarial loss: 0.467891\n",
      "epoch 111; iter: 0; batch classifier loss: 0.071127; batch adversarial loss: 0.448123\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041556; batch adversarial loss: 0.421128\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033017; batch adversarial loss: 0.453809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.108201; batch adversarial loss: 0.489453\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051960; batch adversarial loss: 0.495053\n",
      "epoch 116; iter: 0; batch classifier loss: 0.059680; batch adversarial loss: 0.415084\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060848; batch adversarial loss: 0.469382\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024510; batch adversarial loss: 0.443235\n",
      "epoch 119; iter: 0; batch classifier loss: 0.074158; batch adversarial loss: 0.392971\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051907; batch adversarial loss: 0.449396\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051927; batch adversarial loss: 0.422569\n",
      "epoch 122; iter: 0; batch classifier loss: 0.076281; batch adversarial loss: 0.471290\n",
      "epoch 123; iter: 0; batch classifier loss: 0.069147; batch adversarial loss: 0.455969\n",
      "epoch 124; iter: 0; batch classifier loss: 0.049564; batch adversarial loss: 0.451131\n",
      "epoch 125; iter: 0; batch classifier loss: 0.087561; batch adversarial loss: 0.397462\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029433; batch adversarial loss: 0.500258\n",
      "epoch 127; iter: 0; batch classifier loss: 0.062811; batch adversarial loss: 0.504806\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033374; batch adversarial loss: 0.517162\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027210; batch adversarial loss: 0.552013\n",
      "epoch 130; iter: 0; batch classifier loss: 0.066358; batch adversarial loss: 0.471431\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027040; batch adversarial loss: 0.472279\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036637; batch adversarial loss: 0.526612\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032747; batch adversarial loss: 0.500109\n",
      "epoch 134; iter: 0; batch classifier loss: 0.082747; batch adversarial loss: 0.438836\n",
      "epoch 135; iter: 0; batch classifier loss: 0.056376; batch adversarial loss: 0.442090\n",
      "epoch 136; iter: 0; batch classifier loss: 0.009896; batch adversarial loss: 0.483872\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045260; batch adversarial loss: 0.392492\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030949; batch adversarial loss: 0.441299\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046586; batch adversarial loss: 0.555499\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019083; batch adversarial loss: 0.453785\n",
      "epoch 141; iter: 0; batch classifier loss: 0.007150; batch adversarial loss: 0.543102\n",
      "epoch 142; iter: 0; batch classifier loss: 0.052168; batch adversarial loss: 0.575890\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022773; batch adversarial loss: 0.462710\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020920; batch adversarial loss: 0.543358\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016797; batch adversarial loss: 0.454244\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040145; batch adversarial loss: 0.478933\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030738; batch adversarial loss: 0.418643\n",
      "epoch 148; iter: 0; batch classifier loss: 0.007837; batch adversarial loss: 0.476130\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027418; batch adversarial loss: 0.452771\n",
      "epoch 150; iter: 0; batch classifier loss: 0.008201; batch adversarial loss: 0.438508\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036907; batch adversarial loss: 0.451253\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023553; batch adversarial loss: 0.356476\n",
      "epoch 153; iter: 0; batch classifier loss: 0.050200; batch adversarial loss: 0.468666\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031014; batch adversarial loss: 0.486411\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028342; batch adversarial loss: 0.403126\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015355; batch adversarial loss: 0.485019\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031883; batch adversarial loss: 0.464805\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048572; batch adversarial loss: 0.417814\n",
      "epoch 159; iter: 0; batch classifier loss: 0.048632; batch adversarial loss: 0.528954\n",
      "epoch 160; iter: 0; batch classifier loss: 0.054302; batch adversarial loss: 0.503077\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030258; batch adversarial loss: 0.454542\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027631; batch adversarial loss: 0.380665\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011182; batch adversarial loss: 0.413276\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022441; batch adversarial loss: 0.437674\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022635; batch adversarial loss: 0.405669\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022158; batch adversarial loss: 0.494923\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032043; batch adversarial loss: 0.409600\n",
      "epoch 168; iter: 0; batch classifier loss: 0.043602; batch adversarial loss: 0.441001\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035635; batch adversarial loss: 0.415879\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020030; batch adversarial loss: 0.458178\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012163; batch adversarial loss: 0.402813\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010755; batch adversarial loss: 0.490250\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021680; batch adversarial loss: 0.432370\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031790; batch adversarial loss: 0.446267\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027970; batch adversarial loss: 0.422863\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028630; batch adversarial loss: 0.460418\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014781; batch adversarial loss: 0.479733\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027353; batch adversarial loss: 0.499626\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015022; batch adversarial loss: 0.447532\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018704; batch adversarial loss: 0.441392\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011875; batch adversarial loss: 0.507520\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020939; batch adversarial loss: 0.452516\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021990; batch adversarial loss: 0.490424\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013412; batch adversarial loss: 0.474211\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021481; batch adversarial loss: 0.512725\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018702; batch adversarial loss: 0.492965\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018413; batch adversarial loss: 0.387875\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014582; batch adversarial loss: 0.452064\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008795; batch adversarial loss: 0.419551\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018080; batch adversarial loss: 0.486547\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008013; batch adversarial loss: 0.527195\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026637; batch adversarial loss: 0.459001\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031784; batch adversarial loss: 0.403895\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012153; batch adversarial loss: 0.457675\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022927; batch adversarial loss: 0.471747\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014108; batch adversarial loss: 0.377866\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027068; batch adversarial loss: 0.557936\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010907; batch adversarial loss: 0.470573\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011567; batch adversarial loss: 0.431357\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702049; batch adversarial loss: 0.794607\n",
      "epoch 1; iter: 0; batch classifier loss: 0.449817; batch adversarial loss: 0.780766\n",
      "epoch 2; iter: 0; batch classifier loss: 0.409863; batch adversarial loss: 0.763425\n",
      "epoch 3; iter: 0; batch classifier loss: 0.394375; batch adversarial loss: 0.700909\n",
      "epoch 4; iter: 0; batch classifier loss: 0.405150; batch adversarial loss: 0.693246\n",
      "epoch 5; iter: 0; batch classifier loss: 0.357067; batch adversarial loss: 0.655501\n",
      "epoch 6; iter: 0; batch classifier loss: 0.325227; batch adversarial loss: 0.629612\n",
      "epoch 7; iter: 0; batch classifier loss: 0.284805; batch adversarial loss: 0.616580\n",
      "epoch 8; iter: 0; batch classifier loss: 0.279088; batch adversarial loss: 0.577311\n",
      "epoch 9; iter: 0; batch classifier loss: 0.303750; batch adversarial loss: 0.524018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.274033; batch adversarial loss: 0.554621\n",
      "epoch 11; iter: 0; batch classifier loss: 0.308910; batch adversarial loss: 0.517364\n",
      "epoch 12; iter: 0; batch classifier loss: 0.369345; batch adversarial loss: 0.464030\n",
      "epoch 13; iter: 0; batch classifier loss: 0.214506; batch adversarial loss: 0.485392\n",
      "epoch 14; iter: 0; batch classifier loss: 0.286614; batch adversarial loss: 0.411847\n",
      "epoch 15; iter: 0; batch classifier loss: 0.238743; batch adversarial loss: 0.409975\n",
      "epoch 16; iter: 0; batch classifier loss: 0.202131; batch adversarial loss: 0.447505\n",
      "epoch 17; iter: 0; batch classifier loss: 0.177823; batch adversarial loss: 0.461962\n",
      "epoch 18; iter: 0; batch classifier loss: 0.229294; batch adversarial loss: 0.420734\n",
      "epoch 19; iter: 0; batch classifier loss: 0.195558; batch adversarial loss: 0.400622\n",
      "epoch 20; iter: 0; batch classifier loss: 0.200125; batch adversarial loss: 0.409738\n",
      "epoch 21; iter: 0; batch classifier loss: 0.182879; batch adversarial loss: 0.416437\n",
      "epoch 22; iter: 0; batch classifier loss: 0.219485; batch adversarial loss: 0.441598\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168868; batch adversarial loss: 0.467741\n",
      "epoch 24; iter: 0; batch classifier loss: 0.159989; batch adversarial loss: 0.407759\n",
      "epoch 25; iter: 0; batch classifier loss: 0.151630; batch adversarial loss: 0.486125\n",
      "epoch 26; iter: 0; batch classifier loss: 0.162966; batch adversarial loss: 0.491895\n",
      "epoch 27; iter: 0; batch classifier loss: 0.205479; batch adversarial loss: 0.422192\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185871; batch adversarial loss: 0.365317\n",
      "epoch 29; iter: 0; batch classifier loss: 0.174337; batch adversarial loss: 0.421046\n",
      "epoch 30; iter: 0; batch classifier loss: 0.165571; batch adversarial loss: 0.314657\n",
      "epoch 31; iter: 0; batch classifier loss: 0.158025; batch adversarial loss: 0.477726\n",
      "epoch 32; iter: 0; batch classifier loss: 0.169428; batch adversarial loss: 0.409947\n",
      "epoch 33; iter: 0; batch classifier loss: 0.116015; batch adversarial loss: 0.425673\n",
      "epoch 34; iter: 0; batch classifier loss: 0.140896; batch adversarial loss: 0.331530\n",
      "epoch 35; iter: 0; batch classifier loss: 0.157346; batch adversarial loss: 0.403892\n",
      "epoch 36; iter: 0; batch classifier loss: 0.123952; batch adversarial loss: 0.368812\n",
      "epoch 37; iter: 0; batch classifier loss: 0.099863; batch adversarial loss: 0.420619\n",
      "epoch 38; iter: 0; batch classifier loss: 0.131571; batch adversarial loss: 0.461946\n",
      "epoch 39; iter: 0; batch classifier loss: 0.091885; batch adversarial loss: 0.416322\n",
      "epoch 40; iter: 0; batch classifier loss: 0.151140; batch adversarial loss: 0.482012\n",
      "epoch 41; iter: 0; batch classifier loss: 0.117329; batch adversarial loss: 0.460021\n",
      "epoch 42; iter: 0; batch classifier loss: 0.123074; batch adversarial loss: 0.445262\n",
      "epoch 43; iter: 0; batch classifier loss: 0.092094; batch adversarial loss: 0.450827\n",
      "epoch 44; iter: 0; batch classifier loss: 0.097788; batch adversarial loss: 0.421749\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097130; batch adversarial loss: 0.439596\n",
      "epoch 46; iter: 0; batch classifier loss: 0.125151; batch adversarial loss: 0.424490\n",
      "epoch 47; iter: 0; batch classifier loss: 0.165384; batch adversarial loss: 0.422542\n",
      "epoch 48; iter: 0; batch classifier loss: 0.096296; batch adversarial loss: 0.457367\n",
      "epoch 49; iter: 0; batch classifier loss: 0.085991; batch adversarial loss: 0.425795\n",
      "epoch 50; iter: 0; batch classifier loss: 0.104344; batch adversarial loss: 0.577728\n",
      "epoch 51; iter: 0; batch classifier loss: 0.096065; batch adversarial loss: 0.352157\n",
      "epoch 52; iter: 0; batch classifier loss: 0.148478; batch adversarial loss: 0.392068\n",
      "epoch 53; iter: 0; batch classifier loss: 0.115352; batch adversarial loss: 0.506155\n",
      "epoch 54; iter: 0; batch classifier loss: 0.104110; batch adversarial loss: 0.375271\n",
      "epoch 55; iter: 0; batch classifier loss: 0.134536; batch adversarial loss: 0.405217\n",
      "epoch 56; iter: 0; batch classifier loss: 0.104217; batch adversarial loss: 0.507827\n",
      "epoch 57; iter: 0; batch classifier loss: 0.087714; batch adversarial loss: 0.347055\n",
      "epoch 58; iter: 0; batch classifier loss: 0.088926; batch adversarial loss: 0.363439\n",
      "epoch 59; iter: 0; batch classifier loss: 0.112885; batch adversarial loss: 0.464972\n",
      "epoch 60; iter: 0; batch classifier loss: 0.088491; batch adversarial loss: 0.480661\n",
      "epoch 61; iter: 0; batch classifier loss: 0.096088; batch adversarial loss: 0.437016\n",
      "epoch 62; iter: 0; batch classifier loss: 0.069692; batch adversarial loss: 0.387537\n",
      "epoch 63; iter: 0; batch classifier loss: 0.057808; batch adversarial loss: 0.412392\n",
      "epoch 64; iter: 0; batch classifier loss: 0.081734; batch adversarial loss: 0.448229\n",
      "epoch 65; iter: 0; batch classifier loss: 0.109495; batch adversarial loss: 0.456311\n",
      "epoch 66; iter: 0; batch classifier loss: 0.108955; batch adversarial loss: 0.351605\n",
      "epoch 67; iter: 0; batch classifier loss: 0.093609; batch adversarial loss: 0.452242\n",
      "epoch 68; iter: 0; batch classifier loss: 0.090998; batch adversarial loss: 0.486042\n",
      "epoch 69; iter: 0; batch classifier loss: 0.079048; batch adversarial loss: 0.338717\n",
      "epoch 70; iter: 0; batch classifier loss: 0.100341; batch adversarial loss: 0.429787\n",
      "epoch 71; iter: 0; batch classifier loss: 0.096318; batch adversarial loss: 0.472798\n",
      "epoch 72; iter: 0; batch classifier loss: 0.066744; batch adversarial loss: 0.497861\n",
      "epoch 73; iter: 0; batch classifier loss: 0.091728; batch adversarial loss: 0.434400\n",
      "epoch 74; iter: 0; batch classifier loss: 0.062076; batch adversarial loss: 0.453294\n",
      "epoch 75; iter: 0; batch classifier loss: 0.044180; batch adversarial loss: 0.451269\n",
      "epoch 76; iter: 0; batch classifier loss: 0.061118; batch adversarial loss: 0.397789\n",
      "epoch 77; iter: 0; batch classifier loss: 0.075576; batch adversarial loss: 0.441850\n",
      "epoch 78; iter: 0; batch classifier loss: 0.070034; batch adversarial loss: 0.427460\n",
      "epoch 79; iter: 0; batch classifier loss: 0.043414; batch adversarial loss: 0.523703\n",
      "epoch 80; iter: 0; batch classifier loss: 0.080226; batch adversarial loss: 0.478240\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074705; batch adversarial loss: 0.328419\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052317; batch adversarial loss: 0.468727\n",
      "epoch 83; iter: 0; batch classifier loss: 0.033908; batch adversarial loss: 0.445776\n",
      "epoch 84; iter: 0; batch classifier loss: 0.057442; batch adversarial loss: 0.370837\n",
      "epoch 85; iter: 0; batch classifier loss: 0.038872; batch adversarial loss: 0.508617\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046349; batch adversarial loss: 0.480067\n",
      "epoch 87; iter: 0; batch classifier loss: 0.034621; batch adversarial loss: 0.394333\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062235; batch adversarial loss: 0.382573\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080441; batch adversarial loss: 0.428652\n",
      "epoch 90; iter: 0; batch classifier loss: 0.028416; batch adversarial loss: 0.454393\n",
      "epoch 91; iter: 0; batch classifier loss: 0.078280; batch adversarial loss: 0.436259\n",
      "epoch 92; iter: 0; batch classifier loss: 0.031642; batch adversarial loss: 0.518780\n",
      "epoch 93; iter: 0; batch classifier loss: 0.031787; batch adversarial loss: 0.424233\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033937; batch adversarial loss: 0.506625\n",
      "epoch 95; iter: 0; batch classifier loss: 0.024090; batch adversarial loss: 0.421076\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037687; batch adversarial loss: 0.528128\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037303; batch adversarial loss: 0.531051\n",
      "epoch 98; iter: 0; batch classifier loss: 0.032213; batch adversarial loss: 0.481155\n",
      "epoch 99; iter: 0; batch classifier loss: 0.016239; batch adversarial loss: 0.536823\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050615; batch adversarial loss: 0.341471\n",
      "epoch 101; iter: 0; batch classifier loss: 0.045347; batch adversarial loss: 0.449981\n",
      "epoch 102; iter: 0; batch classifier loss: 0.020999; batch adversarial loss: 0.472678\n",
      "epoch 103; iter: 0; batch classifier loss: 0.027900; batch adversarial loss: 0.476354\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063567; batch adversarial loss: 0.521625\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059999; batch adversarial loss: 0.327286\n",
      "epoch 106; iter: 0; batch classifier loss: 0.023708; batch adversarial loss: 0.475348\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063498; batch adversarial loss: 0.504821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.028840; batch adversarial loss: 0.403439\n",
      "epoch 109; iter: 0; batch classifier loss: 0.116776; batch adversarial loss: 0.634356\n",
      "epoch 110; iter: 0; batch classifier loss: 0.080288; batch adversarial loss: 0.520916\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042514; batch adversarial loss: 0.440113\n",
      "epoch 112; iter: 0; batch classifier loss: 0.158613; batch adversarial loss: 0.656567\n",
      "epoch 113; iter: 0; batch classifier loss: 0.122849; batch adversarial loss: 0.501120\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060904; batch adversarial loss: 0.475788\n",
      "epoch 115; iter: 0; batch classifier loss: 0.168123; batch adversarial loss: 0.689565\n",
      "epoch 116; iter: 0; batch classifier loss: 0.179955; batch adversarial loss: 0.755064\n",
      "epoch 117; iter: 0; batch classifier loss: 0.187611; batch adversarial loss: 0.681309\n",
      "epoch 118; iter: 0; batch classifier loss: 0.202789; batch adversarial loss: 0.564774\n",
      "epoch 119; iter: 0; batch classifier loss: 0.216841; batch adversarial loss: 0.783595\n",
      "epoch 120; iter: 0; batch classifier loss: 0.079183; batch adversarial loss: 0.478854\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057120; batch adversarial loss: 0.492965\n",
      "epoch 122; iter: 0; batch classifier loss: 0.267365; batch adversarial loss: 0.690632\n",
      "epoch 123; iter: 0; batch classifier loss: 0.141699; batch adversarial loss: 0.540831\n",
      "epoch 124; iter: 0; batch classifier loss: 0.141332; batch adversarial loss: 0.558757\n",
      "epoch 125; iter: 0; batch classifier loss: 0.077745; batch adversarial loss: 0.446258\n",
      "epoch 126; iter: 0; batch classifier loss: 0.199247; batch adversarial loss: 0.664103\n",
      "epoch 127; iter: 0; batch classifier loss: 0.122843; batch adversarial loss: 0.484847\n",
      "epoch 128; iter: 0; batch classifier loss: 0.236722; batch adversarial loss: 0.698527\n",
      "epoch 129; iter: 0; batch classifier loss: 0.132838; batch adversarial loss: 0.552384\n",
      "epoch 130; iter: 0; batch classifier loss: 0.093059; batch adversarial loss: 0.534326\n",
      "epoch 131; iter: 0; batch classifier loss: 0.182603; batch adversarial loss: 0.554969\n",
      "epoch 132; iter: 0; batch classifier loss: 0.184255; batch adversarial loss: 0.529450\n",
      "epoch 133; iter: 0; batch classifier loss: 0.108698; batch adversarial loss: 0.421350\n",
      "epoch 134; iter: 0; batch classifier loss: 0.083158; batch adversarial loss: 0.425724\n",
      "epoch 135; iter: 0; batch classifier loss: 0.111812; batch adversarial loss: 0.496284\n",
      "epoch 136; iter: 0; batch classifier loss: 0.174344; batch adversarial loss: 0.659481\n",
      "epoch 137; iter: 0; batch classifier loss: 0.173677; batch adversarial loss: 0.552727\n",
      "epoch 138; iter: 0; batch classifier loss: 0.116731; batch adversarial loss: 0.498873\n",
      "epoch 139; iter: 0; batch classifier loss: 0.143632; batch adversarial loss: 0.552517\n",
      "epoch 140; iter: 0; batch classifier loss: 0.113667; batch adversarial loss: 0.531915\n",
      "epoch 141; iter: 0; batch classifier loss: 0.088286; batch adversarial loss: 0.470337\n",
      "epoch 142; iter: 0; batch classifier loss: 0.135112; batch adversarial loss: 0.522526\n",
      "epoch 143; iter: 0; batch classifier loss: 0.113688; batch adversarial loss: 0.442745\n",
      "epoch 144; iter: 0; batch classifier loss: 0.108453; batch adversarial loss: 0.438796\n",
      "epoch 145; iter: 0; batch classifier loss: 0.065909; batch adversarial loss: 0.478424\n",
      "epoch 146; iter: 0; batch classifier loss: 0.101747; batch adversarial loss: 0.444300\n",
      "epoch 147; iter: 0; batch classifier loss: 0.092808; batch adversarial loss: 0.451748\n",
      "epoch 148; iter: 0; batch classifier loss: 0.094968; batch adversarial loss: 0.447810\n",
      "epoch 149; iter: 0; batch classifier loss: 0.078342; batch adversarial loss: 0.446919\n",
      "epoch 150; iter: 0; batch classifier loss: 0.050556; batch adversarial loss: 0.409980\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030432; batch adversarial loss: 0.396165\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020292; batch adversarial loss: 0.556137\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026404; batch adversarial loss: 0.516511\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043787; batch adversarial loss: 0.429778\n",
      "epoch 155; iter: 0; batch classifier loss: 0.055975; batch adversarial loss: 0.420240\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011460; batch adversarial loss: 0.392943\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042758; batch adversarial loss: 0.452950\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042113; batch adversarial loss: 0.436295\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033884; batch adversarial loss: 0.395128\n",
      "epoch 160; iter: 0; batch classifier loss: 0.039687; batch adversarial loss: 0.601842\n",
      "epoch 161; iter: 0; batch classifier loss: 0.053805; batch adversarial loss: 0.355137\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023608; batch adversarial loss: 0.457317\n",
      "epoch 163; iter: 0; batch classifier loss: 0.031434; batch adversarial loss: 0.530040\n",
      "epoch 164; iter: 0; batch classifier loss: 0.045256; batch adversarial loss: 0.467445\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032302; batch adversarial loss: 0.438425\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037532; batch adversarial loss: 0.463734\n",
      "epoch 167; iter: 0; batch classifier loss: 0.079507; batch adversarial loss: 0.524934\n",
      "epoch 168; iter: 0; batch classifier loss: 0.041741; batch adversarial loss: 0.464071\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026614; batch adversarial loss: 0.385312\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012718; batch adversarial loss: 0.560765\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029246; batch adversarial loss: 0.537388\n",
      "epoch 172; iter: 0; batch classifier loss: 0.087091; batch adversarial loss: 0.412448\n",
      "epoch 173; iter: 0; batch classifier loss: 0.041428; batch adversarial loss: 0.376679\n",
      "epoch 174; iter: 0; batch classifier loss: 0.059818; batch adversarial loss: 0.498961\n",
      "epoch 175; iter: 0; batch classifier loss: 0.056419; batch adversarial loss: 0.496238\n",
      "epoch 176; iter: 0; batch classifier loss: 0.048194; batch adversarial loss: 0.426257\n",
      "epoch 177; iter: 0; batch classifier loss: 0.051236; batch adversarial loss: 0.465889\n",
      "epoch 178; iter: 0; batch classifier loss: 0.043988; batch adversarial loss: 0.399031\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034331; batch adversarial loss: 0.412444\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031473; batch adversarial loss: 0.438855\n",
      "epoch 181; iter: 0; batch classifier loss: 0.054493; batch adversarial loss: 0.412844\n",
      "epoch 182; iter: 0; batch classifier loss: 0.043640; batch adversarial loss: 0.405529\n",
      "epoch 183; iter: 0; batch classifier loss: 0.048858; batch adversarial loss: 0.416598\n",
      "epoch 184; iter: 0; batch classifier loss: 0.057167; batch adversarial loss: 0.509254\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028025; batch adversarial loss: 0.438182\n",
      "epoch 186; iter: 0; batch classifier loss: 0.058516; batch adversarial loss: 0.508010\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035638; batch adversarial loss: 0.469638\n",
      "epoch 188; iter: 0; batch classifier loss: 0.080666; batch adversarial loss: 0.443547\n",
      "epoch 189; iter: 0; batch classifier loss: 0.078595; batch adversarial loss: 0.438783\n",
      "epoch 190; iter: 0; batch classifier loss: 0.033531; batch adversarial loss: 0.381034\n",
      "epoch 191; iter: 0; batch classifier loss: 0.051811; batch adversarial loss: 0.401089\n",
      "epoch 192; iter: 0; batch classifier loss: 0.063484; batch adversarial loss: 0.511784\n",
      "epoch 193; iter: 0; batch classifier loss: 0.061673; batch adversarial loss: 0.532240\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035382; batch adversarial loss: 0.491200\n",
      "epoch 195; iter: 0; batch classifier loss: 0.044838; batch adversarial loss: 0.538466\n",
      "epoch 196; iter: 0; batch classifier loss: 0.045083; batch adversarial loss: 0.483402\n",
      "epoch 197; iter: 0; batch classifier loss: 0.079154; batch adversarial loss: 0.411408\n",
      "epoch 198; iter: 0; batch classifier loss: 0.064522; batch adversarial loss: 0.549951\n",
      "epoch 199; iter: 0; batch classifier loss: 0.052705; batch adversarial loss: 0.465900\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690436; batch adversarial loss: 0.891275\n",
      "epoch 1; iter: 0; batch classifier loss: 0.374098; batch adversarial loss: 0.854250\n",
      "epoch 2; iter: 0; batch classifier loss: 0.358242; batch adversarial loss: 0.826845\n",
      "epoch 3; iter: 0; batch classifier loss: 0.301935; batch adversarial loss: 0.740786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.312268; batch adversarial loss: 0.703164\n",
      "epoch 5; iter: 0; batch classifier loss: 0.313322; batch adversarial loss: 0.659707\n",
      "epoch 6; iter: 0; batch classifier loss: 0.323075; batch adversarial loss: 0.662588\n",
      "epoch 7; iter: 0; batch classifier loss: 0.332509; batch adversarial loss: 0.615121\n",
      "epoch 8; iter: 0; batch classifier loss: 0.368928; batch adversarial loss: 0.638110\n",
      "epoch 9; iter: 0; batch classifier loss: 0.293099; batch adversarial loss: 0.570602\n",
      "epoch 10; iter: 0; batch classifier loss: 0.230003; batch adversarial loss: 0.541026\n",
      "epoch 11; iter: 0; batch classifier loss: 0.299172; batch adversarial loss: 0.545989\n",
      "epoch 12; iter: 0; batch classifier loss: 0.283230; batch adversarial loss: 0.517876\n",
      "epoch 13; iter: 0; batch classifier loss: 0.267835; batch adversarial loss: 0.521466\n",
      "epoch 14; iter: 0; batch classifier loss: 0.270521; batch adversarial loss: 0.483084\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307272; batch adversarial loss: 0.463324\n",
      "epoch 16; iter: 0; batch classifier loss: 0.330580; batch adversarial loss: 0.444698\n",
      "epoch 17; iter: 0; batch classifier loss: 0.207624; batch adversarial loss: 0.493967\n",
      "epoch 18; iter: 0; batch classifier loss: 0.247565; batch adversarial loss: 0.459974\n",
      "epoch 19; iter: 0; batch classifier loss: 0.215391; batch adversarial loss: 0.412465\n",
      "epoch 20; iter: 0; batch classifier loss: 0.238510; batch adversarial loss: 0.361508\n",
      "epoch 21; iter: 0; batch classifier loss: 0.242053; batch adversarial loss: 0.417608\n",
      "epoch 22; iter: 0; batch classifier loss: 0.321210; batch adversarial loss: 0.407873\n",
      "epoch 23; iter: 0; batch classifier loss: 0.185341; batch adversarial loss: 0.475622\n",
      "epoch 24; iter: 0; batch classifier loss: 0.224949; batch adversarial loss: 0.407455\n",
      "epoch 25; iter: 0; batch classifier loss: 0.301640; batch adversarial loss: 0.387917\n",
      "epoch 26; iter: 0; batch classifier loss: 0.239406; batch adversarial loss: 0.397729\n",
      "epoch 27; iter: 0; batch classifier loss: 0.172779; batch adversarial loss: 0.350653\n",
      "epoch 28; iter: 0; batch classifier loss: 0.201157; batch adversarial loss: 0.399491\n",
      "epoch 29; iter: 0; batch classifier loss: 0.229652; batch adversarial loss: 0.389402\n",
      "epoch 30; iter: 0; batch classifier loss: 0.189820; batch adversarial loss: 0.348235\n",
      "epoch 31; iter: 0; batch classifier loss: 0.165419; batch adversarial loss: 0.398704\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181617; batch adversarial loss: 0.418394\n",
      "epoch 33; iter: 0; batch classifier loss: 0.208188; batch adversarial loss: 0.379692\n",
      "epoch 34; iter: 0; batch classifier loss: 0.174207; batch adversarial loss: 0.429837\n",
      "epoch 35; iter: 0; batch classifier loss: 0.194054; batch adversarial loss: 0.449485\n",
      "epoch 36; iter: 0; batch classifier loss: 0.160961; batch adversarial loss: 0.336823\n",
      "epoch 37; iter: 0; batch classifier loss: 0.164883; batch adversarial loss: 0.385355\n",
      "epoch 38; iter: 0; batch classifier loss: 0.162268; batch adversarial loss: 0.479072\n",
      "epoch 39; iter: 0; batch classifier loss: 0.191051; batch adversarial loss: 0.418937\n",
      "epoch 40; iter: 0; batch classifier loss: 0.125575; batch adversarial loss: 0.392093\n",
      "epoch 41; iter: 0; batch classifier loss: 0.147727; batch adversarial loss: 0.384644\n",
      "epoch 42; iter: 0; batch classifier loss: 0.083453; batch adversarial loss: 0.409026\n",
      "epoch 43; iter: 0; batch classifier loss: 0.130734; batch adversarial loss: 0.423833\n",
      "epoch 44; iter: 0; batch classifier loss: 0.137307; batch adversarial loss: 0.357931\n",
      "epoch 45; iter: 0; batch classifier loss: 0.073320; batch adversarial loss: 0.363918\n",
      "epoch 46; iter: 0; batch classifier loss: 0.131105; batch adversarial loss: 0.324136\n",
      "epoch 47; iter: 0; batch classifier loss: 0.178756; batch adversarial loss: 0.419022\n",
      "epoch 48; iter: 0; batch classifier loss: 0.137373; batch adversarial loss: 0.487741\n",
      "epoch 49; iter: 0; batch classifier loss: 0.109483; batch adversarial loss: 0.414360\n",
      "epoch 50; iter: 0; batch classifier loss: 0.121629; batch adversarial loss: 0.359246\n",
      "epoch 51; iter: 0; batch classifier loss: 0.097883; batch adversarial loss: 0.372773\n",
      "epoch 52; iter: 0; batch classifier loss: 0.110485; batch adversarial loss: 0.402171\n",
      "epoch 53; iter: 0; batch classifier loss: 0.126855; batch adversarial loss: 0.361873\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095159; batch adversarial loss: 0.472322\n",
      "epoch 55; iter: 0; batch classifier loss: 0.078319; batch adversarial loss: 0.458847\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119864; batch adversarial loss: 0.381883\n",
      "epoch 57; iter: 0; batch classifier loss: 0.113117; batch adversarial loss: 0.453616\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097293; batch adversarial loss: 0.431626\n",
      "epoch 59; iter: 0; batch classifier loss: 0.103640; batch adversarial loss: 0.433292\n",
      "epoch 60; iter: 0; batch classifier loss: 0.141954; batch adversarial loss: 0.378961\n",
      "epoch 61; iter: 0; batch classifier loss: 0.073028; batch adversarial loss: 0.433520\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078791; batch adversarial loss: 0.329560\n",
      "epoch 63; iter: 0; batch classifier loss: 0.081807; batch adversarial loss: 0.370146\n",
      "epoch 64; iter: 0; batch classifier loss: 0.093653; batch adversarial loss: 0.454770\n",
      "epoch 65; iter: 0; batch classifier loss: 0.101146; batch adversarial loss: 0.345426\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089523; batch adversarial loss: 0.411892\n",
      "epoch 67; iter: 0; batch classifier loss: 0.109642; batch adversarial loss: 0.418410\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082659; batch adversarial loss: 0.428759\n",
      "epoch 69; iter: 0; batch classifier loss: 0.053877; batch adversarial loss: 0.394036\n",
      "epoch 70; iter: 0; batch classifier loss: 0.060891; batch adversarial loss: 0.474237\n",
      "epoch 71; iter: 0; batch classifier loss: 0.086786; batch adversarial loss: 0.434377\n",
      "epoch 72; iter: 0; batch classifier loss: 0.079210; batch adversarial loss: 0.404211\n",
      "epoch 73; iter: 0; batch classifier loss: 0.098805; batch adversarial loss: 0.258262\n",
      "epoch 74; iter: 0; batch classifier loss: 0.065602; batch adversarial loss: 0.414061\n",
      "epoch 75; iter: 0; batch classifier loss: 0.068633; batch adversarial loss: 0.393335\n",
      "epoch 76; iter: 0; batch classifier loss: 0.053285; batch adversarial loss: 0.468788\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084032; batch adversarial loss: 0.509362\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066942; batch adversarial loss: 0.391759\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065457; batch adversarial loss: 0.447961\n",
      "epoch 80; iter: 0; batch classifier loss: 0.085315; batch adversarial loss: 0.370077\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073211; batch adversarial loss: 0.455967\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065668; batch adversarial loss: 0.436993\n",
      "epoch 83; iter: 0; batch classifier loss: 0.094461; batch adversarial loss: 0.460382\n",
      "epoch 84; iter: 0; batch classifier loss: 0.083097; batch adversarial loss: 0.423538\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088033; batch adversarial loss: 0.325498\n",
      "epoch 86; iter: 0; batch classifier loss: 0.093357; batch adversarial loss: 0.421043\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082555; batch adversarial loss: 0.410758\n",
      "epoch 88; iter: 0; batch classifier loss: 0.077870; batch adversarial loss: 0.464908\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060205; batch adversarial loss: 0.324164\n",
      "epoch 90; iter: 0; batch classifier loss: 0.098304; batch adversarial loss: 0.441792\n",
      "epoch 91; iter: 0; batch classifier loss: 0.089414; batch adversarial loss: 0.384467\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071425; batch adversarial loss: 0.382675\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064979; batch adversarial loss: 0.367441\n",
      "epoch 94; iter: 0; batch classifier loss: 0.080701; batch adversarial loss: 0.447766\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052661; batch adversarial loss: 0.461998\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048213; batch adversarial loss: 0.374789\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042719; batch adversarial loss: 0.418924\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054965; batch adversarial loss: 0.341248\n",
      "epoch 99; iter: 0; batch classifier loss: 0.084876; batch adversarial loss: 0.443674\n",
      "epoch 100; iter: 0; batch classifier loss: 0.101482; batch adversarial loss: 0.404199\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050977; batch adversarial loss: 0.391698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.074589; batch adversarial loss: 0.389863\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063089; batch adversarial loss: 0.373509\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041767; batch adversarial loss: 0.457520\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050570; batch adversarial loss: 0.369046\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050880; batch adversarial loss: 0.393148\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041104; batch adversarial loss: 0.392450\n",
      "epoch 108; iter: 0; batch classifier loss: 0.075571; batch adversarial loss: 0.319606\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047993; batch adversarial loss: 0.391251\n",
      "epoch 110; iter: 0; batch classifier loss: 0.080482; batch adversarial loss: 0.436828\n",
      "epoch 111; iter: 0; batch classifier loss: 0.071095; batch adversarial loss: 0.439935\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046396; batch adversarial loss: 0.492391\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027679; batch adversarial loss: 0.562101\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052290; batch adversarial loss: 0.395446\n",
      "epoch 115; iter: 0; batch classifier loss: 0.072549; batch adversarial loss: 0.475487\n",
      "epoch 116; iter: 0; batch classifier loss: 0.064900; batch adversarial loss: 0.378134\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035603; batch adversarial loss: 0.420214\n",
      "epoch 118; iter: 0; batch classifier loss: 0.038611; batch adversarial loss: 0.558871\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033229; batch adversarial loss: 0.434059\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032888; batch adversarial loss: 0.398602\n",
      "epoch 121; iter: 0; batch classifier loss: 0.083241; batch adversarial loss: 0.540171\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041964; batch adversarial loss: 0.404720\n",
      "epoch 123; iter: 0; batch classifier loss: 0.020145; batch adversarial loss: 0.455986\n",
      "epoch 124; iter: 0; batch classifier loss: 0.063273; batch adversarial loss: 0.340805\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036569; batch adversarial loss: 0.390896\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032797; batch adversarial loss: 0.398670\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053363; batch adversarial loss: 0.514077\n",
      "epoch 128; iter: 0; batch classifier loss: 0.013395; batch adversarial loss: 0.364951\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059020; batch adversarial loss: 0.395860\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048042; batch adversarial loss: 0.361993\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023891; batch adversarial loss: 0.505819\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035836; batch adversarial loss: 0.488701\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049855; batch adversarial loss: 0.438568\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037246; batch adversarial loss: 0.435241\n",
      "epoch 135; iter: 0; batch classifier loss: 0.054351; batch adversarial loss: 0.385721\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038134; batch adversarial loss: 0.474248\n",
      "epoch 137; iter: 0; batch classifier loss: 0.057236; batch adversarial loss: 0.399644\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021487; batch adversarial loss: 0.448771\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009841; batch adversarial loss: 0.414780\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023529; batch adversarial loss: 0.398610\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031807; batch adversarial loss: 0.520676\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033948; batch adversarial loss: 0.420918\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025198; batch adversarial loss: 0.432490\n",
      "epoch 144; iter: 0; batch classifier loss: 0.054551; batch adversarial loss: 0.476805\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041009; batch adversarial loss: 0.462724\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028449; batch adversarial loss: 0.461392\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046473; batch adversarial loss: 0.360177\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034758; batch adversarial loss: 0.491683\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034846; batch adversarial loss: 0.381390\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022326; batch adversarial loss: 0.402215\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025421; batch adversarial loss: 0.452458\n",
      "epoch 152; iter: 0; batch classifier loss: 0.006979; batch adversarial loss: 0.334956\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011530; batch adversarial loss: 0.461445\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012976; batch adversarial loss: 0.490471\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028040; batch adversarial loss: 0.460428\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029602; batch adversarial loss: 0.392944\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024052; batch adversarial loss: 0.469725\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048759; batch adversarial loss: 0.426743\n",
      "epoch 159; iter: 0; batch classifier loss: 0.064001; batch adversarial loss: 0.566666\n",
      "epoch 160; iter: 0; batch classifier loss: 0.058599; batch adversarial loss: 0.560788\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037674; batch adversarial loss: 0.555227\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016539; batch adversarial loss: 0.468694\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032966; batch adversarial loss: 0.441558\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033334; batch adversarial loss: 0.518265\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018899; batch adversarial loss: 0.401305\n",
      "epoch 166; iter: 0; batch classifier loss: 0.140795; batch adversarial loss: 0.732625\n",
      "epoch 167; iter: 0; batch classifier loss: 0.055103; batch adversarial loss: 0.501988\n",
      "epoch 168; iter: 0; batch classifier loss: 0.087706; batch adversarial loss: 0.512114\n",
      "epoch 169; iter: 0; batch classifier loss: 0.052582; batch adversarial loss: 0.514176\n",
      "epoch 170; iter: 0; batch classifier loss: 0.119659; batch adversarial loss: 0.542027\n",
      "epoch 171; iter: 0; batch classifier loss: 0.117411; batch adversarial loss: 0.626656\n",
      "epoch 172; iter: 0; batch classifier loss: 0.131824; batch adversarial loss: 0.602038\n",
      "epoch 173; iter: 0; batch classifier loss: 0.100835; batch adversarial loss: 0.608299\n",
      "epoch 174; iter: 0; batch classifier loss: 0.127012; batch adversarial loss: 0.488437\n",
      "epoch 175; iter: 0; batch classifier loss: 0.145728; batch adversarial loss: 0.639748\n",
      "epoch 176; iter: 0; batch classifier loss: 0.124966; batch adversarial loss: 0.567046\n",
      "epoch 177; iter: 0; batch classifier loss: 0.176107; batch adversarial loss: 0.708303\n",
      "epoch 178; iter: 0; batch classifier loss: 0.115302; batch adversarial loss: 0.617878\n",
      "epoch 179; iter: 0; batch classifier loss: 0.127662; batch adversarial loss: 0.605320\n",
      "epoch 180; iter: 0; batch classifier loss: 0.170941; batch adversarial loss: 0.621228\n",
      "epoch 181; iter: 0; batch classifier loss: 0.238046; batch adversarial loss: 0.817156\n",
      "epoch 182; iter: 0; batch classifier loss: 0.173663; batch adversarial loss: 0.660731\n",
      "epoch 183; iter: 0; batch classifier loss: 0.211934; batch adversarial loss: 0.759283\n",
      "epoch 184; iter: 0; batch classifier loss: 0.206903; batch adversarial loss: 0.661836\n",
      "epoch 185; iter: 0; batch classifier loss: 0.114870; batch adversarial loss: 0.571710\n",
      "epoch 186; iter: 0; batch classifier loss: 0.107665; batch adversarial loss: 0.481445\n",
      "epoch 187; iter: 0; batch classifier loss: 0.106115; batch adversarial loss: 0.522451\n",
      "epoch 188; iter: 0; batch classifier loss: 0.143458; batch adversarial loss: 0.597024\n",
      "epoch 189; iter: 0; batch classifier loss: 0.167285; batch adversarial loss: 0.653496\n",
      "epoch 190; iter: 0; batch classifier loss: 0.064073; batch adversarial loss: 0.424055\n",
      "epoch 191; iter: 0; batch classifier loss: 0.199576; batch adversarial loss: 0.821226\n",
      "epoch 192; iter: 0; batch classifier loss: 0.126190; batch adversarial loss: 0.534793\n",
      "epoch 193; iter: 0; batch classifier loss: 0.172431; batch adversarial loss: 0.584249\n",
      "epoch 194; iter: 0; batch classifier loss: 0.127237; batch adversarial loss: 0.513997\n",
      "epoch 195; iter: 0; batch classifier loss: 0.152277; batch adversarial loss: 0.587468\n",
      "epoch 196; iter: 0; batch classifier loss: 0.190074; batch adversarial loss: 0.655364\n",
      "epoch 197; iter: 0; batch classifier loss: 0.082911; batch adversarial loss: 0.406485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.140560; batch adversarial loss: 0.571100\n",
      "epoch 199; iter: 0; batch classifier loss: 0.104313; batch adversarial loss: 0.468268\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710191; batch adversarial loss: 0.774595\n",
      "epoch 1; iter: 0; batch classifier loss: 0.469218; batch adversarial loss: 0.721295\n",
      "epoch 2; iter: 0; batch classifier loss: 0.416176; batch adversarial loss: 0.678798\n",
      "epoch 3; iter: 0; batch classifier loss: 0.429090; batch adversarial loss: 0.645671\n",
      "epoch 4; iter: 0; batch classifier loss: 0.310582; batch adversarial loss: 0.602975\n",
      "epoch 5; iter: 0; batch classifier loss: 0.310453; batch adversarial loss: 0.576045\n",
      "epoch 6; iter: 0; batch classifier loss: 0.230200; batch adversarial loss: 0.560289\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300246; batch adversarial loss: 0.535865\n",
      "epoch 8; iter: 0; batch classifier loss: 0.242477; batch adversarial loss: 0.526700\n",
      "epoch 9; iter: 0; batch classifier loss: 0.291246; batch adversarial loss: 0.479374\n",
      "epoch 10; iter: 0; batch classifier loss: 0.198156; batch adversarial loss: 0.528197\n",
      "epoch 11; iter: 0; batch classifier loss: 0.202588; batch adversarial loss: 0.504131\n",
      "epoch 12; iter: 0; batch classifier loss: 0.247010; batch adversarial loss: 0.511220\n",
      "epoch 13; iter: 0; batch classifier loss: 0.268029; batch adversarial loss: 0.558212\n",
      "epoch 14; iter: 0; batch classifier loss: 0.264225; batch adversarial loss: 0.503297\n",
      "epoch 15; iter: 0; batch classifier loss: 0.279083; batch adversarial loss: 0.508639\n",
      "epoch 16; iter: 0; batch classifier loss: 0.186917; batch adversarial loss: 0.413517\n",
      "epoch 17; iter: 0; batch classifier loss: 0.238378; batch adversarial loss: 0.538078\n",
      "epoch 18; iter: 0; batch classifier loss: 0.263804; batch adversarial loss: 0.532151\n",
      "epoch 19; iter: 0; batch classifier loss: 0.270416; batch adversarial loss: 0.390496\n",
      "epoch 20; iter: 0; batch classifier loss: 0.379355; batch adversarial loss: 0.489804\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478400; batch adversarial loss: 0.518257\n",
      "epoch 22; iter: 0; batch classifier loss: 0.317237; batch adversarial loss: 0.442847\n",
      "epoch 23; iter: 0; batch classifier loss: 0.380937; batch adversarial loss: 0.466742\n",
      "epoch 24; iter: 0; batch classifier loss: 0.224166; batch adversarial loss: 0.509565\n",
      "epoch 25; iter: 0; batch classifier loss: 0.191045; batch adversarial loss: 0.453659\n",
      "epoch 26; iter: 0; batch classifier loss: 0.133287; batch adversarial loss: 0.479163\n",
      "epoch 27; iter: 0; batch classifier loss: 0.197132; batch adversarial loss: 0.508696\n",
      "epoch 28; iter: 0; batch classifier loss: 0.147920; batch adversarial loss: 0.490564\n",
      "epoch 29; iter: 0; batch classifier loss: 0.182202; batch adversarial loss: 0.414106\n",
      "epoch 30; iter: 0; batch classifier loss: 0.145961; batch adversarial loss: 0.510244\n",
      "epoch 31; iter: 0; batch classifier loss: 0.134568; batch adversarial loss: 0.424907\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146206; batch adversarial loss: 0.491738\n",
      "epoch 33; iter: 0; batch classifier loss: 0.139464; batch adversarial loss: 0.450092\n",
      "epoch 34; iter: 0; batch classifier loss: 0.118017; batch adversarial loss: 0.467070\n",
      "epoch 35; iter: 0; batch classifier loss: 0.147986; batch adversarial loss: 0.360472\n",
      "epoch 36; iter: 0; batch classifier loss: 0.163288; batch adversarial loss: 0.397931\n",
      "epoch 37; iter: 0; batch classifier loss: 0.150886; batch adversarial loss: 0.414633\n",
      "epoch 38; iter: 0; batch classifier loss: 0.096679; batch adversarial loss: 0.460414\n",
      "epoch 39; iter: 0; batch classifier loss: 0.138899; batch adversarial loss: 0.428883\n",
      "epoch 40; iter: 0; batch classifier loss: 0.140171; batch adversarial loss: 0.435067\n",
      "epoch 41; iter: 0; batch classifier loss: 0.148304; batch adversarial loss: 0.426633\n",
      "epoch 42; iter: 0; batch classifier loss: 0.199354; batch adversarial loss: 0.508872\n",
      "epoch 43; iter: 0; batch classifier loss: 0.092375; batch adversarial loss: 0.378890\n",
      "epoch 44; iter: 0; batch classifier loss: 0.163843; batch adversarial loss: 0.435512\n",
      "epoch 45; iter: 0; batch classifier loss: 0.113207; batch adversarial loss: 0.552429\n",
      "epoch 46; iter: 0; batch classifier loss: 0.090451; batch adversarial loss: 0.503389\n",
      "epoch 47; iter: 0; batch classifier loss: 0.121625; batch adversarial loss: 0.486392\n",
      "epoch 48; iter: 0; batch classifier loss: 0.128979; batch adversarial loss: 0.418061\n",
      "epoch 49; iter: 0; batch classifier loss: 0.090524; batch adversarial loss: 0.548585\n",
      "epoch 50; iter: 0; batch classifier loss: 0.141315; batch adversarial loss: 0.394290\n",
      "epoch 51; iter: 0; batch classifier loss: 0.107733; batch adversarial loss: 0.521986\n",
      "epoch 52; iter: 0; batch classifier loss: 0.107084; batch adversarial loss: 0.556174\n",
      "epoch 53; iter: 0; batch classifier loss: 0.133216; batch adversarial loss: 0.405808\n",
      "epoch 54; iter: 0; batch classifier loss: 0.126005; batch adversarial loss: 0.483720\n",
      "epoch 55; iter: 0; batch classifier loss: 0.163376; batch adversarial loss: 0.457589\n",
      "epoch 56; iter: 0; batch classifier loss: 0.163028; batch adversarial loss: 0.492890\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095955; batch adversarial loss: 0.474763\n",
      "epoch 58; iter: 0; batch classifier loss: 0.118523; batch adversarial loss: 0.429766\n",
      "epoch 59; iter: 0; batch classifier loss: 0.098946; batch adversarial loss: 0.454074\n",
      "epoch 60; iter: 0; batch classifier loss: 0.103280; batch adversarial loss: 0.482210\n",
      "epoch 61; iter: 0; batch classifier loss: 0.126932; batch adversarial loss: 0.470884\n",
      "epoch 62; iter: 0; batch classifier loss: 0.109741; batch adversarial loss: 0.386498\n",
      "epoch 63; iter: 0; batch classifier loss: 0.080548; batch adversarial loss: 0.473809\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082821; batch adversarial loss: 0.442899\n",
      "epoch 65; iter: 0; batch classifier loss: 0.133843; batch adversarial loss: 0.441847\n",
      "epoch 66; iter: 0; batch classifier loss: 0.135581; batch adversarial loss: 0.441270\n",
      "epoch 67; iter: 0; batch classifier loss: 0.104154; batch adversarial loss: 0.492424\n",
      "epoch 68; iter: 0; batch classifier loss: 0.093918; batch adversarial loss: 0.593550\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087116; batch adversarial loss: 0.446483\n",
      "epoch 70; iter: 0; batch classifier loss: 0.140480; batch adversarial loss: 0.470749\n",
      "epoch 71; iter: 0; batch classifier loss: 0.144112; batch adversarial loss: 0.432289\n",
      "epoch 72; iter: 0; batch classifier loss: 0.125180; batch adversarial loss: 0.532744\n",
      "epoch 73; iter: 0; batch classifier loss: 0.095281; batch adversarial loss: 0.489776\n",
      "epoch 74; iter: 0; batch classifier loss: 0.102641; batch adversarial loss: 0.508627\n",
      "epoch 75; iter: 0; batch classifier loss: 0.100820; batch adversarial loss: 0.450409\n",
      "epoch 76; iter: 0; batch classifier loss: 0.053771; batch adversarial loss: 0.464094\n",
      "epoch 77; iter: 0; batch classifier loss: 0.071089; batch adversarial loss: 0.462111\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062947; batch adversarial loss: 0.416326\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060585; batch adversarial loss: 0.452692\n",
      "epoch 80; iter: 0; batch classifier loss: 0.114453; batch adversarial loss: 0.434001\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083727; batch adversarial loss: 0.521767\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063056; batch adversarial loss: 0.380726\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071407; batch adversarial loss: 0.441272\n",
      "epoch 84; iter: 0; batch classifier loss: 0.088447; batch adversarial loss: 0.469084\n",
      "epoch 85; iter: 0; batch classifier loss: 0.048543; batch adversarial loss: 0.432362\n",
      "epoch 86; iter: 0; batch classifier loss: 0.101373; batch adversarial loss: 0.362378\n",
      "epoch 87; iter: 0; batch classifier loss: 0.044097; batch adversarial loss: 0.445498\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075479; batch adversarial loss: 0.431868\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063985; batch adversarial loss: 0.457687\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056074; batch adversarial loss: 0.387870\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077820; batch adversarial loss: 0.528094\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069271; batch adversarial loss: 0.396788\n",
      "epoch 93; iter: 0; batch classifier loss: 0.037053; batch adversarial loss: 0.427768\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050251; batch adversarial loss: 0.497062\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079301; batch adversarial loss: 0.413377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.110061; batch adversarial loss: 0.417015\n",
      "epoch 97; iter: 0; batch classifier loss: 0.070153; batch adversarial loss: 0.442500\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051094; batch adversarial loss: 0.379893\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052347; batch adversarial loss: 0.485246\n",
      "epoch 100; iter: 0; batch classifier loss: 0.032236; batch adversarial loss: 0.409752\n",
      "epoch 101; iter: 0; batch classifier loss: 0.074969; batch adversarial loss: 0.422832\n",
      "epoch 102; iter: 0; batch classifier loss: 0.069937; batch adversarial loss: 0.500933\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050890; batch adversarial loss: 0.506674\n",
      "epoch 104; iter: 0; batch classifier loss: 0.042984; batch adversarial loss: 0.470323\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064745; batch adversarial loss: 0.416364\n",
      "epoch 106; iter: 0; batch classifier loss: 0.066620; batch adversarial loss: 0.483829\n",
      "epoch 107; iter: 0; batch classifier loss: 0.079301; batch adversarial loss: 0.451866\n",
      "epoch 108; iter: 0; batch classifier loss: 0.061117; batch adversarial loss: 0.433034\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032272; batch adversarial loss: 0.440268\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047728; batch adversarial loss: 0.511061\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042359; batch adversarial loss: 0.400624\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075116; batch adversarial loss: 0.475117\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051478; batch adversarial loss: 0.512259\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030348; batch adversarial loss: 0.537532\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043240; batch adversarial loss: 0.432235\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042508; batch adversarial loss: 0.326671\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050295; batch adversarial loss: 0.419593\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037647; batch adversarial loss: 0.467848\n",
      "epoch 119; iter: 0; batch classifier loss: 0.058152; batch adversarial loss: 0.427319\n",
      "epoch 120; iter: 0; batch classifier loss: 0.056736; batch adversarial loss: 0.659756\n",
      "epoch 121; iter: 0; batch classifier loss: 0.020446; batch adversarial loss: 0.559546\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017500; batch adversarial loss: 0.361278\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038095; batch adversarial loss: 0.450359\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024781; batch adversarial loss: 0.518772\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026557; batch adversarial loss: 0.421732\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039921; batch adversarial loss: 0.451291\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050459; batch adversarial loss: 0.436148\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063407; batch adversarial loss: 0.435687\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059869; batch adversarial loss: 0.511905\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051788; batch adversarial loss: 0.425626\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027840; batch adversarial loss: 0.440512\n",
      "epoch 132; iter: 0; batch classifier loss: 0.052865; batch adversarial loss: 0.421794\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039355; batch adversarial loss: 0.490954\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015438; batch adversarial loss: 0.442895\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037030; batch adversarial loss: 0.475537\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040513; batch adversarial loss: 0.469961\n",
      "epoch 137; iter: 0; batch classifier loss: 0.064811; batch adversarial loss: 0.421085\n",
      "epoch 138; iter: 0; batch classifier loss: 0.064749; batch adversarial loss: 0.393484\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016722; batch adversarial loss: 0.503055\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028493; batch adversarial loss: 0.383356\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027189; batch adversarial loss: 0.430077\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040797; batch adversarial loss: 0.484954\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019101; batch adversarial loss: 0.484670\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021119; batch adversarial loss: 0.412306\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017658; batch adversarial loss: 0.448918\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022368; batch adversarial loss: 0.418695\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022718; batch adversarial loss: 0.432987\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019631; batch adversarial loss: 0.442936\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020418; batch adversarial loss: 0.503808\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029178; batch adversarial loss: 0.435542\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037447; batch adversarial loss: 0.496916\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024917; batch adversarial loss: 0.454271\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016354; batch adversarial loss: 0.404923\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035017; batch adversarial loss: 0.432260\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035195; batch adversarial loss: 0.441936\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025439; batch adversarial loss: 0.446166\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017522; batch adversarial loss: 0.472476\n",
      "epoch 158; iter: 0; batch classifier loss: 0.076247; batch adversarial loss: 0.386214\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018526; batch adversarial loss: 0.383247\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014338; batch adversarial loss: 0.416508\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029179; batch adversarial loss: 0.479363\n",
      "epoch 162; iter: 0; batch classifier loss: 0.064812; batch adversarial loss: 0.425634\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017388; batch adversarial loss: 0.440151\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018756; batch adversarial loss: 0.375901\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018034; batch adversarial loss: 0.459468\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028451; batch adversarial loss: 0.439904\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029541; batch adversarial loss: 0.443056\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020644; batch adversarial loss: 0.459755\n",
      "epoch 169; iter: 0; batch classifier loss: 0.043616; batch adversarial loss: 0.443780\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016719; batch adversarial loss: 0.474383\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027403; batch adversarial loss: 0.410736\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028126; batch adversarial loss: 0.399212\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013112; batch adversarial loss: 0.379905\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031076; batch adversarial loss: 0.411498\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023039; batch adversarial loss: 0.469740\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025439; batch adversarial loss: 0.497427\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022198; batch adversarial loss: 0.484027\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016966; batch adversarial loss: 0.456001\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033030; batch adversarial loss: 0.364443\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010509; batch adversarial loss: 0.449959\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032436; batch adversarial loss: 0.445756\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011142; batch adversarial loss: 0.369398\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023291; batch adversarial loss: 0.509020\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030898; batch adversarial loss: 0.627205\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017131; batch adversarial loss: 0.491051\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017134; batch adversarial loss: 0.463236\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027824; batch adversarial loss: 0.439353\n",
      "epoch 188; iter: 0; batch classifier loss: 0.036485; batch adversarial loss: 0.495687\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023052; batch adversarial loss: 0.464437\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035156; batch adversarial loss: 0.487645\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011982; batch adversarial loss: 0.455117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.008042; batch adversarial loss: 0.524715\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006190; batch adversarial loss: 0.395536\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028575; batch adversarial loss: 0.447387\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030016; batch adversarial loss: 0.438738\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013359; batch adversarial loss: 0.501041\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017496; batch adversarial loss: 0.497451\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021348; batch adversarial loss: 0.332934\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015085; batch adversarial loss: 0.499939\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706138; batch adversarial loss: 0.565641\n",
      "epoch 1; iter: 0; batch classifier loss: 0.348799; batch adversarial loss: 0.607681\n",
      "epoch 2; iter: 0; batch classifier loss: 0.420434; batch adversarial loss: 0.593579\n",
      "epoch 3; iter: 0; batch classifier loss: 0.343098; batch adversarial loss: 0.578482\n",
      "epoch 4; iter: 0; batch classifier loss: 0.319331; batch adversarial loss: 0.562224\n",
      "epoch 5; iter: 0; batch classifier loss: 0.287553; batch adversarial loss: 0.552597\n",
      "epoch 6; iter: 0; batch classifier loss: 0.304379; batch adversarial loss: 0.538422\n",
      "epoch 7; iter: 0; batch classifier loss: 0.294055; batch adversarial loss: 0.532948\n",
      "epoch 8; iter: 0; batch classifier loss: 0.310260; batch adversarial loss: 0.561138\n",
      "epoch 9; iter: 0; batch classifier loss: 0.303098; batch adversarial loss: 0.497253\n",
      "epoch 10; iter: 0; batch classifier loss: 0.262791; batch adversarial loss: 0.525436\n",
      "epoch 11; iter: 0; batch classifier loss: 0.323702; batch adversarial loss: 0.540247\n",
      "epoch 12; iter: 0; batch classifier loss: 0.235804; batch adversarial loss: 0.521094\n",
      "epoch 13; iter: 0; batch classifier loss: 0.399743; batch adversarial loss: 0.574719\n",
      "epoch 14; iter: 0; batch classifier loss: 0.315050; batch adversarial loss: 0.538369\n",
      "epoch 15; iter: 0; batch classifier loss: 0.379716; batch adversarial loss: 0.544191\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528462; batch adversarial loss: 0.495917\n",
      "epoch 17; iter: 0; batch classifier loss: 0.391228; batch adversarial loss: 0.415306\n",
      "epoch 18; iter: 0; batch classifier loss: 0.234808; batch adversarial loss: 0.418926\n",
      "epoch 19; iter: 0; batch classifier loss: 0.222890; batch adversarial loss: 0.482678\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222044; batch adversarial loss: 0.486323\n",
      "epoch 21; iter: 0; batch classifier loss: 0.220390; batch adversarial loss: 0.456312\n",
      "epoch 22; iter: 0; batch classifier loss: 0.145537; batch adversarial loss: 0.508209\n",
      "epoch 23; iter: 0; batch classifier loss: 0.235893; batch adversarial loss: 0.417668\n",
      "epoch 24; iter: 0; batch classifier loss: 0.171793; batch adversarial loss: 0.485699\n",
      "epoch 25; iter: 0; batch classifier loss: 0.156272; batch adversarial loss: 0.567398\n",
      "epoch 26; iter: 0; batch classifier loss: 0.210988; batch adversarial loss: 0.444759\n",
      "epoch 27; iter: 0; batch classifier loss: 0.213165; batch adversarial loss: 0.407837\n",
      "epoch 28; iter: 0; batch classifier loss: 0.154888; batch adversarial loss: 0.446613\n",
      "epoch 29; iter: 0; batch classifier loss: 0.156401; batch adversarial loss: 0.435704\n",
      "epoch 30; iter: 0; batch classifier loss: 0.141556; batch adversarial loss: 0.410377\n",
      "epoch 31; iter: 0; batch classifier loss: 0.153418; batch adversarial loss: 0.374350\n",
      "epoch 32; iter: 0; batch classifier loss: 0.178532; batch adversarial loss: 0.522451\n",
      "epoch 33; iter: 0; batch classifier loss: 0.152951; batch adversarial loss: 0.419501\n",
      "epoch 34; iter: 0; batch classifier loss: 0.137520; batch adversarial loss: 0.468784\n",
      "epoch 35; iter: 0; batch classifier loss: 0.114199; batch adversarial loss: 0.412259\n",
      "epoch 36; iter: 0; batch classifier loss: 0.089917; batch adversarial loss: 0.383678\n",
      "epoch 37; iter: 0; batch classifier loss: 0.143280; batch adversarial loss: 0.438867\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126698; batch adversarial loss: 0.454639\n",
      "epoch 39; iter: 0; batch classifier loss: 0.154842; batch adversarial loss: 0.503211\n",
      "epoch 40; iter: 0; batch classifier loss: 0.079677; batch adversarial loss: 0.468851\n",
      "epoch 41; iter: 0; batch classifier loss: 0.164033; batch adversarial loss: 0.469108\n",
      "epoch 42; iter: 0; batch classifier loss: 0.098586; batch adversarial loss: 0.419720\n",
      "epoch 43; iter: 0; batch classifier loss: 0.098297; batch adversarial loss: 0.461495\n",
      "epoch 44; iter: 0; batch classifier loss: 0.114703; batch adversarial loss: 0.374142\n",
      "epoch 45; iter: 0; batch classifier loss: 0.073684; batch adversarial loss: 0.394014\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117267; batch adversarial loss: 0.427249\n",
      "epoch 47; iter: 0; batch classifier loss: 0.103104; batch adversarial loss: 0.427269\n",
      "epoch 48; iter: 0; batch classifier loss: 0.133747; batch adversarial loss: 0.414616\n",
      "epoch 49; iter: 0; batch classifier loss: 0.092939; batch adversarial loss: 0.520576\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094520; batch adversarial loss: 0.433557\n",
      "epoch 51; iter: 0; batch classifier loss: 0.168436; batch adversarial loss: 0.544587\n",
      "epoch 52; iter: 0; batch classifier loss: 0.124542; batch adversarial loss: 0.475648\n",
      "epoch 53; iter: 0; batch classifier loss: 0.133495; batch adversarial loss: 0.543421\n",
      "epoch 54; iter: 0; batch classifier loss: 0.131852; batch adversarial loss: 0.479339\n",
      "epoch 55; iter: 0; batch classifier loss: 0.115805; batch adversarial loss: 0.360469\n",
      "epoch 56; iter: 0; batch classifier loss: 0.164513; batch adversarial loss: 0.453841\n",
      "epoch 57; iter: 0; batch classifier loss: 0.127471; batch adversarial loss: 0.538589\n",
      "epoch 58; iter: 0; batch classifier loss: 0.107550; batch adversarial loss: 0.397983\n",
      "epoch 59; iter: 0; batch classifier loss: 0.186738; batch adversarial loss: 0.462271\n",
      "epoch 60; iter: 0; batch classifier loss: 0.138847; batch adversarial loss: 0.445339\n",
      "epoch 61; iter: 0; batch classifier loss: 0.144275; batch adversarial loss: 0.405913\n",
      "epoch 62; iter: 0; batch classifier loss: 0.154920; batch adversarial loss: 0.371959\n",
      "epoch 63; iter: 0; batch classifier loss: 0.128220; batch adversarial loss: 0.393216\n",
      "epoch 64; iter: 0; batch classifier loss: 0.129076; batch adversarial loss: 0.406942\n",
      "epoch 65; iter: 0; batch classifier loss: 0.111670; batch adversarial loss: 0.479377\n",
      "epoch 66; iter: 0; batch classifier loss: 0.125235; batch adversarial loss: 0.467956\n",
      "epoch 67; iter: 0; batch classifier loss: 0.184913; batch adversarial loss: 0.433151\n",
      "epoch 68; iter: 0; batch classifier loss: 0.120044; batch adversarial loss: 0.469366\n",
      "epoch 69; iter: 0; batch classifier loss: 0.105678; batch adversarial loss: 0.469913\n",
      "epoch 70; iter: 0; batch classifier loss: 0.124945; batch adversarial loss: 0.413454\n",
      "epoch 71; iter: 0; batch classifier loss: 0.128711; batch adversarial loss: 0.580184\n",
      "epoch 72; iter: 0; batch classifier loss: 0.078174; batch adversarial loss: 0.460448\n",
      "epoch 73; iter: 0; batch classifier loss: 0.125921; batch adversarial loss: 0.386145\n",
      "epoch 74; iter: 0; batch classifier loss: 0.110168; batch adversarial loss: 0.532540\n",
      "epoch 75; iter: 0; batch classifier loss: 0.143768; batch adversarial loss: 0.507250\n",
      "epoch 76; iter: 0; batch classifier loss: 0.117702; batch adversarial loss: 0.385641\n",
      "epoch 77; iter: 0; batch classifier loss: 0.120633; batch adversarial loss: 0.385094\n",
      "epoch 78; iter: 0; batch classifier loss: 0.170245; batch adversarial loss: 0.470907\n",
      "epoch 79; iter: 0; batch classifier loss: 0.185943; batch adversarial loss: 0.383456\n",
      "epoch 80; iter: 0; batch classifier loss: 0.129701; batch adversarial loss: 0.446485\n",
      "epoch 81; iter: 0; batch classifier loss: 0.151732; batch adversarial loss: 0.434046\n",
      "epoch 82; iter: 0; batch classifier loss: 0.141791; batch adversarial loss: 0.545849\n",
      "epoch 83; iter: 0; batch classifier loss: 0.167579; batch adversarial loss: 0.483563\n",
      "epoch 84; iter: 0; batch classifier loss: 0.218561; batch adversarial loss: 0.496494\n",
      "epoch 85; iter: 0; batch classifier loss: 0.157374; batch adversarial loss: 0.508586\n",
      "epoch 86; iter: 0; batch classifier loss: 0.176570; batch adversarial loss: 0.508473\n",
      "epoch 87; iter: 0; batch classifier loss: 0.134961; batch adversarial loss: 0.396599\n",
      "epoch 88; iter: 0; batch classifier loss: 0.193527; batch adversarial loss: 0.371570\n",
      "epoch 89; iter: 0; batch classifier loss: 0.152365; batch adversarial loss: 0.471605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.174467; batch adversarial loss: 0.433284\n",
      "epoch 91; iter: 0; batch classifier loss: 0.147364; batch adversarial loss: 0.397733\n",
      "epoch 92; iter: 0; batch classifier loss: 0.134052; batch adversarial loss: 0.533213\n",
      "epoch 93; iter: 0; batch classifier loss: 0.146508; batch adversarial loss: 0.471224\n",
      "epoch 94; iter: 0; batch classifier loss: 0.095418; batch adversarial loss: 0.421297\n",
      "epoch 95; iter: 0; batch classifier loss: 0.105545; batch adversarial loss: 0.459076\n",
      "epoch 96; iter: 0; batch classifier loss: 0.164242; batch adversarial loss: 0.470635\n",
      "epoch 97; iter: 0; batch classifier loss: 0.121750; batch adversarial loss: 0.508820\n",
      "epoch 98; iter: 0; batch classifier loss: 0.172893; batch adversarial loss: 0.458393\n",
      "epoch 99; iter: 0; batch classifier loss: 0.119895; batch adversarial loss: 0.496237\n",
      "epoch 100; iter: 0; batch classifier loss: 0.137402; batch adversarial loss: 0.408753\n",
      "epoch 101; iter: 0; batch classifier loss: 0.127821; batch adversarial loss: 0.421485\n",
      "epoch 102; iter: 0; batch classifier loss: 0.131583; batch adversarial loss: 0.421360\n",
      "epoch 103; iter: 0; batch classifier loss: 0.126166; batch adversarial loss: 0.510134\n",
      "epoch 104; iter: 0; batch classifier loss: 0.140079; batch adversarial loss: 0.445881\n",
      "epoch 105; iter: 0; batch classifier loss: 0.131055; batch adversarial loss: 0.434185\n",
      "epoch 106; iter: 0; batch classifier loss: 0.105723; batch adversarial loss: 0.359127\n",
      "epoch 107; iter: 0; batch classifier loss: 0.163632; batch adversarial loss: 0.384221\n",
      "epoch 108; iter: 0; batch classifier loss: 0.140216; batch adversarial loss: 0.409249\n",
      "epoch 109; iter: 0; batch classifier loss: 0.116049; batch adversarial loss: 0.421141\n",
      "epoch 110; iter: 0; batch classifier loss: 0.112526; batch adversarial loss: 0.434823\n",
      "epoch 111; iter: 0; batch classifier loss: 0.151296; batch adversarial loss: 0.496674\n",
      "epoch 112; iter: 0; batch classifier loss: 0.100242; batch adversarial loss: 0.546807\n",
      "epoch 113; iter: 0; batch classifier loss: 0.113785; batch adversarial loss: 0.508646\n",
      "epoch 114; iter: 0; batch classifier loss: 0.106342; batch adversarial loss: 0.370886\n",
      "epoch 115; iter: 0; batch classifier loss: 0.102558; batch adversarial loss: 0.494757\n",
      "epoch 116; iter: 0; batch classifier loss: 0.159086; batch adversarial loss: 0.357883\n",
      "epoch 117; iter: 0; batch classifier loss: 0.085615; batch adversarial loss: 0.557727\n",
      "epoch 118; iter: 0; batch classifier loss: 0.128303; batch adversarial loss: 0.509334\n",
      "epoch 119; iter: 0; batch classifier loss: 0.122318; batch adversarial loss: 0.434878\n",
      "epoch 120; iter: 0; batch classifier loss: 0.098241; batch adversarial loss: 0.434710\n",
      "epoch 121; iter: 0; batch classifier loss: 0.162585; batch adversarial loss: 0.471292\n",
      "epoch 122; iter: 0; batch classifier loss: 0.106548; batch adversarial loss: 0.508572\n",
      "epoch 123; iter: 0; batch classifier loss: 0.111275; batch adversarial loss: 0.523997\n",
      "epoch 124; iter: 0; batch classifier loss: 0.089280; batch adversarial loss: 0.456165\n",
      "epoch 125; iter: 0; batch classifier loss: 0.098050; batch adversarial loss: 0.457557\n",
      "epoch 126; iter: 0; batch classifier loss: 0.090871; batch adversarial loss: 0.394663\n",
      "epoch 127; iter: 0; batch classifier loss: 0.080088; batch adversarial loss: 0.442811\n",
      "epoch 128; iter: 0; batch classifier loss: 0.128950; batch adversarial loss: 0.418461\n",
      "epoch 129; iter: 0; batch classifier loss: 0.087872; batch adversarial loss: 0.520824\n",
      "epoch 130; iter: 0; batch classifier loss: 0.073548; batch adversarial loss: 0.433634\n",
      "epoch 131; iter: 0; batch classifier loss: 0.079415; batch adversarial loss: 0.449009\n",
      "epoch 132; iter: 0; batch classifier loss: 0.092732; batch adversarial loss: 0.398472\n",
      "epoch 133; iter: 0; batch classifier loss: 0.054037; batch adversarial loss: 0.434030\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069276; batch adversarial loss: 0.595947\n",
      "epoch 135; iter: 0; batch classifier loss: 0.101052; batch adversarial loss: 0.437756\n",
      "epoch 136; iter: 0; batch classifier loss: 0.060031; batch adversarial loss: 0.479252\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054168; batch adversarial loss: 0.408837\n",
      "epoch 138; iter: 0; batch classifier loss: 0.051639; batch adversarial loss: 0.423231\n",
      "epoch 139; iter: 0; batch classifier loss: 0.064315; batch adversarial loss: 0.455065\n",
      "epoch 140; iter: 0; batch classifier loss: 0.063012; batch adversarial loss: 0.391750\n",
      "epoch 141; iter: 0; batch classifier loss: 0.059764; batch adversarial loss: 0.389025\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023167; batch adversarial loss: 0.500033\n",
      "epoch 143; iter: 0; batch classifier loss: 0.059580; batch adversarial loss: 0.408068\n",
      "epoch 144; iter: 0; batch classifier loss: 0.064621; batch adversarial loss: 0.380849\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041932; batch adversarial loss: 0.401815\n",
      "epoch 146; iter: 0; batch classifier loss: 0.056106; batch adversarial loss: 0.529653\n",
      "epoch 147; iter: 0; batch classifier loss: 0.050095; batch adversarial loss: 0.517164\n",
      "epoch 148; iter: 0; batch classifier loss: 0.065054; batch adversarial loss: 0.490181\n",
      "epoch 149; iter: 0; batch classifier loss: 0.057553; batch adversarial loss: 0.455754\n",
      "epoch 150; iter: 0; batch classifier loss: 0.047062; batch adversarial loss: 0.326998\n",
      "epoch 151; iter: 0; batch classifier loss: 0.063749; batch adversarial loss: 0.396518\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034816; batch adversarial loss: 0.391447\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036450; batch adversarial loss: 0.393598\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039141; batch adversarial loss: 0.427236\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022324; batch adversarial loss: 0.530759\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042098; batch adversarial loss: 0.411118\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036662; batch adversarial loss: 0.444031\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030770; batch adversarial loss: 0.475420\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012234; batch adversarial loss: 0.438566\n",
      "epoch 160; iter: 0; batch classifier loss: 0.057747; batch adversarial loss: 0.406347\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029605; batch adversarial loss: 0.504574\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023841; batch adversarial loss: 0.400088\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018721; batch adversarial loss: 0.487993\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026307; batch adversarial loss: 0.564272\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024243; batch adversarial loss: 0.461307\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034666; batch adversarial loss: 0.338607\n",
      "epoch 167; iter: 0; batch classifier loss: 0.080590; batch adversarial loss: 0.467225\n",
      "epoch 168; iter: 0; batch classifier loss: 0.055580; batch adversarial loss: 0.475308\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017569; batch adversarial loss: 0.492108\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035036; batch adversarial loss: 0.437801\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030318; batch adversarial loss: 0.440879\n",
      "epoch 172; iter: 0; batch classifier loss: 0.041281; batch adversarial loss: 0.519989\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034998; batch adversarial loss: 0.425259\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020393; batch adversarial loss: 0.493914\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025272; batch adversarial loss: 0.416191\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012444; batch adversarial loss: 0.441313\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038333; batch adversarial loss: 0.433123\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016057; batch adversarial loss: 0.516928\n",
      "epoch 179; iter: 0; batch classifier loss: 0.054137; batch adversarial loss: 0.469365\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017201; batch adversarial loss: 0.488744\n",
      "epoch 181; iter: 0; batch classifier loss: 0.042906; batch adversarial loss: 0.516952\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018564; batch adversarial loss: 0.461692\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022432; batch adversarial loss: 0.444418\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014579; batch adversarial loss: 0.449389\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024928; batch adversarial loss: 0.475280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.039631; batch adversarial loss: 0.423836\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011489; batch adversarial loss: 0.427600\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022731; batch adversarial loss: 0.487459\n",
      "epoch 189; iter: 0; batch classifier loss: 0.049176; batch adversarial loss: 0.367666\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029430; batch adversarial loss: 0.470526\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018317; batch adversarial loss: 0.346069\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016664; batch adversarial loss: 0.419958\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015330; batch adversarial loss: 0.427680\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020907; batch adversarial loss: 0.499676\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015578; batch adversarial loss: 0.419795\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019657; batch adversarial loss: 0.349829\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018334; batch adversarial loss: 0.386431\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010361; batch adversarial loss: 0.429811\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026510; batch adversarial loss: 0.406607\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697085; batch adversarial loss: 0.735594\n",
      "epoch 1; iter: 0; batch classifier loss: 0.522699; batch adversarial loss: 0.664764\n",
      "epoch 2; iter: 0; batch classifier loss: 0.426236; batch adversarial loss: 0.630089\n",
      "epoch 3; iter: 0; batch classifier loss: 0.372931; batch adversarial loss: 0.614960\n",
      "epoch 4; iter: 0; batch classifier loss: 0.393260; batch adversarial loss: 0.596607\n",
      "epoch 5; iter: 0; batch classifier loss: 0.492177; batch adversarial loss: 0.593887\n",
      "epoch 6; iter: 0; batch classifier loss: 0.369007; batch adversarial loss: 0.583135\n",
      "epoch 7; iter: 0; batch classifier loss: 0.361779; batch adversarial loss: 0.560224\n",
      "epoch 8; iter: 0; batch classifier loss: 0.317202; batch adversarial loss: 0.561807\n",
      "epoch 9; iter: 0; batch classifier loss: 0.382978; batch adversarial loss: 0.541451\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358096; batch adversarial loss: 0.559578\n",
      "epoch 11; iter: 0; batch classifier loss: 0.423678; batch adversarial loss: 0.520717\n",
      "epoch 12; iter: 0; batch classifier loss: 0.415739; batch adversarial loss: 0.523537\n",
      "epoch 13; iter: 0; batch classifier loss: 0.400771; batch adversarial loss: 0.503040\n",
      "epoch 14; iter: 0; batch classifier loss: 0.403994; batch adversarial loss: 0.537444\n",
      "epoch 15; iter: 0; batch classifier loss: 0.405955; batch adversarial loss: 0.498817\n",
      "epoch 16; iter: 0; batch classifier loss: 0.331359; batch adversarial loss: 0.515646\n",
      "epoch 17; iter: 0; batch classifier loss: 0.310546; batch adversarial loss: 0.523914\n",
      "epoch 18; iter: 0; batch classifier loss: 0.342097; batch adversarial loss: 0.446808\n",
      "epoch 19; iter: 0; batch classifier loss: 0.288678; batch adversarial loss: 0.533601\n",
      "epoch 20; iter: 0; batch classifier loss: 0.337939; batch adversarial loss: 0.466040\n",
      "epoch 21; iter: 0; batch classifier loss: 0.396335; batch adversarial loss: 0.487272\n",
      "epoch 22; iter: 0; batch classifier loss: 0.221519; batch adversarial loss: 0.515791\n",
      "epoch 23; iter: 0; batch classifier loss: 0.348180; batch adversarial loss: 0.518321\n",
      "epoch 24; iter: 0; batch classifier loss: 0.312290; batch adversarial loss: 0.469924\n",
      "epoch 25; iter: 0; batch classifier loss: 0.290557; batch adversarial loss: 0.540272\n",
      "epoch 26; iter: 0; batch classifier loss: 0.267074; batch adversarial loss: 0.485507\n",
      "epoch 27; iter: 0; batch classifier loss: 0.327014; batch adversarial loss: 0.511511\n",
      "epoch 28; iter: 0; batch classifier loss: 0.277723; batch adversarial loss: 0.412420\n",
      "epoch 29; iter: 0; batch classifier loss: 0.272208; batch adversarial loss: 0.589733\n",
      "epoch 30; iter: 0; batch classifier loss: 0.240278; batch adversarial loss: 0.512479\n",
      "epoch 31; iter: 0; batch classifier loss: 0.258149; batch adversarial loss: 0.474203\n",
      "epoch 32; iter: 0; batch classifier loss: 0.318664; batch adversarial loss: 0.414930\n",
      "epoch 33; iter: 0; batch classifier loss: 0.321638; batch adversarial loss: 0.421028\n",
      "epoch 34; iter: 0; batch classifier loss: 0.227449; batch adversarial loss: 0.450611\n",
      "epoch 35; iter: 0; batch classifier loss: 0.282410; batch adversarial loss: 0.459013\n",
      "epoch 36; iter: 0; batch classifier loss: 0.269708; batch adversarial loss: 0.441297\n",
      "epoch 37; iter: 0; batch classifier loss: 0.273435; batch adversarial loss: 0.457336\n",
      "epoch 38; iter: 0; batch classifier loss: 0.220748; batch adversarial loss: 0.425311\n",
      "epoch 39; iter: 0; batch classifier loss: 0.258153; batch adversarial loss: 0.473495\n",
      "epoch 40; iter: 0; batch classifier loss: 0.249508; batch adversarial loss: 0.392751\n",
      "epoch 41; iter: 0; batch classifier loss: 0.222407; batch adversarial loss: 0.459353\n",
      "epoch 42; iter: 0; batch classifier loss: 0.183451; batch adversarial loss: 0.558684\n",
      "epoch 43; iter: 0; batch classifier loss: 0.235660; batch adversarial loss: 0.460649\n",
      "epoch 44; iter: 0; batch classifier loss: 0.293710; batch adversarial loss: 0.412765\n",
      "epoch 45; iter: 0; batch classifier loss: 0.297772; batch adversarial loss: 0.436570\n",
      "epoch 46; iter: 0; batch classifier loss: 0.285614; batch adversarial loss: 0.459739\n",
      "epoch 47; iter: 0; batch classifier loss: 0.216211; batch adversarial loss: 0.505213\n",
      "epoch 48; iter: 0; batch classifier loss: 0.183512; batch adversarial loss: 0.518424\n",
      "epoch 49; iter: 0; batch classifier loss: 0.166249; batch adversarial loss: 0.387754\n",
      "epoch 50; iter: 0; batch classifier loss: 0.150050; batch adversarial loss: 0.445387\n",
      "epoch 51; iter: 0; batch classifier loss: 0.149027; batch adversarial loss: 0.508180\n",
      "epoch 52; iter: 0; batch classifier loss: 0.228249; batch adversarial loss: 0.433425\n",
      "epoch 53; iter: 0; batch classifier loss: 0.217588; batch adversarial loss: 0.398265\n",
      "epoch 54; iter: 0; batch classifier loss: 0.273075; batch adversarial loss: 0.326013\n",
      "epoch 55; iter: 0; batch classifier loss: 0.297929; batch adversarial loss: 0.434259\n",
      "epoch 56; iter: 0; batch classifier loss: 0.207036; batch adversarial loss: 0.544311\n",
      "epoch 57; iter: 0; batch classifier loss: 0.103567; batch adversarial loss: 0.544042\n",
      "epoch 58; iter: 0; batch classifier loss: 0.207829; batch adversarial loss: 0.410368\n",
      "epoch 59; iter: 0; batch classifier loss: 0.182604; batch adversarial loss: 0.446459\n",
      "epoch 60; iter: 0; batch classifier loss: 0.142772; batch adversarial loss: 0.421544\n",
      "epoch 61; iter: 0; batch classifier loss: 0.171483; batch adversarial loss: 0.408662\n",
      "epoch 62; iter: 0; batch classifier loss: 0.182191; batch adversarial loss: 0.496445\n",
      "epoch 63; iter: 0; batch classifier loss: 0.212569; batch adversarial loss: 0.483308\n",
      "epoch 64; iter: 0; batch classifier loss: 0.132792; batch adversarial loss: 0.446976\n",
      "epoch 65; iter: 0; batch classifier loss: 0.145263; batch adversarial loss: 0.446104\n",
      "epoch 66; iter: 0; batch classifier loss: 0.213498; batch adversarial loss: 0.421377\n",
      "epoch 67; iter: 0; batch classifier loss: 0.154932; batch adversarial loss: 0.495668\n",
      "epoch 68; iter: 0; batch classifier loss: 0.176746; batch adversarial loss: 0.508895\n",
      "epoch 69; iter: 0; batch classifier loss: 0.126437; batch adversarial loss: 0.483369\n",
      "epoch 70; iter: 0; batch classifier loss: 0.269561; batch adversarial loss: 0.421628\n",
      "epoch 71; iter: 0; batch classifier loss: 0.226340; batch adversarial loss: 0.460211\n",
      "epoch 72; iter: 0; batch classifier loss: 0.256333; batch adversarial loss: 0.458265\n",
      "epoch 73; iter: 0; batch classifier loss: 0.203953; batch adversarial loss: 0.434456\n",
      "epoch 74; iter: 0; batch classifier loss: 0.097185; batch adversarial loss: 0.458041\n",
      "epoch 75; iter: 0; batch classifier loss: 0.085035; batch adversarial loss: 0.470876\n",
      "epoch 76; iter: 0; batch classifier loss: 0.124715; batch adversarial loss: 0.396861\n",
      "epoch 77; iter: 0; batch classifier loss: 0.142356; batch adversarial loss: 0.467137\n",
      "epoch 78; iter: 0; batch classifier loss: 0.243429; batch adversarial loss: 0.419768\n",
      "epoch 79; iter: 0; batch classifier loss: 0.241648; batch adversarial loss: 0.459326\n",
      "epoch 80; iter: 0; batch classifier loss: 0.216796; batch adversarial loss: 0.372345\n",
      "epoch 81; iter: 0; batch classifier loss: 0.213208; batch adversarial loss: 0.372209\n",
      "epoch 82; iter: 0; batch classifier loss: 0.173405; batch adversarial loss: 0.433847\n",
      "epoch 83; iter: 0; batch classifier loss: 0.139441; batch adversarial loss: 0.642006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.212589; batch adversarial loss: 0.410090\n",
      "epoch 85; iter: 0; batch classifier loss: 0.224439; batch adversarial loss: 0.445156\n",
      "epoch 86; iter: 0; batch classifier loss: 0.257856; batch adversarial loss: 0.457505\n",
      "epoch 87; iter: 0; batch classifier loss: 0.200360; batch adversarial loss: 0.447061\n",
      "epoch 88; iter: 0; batch classifier loss: 0.207458; batch adversarial loss: 0.581329\n",
      "epoch 89; iter: 0; batch classifier loss: 0.153028; batch adversarial loss: 0.482837\n",
      "epoch 90; iter: 0; batch classifier loss: 0.111242; batch adversarial loss: 0.431551\n",
      "epoch 91; iter: 0; batch classifier loss: 0.090461; batch adversarial loss: 0.492878\n",
      "epoch 92; iter: 0; batch classifier loss: 0.127018; batch adversarial loss: 0.444185\n",
      "epoch 93; iter: 0; batch classifier loss: 0.164034; batch adversarial loss: 0.404764\n",
      "epoch 94; iter: 0; batch classifier loss: 0.160386; batch adversarial loss: 0.509468\n",
      "epoch 95; iter: 0; batch classifier loss: 0.212805; batch adversarial loss: 0.321994\n",
      "epoch 96; iter: 0; batch classifier loss: 0.161306; batch adversarial loss: 0.497419\n",
      "epoch 97; iter: 0; batch classifier loss: 0.167818; batch adversarial loss: 0.435988\n",
      "epoch 98; iter: 0; batch classifier loss: 0.200669; batch adversarial loss: 0.420505\n",
      "epoch 99; iter: 0; batch classifier loss: 0.116631; batch adversarial loss: 0.460413\n",
      "epoch 100; iter: 0; batch classifier loss: 0.145784; batch adversarial loss: 0.495469\n",
      "epoch 101; iter: 0; batch classifier loss: 0.097938; batch adversarial loss: 0.535129\n",
      "epoch 102; iter: 0; batch classifier loss: 0.108375; batch adversarial loss: 0.508134\n",
      "epoch 103; iter: 0; batch classifier loss: 0.128686; batch adversarial loss: 0.467054\n",
      "epoch 104; iter: 0; batch classifier loss: 0.092621; batch adversarial loss: 0.519299\n",
      "epoch 105; iter: 0; batch classifier loss: 0.109103; batch adversarial loss: 0.524422\n",
      "epoch 106; iter: 0; batch classifier loss: 0.098127; batch adversarial loss: 0.428099\n",
      "epoch 107; iter: 0; batch classifier loss: 0.074243; batch adversarial loss: 0.494060\n",
      "epoch 108; iter: 0; batch classifier loss: 0.073675; batch adversarial loss: 0.539349\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051739; batch adversarial loss: 0.465425\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037352; batch adversarial loss: 0.497530\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055422; batch adversarial loss: 0.474348\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043593; batch adversarial loss: 0.333649\n",
      "epoch 113; iter: 0; batch classifier loss: 0.081485; batch adversarial loss: 0.389672\n",
      "epoch 114; iter: 0; batch classifier loss: 0.055768; batch adversarial loss: 0.394458\n",
      "epoch 115; iter: 0; batch classifier loss: 0.068362; batch adversarial loss: 0.427649\n",
      "epoch 116; iter: 0; batch classifier loss: 0.080919; batch adversarial loss: 0.407499\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048314; batch adversarial loss: 0.422807\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069338; batch adversarial loss: 0.445484\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050967; batch adversarial loss: 0.363989\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041038; batch adversarial loss: 0.409274\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026916; batch adversarial loss: 0.460229\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048184; batch adversarial loss: 0.510186\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033273; batch adversarial loss: 0.413376\n",
      "epoch 124; iter: 0; batch classifier loss: 0.018350; batch adversarial loss: 0.479685\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040985; batch adversarial loss: 0.508497\n",
      "epoch 126; iter: 0; batch classifier loss: 0.049909; batch adversarial loss: 0.364440\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022226; batch adversarial loss: 0.497359\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024429; batch adversarial loss: 0.467320\n",
      "epoch 129; iter: 0; batch classifier loss: 0.011985; batch adversarial loss: 0.500399\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044698; batch adversarial loss: 0.433984\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024197; batch adversarial loss: 0.450391\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026427; batch adversarial loss: 0.407582\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041058; batch adversarial loss: 0.439397\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038907; batch adversarial loss: 0.427328\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043208; batch adversarial loss: 0.505450\n",
      "epoch 136; iter: 0; batch classifier loss: 0.014863; batch adversarial loss: 0.382923\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040299; batch adversarial loss: 0.597982\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036752; batch adversarial loss: 0.459770\n",
      "epoch 139; iter: 0; batch classifier loss: 0.006678; batch adversarial loss: 0.477697\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019108; batch adversarial loss: 0.475742\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020887; batch adversarial loss: 0.454236\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017162; batch adversarial loss: 0.419792\n",
      "epoch 143; iter: 0; batch classifier loss: 0.017773; batch adversarial loss: 0.545156\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014275; batch adversarial loss: 0.420386\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027270; batch adversarial loss: 0.456599\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022358; batch adversarial loss: 0.359224\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035971; batch adversarial loss: 0.388383\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017907; batch adversarial loss: 0.402655\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020944; batch adversarial loss: 0.514579\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015264; batch adversarial loss: 0.451169\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017072; batch adversarial loss: 0.399229\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033792; batch adversarial loss: 0.447904\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035870; batch adversarial loss: 0.346661\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041960; batch adversarial loss: 0.438484\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014692; batch adversarial loss: 0.412693\n",
      "epoch 156; iter: 0; batch classifier loss: 0.004564; batch adversarial loss: 0.494187\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038815; batch adversarial loss: 0.493549\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010174; batch adversarial loss: 0.544648\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011211; batch adversarial loss: 0.450101\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029521; batch adversarial loss: 0.426990\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007792; batch adversarial loss: 0.483197\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038468; batch adversarial loss: 0.427730\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026987; batch adversarial loss: 0.473712\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032220; batch adversarial loss: 0.416788\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016844; batch adversarial loss: 0.372686\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021943; batch adversarial loss: 0.445507\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030208; batch adversarial loss: 0.505238\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014605; batch adversarial loss: 0.496858\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007821; batch adversarial loss: 0.475580\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035990; batch adversarial loss: 0.453179\n",
      "epoch 171; iter: 0; batch classifier loss: 0.044228; batch adversarial loss: 0.468781\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026576; batch adversarial loss: 0.402910\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015475; batch adversarial loss: 0.445912\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010538; batch adversarial loss: 0.442088\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016381; batch adversarial loss: 0.448672\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013455; batch adversarial loss: 0.438794\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023405; batch adversarial loss: 0.580948\n",
      "epoch 178; iter: 0; batch classifier loss: 0.045645; batch adversarial loss: 0.440312\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021345; batch adversarial loss: 0.451046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.003300; batch adversarial loss: 0.483116\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009514; batch adversarial loss: 0.511748\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012480; batch adversarial loss: 0.449933\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007657; batch adversarial loss: 0.422475\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008901; batch adversarial loss: 0.408783\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012812; batch adversarial loss: 0.446034\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009937; batch adversarial loss: 0.513875\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008562; batch adversarial loss: 0.445682\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022138; batch adversarial loss: 0.414060\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028636; batch adversarial loss: 0.366582\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010524; batch adversarial loss: 0.477273\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034835; batch adversarial loss: 0.434495\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028595; batch adversarial loss: 0.439485\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025513; batch adversarial loss: 0.500682\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007268; batch adversarial loss: 0.419154\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012483; batch adversarial loss: 0.507112\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006626; batch adversarial loss: 0.566070\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012137; batch adversarial loss: 0.542192\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025933; batch adversarial loss: 0.336235\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011657; batch adversarial loss: 0.426750\n",
      "epoch 0; iter: 0; batch classifier loss: 0.660844; batch adversarial loss: 0.689238\n",
      "epoch 1; iter: 0; batch classifier loss: 0.506908; batch adversarial loss: 0.656105\n",
      "epoch 2; iter: 0; batch classifier loss: 0.442004; batch adversarial loss: 0.612038\n",
      "epoch 3; iter: 0; batch classifier loss: 0.315062; batch adversarial loss: 0.603802\n",
      "epoch 4; iter: 0; batch classifier loss: 0.345687; batch adversarial loss: 0.599109\n",
      "epoch 5; iter: 0; batch classifier loss: 0.409167; batch adversarial loss: 0.597597\n",
      "epoch 6; iter: 0; batch classifier loss: 0.403817; batch adversarial loss: 0.555428\n",
      "epoch 7; iter: 0; batch classifier loss: 0.444393; batch adversarial loss: 0.574836\n",
      "epoch 8; iter: 0; batch classifier loss: 0.574585; batch adversarial loss: 0.569602\n",
      "epoch 9; iter: 0; batch classifier loss: 0.426485; batch adversarial loss: 0.517789\n",
      "epoch 10; iter: 0; batch classifier loss: 0.437316; batch adversarial loss: 0.546452\n",
      "epoch 11; iter: 0; batch classifier loss: 0.326775; batch adversarial loss: 0.512867\n",
      "epoch 12; iter: 0; batch classifier loss: 0.367276; batch adversarial loss: 0.501739\n",
      "epoch 13; iter: 0; batch classifier loss: 0.360642; batch adversarial loss: 0.521603\n",
      "epoch 14; iter: 0; batch classifier loss: 0.264597; batch adversarial loss: 0.547135\n",
      "epoch 15; iter: 0; batch classifier loss: 0.414522; batch adversarial loss: 0.451371\n",
      "epoch 16; iter: 0; batch classifier loss: 0.383110; batch adversarial loss: 0.448530\n",
      "epoch 17; iter: 0; batch classifier loss: 0.230621; batch adversarial loss: 0.478136\n",
      "epoch 18; iter: 0; batch classifier loss: 0.336534; batch adversarial loss: 0.521751\n",
      "epoch 19; iter: 0; batch classifier loss: 0.263255; batch adversarial loss: 0.526110\n",
      "epoch 20; iter: 0; batch classifier loss: 0.293955; batch adversarial loss: 0.467095\n",
      "epoch 21; iter: 0; batch classifier loss: 0.197097; batch adversarial loss: 0.469704\n",
      "epoch 22; iter: 0; batch classifier loss: 0.271069; batch adversarial loss: 0.466137\n",
      "epoch 23; iter: 0; batch classifier loss: 0.189880; batch adversarial loss: 0.441199\n",
      "epoch 24; iter: 0; batch classifier loss: 0.202776; batch adversarial loss: 0.435962\n",
      "epoch 25; iter: 0; batch classifier loss: 0.253237; batch adversarial loss: 0.511594\n",
      "epoch 26; iter: 0; batch classifier loss: 0.212251; batch adversarial loss: 0.434944\n",
      "epoch 27; iter: 0; batch classifier loss: 0.226788; batch adversarial loss: 0.461281\n",
      "epoch 28; iter: 0; batch classifier loss: 0.257756; batch adversarial loss: 0.435494\n",
      "epoch 29; iter: 0; batch classifier loss: 0.214953; batch adversarial loss: 0.422021\n",
      "epoch 30; iter: 0; batch classifier loss: 0.175403; batch adversarial loss: 0.421056\n",
      "epoch 31; iter: 0; batch classifier loss: 0.230681; batch adversarial loss: 0.522682\n",
      "epoch 32; iter: 0; batch classifier loss: 0.129125; batch adversarial loss: 0.427404\n",
      "epoch 33; iter: 0; batch classifier loss: 0.179617; batch adversarial loss: 0.489888\n",
      "epoch 34; iter: 0; batch classifier loss: 0.134768; batch adversarial loss: 0.540583\n",
      "epoch 35; iter: 0; batch classifier loss: 0.164593; batch adversarial loss: 0.455386\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187357; batch adversarial loss: 0.422223\n",
      "epoch 37; iter: 0; batch classifier loss: 0.131833; batch adversarial loss: 0.511450\n",
      "epoch 38; iter: 0; batch classifier loss: 0.137992; batch adversarial loss: 0.499871\n",
      "epoch 39; iter: 0; batch classifier loss: 0.169573; batch adversarial loss: 0.426545\n",
      "epoch 40; iter: 0; batch classifier loss: 0.119261; batch adversarial loss: 0.495583\n",
      "epoch 41; iter: 0; batch classifier loss: 0.122350; batch adversarial loss: 0.495569\n",
      "epoch 42; iter: 0; batch classifier loss: 0.095203; batch adversarial loss: 0.514314\n",
      "epoch 43; iter: 0; batch classifier loss: 0.143060; batch adversarial loss: 0.389727\n",
      "epoch 44; iter: 0; batch classifier loss: 0.088636; batch adversarial loss: 0.593180\n",
      "epoch 45; iter: 0; batch classifier loss: 0.174196; batch adversarial loss: 0.420470\n",
      "epoch 46; iter: 0; batch classifier loss: 0.133248; batch adversarial loss: 0.489391\n",
      "epoch 47; iter: 0; batch classifier loss: 0.135735; batch adversarial loss: 0.453233\n",
      "epoch 48; iter: 0; batch classifier loss: 0.136480; batch adversarial loss: 0.353602\n",
      "epoch 49; iter: 0; batch classifier loss: 0.127772; batch adversarial loss: 0.573126\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108210; batch adversarial loss: 0.443227\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121840; batch adversarial loss: 0.477695\n",
      "epoch 52; iter: 0; batch classifier loss: 0.107180; batch adversarial loss: 0.506265\n",
      "epoch 53; iter: 0; batch classifier loss: 0.111427; batch adversarial loss: 0.550726\n",
      "epoch 54; iter: 0; batch classifier loss: 0.094940; batch adversarial loss: 0.363179\n",
      "epoch 55; iter: 0; batch classifier loss: 0.126675; batch adversarial loss: 0.441805\n",
      "epoch 56; iter: 0; batch classifier loss: 0.089844; batch adversarial loss: 0.456161\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112477; batch adversarial loss: 0.378282\n",
      "epoch 58; iter: 0; batch classifier loss: 0.101496; batch adversarial loss: 0.384165\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084882; batch adversarial loss: 0.431683\n",
      "epoch 60; iter: 0; batch classifier loss: 0.067591; batch adversarial loss: 0.441974\n",
      "epoch 61; iter: 0; batch classifier loss: 0.105948; batch adversarial loss: 0.379952\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080393; batch adversarial loss: 0.497196\n",
      "epoch 63; iter: 0; batch classifier loss: 0.079262; batch adversarial loss: 0.411841\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090814; batch adversarial loss: 0.451587\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088311; batch adversarial loss: 0.402702\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084553; batch adversarial loss: 0.451302\n",
      "epoch 67; iter: 0; batch classifier loss: 0.066023; batch adversarial loss: 0.492627\n",
      "epoch 68; iter: 0; batch classifier loss: 0.095433; batch adversarial loss: 0.438628\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073189; batch adversarial loss: 0.481452\n",
      "epoch 70; iter: 0; batch classifier loss: 0.070351; batch adversarial loss: 0.548217\n",
      "epoch 71; iter: 0; batch classifier loss: 0.055449; batch adversarial loss: 0.459286\n",
      "epoch 72; iter: 0; batch classifier loss: 0.076432; batch adversarial loss: 0.417579\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079238; batch adversarial loss: 0.447313\n",
      "epoch 74; iter: 0; batch classifier loss: 0.060732; batch adversarial loss: 0.519705\n",
      "epoch 75; iter: 0; batch classifier loss: 0.080826; batch adversarial loss: 0.459794\n",
      "epoch 76; iter: 0; batch classifier loss: 0.056657; batch adversarial loss: 0.414562\n",
      "epoch 77; iter: 0; batch classifier loss: 0.099819; batch adversarial loss: 0.517929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.111943; batch adversarial loss: 0.443561\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082106; batch adversarial loss: 0.442458\n",
      "epoch 80; iter: 0; batch classifier loss: 0.086681; batch adversarial loss: 0.496370\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064918; batch adversarial loss: 0.396992\n",
      "epoch 82; iter: 0; batch classifier loss: 0.069459; batch adversarial loss: 0.373471\n",
      "epoch 83; iter: 0; batch classifier loss: 0.046215; batch adversarial loss: 0.525186\n",
      "epoch 84; iter: 0; batch classifier loss: 0.096400; batch adversarial loss: 0.498986\n",
      "epoch 85; iter: 0; batch classifier loss: 0.078669; batch adversarial loss: 0.404924\n",
      "epoch 86; iter: 0; batch classifier loss: 0.050425; batch adversarial loss: 0.354477\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048236; batch adversarial loss: 0.440008\n",
      "epoch 88; iter: 0; batch classifier loss: 0.084997; batch adversarial loss: 0.486436\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042927; batch adversarial loss: 0.608517\n",
      "epoch 90; iter: 0; batch classifier loss: 0.058928; batch adversarial loss: 0.492803\n",
      "epoch 91; iter: 0; batch classifier loss: 0.058426; batch adversarial loss: 0.421769\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074801; batch adversarial loss: 0.471427\n",
      "epoch 93; iter: 0; batch classifier loss: 0.039021; batch adversarial loss: 0.447191\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050513; batch adversarial loss: 0.395150\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064303; batch adversarial loss: 0.431891\n",
      "epoch 96; iter: 0; batch classifier loss: 0.026055; batch adversarial loss: 0.490844\n",
      "epoch 97; iter: 0; batch classifier loss: 0.027249; batch adversarial loss: 0.533532\n",
      "epoch 98; iter: 0; batch classifier loss: 0.031064; batch adversarial loss: 0.469609\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041288; batch adversarial loss: 0.529434\n",
      "epoch 100; iter: 0; batch classifier loss: 0.085341; batch adversarial loss: 0.411984\n",
      "epoch 101; iter: 0; batch classifier loss: 0.060932; batch adversarial loss: 0.554553\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053252; batch adversarial loss: 0.414802\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060027; batch adversarial loss: 0.468153\n",
      "epoch 104; iter: 0; batch classifier loss: 0.029926; batch adversarial loss: 0.438313\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056700; batch adversarial loss: 0.429149\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050465; batch adversarial loss: 0.475127\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034050; batch adversarial loss: 0.446503\n",
      "epoch 108; iter: 0; batch classifier loss: 0.032820; batch adversarial loss: 0.575496\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037147; batch adversarial loss: 0.517430\n",
      "epoch 110; iter: 0; batch classifier loss: 0.054261; batch adversarial loss: 0.393817\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051201; batch adversarial loss: 0.484132\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059494; batch adversarial loss: 0.430835\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027268; batch adversarial loss: 0.349813\n",
      "epoch 114; iter: 0; batch classifier loss: 0.031342; batch adversarial loss: 0.426482\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060900; batch adversarial loss: 0.401237\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029465; batch adversarial loss: 0.492165\n",
      "epoch 117; iter: 0; batch classifier loss: 0.076861; batch adversarial loss: 0.391947\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048069; batch adversarial loss: 0.499761\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041115; batch adversarial loss: 0.406980\n",
      "epoch 120; iter: 0; batch classifier loss: 0.024796; batch adversarial loss: 0.455454\n",
      "epoch 121; iter: 0; batch classifier loss: 0.023126; batch adversarial loss: 0.547430\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042764; batch adversarial loss: 0.485635\n",
      "epoch 123; iter: 0; batch classifier loss: 0.022300; batch adversarial loss: 0.458544\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025830; batch adversarial loss: 0.420653\n",
      "epoch 125; iter: 0; batch classifier loss: 0.019266; batch adversarial loss: 0.360113\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031160; batch adversarial loss: 0.437119\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030380; batch adversarial loss: 0.468837\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056991; batch adversarial loss: 0.471172\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018187; batch adversarial loss: 0.469785\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028368; batch adversarial loss: 0.454230\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044550; batch adversarial loss: 0.446021\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050515; batch adversarial loss: 0.427019\n",
      "epoch 133; iter: 0; batch classifier loss: 0.070935; batch adversarial loss: 0.543826\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026876; batch adversarial loss: 0.366235\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032548; batch adversarial loss: 0.451565\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013893; batch adversarial loss: 0.387436\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035249; batch adversarial loss: 0.474941\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033792; batch adversarial loss: 0.501449\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018708; batch adversarial loss: 0.434106\n",
      "epoch 140; iter: 0; batch classifier loss: 0.011678; batch adversarial loss: 0.517391\n",
      "epoch 141; iter: 0; batch classifier loss: 0.011374; batch adversarial loss: 0.372961\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019403; batch adversarial loss: 0.462297\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019573; batch adversarial loss: 0.407982\n",
      "epoch 144; iter: 0; batch classifier loss: 0.054737; batch adversarial loss: 0.479546\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028434; batch adversarial loss: 0.414029\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026907; batch adversarial loss: 0.488853\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042628; batch adversarial loss: 0.496969\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030396; batch adversarial loss: 0.453537\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012459; batch adversarial loss: 0.453503\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020972; batch adversarial loss: 0.467482\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027335; batch adversarial loss: 0.468317\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017832; batch adversarial loss: 0.500665\n",
      "epoch 153; iter: 0; batch classifier loss: 0.004090; batch adversarial loss: 0.450159\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014987; batch adversarial loss: 0.415404\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018771; batch adversarial loss: 0.459278\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027517; batch adversarial loss: 0.402380\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010274; batch adversarial loss: 0.439045\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015568; batch adversarial loss: 0.460251\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010995; batch adversarial loss: 0.393990\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032282; batch adversarial loss: 0.463379\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035081; batch adversarial loss: 0.456144\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020310; batch adversarial loss: 0.529522\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026601; batch adversarial loss: 0.305380\n",
      "epoch 164; iter: 0; batch classifier loss: 0.007426; batch adversarial loss: 0.340904\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044817; batch adversarial loss: 0.424784\n",
      "epoch 166; iter: 0; batch classifier loss: 0.009806; batch adversarial loss: 0.387250\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006918; batch adversarial loss: 0.423746\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013606; batch adversarial loss: 0.420677\n",
      "epoch 169; iter: 0; batch classifier loss: 0.045362; batch adversarial loss: 0.474899\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028618; batch adversarial loss: 0.542723\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025714; batch adversarial loss: 0.513201\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005797; batch adversarial loss: 0.485621\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006106; batch adversarial loss: 0.560511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.020860; batch adversarial loss: 0.416328\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017504; batch adversarial loss: 0.398467\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019131; batch adversarial loss: 0.525789\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024482; batch adversarial loss: 0.362741\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024667; batch adversarial loss: 0.583496\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015689; batch adversarial loss: 0.553970\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013626; batch adversarial loss: 0.535722\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017361; batch adversarial loss: 0.416119\n",
      "epoch 182; iter: 0; batch classifier loss: 0.041347; batch adversarial loss: 0.430518\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027882; batch adversarial loss: 0.393472\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015164; batch adversarial loss: 0.422107\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008163; batch adversarial loss: 0.389793\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022355; batch adversarial loss: 0.350927\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009455; batch adversarial loss: 0.610992\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009565; batch adversarial loss: 0.458094\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007137; batch adversarial loss: 0.435198\n",
      "epoch 190; iter: 0; batch classifier loss: 0.043582; batch adversarial loss: 0.383662\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032583; batch adversarial loss: 0.452533\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021132; batch adversarial loss: 0.395032\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006874; batch adversarial loss: 0.454589\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018749; batch adversarial loss: 0.435361\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020933; batch adversarial loss: 0.482989\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012569; batch adversarial loss: 0.483645\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009954; batch adversarial loss: 0.439466\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013207; batch adversarial loss: 0.447292\n",
      "epoch 199; iter: 0; batch classifier loss: 0.003439; batch adversarial loss: 0.557125\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701264; batch adversarial loss: 0.701084\n",
      "epoch 1; iter: 0; batch classifier loss: 0.489311; batch adversarial loss: 0.718826\n",
      "epoch 2; iter: 0; batch classifier loss: 0.460902; batch adversarial loss: 0.664396\n",
      "epoch 3; iter: 0; batch classifier loss: 0.397376; batch adversarial loss: 0.639760\n",
      "epoch 4; iter: 0; batch classifier loss: 0.319760; batch adversarial loss: 0.630572\n",
      "epoch 5; iter: 0; batch classifier loss: 0.242889; batch adversarial loss: 0.584304\n",
      "epoch 6; iter: 0; batch classifier loss: 0.289145; batch adversarial loss: 0.550983\n",
      "epoch 7; iter: 0; batch classifier loss: 0.324215; batch adversarial loss: 0.496535\n",
      "epoch 8; iter: 0; batch classifier loss: 0.290460; batch adversarial loss: 0.501978\n",
      "epoch 9; iter: 0; batch classifier loss: 0.224494; batch adversarial loss: 0.495185\n",
      "epoch 10; iter: 0; batch classifier loss: 0.303581; batch adversarial loss: 0.510464\n",
      "epoch 11; iter: 0; batch classifier loss: 0.227021; batch adversarial loss: 0.464865\n",
      "epoch 12; iter: 0; batch classifier loss: 0.193717; batch adversarial loss: 0.525487\n",
      "epoch 13; iter: 0; batch classifier loss: 0.250056; batch adversarial loss: 0.509975\n",
      "epoch 14; iter: 0; batch classifier loss: 0.179318; batch adversarial loss: 0.500471\n",
      "epoch 15; iter: 0; batch classifier loss: 0.115457; batch adversarial loss: 0.395133\n",
      "epoch 16; iter: 0; batch classifier loss: 0.225540; batch adversarial loss: 0.417859\n",
      "epoch 17; iter: 0; batch classifier loss: 0.196978; batch adversarial loss: 0.457033\n",
      "epoch 18; iter: 0; batch classifier loss: 0.103980; batch adversarial loss: 0.449775\n",
      "epoch 19; iter: 0; batch classifier loss: 0.150799; batch adversarial loss: 0.482013\n",
      "epoch 20; iter: 0; batch classifier loss: 0.174101; batch adversarial loss: 0.453557\n",
      "epoch 21; iter: 0; batch classifier loss: 0.084393; batch adversarial loss: 0.519391\n",
      "epoch 22; iter: 0; batch classifier loss: 0.145953; batch adversarial loss: 0.425445\n",
      "epoch 23; iter: 0; batch classifier loss: 0.115744; batch adversarial loss: 0.405816\n",
      "epoch 24; iter: 0; batch classifier loss: 0.127856; batch adversarial loss: 0.411246\n",
      "epoch 25; iter: 0; batch classifier loss: 0.164911; batch adversarial loss: 0.467732\n",
      "epoch 26; iter: 0; batch classifier loss: 0.130478; batch adversarial loss: 0.514701\n",
      "epoch 27; iter: 0; batch classifier loss: 0.161496; batch adversarial loss: 0.539979\n",
      "epoch 28; iter: 0; batch classifier loss: 0.142214; batch adversarial loss: 0.388192\n",
      "epoch 29; iter: 0; batch classifier loss: 0.142431; batch adversarial loss: 0.587024\n",
      "epoch 30; iter: 0; batch classifier loss: 0.210880; batch adversarial loss: 0.588394\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178493; batch adversarial loss: 0.611547\n",
      "epoch 32; iter: 0; batch classifier loss: 0.168267; batch adversarial loss: 0.503100\n",
      "epoch 33; iter: 0; batch classifier loss: 0.132843; batch adversarial loss: 0.445128\n",
      "epoch 34; iter: 0; batch classifier loss: 0.160063; batch adversarial loss: 0.515145\n",
      "epoch 35; iter: 0; batch classifier loss: 0.109431; batch adversarial loss: 0.378578\n",
      "epoch 36; iter: 0; batch classifier loss: 0.136832; batch adversarial loss: 0.419016\n",
      "epoch 37; iter: 0; batch classifier loss: 0.162327; batch adversarial loss: 0.491088\n",
      "epoch 38; iter: 0; batch classifier loss: 0.119338; batch adversarial loss: 0.422012\n",
      "epoch 39; iter: 0; batch classifier loss: 0.249600; batch adversarial loss: 0.578501\n",
      "epoch 40; iter: 0; batch classifier loss: 0.204558; batch adversarial loss: 0.456979\n",
      "epoch 41; iter: 0; batch classifier loss: 0.256948; batch adversarial loss: 0.508947\n",
      "epoch 42; iter: 0; batch classifier loss: 0.195725; batch adversarial loss: 0.418234\n",
      "epoch 43; iter: 0; batch classifier loss: 0.118946; batch adversarial loss: 0.435287\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101057; batch adversarial loss: 0.432705\n",
      "epoch 45; iter: 0; batch classifier loss: 0.077220; batch adversarial loss: 0.399721\n",
      "epoch 46; iter: 0; batch classifier loss: 0.066858; batch adversarial loss: 0.517851\n",
      "epoch 47; iter: 0; batch classifier loss: 0.057785; batch adversarial loss: 0.419577\n",
      "epoch 48; iter: 0; batch classifier loss: 0.087145; batch adversarial loss: 0.416764\n",
      "epoch 49; iter: 0; batch classifier loss: 0.063572; batch adversarial loss: 0.436706\n",
      "epoch 50; iter: 0; batch classifier loss: 0.069708; batch adversarial loss: 0.447503\n",
      "epoch 51; iter: 0; batch classifier loss: 0.069542; batch adversarial loss: 0.456475\n",
      "epoch 52; iter: 0; batch classifier loss: 0.080293; batch adversarial loss: 0.422390\n",
      "epoch 53; iter: 0; batch classifier loss: 0.059382; batch adversarial loss: 0.420633\n",
      "epoch 54; iter: 0; batch classifier loss: 0.090969; batch adversarial loss: 0.463735\n",
      "epoch 55; iter: 0; batch classifier loss: 0.078755; batch adversarial loss: 0.429647\n",
      "epoch 56; iter: 0; batch classifier loss: 0.039456; batch adversarial loss: 0.496850\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107775; batch adversarial loss: 0.418972\n",
      "epoch 58; iter: 0; batch classifier loss: 0.100140; batch adversarial loss: 0.398268\n",
      "epoch 59; iter: 0; batch classifier loss: 0.137568; batch adversarial loss: 0.498219\n",
      "epoch 60; iter: 0; batch classifier loss: 0.050873; batch adversarial loss: 0.407272\n",
      "epoch 61; iter: 0; batch classifier loss: 0.063473; batch adversarial loss: 0.392999\n",
      "epoch 62; iter: 0; batch classifier loss: 0.075528; batch adversarial loss: 0.473351\n",
      "epoch 63; iter: 0; batch classifier loss: 0.066826; batch adversarial loss: 0.526453\n",
      "epoch 64; iter: 0; batch classifier loss: 0.068579; batch adversarial loss: 0.418664\n",
      "epoch 65; iter: 0; batch classifier loss: 0.104280; batch adversarial loss: 0.437785\n",
      "epoch 66; iter: 0; batch classifier loss: 0.113701; batch adversarial loss: 0.442226\n",
      "epoch 67; iter: 0; batch classifier loss: 0.142938; batch adversarial loss: 0.365927\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070256; batch adversarial loss: 0.364949\n",
      "epoch 69; iter: 0; batch classifier loss: 0.111918; batch adversarial loss: 0.476172\n",
      "epoch 70; iter: 0; batch classifier loss: 0.076886; batch adversarial loss: 0.492755\n",
      "epoch 71; iter: 0; batch classifier loss: 0.110845; batch adversarial loss: 0.361170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.090480; batch adversarial loss: 0.348966\n",
      "epoch 73; iter: 0; batch classifier loss: 0.130207; batch adversarial loss: 0.440048\n",
      "epoch 74; iter: 0; batch classifier loss: 0.050426; batch adversarial loss: 0.503630\n",
      "epoch 75; iter: 0; batch classifier loss: 0.048921; batch adversarial loss: 0.535390\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065257; batch adversarial loss: 0.437004\n",
      "epoch 77; iter: 0; batch classifier loss: 0.083767; batch adversarial loss: 0.467030\n",
      "epoch 78; iter: 0; batch classifier loss: 0.118665; batch adversarial loss: 0.454003\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068588; batch adversarial loss: 0.454351\n",
      "epoch 80; iter: 0; batch classifier loss: 0.081676; batch adversarial loss: 0.473470\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068668; batch adversarial loss: 0.400573\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065298; batch adversarial loss: 0.361497\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079689; batch adversarial loss: 0.480299\n",
      "epoch 84; iter: 0; batch classifier loss: 0.061028; batch adversarial loss: 0.466766\n",
      "epoch 85; iter: 0; batch classifier loss: 0.066184; batch adversarial loss: 0.431927\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063902; batch adversarial loss: 0.464497\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042404; batch adversarial loss: 0.504140\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049738; batch adversarial loss: 0.496570\n",
      "epoch 89; iter: 0; batch classifier loss: 0.082470; batch adversarial loss: 0.602153\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073629; batch adversarial loss: 0.477580\n",
      "epoch 91; iter: 0; batch classifier loss: 0.061780; batch adversarial loss: 0.399574\n",
      "epoch 92; iter: 0; batch classifier loss: 0.098014; batch adversarial loss: 0.503041\n",
      "epoch 93; iter: 0; batch classifier loss: 0.060568; batch adversarial loss: 0.458604\n",
      "epoch 94; iter: 0; batch classifier loss: 0.081982; batch adversarial loss: 0.471873\n",
      "epoch 95; iter: 0; batch classifier loss: 0.092098; batch adversarial loss: 0.423065\n",
      "epoch 96; iter: 0; batch classifier loss: 0.078050; batch adversarial loss: 0.420222\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066154; batch adversarial loss: 0.476749\n",
      "epoch 98; iter: 0; batch classifier loss: 0.080588; batch adversarial loss: 0.470339\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062787; batch adversarial loss: 0.431834\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038453; batch adversarial loss: 0.336103\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083729; batch adversarial loss: 0.639503\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033731; batch adversarial loss: 0.412516\n",
      "epoch 103; iter: 0; batch classifier loss: 0.112218; batch adversarial loss: 0.442597\n",
      "epoch 104; iter: 0; batch classifier loss: 0.067608; batch adversarial loss: 0.529027\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050109; batch adversarial loss: 0.423286\n",
      "epoch 106; iter: 0; batch classifier loss: 0.065290; batch adversarial loss: 0.405151\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062664; batch adversarial loss: 0.477581\n",
      "epoch 108; iter: 0; batch classifier loss: 0.047181; batch adversarial loss: 0.499941\n",
      "epoch 109; iter: 0; batch classifier loss: 0.076206; batch adversarial loss: 0.393282\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050518; batch adversarial loss: 0.400042\n",
      "epoch 111; iter: 0; batch classifier loss: 0.096957; batch adversarial loss: 0.404679\n",
      "epoch 112; iter: 0; batch classifier loss: 0.062962; batch adversarial loss: 0.492103\n",
      "epoch 113; iter: 0; batch classifier loss: 0.087192; batch adversarial loss: 0.549240\n",
      "epoch 114; iter: 0; batch classifier loss: 0.075988; batch adversarial loss: 0.439938\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035841; batch adversarial loss: 0.415633\n",
      "epoch 116; iter: 0; batch classifier loss: 0.059808; batch adversarial loss: 0.479430\n",
      "epoch 117; iter: 0; batch classifier loss: 0.082089; batch adversarial loss: 0.480374\n",
      "epoch 118; iter: 0; batch classifier loss: 0.078817; batch adversarial loss: 0.406431\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031393; batch adversarial loss: 0.442332\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035627; batch adversarial loss: 0.410565\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027373; batch adversarial loss: 0.463187\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043851; batch adversarial loss: 0.416407\n",
      "epoch 123; iter: 0; batch classifier loss: 0.052254; batch adversarial loss: 0.461710\n",
      "epoch 124; iter: 0; batch classifier loss: 0.017518; batch adversarial loss: 0.407219\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047798; batch adversarial loss: 0.536441\n",
      "epoch 126; iter: 0; batch classifier loss: 0.054682; batch adversarial loss: 0.456602\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023265; batch adversarial loss: 0.438883\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038743; batch adversarial loss: 0.536654\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037968; batch adversarial loss: 0.458479\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036384; batch adversarial loss: 0.385038\n",
      "epoch 131; iter: 0; batch classifier loss: 0.071114; batch adversarial loss: 0.405869\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033819; batch adversarial loss: 0.451869\n",
      "epoch 133; iter: 0; batch classifier loss: 0.055337; batch adversarial loss: 0.506658\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032033; batch adversarial loss: 0.477189\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035431; batch adversarial loss: 0.457283\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018114; batch adversarial loss: 0.312147\n",
      "epoch 137; iter: 0; batch classifier loss: 0.050968; batch adversarial loss: 0.352156\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040019; batch adversarial loss: 0.402460\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020053; batch adversarial loss: 0.377671\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028326; batch adversarial loss: 0.436239\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021354; batch adversarial loss: 0.469992\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048195; batch adversarial loss: 0.457639\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027917; batch adversarial loss: 0.398610\n",
      "epoch 144; iter: 0; batch classifier loss: 0.046475; batch adversarial loss: 0.512075\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028159; batch adversarial loss: 0.359325\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020196; batch adversarial loss: 0.423913\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019510; batch adversarial loss: 0.392172\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032926; batch adversarial loss: 0.477645\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030118; batch adversarial loss: 0.438893\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023968; batch adversarial loss: 0.353479\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040454; batch adversarial loss: 0.470582\n",
      "epoch 152; iter: 0; batch classifier loss: 0.054493; batch adversarial loss: 0.405223\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040941; batch adversarial loss: 0.472633\n",
      "epoch 154; iter: 0; batch classifier loss: 0.082029; batch adversarial loss: 0.517844\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015993; batch adversarial loss: 0.452905\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044744; batch adversarial loss: 0.479760\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022947; batch adversarial loss: 0.459337\n",
      "epoch 158; iter: 0; batch classifier loss: 0.060311; batch adversarial loss: 0.437776\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012501; batch adversarial loss: 0.484465\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023413; batch adversarial loss: 0.365298\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039166; batch adversarial loss: 0.362464\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038405; batch adversarial loss: 0.430730\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033710; batch adversarial loss: 0.432618\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033177; batch adversarial loss: 0.461275\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013248; batch adversarial loss: 0.390159\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035560; batch adversarial loss: 0.464234\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019740; batch adversarial loss: 0.496792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.030885; batch adversarial loss: 0.601419\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023552; batch adversarial loss: 0.390016\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024820; batch adversarial loss: 0.441608\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036405; batch adversarial loss: 0.531536\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017765; batch adversarial loss: 0.420066\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022879; batch adversarial loss: 0.524472\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037244; batch adversarial loss: 0.457958\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008544; batch adversarial loss: 0.406590\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010573; batch adversarial loss: 0.459356\n",
      "epoch 177; iter: 0; batch classifier loss: 0.039897; batch adversarial loss: 0.350452\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009092; batch adversarial loss: 0.465963\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016683; batch adversarial loss: 0.506369\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024050; batch adversarial loss: 0.503096\n",
      "epoch 181; iter: 0; batch classifier loss: 0.002568; batch adversarial loss: 0.431370\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018853; batch adversarial loss: 0.431578\n",
      "epoch 183; iter: 0; batch classifier loss: 0.004026; batch adversarial loss: 0.483016\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007874; batch adversarial loss: 0.398411\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033555; batch adversarial loss: 0.478254\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024029; batch adversarial loss: 0.403789\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012505; batch adversarial loss: 0.459785\n",
      "epoch 188; iter: 0; batch classifier loss: 0.045327; batch adversarial loss: 0.494639\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021114; batch adversarial loss: 0.551142\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007349; batch adversarial loss: 0.502947\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026521; batch adversarial loss: 0.479669\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019022; batch adversarial loss: 0.493325\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026631; batch adversarial loss: 0.398026\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012720; batch adversarial loss: 0.408943\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016044; batch adversarial loss: 0.486245\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007716; batch adversarial loss: 0.554802\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013165; batch adversarial loss: 0.546209\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006023; batch adversarial loss: 0.372966\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007853; batch adversarial loss: 0.470873\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726910; batch adversarial loss: 0.822698\n",
      "epoch 1; iter: 0; batch classifier loss: 0.498070; batch adversarial loss: 0.769712\n",
      "epoch 2; iter: 0; batch classifier loss: 0.590034; batch adversarial loss: 0.736004\n",
      "epoch 3; iter: 0; batch classifier loss: 0.567881; batch adversarial loss: 0.687347\n",
      "epoch 4; iter: 0; batch classifier loss: 0.768105; batch adversarial loss: 0.624692\n",
      "epoch 5; iter: 0; batch classifier loss: 0.583219; batch adversarial loss: 0.609418\n",
      "epoch 6; iter: 0; batch classifier loss: 0.418553; batch adversarial loss: 0.576268\n",
      "epoch 7; iter: 0; batch classifier loss: 0.426028; batch adversarial loss: 0.548652\n",
      "epoch 8; iter: 0; batch classifier loss: 0.370702; batch adversarial loss: 0.548399\n",
      "epoch 9; iter: 0; batch classifier loss: 0.399344; batch adversarial loss: 0.561378\n",
      "epoch 10; iter: 0; batch classifier loss: 0.373351; batch adversarial loss: 0.531040\n",
      "epoch 11; iter: 0; batch classifier loss: 0.396340; batch adversarial loss: 0.558453\n",
      "epoch 12; iter: 0; batch classifier loss: 0.430896; batch adversarial loss: 0.553438\n",
      "epoch 13; iter: 0; batch classifier loss: 0.343460; batch adversarial loss: 0.528949\n",
      "epoch 14; iter: 0; batch classifier loss: 0.421533; batch adversarial loss: 0.521761\n",
      "epoch 15; iter: 0; batch classifier loss: 0.393806; batch adversarial loss: 0.457598\n",
      "epoch 16; iter: 0; batch classifier loss: 0.355646; batch adversarial loss: 0.451880\n",
      "epoch 17; iter: 0; batch classifier loss: 0.422374; batch adversarial loss: 0.498979\n",
      "epoch 18; iter: 0; batch classifier loss: 0.362799; batch adversarial loss: 0.462526\n",
      "epoch 19; iter: 0; batch classifier loss: 0.364860; batch adversarial loss: 0.518911\n",
      "epoch 20; iter: 0; batch classifier loss: 0.361469; batch adversarial loss: 0.465925\n",
      "epoch 21; iter: 0; batch classifier loss: 0.420669; batch adversarial loss: 0.474512\n",
      "epoch 22; iter: 0; batch classifier loss: 0.254996; batch adversarial loss: 0.492679\n",
      "epoch 23; iter: 0; batch classifier loss: 0.337616; batch adversarial loss: 0.426057\n",
      "epoch 24; iter: 0; batch classifier loss: 0.341683; batch adversarial loss: 0.475785\n",
      "epoch 25; iter: 0; batch classifier loss: 0.278092; batch adversarial loss: 0.422906\n",
      "epoch 26; iter: 0; batch classifier loss: 0.251249; batch adversarial loss: 0.515309\n",
      "epoch 27; iter: 0; batch classifier loss: 0.273850; batch adversarial loss: 0.457956\n",
      "epoch 28; iter: 0; batch classifier loss: 0.226897; batch adversarial loss: 0.410515\n",
      "epoch 29; iter: 0; batch classifier loss: 0.226586; batch adversarial loss: 0.517173\n",
      "epoch 30; iter: 0; batch classifier loss: 0.281491; batch adversarial loss: 0.489215\n",
      "epoch 31; iter: 0; batch classifier loss: 0.234144; batch adversarial loss: 0.442799\n",
      "epoch 32; iter: 0; batch classifier loss: 0.247486; batch adversarial loss: 0.447723\n",
      "epoch 33; iter: 0; batch classifier loss: 0.199281; batch adversarial loss: 0.516940\n",
      "epoch 34; iter: 0; batch classifier loss: 0.184881; batch adversarial loss: 0.466594\n",
      "epoch 35; iter: 0; batch classifier loss: 0.189368; batch adversarial loss: 0.529230\n",
      "epoch 36; iter: 0; batch classifier loss: 0.201554; batch adversarial loss: 0.474963\n",
      "epoch 37; iter: 0; batch classifier loss: 0.211254; batch adversarial loss: 0.543887\n",
      "epoch 38; iter: 0; batch classifier loss: 0.177224; batch adversarial loss: 0.558062\n",
      "epoch 39; iter: 0; batch classifier loss: 0.253771; batch adversarial loss: 0.402600\n",
      "epoch 40; iter: 0; batch classifier loss: 0.247463; batch adversarial loss: 0.464172\n",
      "epoch 41; iter: 0; batch classifier loss: 0.223983; batch adversarial loss: 0.438439\n",
      "epoch 42; iter: 0; batch classifier loss: 0.216328; batch adversarial loss: 0.446245\n",
      "epoch 43; iter: 0; batch classifier loss: 0.223557; batch adversarial loss: 0.488428\n",
      "epoch 44; iter: 0; batch classifier loss: 0.168909; batch adversarial loss: 0.469806\n",
      "epoch 45; iter: 0; batch classifier loss: 0.241114; batch adversarial loss: 0.454176\n",
      "epoch 46; iter: 0; batch classifier loss: 0.188272; batch adversarial loss: 0.357060\n",
      "epoch 47; iter: 0; batch classifier loss: 0.223317; batch adversarial loss: 0.350672\n",
      "epoch 48; iter: 0; batch classifier loss: 0.208524; batch adversarial loss: 0.469461\n",
      "epoch 49; iter: 0; batch classifier loss: 0.173424; batch adversarial loss: 0.521478\n",
      "epoch 50; iter: 0; batch classifier loss: 0.177457; batch adversarial loss: 0.371599\n",
      "epoch 51; iter: 0; batch classifier loss: 0.171449; batch adversarial loss: 0.378222\n",
      "epoch 52; iter: 0; batch classifier loss: 0.218415; batch adversarial loss: 0.446502\n",
      "epoch 53; iter: 0; batch classifier loss: 0.277773; batch adversarial loss: 0.447425\n",
      "epoch 54; iter: 0; batch classifier loss: 0.243776; batch adversarial loss: 0.458989\n",
      "epoch 55; iter: 0; batch classifier loss: 0.191230; batch adversarial loss: 0.468732\n",
      "epoch 56; iter: 0; batch classifier loss: 0.157398; batch adversarial loss: 0.436030\n",
      "epoch 57; iter: 0; batch classifier loss: 0.174684; batch adversarial loss: 0.532325\n",
      "epoch 58; iter: 0; batch classifier loss: 0.175946; batch adversarial loss: 0.398671\n",
      "epoch 59; iter: 0; batch classifier loss: 0.280799; batch adversarial loss: 0.371976\n",
      "epoch 60; iter: 0; batch classifier loss: 0.198039; batch adversarial loss: 0.446241\n",
      "epoch 61; iter: 0; batch classifier loss: 0.233272; batch adversarial loss: 0.470134\n",
      "epoch 62; iter: 0; batch classifier loss: 0.244396; batch adversarial loss: 0.532229\n",
      "epoch 63; iter: 0; batch classifier loss: 0.208439; batch adversarial loss: 0.435130\n",
      "epoch 64; iter: 0; batch classifier loss: 0.198944; batch adversarial loss: 0.386111\n",
      "epoch 65; iter: 0; batch classifier loss: 0.137383; batch adversarial loss: 0.470585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.196301; batch adversarial loss: 0.445757\n",
      "epoch 67; iter: 0; batch classifier loss: 0.265330; batch adversarial loss: 0.435883\n",
      "epoch 68; iter: 0; batch classifier loss: 0.204771; batch adversarial loss: 0.397447\n",
      "epoch 69; iter: 0; batch classifier loss: 0.235458; batch adversarial loss: 0.470585\n",
      "epoch 70; iter: 0; batch classifier loss: 0.188565; batch adversarial loss: 0.360306\n",
      "epoch 71; iter: 0; batch classifier loss: 0.172059; batch adversarial loss: 0.397257\n",
      "epoch 72; iter: 0; batch classifier loss: 0.204143; batch adversarial loss: 0.457584\n",
      "epoch 73; iter: 0; batch classifier loss: 0.222516; batch adversarial loss: 0.397181\n",
      "epoch 74; iter: 0; batch classifier loss: 0.166796; batch adversarial loss: 0.532559\n",
      "epoch 75; iter: 0; batch classifier loss: 0.123251; batch adversarial loss: 0.582883\n",
      "epoch 76; iter: 0; batch classifier loss: 0.146177; batch adversarial loss: 0.435204\n",
      "epoch 77; iter: 0; batch classifier loss: 0.147066; batch adversarial loss: 0.433316\n",
      "epoch 78; iter: 0; batch classifier loss: 0.221411; batch adversarial loss: 0.470164\n",
      "epoch 79; iter: 0; batch classifier loss: 0.208991; batch adversarial loss: 0.557483\n",
      "epoch 80; iter: 0; batch classifier loss: 0.195971; batch adversarial loss: 0.458821\n",
      "epoch 81; iter: 0; batch classifier loss: 0.163595; batch adversarial loss: 0.470676\n",
      "epoch 82; iter: 0; batch classifier loss: 0.148813; batch adversarial loss: 0.446248\n",
      "epoch 83; iter: 0; batch classifier loss: 0.206040; batch adversarial loss: 0.447618\n",
      "epoch 84; iter: 0; batch classifier loss: 0.208525; batch adversarial loss: 0.420126\n",
      "epoch 85; iter: 0; batch classifier loss: 0.180739; batch adversarial loss: 0.422198\n",
      "epoch 86; iter: 0; batch classifier loss: 0.189610; batch adversarial loss: 0.522732\n",
      "epoch 87; iter: 0; batch classifier loss: 0.115780; batch adversarial loss: 0.470065\n",
      "epoch 88; iter: 0; batch classifier loss: 0.147322; batch adversarial loss: 0.519728\n",
      "epoch 89; iter: 0; batch classifier loss: 0.100889; batch adversarial loss: 0.454967\n",
      "epoch 90; iter: 0; batch classifier loss: 0.110639; batch adversarial loss: 0.495127\n",
      "epoch 91; iter: 0; batch classifier loss: 0.108726; batch adversarial loss: 0.440452\n",
      "epoch 92; iter: 0; batch classifier loss: 0.059081; batch adversarial loss: 0.452752\n",
      "epoch 93; iter: 0; batch classifier loss: 0.157054; batch adversarial loss: 0.334885\n",
      "epoch 94; iter: 0; batch classifier loss: 0.090169; batch adversarial loss: 0.399353\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077500; batch adversarial loss: 0.407167\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049569; batch adversarial loss: 0.421802\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047601; batch adversarial loss: 0.476065\n",
      "epoch 98; iter: 0; batch classifier loss: 0.075986; batch adversarial loss: 0.493384\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042087; batch adversarial loss: 0.452343\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075007; batch adversarial loss: 0.469543\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056550; batch adversarial loss: 0.468332\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050836; batch adversarial loss: 0.424929\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041353; batch adversarial loss: 0.330891\n",
      "epoch 104; iter: 0; batch classifier loss: 0.055147; batch adversarial loss: 0.455321\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041328; batch adversarial loss: 0.498109\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046402; batch adversarial loss: 0.393360\n",
      "epoch 107; iter: 0; batch classifier loss: 0.021705; batch adversarial loss: 0.431185\n",
      "epoch 108; iter: 0; batch classifier loss: 0.031215; batch adversarial loss: 0.385417\n",
      "epoch 109; iter: 0; batch classifier loss: 0.028259; batch adversarial loss: 0.536708\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023513; batch adversarial loss: 0.441543\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043685; batch adversarial loss: 0.413732\n",
      "epoch 112; iter: 0; batch classifier loss: 0.032063; batch adversarial loss: 0.474368\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055496; batch adversarial loss: 0.531191\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053082; batch adversarial loss: 0.442457\n",
      "epoch 115; iter: 0; batch classifier loss: 0.021368; batch adversarial loss: 0.354121\n",
      "epoch 116; iter: 0; batch classifier loss: 0.013706; batch adversarial loss: 0.481736\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036070; batch adversarial loss: 0.470985\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025557; batch adversarial loss: 0.405918\n",
      "epoch 119; iter: 0; batch classifier loss: 0.020122; batch adversarial loss: 0.443335\n",
      "epoch 120; iter: 0; batch classifier loss: 0.017790; batch adversarial loss: 0.423089\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046339; batch adversarial loss: 0.527732\n",
      "epoch 122; iter: 0; batch classifier loss: 0.023739; batch adversarial loss: 0.448212\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038037; batch adversarial loss: 0.452657\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022916; batch adversarial loss: 0.463192\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026699; batch adversarial loss: 0.454617\n",
      "epoch 126; iter: 0; batch classifier loss: 0.010953; batch adversarial loss: 0.419516\n",
      "epoch 127; iter: 0; batch classifier loss: 0.017091; batch adversarial loss: 0.438932\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027643; batch adversarial loss: 0.428846\n",
      "epoch 129; iter: 0; batch classifier loss: 0.013342; batch adversarial loss: 0.486098\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016100; batch adversarial loss: 0.486592\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018742; batch adversarial loss: 0.440356\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042625; batch adversarial loss: 0.442318\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020590; batch adversarial loss: 0.499465\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025381; batch adversarial loss: 0.327670\n",
      "epoch 135; iter: 0; batch classifier loss: 0.015516; batch adversarial loss: 0.483436\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031636; batch adversarial loss: 0.425195\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015645; batch adversarial loss: 0.453762\n",
      "epoch 138; iter: 0; batch classifier loss: 0.061147; batch adversarial loss: 0.425121\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014098; batch adversarial loss: 0.360562\n",
      "epoch 140; iter: 0; batch classifier loss: 0.012445; batch adversarial loss: 0.406535\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031035; batch adversarial loss: 0.420078\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033106; batch adversarial loss: 0.424176\n",
      "epoch 143; iter: 0; batch classifier loss: 0.010834; batch adversarial loss: 0.425299\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012495; batch adversarial loss: 0.540952\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039710; batch adversarial loss: 0.436661\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027176; batch adversarial loss: 0.557539\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019274; batch adversarial loss: 0.358384\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034059; batch adversarial loss: 0.416915\n",
      "epoch 149; iter: 0; batch classifier loss: 0.005452; batch adversarial loss: 0.475572\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020149; batch adversarial loss: 0.484711\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008210; batch adversarial loss: 0.450424\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008538; batch adversarial loss: 0.391630\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020364; batch adversarial loss: 0.522446\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014478; batch adversarial loss: 0.562298\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049748; batch adversarial loss: 0.410187\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011034; batch adversarial loss: 0.473758\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015109; batch adversarial loss: 0.557074\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013192; batch adversarial loss: 0.430974\n",
      "epoch 159; iter: 0; batch classifier loss: 0.069231; batch adversarial loss: 0.387736\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007295; batch adversarial loss: 0.424448\n",
      "epoch 161; iter: 0; batch classifier loss: 0.047000; batch adversarial loss: 0.501316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.023248; batch adversarial loss: 0.511351\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015522; batch adversarial loss: 0.476293\n",
      "epoch 164; iter: 0; batch classifier loss: 0.040095; batch adversarial loss: 0.535493\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011788; batch adversarial loss: 0.457871\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040885; batch adversarial loss: 0.530092\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014116; batch adversarial loss: 0.443851\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017411; batch adversarial loss: 0.450730\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012599; batch adversarial loss: 0.478307\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010840; batch adversarial loss: 0.525986\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010553; batch adversarial loss: 0.433643\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033712; batch adversarial loss: 0.418828\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010460; batch adversarial loss: 0.474730\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013185; batch adversarial loss: 0.557023\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024971; batch adversarial loss: 0.408946\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010555; batch adversarial loss: 0.481015\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014926; batch adversarial loss: 0.466511\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018182; batch adversarial loss: 0.438557\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019992; batch adversarial loss: 0.479622\n",
      "epoch 180; iter: 0; batch classifier loss: 0.055370; batch adversarial loss: 0.428941\n",
      "epoch 181; iter: 0; batch classifier loss: 0.055387; batch adversarial loss: 0.451755\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015789; batch adversarial loss: 0.480849\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034558; batch adversarial loss: 0.463031\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026728; batch adversarial loss: 0.508493\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018386; batch adversarial loss: 0.536144\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020349; batch adversarial loss: 0.523467\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012390; batch adversarial loss: 0.508080\n",
      "epoch 188; iter: 0; batch classifier loss: 0.055346; batch adversarial loss: 0.412308\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021479; batch adversarial loss: 0.435477\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006874; batch adversarial loss: 0.408758\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022117; batch adversarial loss: 0.447992\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006541; batch adversarial loss: 0.484371\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005459; batch adversarial loss: 0.464097\n",
      "epoch 194; iter: 0; batch classifier loss: 0.002790; batch adversarial loss: 0.489944\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025543; batch adversarial loss: 0.433156\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030290; batch adversarial loss: 0.413154\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034860; batch adversarial loss: 0.435741\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004648; batch adversarial loss: 0.470489\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017435; batch adversarial loss: 0.480281\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698668; batch adversarial loss: 0.728662\n",
      "epoch 1; iter: 0; batch classifier loss: 0.432768; batch adversarial loss: 0.729321\n",
      "epoch 2; iter: 0; batch classifier loss: 0.428103; batch adversarial loss: 0.692204\n",
      "epoch 3; iter: 0; batch classifier loss: 0.365167; batch adversarial loss: 0.654473\n",
      "epoch 4; iter: 0; batch classifier loss: 0.343182; batch adversarial loss: 0.618214\n",
      "epoch 5; iter: 0; batch classifier loss: 0.324080; batch adversarial loss: 0.608537\n",
      "epoch 6; iter: 0; batch classifier loss: 0.327517; batch adversarial loss: 0.585309\n",
      "epoch 7; iter: 0; batch classifier loss: 0.372066; batch adversarial loss: 0.525525\n",
      "epoch 8; iter: 0; batch classifier loss: 0.283637; batch adversarial loss: 0.502051\n",
      "epoch 9; iter: 0; batch classifier loss: 0.289570; batch adversarial loss: 0.468270\n",
      "epoch 10; iter: 0; batch classifier loss: 0.255020; batch adversarial loss: 0.501745\n",
      "epoch 11; iter: 0; batch classifier loss: 0.244924; batch adversarial loss: 0.449567\n",
      "epoch 12; iter: 0; batch classifier loss: 0.216271; batch adversarial loss: 0.538857\n",
      "epoch 13; iter: 0; batch classifier loss: 0.257532; batch adversarial loss: 0.461401\n",
      "epoch 14; iter: 0; batch classifier loss: 0.175318; batch adversarial loss: 0.472531\n",
      "epoch 15; iter: 0; batch classifier loss: 0.151134; batch adversarial loss: 0.442929\n",
      "epoch 16; iter: 0; batch classifier loss: 0.260371; batch adversarial loss: 0.383341\n",
      "epoch 17; iter: 0; batch classifier loss: 0.149253; batch adversarial loss: 0.462315\n",
      "epoch 18; iter: 0; batch classifier loss: 0.217341; batch adversarial loss: 0.360668\n",
      "epoch 19; iter: 0; batch classifier loss: 0.189911; batch adversarial loss: 0.443771\n",
      "epoch 20; iter: 0; batch classifier loss: 0.193818; batch adversarial loss: 0.430534\n",
      "epoch 21; iter: 0; batch classifier loss: 0.210562; batch adversarial loss: 0.524796\n",
      "epoch 22; iter: 0; batch classifier loss: 0.191670; batch adversarial loss: 0.373349\n",
      "epoch 23; iter: 0; batch classifier loss: 0.224271; batch adversarial loss: 0.371002\n",
      "epoch 24; iter: 0; batch classifier loss: 0.130222; batch adversarial loss: 0.398588\n",
      "epoch 25; iter: 0; batch classifier loss: 0.143625; batch adversarial loss: 0.299227\n",
      "epoch 26; iter: 0; batch classifier loss: 0.150031; batch adversarial loss: 0.474118\n",
      "epoch 27; iter: 0; batch classifier loss: 0.251915; batch adversarial loss: 0.406468\n",
      "epoch 28; iter: 0; batch classifier loss: 0.207388; batch adversarial loss: 0.449583\n",
      "epoch 29; iter: 0; batch classifier loss: 0.162142; batch adversarial loss: 0.428772\n",
      "epoch 30; iter: 0; batch classifier loss: 0.136203; batch adversarial loss: 0.408302\n",
      "epoch 31; iter: 0; batch classifier loss: 0.230534; batch adversarial loss: 0.427200\n",
      "epoch 32; iter: 0; batch classifier loss: 0.148547; batch adversarial loss: 0.469736\n",
      "epoch 33; iter: 0; batch classifier loss: 0.203511; batch adversarial loss: 0.407320\n",
      "epoch 34; iter: 0; batch classifier loss: 0.115926; batch adversarial loss: 0.424836\n",
      "epoch 35; iter: 0; batch classifier loss: 0.102784; batch adversarial loss: 0.444909\n",
      "epoch 36; iter: 0; batch classifier loss: 0.125896; batch adversarial loss: 0.383220\n",
      "epoch 37; iter: 0; batch classifier loss: 0.140265; batch adversarial loss: 0.467566\n",
      "epoch 38; iter: 0; batch classifier loss: 0.132902; batch adversarial loss: 0.398202\n",
      "epoch 39; iter: 0; batch classifier loss: 0.120917; batch adversarial loss: 0.326968\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091578; batch adversarial loss: 0.448571\n",
      "epoch 41; iter: 0; batch classifier loss: 0.091154; batch adversarial loss: 0.418981\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106846; batch adversarial loss: 0.378174\n",
      "epoch 43; iter: 0; batch classifier loss: 0.139171; batch adversarial loss: 0.392802\n",
      "epoch 44; iter: 0; batch classifier loss: 0.092695; batch adversarial loss: 0.426229\n",
      "epoch 45; iter: 0; batch classifier loss: 0.096546; batch adversarial loss: 0.446442\n",
      "epoch 46; iter: 0; batch classifier loss: 0.122530; batch adversarial loss: 0.382468\n",
      "epoch 47; iter: 0; batch classifier loss: 0.072649; batch adversarial loss: 0.452973\n",
      "epoch 48; iter: 0; batch classifier loss: 0.090835; batch adversarial loss: 0.500804\n",
      "epoch 49; iter: 0; batch classifier loss: 0.105992; batch adversarial loss: 0.383803\n",
      "epoch 50; iter: 0; batch classifier loss: 0.128271; batch adversarial loss: 0.420594\n",
      "epoch 51; iter: 0; batch classifier loss: 0.134205; batch adversarial loss: 0.443606\n",
      "epoch 52; iter: 0; batch classifier loss: 0.143826; batch adversarial loss: 0.415035\n",
      "epoch 53; iter: 0; batch classifier loss: 0.093064; batch adversarial loss: 0.403795\n",
      "epoch 54; iter: 0; batch classifier loss: 0.091780; batch adversarial loss: 0.426662\n",
      "epoch 55; iter: 0; batch classifier loss: 0.116701; batch adversarial loss: 0.467629\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099200; batch adversarial loss: 0.404540\n",
      "epoch 57; iter: 0; batch classifier loss: 0.059613; batch adversarial loss: 0.405971\n",
      "epoch 58; iter: 0; batch classifier loss: 0.186455; batch adversarial loss: 0.418598\n",
      "epoch 59; iter: 0; batch classifier loss: 0.117886; batch adversarial loss: 0.427062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.124090; batch adversarial loss: 0.413137\n",
      "epoch 61; iter: 0; batch classifier loss: 0.060218; batch adversarial loss: 0.345523\n",
      "epoch 62; iter: 0; batch classifier loss: 0.088910; batch adversarial loss: 0.429326\n",
      "epoch 63; iter: 0; batch classifier loss: 0.082276; batch adversarial loss: 0.399999\n",
      "epoch 64; iter: 0; batch classifier loss: 0.117630; batch adversarial loss: 0.383532\n",
      "epoch 65; iter: 0; batch classifier loss: 0.063661; batch adversarial loss: 0.413284\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096937; batch adversarial loss: 0.411861\n",
      "epoch 67; iter: 0; batch classifier loss: 0.078644; batch adversarial loss: 0.493432\n",
      "epoch 68; iter: 0; batch classifier loss: 0.073281; batch adversarial loss: 0.391840\n",
      "epoch 69; iter: 0; batch classifier loss: 0.067385; batch adversarial loss: 0.397075\n",
      "epoch 70; iter: 0; batch classifier loss: 0.102196; batch adversarial loss: 0.426428\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058545; batch adversarial loss: 0.373826\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080898; batch adversarial loss: 0.442219\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076237; batch adversarial loss: 0.413533\n",
      "epoch 74; iter: 0; batch classifier loss: 0.049786; batch adversarial loss: 0.411107\n",
      "epoch 75; iter: 0; batch classifier loss: 0.055429; batch adversarial loss: 0.456220\n",
      "epoch 76; iter: 0; batch classifier loss: 0.049416; batch adversarial loss: 0.388196\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076161; batch adversarial loss: 0.476142\n",
      "epoch 78; iter: 0; batch classifier loss: 0.093284; batch adversarial loss: 0.455734\n",
      "epoch 79; iter: 0; batch classifier loss: 0.077177; batch adversarial loss: 0.354253\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056217; batch adversarial loss: 0.424146\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057138; batch adversarial loss: 0.444353\n",
      "epoch 82; iter: 0; batch classifier loss: 0.058315; batch adversarial loss: 0.437644\n",
      "epoch 83; iter: 0; batch classifier loss: 0.058478; batch adversarial loss: 0.441828\n",
      "epoch 84; iter: 0; batch classifier loss: 0.081273; batch adversarial loss: 0.342950\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083252; batch adversarial loss: 0.392373\n",
      "epoch 86; iter: 0; batch classifier loss: 0.066830; batch adversarial loss: 0.457948\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055828; batch adversarial loss: 0.398704\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057529; batch adversarial loss: 0.417136\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053226; batch adversarial loss: 0.429850\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065848; batch adversarial loss: 0.497443\n",
      "epoch 91; iter: 0; batch classifier loss: 0.040070; batch adversarial loss: 0.414584\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066354; batch adversarial loss: 0.364012\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054183; batch adversarial loss: 0.444192\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043197; batch adversarial loss: 0.471354\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050968; batch adversarial loss: 0.451557\n",
      "epoch 96; iter: 0; batch classifier loss: 0.038960; batch adversarial loss: 0.392103\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057104; batch adversarial loss: 0.429279\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035357; batch adversarial loss: 0.444484\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056539; batch adversarial loss: 0.495177\n",
      "epoch 100; iter: 0; batch classifier loss: 0.095018; batch adversarial loss: 0.488699\n",
      "epoch 101; iter: 0; batch classifier loss: 0.053590; batch adversarial loss: 0.410061\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063100; batch adversarial loss: 0.431908\n",
      "epoch 103; iter: 0; batch classifier loss: 0.093106; batch adversarial loss: 0.484646\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036260; batch adversarial loss: 0.370893\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044596; batch adversarial loss: 0.394537\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035250; batch adversarial loss: 0.402936\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052165; batch adversarial loss: 0.568491\n",
      "epoch 108; iter: 0; batch classifier loss: 0.029403; batch adversarial loss: 0.472474\n",
      "epoch 109; iter: 0; batch classifier loss: 0.069856; batch adversarial loss: 0.341069\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040526; batch adversarial loss: 0.404835\n",
      "epoch 111; iter: 0; batch classifier loss: 0.024574; batch adversarial loss: 0.395205\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027741; batch adversarial loss: 0.420250\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045050; batch adversarial loss: 0.363887\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035924; batch adversarial loss: 0.434789\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033323; batch adversarial loss: 0.395620\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024546; batch adversarial loss: 0.424128\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032282; batch adversarial loss: 0.440941\n",
      "epoch 118; iter: 0; batch classifier loss: 0.034259; batch adversarial loss: 0.394708\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040716; batch adversarial loss: 0.442126\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047634; batch adversarial loss: 0.508009\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037231; batch adversarial loss: 0.405273\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042530; batch adversarial loss: 0.471108\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014786; batch adversarial loss: 0.441237\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038457; batch adversarial loss: 0.398497\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027681; batch adversarial loss: 0.373344\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019915; batch adversarial loss: 0.442775\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032851; batch adversarial loss: 0.518308\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029648; batch adversarial loss: 0.507139\n",
      "epoch 129; iter: 0; batch classifier loss: 0.094575; batch adversarial loss: 0.425841\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026277; batch adversarial loss: 0.478352\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026477; batch adversarial loss: 0.442651\n",
      "epoch 132; iter: 0; batch classifier loss: 0.049091; batch adversarial loss: 0.568844\n",
      "epoch 133; iter: 0; batch classifier loss: 0.065045; batch adversarial loss: 0.513423\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031405; batch adversarial loss: 0.489584\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037143; batch adversarial loss: 0.518533\n",
      "epoch 136; iter: 0; batch classifier loss: 0.066817; batch adversarial loss: 0.549415\n",
      "epoch 137; iter: 0; batch classifier loss: 0.076548; batch adversarial loss: 0.497198\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032116; batch adversarial loss: 0.524927\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043116; batch adversarial loss: 0.462154\n",
      "epoch 140; iter: 0; batch classifier loss: 0.067365; batch adversarial loss: 0.521034\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052505; batch adversarial loss: 0.481694\n",
      "epoch 142; iter: 0; batch classifier loss: 0.088613; batch adversarial loss: 0.651111\n",
      "epoch 143; iter: 0; batch classifier loss: 0.076137; batch adversarial loss: 0.623303\n",
      "epoch 144; iter: 0; batch classifier loss: 0.152077; batch adversarial loss: 0.626564\n",
      "epoch 145; iter: 0; batch classifier loss: 0.117143; batch adversarial loss: 0.599635\n",
      "epoch 146; iter: 0; batch classifier loss: 0.128394; batch adversarial loss: 0.682773\n",
      "epoch 147; iter: 0; batch classifier loss: 0.081471; batch adversarial loss: 0.474074\n",
      "epoch 148; iter: 0; batch classifier loss: 0.112044; batch adversarial loss: 0.482441\n",
      "epoch 149; iter: 0; batch classifier loss: 0.124455; batch adversarial loss: 0.559805\n",
      "epoch 150; iter: 0; batch classifier loss: 0.138974; batch adversarial loss: 0.569027\n",
      "epoch 151; iter: 0; batch classifier loss: 0.100055; batch adversarial loss: 0.484480\n",
      "epoch 152; iter: 0; batch classifier loss: 0.120894; batch adversarial loss: 0.545653\n",
      "epoch 153; iter: 0; batch classifier loss: 0.124835; batch adversarial loss: 0.549203\n",
      "epoch 154; iter: 0; batch classifier loss: 0.189992; batch adversarial loss: 0.821173\n",
      "epoch 155; iter: 0; batch classifier loss: 0.079646; batch adversarial loss: 0.505026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.107939; batch adversarial loss: 0.570488\n",
      "epoch 157; iter: 0; batch classifier loss: 0.087487; batch adversarial loss: 0.407825\n",
      "epoch 158; iter: 0; batch classifier loss: 0.063517; batch adversarial loss: 0.502761\n",
      "epoch 159; iter: 0; batch classifier loss: 0.105603; batch adversarial loss: 0.444929\n",
      "epoch 160; iter: 0; batch classifier loss: 0.101992; batch adversarial loss: 0.527501\n",
      "epoch 161; iter: 0; batch classifier loss: 0.058903; batch adversarial loss: 0.406132\n",
      "epoch 162; iter: 0; batch classifier loss: 0.122875; batch adversarial loss: 0.569935\n",
      "epoch 163; iter: 0; batch classifier loss: 0.131836; batch adversarial loss: 0.642845\n",
      "epoch 164; iter: 0; batch classifier loss: 0.119905; batch adversarial loss: 0.541078\n",
      "epoch 165; iter: 0; batch classifier loss: 0.157040; batch adversarial loss: 0.638509\n",
      "epoch 166; iter: 0; batch classifier loss: 0.172882; batch adversarial loss: 0.607540\n",
      "epoch 167; iter: 0; batch classifier loss: 0.121479; batch adversarial loss: 0.552264\n",
      "epoch 168; iter: 0; batch classifier loss: 0.091960; batch adversarial loss: 0.429249\n",
      "epoch 169; iter: 0; batch classifier loss: 0.080468; batch adversarial loss: 0.522737\n",
      "epoch 170; iter: 0; batch classifier loss: 0.114703; batch adversarial loss: 0.555402\n",
      "epoch 171; iter: 0; batch classifier loss: 0.124513; batch adversarial loss: 0.460604\n",
      "epoch 172; iter: 0; batch classifier loss: 0.151267; batch adversarial loss: 0.509796\n",
      "epoch 173; iter: 0; batch classifier loss: 0.116331; batch adversarial loss: 0.430491\n",
      "epoch 174; iter: 0; batch classifier loss: 0.161707; batch adversarial loss: 0.541789\n",
      "epoch 175; iter: 0; batch classifier loss: 0.118501; batch adversarial loss: 0.529178\n",
      "epoch 176; iter: 0; batch classifier loss: 0.088721; batch adversarial loss: 0.465614\n",
      "epoch 177; iter: 0; batch classifier loss: 0.095922; batch adversarial loss: 0.534592\n",
      "epoch 178; iter: 0; batch classifier loss: 0.176921; batch adversarial loss: 0.577662\n",
      "epoch 179; iter: 0; batch classifier loss: 0.057072; batch adversarial loss: 0.385969\n",
      "epoch 180; iter: 0; batch classifier loss: 0.096223; batch adversarial loss: 0.376811\n",
      "epoch 181; iter: 0; batch classifier loss: 0.071433; batch adversarial loss: 0.410564\n",
      "epoch 182; iter: 0; batch classifier loss: 0.119788; batch adversarial loss: 0.489871\n",
      "epoch 183; iter: 0; batch classifier loss: 0.088678; batch adversarial loss: 0.461048\n",
      "epoch 184; iter: 0; batch classifier loss: 0.122859; batch adversarial loss: 0.594135\n",
      "epoch 185; iter: 0; batch classifier loss: 0.092278; batch adversarial loss: 0.429392\n",
      "epoch 186; iter: 0; batch classifier loss: 0.084540; batch adversarial loss: 0.451442\n",
      "epoch 187; iter: 0; batch classifier loss: 0.070282; batch adversarial loss: 0.424981\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041670; batch adversarial loss: 0.348787\n",
      "epoch 189; iter: 0; batch classifier loss: 0.085415; batch adversarial loss: 0.544048\n",
      "epoch 190; iter: 0; batch classifier loss: 0.051248; batch adversarial loss: 0.519692\n",
      "epoch 191; iter: 0; batch classifier loss: 0.054425; batch adversarial loss: 0.483299\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025342; batch adversarial loss: 0.519113\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024563; batch adversarial loss: 0.392441\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026068; batch adversarial loss: 0.431855\n",
      "epoch 195; iter: 0; batch classifier loss: 0.033380; batch adversarial loss: 0.415653\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030996; batch adversarial loss: 0.406222\n",
      "epoch 197; iter: 0; batch classifier loss: 0.040360; batch adversarial loss: 0.431474\n",
      "epoch 198; iter: 0; batch classifier loss: 0.039462; batch adversarial loss: 0.431560\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017187; batch adversarial loss: 0.437208\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715259; batch adversarial loss: 1.034561\n",
      "epoch 1; iter: 0; batch classifier loss: 0.728068; batch adversarial loss: 1.139847\n",
      "epoch 2; iter: 0; batch classifier loss: 1.113055; batch adversarial loss: 1.243979\n",
      "epoch 3; iter: 0; batch classifier loss: 1.009236; batch adversarial loss: 1.063615\n",
      "epoch 4; iter: 0; batch classifier loss: 1.228662; batch adversarial loss: 1.019347\n",
      "epoch 5; iter: 0; batch classifier loss: 0.974816; batch adversarial loss: 0.871563\n",
      "epoch 6; iter: 0; batch classifier loss: 1.095935; batch adversarial loss: 0.842942\n",
      "epoch 7; iter: 0; batch classifier loss: 0.832318; batch adversarial loss: 0.735810\n",
      "epoch 8; iter: 0; batch classifier loss: 0.869178; batch adversarial loss: 0.678063\n",
      "epoch 9; iter: 0; batch classifier loss: 0.713100; batch adversarial loss: 0.644848\n",
      "epoch 10; iter: 0; batch classifier loss: 0.690302; batch adversarial loss: 0.606387\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533560; batch adversarial loss: 0.552056\n",
      "epoch 12; iter: 0; batch classifier loss: 0.453667; batch adversarial loss: 0.538062\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340332; batch adversarial loss: 0.536947\n",
      "epoch 14; iter: 0; batch classifier loss: 0.309497; batch adversarial loss: 0.554024\n",
      "epoch 15; iter: 0; batch classifier loss: 0.296756; batch adversarial loss: 0.562065\n",
      "epoch 16; iter: 0; batch classifier loss: 0.299023; batch adversarial loss: 0.535152\n",
      "epoch 17; iter: 0; batch classifier loss: 0.306325; batch adversarial loss: 0.492627\n",
      "epoch 18; iter: 0; batch classifier loss: 0.261214; batch adversarial loss: 0.490788\n",
      "epoch 19; iter: 0; batch classifier loss: 0.207269; batch adversarial loss: 0.464499\n",
      "epoch 20; iter: 0; batch classifier loss: 0.257418; batch adversarial loss: 0.519002\n",
      "epoch 21; iter: 0; batch classifier loss: 0.211254; batch adversarial loss: 0.500737\n",
      "epoch 22; iter: 0; batch classifier loss: 0.215159; batch adversarial loss: 0.483832\n",
      "epoch 23; iter: 0; batch classifier loss: 0.210496; batch adversarial loss: 0.494424\n",
      "epoch 24; iter: 0; batch classifier loss: 0.201290; batch adversarial loss: 0.519915\n",
      "epoch 25; iter: 0; batch classifier loss: 0.223522; batch adversarial loss: 0.459003\n",
      "epoch 26; iter: 0; batch classifier loss: 0.209375; batch adversarial loss: 0.457174\n",
      "epoch 27; iter: 0; batch classifier loss: 0.164203; batch adversarial loss: 0.490101\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184480; batch adversarial loss: 0.560484\n",
      "epoch 29; iter: 0; batch classifier loss: 0.142951; batch adversarial loss: 0.365312\n",
      "epoch 30; iter: 0; batch classifier loss: 0.134007; batch adversarial loss: 0.368670\n",
      "epoch 31; iter: 0; batch classifier loss: 0.175051; batch adversarial loss: 0.447304\n",
      "epoch 32; iter: 0; batch classifier loss: 0.150856; batch adversarial loss: 0.463719\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143113; batch adversarial loss: 0.507687\n",
      "epoch 34; iter: 0; batch classifier loss: 0.170127; batch adversarial loss: 0.506754\n",
      "epoch 35; iter: 0; batch classifier loss: 0.165798; batch adversarial loss: 0.454400\n",
      "epoch 36; iter: 0; batch classifier loss: 0.138546; batch adversarial loss: 0.509786\n",
      "epoch 37; iter: 0; batch classifier loss: 0.122663; batch adversarial loss: 0.478640\n",
      "epoch 38; iter: 0; batch classifier loss: 0.123574; batch adversarial loss: 0.445058\n",
      "epoch 39; iter: 0; batch classifier loss: 0.117594; batch adversarial loss: 0.383038\n",
      "epoch 40; iter: 0; batch classifier loss: 0.121960; batch adversarial loss: 0.464259\n",
      "epoch 41; iter: 0; batch classifier loss: 0.088304; batch adversarial loss: 0.423677\n",
      "epoch 42; iter: 0; batch classifier loss: 0.097553; batch adversarial loss: 0.541747\n",
      "epoch 43; iter: 0; batch classifier loss: 0.094141; batch adversarial loss: 0.436002\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098955; batch adversarial loss: 0.504971\n",
      "epoch 45; iter: 0; batch classifier loss: 0.090245; batch adversarial loss: 0.556261\n",
      "epoch 46; iter: 0; batch classifier loss: 0.100873; batch adversarial loss: 0.498878\n",
      "epoch 47; iter: 0; batch classifier loss: 0.092277; batch adversarial loss: 0.479265\n",
      "epoch 48; iter: 0; batch classifier loss: 0.097900; batch adversarial loss: 0.483403\n",
      "epoch 49; iter: 0; batch classifier loss: 0.121370; batch adversarial loss: 0.520113\n",
      "epoch 50; iter: 0; batch classifier loss: 0.127904; batch adversarial loss: 0.424854\n",
      "epoch 51; iter: 0; batch classifier loss: 0.143273; batch adversarial loss: 0.501560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.099594; batch adversarial loss: 0.361600\n",
      "epoch 53; iter: 0; batch classifier loss: 0.083183; batch adversarial loss: 0.409612\n",
      "epoch 54; iter: 0; batch classifier loss: 0.064177; batch adversarial loss: 0.515483\n",
      "epoch 55; iter: 0; batch classifier loss: 0.075009; batch adversarial loss: 0.491668\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082727; batch adversarial loss: 0.491345\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073992; batch adversarial loss: 0.466990\n",
      "epoch 58; iter: 0; batch classifier loss: 0.094692; batch adversarial loss: 0.392726\n",
      "epoch 59; iter: 0; batch classifier loss: 0.074738; batch adversarial loss: 0.514018\n",
      "epoch 60; iter: 0; batch classifier loss: 0.123208; batch adversarial loss: 0.499103\n",
      "epoch 61; iter: 0; batch classifier loss: 0.079328; batch adversarial loss: 0.420323\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085703; batch adversarial loss: 0.428171\n",
      "epoch 63; iter: 0; batch classifier loss: 0.069456; batch adversarial loss: 0.488271\n",
      "epoch 64; iter: 0; batch classifier loss: 0.077910; batch adversarial loss: 0.400866\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065233; batch adversarial loss: 0.467496\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073855; batch adversarial loss: 0.467947\n",
      "epoch 67; iter: 0; batch classifier loss: 0.051194; batch adversarial loss: 0.434209\n",
      "epoch 68; iter: 0; batch classifier loss: 0.056333; batch adversarial loss: 0.519385\n",
      "epoch 69; iter: 0; batch classifier loss: 0.115974; batch adversarial loss: 0.470477\n",
      "epoch 70; iter: 0; batch classifier loss: 0.044740; batch adversarial loss: 0.375892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.061897; batch adversarial loss: 0.489667\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072180; batch adversarial loss: 0.473960\n",
      "epoch 73; iter: 0; batch classifier loss: 0.098391; batch adversarial loss: 0.486065\n",
      "epoch 74; iter: 0; batch classifier loss: 0.042810; batch adversarial loss: 0.495378\n",
      "epoch 75; iter: 0; batch classifier loss: 0.088393; batch adversarial loss: 0.359060\n",
      "epoch 76; iter: 0; batch classifier loss: 0.041933; batch adversarial loss: 0.436387\n",
      "epoch 77; iter: 0; batch classifier loss: 0.070725; batch adversarial loss: 0.503352\n",
      "epoch 78; iter: 0; batch classifier loss: 0.063561; batch adversarial loss: 0.502786\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080161; batch adversarial loss: 0.527622\n",
      "epoch 80; iter: 0; batch classifier loss: 0.040516; batch adversarial loss: 0.408388\n",
      "epoch 81; iter: 0; batch classifier loss: 0.046836; batch adversarial loss: 0.429445\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065435; batch adversarial loss: 0.481108\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056040; batch adversarial loss: 0.407615\n",
      "epoch 84; iter: 0; batch classifier loss: 0.039560; batch adversarial loss: 0.528343\n",
      "epoch 85; iter: 0; batch classifier loss: 0.042836; batch adversarial loss: 0.394257\n",
      "epoch 86; iter: 0; batch classifier loss: 0.034768; batch adversarial loss: 0.524631\n",
      "epoch 87; iter: 0; batch classifier loss: 0.086493; batch adversarial loss: 0.424522\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059760; batch adversarial loss: 0.488530\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042055; batch adversarial loss: 0.442192\n",
      "epoch 90; iter: 0; batch classifier loss: 0.049076; batch adversarial loss: 0.422346\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043741; batch adversarial loss: 0.375334\n",
      "epoch 92; iter: 0; batch classifier loss: 0.020572; batch adversarial loss: 0.445117\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051911; batch adversarial loss: 0.478025\n",
      "epoch 94; iter: 0; batch classifier loss: 0.082905; batch adversarial loss: 0.434356\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048649; batch adversarial loss: 0.488663\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047504; batch adversarial loss: 0.458875\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065623; batch adversarial loss: 0.445691\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054148; batch adversarial loss: 0.412410\n",
      "epoch 99; iter: 0; batch classifier loss: 0.088189; batch adversarial loss: 0.370590\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045220; batch adversarial loss: 0.574163\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054011; batch adversarial loss: 0.362457\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053767; batch adversarial loss: 0.472183\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045363; batch adversarial loss: 0.519944\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058542; batch adversarial loss: 0.374683\n",
      "epoch 105; iter: 0; batch classifier loss: 0.023609; batch adversarial loss: 0.454234\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050235; batch adversarial loss: 0.431113\n",
      "epoch 107; iter: 0; batch classifier loss: 0.043575; batch adversarial loss: 0.492807\n",
      "epoch 108; iter: 0; batch classifier loss: 0.026876; batch adversarial loss: 0.496936\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042705; batch adversarial loss: 0.371425\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035370; batch adversarial loss: 0.461623\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050796; batch adversarial loss: 0.394158\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038542; batch adversarial loss: 0.498939\n",
      "epoch 113; iter: 0; batch classifier loss: 0.026559; batch adversarial loss: 0.524397\n",
      "epoch 114; iter: 0; batch classifier loss: 0.031202; batch adversarial loss: 0.467665\n",
      "epoch 115; iter: 0; batch classifier loss: 0.013373; batch adversarial loss: 0.401450\n",
      "epoch 116; iter: 0; batch classifier loss: 0.086491; batch adversarial loss: 0.451729\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045898; batch adversarial loss: 0.495079\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052153; batch adversarial loss: 0.405451\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026735; batch adversarial loss: 0.391658\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046725; batch adversarial loss: 0.408916\n",
      "epoch 121; iter: 0; batch classifier loss: 0.081837; batch adversarial loss: 0.374305\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030925; batch adversarial loss: 0.415058\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026056; batch adversarial loss: 0.479944\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027177; batch adversarial loss: 0.449784\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034137; batch adversarial loss: 0.538857\n",
      "epoch 126; iter: 0; batch classifier loss: 0.016705; batch adversarial loss: 0.470082\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023550; batch adversarial loss: 0.488007\n",
      "epoch 128; iter: 0; batch classifier loss: 0.013709; batch adversarial loss: 0.423367\n",
      "epoch 129; iter: 0; batch classifier loss: 0.055508; batch adversarial loss: 0.479018\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056628; batch adversarial loss: 0.451061\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039791; batch adversarial loss: 0.325096\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044287; batch adversarial loss: 0.410731\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015057; batch adversarial loss: 0.525959\n",
      "epoch 134; iter: 0; batch classifier loss: 0.068762; batch adversarial loss: 0.365859\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025180; batch adversarial loss: 0.503628\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049362; batch adversarial loss: 0.461283\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038708; batch adversarial loss: 0.475943\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046343; batch adversarial loss: 0.479204\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016051; batch adversarial loss: 0.393246\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013732; batch adversarial loss: 0.473729\n",
      "epoch 141; iter: 0; batch classifier loss: 0.014830; batch adversarial loss: 0.554720\n",
      "epoch 142; iter: 0; batch classifier loss: 0.012238; batch adversarial loss: 0.535712\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022641; batch adversarial loss: 0.468997\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016341; batch adversarial loss: 0.405298\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023453; batch adversarial loss: 0.444769\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020491; batch adversarial loss: 0.455068\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026262; batch adversarial loss: 0.515434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.028073; batch adversarial loss: 0.430875\n",
      "epoch 149; iter: 0; batch classifier loss: 0.064584; batch adversarial loss: 0.418949\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028958; batch adversarial loss: 0.493816\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013085; batch adversarial loss: 0.484448\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031679; batch adversarial loss: 0.548664\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022330; batch adversarial loss: 0.511891\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024407; batch adversarial loss: 0.472524\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031227; batch adversarial loss: 0.530843\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011466; batch adversarial loss: 0.401846\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009193; batch adversarial loss: 0.515573\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033730; batch adversarial loss: 0.409634\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012859; batch adversarial loss: 0.385257\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022665; batch adversarial loss: 0.453160\n",
      "epoch 161; iter: 0; batch classifier loss: 0.054565; batch adversarial loss: 0.431788\n",
      "epoch 162; iter: 0; batch classifier loss: 0.003526; batch adversarial loss: 0.459228\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033324; batch adversarial loss: 0.389185\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020177; batch adversarial loss: 0.423911\n",
      "epoch 165; iter: 0; batch classifier loss: 0.039785; batch adversarial loss: 0.435900\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034729; batch adversarial loss: 0.388048\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026276; batch adversarial loss: 0.400539\n",
      "epoch 168; iter: 0; batch classifier loss: 0.050624; batch adversarial loss: 0.504806\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011971; batch adversarial loss: 0.457294\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032388; batch adversarial loss: 0.459885\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038806; batch adversarial loss: 0.447289\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032440; batch adversarial loss: 0.494779\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008467; batch adversarial loss: 0.423730\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018000; batch adversarial loss: 0.404311\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032876; batch adversarial loss: 0.508561\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032841; batch adversarial loss: 0.439763\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012773; batch adversarial loss: 0.473491\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009684; batch adversarial loss: 0.438413\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037203; batch adversarial loss: 0.479531\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017718; batch adversarial loss: 0.475078\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008101; batch adversarial loss: 0.442972\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014163; batch adversarial loss: 0.425248\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027244; batch adversarial loss: 0.441289\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020366; batch adversarial loss: 0.414693\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009146; batch adversarial loss: 0.434522\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013343; batch adversarial loss: 0.514798\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009249; batch adversarial loss: 0.552166\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020387; batch adversarial loss: 0.486776\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021905; batch adversarial loss: 0.529795\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005020; batch adversarial loss: 0.451243\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015771; batch adversarial loss: 0.386648\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013134; batch adversarial loss: 0.486766\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012347; batch adversarial loss: 0.526940\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016255; batch adversarial loss: 0.420850\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021170; batch adversarial loss: 0.380584\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008205; batch adversarial loss: 0.581972\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031522; batch adversarial loss: 0.348310\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002971; batch adversarial loss: 0.482937\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012989; batch adversarial loss: 0.399721\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713428; batch adversarial loss: 0.721215\n",
      "epoch 1; iter: 0; batch classifier loss: 0.490884; batch adversarial loss: 0.662196\n",
      "epoch 2; iter: 0; batch classifier loss: 0.391307; batch adversarial loss: 0.630861\n",
      "epoch 3; iter: 0; batch classifier loss: 0.402984; batch adversarial loss: 0.591708\n",
      "epoch 4; iter: 0; batch classifier loss: 0.420829; batch adversarial loss: 0.574192\n",
      "epoch 5; iter: 0; batch classifier loss: 0.402833; batch adversarial loss: 0.579754\n",
      "epoch 6; iter: 0; batch classifier loss: 0.334219; batch adversarial loss: 0.542566\n",
      "epoch 7; iter: 0; batch classifier loss: 0.401161; batch adversarial loss: 0.560489\n",
      "epoch 8; iter: 0; batch classifier loss: 0.289753; batch adversarial loss: 0.580767\n",
      "epoch 9; iter: 0; batch classifier loss: 0.344333; batch adversarial loss: 0.525130\n",
      "epoch 10; iter: 0; batch classifier loss: 0.319692; batch adversarial loss: 0.482378\n",
      "epoch 11; iter: 0; batch classifier loss: 0.378510; batch adversarial loss: 0.540149\n",
      "epoch 12; iter: 0; batch classifier loss: 0.332719; batch adversarial loss: 0.510675\n",
      "epoch 13; iter: 0; batch classifier loss: 0.332922; batch adversarial loss: 0.485444\n",
      "epoch 14; iter: 0; batch classifier loss: 0.300034; batch adversarial loss: 0.530295\n",
      "epoch 15; iter: 0; batch classifier loss: 0.259545; batch adversarial loss: 0.552729\n",
      "epoch 16; iter: 0; batch classifier loss: 0.287448; batch adversarial loss: 0.530430\n",
      "epoch 17; iter: 0; batch classifier loss: 0.331016; batch adversarial loss: 0.469854\n",
      "epoch 18; iter: 0; batch classifier loss: 0.255709; batch adversarial loss: 0.543999\n",
      "epoch 19; iter: 0; batch classifier loss: 0.269547; batch adversarial loss: 0.494048\n",
      "epoch 20; iter: 0; batch classifier loss: 0.218360; batch adversarial loss: 0.488696\n",
      "epoch 21; iter: 0; batch classifier loss: 0.220150; batch adversarial loss: 0.492655\n",
      "epoch 22; iter: 0; batch classifier loss: 0.254903; batch adversarial loss: 0.553747\n",
      "epoch 23; iter: 0; batch classifier loss: 0.208440; batch adversarial loss: 0.567658\n",
      "epoch 24; iter: 0; batch classifier loss: 0.250447; batch adversarial loss: 0.478661\n",
      "epoch 25; iter: 0; batch classifier loss: 0.241501; batch adversarial loss: 0.566453\n",
      "epoch 26; iter: 0; batch classifier loss: 0.202940; batch adversarial loss: 0.445049\n",
      "epoch 27; iter: 0; batch classifier loss: 0.180014; batch adversarial loss: 0.367338\n",
      "epoch 28; iter: 0; batch classifier loss: 0.252701; batch adversarial loss: 0.514520\n",
      "epoch 29; iter: 0; batch classifier loss: 0.225259; batch adversarial loss: 0.557873\n",
      "epoch 30; iter: 0; batch classifier loss: 0.222844; batch adversarial loss: 0.487418\n",
      "epoch 31; iter: 0; batch classifier loss: 0.216999; batch adversarial loss: 0.378456\n",
      "epoch 32; iter: 0; batch classifier loss: 0.168383; batch adversarial loss: 0.513982\n",
      "epoch 33; iter: 0; batch classifier loss: 0.172996; batch adversarial loss: 0.386207\n",
      "epoch 34; iter: 0; batch classifier loss: 0.192184; batch adversarial loss: 0.420154\n",
      "epoch 35; iter: 0; batch classifier loss: 0.117016; batch adversarial loss: 0.435042\n",
      "epoch 36; iter: 0; batch classifier loss: 0.186708; batch adversarial loss: 0.524525\n",
      "epoch 37; iter: 0; batch classifier loss: 0.143935; batch adversarial loss: 0.489973\n",
      "epoch 38; iter: 0; batch classifier loss: 0.164012; batch adversarial loss: 0.470663\n",
      "epoch 39; iter: 0; batch classifier loss: 0.158364; batch adversarial loss: 0.544034\n",
      "epoch 40; iter: 0; batch classifier loss: 0.166988; batch adversarial loss: 0.468220\n",
      "epoch 41; iter: 0; batch classifier loss: 0.173770; batch adversarial loss: 0.374787\n",
      "epoch 42; iter: 0; batch classifier loss: 0.155911; batch adversarial loss: 0.478487\n",
      "epoch 43; iter: 0; batch classifier loss: 0.108542; batch adversarial loss: 0.473031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.101530; batch adversarial loss: 0.516170\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102861; batch adversarial loss: 0.500567\n",
      "epoch 46; iter: 0; batch classifier loss: 0.141017; batch adversarial loss: 0.437863\n",
      "epoch 47; iter: 0; batch classifier loss: 0.081892; batch adversarial loss: 0.436614\n",
      "epoch 48; iter: 0; batch classifier loss: 0.143874; batch adversarial loss: 0.447750\n",
      "epoch 49; iter: 0; batch classifier loss: 0.141728; batch adversarial loss: 0.384290\n",
      "epoch 50; iter: 0; batch classifier loss: 0.128291; batch adversarial loss: 0.512115\n",
      "epoch 51; iter: 0; batch classifier loss: 0.125979; batch adversarial loss: 0.420010\n",
      "epoch 52; iter: 0; batch classifier loss: 0.166054; batch adversarial loss: 0.347233\n",
      "epoch 53; iter: 0; batch classifier loss: 0.091841; batch adversarial loss: 0.461066\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095014; batch adversarial loss: 0.381921\n",
      "epoch 55; iter: 0; batch classifier loss: 0.126619; batch adversarial loss: 0.496064\n",
      "epoch 56; iter: 0; batch classifier loss: 0.120881; batch adversarial loss: 0.444967\n",
      "epoch 57; iter: 0; batch classifier loss: 0.137600; batch adversarial loss: 0.413494\n",
      "epoch 58; iter: 0; batch classifier loss: 0.093592; batch adversarial loss: 0.510775\n",
      "epoch 59; iter: 0; batch classifier loss: 0.074961; batch adversarial loss: 0.450148\n",
      "epoch 60; iter: 0; batch classifier loss: 0.066399; batch adversarial loss: 0.437552\n",
      "epoch 61; iter: 0; batch classifier loss: 0.091996; batch adversarial loss: 0.483748\n",
      "epoch 62; iter: 0; batch classifier loss: 0.083327; batch adversarial loss: 0.520863\n",
      "epoch 63; iter: 0; batch classifier loss: 0.094498; batch adversarial loss: 0.524350\n",
      "epoch 64; iter: 0; batch classifier loss: 0.099727; batch adversarial loss: 0.441644\n",
      "epoch 65; iter: 0; batch classifier loss: 0.085999; batch adversarial loss: 0.426605\n",
      "epoch 66; iter: 0; batch classifier loss: 0.058265; batch adversarial loss: 0.470869\n",
      "epoch 67; iter: 0; batch classifier loss: 0.085874; batch adversarial loss: 0.424183\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060103; batch adversarial loss: 0.490281\n",
      "epoch 69; iter: 0; batch classifier loss: 0.080453; batch adversarial loss: 0.516089\n",
      "epoch 70; iter: 0; batch classifier loss: 0.060417; batch adversarial loss: 0.467863\n",
      "epoch 71; iter: 0; batch classifier loss: 0.076729; batch adversarial loss: 0.402477\n",
      "epoch 72; iter: 0; batch classifier loss: 0.073327; batch adversarial loss: 0.518923\n",
      "epoch 73; iter: 0; batch classifier loss: 0.063438; batch adversarial loss: 0.515429\n",
      "epoch 74; iter: 0; batch classifier loss: 0.060189; batch adversarial loss: 0.367090\n",
      "epoch 75; iter: 0; batch classifier loss: 0.037074; batch adversarial loss: 0.407926\n",
      "epoch 76; iter: 0; batch classifier loss: 0.047284; batch adversarial loss: 0.473375\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045029; batch adversarial loss: 0.425570\n",
      "epoch 78; iter: 0; batch classifier loss: 0.087056; batch adversarial loss: 0.489463\n",
      "epoch 79; iter: 0; batch classifier loss: 0.046009; batch adversarial loss: 0.545786\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067195; batch adversarial loss: 0.407175\n",
      "epoch 81; iter: 0; batch classifier loss: 0.092876; batch adversarial loss: 0.404026\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067778; batch adversarial loss: 0.486781\n",
      "epoch 83; iter: 0; batch classifier loss: 0.038898; batch adversarial loss: 0.458183\n",
      "epoch 84; iter: 0; batch classifier loss: 0.025361; batch adversarial loss: 0.466943\n",
      "epoch 85; iter: 0; batch classifier loss: 0.040933; batch adversarial loss: 0.451935\n",
      "epoch 86; iter: 0; batch classifier loss: 0.043938; batch adversarial loss: 0.450821\n",
      "epoch 87; iter: 0; batch classifier loss: 0.069710; batch adversarial loss: 0.530984\n",
      "epoch 88; iter: 0; batch classifier loss: 0.036042; batch adversarial loss: 0.439771\n",
      "epoch 89; iter: 0; batch classifier loss: 0.044179; batch adversarial loss: 0.561174\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048241; batch adversarial loss: 0.438516\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052605; batch adversarial loss: 0.372391\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065870; batch adversarial loss: 0.462013\n",
      "epoch 93; iter: 0; batch classifier loss: 0.031034; batch adversarial loss: 0.338144\n",
      "epoch 94; iter: 0; batch classifier loss: 0.076277; batch adversarial loss: 0.418210\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077772; batch adversarial loss: 0.441096\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049280; batch adversarial loss: 0.470179\n",
      "epoch 97; iter: 0; batch classifier loss: 0.038164; batch adversarial loss: 0.508625\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036825; batch adversarial loss: 0.494735\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050769; batch adversarial loss: 0.470691\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050637; batch adversarial loss: 0.466941\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041233; batch adversarial loss: 0.523313\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032264; batch adversarial loss: 0.439836\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052246; batch adversarial loss: 0.410016\n",
      "epoch 104; iter: 0; batch classifier loss: 0.055676; batch adversarial loss: 0.348857\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053317; batch adversarial loss: 0.405318\n",
      "epoch 106; iter: 0; batch classifier loss: 0.028886; batch adversarial loss: 0.470613\n",
      "epoch 107; iter: 0; batch classifier loss: 0.029958; batch adversarial loss: 0.460298\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033267; batch adversarial loss: 0.365220\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033707; batch adversarial loss: 0.409717\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036611; batch adversarial loss: 0.397551\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041976; batch adversarial loss: 0.604340\n",
      "epoch 112; iter: 0; batch classifier loss: 0.028560; batch adversarial loss: 0.561677\n",
      "epoch 113; iter: 0; batch classifier loss: 0.036544; batch adversarial loss: 0.498015\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034235; batch adversarial loss: 0.402183\n",
      "epoch 115; iter: 0; batch classifier loss: 0.013859; batch adversarial loss: 0.381501\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051856; batch adversarial loss: 0.456774\n",
      "epoch 117; iter: 0; batch classifier loss: 0.017102; batch adversarial loss: 0.523625\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032322; batch adversarial loss: 0.392002\n",
      "epoch 119; iter: 0; batch classifier loss: 0.064761; batch adversarial loss: 0.402160\n",
      "epoch 120; iter: 0; batch classifier loss: 0.019271; batch adversarial loss: 0.495923\n",
      "epoch 121; iter: 0; batch classifier loss: 0.016186; batch adversarial loss: 0.398884\n",
      "epoch 122; iter: 0; batch classifier loss: 0.019988; batch adversarial loss: 0.461953\n",
      "epoch 123; iter: 0; batch classifier loss: 0.065084; batch adversarial loss: 0.399135\n",
      "epoch 124; iter: 0; batch classifier loss: 0.009057; batch adversarial loss: 0.425036\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020855; batch adversarial loss: 0.425289\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023430; batch adversarial loss: 0.409640\n",
      "epoch 127; iter: 0; batch classifier loss: 0.017039; batch adversarial loss: 0.442054\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056180; batch adversarial loss: 0.454998\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023443; batch adversarial loss: 0.454596\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045911; batch adversarial loss: 0.472278\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027325; batch adversarial loss: 0.407232\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040884; batch adversarial loss: 0.428494\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019976; batch adversarial loss: 0.431319\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021137; batch adversarial loss: 0.497800\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035842; batch adversarial loss: 0.464284\n",
      "epoch 136; iter: 0; batch classifier loss: 0.010995; batch adversarial loss: 0.523206\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036759; batch adversarial loss: 0.504975\n",
      "epoch 138; iter: 0; batch classifier loss: 0.007196; batch adversarial loss: 0.441070\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038168; batch adversarial loss: 0.453740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.008217; batch adversarial loss: 0.442953\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040171; batch adversarial loss: 0.430128\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019978; batch adversarial loss: 0.437713\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029874; batch adversarial loss: 0.376679\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033154; batch adversarial loss: 0.433814\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033577; batch adversarial loss: 0.516977\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030975; batch adversarial loss: 0.442309\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025520; batch adversarial loss: 0.483843\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033968; batch adversarial loss: 0.481996\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027731; batch adversarial loss: 0.481664\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011389; batch adversarial loss: 0.465963\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021719; batch adversarial loss: 0.491615\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008046; batch adversarial loss: 0.382301\n",
      "epoch 153; iter: 0; batch classifier loss: 0.005119; batch adversarial loss: 0.513420\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012100; batch adversarial loss: 0.450115\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015211; batch adversarial loss: 0.442236\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029842; batch adversarial loss: 0.379437\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009502; batch adversarial loss: 0.443283\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018133; batch adversarial loss: 0.526801\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018254; batch adversarial loss: 0.442201\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010536; batch adversarial loss: 0.559215\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029585; batch adversarial loss: 0.394635\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031724; batch adversarial loss: 0.468170\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019107; batch adversarial loss: 0.541186\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019429; batch adversarial loss: 0.471850\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035103; batch adversarial loss: 0.496684\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030480; batch adversarial loss: 0.539943\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009953; batch adversarial loss: 0.399343\n",
      "epoch 168; iter: 0; batch classifier loss: 0.006696; batch adversarial loss: 0.365864\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015773; batch adversarial loss: 0.470721\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011235; batch adversarial loss: 0.600979\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025369; batch adversarial loss: 0.420918\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019510; batch adversarial loss: 0.472386\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017135; batch adversarial loss: 0.451600\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017073; batch adversarial loss: 0.553579\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013874; batch adversarial loss: 0.541457\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012837; batch adversarial loss: 0.386262\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018347; batch adversarial loss: 0.405041\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018870; batch adversarial loss: 0.504848\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034953; batch adversarial loss: 0.423424\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011023; batch adversarial loss: 0.493705\n",
      "epoch 181; iter: 0; batch classifier loss: 0.055024; batch adversarial loss: 0.428836\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038837; batch adversarial loss: 0.477567\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024518; batch adversarial loss: 0.513910\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019653; batch adversarial loss: 0.448002\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021998; batch adversarial loss: 0.483099\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010789; batch adversarial loss: 0.395655\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024264; batch adversarial loss: 0.469757\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041606; batch adversarial loss: 0.402562\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023664; batch adversarial loss: 0.658122\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023927; batch adversarial loss: 0.516293\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013844; batch adversarial loss: 0.473563\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004165; batch adversarial loss: 0.462967\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011479; batch adversarial loss: 0.421981\n",
      "epoch 194; iter: 0; batch classifier loss: 0.069189; batch adversarial loss: 0.491172\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024080; batch adversarial loss: 0.427937\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007899; batch adversarial loss: 0.392602\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033253; batch adversarial loss: 0.415041\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008147; batch adversarial loss: 0.382469\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008083; batch adversarial loss: 0.484388\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696710; batch adversarial loss: 0.822919\n",
      "epoch 1; iter: 0; batch classifier loss: 0.573799; batch adversarial loss: 0.799043\n",
      "epoch 2; iter: 0; batch classifier loss: 0.744700; batch adversarial loss: 0.790473\n",
      "epoch 3; iter: 0; batch classifier loss: 0.804387; batch adversarial loss: 0.724887\n",
      "epoch 4; iter: 0; batch classifier loss: 0.678540; batch adversarial loss: 0.680813\n",
      "epoch 5; iter: 0; batch classifier loss: 0.524342; batch adversarial loss: 0.616740\n",
      "epoch 6; iter: 0; batch classifier loss: 0.404659; batch adversarial loss: 0.556087\n",
      "epoch 7; iter: 0; batch classifier loss: 0.392402; batch adversarial loss: 0.563272\n",
      "epoch 8; iter: 0; batch classifier loss: 0.306203; batch adversarial loss: 0.530407\n",
      "epoch 9; iter: 0; batch classifier loss: 0.374683; batch adversarial loss: 0.525979\n",
      "epoch 10; iter: 0; batch classifier loss: 0.348157; batch adversarial loss: 0.555343\n",
      "epoch 11; iter: 0; batch classifier loss: 0.295224; batch adversarial loss: 0.527483\n",
      "epoch 12; iter: 0; batch classifier loss: 0.292799; batch adversarial loss: 0.511947\n",
      "epoch 13; iter: 0; batch classifier loss: 0.288389; batch adversarial loss: 0.516359\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236161; batch adversarial loss: 0.569657\n",
      "epoch 15; iter: 0; batch classifier loss: 0.248290; batch adversarial loss: 0.525393\n",
      "epoch 16; iter: 0; batch classifier loss: 0.280905; batch adversarial loss: 0.506991\n",
      "epoch 17; iter: 0; batch classifier loss: 0.268218; batch adversarial loss: 0.467716\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214228; batch adversarial loss: 0.500054\n",
      "epoch 19; iter: 0; batch classifier loss: 0.238885; batch adversarial loss: 0.531741\n",
      "epoch 20; iter: 0; batch classifier loss: 0.195359; batch adversarial loss: 0.433109\n",
      "epoch 21; iter: 0; batch classifier loss: 0.265723; batch adversarial loss: 0.476741\n",
      "epoch 22; iter: 0; batch classifier loss: 0.225014; batch adversarial loss: 0.459315\n",
      "epoch 23; iter: 0; batch classifier loss: 0.225866; batch adversarial loss: 0.506164\n",
      "epoch 24; iter: 0; batch classifier loss: 0.169305; batch adversarial loss: 0.561355\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215933; batch adversarial loss: 0.403357\n",
      "epoch 26; iter: 0; batch classifier loss: 0.124527; batch adversarial loss: 0.476647\n",
      "epoch 27; iter: 0; batch classifier loss: 0.217791; batch adversarial loss: 0.441684\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184929; batch adversarial loss: 0.392656\n",
      "epoch 29; iter: 0; batch classifier loss: 0.291731; batch adversarial loss: 0.524972\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153794; batch adversarial loss: 0.457397\n",
      "epoch 31; iter: 0; batch classifier loss: 0.138224; batch adversarial loss: 0.377250\n",
      "epoch 32; iter: 0; batch classifier loss: 0.171114; batch adversarial loss: 0.468623\n",
      "epoch 33; iter: 0; batch classifier loss: 0.199812; batch adversarial loss: 0.467620\n",
      "epoch 34; iter: 0; batch classifier loss: 0.111549; batch adversarial loss: 0.490061\n",
      "epoch 35; iter: 0; batch classifier loss: 0.153204; batch adversarial loss: 0.485099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.087639; batch adversarial loss: 0.389511\n",
      "epoch 37; iter: 0; batch classifier loss: 0.149168; batch adversarial loss: 0.440296\n",
      "epoch 38; iter: 0; batch classifier loss: 0.128827; batch adversarial loss: 0.446598\n",
      "epoch 39; iter: 0; batch classifier loss: 0.112332; batch adversarial loss: 0.537249\n",
      "epoch 40; iter: 0; batch classifier loss: 0.159218; batch adversarial loss: 0.471801\n",
      "epoch 41; iter: 0; batch classifier loss: 0.111789; batch adversarial loss: 0.445616\n",
      "epoch 42; iter: 0; batch classifier loss: 0.113759; batch adversarial loss: 0.495198\n",
      "epoch 43; iter: 0; batch classifier loss: 0.160005; batch adversarial loss: 0.491234\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127799; batch adversarial loss: 0.490806\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104435; batch adversarial loss: 0.395586\n",
      "epoch 46; iter: 0; batch classifier loss: 0.150070; batch adversarial loss: 0.458435\n",
      "epoch 47; iter: 0; batch classifier loss: 0.067918; batch adversarial loss: 0.449757\n",
      "epoch 48; iter: 0; batch classifier loss: 0.180409; batch adversarial loss: 0.404248\n",
      "epoch 49; iter: 0; batch classifier loss: 0.115098; batch adversarial loss: 0.476381\n",
      "epoch 50; iter: 0; batch classifier loss: 0.076859; batch adversarial loss: 0.467869\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098956; batch adversarial loss: 0.558712\n",
      "epoch 52; iter: 0; batch classifier loss: 0.064289; batch adversarial loss: 0.457016\n",
      "epoch 53; iter: 0; batch classifier loss: 0.075101; batch adversarial loss: 0.440463\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103802; batch adversarial loss: 0.486132\n",
      "epoch 55; iter: 0; batch classifier loss: 0.107012; batch adversarial loss: 0.492090\n",
      "epoch 56; iter: 0; batch classifier loss: 0.097774; batch adversarial loss: 0.424855\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107625; batch adversarial loss: 0.456817\n",
      "epoch 58; iter: 0; batch classifier loss: 0.124378; batch adversarial loss: 0.434749\n",
      "epoch 59; iter: 0; batch classifier loss: 0.079896; batch adversarial loss: 0.423623\n",
      "epoch 60; iter: 0; batch classifier loss: 0.089646; batch adversarial loss: 0.452201\n",
      "epoch 61; iter: 0; batch classifier loss: 0.096053; batch adversarial loss: 0.385139\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084299; batch adversarial loss: 0.526648\n",
      "epoch 63; iter: 0; batch classifier loss: 0.059297; batch adversarial loss: 0.575462\n",
      "epoch 64; iter: 0; batch classifier loss: 0.059943; batch adversarial loss: 0.603719\n",
      "epoch 65; iter: 0; batch classifier loss: 0.083264; batch adversarial loss: 0.498759\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084328; batch adversarial loss: 0.435782\n",
      "epoch 67; iter: 0; batch classifier loss: 0.092613; batch adversarial loss: 0.425508\n",
      "epoch 68; iter: 0; batch classifier loss: 0.104387; batch adversarial loss: 0.456817\n",
      "epoch 69; iter: 0; batch classifier loss: 0.058163; batch adversarial loss: 0.431827\n",
      "epoch 70; iter: 0; batch classifier loss: 0.076059; batch adversarial loss: 0.350931\n",
      "epoch 71; iter: 0; batch classifier loss: 0.049560; batch adversarial loss: 0.498521\n",
      "epoch 72; iter: 0; batch classifier loss: 0.121030; batch adversarial loss: 0.432692\n",
      "epoch 73; iter: 0; batch classifier loss: 0.081030; batch adversarial loss: 0.373696\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079384; batch adversarial loss: 0.413109\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059563; batch adversarial loss: 0.409849\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076190; batch adversarial loss: 0.410269\n",
      "epoch 77; iter: 0; batch classifier loss: 0.041044; batch adversarial loss: 0.393538\n",
      "epoch 78; iter: 0; batch classifier loss: 0.112672; batch adversarial loss: 0.437633\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085803; batch adversarial loss: 0.346309\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084046; batch adversarial loss: 0.401832\n",
      "epoch 81; iter: 0; batch classifier loss: 0.061459; batch adversarial loss: 0.453257\n",
      "epoch 82; iter: 0; batch classifier loss: 0.044824; batch adversarial loss: 0.514319\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064165; batch adversarial loss: 0.461605\n",
      "epoch 84; iter: 0; batch classifier loss: 0.063458; batch adversarial loss: 0.450637\n",
      "epoch 85; iter: 0; batch classifier loss: 0.028185; batch adversarial loss: 0.485573\n",
      "epoch 86; iter: 0; batch classifier loss: 0.043164; batch adversarial loss: 0.508323\n",
      "epoch 87; iter: 0; batch classifier loss: 0.065253; batch adversarial loss: 0.412840\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073306; batch adversarial loss: 0.458735\n",
      "epoch 89; iter: 0; batch classifier loss: 0.039370; batch adversarial loss: 0.422492\n",
      "epoch 90; iter: 0; batch classifier loss: 0.043328; batch adversarial loss: 0.501373\n",
      "epoch 91; iter: 0; batch classifier loss: 0.108215; batch adversarial loss: 0.493516\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064930; batch adversarial loss: 0.498219\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048022; batch adversarial loss: 0.513182\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070807; batch adversarial loss: 0.438120\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068307; batch adversarial loss: 0.411954\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057912; batch adversarial loss: 0.424219\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069238; batch adversarial loss: 0.480400\n",
      "epoch 98; iter: 0; batch classifier loss: 0.033386; batch adversarial loss: 0.446191\n",
      "epoch 99; iter: 0; batch classifier loss: 0.048019; batch adversarial loss: 0.397977\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075898; batch adversarial loss: 0.373916\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051226; batch adversarial loss: 0.425319\n",
      "epoch 102; iter: 0; batch classifier loss: 0.039407; batch adversarial loss: 0.482440\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049810; batch adversarial loss: 0.445130\n",
      "epoch 104; iter: 0; batch classifier loss: 0.042729; batch adversarial loss: 0.531530\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049431; batch adversarial loss: 0.491111\n",
      "epoch 106; iter: 0; batch classifier loss: 0.108660; batch adversarial loss: 0.477799\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037259; batch adversarial loss: 0.436781\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049818; batch adversarial loss: 0.434727\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049589; batch adversarial loss: 0.579837\n",
      "epoch 110; iter: 0; batch classifier loss: 0.034492; batch adversarial loss: 0.494775\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029933; batch adversarial loss: 0.463882\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057492; batch adversarial loss: 0.417863\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047290; batch adversarial loss: 0.496425\n",
      "epoch 114; iter: 0; batch classifier loss: 0.013148; batch adversarial loss: 0.455408\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041298; batch adversarial loss: 0.412318\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048508; batch adversarial loss: 0.435190\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032152; batch adversarial loss: 0.473575\n",
      "epoch 118; iter: 0; batch classifier loss: 0.061556; batch adversarial loss: 0.456961\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040278; batch adversarial loss: 0.363443\n",
      "epoch 120; iter: 0; batch classifier loss: 0.018957; batch adversarial loss: 0.426366\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060927; batch adversarial loss: 0.481381\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029545; batch adversarial loss: 0.410641\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019910; batch adversarial loss: 0.491895\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033477; batch adversarial loss: 0.393309\n",
      "epoch 125; iter: 0; batch classifier loss: 0.065034; batch adversarial loss: 0.506028\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048816; batch adversarial loss: 0.400272\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027257; batch adversarial loss: 0.474138\n",
      "epoch 128; iter: 0; batch classifier loss: 0.015848; batch adversarial loss: 0.376883\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018928; batch adversarial loss: 0.428203\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043654; batch adversarial loss: 0.373152\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021350; batch adversarial loss: 0.428334\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024062; batch adversarial loss: 0.497751\n",
      "epoch 133; iter: 0; batch classifier loss: 0.016133; batch adversarial loss: 0.507620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.033754; batch adversarial loss: 0.437347\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014767; batch adversarial loss: 0.403172\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016762; batch adversarial loss: 0.449859\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027708; batch adversarial loss: 0.430981\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021478; batch adversarial loss: 0.434334\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046759; batch adversarial loss: 0.449129\n",
      "epoch 140; iter: 0; batch classifier loss: 0.062701; batch adversarial loss: 0.333719\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035223; batch adversarial loss: 0.467520\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032642; batch adversarial loss: 0.484168\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031176; batch adversarial loss: 0.453659\n",
      "epoch 144; iter: 0; batch classifier loss: 0.010958; batch adversarial loss: 0.404564\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020056; batch adversarial loss: 0.367768\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021337; batch adversarial loss: 0.369818\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011443; batch adversarial loss: 0.535304\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023986; batch adversarial loss: 0.422701\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034208; batch adversarial loss: 0.472751\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015085; batch adversarial loss: 0.409211\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014884; batch adversarial loss: 0.381371\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023850; batch adversarial loss: 0.514944\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025484; batch adversarial loss: 0.455290\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023191; batch adversarial loss: 0.509711\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021602; batch adversarial loss: 0.512893\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013346; batch adversarial loss: 0.490423\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026690; batch adversarial loss: 0.445515\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020569; batch adversarial loss: 0.574308\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011647; batch adversarial loss: 0.491416\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029530; batch adversarial loss: 0.396969\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032741; batch adversarial loss: 0.417726\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021142; batch adversarial loss: 0.385830\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006649; batch adversarial loss: 0.465975\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022873; batch adversarial loss: 0.469157\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016977; batch adversarial loss: 0.480606\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017781; batch adversarial loss: 0.495828\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025289; batch adversarial loss: 0.406156\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013142; batch adversarial loss: 0.433392\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031628; batch adversarial loss: 0.416244\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023670; batch adversarial loss: 0.471377\n",
      "epoch 171; iter: 0; batch classifier loss: 0.068152; batch adversarial loss: 0.412159\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008611; batch adversarial loss: 0.397777\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011732; batch adversarial loss: 0.485514\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017472; batch adversarial loss: 0.416101\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026208; batch adversarial loss: 0.462168\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011144; batch adversarial loss: 0.502471\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008965; batch adversarial loss: 0.400458\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016114; batch adversarial loss: 0.456086\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010067; batch adversarial loss: 0.494899\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013366; batch adversarial loss: 0.414069\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008636; batch adversarial loss: 0.510915\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017585; batch adversarial loss: 0.431878\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014840; batch adversarial loss: 0.444522\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010417; batch adversarial loss: 0.365649\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011738; batch adversarial loss: 0.431053\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033000; batch adversarial loss: 0.380116\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032304; batch adversarial loss: 0.476313\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030618; batch adversarial loss: 0.320230\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011772; batch adversarial loss: 0.497340\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020399; batch adversarial loss: 0.469286\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018425; batch adversarial loss: 0.402721\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015081; batch adversarial loss: 0.448565\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005537; batch adversarial loss: 0.299609\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009898; batch adversarial loss: 0.414306\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008272; batch adversarial loss: 0.358686\n",
      "epoch 196; iter: 0; batch classifier loss: 0.002995; batch adversarial loss: 0.412207\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005556; batch adversarial loss: 0.435259\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017599; batch adversarial loss: 0.407677\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004981; batch adversarial loss: 0.445594\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691417; batch adversarial loss: 0.623410\n",
      "epoch 1; iter: 0; batch classifier loss: 0.420356; batch adversarial loss: 0.621933\n",
      "epoch 2; iter: 0; batch classifier loss: 0.338501; batch adversarial loss: 0.596416\n",
      "epoch 3; iter: 0; batch classifier loss: 0.247775; batch adversarial loss: 0.579730\n",
      "epoch 4; iter: 0; batch classifier loss: 0.355643; batch adversarial loss: 0.577385\n",
      "epoch 5; iter: 0; batch classifier loss: 0.300824; batch adversarial loss: 0.548014\n",
      "epoch 6; iter: 0; batch classifier loss: 0.288953; batch adversarial loss: 0.518644\n",
      "epoch 7; iter: 0; batch classifier loss: 0.277828; batch adversarial loss: 0.565074\n",
      "epoch 8; iter: 0; batch classifier loss: 0.271970; batch adversarial loss: 0.512006\n",
      "epoch 9; iter: 0; batch classifier loss: 0.229436; batch adversarial loss: 0.506776\n",
      "epoch 10; iter: 0; batch classifier loss: 0.257998; batch adversarial loss: 0.540689\n",
      "epoch 11; iter: 0; batch classifier loss: 0.232150; batch adversarial loss: 0.514270\n",
      "epoch 12; iter: 0; batch classifier loss: 0.252331; batch adversarial loss: 0.576879\n",
      "epoch 13; iter: 0; batch classifier loss: 0.314538; batch adversarial loss: 0.507492\n",
      "epoch 14; iter: 0; batch classifier loss: 0.331347; batch adversarial loss: 0.498144\n",
      "epoch 15; iter: 0; batch classifier loss: 0.233643; batch adversarial loss: 0.569391\n",
      "epoch 16; iter: 0; batch classifier loss: 0.254279; batch adversarial loss: 0.497899\n",
      "epoch 17; iter: 0; batch classifier loss: 0.317826; batch adversarial loss: 0.547832\n",
      "epoch 18; iter: 0; batch classifier loss: 0.303773; batch adversarial loss: 0.508548\n",
      "epoch 19; iter: 0; batch classifier loss: 0.370743; batch adversarial loss: 0.447265\n",
      "epoch 20; iter: 0; batch classifier loss: 0.316975; batch adversarial loss: 0.471423\n",
      "epoch 21; iter: 0; batch classifier loss: 0.457814; batch adversarial loss: 0.486330\n",
      "epoch 22; iter: 0; batch classifier loss: 0.349625; batch adversarial loss: 0.480001\n",
      "epoch 23; iter: 0; batch classifier loss: 0.275460; batch adversarial loss: 0.446939\n",
      "epoch 24; iter: 0; batch classifier loss: 0.175211; batch adversarial loss: 0.481908\n",
      "epoch 25; iter: 0; batch classifier loss: 0.167752; batch adversarial loss: 0.487509\n",
      "epoch 26; iter: 0; batch classifier loss: 0.170783; batch adversarial loss: 0.478804\n",
      "epoch 27; iter: 0; batch classifier loss: 0.121750; batch adversarial loss: 0.447606\n",
      "epoch 28; iter: 0; batch classifier loss: 0.134533; batch adversarial loss: 0.448614\n",
      "epoch 29; iter: 0; batch classifier loss: 0.115269; batch adversarial loss: 0.464036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.123570; batch adversarial loss: 0.496446\n",
      "epoch 31; iter: 0; batch classifier loss: 0.130841; batch adversarial loss: 0.356115\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154628; batch adversarial loss: 0.466639\n",
      "epoch 33; iter: 0; batch classifier loss: 0.111766; batch adversarial loss: 0.349215\n",
      "epoch 34; iter: 0; batch classifier loss: 0.135422; batch adversarial loss: 0.526106\n",
      "epoch 35; iter: 0; batch classifier loss: 0.141604; batch adversarial loss: 0.420780\n",
      "epoch 36; iter: 0; batch classifier loss: 0.137666; batch adversarial loss: 0.480174\n",
      "epoch 37; iter: 0; batch classifier loss: 0.102814; batch adversarial loss: 0.465697\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099470; batch adversarial loss: 0.453226\n",
      "epoch 39; iter: 0; batch classifier loss: 0.095148; batch adversarial loss: 0.454294\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124361; batch adversarial loss: 0.379426\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106408; batch adversarial loss: 0.486869\n",
      "epoch 42; iter: 0; batch classifier loss: 0.133556; batch adversarial loss: 0.434340\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104155; batch adversarial loss: 0.458626\n",
      "epoch 44; iter: 0; batch classifier loss: 0.097256; batch adversarial loss: 0.525486\n",
      "epoch 45; iter: 0; batch classifier loss: 0.121538; batch adversarial loss: 0.424634\n",
      "epoch 46; iter: 0; batch classifier loss: 0.085494; batch adversarial loss: 0.540735\n",
      "epoch 47; iter: 0; batch classifier loss: 0.080986; batch adversarial loss: 0.520857\n",
      "epoch 48; iter: 0; batch classifier loss: 0.180056; batch adversarial loss: 0.407295\n",
      "epoch 49; iter: 0; batch classifier loss: 0.120189; batch adversarial loss: 0.429777\n",
      "epoch 50; iter: 0; batch classifier loss: 0.077503; batch adversarial loss: 0.457447\n",
      "epoch 51; iter: 0; batch classifier loss: 0.089298; batch adversarial loss: 0.477187\n",
      "epoch 52; iter: 0; batch classifier loss: 0.134292; batch adversarial loss: 0.467301\n",
      "epoch 53; iter: 0; batch classifier loss: 0.099375; batch adversarial loss: 0.480425\n",
      "epoch 54; iter: 0; batch classifier loss: 0.100851; batch adversarial loss: 0.510080\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084294; batch adversarial loss: 0.509685\n",
      "epoch 56; iter: 0; batch classifier loss: 0.039497; batch adversarial loss: 0.525391\n",
      "epoch 57; iter: 0; batch classifier loss: 0.087592; batch adversarial loss: 0.428495\n",
      "epoch 58; iter: 0; batch classifier loss: 0.068702; batch adversarial loss: 0.415341\n",
      "epoch 59; iter: 0; batch classifier loss: 0.126320; batch adversarial loss: 0.479476\n",
      "epoch 60; iter: 0; batch classifier loss: 0.129546; batch adversarial loss: 0.444677\n",
      "epoch 61; iter: 0; batch classifier loss: 0.125219; batch adversarial loss: 0.474565\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090972; batch adversarial loss: 0.515640\n",
      "epoch 63; iter: 0; batch classifier loss: 0.051377; batch adversarial loss: 0.537706\n",
      "epoch 64; iter: 0; batch classifier loss: 0.039066; batch adversarial loss: 0.472587\n",
      "epoch 65; iter: 0; batch classifier loss: 0.092294; batch adversarial loss: 0.450258\n",
      "epoch 66; iter: 0; batch classifier loss: 0.145598; batch adversarial loss: 0.406912\n",
      "epoch 67; iter: 0; batch classifier loss: 0.057283; batch adversarial loss: 0.491501\n",
      "epoch 68; iter: 0; batch classifier loss: 0.075061; batch adversarial loss: 0.504634\n",
      "epoch 69; iter: 0; batch classifier loss: 0.149722; batch adversarial loss: 0.339507\n",
      "epoch 70; iter: 0; batch classifier loss: 0.085755; batch adversarial loss: 0.434454\n",
      "epoch 71; iter: 0; batch classifier loss: 0.051167; batch adversarial loss: 0.376718\n",
      "epoch 72; iter: 0; batch classifier loss: 0.070230; batch adversarial loss: 0.451078\n",
      "epoch 73; iter: 0; batch classifier loss: 0.103942; batch adversarial loss: 0.327865\n",
      "epoch 74; iter: 0; batch classifier loss: 0.077260; batch adversarial loss: 0.431767\n",
      "epoch 75; iter: 0; batch classifier loss: 0.141991; batch adversarial loss: 0.483534\n",
      "epoch 76; iter: 0; batch classifier loss: 0.143400; batch adversarial loss: 0.443982\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102054; batch adversarial loss: 0.424967\n",
      "epoch 78; iter: 0; batch classifier loss: 0.113084; batch adversarial loss: 0.547726\n",
      "epoch 79; iter: 0; batch classifier loss: 0.117474; batch adversarial loss: 0.459383\n",
      "epoch 80; iter: 0; batch classifier loss: 0.141973; batch adversarial loss: 0.361250\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071290; batch adversarial loss: 0.428749\n",
      "epoch 82; iter: 0; batch classifier loss: 0.084734; batch adversarial loss: 0.404017\n",
      "epoch 83; iter: 0; batch classifier loss: 0.096151; batch adversarial loss: 0.478072\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046353; batch adversarial loss: 0.475568\n",
      "epoch 85; iter: 0; batch classifier loss: 0.050945; batch adversarial loss: 0.471697\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051682; batch adversarial loss: 0.456627\n",
      "epoch 87; iter: 0; batch classifier loss: 0.091756; batch adversarial loss: 0.504146\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050171; batch adversarial loss: 0.495335\n",
      "epoch 89; iter: 0; batch classifier loss: 0.083335; batch adversarial loss: 0.389350\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062895; batch adversarial loss: 0.501490\n",
      "epoch 91; iter: 0; batch classifier loss: 0.098528; batch adversarial loss: 0.363064\n",
      "epoch 92; iter: 0; batch classifier loss: 0.107264; batch adversarial loss: 0.435950\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051688; batch adversarial loss: 0.473598\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044888; batch adversarial loss: 0.533515\n",
      "epoch 95; iter: 0; batch classifier loss: 0.043422; batch adversarial loss: 0.516131\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055646; batch adversarial loss: 0.412077\n",
      "epoch 97; iter: 0; batch classifier loss: 0.078587; batch adversarial loss: 0.491057\n",
      "epoch 98; iter: 0; batch classifier loss: 0.080037; batch adversarial loss: 0.457753\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069226; batch adversarial loss: 0.481101\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061449; batch adversarial loss: 0.446666\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075843; batch adversarial loss: 0.428530\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047917; batch adversarial loss: 0.394194\n",
      "epoch 103; iter: 0; batch classifier loss: 0.069127; batch adversarial loss: 0.475622\n",
      "epoch 104; iter: 0; batch classifier loss: 0.055953; batch adversarial loss: 0.455760\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059157; batch adversarial loss: 0.561501\n",
      "epoch 106; iter: 0; batch classifier loss: 0.083067; batch adversarial loss: 0.522416\n",
      "epoch 107; iter: 0; batch classifier loss: 0.096705; batch adversarial loss: 0.480200\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048499; batch adversarial loss: 0.357694\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041185; batch adversarial loss: 0.465716\n",
      "epoch 110; iter: 0; batch classifier loss: 0.075187; batch adversarial loss: 0.467029\n",
      "epoch 111; iter: 0; batch classifier loss: 0.079938; batch adversarial loss: 0.446621\n",
      "epoch 112; iter: 0; batch classifier loss: 0.070852; batch adversarial loss: 0.427944\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046802; batch adversarial loss: 0.438743\n",
      "epoch 114; iter: 0; batch classifier loss: 0.080310; batch adversarial loss: 0.395599\n",
      "epoch 115; iter: 0; batch classifier loss: 0.026593; batch adversarial loss: 0.369328\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050480; batch adversarial loss: 0.437817\n",
      "epoch 117; iter: 0; batch classifier loss: 0.085228; batch adversarial loss: 0.364060\n",
      "epoch 118; iter: 0; batch classifier loss: 0.078453; batch adversarial loss: 0.381159\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050421; batch adversarial loss: 0.440855\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043944; batch adversarial loss: 0.422950\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029847; batch adversarial loss: 0.440380\n",
      "epoch 122; iter: 0; batch classifier loss: 0.086013; batch adversarial loss: 0.454021\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023317; batch adversarial loss: 0.453942\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039171; batch adversarial loss: 0.407998\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045437; batch adversarial loss: 0.408351\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050488; batch adversarial loss: 0.499618\n",
      "epoch 127; iter: 0; batch classifier loss: 0.016000; batch adversarial loss: 0.551720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.068977; batch adversarial loss: 0.362271\n",
      "epoch 129; iter: 0; batch classifier loss: 0.053390; batch adversarial loss: 0.416083\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046997; batch adversarial loss: 0.457708\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040755; batch adversarial loss: 0.489203\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040672; batch adversarial loss: 0.387862\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032528; batch adversarial loss: 0.420189\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023566; batch adversarial loss: 0.401337\n",
      "epoch 135; iter: 0; batch classifier loss: 0.094443; batch adversarial loss: 0.515158\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054745; batch adversarial loss: 0.476123\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036125; batch adversarial loss: 0.431462\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039594; batch adversarial loss: 0.437384\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040836; batch adversarial loss: 0.474272\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037253; batch adversarial loss: 0.407118\n",
      "epoch 141; iter: 0; batch classifier loss: 0.056632; batch adversarial loss: 0.456342\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049303; batch adversarial loss: 0.454543\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031129; batch adversarial loss: 0.427080\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030083; batch adversarial loss: 0.502595\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019904; batch adversarial loss: 0.448120\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017222; batch adversarial loss: 0.446887\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026372; batch adversarial loss: 0.533800\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023525; batch adversarial loss: 0.449479\n",
      "epoch 149; iter: 0; batch classifier loss: 0.046710; batch adversarial loss: 0.453764\n",
      "epoch 150; iter: 0; batch classifier loss: 0.059580; batch adversarial loss: 0.445672\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022083; batch adversarial loss: 0.491100\n",
      "epoch 152; iter: 0; batch classifier loss: 0.051785; batch adversarial loss: 0.536547\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035399; batch adversarial loss: 0.377316\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039405; batch adversarial loss: 0.415233\n",
      "epoch 155; iter: 0; batch classifier loss: 0.045293; batch adversarial loss: 0.452004\n",
      "epoch 156; iter: 0; batch classifier loss: 0.009292; batch adversarial loss: 0.539077\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029884; batch adversarial loss: 0.415212\n",
      "epoch 158; iter: 0; batch classifier loss: 0.065286; batch adversarial loss: 0.420138\n",
      "epoch 159; iter: 0; batch classifier loss: 0.048640; batch adversarial loss: 0.419356\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033283; batch adversarial loss: 0.450222\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038075; batch adversarial loss: 0.385125\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016572; batch adversarial loss: 0.527947\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040483; batch adversarial loss: 0.461878\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011865; batch adversarial loss: 0.443072\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017364; batch adversarial loss: 0.472500\n",
      "epoch 166; iter: 0; batch classifier loss: 0.053450; batch adversarial loss: 0.393127\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021335; batch adversarial loss: 0.408743\n",
      "epoch 168; iter: 0; batch classifier loss: 0.044496; batch adversarial loss: 0.435101\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029357; batch adversarial loss: 0.488118\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038665; batch adversarial loss: 0.495770\n",
      "epoch 171; iter: 0; batch classifier loss: 0.072479; batch adversarial loss: 0.344809\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040423; batch adversarial loss: 0.509329\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028836; batch adversarial loss: 0.466222\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024107; batch adversarial loss: 0.356169\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009055; batch adversarial loss: 0.416928\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033135; batch adversarial loss: 0.434420\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012077; batch adversarial loss: 0.486617\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032408; batch adversarial loss: 0.414696\n",
      "epoch 179; iter: 0; batch classifier loss: 0.099975; batch adversarial loss: 0.474128\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030971; batch adversarial loss: 0.418880\n",
      "epoch 181; iter: 0; batch classifier loss: 0.061229; batch adversarial loss: 0.494896\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042747; batch adversarial loss: 0.299129\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020483; batch adversarial loss: 0.383415\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034810; batch adversarial loss: 0.431127\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040024; batch adversarial loss: 0.488007\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026825; batch adversarial loss: 0.473051\n",
      "epoch 187; iter: 0; batch classifier loss: 0.043964; batch adversarial loss: 0.505172\n",
      "epoch 188; iter: 0; batch classifier loss: 0.075506; batch adversarial loss: 0.361700\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034432; batch adversarial loss: 0.484441\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035683; batch adversarial loss: 0.413498\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006867; batch adversarial loss: 0.505928\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012154; batch adversarial loss: 0.402653\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025574; batch adversarial loss: 0.420022\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015996; batch adversarial loss: 0.437887\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034282; batch adversarial loss: 0.430265\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024582; batch adversarial loss: 0.450637\n",
      "epoch 197; iter: 0; batch classifier loss: 0.052642; batch adversarial loss: 0.491981\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010379; batch adversarial loss: 0.516067\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019561; batch adversarial loss: 0.350179\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689959; batch adversarial loss: 0.587604\n",
      "epoch 1; iter: 0; batch classifier loss: 0.455610; batch adversarial loss: 0.606179\n",
      "epoch 2; iter: 0; batch classifier loss: 0.341480; batch adversarial loss: 0.591913\n",
      "epoch 3; iter: 0; batch classifier loss: 0.289299; batch adversarial loss: 0.579868\n",
      "epoch 4; iter: 0; batch classifier loss: 0.340166; batch adversarial loss: 0.573718\n",
      "epoch 5; iter: 0; batch classifier loss: 0.247751; batch adversarial loss: 0.564290\n",
      "epoch 6; iter: 0; batch classifier loss: 0.284924; batch adversarial loss: 0.539131\n",
      "epoch 7; iter: 0; batch classifier loss: 0.223567; batch adversarial loss: 0.517513\n",
      "epoch 8; iter: 0; batch classifier loss: 0.270228; batch adversarial loss: 0.532563\n",
      "epoch 9; iter: 0; batch classifier loss: 0.353183; batch adversarial loss: 0.530049\n",
      "epoch 10; iter: 0; batch classifier loss: 0.263264; batch adversarial loss: 0.472768\n",
      "epoch 11; iter: 0; batch classifier loss: 0.231997; batch adversarial loss: 0.543671\n",
      "epoch 12; iter: 0; batch classifier loss: 0.269936; batch adversarial loss: 0.480975\n",
      "epoch 13; iter: 0; batch classifier loss: 0.315876; batch adversarial loss: 0.507748\n",
      "epoch 14; iter: 0; batch classifier loss: 0.246116; batch adversarial loss: 0.498051\n",
      "epoch 15; iter: 0; batch classifier loss: 0.344463; batch adversarial loss: 0.472751\n",
      "epoch 16; iter: 0; batch classifier loss: 0.405998; batch adversarial loss: 0.567953\n",
      "epoch 17; iter: 0; batch classifier loss: 0.374268; batch adversarial loss: 0.507600\n",
      "epoch 18; iter: 0; batch classifier loss: 0.413175; batch adversarial loss: 0.498027\n",
      "epoch 19; iter: 0; batch classifier loss: 0.477331; batch adversarial loss: 0.429427\n",
      "epoch 20; iter: 0; batch classifier loss: 0.324705; batch adversarial loss: 0.425929\n",
      "epoch 21; iter: 0; batch classifier loss: 0.193695; batch adversarial loss: 0.400676\n",
      "epoch 22; iter: 0; batch classifier loss: 0.155839; batch adversarial loss: 0.490664\n",
      "epoch 23; iter: 0; batch classifier loss: 0.201485; batch adversarial loss: 0.460011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.131753; batch adversarial loss: 0.389775\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177432; batch adversarial loss: 0.530064\n",
      "epoch 26; iter: 0; batch classifier loss: 0.125386; batch adversarial loss: 0.386167\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152984; batch adversarial loss: 0.443434\n",
      "epoch 28; iter: 0; batch classifier loss: 0.125897; batch adversarial loss: 0.443048\n",
      "epoch 29; iter: 0; batch classifier loss: 0.152188; batch adversarial loss: 0.461440\n",
      "epoch 30; iter: 0; batch classifier loss: 0.119598; batch adversarial loss: 0.495446\n",
      "epoch 31; iter: 0; batch classifier loss: 0.125837; batch adversarial loss: 0.463881\n",
      "epoch 32; iter: 0; batch classifier loss: 0.137734; batch adversarial loss: 0.609056\n",
      "epoch 33; iter: 0; batch classifier loss: 0.120960; batch adversarial loss: 0.505255\n",
      "epoch 34; iter: 0; batch classifier loss: 0.089878; batch adversarial loss: 0.366249\n",
      "epoch 35; iter: 0; batch classifier loss: 0.118326; batch adversarial loss: 0.431748\n",
      "epoch 36; iter: 0; batch classifier loss: 0.111449; batch adversarial loss: 0.379240\n",
      "epoch 37; iter: 0; batch classifier loss: 0.089478; batch adversarial loss: 0.464741\n",
      "epoch 38; iter: 0; batch classifier loss: 0.160649; batch adversarial loss: 0.481824\n",
      "epoch 39; iter: 0; batch classifier loss: 0.078241; batch adversarial loss: 0.327577\n",
      "epoch 40; iter: 0; batch classifier loss: 0.105235; batch adversarial loss: 0.506455\n",
      "epoch 41; iter: 0; batch classifier loss: 0.109907; batch adversarial loss: 0.478544\n",
      "epoch 42; iter: 0; batch classifier loss: 0.098844; batch adversarial loss: 0.494371\n",
      "epoch 43; iter: 0; batch classifier loss: 0.066913; batch adversarial loss: 0.463157\n",
      "epoch 44; iter: 0; batch classifier loss: 0.086358; batch adversarial loss: 0.455709\n",
      "epoch 45; iter: 0; batch classifier loss: 0.080424; batch adversarial loss: 0.488558\n",
      "epoch 46; iter: 0; batch classifier loss: 0.103502; batch adversarial loss: 0.392176\n",
      "epoch 47; iter: 0; batch classifier loss: 0.055047; batch adversarial loss: 0.477436\n",
      "epoch 48; iter: 0; batch classifier loss: 0.067852; batch adversarial loss: 0.426992\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113776; batch adversarial loss: 0.429750\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098135; batch adversarial loss: 0.453994\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098393; batch adversarial loss: 0.396534\n",
      "epoch 52; iter: 0; batch classifier loss: 0.107894; batch adversarial loss: 0.527988\n",
      "epoch 53; iter: 0; batch classifier loss: 0.062026; batch adversarial loss: 0.425021\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103726; batch adversarial loss: 0.331464\n",
      "epoch 55; iter: 0; batch classifier loss: 0.088556; batch adversarial loss: 0.434812\n",
      "epoch 56; iter: 0; batch classifier loss: 0.097907; batch adversarial loss: 0.425432\n",
      "epoch 57; iter: 0; batch classifier loss: 0.060007; batch adversarial loss: 0.400071\n",
      "epoch 58; iter: 0; batch classifier loss: 0.129823; batch adversarial loss: 0.347031\n",
      "epoch 59; iter: 0; batch classifier loss: 0.050590; batch adversarial loss: 0.534786\n",
      "epoch 60; iter: 0; batch classifier loss: 0.111514; batch adversarial loss: 0.429620\n",
      "epoch 61; iter: 0; batch classifier loss: 0.060798; batch adversarial loss: 0.353051\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094453; batch adversarial loss: 0.329982\n",
      "epoch 63; iter: 0; batch classifier loss: 0.065185; batch adversarial loss: 0.469556\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073896; batch adversarial loss: 0.395931\n",
      "epoch 65; iter: 0; batch classifier loss: 0.100793; batch adversarial loss: 0.572896\n",
      "epoch 66; iter: 0; batch classifier loss: 0.099083; batch adversarial loss: 0.413078\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080777; batch adversarial loss: 0.459573\n",
      "epoch 68; iter: 0; batch classifier loss: 0.151228; batch adversarial loss: 0.430674\n",
      "epoch 69; iter: 0; batch classifier loss: 0.098935; batch adversarial loss: 0.438705\n",
      "epoch 70; iter: 0; batch classifier loss: 0.124266; batch adversarial loss: 0.525009\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071230; batch adversarial loss: 0.450557\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054155; batch adversarial loss: 0.473174\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068592; batch adversarial loss: 0.477004\n",
      "epoch 74; iter: 0; batch classifier loss: 0.050306; batch adversarial loss: 0.496967\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059256; batch adversarial loss: 0.528780\n",
      "epoch 76; iter: 0; batch classifier loss: 0.145016; batch adversarial loss: 0.442099\n",
      "epoch 77; iter: 0; batch classifier loss: 0.082052; batch adversarial loss: 0.433169\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054639; batch adversarial loss: 0.518525\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080397; batch adversarial loss: 0.378467\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075024; batch adversarial loss: 0.474923\n",
      "epoch 81; iter: 0; batch classifier loss: 0.114220; batch adversarial loss: 0.384662\n",
      "epoch 82; iter: 0; batch classifier loss: 0.049871; batch adversarial loss: 0.523134\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080747; batch adversarial loss: 0.444963\n",
      "epoch 84; iter: 0; batch classifier loss: 0.083555; batch adversarial loss: 0.503218\n",
      "epoch 85; iter: 0; batch classifier loss: 0.119520; batch adversarial loss: 0.485247\n",
      "epoch 86; iter: 0; batch classifier loss: 0.100446; batch adversarial loss: 0.395734\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057676; batch adversarial loss: 0.496474\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070994; batch adversarial loss: 0.384548\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069973; batch adversarial loss: 0.488601\n",
      "epoch 90; iter: 0; batch classifier loss: 0.105271; batch adversarial loss: 0.360399\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083901; batch adversarial loss: 0.429334\n",
      "epoch 92; iter: 0; batch classifier loss: 0.140474; batch adversarial loss: 0.346107\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050137; batch adversarial loss: 0.501179\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048460; batch adversarial loss: 0.462594\n",
      "epoch 95; iter: 0; batch classifier loss: 0.116460; batch adversarial loss: 0.438596\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070207; batch adversarial loss: 0.353710\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066316; batch adversarial loss: 0.389366\n",
      "epoch 98; iter: 0; batch classifier loss: 0.107467; batch adversarial loss: 0.418405\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058889; batch adversarial loss: 0.497169\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074312; batch adversarial loss: 0.382645\n",
      "epoch 101; iter: 0; batch classifier loss: 0.128452; batch adversarial loss: 0.477617\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066075; batch adversarial loss: 0.318224\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048854; batch adversarial loss: 0.424157\n",
      "epoch 104; iter: 0; batch classifier loss: 0.091284; batch adversarial loss: 0.450977\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059207; batch adversarial loss: 0.498702\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053098; batch adversarial loss: 0.468330\n",
      "epoch 107; iter: 0; batch classifier loss: 0.068521; batch adversarial loss: 0.505752\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067928; batch adversarial loss: 0.411091\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047616; batch adversarial loss: 0.377953\n",
      "epoch 110; iter: 0; batch classifier loss: 0.082006; batch adversarial loss: 0.413433\n",
      "epoch 111; iter: 0; batch classifier loss: 0.067580; batch adversarial loss: 0.506001\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041185; batch adversarial loss: 0.370266\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029128; batch adversarial loss: 0.401080\n",
      "epoch 114; iter: 0; batch classifier loss: 0.066074; batch adversarial loss: 0.407578\n",
      "epoch 115; iter: 0; batch classifier loss: 0.079748; batch adversarial loss: 0.514685\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033899; batch adversarial loss: 0.454695\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047183; batch adversarial loss: 0.401638\n",
      "epoch 118; iter: 0; batch classifier loss: 0.081951; batch adversarial loss: 0.449988\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038508; batch adversarial loss: 0.451061\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047289; batch adversarial loss: 0.492773\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048054; batch adversarial loss: 0.692780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.023114; batch adversarial loss: 0.418277\n",
      "epoch 123; iter: 0; batch classifier loss: 0.071053; batch adversarial loss: 0.444511\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035873; batch adversarial loss: 0.431127\n",
      "epoch 125; iter: 0; batch classifier loss: 0.064116; batch adversarial loss: 0.457924\n",
      "epoch 126; iter: 0; batch classifier loss: 0.058957; batch adversarial loss: 0.495198\n",
      "epoch 127; iter: 0; batch classifier loss: 0.052544; batch adversarial loss: 0.444175\n",
      "epoch 128; iter: 0; batch classifier loss: 0.057552; batch adversarial loss: 0.474098\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043403; batch adversarial loss: 0.469513\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044111; batch adversarial loss: 0.313229\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039353; batch adversarial loss: 0.452373\n",
      "epoch 132; iter: 0; batch classifier loss: 0.088131; batch adversarial loss: 0.465140\n",
      "epoch 133; iter: 0; batch classifier loss: 0.009805; batch adversarial loss: 0.395659\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031010; batch adversarial loss: 0.439154\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018135; batch adversarial loss: 0.350250\n",
      "epoch 136; iter: 0; batch classifier loss: 0.079203; batch adversarial loss: 0.413312\n",
      "epoch 137; iter: 0; batch classifier loss: 0.068400; batch adversarial loss: 0.437651\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030482; batch adversarial loss: 0.408976\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038007; batch adversarial loss: 0.398715\n",
      "epoch 140; iter: 0; batch classifier loss: 0.069312; batch adversarial loss: 0.404890\n",
      "epoch 141; iter: 0; batch classifier loss: 0.079192; batch adversarial loss: 0.435847\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033153; batch adversarial loss: 0.420197\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035675; batch adversarial loss: 0.649403\n",
      "epoch 144; iter: 0; batch classifier loss: 0.087042; batch adversarial loss: 0.468291\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018117; batch adversarial loss: 0.411618\n",
      "epoch 146; iter: 0; batch classifier loss: 0.069817; batch adversarial loss: 0.480938\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032719; batch adversarial loss: 0.482369\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019631; batch adversarial loss: 0.437908\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021278; batch adversarial loss: 0.403616\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038936; batch adversarial loss: 0.391603\n",
      "epoch 151; iter: 0; batch classifier loss: 0.045975; batch adversarial loss: 0.383952\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008579; batch adversarial loss: 0.383380\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030522; batch adversarial loss: 0.389668\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044488; batch adversarial loss: 0.384751\n",
      "epoch 155; iter: 0; batch classifier loss: 0.070973; batch adversarial loss: 0.394579\n",
      "epoch 156; iter: 0; batch classifier loss: 0.059332; batch adversarial loss: 0.428465\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042239; batch adversarial loss: 0.395246\n",
      "epoch 158; iter: 0; batch classifier loss: 0.039534; batch adversarial loss: 0.485298\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036984; batch adversarial loss: 0.423651\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037031; batch adversarial loss: 0.404067\n",
      "epoch 161; iter: 0; batch classifier loss: 0.044343; batch adversarial loss: 0.576714\n",
      "epoch 162; iter: 0; batch classifier loss: 0.049439; batch adversarial loss: 0.383461\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024608; batch adversarial loss: 0.477057\n",
      "epoch 164; iter: 0; batch classifier loss: 0.039932; batch adversarial loss: 0.487625\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038056; batch adversarial loss: 0.465591\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027198; batch adversarial loss: 0.486407\n",
      "epoch 167; iter: 0; batch classifier loss: 0.055620; batch adversarial loss: 0.485912\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010741; batch adversarial loss: 0.466993\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020640; batch adversarial loss: 0.452905\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032852; batch adversarial loss: 0.354923\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036202; batch adversarial loss: 0.371315\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032315; batch adversarial loss: 0.457868\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013043; batch adversarial loss: 0.369083\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009397; batch adversarial loss: 0.524984\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029786; batch adversarial loss: 0.490863\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033504; batch adversarial loss: 0.558730\n",
      "epoch 177; iter: 0; batch classifier loss: 0.059607; batch adversarial loss: 0.505136\n",
      "epoch 178; iter: 0; batch classifier loss: 0.046066; batch adversarial loss: 0.444577\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033565; batch adversarial loss: 0.477309\n",
      "epoch 180; iter: 0; batch classifier loss: 0.048149; batch adversarial loss: 0.415311\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016902; batch adversarial loss: 0.483061\n",
      "epoch 182; iter: 0; batch classifier loss: 0.055920; batch adversarial loss: 0.498127\n",
      "epoch 183; iter: 0; batch classifier loss: 0.044278; batch adversarial loss: 0.358890\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034767; batch adversarial loss: 0.447856\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027416; batch adversarial loss: 0.420820\n",
      "epoch 186; iter: 0; batch classifier loss: 0.069567; batch adversarial loss: 0.462377\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042743; batch adversarial loss: 0.442971\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023727; batch adversarial loss: 0.436262\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013916; batch adversarial loss: 0.472263\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034470; batch adversarial loss: 0.410822\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013533; batch adversarial loss: 0.504780\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028681; batch adversarial loss: 0.430304\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004864; batch adversarial loss: 0.374517\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032274; batch adversarial loss: 0.382661\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028494; batch adversarial loss: 0.350485\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016038; batch adversarial loss: 0.491207\n",
      "epoch 197; iter: 0; batch classifier loss: 0.041374; batch adversarial loss: 0.380399\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024330; batch adversarial loss: 0.452160\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016630; batch adversarial loss: 0.415996\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735629; batch adversarial loss: 0.495543\n",
      "epoch 1; iter: 0; batch classifier loss: 0.374572; batch adversarial loss: 0.601861\n",
      "epoch 2; iter: 0; batch classifier loss: 0.359153; batch adversarial loss: 0.597307\n",
      "epoch 3; iter: 0; batch classifier loss: 0.360902; batch adversarial loss: 0.585874\n",
      "epoch 4; iter: 0; batch classifier loss: 0.400480; batch adversarial loss: 0.578927\n",
      "epoch 5; iter: 0; batch classifier loss: 0.342806; batch adversarial loss: 0.536795\n",
      "epoch 6; iter: 0; batch classifier loss: 0.332350; batch adversarial loss: 0.566696\n",
      "epoch 7; iter: 0; batch classifier loss: 0.400872; batch adversarial loss: 0.558242\n",
      "epoch 8; iter: 0; batch classifier loss: 0.381379; batch adversarial loss: 0.536879\n",
      "epoch 9; iter: 0; batch classifier loss: 0.271951; batch adversarial loss: 0.525641\n",
      "epoch 10; iter: 0; batch classifier loss: 0.265271; batch adversarial loss: 0.513416\n",
      "epoch 11; iter: 0; batch classifier loss: 0.322178; batch adversarial loss: 0.554978\n",
      "epoch 12; iter: 0; batch classifier loss: 0.283944; batch adversarial loss: 0.485920\n",
      "epoch 13; iter: 0; batch classifier loss: 0.404523; batch adversarial loss: 0.506262\n",
      "epoch 14; iter: 0; batch classifier loss: 0.633723; batch adversarial loss: 0.559903\n",
      "epoch 15; iter: 0; batch classifier loss: 0.574235; batch adversarial loss: 0.477954\n",
      "epoch 16; iter: 0; batch classifier loss: 0.491957; batch adversarial loss: 0.445493\n",
      "epoch 17; iter: 0; batch classifier loss: 0.367052; batch adversarial loss: 0.468520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.197936; batch adversarial loss: 0.411002\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261497; batch adversarial loss: 0.482167\n",
      "epoch 20; iter: 0; batch classifier loss: 0.213137; batch adversarial loss: 0.446045\n",
      "epoch 21; iter: 0; batch classifier loss: 0.197687; batch adversarial loss: 0.536792\n",
      "epoch 22; iter: 0; batch classifier loss: 0.150640; batch adversarial loss: 0.464584\n",
      "epoch 23; iter: 0; batch classifier loss: 0.165469; batch adversarial loss: 0.433211\n",
      "epoch 24; iter: 0; batch classifier loss: 0.186892; batch adversarial loss: 0.591155\n",
      "epoch 25; iter: 0; batch classifier loss: 0.183827; batch adversarial loss: 0.461632\n",
      "epoch 26; iter: 0; batch classifier loss: 0.141162; batch adversarial loss: 0.513494\n",
      "epoch 27; iter: 0; batch classifier loss: 0.132222; batch adversarial loss: 0.463611\n",
      "epoch 28; iter: 0; batch classifier loss: 0.131516; batch adversarial loss: 0.439399\n",
      "epoch 29; iter: 0; batch classifier loss: 0.118688; batch adversarial loss: 0.524665\n",
      "epoch 30; iter: 0; batch classifier loss: 0.073234; batch adversarial loss: 0.394848\n",
      "epoch 31; iter: 0; batch classifier loss: 0.107646; batch adversarial loss: 0.510580\n",
      "epoch 32; iter: 0; batch classifier loss: 0.111519; batch adversarial loss: 0.419529\n",
      "epoch 33; iter: 0; batch classifier loss: 0.132236; batch adversarial loss: 0.334649\n",
      "epoch 34; iter: 0; batch classifier loss: 0.115005; batch adversarial loss: 0.460083\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122143; batch adversarial loss: 0.450289\n",
      "epoch 36; iter: 0; batch classifier loss: 0.086631; batch adversarial loss: 0.418479\n",
      "epoch 37; iter: 0; batch classifier loss: 0.146575; batch adversarial loss: 0.437933\n",
      "epoch 38; iter: 0; batch classifier loss: 0.104441; batch adversarial loss: 0.524112\n",
      "epoch 39; iter: 0; batch classifier loss: 0.089458; batch adversarial loss: 0.531599\n",
      "epoch 40; iter: 0; batch classifier loss: 0.102964; batch adversarial loss: 0.528125\n",
      "epoch 41; iter: 0; batch classifier loss: 0.084960; batch adversarial loss: 0.527410\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117426; batch adversarial loss: 0.460734\n",
      "epoch 43; iter: 0; batch classifier loss: 0.153332; batch adversarial loss: 0.378793\n",
      "epoch 44; iter: 0; batch classifier loss: 0.091773; batch adversarial loss: 0.428557\n",
      "epoch 45; iter: 0; batch classifier loss: 0.078739; batch adversarial loss: 0.458990\n",
      "epoch 46; iter: 0; batch classifier loss: 0.083150; batch adversarial loss: 0.383920\n",
      "epoch 47; iter: 0; batch classifier loss: 0.082154; batch adversarial loss: 0.423188\n",
      "epoch 48; iter: 0; batch classifier loss: 0.122064; batch adversarial loss: 0.447335\n",
      "epoch 49; iter: 0; batch classifier loss: 0.084157; batch adversarial loss: 0.403944\n",
      "epoch 50; iter: 0; batch classifier loss: 0.085868; batch adversarial loss: 0.487988\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081788; batch adversarial loss: 0.499828\n",
      "epoch 52; iter: 0; batch classifier loss: 0.070667; batch adversarial loss: 0.444385\n",
      "epoch 53; iter: 0; batch classifier loss: 0.074032; batch adversarial loss: 0.485395\n",
      "epoch 54; iter: 0; batch classifier loss: 0.128865; batch adversarial loss: 0.489652\n",
      "epoch 55; iter: 0; batch classifier loss: 0.059339; batch adversarial loss: 0.446496\n",
      "epoch 56; iter: 0; batch classifier loss: 0.095884; batch adversarial loss: 0.495892\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095054; batch adversarial loss: 0.430354\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090629; batch adversarial loss: 0.470059\n",
      "epoch 59; iter: 0; batch classifier loss: 0.073478; batch adversarial loss: 0.398891\n",
      "epoch 60; iter: 0; batch classifier loss: 0.121832; batch adversarial loss: 0.509495\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093191; batch adversarial loss: 0.535111\n",
      "epoch 62; iter: 0; batch classifier loss: 0.100284; batch adversarial loss: 0.469998\n",
      "epoch 63; iter: 0; batch classifier loss: 0.068720; batch adversarial loss: 0.423748\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082654; batch adversarial loss: 0.434376\n",
      "epoch 65; iter: 0; batch classifier loss: 0.062646; batch adversarial loss: 0.467968\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068926; batch adversarial loss: 0.536668\n",
      "epoch 67; iter: 0; batch classifier loss: 0.112659; batch adversarial loss: 0.480070\n",
      "epoch 68; iter: 0; batch classifier loss: 0.058043; batch adversarial loss: 0.458264\n",
      "epoch 69; iter: 0; batch classifier loss: 0.079893; batch adversarial loss: 0.477411\n",
      "epoch 70; iter: 0; batch classifier loss: 0.076749; batch adversarial loss: 0.460109\n",
      "epoch 71; iter: 0; batch classifier loss: 0.067896; batch adversarial loss: 0.339788\n",
      "epoch 72; iter: 0; batch classifier loss: 0.120524; batch adversarial loss: 0.388794\n",
      "epoch 73; iter: 0; batch classifier loss: 0.112472; batch adversarial loss: 0.428307\n",
      "epoch 74; iter: 0; batch classifier loss: 0.042510; batch adversarial loss: 0.473603\n",
      "epoch 75; iter: 0; batch classifier loss: 0.045719; batch adversarial loss: 0.448107\n",
      "epoch 76; iter: 0; batch classifier loss: 0.074115; batch adversarial loss: 0.468902\n",
      "epoch 77; iter: 0; batch classifier loss: 0.108606; batch adversarial loss: 0.517730\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061572; batch adversarial loss: 0.459773\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076523; batch adversarial loss: 0.458143\n",
      "epoch 80; iter: 0; batch classifier loss: 0.108483; batch adversarial loss: 0.553892\n",
      "epoch 81; iter: 0; batch classifier loss: 0.047396; batch adversarial loss: 0.488777\n",
      "epoch 82; iter: 0; batch classifier loss: 0.096643; batch adversarial loss: 0.447009\n",
      "epoch 83; iter: 0; batch classifier loss: 0.107367; batch adversarial loss: 0.540977\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065318; batch adversarial loss: 0.450505\n",
      "epoch 85; iter: 0; batch classifier loss: 0.141444; batch adversarial loss: 0.479210\n",
      "epoch 86; iter: 0; batch classifier loss: 0.028121; batch adversarial loss: 0.431357\n",
      "epoch 87; iter: 0; batch classifier loss: 0.077818; batch adversarial loss: 0.405929\n",
      "epoch 88; iter: 0; batch classifier loss: 0.034529; batch adversarial loss: 0.351083\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058033; batch adversarial loss: 0.515524\n",
      "epoch 90; iter: 0; batch classifier loss: 0.071611; batch adversarial loss: 0.473246\n",
      "epoch 91; iter: 0; batch classifier loss: 0.058983; batch adversarial loss: 0.543161\n",
      "epoch 92; iter: 0; batch classifier loss: 0.067561; batch adversarial loss: 0.459782\n",
      "epoch 93; iter: 0; batch classifier loss: 0.059173; batch adversarial loss: 0.361361\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033002; batch adversarial loss: 0.396395\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056819; batch adversarial loss: 0.541117\n",
      "epoch 96; iter: 0; batch classifier loss: 0.083550; batch adversarial loss: 0.466504\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073225; batch adversarial loss: 0.521413\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044609; batch adversarial loss: 0.402539\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053965; batch adversarial loss: 0.458034\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067013; batch adversarial loss: 0.354422\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044124; batch adversarial loss: 0.433918\n",
      "epoch 102; iter: 0; batch classifier loss: 0.039320; batch adversarial loss: 0.463028\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045039; batch adversarial loss: 0.573486\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033556; batch adversarial loss: 0.503189\n",
      "epoch 105; iter: 0; batch classifier loss: 0.071572; batch adversarial loss: 0.461723\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025247; batch adversarial loss: 0.452236\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033011; batch adversarial loss: 0.413658\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051725; batch adversarial loss: 0.496436\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046059; batch adversarial loss: 0.504573\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051091; batch adversarial loss: 0.483679\n",
      "epoch 111; iter: 0; batch classifier loss: 0.093283; batch adversarial loss: 0.412564\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027075; batch adversarial loss: 0.486837\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039211; batch adversarial loss: 0.564646\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029984; batch adversarial loss: 0.419453\n",
      "epoch 115; iter: 0; batch classifier loss: 0.016731; batch adversarial loss: 0.408133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.032111; batch adversarial loss: 0.411047\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028087; batch adversarial loss: 0.499971\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051390; batch adversarial loss: 0.447699\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046058; batch adversarial loss: 0.423140\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040089; batch adversarial loss: 0.434827\n",
      "epoch 121; iter: 0; batch classifier loss: 0.065883; batch adversarial loss: 0.513426\n",
      "epoch 122; iter: 0; batch classifier loss: 0.058487; batch adversarial loss: 0.515732\n",
      "epoch 123; iter: 0; batch classifier loss: 0.020265; batch adversarial loss: 0.423128\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029431; batch adversarial loss: 0.425701\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033012; batch adversarial loss: 0.427803\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022103; batch adversarial loss: 0.404832\n",
      "epoch 127; iter: 0; batch classifier loss: 0.013839; batch adversarial loss: 0.424384\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035711; batch adversarial loss: 0.473714\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035365; batch adversarial loss: 0.397709\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021596; batch adversarial loss: 0.463592\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034246; batch adversarial loss: 0.522407\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031154; batch adversarial loss: 0.364843\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036614; batch adversarial loss: 0.466773\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049536; batch adversarial loss: 0.474061\n",
      "epoch 135; iter: 0; batch classifier loss: 0.006606; batch adversarial loss: 0.445814\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017573; batch adversarial loss: 0.430795\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045720; batch adversarial loss: 0.435875\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048326; batch adversarial loss: 0.331587\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033951; batch adversarial loss: 0.431393\n",
      "epoch 140; iter: 0; batch classifier loss: 0.015543; batch adversarial loss: 0.419141\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022375; batch adversarial loss: 0.390079\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013937; batch adversarial loss: 0.407818\n",
      "epoch 143; iter: 0; batch classifier loss: 0.008899; batch adversarial loss: 0.474975\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018905; batch adversarial loss: 0.408505\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030372; batch adversarial loss: 0.419087\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025388; batch adversarial loss: 0.434863\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029462; batch adversarial loss: 0.540886\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026546; batch adversarial loss: 0.394606\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016300; batch adversarial loss: 0.536320\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031178; batch adversarial loss: 0.468871\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048407; batch adversarial loss: 0.432077\n",
      "epoch 152; iter: 0; batch classifier loss: 0.047483; batch adversarial loss: 0.479862\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016432; batch adversarial loss: 0.451679\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016070; batch adversarial loss: 0.372530\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015111; batch adversarial loss: 0.473555\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015379; batch adversarial loss: 0.558289\n",
      "epoch 157; iter: 0; batch classifier loss: 0.058039; batch adversarial loss: 0.500559\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013824; batch adversarial loss: 0.438223\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020072; batch adversarial loss: 0.420795\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026932; batch adversarial loss: 0.414107\n",
      "epoch 161; iter: 0; batch classifier loss: 0.048821; batch adversarial loss: 0.491826\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015714; batch adversarial loss: 0.476939\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010233; batch adversarial loss: 0.450266\n",
      "epoch 164; iter: 0; batch classifier loss: 0.007936; batch adversarial loss: 0.365916\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020983; batch adversarial loss: 0.477140\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031970; batch adversarial loss: 0.484399\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025455; batch adversarial loss: 0.467517\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017507; batch adversarial loss: 0.482413\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016151; batch adversarial loss: 0.373582\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015177; batch adversarial loss: 0.424075\n",
      "epoch 171; iter: 0; batch classifier loss: 0.004541; batch adversarial loss: 0.438093\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023119; batch adversarial loss: 0.343884\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018738; batch adversarial loss: 0.444809\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022914; batch adversarial loss: 0.439312\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020345; batch adversarial loss: 0.484880\n",
      "epoch 176; iter: 0; batch classifier loss: 0.042388; batch adversarial loss: 0.513281\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042302; batch adversarial loss: 0.403796\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021587; batch adversarial loss: 0.576012\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012963; batch adversarial loss: 0.435974\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006651; batch adversarial loss: 0.513929\n",
      "epoch 181; iter: 0; batch classifier loss: 0.053852; batch adversarial loss: 0.413850\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027158; batch adversarial loss: 0.482324\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008551; batch adversarial loss: 0.416432\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023858; batch adversarial loss: 0.430410\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007790; batch adversarial loss: 0.413886\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012858; batch adversarial loss: 0.505416\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017641; batch adversarial loss: 0.445044\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030098; batch adversarial loss: 0.426967\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008914; batch adversarial loss: 0.450065\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020640; batch adversarial loss: 0.488081\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021691; batch adversarial loss: 0.460052\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026188; batch adversarial loss: 0.373645\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012663; batch adversarial loss: 0.360400\n",
      "epoch 194; iter: 0; batch classifier loss: 0.049661; batch adversarial loss: 0.425965\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026066; batch adversarial loss: 0.453400\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009125; batch adversarial loss: 0.460895\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007839; batch adversarial loss: 0.566190\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019948; batch adversarial loss: 0.498756\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007337; batch adversarial loss: 0.431991\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673444; batch adversarial loss: 0.795492\n",
      "epoch 1; iter: 0; batch classifier loss: 0.538200; batch adversarial loss: 0.747982\n",
      "epoch 2; iter: 0; batch classifier loss: 0.576651; batch adversarial loss: 0.689955\n",
      "epoch 3; iter: 0; batch classifier loss: 0.501561; batch adversarial loss: 0.642136\n",
      "epoch 4; iter: 0; batch classifier loss: 0.414518; batch adversarial loss: 0.588226\n",
      "epoch 5; iter: 0; batch classifier loss: 0.375501; batch adversarial loss: 0.587426\n",
      "epoch 6; iter: 0; batch classifier loss: 0.337662; batch adversarial loss: 0.553297\n",
      "epoch 7; iter: 0; batch classifier loss: 0.368761; batch adversarial loss: 0.578953\n",
      "epoch 8; iter: 0; batch classifier loss: 0.335233; batch adversarial loss: 0.505690\n",
      "epoch 9; iter: 0; batch classifier loss: 0.328684; batch adversarial loss: 0.530219\n",
      "epoch 10; iter: 0; batch classifier loss: 0.367930; batch adversarial loss: 0.515998\n",
      "epoch 11; iter: 0; batch classifier loss: 0.246435; batch adversarial loss: 0.515238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.280599; batch adversarial loss: 0.562843\n",
      "epoch 13; iter: 0; batch classifier loss: 0.285804; batch adversarial loss: 0.545466\n",
      "epoch 14; iter: 0; batch classifier loss: 0.233097; batch adversarial loss: 0.518440\n",
      "epoch 15; iter: 0; batch classifier loss: 0.277224; batch adversarial loss: 0.449848\n",
      "epoch 16; iter: 0; batch classifier loss: 0.235056; batch adversarial loss: 0.493309\n",
      "epoch 17; iter: 0; batch classifier loss: 0.315337; batch adversarial loss: 0.477324\n",
      "epoch 18; iter: 0; batch classifier loss: 0.228400; batch adversarial loss: 0.475678\n",
      "epoch 19; iter: 0; batch classifier loss: 0.270539; batch adversarial loss: 0.465405\n",
      "epoch 20; iter: 0; batch classifier loss: 0.260227; batch adversarial loss: 0.472657\n",
      "epoch 21; iter: 0; batch classifier loss: 0.240913; batch adversarial loss: 0.429629\n",
      "epoch 22; iter: 0; batch classifier loss: 0.204086; batch adversarial loss: 0.503687\n",
      "epoch 23; iter: 0; batch classifier loss: 0.210366; batch adversarial loss: 0.449636\n",
      "epoch 24; iter: 0; batch classifier loss: 0.161720; batch adversarial loss: 0.525408\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174803; batch adversarial loss: 0.475386\n",
      "epoch 26; iter: 0; batch classifier loss: 0.191797; batch adversarial loss: 0.483138\n",
      "epoch 27; iter: 0; batch classifier loss: 0.229978; batch adversarial loss: 0.405529\n",
      "epoch 28; iter: 0; batch classifier loss: 0.120309; batch adversarial loss: 0.477701\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197274; batch adversarial loss: 0.416312\n",
      "epoch 30; iter: 0; batch classifier loss: 0.220543; batch adversarial loss: 0.509522\n",
      "epoch 31; iter: 0; batch classifier loss: 0.205118; batch adversarial loss: 0.479051\n",
      "epoch 32; iter: 0; batch classifier loss: 0.207984; batch adversarial loss: 0.452507\n",
      "epoch 33; iter: 0; batch classifier loss: 0.190159; batch adversarial loss: 0.410773\n",
      "epoch 34; iter: 0; batch classifier loss: 0.184572; batch adversarial loss: 0.451864\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160295; batch adversarial loss: 0.415643\n",
      "epoch 36; iter: 0; batch classifier loss: 0.205524; batch adversarial loss: 0.462297\n",
      "epoch 37; iter: 0; batch classifier loss: 0.263717; batch adversarial loss: 0.405085\n",
      "epoch 38; iter: 0; batch classifier loss: 0.163056; batch adversarial loss: 0.441932\n",
      "epoch 39; iter: 0; batch classifier loss: 0.159494; batch adversarial loss: 0.455770\n",
      "epoch 40; iter: 0; batch classifier loss: 0.176275; batch adversarial loss: 0.418531\n",
      "epoch 41; iter: 0; batch classifier loss: 0.211664; batch adversarial loss: 0.410024\n",
      "epoch 42; iter: 0; batch classifier loss: 0.152686; batch adversarial loss: 0.452446\n",
      "epoch 43; iter: 0; batch classifier loss: 0.214471; batch adversarial loss: 0.526364\n",
      "epoch 44; iter: 0; batch classifier loss: 0.188536; batch adversarial loss: 0.458475\n",
      "epoch 45; iter: 0; batch classifier loss: 0.274406; batch adversarial loss: 0.520185\n",
      "epoch 46; iter: 0; batch classifier loss: 0.171591; batch adversarial loss: 0.478487\n",
      "epoch 47; iter: 0; batch classifier loss: 0.157822; batch adversarial loss: 0.463019\n",
      "epoch 48; iter: 0; batch classifier loss: 0.112349; batch adversarial loss: 0.538077\n",
      "epoch 49; iter: 0; batch classifier loss: 0.195210; batch adversarial loss: 0.445797\n",
      "epoch 50; iter: 0; batch classifier loss: 0.118445; batch adversarial loss: 0.454603\n",
      "epoch 51; iter: 0; batch classifier loss: 0.157774; batch adversarial loss: 0.410605\n",
      "epoch 52; iter: 0; batch classifier loss: 0.163717; batch adversarial loss: 0.408214\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096275; batch adversarial loss: 0.455912\n",
      "epoch 54; iter: 0; batch classifier loss: 0.137272; batch adversarial loss: 0.424404\n",
      "epoch 55; iter: 0; batch classifier loss: 0.133398; batch adversarial loss: 0.404889\n",
      "epoch 56; iter: 0; batch classifier loss: 0.087452; batch adversarial loss: 0.472499\n",
      "epoch 57; iter: 0; batch classifier loss: 0.110241; batch adversarial loss: 0.385933\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103138; batch adversarial loss: 0.520663\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083949; batch adversarial loss: 0.477373\n",
      "epoch 60; iter: 0; batch classifier loss: 0.126663; batch adversarial loss: 0.451757\n",
      "epoch 61; iter: 0; batch classifier loss: 0.138674; batch adversarial loss: 0.485606\n",
      "epoch 62; iter: 0; batch classifier loss: 0.107964; batch adversarial loss: 0.433142\n",
      "epoch 63; iter: 0; batch classifier loss: 0.125386; batch adversarial loss: 0.523509\n",
      "epoch 64; iter: 0; batch classifier loss: 0.091656; batch adversarial loss: 0.464334\n",
      "epoch 65; iter: 0; batch classifier loss: 0.112528; batch adversarial loss: 0.451578\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088149; batch adversarial loss: 0.544851\n",
      "epoch 67; iter: 0; batch classifier loss: 0.193921; batch adversarial loss: 0.403288\n",
      "epoch 68; iter: 0; batch classifier loss: 0.079916; batch adversarial loss: 0.403938\n",
      "epoch 69; iter: 0; batch classifier loss: 0.057053; batch adversarial loss: 0.407257\n",
      "epoch 70; iter: 0; batch classifier loss: 0.083264; batch adversarial loss: 0.433279\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079893; batch adversarial loss: 0.420139\n",
      "epoch 72; iter: 0; batch classifier loss: 0.096456; batch adversarial loss: 0.394814\n",
      "epoch 73; iter: 0; batch classifier loss: 0.071680; batch adversarial loss: 0.573008\n",
      "epoch 74; iter: 0; batch classifier loss: 0.091089; batch adversarial loss: 0.526762\n",
      "epoch 75; iter: 0; batch classifier loss: 0.090176; batch adversarial loss: 0.462748\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081954; batch adversarial loss: 0.494190\n",
      "epoch 77; iter: 0; batch classifier loss: 0.071382; batch adversarial loss: 0.501573\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080655; batch adversarial loss: 0.523745\n",
      "epoch 79; iter: 0; batch classifier loss: 0.050465; batch adversarial loss: 0.517143\n",
      "epoch 80; iter: 0; batch classifier loss: 0.100671; batch adversarial loss: 0.413370\n",
      "epoch 81; iter: 0; batch classifier loss: 0.090428; batch adversarial loss: 0.454729\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053606; batch adversarial loss: 0.470214\n",
      "epoch 83; iter: 0; batch classifier loss: 0.055873; batch adversarial loss: 0.536913\n",
      "epoch 84; iter: 0; batch classifier loss: 0.088401; batch adversarial loss: 0.558977\n",
      "epoch 85; iter: 0; batch classifier loss: 0.072150; batch adversarial loss: 0.402066\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057671; batch adversarial loss: 0.385832\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071449; batch adversarial loss: 0.338098\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050401; batch adversarial loss: 0.457463\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054116; batch adversarial loss: 0.552598\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051267; batch adversarial loss: 0.522846\n",
      "epoch 91; iter: 0; batch classifier loss: 0.038665; batch adversarial loss: 0.481789\n",
      "epoch 92; iter: 0; batch classifier loss: 0.096777; batch adversarial loss: 0.423446\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055251; batch adversarial loss: 0.515911\n",
      "epoch 94; iter: 0; batch classifier loss: 0.040095; batch adversarial loss: 0.498285\n",
      "epoch 95; iter: 0; batch classifier loss: 0.039083; batch adversarial loss: 0.456096\n",
      "epoch 96; iter: 0; batch classifier loss: 0.042926; batch adversarial loss: 0.555219\n",
      "epoch 97; iter: 0; batch classifier loss: 0.067259; batch adversarial loss: 0.503312\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049310; batch adversarial loss: 0.426864\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040138; batch adversarial loss: 0.490173\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047919; batch adversarial loss: 0.363164\n",
      "epoch 101; iter: 0; batch classifier loss: 0.047819; batch adversarial loss: 0.453179\n",
      "epoch 102; iter: 0; batch classifier loss: 0.027790; batch adversarial loss: 0.462930\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047467; batch adversarial loss: 0.484520\n",
      "epoch 104; iter: 0; batch classifier loss: 0.024842; batch adversarial loss: 0.321885\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056904; batch adversarial loss: 0.527000\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033406; batch adversarial loss: 0.516258\n",
      "epoch 107; iter: 0; batch classifier loss: 0.078216; batch adversarial loss: 0.398898\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069267; batch adversarial loss: 0.415251\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054245; batch adversarial loss: 0.409713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.061619; batch adversarial loss: 0.324004\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035900; batch adversarial loss: 0.469383\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059669; batch adversarial loss: 0.362181\n",
      "epoch 113; iter: 0; batch classifier loss: 0.071464; batch adversarial loss: 0.450489\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041408; batch adversarial loss: 0.424627\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033683; batch adversarial loss: 0.510253\n",
      "epoch 116; iter: 0; batch classifier loss: 0.063323; batch adversarial loss: 0.432016\n",
      "epoch 117; iter: 0; batch classifier loss: 0.013986; batch adversarial loss: 0.458218\n",
      "epoch 118; iter: 0; batch classifier loss: 0.055652; batch adversarial loss: 0.464849\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021434; batch adversarial loss: 0.468411\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035951; batch adversarial loss: 0.467830\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034790; batch adversarial loss: 0.357469\n",
      "epoch 122; iter: 0; batch classifier loss: 0.024404; batch adversarial loss: 0.453875\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042778; batch adversarial loss: 0.461097\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023388; batch adversarial loss: 0.438546\n",
      "epoch 125; iter: 0; batch classifier loss: 0.065633; batch adversarial loss: 0.416610\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028394; batch adversarial loss: 0.462876\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048183; batch adversarial loss: 0.451988\n",
      "epoch 128; iter: 0; batch classifier loss: 0.046854; batch adversarial loss: 0.436753\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059833; batch adversarial loss: 0.458181\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037578; batch adversarial loss: 0.501884\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049323; batch adversarial loss: 0.450108\n",
      "epoch 132; iter: 0; batch classifier loss: 0.010557; batch adversarial loss: 0.610863\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021677; batch adversarial loss: 0.481784\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033401; batch adversarial loss: 0.479533\n",
      "epoch 135; iter: 0; batch classifier loss: 0.010652; batch adversarial loss: 0.563688\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037252; batch adversarial loss: 0.481358\n",
      "epoch 137; iter: 0; batch classifier loss: 0.006864; batch adversarial loss: 0.471820\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026774; batch adversarial loss: 0.480525\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021437; batch adversarial loss: 0.395366\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020997; batch adversarial loss: 0.424929\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033984; batch adversarial loss: 0.473058\n",
      "epoch 142; iter: 0; batch classifier loss: 0.011183; batch adversarial loss: 0.523419\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015488; batch adversarial loss: 0.458142\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022891; batch adversarial loss: 0.376199\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024509; batch adversarial loss: 0.419719\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020784; batch adversarial loss: 0.517568\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041533; batch adversarial loss: 0.412973\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035858; batch adversarial loss: 0.444898\n",
      "epoch 149; iter: 0; batch classifier loss: 0.009517; batch adversarial loss: 0.394009\n",
      "epoch 150; iter: 0; batch classifier loss: 0.066339; batch adversarial loss: 0.534577\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030982; batch adversarial loss: 0.445503\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022256; batch adversarial loss: 0.445950\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019210; batch adversarial loss: 0.534867\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017670; batch adversarial loss: 0.461979\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038770; batch adversarial loss: 0.508063\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012035; batch adversarial loss: 0.452114\n",
      "epoch 157; iter: 0; batch classifier loss: 0.008132; batch adversarial loss: 0.479649\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045292; batch adversarial loss: 0.445130\n",
      "epoch 159; iter: 0; batch classifier loss: 0.063017; batch adversarial loss: 0.386503\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029051; batch adversarial loss: 0.390393\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016678; batch adversarial loss: 0.461271\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025160; batch adversarial loss: 0.523960\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011142; batch adversarial loss: 0.460228\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012828; batch adversarial loss: 0.459873\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036879; batch adversarial loss: 0.393274\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020939; batch adversarial loss: 0.398935\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029439; batch adversarial loss: 0.475523\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029893; batch adversarial loss: 0.485256\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016357; batch adversarial loss: 0.473576\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039867; batch adversarial loss: 0.381307\n",
      "epoch 171; iter: 0; batch classifier loss: 0.043662; batch adversarial loss: 0.529277\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030369; batch adversarial loss: 0.458642\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036266; batch adversarial loss: 0.471455\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031162; batch adversarial loss: 0.444758\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006314; batch adversarial loss: 0.477547\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013576; batch adversarial loss: 0.440626\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020016; batch adversarial loss: 0.524788\n",
      "epoch 178; iter: 0; batch classifier loss: 0.052039; batch adversarial loss: 0.478143\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035142; batch adversarial loss: 0.473735\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016475; batch adversarial loss: 0.327333\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029501; batch adversarial loss: 0.452934\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020365; batch adversarial loss: 0.411432\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015716; batch adversarial loss: 0.501500\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012035; batch adversarial loss: 0.432196\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022334; batch adversarial loss: 0.395447\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035769; batch adversarial loss: 0.441135\n",
      "epoch 187; iter: 0; batch classifier loss: 0.051392; batch adversarial loss: 0.412991\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020190; batch adversarial loss: 0.435701\n",
      "epoch 189; iter: 0; batch classifier loss: 0.039460; batch adversarial loss: 0.465326\n",
      "epoch 190; iter: 0; batch classifier loss: 0.044314; batch adversarial loss: 0.434500\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020485; batch adversarial loss: 0.521967\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018244; batch adversarial loss: 0.411698\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023434; batch adversarial loss: 0.386703\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023026; batch adversarial loss: 0.436987\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013623; batch adversarial loss: 0.461902\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006181; batch adversarial loss: 0.428749\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008064; batch adversarial loss: 0.326917\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016696; batch adversarial loss: 0.450875\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025189; batch adversarial loss: 0.417987\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691575; batch adversarial loss: 0.468071\n",
      "epoch 1; iter: 0; batch classifier loss: 0.463230; batch adversarial loss: 0.564957\n",
      "epoch 2; iter: 0; batch classifier loss: 0.316225; batch adversarial loss: 0.602438\n",
      "epoch 3; iter: 0; batch classifier loss: 0.325133; batch adversarial loss: 0.632001\n",
      "epoch 4; iter: 0; batch classifier loss: 0.325586; batch adversarial loss: 0.575156\n",
      "epoch 5; iter: 0; batch classifier loss: 0.378426; batch adversarial loss: 0.562886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.438435; batch adversarial loss: 0.640708\n",
      "epoch 7; iter: 0; batch classifier loss: 0.378513; batch adversarial loss: 0.566715\n",
      "epoch 8; iter: 0; batch classifier loss: 0.331001; batch adversarial loss: 0.539289\n",
      "epoch 9; iter: 0; batch classifier loss: 0.331438; batch adversarial loss: 0.582534\n",
      "epoch 10; iter: 0; batch classifier loss: 0.294125; batch adversarial loss: 0.547760\n",
      "epoch 11; iter: 0; batch classifier loss: 0.353488; batch adversarial loss: 0.516880\n",
      "epoch 12; iter: 0; batch classifier loss: 0.357696; batch adversarial loss: 0.525842\n",
      "epoch 13; iter: 0; batch classifier loss: 0.436862; batch adversarial loss: 0.518465\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510694; batch adversarial loss: 0.594885\n",
      "epoch 15; iter: 0; batch classifier loss: 0.503765; batch adversarial loss: 0.524586\n",
      "epoch 16; iter: 0; batch classifier loss: 0.546054; batch adversarial loss: 0.453880\n",
      "epoch 17; iter: 0; batch classifier loss: 0.284159; batch adversarial loss: 0.457061\n",
      "epoch 18; iter: 0; batch classifier loss: 0.232750; batch adversarial loss: 0.484190\n",
      "epoch 19; iter: 0; batch classifier loss: 0.176248; batch adversarial loss: 0.507374\n",
      "epoch 20; iter: 0; batch classifier loss: 0.281075; batch adversarial loss: 0.515974\n",
      "epoch 21; iter: 0; batch classifier loss: 0.265598; batch adversarial loss: 0.443483\n",
      "epoch 22; iter: 0; batch classifier loss: 0.202390; batch adversarial loss: 0.503119\n",
      "epoch 23; iter: 0; batch classifier loss: 0.221005; batch adversarial loss: 0.378649\n",
      "epoch 24; iter: 0; batch classifier loss: 0.166004; batch adversarial loss: 0.400429\n",
      "epoch 25; iter: 0; batch classifier loss: 0.178552; batch adversarial loss: 0.608390\n",
      "epoch 26; iter: 0; batch classifier loss: 0.132062; batch adversarial loss: 0.370006\n",
      "epoch 27; iter: 0; batch classifier loss: 0.193051; batch adversarial loss: 0.462143\n",
      "epoch 28; iter: 0; batch classifier loss: 0.145085; batch adversarial loss: 0.472805\n",
      "epoch 29; iter: 0; batch classifier loss: 0.104581; batch adversarial loss: 0.499945\n",
      "epoch 30; iter: 0; batch classifier loss: 0.141666; batch adversarial loss: 0.414386\n",
      "epoch 31; iter: 0; batch classifier loss: 0.132210; batch adversarial loss: 0.509004\n",
      "epoch 32; iter: 0; batch classifier loss: 0.189595; batch adversarial loss: 0.553010\n",
      "epoch 33; iter: 0; batch classifier loss: 0.123891; batch adversarial loss: 0.429375\n",
      "epoch 34; iter: 0; batch classifier loss: 0.130836; batch adversarial loss: 0.407485\n",
      "epoch 35; iter: 0; batch classifier loss: 0.108597; batch adversarial loss: 0.437479\n",
      "epoch 36; iter: 0; batch classifier loss: 0.082060; batch adversarial loss: 0.580221\n",
      "epoch 37; iter: 0; batch classifier loss: 0.070881; batch adversarial loss: 0.413212\n",
      "epoch 38; iter: 0; batch classifier loss: 0.092438; batch adversarial loss: 0.484876\n",
      "epoch 39; iter: 0; batch classifier loss: 0.085274; batch adversarial loss: 0.440286\n",
      "epoch 40; iter: 0; batch classifier loss: 0.117247; batch adversarial loss: 0.434680\n",
      "epoch 41; iter: 0; batch classifier loss: 0.168878; batch adversarial loss: 0.473606\n",
      "epoch 42; iter: 0; batch classifier loss: 0.108279; batch adversarial loss: 0.396760\n",
      "epoch 43; iter: 0; batch classifier loss: 0.118818; batch adversarial loss: 0.408918\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127235; batch adversarial loss: 0.421609\n",
      "epoch 45; iter: 0; batch classifier loss: 0.137032; batch adversarial loss: 0.498186\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117105; batch adversarial loss: 0.435833\n",
      "epoch 47; iter: 0; batch classifier loss: 0.131449; batch adversarial loss: 0.405414\n",
      "epoch 48; iter: 0; batch classifier loss: 0.115868; batch adversarial loss: 0.466665\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101280; batch adversarial loss: 0.419972\n",
      "epoch 50; iter: 0; batch classifier loss: 0.136162; batch adversarial loss: 0.427028\n",
      "epoch 51; iter: 0; batch classifier loss: 0.104213; batch adversarial loss: 0.499559\n",
      "epoch 52; iter: 0; batch classifier loss: 0.164574; batch adversarial loss: 0.415266\n",
      "epoch 53; iter: 0; batch classifier loss: 0.100370; batch adversarial loss: 0.412767\n",
      "epoch 54; iter: 0; batch classifier loss: 0.129615; batch adversarial loss: 0.446385\n",
      "epoch 55; iter: 0; batch classifier loss: 0.124754; batch adversarial loss: 0.448243\n",
      "epoch 56; iter: 0; batch classifier loss: 0.110698; batch adversarial loss: 0.436371\n",
      "epoch 57; iter: 0; batch classifier loss: 0.137380; batch adversarial loss: 0.444134\n",
      "epoch 58; iter: 0; batch classifier loss: 0.085499; batch adversarial loss: 0.508089\n",
      "epoch 59; iter: 0; batch classifier loss: 0.126666; batch adversarial loss: 0.492591\n",
      "epoch 60; iter: 0; batch classifier loss: 0.187919; batch adversarial loss: 0.466773\n",
      "epoch 61; iter: 0; batch classifier loss: 0.141751; batch adversarial loss: 0.509637\n",
      "epoch 62; iter: 0; batch classifier loss: 0.140261; batch adversarial loss: 0.476471\n",
      "epoch 63; iter: 0; batch classifier loss: 0.120049; batch adversarial loss: 0.391567\n",
      "epoch 64; iter: 0; batch classifier loss: 0.107864; batch adversarial loss: 0.474962\n",
      "epoch 65; iter: 0; batch classifier loss: 0.130915; batch adversarial loss: 0.467894\n",
      "epoch 66; iter: 0; batch classifier loss: 0.104415; batch adversarial loss: 0.394606\n",
      "epoch 67; iter: 0; batch classifier loss: 0.130920; batch adversarial loss: 0.450525\n",
      "epoch 68; iter: 0; batch classifier loss: 0.121328; batch adversarial loss: 0.467955\n",
      "epoch 69; iter: 0; batch classifier loss: 0.151791; batch adversarial loss: 0.333643\n",
      "epoch 70; iter: 0; batch classifier loss: 0.174007; batch adversarial loss: 0.496581\n",
      "epoch 71; iter: 0; batch classifier loss: 0.163161; batch adversarial loss: 0.407662\n",
      "epoch 72; iter: 0; batch classifier loss: 0.145459; batch adversarial loss: 0.407787\n",
      "epoch 73; iter: 0; batch classifier loss: 0.146414; batch adversarial loss: 0.486529\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066200; batch adversarial loss: 0.435590\n",
      "epoch 75; iter: 0; batch classifier loss: 0.118529; batch adversarial loss: 0.466704\n",
      "epoch 76; iter: 0; batch classifier loss: 0.122995; batch adversarial loss: 0.469375\n",
      "epoch 77; iter: 0; batch classifier loss: 0.112575; batch adversarial loss: 0.534015\n",
      "epoch 78; iter: 0; batch classifier loss: 0.178571; batch adversarial loss: 0.472579\n",
      "epoch 79; iter: 0; batch classifier loss: 0.113012; batch adversarial loss: 0.421660\n",
      "epoch 80; iter: 0; batch classifier loss: 0.148525; batch adversarial loss: 0.456672\n",
      "epoch 81; iter: 0; batch classifier loss: 0.118503; batch adversarial loss: 0.447590\n",
      "epoch 82; iter: 0; batch classifier loss: 0.096715; batch adversarial loss: 0.468919\n",
      "epoch 83; iter: 0; batch classifier loss: 0.101315; batch adversarial loss: 0.469136\n",
      "epoch 84; iter: 0; batch classifier loss: 0.119903; batch adversarial loss: 0.356764\n",
      "epoch 85; iter: 0; batch classifier loss: 0.148296; batch adversarial loss: 0.435146\n",
      "epoch 86; iter: 0; batch classifier loss: 0.133810; batch adversarial loss: 0.504736\n",
      "epoch 87; iter: 0; batch classifier loss: 0.155605; batch adversarial loss: 0.411213\n",
      "epoch 88; iter: 0; batch classifier loss: 0.171836; batch adversarial loss: 0.391335\n",
      "epoch 89; iter: 0; batch classifier loss: 0.135005; batch adversarial loss: 0.472774\n",
      "epoch 90; iter: 0; batch classifier loss: 0.108311; batch adversarial loss: 0.430310\n",
      "epoch 91; iter: 0; batch classifier loss: 0.137199; batch adversarial loss: 0.467248\n",
      "epoch 92; iter: 0; batch classifier loss: 0.175209; batch adversarial loss: 0.504768\n",
      "epoch 93; iter: 0; batch classifier loss: 0.133856; batch adversarial loss: 0.458232\n",
      "epoch 94; iter: 0; batch classifier loss: 0.106411; batch adversarial loss: 0.570148\n",
      "epoch 95; iter: 0; batch classifier loss: 0.108699; batch adversarial loss: 0.491974\n",
      "epoch 96; iter: 0; batch classifier loss: 0.134282; batch adversarial loss: 0.490219\n",
      "epoch 97; iter: 0; batch classifier loss: 0.164617; batch adversarial loss: 0.420336\n",
      "epoch 98; iter: 0; batch classifier loss: 0.106837; batch adversarial loss: 0.327000\n",
      "epoch 99; iter: 0; batch classifier loss: 0.175743; batch adversarial loss: 0.383000\n",
      "epoch 100; iter: 0; batch classifier loss: 0.180248; batch adversarial loss: 0.463278\n",
      "epoch 101; iter: 0; batch classifier loss: 0.180275; batch adversarial loss: 0.353938\n",
      "epoch 102; iter: 0; batch classifier loss: 0.088545; batch adversarial loss: 0.481867\n",
      "epoch 103; iter: 0; batch classifier loss: 0.169470; batch adversarial loss: 0.391343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.172301; batch adversarial loss: 0.508972\n",
      "epoch 105; iter: 0; batch classifier loss: 0.124017; batch adversarial loss: 0.455877\n",
      "epoch 106; iter: 0; batch classifier loss: 0.133447; batch adversarial loss: 0.567285\n",
      "epoch 107; iter: 0; batch classifier loss: 0.136938; batch adversarial loss: 0.433145\n",
      "epoch 108; iter: 0; batch classifier loss: 0.153220; batch adversarial loss: 0.399291\n",
      "epoch 109; iter: 0; batch classifier loss: 0.160751; batch adversarial loss: 0.427753\n",
      "epoch 110; iter: 0; batch classifier loss: 0.117413; batch adversarial loss: 0.464045\n",
      "epoch 111; iter: 0; batch classifier loss: 0.144897; batch adversarial loss: 0.395092\n",
      "epoch 112; iter: 0; batch classifier loss: 0.101723; batch adversarial loss: 0.515918\n",
      "epoch 113; iter: 0; batch classifier loss: 0.123353; batch adversarial loss: 0.521284\n",
      "epoch 114; iter: 0; batch classifier loss: 0.202187; batch adversarial loss: 0.462732\n",
      "epoch 115; iter: 0; batch classifier loss: 0.189773; batch adversarial loss: 0.505625\n",
      "epoch 116; iter: 0; batch classifier loss: 0.079743; batch adversarial loss: 0.496951\n",
      "epoch 117; iter: 0; batch classifier loss: 0.123249; batch adversarial loss: 0.484883\n",
      "epoch 118; iter: 0; batch classifier loss: 0.087670; batch adversarial loss: 0.477603\n",
      "epoch 119; iter: 0; batch classifier loss: 0.146499; batch adversarial loss: 0.499978\n",
      "epoch 120; iter: 0; batch classifier loss: 0.093843; batch adversarial loss: 0.457201\n",
      "epoch 121; iter: 0; batch classifier loss: 0.106334; batch adversarial loss: 0.486132\n",
      "epoch 122; iter: 0; batch classifier loss: 0.093182; batch adversarial loss: 0.383644\n",
      "epoch 123; iter: 0; batch classifier loss: 0.114483; batch adversarial loss: 0.443042\n",
      "epoch 124; iter: 0; batch classifier loss: 0.087057; batch adversarial loss: 0.394318\n",
      "epoch 125; iter: 0; batch classifier loss: 0.133623; batch adversarial loss: 0.437424\n",
      "epoch 126; iter: 0; batch classifier loss: 0.100720; batch adversarial loss: 0.500886\n",
      "epoch 127; iter: 0; batch classifier loss: 0.096726; batch adversarial loss: 0.428000\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039437; batch adversarial loss: 0.542971\n",
      "epoch 129; iter: 0; batch classifier loss: 0.058821; batch adversarial loss: 0.445321\n",
      "epoch 130; iter: 0; batch classifier loss: 0.072270; batch adversarial loss: 0.518716\n",
      "epoch 131; iter: 0; batch classifier loss: 0.101255; batch adversarial loss: 0.455868\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057799; batch adversarial loss: 0.481901\n",
      "epoch 133; iter: 0; batch classifier loss: 0.050735; batch adversarial loss: 0.432521\n",
      "epoch 134; iter: 0; batch classifier loss: 0.054562; batch adversarial loss: 0.470443\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042050; batch adversarial loss: 0.529672\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024197; batch adversarial loss: 0.411601\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040340; batch adversarial loss: 0.538996\n",
      "epoch 138; iter: 0; batch classifier loss: 0.054054; batch adversarial loss: 0.482549\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041050; batch adversarial loss: 0.532747\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046720; batch adversarial loss: 0.350967\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042214; batch adversarial loss: 0.509914\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045128; batch adversarial loss: 0.465060\n",
      "epoch 143; iter: 0; batch classifier loss: 0.058398; batch adversarial loss: 0.404917\n",
      "epoch 144; iter: 0; batch classifier loss: 0.071931; batch adversarial loss: 0.361578\n",
      "epoch 145; iter: 0; batch classifier loss: 0.058928; batch adversarial loss: 0.511269\n",
      "epoch 146; iter: 0; batch classifier loss: 0.074592; batch adversarial loss: 0.312247\n",
      "epoch 147; iter: 0; batch classifier loss: 0.071731; batch adversarial loss: 0.372360\n",
      "epoch 148; iter: 0; batch classifier loss: 0.051127; batch adversarial loss: 0.373869\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014199; batch adversarial loss: 0.457216\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024995; batch adversarial loss: 0.427009\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022355; batch adversarial loss: 0.479869\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039807; batch adversarial loss: 0.458769\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030127; batch adversarial loss: 0.569481\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018739; batch adversarial loss: 0.466143\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033674; batch adversarial loss: 0.425980\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044174; batch adversarial loss: 0.434114\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031956; batch adversarial loss: 0.378770\n",
      "epoch 158; iter: 0; batch classifier loss: 0.040318; batch adversarial loss: 0.465850\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015136; batch adversarial loss: 0.438451\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036314; batch adversarial loss: 0.468275\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035084; batch adversarial loss: 0.484666\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025474; batch adversarial loss: 0.393958\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022885; batch adversarial loss: 0.462820\n",
      "epoch 164; iter: 0; batch classifier loss: 0.054409; batch adversarial loss: 0.438675\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014438; batch adversarial loss: 0.421390\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021521; batch adversarial loss: 0.491570\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011266; batch adversarial loss: 0.503007\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029766; batch adversarial loss: 0.381095\n",
      "epoch 169; iter: 0; batch classifier loss: 0.049306; batch adversarial loss: 0.540103\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010450; batch adversarial loss: 0.365880\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028221; batch adversarial loss: 0.477468\n",
      "epoch 172; iter: 0; batch classifier loss: 0.052415; batch adversarial loss: 0.417595\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022271; batch adversarial loss: 0.468995\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021686; batch adversarial loss: 0.495450\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029131; batch adversarial loss: 0.570789\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040980; batch adversarial loss: 0.383827\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030034; batch adversarial loss: 0.406862\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014112; batch adversarial loss: 0.438558\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037700; batch adversarial loss: 0.457849\n",
      "epoch 180; iter: 0; batch classifier loss: 0.038530; batch adversarial loss: 0.398656\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029801; batch adversarial loss: 0.458207\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034207; batch adversarial loss: 0.477144\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013588; batch adversarial loss: 0.384128\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013034; batch adversarial loss: 0.479609\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022496; batch adversarial loss: 0.551425\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019177; batch adversarial loss: 0.484621\n",
      "epoch 187; iter: 0; batch classifier loss: 0.047674; batch adversarial loss: 0.431803\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020845; batch adversarial loss: 0.443062\n",
      "epoch 189; iter: 0; batch classifier loss: 0.047606; batch adversarial loss: 0.476106\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011218; batch adversarial loss: 0.455502\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023559; batch adversarial loss: 0.456003\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006042; batch adversarial loss: 0.374893\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009923; batch adversarial loss: 0.418872\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023930; batch adversarial loss: 0.474843\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012436; batch adversarial loss: 0.347374\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018528; batch adversarial loss: 0.439164\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015108; batch adversarial loss: 0.378555\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022066; batch adversarial loss: 0.476633\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013324; batch adversarial loss: 0.384955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.694998; batch adversarial loss: 0.612719\n",
      "epoch 1; iter: 0; batch classifier loss: 0.390467; batch adversarial loss: 0.628777\n",
      "epoch 2; iter: 0; batch classifier loss: 0.407724; batch adversarial loss: 0.599350\n",
      "epoch 3; iter: 0; batch classifier loss: 0.399495; batch adversarial loss: 0.578998\n",
      "epoch 4; iter: 0; batch classifier loss: 0.334319; batch adversarial loss: 0.543135\n",
      "epoch 5; iter: 0; batch classifier loss: 0.440283; batch adversarial loss: 0.544180\n",
      "epoch 6; iter: 0; batch classifier loss: 0.263751; batch adversarial loss: 0.594606\n",
      "epoch 7; iter: 0; batch classifier loss: 0.247624; batch adversarial loss: 0.528041\n",
      "epoch 8; iter: 0; batch classifier loss: 0.348255; batch adversarial loss: 0.493630\n",
      "epoch 9; iter: 0; batch classifier loss: 0.471879; batch adversarial loss: 0.551652\n",
      "epoch 10; iter: 0; batch classifier loss: 0.323582; batch adversarial loss: 0.553490\n",
      "epoch 11; iter: 0; batch classifier loss: 0.397820; batch adversarial loss: 0.553279\n",
      "epoch 12; iter: 0; batch classifier loss: 0.429135; batch adversarial loss: 0.587058\n",
      "epoch 13; iter: 0; batch classifier loss: 0.431307; batch adversarial loss: 0.536900\n",
      "epoch 14; iter: 0; batch classifier loss: 0.578541; batch adversarial loss: 0.541102\n",
      "epoch 15; iter: 0; batch classifier loss: 0.379107; batch adversarial loss: 0.479169\n",
      "epoch 16; iter: 0; batch classifier loss: 0.261606; batch adversarial loss: 0.511685\n",
      "epoch 17; iter: 0; batch classifier loss: 0.254741; batch adversarial loss: 0.510604\n",
      "epoch 18; iter: 0; batch classifier loss: 0.209707; batch adversarial loss: 0.490290\n",
      "epoch 19; iter: 0; batch classifier loss: 0.202278; batch adversarial loss: 0.513688\n",
      "epoch 20; iter: 0; batch classifier loss: 0.192703; batch adversarial loss: 0.450809\n",
      "epoch 21; iter: 0; batch classifier loss: 0.115090; batch adversarial loss: 0.477530\n",
      "epoch 22; iter: 0; batch classifier loss: 0.184851; batch adversarial loss: 0.511749\n",
      "epoch 23; iter: 0; batch classifier loss: 0.179270; batch adversarial loss: 0.480712\n",
      "epoch 24; iter: 0; batch classifier loss: 0.140533; batch adversarial loss: 0.441706\n",
      "epoch 25; iter: 0; batch classifier loss: 0.189508; batch adversarial loss: 0.443998\n",
      "epoch 26; iter: 0; batch classifier loss: 0.127679; batch adversarial loss: 0.469662\n",
      "epoch 27; iter: 0; batch classifier loss: 0.135099; batch adversarial loss: 0.418518\n",
      "epoch 28; iter: 0; batch classifier loss: 0.182697; batch adversarial loss: 0.441102\n",
      "epoch 29; iter: 0; batch classifier loss: 0.107057; batch adversarial loss: 0.442783\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153244; batch adversarial loss: 0.445087\n",
      "epoch 31; iter: 0; batch classifier loss: 0.139108; batch adversarial loss: 0.412630\n",
      "epoch 32; iter: 0; batch classifier loss: 0.111754; batch adversarial loss: 0.407393\n",
      "epoch 33; iter: 0; batch classifier loss: 0.213640; batch adversarial loss: 0.426086\n",
      "epoch 34; iter: 0; batch classifier loss: 0.118015; batch adversarial loss: 0.411343\n",
      "epoch 35; iter: 0; batch classifier loss: 0.126951; batch adversarial loss: 0.398736\n",
      "epoch 36; iter: 0; batch classifier loss: 0.113494; batch adversarial loss: 0.452392\n",
      "epoch 37; iter: 0; batch classifier loss: 0.117972; batch adversarial loss: 0.388101\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127234; batch adversarial loss: 0.442637\n",
      "epoch 39; iter: 0; batch classifier loss: 0.121041; batch adversarial loss: 0.370141\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099413; batch adversarial loss: 0.518036\n",
      "epoch 41; iter: 0; batch classifier loss: 0.076200; batch adversarial loss: 0.503273\n",
      "epoch 42; iter: 0; batch classifier loss: 0.160378; batch adversarial loss: 0.452220\n",
      "epoch 43; iter: 0; batch classifier loss: 0.095127; batch adversarial loss: 0.565937\n",
      "epoch 44; iter: 0; batch classifier loss: 0.133839; batch adversarial loss: 0.403560\n",
      "epoch 45; iter: 0; batch classifier loss: 0.085251; batch adversarial loss: 0.480043\n",
      "epoch 46; iter: 0; batch classifier loss: 0.090201; batch adversarial loss: 0.469173\n",
      "epoch 47; iter: 0; batch classifier loss: 0.102245; batch adversarial loss: 0.526748\n",
      "epoch 48; iter: 0; batch classifier loss: 0.135123; batch adversarial loss: 0.443948\n",
      "epoch 49; iter: 0; batch classifier loss: 0.109344; batch adversarial loss: 0.519550\n",
      "epoch 50; iter: 0; batch classifier loss: 0.053163; batch adversarial loss: 0.454269\n",
      "epoch 51; iter: 0; batch classifier loss: 0.105070; batch adversarial loss: 0.447474\n",
      "epoch 52; iter: 0; batch classifier loss: 0.104296; batch adversarial loss: 0.480352\n",
      "epoch 53; iter: 0; batch classifier loss: 0.080703; batch adversarial loss: 0.481919\n",
      "epoch 54; iter: 0; batch classifier loss: 0.156802; batch adversarial loss: 0.460878\n",
      "epoch 55; iter: 0; batch classifier loss: 0.113703; batch adversarial loss: 0.561960\n",
      "epoch 56; iter: 0; batch classifier loss: 0.071121; batch adversarial loss: 0.479329\n",
      "epoch 57; iter: 0; batch classifier loss: 0.065335; batch adversarial loss: 0.547839\n",
      "epoch 58; iter: 0; batch classifier loss: 0.112015; batch adversarial loss: 0.469059\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083902; batch adversarial loss: 0.462848\n",
      "epoch 60; iter: 0; batch classifier loss: 0.074411; batch adversarial loss: 0.419222\n",
      "epoch 61; iter: 0; batch classifier loss: 0.148347; batch adversarial loss: 0.410412\n",
      "epoch 62; iter: 0; batch classifier loss: 0.077234; batch adversarial loss: 0.506678\n",
      "epoch 63; iter: 0; batch classifier loss: 0.046357; batch adversarial loss: 0.462179\n",
      "epoch 64; iter: 0; batch classifier loss: 0.126284; batch adversarial loss: 0.349538\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077835; batch adversarial loss: 0.523044\n",
      "epoch 66; iter: 0; batch classifier loss: 0.053790; batch adversarial loss: 0.409072\n",
      "epoch 67; iter: 0; batch classifier loss: 0.072176; batch adversarial loss: 0.453206\n",
      "epoch 68; iter: 0; batch classifier loss: 0.036792; batch adversarial loss: 0.430766\n",
      "epoch 69; iter: 0; batch classifier loss: 0.105241; batch adversarial loss: 0.445660\n",
      "epoch 70; iter: 0; batch classifier loss: 0.109613; batch adversarial loss: 0.455395\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071203; batch adversarial loss: 0.420667\n",
      "epoch 72; iter: 0; batch classifier loss: 0.058634; batch adversarial loss: 0.413673\n",
      "epoch 73; iter: 0; batch classifier loss: 0.102114; batch adversarial loss: 0.399184\n",
      "epoch 74; iter: 0; batch classifier loss: 0.097013; batch adversarial loss: 0.450423\n",
      "epoch 75; iter: 0; batch classifier loss: 0.058305; batch adversarial loss: 0.512405\n",
      "epoch 76; iter: 0; batch classifier loss: 0.046180; batch adversarial loss: 0.497053\n",
      "epoch 77; iter: 0; batch classifier loss: 0.041199; batch adversarial loss: 0.464549\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061738; batch adversarial loss: 0.513717\n",
      "epoch 79; iter: 0; batch classifier loss: 0.042390; batch adversarial loss: 0.468063\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070317; batch adversarial loss: 0.388680\n",
      "epoch 81; iter: 0; batch classifier loss: 0.089201; batch adversarial loss: 0.489213\n",
      "epoch 82; iter: 0; batch classifier loss: 0.069961; batch adversarial loss: 0.464254\n",
      "epoch 83; iter: 0; batch classifier loss: 0.077138; batch adversarial loss: 0.425353\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080746; batch adversarial loss: 0.478362\n",
      "epoch 85; iter: 0; batch classifier loss: 0.086819; batch adversarial loss: 0.476585\n",
      "epoch 86; iter: 0; batch classifier loss: 0.049481; batch adversarial loss: 0.436161\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076476; batch adversarial loss: 0.400344\n",
      "epoch 88; iter: 0; batch classifier loss: 0.091827; batch adversarial loss: 0.494212\n",
      "epoch 89; iter: 0; batch classifier loss: 0.101712; batch adversarial loss: 0.563980\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066310; batch adversarial loss: 0.435819\n",
      "epoch 91; iter: 0; batch classifier loss: 0.029390; batch adversarial loss: 0.469160\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074740; batch adversarial loss: 0.423841\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063294; batch adversarial loss: 0.558491\n",
      "epoch 94; iter: 0; batch classifier loss: 0.089800; batch adversarial loss: 0.401439\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042717; batch adversarial loss: 0.474558\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066917; batch adversarial loss: 0.490680\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048649; batch adversarial loss: 0.480140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.054360; batch adversarial loss: 0.479326\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049577; batch adversarial loss: 0.383227\n",
      "epoch 100; iter: 0; batch classifier loss: 0.095197; batch adversarial loss: 0.486846\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063514; batch adversarial loss: 0.449282\n",
      "epoch 102; iter: 0; batch classifier loss: 0.088314; batch adversarial loss: 0.568631\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061683; batch adversarial loss: 0.481414\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058251; batch adversarial loss: 0.524574\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057775; batch adversarial loss: 0.517724\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054902; batch adversarial loss: 0.473378\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050196; batch adversarial loss: 0.516881\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036987; batch adversarial loss: 0.509742\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040508; batch adversarial loss: 0.474103\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028918; batch adversarial loss: 0.454970\n",
      "epoch 111; iter: 0; batch classifier loss: 0.052005; batch adversarial loss: 0.369250\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043982; batch adversarial loss: 0.447409\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048335; batch adversarial loss: 0.403998\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037641; batch adversarial loss: 0.475682\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049302; batch adversarial loss: 0.397566\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032104; batch adversarial loss: 0.397952\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032468; batch adversarial loss: 0.467723\n",
      "epoch 118; iter: 0; batch classifier loss: 0.017663; batch adversarial loss: 0.390801\n",
      "epoch 119; iter: 0; batch classifier loss: 0.064730; batch adversarial loss: 0.477773\n",
      "epoch 120; iter: 0; batch classifier loss: 0.071117; batch adversarial loss: 0.486265\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049729; batch adversarial loss: 0.487691\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062973; batch adversarial loss: 0.478300\n",
      "epoch 123; iter: 0; batch classifier loss: 0.071933; batch adversarial loss: 0.387535\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039706; batch adversarial loss: 0.460097\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029950; batch adversarial loss: 0.467221\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017269; batch adversarial loss: 0.456631\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043138; batch adversarial loss: 0.388534\n",
      "epoch 128; iter: 0; batch classifier loss: 0.050430; batch adversarial loss: 0.454049\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035067; batch adversarial loss: 0.459302\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025279; batch adversarial loss: 0.419056\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028815; batch adversarial loss: 0.446458\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025465; batch adversarial loss: 0.556562\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033691; batch adversarial loss: 0.498368\n",
      "epoch 134; iter: 0; batch classifier loss: 0.041660; batch adversarial loss: 0.488260\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038030; batch adversarial loss: 0.448832\n",
      "epoch 136; iter: 0; batch classifier loss: 0.059164; batch adversarial loss: 0.428754\n",
      "epoch 137; iter: 0; batch classifier loss: 0.009249; batch adversarial loss: 0.493191\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022799; batch adversarial loss: 0.410966\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015861; batch adversarial loss: 0.484035\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028874; batch adversarial loss: 0.463293\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022239; batch adversarial loss: 0.484752\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031811; batch adversarial loss: 0.405894\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018773; batch adversarial loss: 0.517096\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040539; batch adversarial loss: 0.403494\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020455; batch adversarial loss: 0.525110\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010518; batch adversarial loss: 0.401824\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023857; batch adversarial loss: 0.406030\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024727; batch adversarial loss: 0.484533\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028848; batch adversarial loss: 0.509849\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022198; batch adversarial loss: 0.351909\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030449; batch adversarial loss: 0.421450\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015604; batch adversarial loss: 0.472206\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025956; batch adversarial loss: 0.402773\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038695; batch adversarial loss: 0.464923\n",
      "epoch 155; iter: 0; batch classifier loss: 0.006315; batch adversarial loss: 0.357544\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024298; batch adversarial loss: 0.435157\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014226; batch adversarial loss: 0.469767\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024673; batch adversarial loss: 0.451550\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012895; batch adversarial loss: 0.364035\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021453; batch adversarial loss: 0.492331\n",
      "epoch 161; iter: 0; batch classifier loss: 0.071526; batch adversarial loss: 0.549346\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010504; batch adversarial loss: 0.401112\n",
      "epoch 163; iter: 0; batch classifier loss: 0.008371; batch adversarial loss: 0.440842\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023099; batch adversarial loss: 0.467681\n",
      "epoch 165; iter: 0; batch classifier loss: 0.007942; batch adversarial loss: 0.531363\n",
      "epoch 166; iter: 0; batch classifier loss: 0.039413; batch adversarial loss: 0.491609\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030479; batch adversarial loss: 0.486951\n",
      "epoch 168; iter: 0; batch classifier loss: 0.055258; batch adversarial loss: 0.389511\n",
      "epoch 169; iter: 0; batch classifier loss: 0.058327; batch adversarial loss: 0.396634\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018733; batch adversarial loss: 0.377087\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036535; batch adversarial loss: 0.485888\n",
      "epoch 172; iter: 0; batch classifier loss: 0.057501; batch adversarial loss: 0.431904\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038809; batch adversarial loss: 0.523637\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021537; batch adversarial loss: 0.481873\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033267; batch adversarial loss: 0.469871\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014979; batch adversarial loss: 0.483125\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036752; batch adversarial loss: 0.461902\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007195; batch adversarial loss: 0.465908\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032277; batch adversarial loss: 0.406916\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021503; batch adversarial loss: 0.436072\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014430; batch adversarial loss: 0.401651\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022239; batch adversarial loss: 0.381920\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026018; batch adversarial loss: 0.371933\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037654; batch adversarial loss: 0.355543\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042581; batch adversarial loss: 0.451745\n",
      "epoch 186; iter: 0; batch classifier loss: 0.052186; batch adversarial loss: 0.394976\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026637; batch adversarial loss: 0.379354\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011038; batch adversarial loss: 0.420924\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023997; batch adversarial loss: 0.437726\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008188; batch adversarial loss: 0.407584\n",
      "epoch 191; iter: 0; batch classifier loss: 0.054268; batch adversarial loss: 0.473213\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023268; batch adversarial loss: 0.414136\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021676; batch adversarial loss: 0.478725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.042673; batch adversarial loss: 0.391525\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008369; batch adversarial loss: 0.410088\n",
      "epoch 196; iter: 0; batch classifier loss: 0.051948; batch adversarial loss: 0.439656\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021722; batch adversarial loss: 0.462058\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029498; batch adversarial loss: 0.429183\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009148; batch adversarial loss: 0.450421\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724029; batch adversarial loss: 0.736120\n",
      "epoch 1; iter: 0; batch classifier loss: 0.517734; batch adversarial loss: 0.684142\n",
      "epoch 2; iter: 0; batch classifier loss: 0.401443; batch adversarial loss: 0.664133\n",
      "epoch 3; iter: 0; batch classifier loss: 0.368005; batch adversarial loss: 0.640776\n",
      "epoch 4; iter: 0; batch classifier loss: 0.294971; batch adversarial loss: 0.625301\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362422; batch adversarial loss: 0.567388\n",
      "epoch 6; iter: 0; batch classifier loss: 0.310768; batch adversarial loss: 0.550079\n",
      "epoch 7; iter: 0; batch classifier loss: 0.275664; batch adversarial loss: 0.522803\n",
      "epoch 8; iter: 0; batch classifier loss: 0.295775; batch adversarial loss: 0.486877\n",
      "epoch 9; iter: 0; batch classifier loss: 0.343904; batch adversarial loss: 0.470016\n",
      "epoch 10; iter: 0; batch classifier loss: 0.221934; batch adversarial loss: 0.474472\n",
      "epoch 11; iter: 0; batch classifier loss: 0.262293; batch adversarial loss: 0.482788\n",
      "epoch 12; iter: 0; batch classifier loss: 0.178066; batch adversarial loss: 0.476804\n",
      "epoch 13; iter: 0; batch classifier loss: 0.183699; batch adversarial loss: 0.448226\n",
      "epoch 14; iter: 0; batch classifier loss: 0.172028; batch adversarial loss: 0.485622\n",
      "epoch 15; iter: 0; batch classifier loss: 0.181626; batch adversarial loss: 0.433129\n",
      "epoch 16; iter: 0; batch classifier loss: 0.149123; batch adversarial loss: 0.452480\n",
      "epoch 17; iter: 0; batch classifier loss: 0.185364; batch adversarial loss: 0.564785\n",
      "epoch 18; iter: 0; batch classifier loss: 0.140443; batch adversarial loss: 0.430125\n",
      "epoch 19; iter: 0; batch classifier loss: 0.170892; batch adversarial loss: 0.526578\n",
      "epoch 20; iter: 0; batch classifier loss: 0.108864; batch adversarial loss: 0.448228\n",
      "epoch 21; iter: 0; batch classifier loss: 0.122785; batch adversarial loss: 0.512465\n",
      "epoch 22; iter: 0; batch classifier loss: 0.166528; batch adversarial loss: 0.451429\n",
      "epoch 23; iter: 0; batch classifier loss: 0.100928; batch adversarial loss: 0.476809\n",
      "epoch 24; iter: 0; batch classifier loss: 0.181423; batch adversarial loss: 0.475091\n",
      "epoch 25; iter: 0; batch classifier loss: 0.198743; batch adversarial loss: 0.586238\n",
      "epoch 26; iter: 0; batch classifier loss: 0.170757; batch adversarial loss: 0.579908\n",
      "epoch 27; iter: 0; batch classifier loss: 0.157631; batch adversarial loss: 0.578843\n",
      "epoch 28; iter: 0; batch classifier loss: 0.150096; batch adversarial loss: 0.409680\n",
      "epoch 29; iter: 0; batch classifier loss: 0.175307; batch adversarial loss: 0.545850\n",
      "epoch 30; iter: 0; batch classifier loss: 0.164303; batch adversarial loss: 0.596487\n",
      "epoch 31; iter: 0; batch classifier loss: 0.158562; batch adversarial loss: 0.444401\n",
      "epoch 32; iter: 0; batch classifier loss: 0.163623; batch adversarial loss: 0.463201\n",
      "epoch 33; iter: 0; batch classifier loss: 0.228692; batch adversarial loss: 0.572575\n",
      "epoch 34; iter: 0; batch classifier loss: 0.168216; batch adversarial loss: 0.553010\n",
      "epoch 35; iter: 0; batch classifier loss: 0.213373; batch adversarial loss: 0.515928\n",
      "epoch 36; iter: 0; batch classifier loss: 0.174186; batch adversarial loss: 0.508554\n",
      "epoch 37; iter: 0; batch classifier loss: 0.174706; batch adversarial loss: 0.597078\n",
      "epoch 38; iter: 0; batch classifier loss: 0.231503; batch adversarial loss: 0.428918\n",
      "epoch 39; iter: 0; batch classifier loss: 0.245640; batch adversarial loss: 0.498542\n",
      "epoch 40; iter: 0; batch classifier loss: 0.108826; batch adversarial loss: 0.571300\n",
      "epoch 41; iter: 0; batch classifier loss: 0.091834; batch adversarial loss: 0.416748\n",
      "epoch 42; iter: 0; batch classifier loss: 0.108567; batch adversarial loss: 0.484578\n",
      "epoch 43; iter: 0; batch classifier loss: 0.054182; batch adversarial loss: 0.335123\n",
      "epoch 44; iter: 0; batch classifier loss: 0.077314; batch adversarial loss: 0.498918\n",
      "epoch 45; iter: 0; batch classifier loss: 0.068012; batch adversarial loss: 0.495248\n",
      "epoch 46; iter: 0; batch classifier loss: 0.028329; batch adversarial loss: 0.450461\n",
      "epoch 47; iter: 0; batch classifier loss: 0.125773; batch adversarial loss: 0.474114\n",
      "epoch 48; iter: 0; batch classifier loss: 0.066408; batch adversarial loss: 0.427575\n",
      "epoch 49; iter: 0; batch classifier loss: 0.051857; batch adversarial loss: 0.511956\n",
      "epoch 50; iter: 0; batch classifier loss: 0.104214; batch adversarial loss: 0.424978\n",
      "epoch 51; iter: 0; batch classifier loss: 0.050811; batch adversarial loss: 0.514225\n",
      "epoch 52; iter: 0; batch classifier loss: 0.040627; batch adversarial loss: 0.377517\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076491; batch adversarial loss: 0.479864\n",
      "epoch 54; iter: 0; batch classifier loss: 0.047358; batch adversarial loss: 0.439128\n",
      "epoch 55; iter: 0; batch classifier loss: 0.053957; batch adversarial loss: 0.451784\n",
      "epoch 56; iter: 0; batch classifier loss: 0.104664; batch adversarial loss: 0.435067\n",
      "epoch 57; iter: 0; batch classifier loss: 0.092080; batch adversarial loss: 0.486673\n",
      "epoch 58; iter: 0; batch classifier loss: 0.078678; batch adversarial loss: 0.492164\n",
      "epoch 59; iter: 0; batch classifier loss: 0.063980; batch adversarial loss: 0.441216\n",
      "epoch 60; iter: 0; batch classifier loss: 0.052023; batch adversarial loss: 0.414724\n",
      "epoch 61; iter: 0; batch classifier loss: 0.055017; batch adversarial loss: 0.535870\n",
      "epoch 62; iter: 0; batch classifier loss: 0.056577; batch adversarial loss: 0.451404\n",
      "epoch 63; iter: 0; batch classifier loss: 0.061701; batch adversarial loss: 0.498276\n",
      "epoch 64; iter: 0; batch classifier loss: 0.037167; batch adversarial loss: 0.412822\n",
      "epoch 65; iter: 0; batch classifier loss: 0.052106; batch adversarial loss: 0.489112\n",
      "epoch 66; iter: 0; batch classifier loss: 0.046057; batch adversarial loss: 0.609223\n",
      "epoch 67; iter: 0; batch classifier loss: 0.040586; batch adversarial loss: 0.476161\n",
      "epoch 68; iter: 0; batch classifier loss: 0.057895; batch adversarial loss: 0.507561\n",
      "epoch 69; iter: 0; batch classifier loss: 0.047997; batch adversarial loss: 0.525840\n",
      "epoch 70; iter: 0; batch classifier loss: 0.062454; batch adversarial loss: 0.474589\n",
      "epoch 71; iter: 0; batch classifier loss: 0.080714; batch adversarial loss: 0.425986\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074060; batch adversarial loss: 0.428773\n",
      "epoch 73; iter: 0; batch classifier loss: 0.058696; batch adversarial loss: 0.380348\n",
      "epoch 74; iter: 0; batch classifier loss: 0.047568; batch adversarial loss: 0.482992\n",
      "epoch 75; iter: 0; batch classifier loss: 0.064016; batch adversarial loss: 0.435708\n",
      "epoch 76; iter: 0; batch classifier loss: 0.041647; batch adversarial loss: 0.552024\n",
      "epoch 77; iter: 0; batch classifier loss: 0.053483; batch adversarial loss: 0.440338\n",
      "epoch 78; iter: 0; batch classifier loss: 0.050691; batch adversarial loss: 0.377134\n",
      "epoch 79; iter: 0; batch classifier loss: 0.073305; batch adversarial loss: 0.546416\n",
      "epoch 80; iter: 0; batch classifier loss: 0.066421; batch adversarial loss: 0.499868\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050811; batch adversarial loss: 0.483200\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052470; batch adversarial loss: 0.408777\n",
      "epoch 83; iter: 0; batch classifier loss: 0.057480; batch adversarial loss: 0.407082\n",
      "epoch 84; iter: 0; batch classifier loss: 0.069219; batch adversarial loss: 0.390302\n",
      "epoch 85; iter: 0; batch classifier loss: 0.032149; batch adversarial loss: 0.509489\n",
      "epoch 86; iter: 0; batch classifier loss: 0.042073; batch adversarial loss: 0.447392\n",
      "epoch 87; iter: 0; batch classifier loss: 0.034319; batch adversarial loss: 0.478566\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049310; batch adversarial loss: 0.494264\n",
      "epoch 89; iter: 0; batch classifier loss: 0.041986; batch adversarial loss: 0.417585\n",
      "epoch 90; iter: 0; batch classifier loss: 0.070836; batch adversarial loss: 0.360217\n",
      "epoch 91; iter: 0; batch classifier loss: 0.029545; batch adversarial loss: 0.428191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.051255; batch adversarial loss: 0.338771\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048209; batch adversarial loss: 0.515187\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039237; batch adversarial loss: 0.512005\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054365; batch adversarial loss: 0.423822\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059151; batch adversarial loss: 0.421678\n",
      "epoch 97; iter: 0; batch classifier loss: 0.086881; batch adversarial loss: 0.338964\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050695; batch adversarial loss: 0.512188\n",
      "epoch 99; iter: 0; batch classifier loss: 0.077646; batch adversarial loss: 0.422513\n",
      "epoch 100; iter: 0; batch classifier loss: 0.079724; batch adversarial loss: 0.463343\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075436; batch adversarial loss: 0.377726\n",
      "epoch 102; iter: 0; batch classifier loss: 0.077051; batch adversarial loss: 0.459287\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037858; batch adversarial loss: 0.366096\n",
      "epoch 104; iter: 0; batch classifier loss: 0.085410; batch adversarial loss: 0.496396\n",
      "epoch 105; iter: 0; batch classifier loss: 0.022678; batch adversarial loss: 0.422429\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058631; batch adversarial loss: 0.528738\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027241; batch adversarial loss: 0.339015\n",
      "epoch 108; iter: 0; batch classifier loss: 0.061703; batch adversarial loss: 0.398741\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042349; batch adversarial loss: 0.422968\n",
      "epoch 110; iter: 0; batch classifier loss: 0.020725; batch adversarial loss: 0.468091\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039859; batch adversarial loss: 0.480182\n",
      "epoch 112; iter: 0; batch classifier loss: 0.100898; batch adversarial loss: 0.486028\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033260; batch adversarial loss: 0.444350\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030003; batch adversarial loss: 0.400853\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035197; batch adversarial loss: 0.416815\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032235; batch adversarial loss: 0.534203\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048591; batch adversarial loss: 0.476953\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033272; batch adversarial loss: 0.384407\n",
      "epoch 119; iter: 0; batch classifier loss: 0.070377; batch adversarial loss: 0.446036\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043563; batch adversarial loss: 0.374958\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024847; batch adversarial loss: 0.528301\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036863; batch adversarial loss: 0.362575\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021528; batch adversarial loss: 0.484194\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040282; batch adversarial loss: 0.427557\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058493; batch adversarial loss: 0.485739\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033781; batch adversarial loss: 0.452910\n",
      "epoch 127; iter: 0; batch classifier loss: 0.063140; batch adversarial loss: 0.449167\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022216; batch adversarial loss: 0.431886\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026725; batch adversarial loss: 0.497882\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036884; batch adversarial loss: 0.412366\n",
      "epoch 131; iter: 0; batch classifier loss: 0.054259; batch adversarial loss: 0.484411\n",
      "epoch 132; iter: 0; batch classifier loss: 0.010773; batch adversarial loss: 0.422645\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013908; batch adversarial loss: 0.491536\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051009; batch adversarial loss: 0.447946\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011023; batch adversarial loss: 0.446505\n",
      "epoch 136; iter: 0; batch classifier loss: 0.059918; batch adversarial loss: 0.391049\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037009; batch adversarial loss: 0.521439\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030692; batch adversarial loss: 0.493673\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020896; batch adversarial loss: 0.469872\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031330; batch adversarial loss: 0.484956\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025375; batch adversarial loss: 0.460606\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035633; batch adversarial loss: 0.472287\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026173; batch adversarial loss: 0.454634\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031253; batch adversarial loss: 0.380004\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040906; batch adversarial loss: 0.401366\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020561; batch adversarial loss: 0.509329\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036931; batch adversarial loss: 0.385889\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012037; batch adversarial loss: 0.481130\n",
      "epoch 149; iter: 0; batch classifier loss: 0.046446; batch adversarial loss: 0.462003\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016931; batch adversarial loss: 0.480507\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016829; batch adversarial loss: 0.497025\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018588; batch adversarial loss: 0.504263\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028519; batch adversarial loss: 0.503163\n",
      "epoch 154; iter: 0; batch classifier loss: 0.052065; batch adversarial loss: 0.358446\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052567; batch adversarial loss: 0.463144\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036695; batch adversarial loss: 0.372017\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033159; batch adversarial loss: 0.390390\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036104; batch adversarial loss: 0.549709\n",
      "epoch 159; iter: 0; batch classifier loss: 0.007818; batch adversarial loss: 0.428549\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030676; batch adversarial loss: 0.429124\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016677; batch adversarial loss: 0.560551\n",
      "epoch 162; iter: 0; batch classifier loss: 0.044760; batch adversarial loss: 0.499004\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035615; batch adversarial loss: 0.420411\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021427; batch adversarial loss: 0.386651\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025507; batch adversarial loss: 0.493494\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038741; batch adversarial loss: 0.378778\n",
      "epoch 167; iter: 0; batch classifier loss: 0.046726; batch adversarial loss: 0.391661\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026641; batch adversarial loss: 0.340972\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029128; batch adversarial loss: 0.453956\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035711; batch adversarial loss: 0.537347\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016157; batch adversarial loss: 0.499745\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022079; batch adversarial loss: 0.370003\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011108; batch adversarial loss: 0.495066\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017645; batch adversarial loss: 0.493083\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010587; batch adversarial loss: 0.400455\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032499; batch adversarial loss: 0.352673\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030715; batch adversarial loss: 0.421417\n",
      "epoch 178; iter: 0; batch classifier loss: 0.003064; batch adversarial loss: 0.434101\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013643; batch adversarial loss: 0.435760\n",
      "epoch 180; iter: 0; batch classifier loss: 0.043274; batch adversarial loss: 0.427595\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036023; batch adversarial loss: 0.428347\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012166; batch adversarial loss: 0.418876\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016225; batch adversarial loss: 0.338859\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010836; batch adversarial loss: 0.385668\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035239; batch adversarial loss: 0.468577\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008526; batch adversarial loss: 0.356769\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015611; batch adversarial loss: 0.407065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.023395; batch adversarial loss: 0.398138\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017202; batch adversarial loss: 0.436727\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019767; batch adversarial loss: 0.383087\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017497; batch adversarial loss: 0.447888\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028273; batch adversarial loss: 0.453520\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032808; batch adversarial loss: 0.411093\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023944; batch adversarial loss: 0.356473\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012374; batch adversarial loss: 0.416081\n",
      "epoch 196; iter: 0; batch classifier loss: 0.044377; batch adversarial loss: 0.481234\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022831; batch adversarial loss: 0.362466\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013897; batch adversarial loss: 0.464466\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015770; batch adversarial loss: 0.432351\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693190; batch adversarial loss: 0.543058\n",
      "epoch 1; iter: 0; batch classifier loss: 0.410370; batch adversarial loss: 0.582637\n",
      "epoch 2; iter: 0; batch classifier loss: 0.454231; batch adversarial loss: 0.546489\n",
      "epoch 3; iter: 0; batch classifier loss: 0.331981; batch adversarial loss: 0.578094\n",
      "epoch 4; iter: 0; batch classifier loss: 0.371411; batch adversarial loss: 0.518501\n",
      "epoch 5; iter: 0; batch classifier loss: 0.443365; batch adversarial loss: 0.555225\n",
      "epoch 6; iter: 0; batch classifier loss: 0.317410; batch adversarial loss: 0.558221\n",
      "epoch 7; iter: 0; batch classifier loss: 0.337556; batch adversarial loss: 0.651192\n",
      "epoch 8; iter: 0; batch classifier loss: 0.374188; batch adversarial loss: 0.606584\n",
      "epoch 9; iter: 0; batch classifier loss: 0.315497; batch adversarial loss: 0.460504\n",
      "epoch 10; iter: 0; batch classifier loss: 0.335552; batch adversarial loss: 0.549438\n",
      "epoch 11; iter: 0; batch classifier loss: 0.329243; batch adversarial loss: 0.550341\n",
      "epoch 12; iter: 0; batch classifier loss: 0.412408; batch adversarial loss: 0.580080\n",
      "epoch 13; iter: 0; batch classifier loss: 0.387035; batch adversarial loss: 0.517126\n",
      "epoch 14; iter: 0; batch classifier loss: 0.579865; batch adversarial loss: 0.544422\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519136; batch adversarial loss: 0.495563\n",
      "epoch 16; iter: 0; batch classifier loss: 0.509430; batch adversarial loss: 0.514399\n",
      "epoch 17; iter: 0; batch classifier loss: 0.263056; batch adversarial loss: 0.532485\n",
      "epoch 18; iter: 0; batch classifier loss: 0.265298; batch adversarial loss: 0.504618\n",
      "epoch 19; iter: 0; batch classifier loss: 0.242663; batch adversarial loss: 0.506789\n",
      "epoch 20; iter: 0; batch classifier loss: 0.172885; batch adversarial loss: 0.471079\n",
      "epoch 21; iter: 0; batch classifier loss: 0.161802; batch adversarial loss: 0.549703\n",
      "epoch 22; iter: 0; batch classifier loss: 0.178643; batch adversarial loss: 0.500672\n",
      "epoch 23; iter: 0; batch classifier loss: 0.212431; batch adversarial loss: 0.451028\n",
      "epoch 24; iter: 0; batch classifier loss: 0.167952; batch adversarial loss: 0.418330\n",
      "epoch 25; iter: 0; batch classifier loss: 0.141209; batch adversarial loss: 0.550043\n",
      "epoch 26; iter: 0; batch classifier loss: 0.192468; batch adversarial loss: 0.469949\n",
      "epoch 27; iter: 0; batch classifier loss: 0.115918; batch adversarial loss: 0.489216\n",
      "epoch 28; iter: 0; batch classifier loss: 0.121334; batch adversarial loss: 0.569555\n",
      "epoch 29; iter: 0; batch classifier loss: 0.156262; batch adversarial loss: 0.493910\n",
      "epoch 30; iter: 0; batch classifier loss: 0.118003; batch adversarial loss: 0.501089\n",
      "epoch 31; iter: 0; batch classifier loss: 0.094191; batch adversarial loss: 0.426814\n",
      "epoch 32; iter: 0; batch classifier loss: 0.128684; batch adversarial loss: 0.546453\n",
      "epoch 33; iter: 0; batch classifier loss: 0.111469; batch adversarial loss: 0.464838\n",
      "epoch 34; iter: 0; batch classifier loss: 0.121202; batch adversarial loss: 0.446899\n",
      "epoch 35; iter: 0; batch classifier loss: 0.124411; batch adversarial loss: 0.507678\n",
      "epoch 36; iter: 0; batch classifier loss: 0.133125; batch adversarial loss: 0.504388\n",
      "epoch 37; iter: 0; batch classifier loss: 0.103464; batch adversarial loss: 0.445964\n",
      "epoch 38; iter: 0; batch classifier loss: 0.071715; batch adversarial loss: 0.436463\n",
      "epoch 39; iter: 0; batch classifier loss: 0.136945; batch adversarial loss: 0.434846\n",
      "epoch 40; iter: 0; batch classifier loss: 0.081589; batch adversarial loss: 0.487118\n",
      "epoch 41; iter: 0; batch classifier loss: 0.072242; batch adversarial loss: 0.414341\n",
      "epoch 42; iter: 0; batch classifier loss: 0.084815; batch adversarial loss: 0.494902\n",
      "epoch 43; iter: 0; batch classifier loss: 0.099973; batch adversarial loss: 0.584532\n",
      "epoch 44; iter: 0; batch classifier loss: 0.111784; batch adversarial loss: 0.472848\n",
      "epoch 45; iter: 0; batch classifier loss: 0.088553; batch adversarial loss: 0.421955\n",
      "epoch 46; iter: 0; batch classifier loss: 0.139166; batch adversarial loss: 0.439548\n",
      "epoch 47; iter: 0; batch classifier loss: 0.079479; batch adversarial loss: 0.449976\n",
      "epoch 48; iter: 0; batch classifier loss: 0.075512; batch adversarial loss: 0.455945\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094106; batch adversarial loss: 0.443886\n",
      "epoch 50; iter: 0; batch classifier loss: 0.103305; batch adversarial loss: 0.405437\n",
      "epoch 51; iter: 0; batch classifier loss: 0.140306; batch adversarial loss: 0.394267\n",
      "epoch 52; iter: 0; batch classifier loss: 0.085705; batch adversarial loss: 0.427973\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122646; batch adversarial loss: 0.397853\n",
      "epoch 54; iter: 0; batch classifier loss: 0.158421; batch adversarial loss: 0.472374\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122502; batch adversarial loss: 0.478982\n",
      "epoch 56; iter: 0; batch classifier loss: 0.091375; batch adversarial loss: 0.323160\n",
      "epoch 57; iter: 0; batch classifier loss: 0.069856; batch adversarial loss: 0.536160\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080925; batch adversarial loss: 0.382986\n",
      "epoch 59; iter: 0; batch classifier loss: 0.068968; batch adversarial loss: 0.454176\n",
      "epoch 60; iter: 0; batch classifier loss: 0.069089; batch adversarial loss: 0.469735\n",
      "epoch 61; iter: 0; batch classifier loss: 0.084295; batch adversarial loss: 0.427478\n",
      "epoch 62; iter: 0; batch classifier loss: 0.122036; batch adversarial loss: 0.427091\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092496; batch adversarial loss: 0.482067\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090540; batch adversarial loss: 0.475338\n",
      "epoch 65; iter: 0; batch classifier loss: 0.098553; batch adversarial loss: 0.429813\n",
      "epoch 66; iter: 0; batch classifier loss: 0.111004; batch adversarial loss: 0.490996\n",
      "epoch 67; iter: 0; batch classifier loss: 0.066499; batch adversarial loss: 0.439988\n",
      "epoch 68; iter: 0; batch classifier loss: 0.099957; batch adversarial loss: 0.425184\n",
      "epoch 69; iter: 0; batch classifier loss: 0.105906; batch adversarial loss: 0.425019\n",
      "epoch 70; iter: 0; batch classifier loss: 0.062113; batch adversarial loss: 0.418520\n",
      "epoch 71; iter: 0; batch classifier loss: 0.113441; batch adversarial loss: 0.470873\n",
      "epoch 72; iter: 0; batch classifier loss: 0.103053; batch adversarial loss: 0.455506\n",
      "epoch 73; iter: 0; batch classifier loss: 0.115262; batch adversarial loss: 0.500279\n",
      "epoch 74; iter: 0; batch classifier loss: 0.094943; batch adversarial loss: 0.546898\n",
      "epoch 75; iter: 0; batch classifier loss: 0.097066; batch adversarial loss: 0.461789\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072494; batch adversarial loss: 0.477612\n",
      "epoch 77; iter: 0; batch classifier loss: 0.104128; batch adversarial loss: 0.509551\n",
      "epoch 78; iter: 0; batch classifier loss: 0.078421; batch adversarial loss: 0.454771\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071941; batch adversarial loss: 0.512800\n",
      "epoch 80; iter: 0; batch classifier loss: 0.079805; batch adversarial loss: 0.426175\n",
      "epoch 81; iter: 0; batch classifier loss: 0.088962; batch adversarial loss: 0.455729\n",
      "epoch 82; iter: 0; batch classifier loss: 0.081904; batch adversarial loss: 0.500979\n",
      "epoch 83; iter: 0; batch classifier loss: 0.069833; batch adversarial loss: 0.486968\n",
      "epoch 84; iter: 0; batch classifier loss: 0.140826; batch adversarial loss: 0.363038\n",
      "epoch 85; iter: 0; batch classifier loss: 0.092949; batch adversarial loss: 0.481190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.068815; batch adversarial loss: 0.592237\n",
      "epoch 87; iter: 0; batch classifier loss: 0.159221; batch adversarial loss: 0.313089\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073864; batch adversarial loss: 0.546014\n",
      "epoch 89; iter: 0; batch classifier loss: 0.111643; batch adversarial loss: 0.464124\n",
      "epoch 90; iter: 0; batch classifier loss: 0.115882; batch adversarial loss: 0.325211\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056278; batch adversarial loss: 0.502983\n",
      "epoch 92; iter: 0; batch classifier loss: 0.049970; batch adversarial loss: 0.446050\n",
      "epoch 93; iter: 0; batch classifier loss: 0.125423; batch adversarial loss: 0.410854\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083182; batch adversarial loss: 0.477860\n",
      "epoch 95; iter: 0; batch classifier loss: 0.074922; batch adversarial loss: 0.549393\n",
      "epoch 96; iter: 0; batch classifier loss: 0.083354; batch adversarial loss: 0.474891\n",
      "epoch 97; iter: 0; batch classifier loss: 0.038929; batch adversarial loss: 0.495943\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063383; batch adversarial loss: 0.492899\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047159; batch adversarial loss: 0.437406\n",
      "epoch 100; iter: 0; batch classifier loss: 0.082576; batch adversarial loss: 0.481948\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050620; batch adversarial loss: 0.485427\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059096; batch adversarial loss: 0.416813\n",
      "epoch 103; iter: 0; batch classifier loss: 0.075968; batch adversarial loss: 0.515642\n",
      "epoch 104; iter: 0; batch classifier loss: 0.049138; batch adversarial loss: 0.498180\n",
      "epoch 105; iter: 0; batch classifier loss: 0.031610; batch adversarial loss: 0.456755\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050185; batch adversarial loss: 0.402778\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035131; batch adversarial loss: 0.367141\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051795; batch adversarial loss: 0.404349\n",
      "epoch 109; iter: 0; batch classifier loss: 0.056798; batch adversarial loss: 0.457786\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037621; batch adversarial loss: 0.349187\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029064; batch adversarial loss: 0.503859\n",
      "epoch 112; iter: 0; batch classifier loss: 0.070020; batch adversarial loss: 0.401600\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039706; batch adversarial loss: 0.381265\n",
      "epoch 114; iter: 0; batch classifier loss: 0.073977; batch adversarial loss: 0.403018\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042214; batch adversarial loss: 0.430302\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051359; batch adversarial loss: 0.416727\n",
      "epoch 117; iter: 0; batch classifier loss: 0.017476; batch adversarial loss: 0.444073\n",
      "epoch 118; iter: 0; batch classifier loss: 0.053349; batch adversarial loss: 0.420613\n",
      "epoch 119; iter: 0; batch classifier loss: 0.018984; batch adversarial loss: 0.410918\n",
      "epoch 120; iter: 0; batch classifier loss: 0.065748; batch adversarial loss: 0.392960\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037403; batch adversarial loss: 0.404654\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050944; batch adversarial loss: 0.481350\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041728; batch adversarial loss: 0.463805\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031599; batch adversarial loss: 0.387434\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046146; batch adversarial loss: 0.411664\n",
      "epoch 126; iter: 0; batch classifier loss: 0.016213; batch adversarial loss: 0.402401\n",
      "epoch 127; iter: 0; batch classifier loss: 0.084870; batch adversarial loss: 0.495380\n",
      "epoch 128; iter: 0; batch classifier loss: 0.016812; batch adversarial loss: 0.461599\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034433; batch adversarial loss: 0.508425\n",
      "epoch 130; iter: 0; batch classifier loss: 0.073391; batch adversarial loss: 0.429401\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049219; batch adversarial loss: 0.417307\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034856; batch adversarial loss: 0.520561\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034180; batch adversarial loss: 0.490166\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050098; batch adversarial loss: 0.455901\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030847; batch adversarial loss: 0.459854\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039232; batch adversarial loss: 0.459913\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032923; batch adversarial loss: 0.512942\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045431; batch adversarial loss: 0.481549\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023731; batch adversarial loss: 0.507527\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040705; batch adversarial loss: 0.346978\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027829; batch adversarial loss: 0.532257\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017766; batch adversarial loss: 0.533959\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020848; batch adversarial loss: 0.456492\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026040; batch adversarial loss: 0.413621\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022151; batch adversarial loss: 0.399004\n",
      "epoch 146; iter: 0; batch classifier loss: 0.050360; batch adversarial loss: 0.395506\n",
      "epoch 147; iter: 0; batch classifier loss: 0.049445; batch adversarial loss: 0.430596\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038314; batch adversarial loss: 0.405967\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018211; batch adversarial loss: 0.432165\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026566; batch adversarial loss: 0.456354\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012312; batch adversarial loss: 0.506736\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029454; batch adversarial loss: 0.389803\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028445; batch adversarial loss: 0.381435\n",
      "epoch 154; iter: 0; batch classifier loss: 0.056656; batch adversarial loss: 0.540881\n",
      "epoch 155; iter: 0; batch classifier loss: 0.061886; batch adversarial loss: 0.349285\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042016; batch adversarial loss: 0.449162\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033929; batch adversarial loss: 0.497235\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028702; batch adversarial loss: 0.450345\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026934; batch adversarial loss: 0.443569\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046469; batch adversarial loss: 0.400024\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023971; batch adversarial loss: 0.403547\n",
      "epoch 162; iter: 0; batch classifier loss: 0.035171; batch adversarial loss: 0.591127\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027196; batch adversarial loss: 0.442055\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035751; batch adversarial loss: 0.431010\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034605; batch adversarial loss: 0.462941\n",
      "epoch 166; iter: 0; batch classifier loss: 0.063100; batch adversarial loss: 0.366817\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009201; batch adversarial loss: 0.441142\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018606; batch adversarial loss: 0.406853\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028295; batch adversarial loss: 0.425388\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034420; batch adversarial loss: 0.458691\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015141; batch adversarial loss: 0.379879\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018171; batch adversarial loss: 0.374467\n",
      "epoch 173; iter: 0; batch classifier loss: 0.069836; batch adversarial loss: 0.445995\n",
      "epoch 174; iter: 0; batch classifier loss: 0.045573; batch adversarial loss: 0.447197\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016648; batch adversarial loss: 0.505674\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032422; batch adversarial loss: 0.576764\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008254; batch adversarial loss: 0.434605\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015886; batch adversarial loss: 0.473984\n",
      "epoch 179; iter: 0; batch classifier loss: 0.069078; batch adversarial loss: 0.532858\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040712; batch adversarial loss: 0.454893\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018350; batch adversarial loss: 0.483808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.018368; batch adversarial loss: 0.460192\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036574; batch adversarial loss: 0.391129\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036714; batch adversarial loss: 0.502781\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022158; batch adversarial loss: 0.425771\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028376; batch adversarial loss: 0.519818\n",
      "epoch 187; iter: 0; batch classifier loss: 0.043003; batch adversarial loss: 0.476159\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033457; batch adversarial loss: 0.396701\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034528; batch adversarial loss: 0.537685\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028261; batch adversarial loss: 0.424862\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032336; batch adversarial loss: 0.420656\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004475; batch adversarial loss: 0.494415\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025553; batch adversarial loss: 0.306245\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015615; batch adversarial loss: 0.453991\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027606; batch adversarial loss: 0.486307\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032461; batch adversarial loss: 0.440671\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010273; batch adversarial loss: 0.480136\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026751; batch adversarial loss: 0.423911\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010542; batch adversarial loss: 0.464265\n",
      "epoch 0; iter: 0; batch classifier loss: 0.733240; batch adversarial loss: 0.739046\n",
      "epoch 1; iter: 0; batch classifier loss: 0.469705; batch adversarial loss: 0.688088\n",
      "epoch 2; iter: 0; batch classifier loss: 0.458671; batch adversarial loss: 0.651444\n",
      "epoch 3; iter: 0; batch classifier loss: 0.343142; batch adversarial loss: 0.632005\n",
      "epoch 4; iter: 0; batch classifier loss: 0.355028; batch adversarial loss: 0.596262\n",
      "epoch 5; iter: 0; batch classifier loss: 0.372533; batch adversarial loss: 0.576837\n",
      "epoch 6; iter: 0; batch classifier loss: 0.349559; batch adversarial loss: 0.528736\n",
      "epoch 7; iter: 0; batch classifier loss: 0.323691; batch adversarial loss: 0.506958\n",
      "epoch 8; iter: 0; batch classifier loss: 0.277623; batch adversarial loss: 0.506772\n",
      "epoch 9; iter: 0; batch classifier loss: 0.249824; batch adversarial loss: 0.530086\n",
      "epoch 10; iter: 0; batch classifier loss: 0.249766; batch adversarial loss: 0.486127\n",
      "epoch 11; iter: 0; batch classifier loss: 0.202585; batch adversarial loss: 0.464588\n",
      "epoch 12; iter: 0; batch classifier loss: 0.223353; batch adversarial loss: 0.461452\n",
      "epoch 13; iter: 0; batch classifier loss: 0.174634; batch adversarial loss: 0.506585\n",
      "epoch 14; iter: 0; batch classifier loss: 0.196466; batch adversarial loss: 0.555236\n",
      "epoch 15; iter: 0; batch classifier loss: 0.178315; batch adversarial loss: 0.490264\n",
      "epoch 16; iter: 0; batch classifier loss: 0.250618; batch adversarial loss: 0.486994\n",
      "epoch 17; iter: 0; batch classifier loss: 0.159487; batch adversarial loss: 0.458642\n",
      "epoch 18; iter: 0; batch classifier loss: 0.231199; batch adversarial loss: 0.536113\n",
      "epoch 19; iter: 0; batch classifier loss: 0.222060; batch adversarial loss: 0.536593\n",
      "epoch 20; iter: 0; batch classifier loss: 0.232816; batch adversarial loss: 0.489961\n",
      "epoch 21; iter: 0; batch classifier loss: 0.265642; batch adversarial loss: 0.521667\n",
      "epoch 22; iter: 0; batch classifier loss: 0.331833; batch adversarial loss: 0.455319\n",
      "epoch 23; iter: 0; batch classifier loss: 0.385244; batch adversarial loss: 0.459756\n",
      "epoch 24; iter: 0; batch classifier loss: 0.328197; batch adversarial loss: 0.508118\n",
      "epoch 25; iter: 0; batch classifier loss: 0.287293; batch adversarial loss: 0.385323\n",
      "epoch 26; iter: 0; batch classifier loss: 0.166622; batch adversarial loss: 0.524867\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154398; batch adversarial loss: 0.470756\n",
      "epoch 28; iter: 0; batch classifier loss: 0.164720; batch adversarial loss: 0.533376\n",
      "epoch 29; iter: 0; batch classifier loss: 0.183501; batch adversarial loss: 0.413630\n",
      "epoch 30; iter: 0; batch classifier loss: 0.118711; batch adversarial loss: 0.479879\n",
      "epoch 31; iter: 0; batch classifier loss: 0.115362; batch adversarial loss: 0.399354\n",
      "epoch 32; iter: 0; batch classifier loss: 0.162552; batch adversarial loss: 0.452684\n",
      "epoch 33; iter: 0; batch classifier loss: 0.095180; batch adversarial loss: 0.391584\n",
      "epoch 34; iter: 0; batch classifier loss: 0.165995; batch adversarial loss: 0.442342\n",
      "epoch 35; iter: 0; batch classifier loss: 0.118627; batch adversarial loss: 0.430846\n",
      "epoch 36; iter: 0; batch classifier loss: 0.188246; batch adversarial loss: 0.455189\n",
      "epoch 37; iter: 0; batch classifier loss: 0.140978; batch adversarial loss: 0.345418\n",
      "epoch 38; iter: 0; batch classifier loss: 0.079461; batch adversarial loss: 0.503813\n",
      "epoch 39; iter: 0; batch classifier loss: 0.137312; batch adversarial loss: 0.526848\n",
      "epoch 40; iter: 0; batch classifier loss: 0.149556; batch adversarial loss: 0.545600\n",
      "epoch 41; iter: 0; batch classifier loss: 0.121033; batch adversarial loss: 0.425586\n",
      "epoch 42; iter: 0; batch classifier loss: 0.128535; batch adversarial loss: 0.483124\n",
      "epoch 43; iter: 0; batch classifier loss: 0.118612; batch adversarial loss: 0.397289\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112404; batch adversarial loss: 0.433710\n",
      "epoch 45; iter: 0; batch classifier loss: 0.122537; batch adversarial loss: 0.479314\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086025; batch adversarial loss: 0.432098\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119977; batch adversarial loss: 0.469212\n",
      "epoch 48; iter: 0; batch classifier loss: 0.107541; batch adversarial loss: 0.414843\n",
      "epoch 49; iter: 0; batch classifier loss: 0.070180; batch adversarial loss: 0.483443\n",
      "epoch 50; iter: 0; batch classifier loss: 0.127183; batch adversarial loss: 0.476462\n",
      "epoch 51; iter: 0; batch classifier loss: 0.131198; batch adversarial loss: 0.407148\n",
      "epoch 52; iter: 0; batch classifier loss: 0.122179; batch adversarial loss: 0.387111\n",
      "epoch 53; iter: 0; batch classifier loss: 0.120836; batch adversarial loss: 0.479920\n",
      "epoch 54; iter: 0; batch classifier loss: 0.099532; batch adversarial loss: 0.477232\n",
      "epoch 55; iter: 0; batch classifier loss: 0.142885; batch adversarial loss: 0.387290\n",
      "epoch 56; iter: 0; batch classifier loss: 0.096325; batch adversarial loss: 0.419913\n",
      "epoch 57; iter: 0; batch classifier loss: 0.123501; batch adversarial loss: 0.452240\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072695; batch adversarial loss: 0.472641\n",
      "epoch 59; iter: 0; batch classifier loss: 0.141791; batch adversarial loss: 0.456854\n",
      "epoch 60; iter: 0; batch classifier loss: 0.070821; batch adversarial loss: 0.433334\n",
      "epoch 61; iter: 0; batch classifier loss: 0.141123; batch adversarial loss: 0.394017\n",
      "epoch 62; iter: 0; batch classifier loss: 0.127171; batch adversarial loss: 0.490420\n",
      "epoch 63; iter: 0; batch classifier loss: 0.128052; batch adversarial loss: 0.416007\n",
      "epoch 64; iter: 0; batch classifier loss: 0.115451; batch adversarial loss: 0.417832\n",
      "epoch 65; iter: 0; batch classifier loss: 0.132570; batch adversarial loss: 0.406609\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096766; batch adversarial loss: 0.373065\n",
      "epoch 67; iter: 0; batch classifier loss: 0.103859; batch adversarial loss: 0.419767\n",
      "epoch 68; iter: 0; batch classifier loss: 0.123093; batch adversarial loss: 0.393810\n",
      "epoch 69; iter: 0; batch classifier loss: 0.107979; batch adversarial loss: 0.466943\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090553; batch adversarial loss: 0.523926\n",
      "epoch 71; iter: 0; batch classifier loss: 0.094361; batch adversarial loss: 0.469889\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082819; batch adversarial loss: 0.445026\n",
      "epoch 73; iter: 0; batch classifier loss: 0.130194; batch adversarial loss: 0.412938\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082224; batch adversarial loss: 0.440535\n",
      "epoch 75; iter: 0; batch classifier loss: 0.099418; batch adversarial loss: 0.402049\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070109; batch adversarial loss: 0.492143\n",
      "epoch 77; iter: 0; batch classifier loss: 0.083488; batch adversarial loss: 0.467102\n",
      "epoch 78; iter: 0; batch classifier loss: 0.057790; batch adversarial loss: 0.385499\n",
      "epoch 79; iter: 0; batch classifier loss: 0.091117; batch adversarial loss: 0.522062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.072276; batch adversarial loss: 0.500963\n",
      "epoch 81; iter: 0; batch classifier loss: 0.040519; batch adversarial loss: 0.472546\n",
      "epoch 82; iter: 0; batch classifier loss: 0.094832; batch adversarial loss: 0.482695\n",
      "epoch 83; iter: 0; batch classifier loss: 0.060941; batch adversarial loss: 0.410326\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067133; batch adversarial loss: 0.478374\n",
      "epoch 85; iter: 0; batch classifier loss: 0.063923; batch adversarial loss: 0.513809\n",
      "epoch 86; iter: 0; batch classifier loss: 0.071737; batch adversarial loss: 0.419121\n",
      "epoch 87; iter: 0; batch classifier loss: 0.061562; batch adversarial loss: 0.485963\n",
      "epoch 88; iter: 0; batch classifier loss: 0.101422; batch adversarial loss: 0.453520\n",
      "epoch 89; iter: 0; batch classifier loss: 0.121807; batch adversarial loss: 0.459417\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064525; batch adversarial loss: 0.392518\n",
      "epoch 91; iter: 0; batch classifier loss: 0.061485; batch adversarial loss: 0.480215\n",
      "epoch 92; iter: 0; batch classifier loss: 0.056360; batch adversarial loss: 0.453685\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044633; batch adversarial loss: 0.618372\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066626; batch adversarial loss: 0.465968\n",
      "epoch 95; iter: 0; batch classifier loss: 0.035078; batch adversarial loss: 0.411662\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057897; batch adversarial loss: 0.381694\n",
      "epoch 97; iter: 0; batch classifier loss: 0.040029; batch adversarial loss: 0.529008\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072468; batch adversarial loss: 0.418204\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069282; batch adversarial loss: 0.409352\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039671; batch adversarial loss: 0.509874\n",
      "epoch 101; iter: 0; batch classifier loss: 0.045149; batch adversarial loss: 0.416869\n",
      "epoch 102; iter: 0; batch classifier loss: 0.074157; batch adversarial loss: 0.381612\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042087; batch adversarial loss: 0.416171\n",
      "epoch 104; iter: 0; batch classifier loss: 0.035517; batch adversarial loss: 0.512278\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035024; batch adversarial loss: 0.590523\n",
      "epoch 106; iter: 0; batch classifier loss: 0.072567; batch adversarial loss: 0.518324\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028609; batch adversarial loss: 0.494152\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041488; batch adversarial loss: 0.447646\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030986; batch adversarial loss: 0.472994\n",
      "epoch 110; iter: 0; batch classifier loss: 0.084280; batch adversarial loss: 0.497893\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035166; batch adversarial loss: 0.448993\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038775; batch adversarial loss: 0.472110\n",
      "epoch 113; iter: 0; batch classifier loss: 0.031025; batch adversarial loss: 0.487747\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052415; batch adversarial loss: 0.452279\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028353; batch adversarial loss: 0.387923\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045263; batch adversarial loss: 0.509458\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023619; batch adversarial loss: 0.439138\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032557; batch adversarial loss: 0.477221\n",
      "epoch 119; iter: 0; batch classifier loss: 0.020376; batch adversarial loss: 0.458529\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041407; batch adversarial loss: 0.533911\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036758; batch adversarial loss: 0.452537\n",
      "epoch 122; iter: 0; batch classifier loss: 0.057838; batch adversarial loss: 0.430750\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030455; batch adversarial loss: 0.420727\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031061; batch adversarial loss: 0.497672\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032092; batch adversarial loss: 0.457076\n",
      "epoch 126; iter: 0; batch classifier loss: 0.056703; batch adversarial loss: 0.454686\n",
      "epoch 127; iter: 0; batch classifier loss: 0.011096; batch adversarial loss: 0.508052\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032285; batch adversarial loss: 0.431389\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031714; batch adversarial loss: 0.358612\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025530; batch adversarial loss: 0.486660\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017701; batch adversarial loss: 0.381522\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033138; batch adversarial loss: 0.465735\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034793; batch adversarial loss: 0.461791\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043996; batch adversarial loss: 0.513424\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026452; batch adversarial loss: 0.379544\n",
      "epoch 136; iter: 0; batch classifier loss: 0.047811; batch adversarial loss: 0.472705\n",
      "epoch 137; iter: 0; batch classifier loss: 0.005684; batch adversarial loss: 0.465597\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056452; batch adversarial loss: 0.413642\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044034; batch adversarial loss: 0.506963\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019408; batch adversarial loss: 0.472195\n",
      "epoch 141; iter: 0; batch classifier loss: 0.054903; batch adversarial loss: 0.566823\n",
      "epoch 142; iter: 0; batch classifier loss: 0.079627; batch adversarial loss: 0.379721\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029691; batch adversarial loss: 0.502893\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028782; batch adversarial loss: 0.379585\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033126; batch adversarial loss: 0.329440\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030791; batch adversarial loss: 0.373766\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027884; batch adversarial loss: 0.437712\n",
      "epoch 148; iter: 0; batch classifier loss: 0.048148; batch adversarial loss: 0.422875\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017333; batch adversarial loss: 0.460459\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033725; batch adversarial loss: 0.368457\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037576; batch adversarial loss: 0.360150\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028498; batch adversarial loss: 0.456529\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042445; batch adversarial loss: 0.344268\n",
      "epoch 154; iter: 0; batch classifier loss: 0.007097; batch adversarial loss: 0.573847\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016773; batch adversarial loss: 0.540153\n",
      "epoch 156; iter: 0; batch classifier loss: 0.004303; batch adversarial loss: 0.395922\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009057; batch adversarial loss: 0.430046\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025925; batch adversarial loss: 0.471432\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016915; batch adversarial loss: 0.484858\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021812; batch adversarial loss: 0.462230\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014966; batch adversarial loss: 0.533884\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024053; batch adversarial loss: 0.456155\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006458; batch adversarial loss: 0.461471\n",
      "epoch 164; iter: 0; batch classifier loss: 0.004552; batch adversarial loss: 0.480304\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037872; batch adversarial loss: 0.518969\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010534; batch adversarial loss: 0.459419\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016537; batch adversarial loss: 0.451771\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032694; batch adversarial loss: 0.454085\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023774; batch adversarial loss: 0.561404\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012200; batch adversarial loss: 0.452824\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019185; batch adversarial loss: 0.432508\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012291; batch adversarial loss: 0.370647\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021272; batch adversarial loss: 0.433058\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010307; batch adversarial loss: 0.563369\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025050; batch adversarial loss: 0.490027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.034479; batch adversarial loss: 0.433049\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019120; batch adversarial loss: 0.488157\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039838; batch adversarial loss: 0.440346\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028623; batch adversarial loss: 0.436452\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009418; batch adversarial loss: 0.459239\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016300; batch adversarial loss: 0.467566\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026407; batch adversarial loss: 0.494849\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023982; batch adversarial loss: 0.372223\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010736; batch adversarial loss: 0.507278\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026733; batch adversarial loss: 0.476554\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007872; batch adversarial loss: 0.430810\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034206; batch adversarial loss: 0.435634\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008687; batch adversarial loss: 0.465548\n",
      "epoch 189; iter: 0; batch classifier loss: 0.002900; batch adversarial loss: 0.442889\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017211; batch adversarial loss: 0.465393\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023229; batch adversarial loss: 0.440914\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005740; batch adversarial loss: 0.483876\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004734; batch adversarial loss: 0.470647\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019746; batch adversarial loss: 0.437651\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020880; batch adversarial loss: 0.430571\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008159; batch adversarial loss: 0.474747\n",
      "epoch 197; iter: 0; batch classifier loss: 0.002375; batch adversarial loss: 0.549048\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019450; batch adversarial loss: 0.526087\n",
      "epoch 199; iter: 0; batch classifier loss: 0.029382; batch adversarial loss: 0.546987\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669609; batch adversarial loss: 0.969632\n",
      "epoch 1; iter: 0; batch classifier loss: 0.570567; batch adversarial loss: 1.182156\n",
      "epoch 2; iter: 0; batch classifier loss: 0.809677; batch adversarial loss: 1.274664\n",
      "epoch 3; iter: 0; batch classifier loss: 1.000431; batch adversarial loss: 1.183782\n",
      "epoch 4; iter: 0; batch classifier loss: 0.976980; batch adversarial loss: 1.055027\n",
      "epoch 5; iter: 0; batch classifier loss: 1.110653; batch adversarial loss: 0.953478\n",
      "epoch 6; iter: 0; batch classifier loss: 1.038228; batch adversarial loss: 0.872993\n",
      "epoch 7; iter: 0; batch classifier loss: 1.092044; batch adversarial loss: 0.800019\n",
      "epoch 8; iter: 0; batch classifier loss: 0.957279; batch adversarial loss: 0.748779\n",
      "epoch 9; iter: 0; batch classifier loss: 0.934052; batch adversarial loss: 0.678420\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546169; batch adversarial loss: 0.677544\n",
      "epoch 11; iter: 0; batch classifier loss: 0.576855; batch adversarial loss: 0.594301\n",
      "epoch 12; iter: 0; batch classifier loss: 0.350921; batch adversarial loss: 0.574389\n",
      "epoch 13; iter: 0; batch classifier loss: 0.294473; batch adversarial loss: 0.559173\n",
      "epoch 14; iter: 0; batch classifier loss: 0.267668; batch adversarial loss: 0.532613\n",
      "epoch 15; iter: 0; batch classifier loss: 0.250149; batch adversarial loss: 0.518506\n",
      "epoch 16; iter: 0; batch classifier loss: 0.267825; batch adversarial loss: 0.546002\n",
      "epoch 17; iter: 0; batch classifier loss: 0.212201; batch adversarial loss: 0.519695\n",
      "epoch 18; iter: 0; batch classifier loss: 0.263372; batch adversarial loss: 0.524108\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236633; batch adversarial loss: 0.526346\n",
      "epoch 20; iter: 0; batch classifier loss: 0.175363; batch adversarial loss: 0.567071\n",
      "epoch 21; iter: 0; batch classifier loss: 0.156457; batch adversarial loss: 0.483722\n",
      "epoch 22; iter: 0; batch classifier loss: 0.181884; batch adversarial loss: 0.485870\n",
      "epoch 23; iter: 0; batch classifier loss: 0.164605; batch adversarial loss: 0.464115\n",
      "epoch 24; iter: 0; batch classifier loss: 0.168905; batch adversarial loss: 0.492978\n",
      "epoch 25; iter: 0; batch classifier loss: 0.130631; batch adversarial loss: 0.490207\n",
      "epoch 26; iter: 0; batch classifier loss: 0.103557; batch adversarial loss: 0.461259\n",
      "epoch 27; iter: 0; batch classifier loss: 0.170392; batch adversarial loss: 0.431012\n",
      "epoch 28; iter: 0; batch classifier loss: 0.091929; batch adversarial loss: 0.467817\n",
      "epoch 29; iter: 0; batch classifier loss: 0.092460; batch adversarial loss: 0.523251\n",
      "epoch 30; iter: 0; batch classifier loss: 0.103767; batch adversarial loss: 0.459151\n",
      "epoch 31; iter: 0; batch classifier loss: 0.113596; batch adversarial loss: 0.470108\n",
      "epoch 32; iter: 0; batch classifier loss: 0.071686; batch adversarial loss: 0.487306\n",
      "epoch 33; iter: 0; batch classifier loss: 0.088675; batch adversarial loss: 0.407860\n",
      "epoch 34; iter: 0; batch classifier loss: 0.124026; batch adversarial loss: 0.506826\n",
      "epoch 35; iter: 0; batch classifier loss: 0.067645; batch adversarial loss: 0.456577\n",
      "epoch 36; iter: 0; batch classifier loss: 0.094081; batch adversarial loss: 0.443306\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111574; batch adversarial loss: 0.416428\n",
      "epoch 38; iter: 0; batch classifier loss: 0.141616; batch adversarial loss: 0.490016\n",
      "epoch 39; iter: 0; batch classifier loss: 0.134537; batch adversarial loss: 0.514045\n",
      "epoch 40; iter: 0; batch classifier loss: 0.096047; batch adversarial loss: 0.385878\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098589; batch adversarial loss: 0.438846\n",
      "epoch 42; iter: 0; batch classifier loss: 0.115129; batch adversarial loss: 0.480317\n",
      "epoch 43; iter: 0; batch classifier loss: 0.146294; batch adversarial loss: 0.506136\n",
      "epoch 44; iter: 0; batch classifier loss: 0.138234; batch adversarial loss: 0.441321\n",
      "epoch 45; iter: 0; batch classifier loss: 0.114153; batch adversarial loss: 0.477275\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112117; batch adversarial loss: 0.406773\n",
      "epoch 47; iter: 0; batch classifier loss: 0.110542; batch adversarial loss: 0.444770\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100053; batch adversarial loss: 0.487557\n",
      "epoch 49; iter: 0; batch classifier loss: 0.077379; batch adversarial loss: 0.488612\n",
      "epoch 50; iter: 0; batch classifier loss: 0.102563; batch adversarial loss: 0.532870\n",
      "epoch 51; iter: 0; batch classifier loss: 0.067466; batch adversarial loss: 0.544274\n",
      "epoch 52; iter: 0; batch classifier loss: 0.136340; batch adversarial loss: 0.489377\n",
      "epoch 53; iter: 0; batch classifier loss: 0.055519; batch adversarial loss: 0.493923\n",
      "epoch 54; iter: 0; batch classifier loss: 0.060095; batch adversarial loss: 0.531780\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077058; batch adversarial loss: 0.484984\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082060; batch adversarial loss: 0.475226\n",
      "epoch 57; iter: 0; batch classifier loss: 0.040489; batch adversarial loss: 0.468431\n",
      "epoch 58; iter: 0; batch classifier loss: 0.082206; batch adversarial loss: 0.540037\n",
      "epoch 59; iter: 0; batch classifier loss: 0.065685; batch adversarial loss: 0.377587\n",
      "epoch 60; iter: 0; batch classifier loss: 0.060098; batch adversarial loss: 0.390146\n",
      "epoch 61; iter: 0; batch classifier loss: 0.061343; batch adversarial loss: 0.555513\n",
      "epoch 62; iter: 0; batch classifier loss: 0.070762; batch adversarial loss: 0.479358\n",
      "epoch 63; iter: 0; batch classifier loss: 0.069790; batch adversarial loss: 0.391520\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090587; batch adversarial loss: 0.505328\n",
      "epoch 65; iter: 0; batch classifier loss: 0.033790; batch adversarial loss: 0.443674\n",
      "epoch 66; iter: 0; batch classifier loss: 0.069262; batch adversarial loss: 0.524510\n",
      "epoch 67; iter: 0; batch classifier loss: 0.056147; batch adversarial loss: 0.544130\n",
      "epoch 68; iter: 0; batch classifier loss: 0.044749; batch adversarial loss: 0.344350\n",
      "epoch 69; iter: 0; batch classifier loss: 0.025774; batch adversarial loss: 0.455153\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067947; batch adversarial loss: 0.392836\n",
      "epoch 71; iter: 0; batch classifier loss: 0.087095; batch adversarial loss: 0.491104\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064574; batch adversarial loss: 0.470352\n",
      "epoch 73; iter: 0; batch classifier loss: 0.078593; batch adversarial loss: 0.426801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.050421; batch adversarial loss: 0.430241\n",
      "epoch 75; iter: 0; batch classifier loss: 0.042425; batch adversarial loss: 0.554761\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076132; batch adversarial loss: 0.525991\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087479; batch adversarial loss: 0.402435\n",
      "epoch 78; iter: 0; batch classifier loss: 0.055234; batch adversarial loss: 0.516851\n",
      "epoch 79; iter: 0; batch classifier loss: 0.055857; batch adversarial loss: 0.383254\n",
      "epoch 80; iter: 0; batch classifier loss: 0.081105; batch adversarial loss: 0.392004\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068327; batch adversarial loss: 0.467620\n",
      "epoch 82; iter: 0; batch classifier loss: 0.047175; batch adversarial loss: 0.577114\n",
      "epoch 83; iter: 0; batch classifier loss: 0.055235; batch adversarial loss: 0.427295\n",
      "epoch 84; iter: 0; batch classifier loss: 0.053310; batch adversarial loss: 0.493073\n",
      "epoch 85; iter: 0; batch classifier loss: 0.033651; batch adversarial loss: 0.420091\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046405; batch adversarial loss: 0.405808\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049675; batch adversarial loss: 0.429662\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054565; batch adversarial loss: 0.519724\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074684; batch adversarial loss: 0.428309\n",
      "epoch 90; iter: 0; batch classifier loss: 0.088240; batch adversarial loss: 0.459638\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057576; batch adversarial loss: 0.464489\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052119; batch adversarial loss: 0.419238\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063418; batch adversarial loss: 0.491397\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046319; batch adversarial loss: 0.469317\n",
      "epoch 95; iter: 0; batch classifier loss: 0.072541; batch adversarial loss: 0.437901\n",
      "epoch 96; iter: 0; batch classifier loss: 0.038856; batch adversarial loss: 0.421827\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069944; batch adversarial loss: 0.486295\n",
      "epoch 98; iter: 0; batch classifier loss: 0.017704; batch adversarial loss: 0.420472\n",
      "epoch 99; iter: 0; batch classifier loss: 0.076884; batch adversarial loss: 0.499303\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034710; batch adversarial loss: 0.497535\n",
      "epoch 101; iter: 0; batch classifier loss: 0.028108; batch adversarial loss: 0.564416\n",
      "epoch 102; iter: 0; batch classifier loss: 0.039195; batch adversarial loss: 0.423990\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057244; batch adversarial loss: 0.436885\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046480; batch adversarial loss: 0.517269\n",
      "epoch 105; iter: 0; batch classifier loss: 0.025323; batch adversarial loss: 0.534838\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025622; batch adversarial loss: 0.394063\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062833; batch adversarial loss: 0.492692\n",
      "epoch 108; iter: 0; batch classifier loss: 0.024633; batch adversarial loss: 0.502704\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026157; batch adversarial loss: 0.540082\n",
      "epoch 110; iter: 0; batch classifier loss: 0.080780; batch adversarial loss: 0.313536\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035861; batch adversarial loss: 0.418412\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030021; batch adversarial loss: 0.570529\n",
      "epoch 113; iter: 0; batch classifier loss: 0.031906; batch adversarial loss: 0.448497\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027389; batch adversarial loss: 0.525311\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045849; batch adversarial loss: 0.384902\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052070; batch adversarial loss: 0.512848\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048854; batch adversarial loss: 0.443699\n",
      "epoch 118; iter: 0; batch classifier loss: 0.064575; batch adversarial loss: 0.452607\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038113; batch adversarial loss: 0.389694\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062139; batch adversarial loss: 0.405803\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026928; batch adversarial loss: 0.462269\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032099; batch adversarial loss: 0.412268\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031603; batch adversarial loss: 0.470746\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024598; batch adversarial loss: 0.474930\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038627; batch adversarial loss: 0.519887\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029856; batch adversarial loss: 0.551894\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035814; batch adversarial loss: 0.443135\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022063; batch adversarial loss: 0.418845\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016095; batch adversarial loss: 0.373482\n",
      "epoch 130; iter: 0; batch classifier loss: 0.081299; batch adversarial loss: 0.515352\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027178; batch adversarial loss: 0.444176\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015829; batch adversarial loss: 0.429756\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014327; batch adversarial loss: 0.421525\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032938; batch adversarial loss: 0.456861\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037780; batch adversarial loss: 0.515281\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024047; batch adversarial loss: 0.535714\n",
      "epoch 137; iter: 0; batch classifier loss: 0.013084; batch adversarial loss: 0.525841\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029524; batch adversarial loss: 0.479170\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045118; batch adversarial loss: 0.542608\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051211; batch adversarial loss: 0.461456\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048155; batch adversarial loss: 0.490048\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021603; batch adversarial loss: 0.384951\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032235; batch adversarial loss: 0.423536\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016051; batch adversarial loss: 0.431380\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038824; batch adversarial loss: 0.552601\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041563; batch adversarial loss: 0.376177\n",
      "epoch 147; iter: 0; batch classifier loss: 0.071858; batch adversarial loss: 0.465576\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033573; batch adversarial loss: 0.489854\n",
      "epoch 149; iter: 0; batch classifier loss: 0.008132; batch adversarial loss: 0.499738\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014399; batch adversarial loss: 0.423937\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038967; batch adversarial loss: 0.472746\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021048; batch adversarial loss: 0.443599\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013705; batch adversarial loss: 0.452842\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034331; batch adversarial loss: 0.434018\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014071; batch adversarial loss: 0.406869\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016548; batch adversarial loss: 0.481996\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026506; batch adversarial loss: 0.521154\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045380; batch adversarial loss: 0.464231\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031715; batch adversarial loss: 0.541999\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020608; batch adversarial loss: 0.451372\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021402; batch adversarial loss: 0.465553\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013485; batch adversarial loss: 0.464857\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022074; batch adversarial loss: 0.481762\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027280; batch adversarial loss: 0.427213\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013394; batch adversarial loss: 0.458673\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011885; batch adversarial loss: 0.470324\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029538; batch adversarial loss: 0.432363\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023452; batch adversarial loss: 0.509386\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018947; batch adversarial loss: 0.493906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.013251; batch adversarial loss: 0.520971\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014623; batch adversarial loss: 0.521319\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020305; batch adversarial loss: 0.474387\n",
      "epoch 173; iter: 0; batch classifier loss: 0.005705; batch adversarial loss: 0.401841\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013851; batch adversarial loss: 0.508598\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034903; batch adversarial loss: 0.439430\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013488; batch adversarial loss: 0.445067\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032598; batch adversarial loss: 0.489193\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009727; batch adversarial loss: 0.465952\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011898; batch adversarial loss: 0.514228\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011689; batch adversarial loss: 0.544653\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014293; batch adversarial loss: 0.451420\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028306; batch adversarial loss: 0.472211\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006594; batch adversarial loss: 0.469023\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016541; batch adversarial loss: 0.525677\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006587; batch adversarial loss: 0.419459\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012549; batch adversarial loss: 0.443126\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033853; batch adversarial loss: 0.431221\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018615; batch adversarial loss: 0.465141\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012357; batch adversarial loss: 0.532541\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025589; batch adversarial loss: 0.479497\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020547; batch adversarial loss: 0.456891\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029096; batch adversarial loss: 0.476292\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021812; batch adversarial loss: 0.520443\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009457; batch adversarial loss: 0.430012\n",
      "epoch 195; iter: 0; batch classifier loss: 0.050303; batch adversarial loss: 0.421373\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021231; batch adversarial loss: 0.429578\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018341; batch adversarial loss: 0.517117\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013237; batch adversarial loss: 0.427564\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033969; batch adversarial loss: 0.544682\n",
      "epoch 0; iter: 0; batch classifier loss: 0.752309; batch adversarial loss: 0.635738\n",
      "epoch 1; iter: 0; batch classifier loss: 0.403272; batch adversarial loss: 0.636954\n",
      "epoch 2; iter: 0; batch classifier loss: 0.564009; batch adversarial loss: 0.611835\n",
      "epoch 3; iter: 0; batch classifier loss: 0.468212; batch adversarial loss: 0.608812\n",
      "epoch 4; iter: 0; batch classifier loss: 0.390516; batch adversarial loss: 0.645986\n",
      "epoch 5; iter: 0; batch classifier loss: 0.510728; batch adversarial loss: 0.577244\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549655; batch adversarial loss: 0.591308\n",
      "epoch 7; iter: 0; batch classifier loss: 0.616286; batch adversarial loss: 0.578190\n",
      "epoch 8; iter: 0; batch classifier loss: 0.449221; batch adversarial loss: 0.516255\n",
      "epoch 9; iter: 0; batch classifier loss: 0.475619; batch adversarial loss: 0.509401\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560226; batch adversarial loss: 0.491244\n",
      "epoch 11; iter: 0; batch classifier loss: 0.371822; batch adversarial loss: 0.507323\n",
      "epoch 12; iter: 0; batch classifier loss: 0.287013; batch adversarial loss: 0.552302\n",
      "epoch 13; iter: 0; batch classifier loss: 0.443552; batch adversarial loss: 0.557590\n",
      "epoch 14; iter: 0; batch classifier loss: 0.330502; batch adversarial loss: 0.538295\n",
      "epoch 15; iter: 0; batch classifier loss: 0.376548; batch adversarial loss: 0.451958\n",
      "epoch 16; iter: 0; batch classifier loss: 0.355678; batch adversarial loss: 0.432021\n",
      "epoch 17; iter: 0; batch classifier loss: 0.396992; batch adversarial loss: 0.427839\n",
      "epoch 18; iter: 0; batch classifier loss: 0.259544; batch adversarial loss: 0.544862\n",
      "epoch 19; iter: 0; batch classifier loss: 0.325767; batch adversarial loss: 0.422835\n",
      "epoch 20; iter: 0; batch classifier loss: 0.329170; batch adversarial loss: 0.446160\n",
      "epoch 21; iter: 0; batch classifier loss: 0.325674; batch adversarial loss: 0.496929\n",
      "epoch 22; iter: 0; batch classifier loss: 0.284324; batch adversarial loss: 0.522314\n",
      "epoch 23; iter: 0; batch classifier loss: 0.228483; batch adversarial loss: 0.539245\n",
      "epoch 24; iter: 0; batch classifier loss: 0.292820; batch adversarial loss: 0.441916\n",
      "epoch 25; iter: 0; batch classifier loss: 0.290641; batch adversarial loss: 0.520543\n",
      "epoch 26; iter: 0; batch classifier loss: 0.296189; batch adversarial loss: 0.512558\n",
      "epoch 27; iter: 0; batch classifier loss: 0.240484; batch adversarial loss: 0.508912\n",
      "epoch 28; iter: 0; batch classifier loss: 0.356488; batch adversarial loss: 0.425854\n",
      "epoch 29; iter: 0; batch classifier loss: 0.239800; batch adversarial loss: 0.459289\n",
      "epoch 30; iter: 0; batch classifier loss: 0.264337; batch adversarial loss: 0.467590\n",
      "epoch 31; iter: 0; batch classifier loss: 0.275471; batch adversarial loss: 0.453977\n",
      "epoch 32; iter: 0; batch classifier loss: 0.262955; batch adversarial loss: 0.493680\n",
      "epoch 33; iter: 0; batch classifier loss: 0.293095; batch adversarial loss: 0.590976\n",
      "epoch 34; iter: 0; batch classifier loss: 0.220162; batch adversarial loss: 0.480327\n",
      "epoch 35; iter: 0; batch classifier loss: 0.258676; batch adversarial loss: 0.421278\n",
      "epoch 36; iter: 0; batch classifier loss: 0.242963; batch adversarial loss: 0.473367\n",
      "epoch 37; iter: 0; batch classifier loss: 0.332929; batch adversarial loss: 0.475595\n",
      "epoch 38; iter: 0; batch classifier loss: 0.262402; batch adversarial loss: 0.447343\n",
      "epoch 39; iter: 0; batch classifier loss: 0.269813; batch adversarial loss: 0.461033\n",
      "epoch 40; iter: 0; batch classifier loss: 0.207188; batch adversarial loss: 0.425949\n",
      "epoch 41; iter: 0; batch classifier loss: 0.188162; batch adversarial loss: 0.505652\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103473; batch adversarial loss: 0.481734\n",
      "epoch 43; iter: 0; batch classifier loss: 0.162469; batch adversarial loss: 0.505454\n",
      "epoch 44; iter: 0; batch classifier loss: 0.304505; batch adversarial loss: 0.483428\n",
      "epoch 45; iter: 0; batch classifier loss: 0.152525; batch adversarial loss: 0.482992\n",
      "epoch 46; iter: 0; batch classifier loss: 0.266815; batch adversarial loss: 0.471336\n",
      "epoch 47; iter: 0; batch classifier loss: 0.210600; batch adversarial loss: 0.447072\n",
      "epoch 48; iter: 0; batch classifier loss: 0.134497; batch adversarial loss: 0.447197\n",
      "epoch 49; iter: 0; batch classifier loss: 0.180573; batch adversarial loss: 0.469603\n",
      "epoch 50; iter: 0; batch classifier loss: 0.197338; batch adversarial loss: 0.556199\n",
      "epoch 51; iter: 0; batch classifier loss: 0.129271; batch adversarial loss: 0.458585\n",
      "epoch 52; iter: 0; batch classifier loss: 0.141142; batch adversarial loss: 0.385450\n",
      "epoch 53; iter: 0; batch classifier loss: 0.223839; batch adversarial loss: 0.508518\n",
      "epoch 54; iter: 0; batch classifier loss: 0.121511; batch adversarial loss: 0.434325\n",
      "epoch 55; iter: 0; batch classifier loss: 0.137755; batch adversarial loss: 0.422486\n",
      "epoch 56; iter: 0; batch classifier loss: 0.198753; batch adversarial loss: 0.472330\n",
      "epoch 57; iter: 0; batch classifier loss: 0.109544; batch adversarial loss: 0.409856\n",
      "epoch 58; iter: 0; batch classifier loss: 0.106138; batch adversarial loss: 0.394936\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105146; batch adversarial loss: 0.483485\n",
      "epoch 60; iter: 0; batch classifier loss: 0.177229; batch adversarial loss: 0.483439\n",
      "epoch 61; iter: 0; batch classifier loss: 0.163795; batch adversarial loss: 0.508085\n",
      "epoch 62; iter: 0; batch classifier loss: 0.128136; batch adversarial loss: 0.445456\n",
      "epoch 63; iter: 0; batch classifier loss: 0.215536; batch adversarial loss: 0.433884\n",
      "epoch 64; iter: 0; batch classifier loss: 0.208886; batch adversarial loss: 0.409919\n",
      "epoch 65; iter: 0; batch classifier loss: 0.138942; batch adversarial loss: 0.483847\n",
      "epoch 66; iter: 0; batch classifier loss: 0.151301; batch adversarial loss: 0.470923\n",
      "epoch 67; iter: 0; batch classifier loss: 0.198244; batch adversarial loss: 0.446610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.093171; batch adversarial loss: 0.495071\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081339; batch adversarial loss: 0.483155\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103850; batch adversarial loss: 0.359302\n",
      "epoch 71; iter: 0; batch classifier loss: 0.143142; batch adversarial loss: 0.566556\n",
      "epoch 72; iter: 0; batch classifier loss: 0.200575; batch adversarial loss: 0.471951\n",
      "epoch 73; iter: 0; batch classifier loss: 0.220343; batch adversarial loss: 0.472584\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082678; batch adversarial loss: 0.459691\n",
      "epoch 75; iter: 0; batch classifier loss: 0.187453; batch adversarial loss: 0.469397\n",
      "epoch 76; iter: 0; batch classifier loss: 0.151146; batch adversarial loss: 0.396449\n",
      "epoch 77; iter: 0; batch classifier loss: 0.197609; batch adversarial loss: 0.433080\n",
      "epoch 78; iter: 0; batch classifier loss: 0.205822; batch adversarial loss: 0.459134\n",
      "epoch 79; iter: 0; batch classifier loss: 0.183585; batch adversarial loss: 0.532526\n",
      "epoch 80; iter: 0; batch classifier loss: 0.138026; batch adversarial loss: 0.433991\n",
      "epoch 81; iter: 0; batch classifier loss: 0.222140; batch adversarial loss: 0.421904\n",
      "epoch 82; iter: 0; batch classifier loss: 0.102846; batch adversarial loss: 0.471081\n",
      "epoch 83; iter: 0; batch classifier loss: 0.172902; batch adversarial loss: 0.471327\n",
      "epoch 84; iter: 0; batch classifier loss: 0.213879; batch adversarial loss: 0.446172\n",
      "epoch 85; iter: 0; batch classifier loss: 0.207781; batch adversarial loss: 0.557223\n",
      "epoch 86; iter: 0; batch classifier loss: 0.203548; batch adversarial loss: 0.471448\n",
      "epoch 87; iter: 0; batch classifier loss: 0.153641; batch adversarial loss: 0.546327\n",
      "epoch 88; iter: 0; batch classifier loss: 0.195445; batch adversarial loss: 0.520410\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048166; batch adversarial loss: 0.383647\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050238; batch adversarial loss: 0.459443\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075161; batch adversarial loss: 0.439844\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069333; batch adversarial loss: 0.539853\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050266; batch adversarial loss: 0.420725\n",
      "epoch 94; iter: 0; batch classifier loss: 0.073189; batch adversarial loss: 0.527820\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066397; batch adversarial loss: 0.435913\n",
      "epoch 96; iter: 0; batch classifier loss: 0.085190; batch adversarial loss: 0.499250\n",
      "epoch 97; iter: 0; batch classifier loss: 0.068891; batch adversarial loss: 0.499669\n",
      "epoch 98; iter: 0; batch classifier loss: 0.099235; batch adversarial loss: 0.406943\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040068; batch adversarial loss: 0.460461\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057675; batch adversarial loss: 0.552487\n",
      "epoch 101; iter: 0; batch classifier loss: 0.065385; batch adversarial loss: 0.467166\n",
      "epoch 102; iter: 0; batch classifier loss: 0.102174; batch adversarial loss: 0.469784\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072770; batch adversarial loss: 0.398829\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039753; batch adversarial loss: 0.418475\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056178; batch adversarial loss: 0.373916\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045462; batch adversarial loss: 0.385293\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045398; batch adversarial loss: 0.464355\n",
      "epoch 108; iter: 0; batch classifier loss: 0.077955; batch adversarial loss: 0.462145\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059520; batch adversarial loss: 0.488750\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039587; batch adversarial loss: 0.370537\n",
      "epoch 111; iter: 0; batch classifier loss: 0.098454; batch adversarial loss: 0.508104\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063107; batch adversarial loss: 0.408591\n",
      "epoch 113; iter: 0; batch classifier loss: 0.096433; batch adversarial loss: 0.439862\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041364; batch adversarial loss: 0.406114\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041607; batch adversarial loss: 0.400007\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051090; batch adversarial loss: 0.383027\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042967; batch adversarial loss: 0.462086\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040948; batch adversarial loss: 0.483753\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033848; batch adversarial loss: 0.474797\n",
      "epoch 120; iter: 0; batch classifier loss: 0.060164; batch adversarial loss: 0.415113\n",
      "epoch 121; iter: 0; batch classifier loss: 0.094209; batch adversarial loss: 0.398067\n",
      "epoch 122; iter: 0; batch classifier loss: 0.110160; batch adversarial loss: 0.525448\n",
      "epoch 123; iter: 0; batch classifier loss: 0.062011; batch adversarial loss: 0.407627\n",
      "epoch 124; iter: 0; batch classifier loss: 0.111125; batch adversarial loss: 0.433692\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045370; batch adversarial loss: 0.375249\n",
      "epoch 126; iter: 0; batch classifier loss: 0.053043; batch adversarial loss: 0.430062\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035013; batch adversarial loss: 0.466014\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054373; batch adversarial loss: 0.409332\n",
      "epoch 129; iter: 0; batch classifier loss: 0.081246; batch adversarial loss: 0.480313\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046134; batch adversarial loss: 0.494568\n",
      "epoch 131; iter: 0; batch classifier loss: 0.062099; batch adversarial loss: 0.425869\n",
      "epoch 132; iter: 0; batch classifier loss: 0.106185; batch adversarial loss: 0.340349\n",
      "epoch 133; iter: 0; batch classifier loss: 0.084276; batch adversarial loss: 0.436351\n",
      "epoch 134; iter: 0; batch classifier loss: 0.057860; batch adversarial loss: 0.466574\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041601; batch adversarial loss: 0.443864\n",
      "epoch 136; iter: 0; batch classifier loss: 0.051151; batch adversarial loss: 0.472642\n",
      "epoch 137; iter: 0; batch classifier loss: 0.056906; batch adversarial loss: 0.419506\n",
      "epoch 138; iter: 0; batch classifier loss: 0.071894; batch adversarial loss: 0.416482\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032726; batch adversarial loss: 0.415984\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045301; batch adversarial loss: 0.377581\n",
      "epoch 141; iter: 0; batch classifier loss: 0.058078; batch adversarial loss: 0.384957\n",
      "epoch 142; iter: 0; batch classifier loss: 0.054701; batch adversarial loss: 0.506152\n",
      "epoch 143; iter: 0; batch classifier loss: 0.076828; batch adversarial loss: 0.495129\n",
      "epoch 144; iter: 0; batch classifier loss: 0.053209; batch adversarial loss: 0.416668\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039816; batch adversarial loss: 0.433669\n",
      "epoch 146; iter: 0; batch classifier loss: 0.108825; batch adversarial loss: 0.413088\n",
      "epoch 147; iter: 0; batch classifier loss: 0.100861; batch adversarial loss: 0.336692\n",
      "epoch 148; iter: 0; batch classifier loss: 0.051749; batch adversarial loss: 0.508391\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037050; batch adversarial loss: 0.433568\n",
      "epoch 150; iter: 0; batch classifier loss: 0.077977; batch adversarial loss: 0.483423\n",
      "epoch 151; iter: 0; batch classifier loss: 0.062698; batch adversarial loss: 0.468338\n",
      "epoch 152; iter: 0; batch classifier loss: 0.050086; batch adversarial loss: 0.412368\n",
      "epoch 153; iter: 0; batch classifier loss: 0.052597; batch adversarial loss: 0.298616\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031925; batch adversarial loss: 0.474665\n",
      "epoch 155; iter: 0; batch classifier loss: 0.083131; batch adversarial loss: 0.436266\n",
      "epoch 156; iter: 0; batch classifier loss: 0.053906; batch adversarial loss: 0.501203\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040254; batch adversarial loss: 0.334383\n",
      "epoch 158; iter: 0; batch classifier loss: 0.047716; batch adversarial loss: 0.461762\n",
      "epoch 159; iter: 0; batch classifier loss: 0.060599; batch adversarial loss: 0.453748\n",
      "epoch 160; iter: 0; batch classifier loss: 0.078949; batch adversarial loss: 0.453979\n",
      "epoch 161; iter: 0; batch classifier loss: 0.056648; batch adversarial loss: 0.428659\n",
      "epoch 162; iter: 0; batch classifier loss: 0.069497; batch adversarial loss: 0.461168\n",
      "epoch 163; iter: 0; batch classifier loss: 0.047638; batch adversarial loss: 0.460387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.048995; batch adversarial loss: 0.409688\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044001; batch adversarial loss: 0.393628\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045275; batch adversarial loss: 0.417756\n",
      "epoch 167; iter: 0; batch classifier loss: 0.052531; batch adversarial loss: 0.419608\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032248; batch adversarial loss: 0.536609\n",
      "epoch 169; iter: 0; batch classifier loss: 0.088442; batch adversarial loss: 0.501830\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035501; batch adversarial loss: 0.409465\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036412; batch adversarial loss: 0.485304\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017486; batch adversarial loss: 0.412415\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034814; batch adversarial loss: 0.455117\n",
      "epoch 174; iter: 0; batch classifier loss: 0.054970; batch adversarial loss: 0.418743\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037747; batch adversarial loss: 0.554543\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045550; batch adversarial loss: 0.404965\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032401; batch adversarial loss: 0.456128\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030634; batch adversarial loss: 0.538703\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030801; batch adversarial loss: 0.364048\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029285; batch adversarial loss: 0.532384\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034062; batch adversarial loss: 0.424814\n",
      "epoch 182; iter: 0; batch classifier loss: 0.053901; batch adversarial loss: 0.443539\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031123; batch adversarial loss: 0.407488\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027180; batch adversarial loss: 0.377520\n",
      "epoch 185; iter: 0; batch classifier loss: 0.043669; batch adversarial loss: 0.394084\n",
      "epoch 186; iter: 0; batch classifier loss: 0.051029; batch adversarial loss: 0.423334\n",
      "epoch 187; iter: 0; batch classifier loss: 0.046923; batch adversarial loss: 0.416357\n",
      "epoch 188; iter: 0; batch classifier loss: 0.039359; batch adversarial loss: 0.412538\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041205; batch adversarial loss: 0.499452\n",
      "epoch 190; iter: 0; batch classifier loss: 0.048437; batch adversarial loss: 0.400074\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028143; batch adversarial loss: 0.442689\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031859; batch adversarial loss: 0.388648\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035392; batch adversarial loss: 0.488324\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017897; batch adversarial loss: 0.415824\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021762; batch adversarial loss: 0.423342\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021761; batch adversarial loss: 0.482077\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018950; batch adversarial loss: 0.512605\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028177; batch adversarial loss: 0.448150\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023063; batch adversarial loss: 0.409034\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683208; batch adversarial loss: 0.591374\n",
      "epoch 1; iter: 0; batch classifier loss: 0.409126; batch adversarial loss: 0.605394\n",
      "epoch 2; iter: 0; batch classifier loss: 0.444777; batch adversarial loss: 0.602663\n",
      "epoch 3; iter: 0; batch classifier loss: 0.335417; batch adversarial loss: 0.606169\n",
      "epoch 4; iter: 0; batch classifier loss: 0.385407; batch adversarial loss: 0.592745\n",
      "epoch 5; iter: 0; batch classifier loss: 0.414130; batch adversarial loss: 0.572278\n",
      "epoch 6; iter: 0; batch classifier loss: 0.379506; batch adversarial loss: 0.651442\n",
      "epoch 7; iter: 0; batch classifier loss: 0.611911; batch adversarial loss: 0.596630\n",
      "epoch 8; iter: 0; batch classifier loss: 0.517687; batch adversarial loss: 0.595823\n",
      "epoch 9; iter: 0; batch classifier loss: 0.628602; batch adversarial loss: 0.546977\n",
      "epoch 10; iter: 0; batch classifier loss: 0.448557; batch adversarial loss: 0.600846\n",
      "epoch 11; iter: 0; batch classifier loss: 0.374733; batch adversarial loss: 0.488178\n",
      "epoch 12; iter: 0; batch classifier loss: 0.339445; batch adversarial loss: 0.557766\n",
      "epoch 13; iter: 0; batch classifier loss: 0.257285; batch adversarial loss: 0.515370\n",
      "epoch 14; iter: 0; batch classifier loss: 0.253382; batch adversarial loss: 0.496693\n",
      "epoch 15; iter: 0; batch classifier loss: 0.318754; batch adversarial loss: 0.469795\n",
      "epoch 16; iter: 0; batch classifier loss: 0.306859; batch adversarial loss: 0.527755\n",
      "epoch 17; iter: 0; batch classifier loss: 0.287036; batch adversarial loss: 0.476113\n",
      "epoch 18; iter: 0; batch classifier loss: 0.235268; batch adversarial loss: 0.426989\n",
      "epoch 19; iter: 0; batch classifier loss: 0.255754; batch adversarial loss: 0.431949\n",
      "epoch 20; iter: 0; batch classifier loss: 0.271360; batch adversarial loss: 0.482627\n",
      "epoch 21; iter: 0; batch classifier loss: 0.273337; batch adversarial loss: 0.446810\n",
      "epoch 22; iter: 0; batch classifier loss: 0.281139; batch adversarial loss: 0.430076\n",
      "epoch 23; iter: 0; batch classifier loss: 0.231072; batch adversarial loss: 0.481607\n",
      "epoch 24; iter: 0; batch classifier loss: 0.222473; batch adversarial loss: 0.459538\n",
      "epoch 25; iter: 0; batch classifier loss: 0.198049; batch adversarial loss: 0.474199\n",
      "epoch 26; iter: 0; batch classifier loss: 0.212063; batch adversarial loss: 0.413238\n",
      "epoch 27; iter: 0; batch classifier loss: 0.204109; batch adversarial loss: 0.469639\n",
      "epoch 28; iter: 0; batch classifier loss: 0.186762; batch adversarial loss: 0.509024\n",
      "epoch 29; iter: 0; batch classifier loss: 0.228719; batch adversarial loss: 0.446526\n",
      "epoch 30; iter: 0; batch classifier loss: 0.218436; batch adversarial loss: 0.507706\n",
      "epoch 31; iter: 0; batch classifier loss: 0.146832; batch adversarial loss: 0.521189\n",
      "epoch 32; iter: 0; batch classifier loss: 0.210415; batch adversarial loss: 0.474608\n",
      "epoch 33; iter: 0; batch classifier loss: 0.171721; batch adversarial loss: 0.527423\n",
      "epoch 34; iter: 0; batch classifier loss: 0.207047; batch adversarial loss: 0.422098\n",
      "epoch 35; iter: 0; batch classifier loss: 0.244574; batch adversarial loss: 0.483350\n",
      "epoch 36; iter: 0; batch classifier loss: 0.213713; batch adversarial loss: 0.389013\n",
      "epoch 37; iter: 0; batch classifier loss: 0.178079; batch adversarial loss: 0.493665\n",
      "epoch 38; iter: 0; batch classifier loss: 0.175348; batch adversarial loss: 0.508896\n",
      "epoch 39; iter: 0; batch classifier loss: 0.152809; batch adversarial loss: 0.489070\n",
      "epoch 40; iter: 0; batch classifier loss: 0.181397; batch adversarial loss: 0.483304\n",
      "epoch 41; iter: 0; batch classifier loss: 0.184961; batch adversarial loss: 0.455785\n",
      "epoch 42; iter: 0; batch classifier loss: 0.172280; batch adversarial loss: 0.468579\n",
      "epoch 43; iter: 0; batch classifier loss: 0.250725; batch adversarial loss: 0.391608\n",
      "epoch 44; iter: 0; batch classifier loss: 0.235466; batch adversarial loss: 0.480819\n",
      "epoch 45; iter: 0; batch classifier loss: 0.235728; batch adversarial loss: 0.492238\n",
      "epoch 46; iter: 0; batch classifier loss: 0.234483; batch adversarial loss: 0.469223\n",
      "epoch 47; iter: 0; batch classifier loss: 0.211066; batch adversarial loss: 0.375296\n",
      "epoch 48; iter: 0; batch classifier loss: 0.196665; batch adversarial loss: 0.410446\n",
      "epoch 49; iter: 0; batch classifier loss: 0.194337; batch adversarial loss: 0.460620\n",
      "epoch 50; iter: 0; batch classifier loss: 0.224454; batch adversarial loss: 0.460228\n",
      "epoch 51; iter: 0; batch classifier loss: 0.233689; batch adversarial loss: 0.447717\n",
      "epoch 52; iter: 0; batch classifier loss: 0.196890; batch adversarial loss: 0.436486\n",
      "epoch 53; iter: 0; batch classifier loss: 0.208263; batch adversarial loss: 0.483637\n",
      "epoch 54; iter: 0; batch classifier loss: 0.204221; batch adversarial loss: 0.422773\n",
      "epoch 55; iter: 0; batch classifier loss: 0.113330; batch adversarial loss: 0.398885\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119461; batch adversarial loss: 0.432361\n",
      "epoch 57; iter: 0; batch classifier loss: 0.091041; batch adversarial loss: 0.455975\n",
      "epoch 58; iter: 0; batch classifier loss: 0.102247; batch adversarial loss: 0.447183\n",
      "epoch 59; iter: 0; batch classifier loss: 0.074029; batch adversarial loss: 0.456367\n",
      "epoch 60; iter: 0; batch classifier loss: 0.099259; batch adversarial loss: 0.446413\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071916; batch adversarial loss: 0.435124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.073166; batch adversarial loss: 0.401693\n",
      "epoch 63; iter: 0; batch classifier loss: 0.109617; batch adversarial loss: 0.625534\n",
      "epoch 64; iter: 0; batch classifier loss: 0.051512; batch adversarial loss: 0.501236\n",
      "epoch 65; iter: 0; batch classifier loss: 0.094202; batch adversarial loss: 0.517262\n",
      "epoch 66; iter: 0; batch classifier loss: 0.115511; batch adversarial loss: 0.497984\n",
      "epoch 67; iter: 0; batch classifier loss: 0.137714; batch adversarial loss: 0.499852\n",
      "epoch 68; iter: 0; batch classifier loss: 0.131461; batch adversarial loss: 0.487673\n",
      "epoch 69; iter: 0; batch classifier loss: 0.154745; batch adversarial loss: 0.496490\n",
      "epoch 70; iter: 0; batch classifier loss: 0.064452; batch adversarial loss: 0.485962\n",
      "epoch 71; iter: 0; batch classifier loss: 0.123392; batch adversarial loss: 0.468351\n",
      "epoch 72; iter: 0; batch classifier loss: 0.084022; batch adversarial loss: 0.397183\n",
      "epoch 73; iter: 0; batch classifier loss: 0.096332; batch adversarial loss: 0.420034\n",
      "epoch 74; iter: 0; batch classifier loss: 0.095692; batch adversarial loss: 0.501485\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063106; batch adversarial loss: 0.483520\n",
      "epoch 76; iter: 0; batch classifier loss: 0.090614; batch adversarial loss: 0.370572\n",
      "epoch 77; iter: 0; batch classifier loss: 0.052516; batch adversarial loss: 0.436147\n",
      "epoch 78; iter: 0; batch classifier loss: 0.097478; batch adversarial loss: 0.510329\n",
      "epoch 79; iter: 0; batch classifier loss: 0.078617; batch adversarial loss: 0.423946\n",
      "epoch 80; iter: 0; batch classifier loss: 0.052837; batch adversarial loss: 0.383076\n",
      "epoch 81; iter: 0; batch classifier loss: 0.058037; batch adversarial loss: 0.460294\n",
      "epoch 82; iter: 0; batch classifier loss: 0.112218; batch adversarial loss: 0.426194\n",
      "epoch 83; iter: 0; batch classifier loss: 0.043033; batch adversarial loss: 0.389210\n",
      "epoch 84; iter: 0; batch classifier loss: 0.103354; batch adversarial loss: 0.430967\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051511; batch adversarial loss: 0.379396\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053471; batch adversarial loss: 0.522301\n",
      "epoch 87; iter: 0; batch classifier loss: 0.081398; batch adversarial loss: 0.435713\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078472; batch adversarial loss: 0.417857\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056115; batch adversarial loss: 0.398959\n",
      "epoch 90; iter: 0; batch classifier loss: 0.093688; batch adversarial loss: 0.361424\n",
      "epoch 91; iter: 0; batch classifier loss: 0.058212; batch adversarial loss: 0.443860\n",
      "epoch 92; iter: 0; batch classifier loss: 0.049591; batch adversarial loss: 0.578068\n",
      "epoch 93; iter: 0; batch classifier loss: 0.095894; batch adversarial loss: 0.424550\n",
      "epoch 94; iter: 0; batch classifier loss: 0.063875; batch adversarial loss: 0.436383\n",
      "epoch 95; iter: 0; batch classifier loss: 0.019394; batch adversarial loss: 0.527250\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048394; batch adversarial loss: 0.445850\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081788; batch adversarial loss: 0.466274\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046988; batch adversarial loss: 0.588425\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053393; batch adversarial loss: 0.450160\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067320; batch adversarial loss: 0.505374\n",
      "epoch 101; iter: 0; batch classifier loss: 0.086437; batch adversarial loss: 0.565480\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031061; batch adversarial loss: 0.408152\n",
      "epoch 103; iter: 0; batch classifier loss: 0.031202; batch adversarial loss: 0.502297\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034987; batch adversarial loss: 0.378595\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030038; batch adversarial loss: 0.462268\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037590; batch adversarial loss: 0.556473\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033300; batch adversarial loss: 0.409482\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041207; batch adversarial loss: 0.472992\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027599; batch adversarial loss: 0.564698\n",
      "epoch 110; iter: 0; batch classifier loss: 0.056660; batch adversarial loss: 0.396155\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044934; batch adversarial loss: 0.427340\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037166; batch adversarial loss: 0.484043\n",
      "epoch 113; iter: 0; batch classifier loss: 0.024592; batch adversarial loss: 0.423611\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042783; batch adversarial loss: 0.402711\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027936; batch adversarial loss: 0.399814\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046366; batch adversarial loss: 0.428994\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028527; batch adversarial loss: 0.461203\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047940; batch adversarial loss: 0.413629\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034070; batch adversarial loss: 0.389343\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045979; batch adversarial loss: 0.419280\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060364; batch adversarial loss: 0.405089\n",
      "epoch 122; iter: 0; batch classifier loss: 0.018400; batch adversarial loss: 0.478253\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021233; batch adversarial loss: 0.410122\n",
      "epoch 124; iter: 0; batch classifier loss: 0.062035; batch adversarial loss: 0.450325\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020720; batch adversarial loss: 0.482426\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027294; batch adversarial loss: 0.520042\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028237; batch adversarial loss: 0.438844\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025786; batch adversarial loss: 0.496209\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026915; batch adversarial loss: 0.469041\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029470; batch adversarial loss: 0.510569\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036849; batch adversarial loss: 0.460559\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024070; batch adversarial loss: 0.436149\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025228; batch adversarial loss: 0.515296\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050400; batch adversarial loss: 0.428558\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021640; batch adversarial loss: 0.417275\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040782; batch adversarial loss: 0.472420\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024948; batch adversarial loss: 0.467738\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033218; batch adversarial loss: 0.439080\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010291; batch adversarial loss: 0.424240\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019540; batch adversarial loss: 0.446831\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017982; batch adversarial loss: 0.473805\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036359; batch adversarial loss: 0.515042\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016210; batch adversarial loss: 0.452442\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016079; batch adversarial loss: 0.411537\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038676; batch adversarial loss: 0.480523\n",
      "epoch 146; iter: 0; batch classifier loss: 0.033281; batch adversarial loss: 0.388423\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020226; batch adversarial loss: 0.495486\n",
      "epoch 148; iter: 0; batch classifier loss: 0.011496; batch adversarial loss: 0.383095\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019382; batch adversarial loss: 0.402257\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022132; batch adversarial loss: 0.411251\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039466; batch adversarial loss: 0.472493\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026052; batch adversarial loss: 0.434826\n",
      "epoch 153; iter: 0; batch classifier loss: 0.073726; batch adversarial loss: 0.458122\n",
      "epoch 154; iter: 0; batch classifier loss: 0.048634; batch adversarial loss: 0.468414\n",
      "epoch 155; iter: 0; batch classifier loss: 0.006057; batch adversarial loss: 0.375483\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040448; batch adversarial loss: 0.468254\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013392; batch adversarial loss: 0.473207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.024889; batch adversarial loss: 0.433147\n",
      "epoch 159; iter: 0; batch classifier loss: 0.042851; batch adversarial loss: 0.378345\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017223; batch adversarial loss: 0.450163\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017576; batch adversarial loss: 0.469370\n",
      "epoch 162; iter: 0; batch classifier loss: 0.040294; batch adversarial loss: 0.414679\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026304; batch adversarial loss: 0.459163\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021957; batch adversarial loss: 0.438435\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030848; batch adversarial loss: 0.465339\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024313; batch adversarial loss: 0.471825\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036373; batch adversarial loss: 0.439321\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016593; batch adversarial loss: 0.505990\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025004; batch adversarial loss: 0.452853\n",
      "epoch 170; iter: 0; batch classifier loss: 0.046044; batch adversarial loss: 0.427610\n",
      "epoch 171; iter: 0; batch classifier loss: 0.045771; batch adversarial loss: 0.512684\n",
      "epoch 172; iter: 0; batch classifier loss: 0.038536; batch adversarial loss: 0.414461\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033501; batch adversarial loss: 0.451364\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009869; batch adversarial loss: 0.493804\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015667; batch adversarial loss: 0.445678\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032591; batch adversarial loss: 0.459866\n",
      "epoch 177; iter: 0; batch classifier loss: 0.039150; batch adversarial loss: 0.367138\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015954; batch adversarial loss: 0.385306\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020773; batch adversarial loss: 0.486337\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023325; batch adversarial loss: 0.359368\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037492; batch adversarial loss: 0.500393\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026191; batch adversarial loss: 0.448967\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012273; batch adversarial loss: 0.360476\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013171; batch adversarial loss: 0.416908\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022179; batch adversarial loss: 0.522395\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022080; batch adversarial loss: 0.364018\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015978; batch adversarial loss: 0.471129\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010292; batch adversarial loss: 0.474874\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006609; batch adversarial loss: 0.480038\n",
      "epoch 190; iter: 0; batch classifier loss: 0.002608; batch adversarial loss: 0.506584\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012213; batch adversarial loss: 0.397739\n",
      "epoch 192; iter: 0; batch classifier loss: 0.003569; batch adversarial loss: 0.479320\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013641; batch adversarial loss: 0.461654\n",
      "epoch 194; iter: 0; batch classifier loss: 0.038856; batch adversarial loss: 0.463931\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016126; batch adversarial loss: 0.394597\n",
      "epoch 196; iter: 0; batch classifier loss: 0.003499; batch adversarial loss: 0.458684\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006746; batch adversarial loss: 0.448560\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016219; batch adversarial loss: 0.398871\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021581; batch adversarial loss: 0.470690\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705926; batch adversarial loss: 0.489936\n",
      "epoch 1; iter: 0; batch classifier loss: 0.416889; batch adversarial loss: 0.581424\n",
      "epoch 2; iter: 0; batch classifier loss: 0.376968; batch adversarial loss: 0.610550\n",
      "epoch 3; iter: 0; batch classifier loss: 0.390528; batch adversarial loss: 0.576960\n",
      "epoch 4; iter: 0; batch classifier loss: 0.405892; batch adversarial loss: 0.548878\n",
      "epoch 5; iter: 0; batch classifier loss: 0.424371; batch adversarial loss: 0.554973\n",
      "epoch 6; iter: 0; batch classifier loss: 0.375229; batch adversarial loss: 0.524863\n",
      "epoch 7; iter: 0; batch classifier loss: 0.441793; batch adversarial loss: 0.592428\n",
      "epoch 8; iter: 0; batch classifier loss: 0.476574; batch adversarial loss: 0.527124\n",
      "epoch 9; iter: 0; batch classifier loss: 0.665106; batch adversarial loss: 0.633045\n",
      "epoch 10; iter: 0; batch classifier loss: 0.612923; batch adversarial loss: 0.542217\n",
      "epoch 11; iter: 0; batch classifier loss: 0.697047; batch adversarial loss: 0.564962\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514876; batch adversarial loss: 0.534460\n",
      "epoch 13; iter: 0; batch classifier loss: 0.421265; batch adversarial loss: 0.504964\n",
      "epoch 14; iter: 0; batch classifier loss: 0.402702; batch adversarial loss: 0.496805\n",
      "epoch 15; iter: 0; batch classifier loss: 0.331117; batch adversarial loss: 0.426111\n",
      "epoch 16; iter: 0; batch classifier loss: 0.306454; batch adversarial loss: 0.469080\n",
      "epoch 17; iter: 0; batch classifier loss: 0.209907; batch adversarial loss: 0.488516\n",
      "epoch 18; iter: 0; batch classifier loss: 0.209640; batch adversarial loss: 0.448046\n",
      "epoch 19; iter: 0; batch classifier loss: 0.265481; batch adversarial loss: 0.437983\n",
      "epoch 20; iter: 0; batch classifier loss: 0.261987; batch adversarial loss: 0.438105\n",
      "epoch 21; iter: 0; batch classifier loss: 0.240424; batch adversarial loss: 0.532218\n",
      "epoch 22; iter: 0; batch classifier loss: 0.229277; batch adversarial loss: 0.432829\n",
      "epoch 23; iter: 0; batch classifier loss: 0.185704; batch adversarial loss: 0.417715\n",
      "epoch 24; iter: 0; batch classifier loss: 0.171504; batch adversarial loss: 0.485592\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215588; batch adversarial loss: 0.434458\n",
      "epoch 26; iter: 0; batch classifier loss: 0.158103; batch adversarial loss: 0.401314\n",
      "epoch 27; iter: 0; batch classifier loss: 0.233981; batch adversarial loss: 0.451490\n",
      "epoch 28; iter: 0; batch classifier loss: 0.191598; batch adversarial loss: 0.410986\n",
      "epoch 29; iter: 0; batch classifier loss: 0.176677; batch adversarial loss: 0.486481\n",
      "epoch 30; iter: 0; batch classifier loss: 0.165926; batch adversarial loss: 0.502040\n",
      "epoch 31; iter: 0; batch classifier loss: 0.169278; batch adversarial loss: 0.387226\n",
      "epoch 32; iter: 0; batch classifier loss: 0.162858; batch adversarial loss: 0.456844\n",
      "epoch 33; iter: 0; batch classifier loss: 0.168631; batch adversarial loss: 0.524877\n",
      "epoch 34; iter: 0; batch classifier loss: 0.165574; batch adversarial loss: 0.521783\n",
      "epoch 35; iter: 0; batch classifier loss: 0.197080; batch adversarial loss: 0.410861\n",
      "epoch 36; iter: 0; batch classifier loss: 0.175796; batch adversarial loss: 0.448523\n",
      "epoch 37; iter: 0; batch classifier loss: 0.118440; batch adversarial loss: 0.448475\n",
      "epoch 38; iter: 0; batch classifier loss: 0.133205; batch adversarial loss: 0.425236\n",
      "epoch 39; iter: 0; batch classifier loss: 0.171677; batch adversarial loss: 0.433149\n",
      "epoch 40; iter: 0; batch classifier loss: 0.153988; batch adversarial loss: 0.432013\n",
      "epoch 41; iter: 0; batch classifier loss: 0.159672; batch adversarial loss: 0.424695\n",
      "epoch 42; iter: 0; batch classifier loss: 0.184482; batch adversarial loss: 0.455034\n",
      "epoch 43; iter: 0; batch classifier loss: 0.221372; batch adversarial loss: 0.420822\n",
      "epoch 44; iter: 0; batch classifier loss: 0.163126; batch adversarial loss: 0.466076\n",
      "epoch 45; iter: 0; batch classifier loss: 0.198633; batch adversarial loss: 0.386025\n",
      "epoch 46; iter: 0; batch classifier loss: 0.172613; batch adversarial loss: 0.407508\n",
      "epoch 47; iter: 0; batch classifier loss: 0.216143; batch adversarial loss: 0.382372\n",
      "epoch 48; iter: 0; batch classifier loss: 0.161856; batch adversarial loss: 0.490145\n",
      "epoch 49; iter: 0; batch classifier loss: 0.197047; batch adversarial loss: 0.517647\n",
      "epoch 50; iter: 0; batch classifier loss: 0.196022; batch adversarial loss: 0.502840\n",
      "epoch 51; iter: 0; batch classifier loss: 0.198778; batch adversarial loss: 0.405733\n",
      "epoch 52; iter: 0; batch classifier loss: 0.183107; batch adversarial loss: 0.444635\n",
      "epoch 53; iter: 0; batch classifier loss: 0.204978; batch adversarial loss: 0.470485\n",
      "epoch 54; iter: 0; batch classifier loss: 0.167738; batch adversarial loss: 0.482069\n",
      "epoch 55; iter: 0; batch classifier loss: 0.181321; batch adversarial loss: 0.452722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.164698; batch adversarial loss: 0.505189\n",
      "epoch 57; iter: 0; batch classifier loss: 0.153259; batch adversarial loss: 0.519850\n",
      "epoch 58; iter: 0; batch classifier loss: 0.146655; batch adversarial loss: 0.417537\n",
      "epoch 59; iter: 0; batch classifier loss: 0.166395; batch adversarial loss: 0.581265\n",
      "epoch 60; iter: 0; batch classifier loss: 0.162564; batch adversarial loss: 0.444512\n",
      "epoch 61; iter: 0; batch classifier loss: 0.198554; batch adversarial loss: 0.371526\n",
      "epoch 62; iter: 0; batch classifier loss: 0.236172; batch adversarial loss: 0.386428\n",
      "epoch 63; iter: 0; batch classifier loss: 0.123265; batch adversarial loss: 0.511982\n",
      "epoch 64; iter: 0; batch classifier loss: 0.189011; batch adversarial loss: 0.496888\n",
      "epoch 65; iter: 0; batch classifier loss: 0.211622; batch adversarial loss: 0.433490\n",
      "epoch 66; iter: 0; batch classifier loss: 0.247787; batch adversarial loss: 0.422572\n",
      "epoch 67; iter: 0; batch classifier loss: 0.174013; batch adversarial loss: 0.470748\n",
      "epoch 68; iter: 0; batch classifier loss: 0.197690; batch adversarial loss: 0.434593\n",
      "epoch 69; iter: 0; batch classifier loss: 0.171308; batch adversarial loss: 0.459707\n",
      "epoch 70; iter: 0; batch classifier loss: 0.164582; batch adversarial loss: 0.396728\n",
      "epoch 71; iter: 0; batch classifier loss: 0.139375; batch adversarial loss: 0.471370\n",
      "epoch 72; iter: 0; batch classifier loss: 0.143374; batch adversarial loss: 0.421655\n",
      "epoch 73; iter: 0; batch classifier loss: 0.114914; batch adversarial loss: 0.382403\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089665; batch adversarial loss: 0.430663\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096645; batch adversarial loss: 0.396077\n",
      "epoch 76; iter: 0; batch classifier loss: 0.118882; batch adversarial loss: 0.467635\n",
      "epoch 77; iter: 0; batch classifier loss: 0.153119; batch adversarial loss: 0.441111\n",
      "epoch 78; iter: 0; batch classifier loss: 0.192755; batch adversarial loss: 0.412413\n",
      "epoch 79; iter: 0; batch classifier loss: 0.140496; batch adversarial loss: 0.497023\n",
      "epoch 80; iter: 0; batch classifier loss: 0.164852; batch adversarial loss: 0.458721\n",
      "epoch 81; iter: 0; batch classifier loss: 0.131376; batch adversarial loss: 0.511559\n",
      "epoch 82; iter: 0; batch classifier loss: 0.111153; batch adversarial loss: 0.432110\n",
      "epoch 83; iter: 0; batch classifier loss: 0.154513; batch adversarial loss: 0.447101\n",
      "epoch 84; iter: 0; batch classifier loss: 0.142129; batch adversarial loss: 0.386154\n",
      "epoch 85; iter: 0; batch classifier loss: 0.104552; batch adversarial loss: 0.470584\n",
      "epoch 86; iter: 0; batch classifier loss: 0.108685; batch adversarial loss: 0.421850\n",
      "epoch 87; iter: 0; batch classifier loss: 0.205838; batch adversarial loss: 0.435138\n",
      "epoch 88; iter: 0; batch classifier loss: 0.143931; batch adversarial loss: 0.398026\n",
      "epoch 89; iter: 0; batch classifier loss: 0.122752; batch adversarial loss: 0.459634\n",
      "epoch 90; iter: 0; batch classifier loss: 0.136489; batch adversarial loss: 0.488974\n",
      "epoch 91; iter: 0; batch classifier loss: 0.161378; batch adversarial loss: 0.595111\n",
      "epoch 92; iter: 0; batch classifier loss: 0.181563; batch adversarial loss: 0.442350\n",
      "epoch 93; iter: 0; batch classifier loss: 0.152152; batch adversarial loss: 0.475267\n",
      "epoch 94; iter: 0; batch classifier loss: 0.204305; batch adversarial loss: 0.357236\n",
      "epoch 95; iter: 0; batch classifier loss: 0.189637; batch adversarial loss: 0.510612\n",
      "epoch 96; iter: 0; batch classifier loss: 0.159685; batch adversarial loss: 0.421543\n",
      "epoch 97; iter: 0; batch classifier loss: 0.126773; batch adversarial loss: 0.481470\n",
      "epoch 98; iter: 0; batch classifier loss: 0.187549; batch adversarial loss: 0.422368\n",
      "epoch 99; iter: 0; batch classifier loss: 0.169175; batch adversarial loss: 0.495873\n",
      "epoch 100; iter: 0; batch classifier loss: 0.122332; batch adversarial loss: 0.594252\n",
      "epoch 101; iter: 0; batch classifier loss: 0.108063; batch adversarial loss: 0.446164\n",
      "epoch 102; iter: 0; batch classifier loss: 0.134424; batch adversarial loss: 0.369842\n",
      "epoch 103; iter: 0; batch classifier loss: 0.146949; batch adversarial loss: 0.557641\n",
      "epoch 104; iter: 0; batch classifier loss: 0.146311; batch adversarial loss: 0.456392\n",
      "epoch 105; iter: 0; batch classifier loss: 0.136533; batch adversarial loss: 0.443359\n",
      "epoch 106; iter: 0; batch classifier loss: 0.126292; batch adversarial loss: 0.357849\n",
      "epoch 107; iter: 0; batch classifier loss: 0.129100; batch adversarial loss: 0.394772\n",
      "epoch 108; iter: 0; batch classifier loss: 0.161678; batch adversarial loss: 0.440818\n",
      "epoch 109; iter: 0; batch classifier loss: 0.167537; batch adversarial loss: 0.498549\n",
      "epoch 110; iter: 0; batch classifier loss: 0.107555; batch adversarial loss: 0.452109\n",
      "epoch 111; iter: 0; batch classifier loss: 0.108659; batch adversarial loss: 0.493838\n",
      "epoch 112; iter: 0; batch classifier loss: 0.163336; batch adversarial loss: 0.533315\n",
      "epoch 113; iter: 0; batch classifier loss: 0.142573; batch adversarial loss: 0.483799\n",
      "epoch 114; iter: 0; batch classifier loss: 0.098006; batch adversarial loss: 0.391412\n",
      "epoch 115; iter: 0; batch classifier loss: 0.143208; batch adversarial loss: 0.474157\n",
      "epoch 116; iter: 0; batch classifier loss: 0.133045; batch adversarial loss: 0.486308\n",
      "epoch 117; iter: 0; batch classifier loss: 0.077931; batch adversarial loss: 0.485068\n",
      "epoch 118; iter: 0; batch classifier loss: 0.082147; batch adversarial loss: 0.440755\n",
      "epoch 119; iter: 0; batch classifier loss: 0.083904; batch adversarial loss: 0.457175\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057413; batch adversarial loss: 0.419124\n",
      "epoch 121; iter: 0; batch classifier loss: 0.071359; batch adversarial loss: 0.502163\n",
      "epoch 122; iter: 0; batch classifier loss: 0.069815; batch adversarial loss: 0.404884\n",
      "epoch 123; iter: 0; batch classifier loss: 0.066059; batch adversarial loss: 0.448280\n",
      "epoch 124; iter: 0; batch classifier loss: 0.090326; batch adversarial loss: 0.444681\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025080; batch adversarial loss: 0.477831\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046542; batch adversarial loss: 0.411523\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047405; batch adversarial loss: 0.389076\n",
      "epoch 128; iter: 0; batch classifier loss: 0.060585; batch adversarial loss: 0.439534\n",
      "epoch 129; iter: 0; batch classifier loss: 0.064299; batch adversarial loss: 0.403548\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050691; batch adversarial loss: 0.506844\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038140; batch adversarial loss: 0.477729\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053376; batch adversarial loss: 0.463303\n",
      "epoch 133; iter: 0; batch classifier loss: 0.048778; batch adversarial loss: 0.459138\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027564; batch adversarial loss: 0.463931\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041564; batch adversarial loss: 0.379714\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024670; batch adversarial loss: 0.425123\n",
      "epoch 137; iter: 0; batch classifier loss: 0.063318; batch adversarial loss: 0.506619\n",
      "epoch 138; iter: 0; batch classifier loss: 0.052851; batch adversarial loss: 0.426137\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034102; batch adversarial loss: 0.461525\n",
      "epoch 140; iter: 0; batch classifier loss: 0.052579; batch adversarial loss: 0.483885\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032284; batch adversarial loss: 0.481254\n",
      "epoch 142; iter: 0; batch classifier loss: 0.071250; batch adversarial loss: 0.442417\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025379; batch adversarial loss: 0.537234\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027217; batch adversarial loss: 0.468275\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048807; batch adversarial loss: 0.438420\n",
      "epoch 146; iter: 0; batch classifier loss: 0.049859; batch adversarial loss: 0.492982\n",
      "epoch 147; iter: 0; batch classifier loss: 0.064963; batch adversarial loss: 0.400486\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026019; batch adversarial loss: 0.607508\n",
      "epoch 149; iter: 0; batch classifier loss: 0.043876; batch adversarial loss: 0.483090\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052381; batch adversarial loss: 0.436276\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026046; batch adversarial loss: 0.368706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.025728; batch adversarial loss: 0.444753\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019605; batch adversarial loss: 0.507446\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031400; batch adversarial loss: 0.368188\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027494; batch adversarial loss: 0.464682\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044587; batch adversarial loss: 0.366845\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032961; batch adversarial loss: 0.441389\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038615; batch adversarial loss: 0.414884\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018744; batch adversarial loss: 0.495011\n",
      "epoch 160; iter: 0; batch classifier loss: 0.050614; batch adversarial loss: 0.429557\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019540; batch adversarial loss: 0.442284\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032157; batch adversarial loss: 0.417175\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036649; batch adversarial loss: 0.408754\n",
      "epoch 164; iter: 0; batch classifier loss: 0.067732; batch adversarial loss: 0.393514\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014728; batch adversarial loss: 0.492127\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018408; batch adversarial loss: 0.429117\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025717; batch adversarial loss: 0.428952\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013450; batch adversarial loss: 0.355646\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044270; batch adversarial loss: 0.467879\n",
      "epoch 170; iter: 0; batch classifier loss: 0.041900; batch adversarial loss: 0.527551\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020206; batch adversarial loss: 0.461084\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034726; batch adversarial loss: 0.557984\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032935; batch adversarial loss: 0.505985\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010345; batch adversarial loss: 0.456390\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035488; batch adversarial loss: 0.404993\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008764; batch adversarial loss: 0.482335\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036931; batch adversarial loss: 0.438608\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020109; batch adversarial loss: 0.500775\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024864; batch adversarial loss: 0.458320\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014146; batch adversarial loss: 0.522418\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026748; batch adversarial loss: 0.519775\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011069; batch adversarial loss: 0.398404\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030451; batch adversarial loss: 0.483110\n",
      "epoch 184; iter: 0; batch classifier loss: 0.051059; batch adversarial loss: 0.449335\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009424; batch adversarial loss: 0.349534\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041498; batch adversarial loss: 0.486694\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021620; batch adversarial loss: 0.479296\n",
      "epoch 188; iter: 0; batch classifier loss: 0.045203; batch adversarial loss: 0.451260\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025289; batch adversarial loss: 0.436819\n",
      "epoch 190; iter: 0; batch classifier loss: 0.042518; batch adversarial loss: 0.487100\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030867; batch adversarial loss: 0.440570\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006001; batch adversarial loss: 0.532331\n",
      "epoch 193; iter: 0; batch classifier loss: 0.040063; batch adversarial loss: 0.356059\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004896; batch adversarial loss: 0.443641\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011626; batch adversarial loss: 0.405319\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016157; batch adversarial loss: 0.601293\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024218; batch adversarial loss: 0.558066\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024059; batch adversarial loss: 0.452023\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013208; batch adversarial loss: 0.474817\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686794; batch adversarial loss: 0.915533\n",
      "epoch 1; iter: 0; batch classifier loss: 0.493693; batch adversarial loss: 1.024867\n",
      "epoch 2; iter: 0; batch classifier loss: 0.723957; batch adversarial loss: 0.998472\n",
      "epoch 3; iter: 0; batch classifier loss: 0.969240; batch adversarial loss: 0.935281\n",
      "epoch 4; iter: 0; batch classifier loss: 0.890622; batch adversarial loss: 0.837374\n",
      "epoch 5; iter: 0; batch classifier loss: 0.961382; batch adversarial loss: 0.752157\n",
      "epoch 6; iter: 0; batch classifier loss: 0.934723; batch adversarial loss: 0.685589\n",
      "epoch 7; iter: 0; batch classifier loss: 0.820033; batch adversarial loss: 0.629751\n",
      "epoch 8; iter: 0; batch classifier loss: 0.764796; batch adversarial loss: 0.588766\n",
      "epoch 9; iter: 0; batch classifier loss: 0.328535; batch adversarial loss: 0.557889\n",
      "epoch 10; iter: 0; batch classifier loss: 0.310015; batch adversarial loss: 0.537918\n",
      "epoch 11; iter: 0; batch classifier loss: 0.357687; batch adversarial loss: 0.474631\n",
      "epoch 12; iter: 0; batch classifier loss: 0.337343; batch adversarial loss: 0.501257\n",
      "epoch 13; iter: 0; batch classifier loss: 0.241780; batch adversarial loss: 0.519563\n",
      "epoch 14; iter: 0; batch classifier loss: 0.172544; batch adversarial loss: 0.477454\n",
      "epoch 15; iter: 0; batch classifier loss: 0.235255; batch adversarial loss: 0.497866\n",
      "epoch 16; iter: 0; batch classifier loss: 0.132862; batch adversarial loss: 0.433994\n",
      "epoch 17; iter: 0; batch classifier loss: 0.199853; batch adversarial loss: 0.452285\n",
      "epoch 18; iter: 0; batch classifier loss: 0.151314; batch adversarial loss: 0.452645\n",
      "epoch 19; iter: 0; batch classifier loss: 0.202380; batch adversarial loss: 0.436136\n",
      "epoch 20; iter: 0; batch classifier loss: 0.175438; batch adversarial loss: 0.455694\n",
      "epoch 21; iter: 0; batch classifier loss: 0.156522; batch adversarial loss: 0.505911\n",
      "epoch 22; iter: 0; batch classifier loss: 0.111736; batch adversarial loss: 0.414386\n",
      "epoch 23; iter: 0; batch classifier loss: 0.116655; batch adversarial loss: 0.482706\n",
      "epoch 24; iter: 0; batch classifier loss: 0.159479; batch adversarial loss: 0.497456\n",
      "epoch 25; iter: 0; batch classifier loss: 0.102525; batch adversarial loss: 0.456958\n",
      "epoch 26; iter: 0; batch classifier loss: 0.150092; batch adversarial loss: 0.470213\n",
      "epoch 27; iter: 0; batch classifier loss: 0.090495; batch adversarial loss: 0.512456\n",
      "epoch 28; iter: 0; batch classifier loss: 0.142499; batch adversarial loss: 0.475567\n",
      "epoch 29; iter: 0; batch classifier loss: 0.110361; batch adversarial loss: 0.421519\n",
      "epoch 30; iter: 0; batch classifier loss: 0.085859; batch adversarial loss: 0.390008\n",
      "epoch 31; iter: 0; batch classifier loss: 0.152059; batch adversarial loss: 0.425327\n",
      "epoch 32; iter: 0; batch classifier loss: 0.082904; batch adversarial loss: 0.499279\n",
      "epoch 33; iter: 0; batch classifier loss: 0.116188; batch adversarial loss: 0.468380\n",
      "epoch 34; iter: 0; batch classifier loss: 0.093585; batch adversarial loss: 0.489497\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137184; batch adversarial loss: 0.491090\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141575; batch adversarial loss: 0.451125\n",
      "epoch 37; iter: 0; batch classifier loss: 0.087652; batch adversarial loss: 0.441739\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126406; batch adversarial loss: 0.445164\n",
      "epoch 39; iter: 0; batch classifier loss: 0.116771; batch adversarial loss: 0.385629\n",
      "epoch 40; iter: 0; batch classifier loss: 0.125873; batch adversarial loss: 0.420804\n",
      "epoch 41; iter: 0; batch classifier loss: 0.137260; batch adversarial loss: 0.409191\n",
      "epoch 42; iter: 0; batch classifier loss: 0.120965; batch adversarial loss: 0.400731\n",
      "epoch 43; iter: 0; batch classifier loss: 0.123864; batch adversarial loss: 0.440140\n",
      "epoch 44; iter: 0; batch classifier loss: 0.147703; batch adversarial loss: 0.454920\n",
      "epoch 45; iter: 0; batch classifier loss: 0.160464; batch adversarial loss: 0.460289\n",
      "epoch 46; iter: 0; batch classifier loss: 0.121872; batch adversarial loss: 0.452433\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096685; batch adversarial loss: 0.409988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.068604; batch adversarial loss: 0.501678\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080761; batch adversarial loss: 0.431026\n",
      "epoch 50; iter: 0; batch classifier loss: 0.129360; batch adversarial loss: 0.406822\n",
      "epoch 51; iter: 0; batch classifier loss: 0.079942; batch adversarial loss: 0.468434\n",
      "epoch 52; iter: 0; batch classifier loss: 0.094320; batch adversarial loss: 0.403916\n",
      "epoch 53; iter: 0; batch classifier loss: 0.067842; batch adversarial loss: 0.542419\n",
      "epoch 54; iter: 0; batch classifier loss: 0.069863; batch adversarial loss: 0.484952\n",
      "epoch 55; iter: 0; batch classifier loss: 0.100435; batch adversarial loss: 0.389056\n",
      "epoch 56; iter: 0; batch classifier loss: 0.049134; batch adversarial loss: 0.411701\n",
      "epoch 57; iter: 0; batch classifier loss: 0.048936; batch adversarial loss: 0.463760\n",
      "epoch 58; iter: 0; batch classifier loss: 0.039718; batch adversarial loss: 0.431228\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067559; batch adversarial loss: 0.431500\n",
      "epoch 60; iter: 0; batch classifier loss: 0.088260; batch adversarial loss: 0.416145\n",
      "epoch 61; iter: 0; batch classifier loss: 0.052466; batch adversarial loss: 0.507878\n",
      "epoch 62; iter: 0; batch classifier loss: 0.051797; batch adversarial loss: 0.507034\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104852; batch adversarial loss: 0.353881\n",
      "epoch 64; iter: 0; batch classifier loss: 0.048486; batch adversarial loss: 0.440209\n",
      "epoch 65; iter: 0; batch classifier loss: 0.064268; batch adversarial loss: 0.468190\n",
      "epoch 66; iter: 0; batch classifier loss: 0.045346; batch adversarial loss: 0.426620\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061275; batch adversarial loss: 0.413683\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060640; batch adversarial loss: 0.429076\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095510; batch adversarial loss: 0.450703\n",
      "epoch 70; iter: 0; batch classifier loss: 0.104310; batch adversarial loss: 0.466186\n",
      "epoch 71; iter: 0; batch classifier loss: 0.039937; batch adversarial loss: 0.382307\n",
      "epoch 72; iter: 0; batch classifier loss: 0.044788; batch adversarial loss: 0.503940\n",
      "epoch 73; iter: 0; batch classifier loss: 0.059139; batch adversarial loss: 0.453023\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069208; batch adversarial loss: 0.492213\n",
      "epoch 75; iter: 0; batch classifier loss: 0.058212; batch adversarial loss: 0.478663\n",
      "epoch 76; iter: 0; batch classifier loss: 0.039108; batch adversarial loss: 0.378750\n",
      "epoch 77; iter: 0; batch classifier loss: 0.040922; batch adversarial loss: 0.477686\n",
      "epoch 78; iter: 0; batch classifier loss: 0.086134; batch adversarial loss: 0.445877\n",
      "epoch 79; iter: 0; batch classifier loss: 0.039378; batch adversarial loss: 0.551419\n",
      "epoch 80; iter: 0; batch classifier loss: 0.033634; batch adversarial loss: 0.461524\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084148; batch adversarial loss: 0.437609\n",
      "epoch 82; iter: 0; batch classifier loss: 0.040517; batch adversarial loss: 0.402515\n",
      "epoch 83; iter: 0; batch classifier loss: 0.042983; batch adversarial loss: 0.499787\n",
      "epoch 84; iter: 0; batch classifier loss: 0.032129; batch adversarial loss: 0.386418\n",
      "epoch 85; iter: 0; batch classifier loss: 0.050016; batch adversarial loss: 0.417634\n",
      "epoch 86; iter: 0; batch classifier loss: 0.049883; batch adversarial loss: 0.381340\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047904; batch adversarial loss: 0.413516\n",
      "epoch 88; iter: 0; batch classifier loss: 0.107882; batch adversarial loss: 0.464265\n",
      "epoch 89; iter: 0; batch classifier loss: 0.034686; batch adversarial loss: 0.435147\n",
      "epoch 90; iter: 0; batch classifier loss: 0.069996; batch adversarial loss: 0.485505\n",
      "epoch 91; iter: 0; batch classifier loss: 0.024559; batch adversarial loss: 0.364803\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050113; batch adversarial loss: 0.460963\n",
      "epoch 93; iter: 0; batch classifier loss: 0.047590; batch adversarial loss: 0.338443\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048217; batch adversarial loss: 0.510959\n",
      "epoch 95; iter: 0; batch classifier loss: 0.036077; batch adversarial loss: 0.389993\n",
      "epoch 96; iter: 0; batch classifier loss: 0.034740; batch adversarial loss: 0.418747\n",
      "epoch 97; iter: 0; batch classifier loss: 0.040125; batch adversarial loss: 0.437010\n",
      "epoch 98; iter: 0; batch classifier loss: 0.080800; batch adversarial loss: 0.431904\n",
      "epoch 99; iter: 0; batch classifier loss: 0.023226; batch adversarial loss: 0.467847\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064392; batch adversarial loss: 0.324427\n",
      "epoch 101; iter: 0; batch classifier loss: 0.065264; batch adversarial loss: 0.409841\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050264; batch adversarial loss: 0.467607\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055606; batch adversarial loss: 0.336344\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071349; batch adversarial loss: 0.455372\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044639; batch adversarial loss: 0.424249\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044648; batch adversarial loss: 0.368005\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024065; batch adversarial loss: 0.450147\n",
      "epoch 108; iter: 0; batch classifier loss: 0.017737; batch adversarial loss: 0.426566\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041031; batch adversarial loss: 0.424243\n",
      "epoch 110; iter: 0; batch classifier loss: 0.024888; batch adversarial loss: 0.445525\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043241; batch adversarial loss: 0.527022\n",
      "epoch 112; iter: 0; batch classifier loss: 0.082678; batch adversarial loss: 0.378075\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057359; batch adversarial loss: 0.439049\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054655; batch adversarial loss: 0.491745\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024100; batch adversarial loss: 0.460447\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044808; batch adversarial loss: 0.462251\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040813; batch adversarial loss: 0.382229\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031928; batch adversarial loss: 0.486547\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043426; batch adversarial loss: 0.404589\n",
      "epoch 120; iter: 0; batch classifier loss: 0.015120; batch adversarial loss: 0.426136\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041230; batch adversarial loss: 0.387960\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050159; batch adversarial loss: 0.467497\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025028; batch adversarial loss: 0.478701\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057597; batch adversarial loss: 0.437594\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018056; batch adversarial loss: 0.510209\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025794; batch adversarial loss: 0.447646\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026044; batch adversarial loss: 0.460337\n",
      "epoch 128; iter: 0; batch classifier loss: 0.013313; batch adversarial loss: 0.499867\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039133; batch adversarial loss: 0.561430\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028648; batch adversarial loss: 0.408062\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042975; batch adversarial loss: 0.438187\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028893; batch adversarial loss: 0.413834\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035916; batch adversarial loss: 0.478089\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027551; batch adversarial loss: 0.425389\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047792; batch adversarial loss: 0.499127\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039339; batch adversarial loss: 0.461651\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041755; batch adversarial loss: 0.302508\n",
      "epoch 138; iter: 0; batch classifier loss: 0.085125; batch adversarial loss: 0.443045\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023903; batch adversarial loss: 0.542344\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040549; batch adversarial loss: 0.461363\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027451; batch adversarial loss: 0.502589\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037576; batch adversarial loss: 0.563161\n",
      "epoch 143; iter: 0; batch classifier loss: 0.049493; batch adversarial loss: 0.479359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.030558; batch adversarial loss: 0.470874\n",
      "epoch 145; iter: 0; batch classifier loss: 0.057477; batch adversarial loss: 0.489518\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029853; batch adversarial loss: 0.418669\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040079; batch adversarial loss: 0.434356\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019073; batch adversarial loss: 0.407968\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031500; batch adversarial loss: 0.517910\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015338; batch adversarial loss: 0.450677\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018142; batch adversarial loss: 0.528009\n",
      "epoch 152; iter: 0; batch classifier loss: 0.062681; batch adversarial loss: 0.428401\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015290; batch adversarial loss: 0.597862\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021623; batch adversarial loss: 0.475437\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015890; batch adversarial loss: 0.430666\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042663; batch adversarial loss: 0.415570\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025003; batch adversarial loss: 0.463420\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024798; batch adversarial loss: 0.470152\n",
      "epoch 159; iter: 0; batch classifier loss: 0.008892; batch adversarial loss: 0.446345\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017885; batch adversarial loss: 0.489300\n",
      "epoch 161; iter: 0; batch classifier loss: 0.045559; batch adversarial loss: 0.372106\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022555; batch adversarial loss: 0.400416\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032535; batch adversarial loss: 0.334799\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027652; batch adversarial loss: 0.466198\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023689; batch adversarial loss: 0.455762\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023502; batch adversarial loss: 0.565099\n",
      "epoch 167; iter: 0; batch classifier loss: 0.003611; batch adversarial loss: 0.457977\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019492; batch adversarial loss: 0.538060\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006793; batch adversarial loss: 0.454888\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014544; batch adversarial loss: 0.468843\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028904; batch adversarial loss: 0.363235\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005547; batch adversarial loss: 0.488237\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011339; batch adversarial loss: 0.324255\n",
      "epoch 174; iter: 0; batch classifier loss: 0.004989; batch adversarial loss: 0.386968\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015864; batch adversarial loss: 0.417254\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027048; batch adversarial loss: 0.452726\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020072; batch adversarial loss: 0.414157\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033266; batch adversarial loss: 0.416878\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029233; batch adversarial loss: 0.407014\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023769; batch adversarial loss: 0.380578\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017323; batch adversarial loss: 0.399454\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019787; batch adversarial loss: 0.419757\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018231; batch adversarial loss: 0.439780\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006619; batch adversarial loss: 0.454815\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026444; batch adversarial loss: 0.478700\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024573; batch adversarial loss: 0.446739\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024469; batch adversarial loss: 0.487003\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006843; batch adversarial loss: 0.369034\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028130; batch adversarial loss: 0.345118\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022519; batch adversarial loss: 0.491164\n",
      "epoch 191; iter: 0; batch classifier loss: 0.041852; batch adversarial loss: 0.467409\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036265; batch adversarial loss: 0.430449\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009935; batch adversarial loss: 0.568263\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005710; batch adversarial loss: 0.442127\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023287; batch adversarial loss: 0.475572\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005820; batch adversarial loss: 0.387035\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032101; batch adversarial loss: 0.467345\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032013; batch adversarial loss: 0.330592\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019680; batch adversarial loss: 0.362822\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686165; batch adversarial loss: 0.668079\n",
      "epoch 1; iter: 0; batch classifier loss: 0.463424; batch adversarial loss: 0.676012\n",
      "epoch 2; iter: 0; batch classifier loss: 0.365947; batch adversarial loss: 0.619212\n",
      "epoch 3; iter: 0; batch classifier loss: 0.370915; batch adversarial loss: 0.593672\n",
      "epoch 4; iter: 0; batch classifier loss: 0.374868; batch adversarial loss: 0.568986\n",
      "epoch 5; iter: 0; batch classifier loss: 0.331308; batch adversarial loss: 0.525805\n",
      "epoch 6; iter: 0; batch classifier loss: 0.384306; batch adversarial loss: 0.524710\n",
      "epoch 7; iter: 0; batch classifier loss: 0.252198; batch adversarial loss: 0.497031\n",
      "epoch 8; iter: 0; batch classifier loss: 0.259300; batch adversarial loss: 0.463949\n",
      "epoch 9; iter: 0; batch classifier loss: 0.297108; batch adversarial loss: 0.506942\n",
      "epoch 10; iter: 0; batch classifier loss: 0.250943; batch adversarial loss: 0.525453\n",
      "epoch 11; iter: 0; batch classifier loss: 0.210561; batch adversarial loss: 0.473837\n",
      "epoch 12; iter: 0; batch classifier loss: 0.186048; batch adversarial loss: 0.490077\n",
      "epoch 13; iter: 0; batch classifier loss: 0.165727; batch adversarial loss: 0.486466\n",
      "epoch 14; iter: 0; batch classifier loss: 0.172853; batch adversarial loss: 0.493753\n",
      "epoch 15; iter: 0; batch classifier loss: 0.179344; batch adversarial loss: 0.420781\n",
      "epoch 16; iter: 0; batch classifier loss: 0.128572; batch adversarial loss: 0.423844\n",
      "epoch 17; iter: 0; batch classifier loss: 0.120222; batch adversarial loss: 0.496375\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197454; batch adversarial loss: 0.473377\n",
      "epoch 19; iter: 0; batch classifier loss: 0.096173; batch adversarial loss: 0.495207\n",
      "epoch 20; iter: 0; batch classifier loss: 0.122554; batch adversarial loss: 0.435508\n",
      "epoch 21; iter: 0; batch classifier loss: 0.160329; batch adversarial loss: 0.469175\n",
      "epoch 22; iter: 0; batch classifier loss: 0.179504; batch adversarial loss: 0.475379\n",
      "epoch 23; iter: 0; batch classifier loss: 0.153548; batch adversarial loss: 0.497871\n",
      "epoch 24; iter: 0; batch classifier loss: 0.153363; batch adversarial loss: 0.509281\n",
      "epoch 25; iter: 0; batch classifier loss: 0.166957; batch adversarial loss: 0.424652\n",
      "epoch 26; iter: 0; batch classifier loss: 0.167283; batch adversarial loss: 0.396835\n",
      "epoch 27; iter: 0; batch classifier loss: 0.150642; batch adversarial loss: 0.406302\n",
      "epoch 28; iter: 0; batch classifier loss: 0.275834; batch adversarial loss: 0.497853\n",
      "epoch 29; iter: 0; batch classifier loss: 0.174356; batch adversarial loss: 0.547533\n",
      "epoch 30; iter: 0; batch classifier loss: 0.321428; batch adversarial loss: 0.554193\n",
      "epoch 31; iter: 0; batch classifier loss: 0.233868; batch adversarial loss: 0.488282\n",
      "epoch 32; iter: 0; batch classifier loss: 0.311115; batch adversarial loss: 0.421053\n",
      "epoch 33; iter: 0; batch classifier loss: 0.161178; batch adversarial loss: 0.430019\n",
      "epoch 34; iter: 0; batch classifier loss: 0.361138; batch adversarial loss: 0.488375\n",
      "epoch 35; iter: 0; batch classifier loss: 0.301466; batch adversarial loss: 0.486348\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141154; batch adversarial loss: 0.539420\n",
      "epoch 37; iter: 0; batch classifier loss: 0.114646; batch adversarial loss: 0.487560\n",
      "epoch 38; iter: 0; batch classifier loss: 0.096653; batch adversarial loss: 0.365428\n",
      "epoch 39; iter: 0; batch classifier loss: 0.088653; batch adversarial loss: 0.510606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.076828; batch adversarial loss: 0.503172\n",
      "epoch 41; iter: 0; batch classifier loss: 0.120986; batch adversarial loss: 0.412174\n",
      "epoch 42; iter: 0; batch classifier loss: 0.059142; batch adversarial loss: 0.448029\n",
      "epoch 43; iter: 0; batch classifier loss: 0.088568; batch adversarial loss: 0.391970\n",
      "epoch 44; iter: 0; batch classifier loss: 0.072538; batch adversarial loss: 0.505628\n",
      "epoch 45; iter: 0; batch classifier loss: 0.133077; batch adversarial loss: 0.384486\n",
      "epoch 46; iter: 0; batch classifier loss: 0.103544; batch adversarial loss: 0.458849\n",
      "epoch 47; iter: 0; batch classifier loss: 0.094379; batch adversarial loss: 0.446168\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125453; batch adversarial loss: 0.422385\n",
      "epoch 49; iter: 0; batch classifier loss: 0.081482; batch adversarial loss: 0.499412\n",
      "epoch 50; iter: 0; batch classifier loss: 0.084720; batch adversarial loss: 0.443306\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083684; batch adversarial loss: 0.428621\n",
      "epoch 52; iter: 0; batch classifier loss: 0.069914; batch adversarial loss: 0.413534\n",
      "epoch 53; iter: 0; batch classifier loss: 0.061075; batch adversarial loss: 0.423308\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096437; batch adversarial loss: 0.452296\n",
      "epoch 55; iter: 0; batch classifier loss: 0.067083; batch adversarial loss: 0.491130\n",
      "epoch 56; iter: 0; batch classifier loss: 0.146840; batch adversarial loss: 0.487343\n",
      "epoch 57; iter: 0; batch classifier loss: 0.120744; batch adversarial loss: 0.415611\n",
      "epoch 58; iter: 0; batch classifier loss: 0.047709; batch adversarial loss: 0.605200\n",
      "epoch 59; iter: 0; batch classifier loss: 0.076620; batch adversarial loss: 0.405499\n",
      "epoch 60; iter: 0; batch classifier loss: 0.055853; batch adversarial loss: 0.416628\n",
      "epoch 61; iter: 0; batch classifier loss: 0.109778; batch adversarial loss: 0.431312\n",
      "epoch 62; iter: 0; batch classifier loss: 0.052987; batch adversarial loss: 0.362429\n",
      "epoch 63; iter: 0; batch classifier loss: 0.116658; batch adversarial loss: 0.469094\n",
      "epoch 64; iter: 0; batch classifier loss: 0.068796; batch adversarial loss: 0.346287\n",
      "epoch 65; iter: 0; batch classifier loss: 0.036486; batch adversarial loss: 0.593947\n",
      "epoch 66; iter: 0; batch classifier loss: 0.119861; batch adversarial loss: 0.400976\n",
      "epoch 67; iter: 0; batch classifier loss: 0.067459; batch adversarial loss: 0.468814\n",
      "epoch 68; iter: 0; batch classifier loss: 0.074829; batch adversarial loss: 0.414249\n",
      "epoch 69; iter: 0; batch classifier loss: 0.107141; batch adversarial loss: 0.389081\n",
      "epoch 70; iter: 0; batch classifier loss: 0.070446; batch adversarial loss: 0.491184\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115855; batch adversarial loss: 0.449805\n",
      "epoch 72; iter: 0; batch classifier loss: 0.032767; batch adversarial loss: 0.474476\n",
      "epoch 73; iter: 0; batch classifier loss: 0.090011; batch adversarial loss: 0.423566\n",
      "epoch 74; iter: 0; batch classifier loss: 0.074425; batch adversarial loss: 0.452957\n",
      "epoch 75; iter: 0; batch classifier loss: 0.045420; batch adversarial loss: 0.467746\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075043; batch adversarial loss: 0.419684\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055246; batch adversarial loss: 0.378776\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080082; batch adversarial loss: 0.412972\n",
      "epoch 79; iter: 0; batch classifier loss: 0.069664; batch adversarial loss: 0.469446\n",
      "epoch 80; iter: 0; batch classifier loss: 0.042625; batch adversarial loss: 0.506854\n",
      "epoch 81; iter: 0; batch classifier loss: 0.060862; batch adversarial loss: 0.446453\n",
      "epoch 82; iter: 0; batch classifier loss: 0.040271; batch adversarial loss: 0.415712\n",
      "epoch 83; iter: 0; batch classifier loss: 0.049747; batch adversarial loss: 0.436016\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067015; batch adversarial loss: 0.465421\n",
      "epoch 85; iter: 0; batch classifier loss: 0.079872; batch adversarial loss: 0.469513\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074649; batch adversarial loss: 0.326083\n",
      "epoch 87; iter: 0; batch classifier loss: 0.070337; batch adversarial loss: 0.497509\n",
      "epoch 88; iter: 0; batch classifier loss: 0.060872; batch adversarial loss: 0.430765\n",
      "epoch 89; iter: 0; batch classifier loss: 0.043123; batch adversarial loss: 0.425375\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042412; batch adversarial loss: 0.437637\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057789; batch adversarial loss: 0.436849\n",
      "epoch 92; iter: 0; batch classifier loss: 0.040685; batch adversarial loss: 0.398951\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065433; batch adversarial loss: 0.502716\n",
      "epoch 94; iter: 0; batch classifier loss: 0.069521; batch adversarial loss: 0.443365\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063385; batch adversarial loss: 0.451040\n",
      "epoch 96; iter: 0; batch classifier loss: 0.083970; batch adversarial loss: 0.458656\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039353; batch adversarial loss: 0.461696\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048600; batch adversarial loss: 0.488143\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042472; batch adversarial loss: 0.431799\n",
      "epoch 100; iter: 0; batch classifier loss: 0.072629; batch adversarial loss: 0.420768\n",
      "epoch 101; iter: 0; batch classifier loss: 0.053640; batch adversarial loss: 0.393936\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046810; batch adversarial loss: 0.397630\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032519; batch adversarial loss: 0.398577\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058717; batch adversarial loss: 0.418255\n",
      "epoch 105; iter: 0; batch classifier loss: 0.081078; batch adversarial loss: 0.488568\n",
      "epoch 106; iter: 0; batch classifier loss: 0.061600; batch adversarial loss: 0.466184\n",
      "epoch 107; iter: 0; batch classifier loss: 0.082138; batch adversarial loss: 0.520623\n",
      "epoch 108; iter: 0; batch classifier loss: 0.077771; batch adversarial loss: 0.433556\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043057; batch adversarial loss: 0.411923\n",
      "epoch 110; iter: 0; batch classifier loss: 0.063315; batch adversarial loss: 0.421328\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062588; batch adversarial loss: 0.411616\n",
      "epoch 112; iter: 0; batch classifier loss: 0.062719; batch adversarial loss: 0.452817\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052665; batch adversarial loss: 0.537660\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056724; batch adversarial loss: 0.510811\n",
      "epoch 115; iter: 0; batch classifier loss: 0.091789; batch adversarial loss: 0.399614\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055754; batch adversarial loss: 0.539572\n",
      "epoch 117; iter: 0; batch classifier loss: 0.020020; batch adversarial loss: 0.514666\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052322; batch adversarial loss: 0.464661\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037508; batch adversarial loss: 0.457575\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031557; batch adversarial loss: 0.454573\n",
      "epoch 121; iter: 0; batch classifier loss: 0.022740; batch adversarial loss: 0.504459\n",
      "epoch 122; iter: 0; batch classifier loss: 0.016499; batch adversarial loss: 0.548707\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040655; batch adversarial loss: 0.442578\n",
      "epoch 124; iter: 0; batch classifier loss: 0.047198; batch adversarial loss: 0.489562\n",
      "epoch 125; iter: 0; batch classifier loss: 0.059754; batch adversarial loss: 0.495941\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022429; batch adversarial loss: 0.300229\n",
      "epoch 127; iter: 0; batch classifier loss: 0.059752; batch adversarial loss: 0.417170\n",
      "epoch 128; iter: 0; batch classifier loss: 0.020504; batch adversarial loss: 0.521348\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039458; batch adversarial loss: 0.434891\n",
      "epoch 130; iter: 0; batch classifier loss: 0.064651; batch adversarial loss: 0.357687\n",
      "epoch 131; iter: 0; batch classifier loss: 0.016364; batch adversarial loss: 0.426078\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016194; batch adversarial loss: 0.469162\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014438; batch adversarial loss: 0.450533\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039571; batch adversarial loss: 0.428760\n",
      "epoch 135; iter: 0; batch classifier loss: 0.061167; batch adversarial loss: 0.393652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.027779; batch adversarial loss: 0.481025\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026090; batch adversarial loss: 0.426895\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031516; batch adversarial loss: 0.451324\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021730; batch adversarial loss: 0.418896\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013611; batch adversarial loss: 0.448152\n",
      "epoch 141; iter: 0; batch classifier loss: 0.010474; batch adversarial loss: 0.423824\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037415; batch adversarial loss: 0.423418\n",
      "epoch 143; iter: 0; batch classifier loss: 0.052834; batch adversarial loss: 0.491795\n",
      "epoch 144; iter: 0; batch classifier loss: 0.009220; batch adversarial loss: 0.420156\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017968; batch adversarial loss: 0.403966\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044443; batch adversarial loss: 0.482935\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014601; batch adversarial loss: 0.359583\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033541; batch adversarial loss: 0.458795\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023001; batch adversarial loss: 0.365725\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032860; batch adversarial loss: 0.386258\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023722; batch adversarial loss: 0.451501\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040443; batch adversarial loss: 0.442707\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023781; batch adversarial loss: 0.597800\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028617; batch adversarial loss: 0.412946\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021418; batch adversarial loss: 0.444655\n",
      "epoch 156; iter: 0; batch classifier loss: 0.073003; batch adversarial loss: 0.377858\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023112; batch adversarial loss: 0.439600\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037761; batch adversarial loss: 0.373789\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036251; batch adversarial loss: 0.421334\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017025; batch adversarial loss: 0.404289\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016767; batch adversarial loss: 0.407199\n",
      "epoch 162; iter: 0; batch classifier loss: 0.069515; batch adversarial loss: 0.357743\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023318; batch adversarial loss: 0.445699\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030904; batch adversarial loss: 0.494789\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031779; batch adversarial loss: 0.395531\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028012; batch adversarial loss: 0.547379\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022773; batch adversarial loss: 0.491700\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012484; batch adversarial loss: 0.464015\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017646; batch adversarial loss: 0.480834\n",
      "epoch 170; iter: 0; batch classifier loss: 0.053441; batch adversarial loss: 0.484372\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032873; batch adversarial loss: 0.472742\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010119; batch adversarial loss: 0.515743\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037677; batch adversarial loss: 0.415422\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032786; batch adversarial loss: 0.501888\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036276; batch adversarial loss: 0.444987\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011483; batch adversarial loss: 0.424224\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030783; batch adversarial loss: 0.421343\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019018; batch adversarial loss: 0.481958\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031450; batch adversarial loss: 0.495423\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030909; batch adversarial loss: 0.397827\n",
      "epoch 181; iter: 0; batch classifier loss: 0.046934; batch adversarial loss: 0.406310\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019625; batch adversarial loss: 0.333422\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013244; batch adversarial loss: 0.325382\n",
      "epoch 184; iter: 0; batch classifier loss: 0.049021; batch adversarial loss: 0.432902\n",
      "epoch 185; iter: 0; batch classifier loss: 0.059984; batch adversarial loss: 0.459906\n",
      "epoch 186; iter: 0; batch classifier loss: 0.034848; batch adversarial loss: 0.464696\n",
      "epoch 187; iter: 0; batch classifier loss: 0.047428; batch adversarial loss: 0.525898\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027221; batch adversarial loss: 0.443469\n",
      "epoch 189; iter: 0; batch classifier loss: 0.052508; batch adversarial loss: 0.412547\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028077; batch adversarial loss: 0.426153\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024385; batch adversarial loss: 0.435993\n",
      "epoch 192; iter: 0; batch classifier loss: 0.041733; batch adversarial loss: 0.437516\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015915; batch adversarial loss: 0.472313\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012566; batch adversarial loss: 0.362262\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013575; batch adversarial loss: 0.459113\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012912; batch adversarial loss: 0.506014\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016798; batch adversarial loss: 0.397357\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013557; batch adversarial loss: 0.449629\n",
      "epoch 199; iter: 0; batch classifier loss: 0.044282; batch adversarial loss: 0.409639\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708247; batch adversarial loss: 0.793613\n",
      "epoch 1; iter: 0; batch classifier loss: 0.462978; batch adversarial loss: 0.746863\n",
      "epoch 2; iter: 0; batch classifier loss: 0.424977; batch adversarial loss: 0.692632\n",
      "epoch 3; iter: 0; batch classifier loss: 0.539637; batch adversarial loss: 0.648834\n",
      "epoch 4; iter: 0; batch classifier loss: 0.472219; batch adversarial loss: 0.603531\n",
      "epoch 5; iter: 0; batch classifier loss: 0.344263; batch adversarial loss: 0.601476\n",
      "epoch 6; iter: 0; batch classifier loss: 0.293647; batch adversarial loss: 0.580964\n",
      "epoch 7; iter: 0; batch classifier loss: 0.418590; batch adversarial loss: 0.576531\n",
      "epoch 8; iter: 0; batch classifier loss: 0.330145; batch adversarial loss: 0.530825\n",
      "epoch 9; iter: 0; batch classifier loss: 0.368631; batch adversarial loss: 0.568595\n",
      "epoch 10; iter: 0; batch classifier loss: 0.349614; batch adversarial loss: 0.512014\n",
      "epoch 11; iter: 0; batch classifier loss: 0.416853; batch adversarial loss: 0.546345\n",
      "epoch 12; iter: 0; batch classifier loss: 0.361490; batch adversarial loss: 0.512792\n",
      "epoch 13; iter: 0; batch classifier loss: 0.379223; batch adversarial loss: 0.533426\n",
      "epoch 14; iter: 0; batch classifier loss: 0.441668; batch adversarial loss: 0.566909\n",
      "epoch 15; iter: 0; batch classifier loss: 0.430544; batch adversarial loss: 0.468846\n",
      "epoch 16; iter: 0; batch classifier loss: 0.367617; batch adversarial loss: 0.527996\n",
      "epoch 17; iter: 0; batch classifier loss: 0.323320; batch adversarial loss: 0.499844\n",
      "epoch 18; iter: 0; batch classifier loss: 0.333205; batch adversarial loss: 0.437939\n",
      "epoch 19; iter: 0; batch classifier loss: 0.284036; batch adversarial loss: 0.507788\n",
      "epoch 20; iter: 0; batch classifier loss: 0.229923; batch adversarial loss: 0.527891\n",
      "epoch 21; iter: 0; batch classifier loss: 0.286775; batch adversarial loss: 0.477154\n",
      "epoch 22; iter: 0; batch classifier loss: 0.358885; batch adversarial loss: 0.380133\n",
      "epoch 23; iter: 0; batch classifier loss: 0.298083; batch adversarial loss: 0.440871\n",
      "epoch 24; iter: 0; batch classifier loss: 0.266308; batch adversarial loss: 0.476020\n",
      "epoch 25; iter: 0; batch classifier loss: 0.242255; batch adversarial loss: 0.502087\n",
      "epoch 26; iter: 0; batch classifier loss: 0.197365; batch adversarial loss: 0.457506\n",
      "epoch 27; iter: 0; batch classifier loss: 0.209828; batch adversarial loss: 0.469799\n",
      "epoch 28; iter: 0; batch classifier loss: 0.237562; batch adversarial loss: 0.458478\n",
      "epoch 29; iter: 0; batch classifier loss: 0.209100; batch adversarial loss: 0.480075\n",
      "epoch 30; iter: 0; batch classifier loss: 0.203820; batch adversarial loss: 0.502619\n",
      "epoch 31; iter: 0; batch classifier loss: 0.259773; batch adversarial loss: 0.445740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.192473; batch adversarial loss: 0.425322\n",
      "epoch 33; iter: 0; batch classifier loss: 0.231120; batch adversarial loss: 0.487855\n",
      "epoch 34; iter: 0; batch classifier loss: 0.229890; batch adversarial loss: 0.556966\n",
      "epoch 35; iter: 0; batch classifier loss: 0.236111; batch adversarial loss: 0.457292\n",
      "epoch 36; iter: 0; batch classifier loss: 0.157735; batch adversarial loss: 0.507653\n",
      "epoch 37; iter: 0; batch classifier loss: 0.219541; batch adversarial loss: 0.447012\n",
      "epoch 38; iter: 0; batch classifier loss: 0.230034; batch adversarial loss: 0.476914\n",
      "epoch 39; iter: 0; batch classifier loss: 0.213883; batch adversarial loss: 0.486164\n",
      "epoch 40; iter: 0; batch classifier loss: 0.180062; batch adversarial loss: 0.415615\n",
      "epoch 41; iter: 0; batch classifier loss: 0.230872; batch adversarial loss: 0.449940\n",
      "epoch 42; iter: 0; batch classifier loss: 0.176889; batch adversarial loss: 0.532473\n",
      "epoch 43; iter: 0; batch classifier loss: 0.143979; batch adversarial loss: 0.513237\n",
      "epoch 44; iter: 0; batch classifier loss: 0.187787; batch adversarial loss: 0.407614\n",
      "epoch 45; iter: 0; batch classifier loss: 0.174147; batch adversarial loss: 0.476034\n",
      "epoch 46; iter: 0; batch classifier loss: 0.153089; batch adversarial loss: 0.485769\n",
      "epoch 47; iter: 0; batch classifier loss: 0.192419; batch adversarial loss: 0.432318\n",
      "epoch 48; iter: 0; batch classifier loss: 0.121723; batch adversarial loss: 0.486552\n",
      "epoch 49; iter: 0; batch classifier loss: 0.130532; batch adversarial loss: 0.435153\n",
      "epoch 50; iter: 0; batch classifier loss: 0.167852; batch adversarial loss: 0.439703\n",
      "epoch 51; iter: 0; batch classifier loss: 0.163093; batch adversarial loss: 0.378218\n",
      "epoch 52; iter: 0; batch classifier loss: 0.162638; batch adversarial loss: 0.417200\n",
      "epoch 53; iter: 0; batch classifier loss: 0.143630; batch adversarial loss: 0.470485\n",
      "epoch 54; iter: 0; batch classifier loss: 0.083113; batch adversarial loss: 0.501897\n",
      "epoch 55; iter: 0; batch classifier loss: 0.135015; batch adversarial loss: 0.386755\n",
      "epoch 56; iter: 0; batch classifier loss: 0.089985; batch adversarial loss: 0.531847\n",
      "epoch 57; iter: 0; batch classifier loss: 0.142829; batch adversarial loss: 0.401102\n",
      "epoch 58; iter: 0; batch classifier loss: 0.104727; batch adversarial loss: 0.402026\n",
      "epoch 59; iter: 0; batch classifier loss: 0.145705; batch adversarial loss: 0.428683\n",
      "epoch 60; iter: 0; batch classifier loss: 0.078887; batch adversarial loss: 0.420990\n",
      "epoch 61; iter: 0; batch classifier loss: 0.099724; batch adversarial loss: 0.454820\n",
      "epoch 62; iter: 0; batch classifier loss: 0.067856; batch adversarial loss: 0.453205\n",
      "epoch 63; iter: 0; batch classifier loss: 0.170725; batch adversarial loss: 0.426870\n",
      "epoch 64; iter: 0; batch classifier loss: 0.097812; batch adversarial loss: 0.464000\n",
      "epoch 65; iter: 0; batch classifier loss: 0.067696; batch adversarial loss: 0.418805\n",
      "epoch 66; iter: 0; batch classifier loss: 0.098813; batch adversarial loss: 0.420612\n",
      "epoch 67; iter: 0; batch classifier loss: 0.057690; batch adversarial loss: 0.537707\n",
      "epoch 68; iter: 0; batch classifier loss: 0.077700; batch adversarial loss: 0.470701\n",
      "epoch 69; iter: 0; batch classifier loss: 0.066029; batch adversarial loss: 0.481766\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079045; batch adversarial loss: 0.414561\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115425; batch adversarial loss: 0.482870\n",
      "epoch 72; iter: 0; batch classifier loss: 0.063590; batch adversarial loss: 0.491908\n",
      "epoch 73; iter: 0; batch classifier loss: 0.100645; batch adversarial loss: 0.392485\n",
      "epoch 74; iter: 0; batch classifier loss: 0.086492; batch adversarial loss: 0.455637\n",
      "epoch 75; iter: 0; batch classifier loss: 0.066627; batch adversarial loss: 0.492193\n",
      "epoch 76; iter: 0; batch classifier loss: 0.044453; batch adversarial loss: 0.391254\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076928; batch adversarial loss: 0.386591\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079657; batch adversarial loss: 0.389498\n",
      "epoch 79; iter: 0; batch classifier loss: 0.045190; batch adversarial loss: 0.512915\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088837; batch adversarial loss: 0.460237\n",
      "epoch 81; iter: 0; batch classifier loss: 0.080105; batch adversarial loss: 0.463035\n",
      "epoch 82; iter: 0; batch classifier loss: 0.047874; batch adversarial loss: 0.459162\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068605; batch adversarial loss: 0.405721\n",
      "epoch 84; iter: 0; batch classifier loss: 0.025699; batch adversarial loss: 0.472210\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077672; batch adversarial loss: 0.446662\n",
      "epoch 86; iter: 0; batch classifier loss: 0.044832; batch adversarial loss: 0.484154\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066636; batch adversarial loss: 0.422894\n",
      "epoch 88; iter: 0; batch classifier loss: 0.048850; batch adversarial loss: 0.487409\n",
      "epoch 89; iter: 0; batch classifier loss: 0.055277; batch adversarial loss: 0.480256\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051952; batch adversarial loss: 0.418539\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048396; batch adversarial loss: 0.441110\n",
      "epoch 92; iter: 0; batch classifier loss: 0.054212; batch adversarial loss: 0.488605\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036399; batch adversarial loss: 0.351652\n",
      "epoch 94; iter: 0; batch classifier loss: 0.037827; batch adversarial loss: 0.522766\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038992; batch adversarial loss: 0.495131\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047192; batch adversarial loss: 0.505887\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047010; batch adversarial loss: 0.452155\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052371; batch adversarial loss: 0.431769\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037593; batch adversarial loss: 0.479773\n",
      "epoch 100; iter: 0; batch classifier loss: 0.042257; batch adversarial loss: 0.367424\n",
      "epoch 101; iter: 0; batch classifier loss: 0.026404; batch adversarial loss: 0.411840\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042400; batch adversarial loss: 0.388145\n",
      "epoch 103; iter: 0; batch classifier loss: 0.022947; batch adversarial loss: 0.477654\n",
      "epoch 104; iter: 0; batch classifier loss: 0.051138; batch adversarial loss: 0.453755\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043309; batch adversarial loss: 0.380156\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044302; batch adversarial loss: 0.478691\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053442; batch adversarial loss: 0.436912\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046295; batch adversarial loss: 0.506158\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039927; batch adversarial loss: 0.427182\n",
      "epoch 110; iter: 0; batch classifier loss: 0.021373; batch adversarial loss: 0.546627\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030211; batch adversarial loss: 0.424273\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025683; batch adversarial loss: 0.553754\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027375; batch adversarial loss: 0.410680\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030430; batch adversarial loss: 0.438920\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039967; batch adversarial loss: 0.581090\n",
      "epoch 116; iter: 0; batch classifier loss: 0.017188; batch adversarial loss: 0.494993\n",
      "epoch 117; iter: 0; batch classifier loss: 0.021952; batch adversarial loss: 0.499117\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059534; batch adversarial loss: 0.460475\n",
      "epoch 119; iter: 0; batch classifier loss: 0.019725; batch adversarial loss: 0.461111\n",
      "epoch 120; iter: 0; batch classifier loss: 0.014186; batch adversarial loss: 0.493543\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028749; batch adversarial loss: 0.398416\n",
      "epoch 122; iter: 0; batch classifier loss: 0.056888; batch adversarial loss: 0.459996\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049714; batch adversarial loss: 0.376593\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027825; batch adversarial loss: 0.420361\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041987; batch adversarial loss: 0.474291\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024644; batch adversarial loss: 0.444145\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035791; batch adversarial loss: 0.494672\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022205; batch adversarial loss: 0.484194\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024753; batch adversarial loss: 0.472309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.014621; batch adversarial loss: 0.515524\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017459; batch adversarial loss: 0.469549\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029463; batch adversarial loss: 0.494541\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036669; batch adversarial loss: 0.514707\n",
      "epoch 134; iter: 0; batch classifier loss: 0.022417; batch adversarial loss: 0.528173\n",
      "epoch 135; iter: 0; batch classifier loss: 0.072267; batch adversarial loss: 0.486197\n",
      "epoch 136; iter: 0; batch classifier loss: 0.052476; batch adversarial loss: 0.472253\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042197; batch adversarial loss: 0.385827\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019673; batch adversarial loss: 0.454426\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018470; batch adversarial loss: 0.497125\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013195; batch adversarial loss: 0.474748\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028549; batch adversarial loss: 0.544292\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018334; batch adversarial loss: 0.446543\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031658; batch adversarial loss: 0.331025\n",
      "epoch 144; iter: 0; batch classifier loss: 0.007515; batch adversarial loss: 0.428239\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033389; batch adversarial loss: 0.429057\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045206; batch adversarial loss: 0.457087\n",
      "epoch 147; iter: 0; batch classifier loss: 0.008803; batch adversarial loss: 0.387413\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017049; batch adversarial loss: 0.490546\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036222; batch adversarial loss: 0.426069\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031097; batch adversarial loss: 0.474379\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022112; batch adversarial loss: 0.480419\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022572; batch adversarial loss: 0.464428\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020625; batch adversarial loss: 0.456675\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028715; batch adversarial loss: 0.511170\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049164; batch adversarial loss: 0.458109\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027362; batch adversarial loss: 0.326135\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018282; batch adversarial loss: 0.385967\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009204; batch adversarial loss: 0.484492\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040180; batch adversarial loss: 0.469825\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022863; batch adversarial loss: 0.432739\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021440; batch adversarial loss: 0.429571\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011910; batch adversarial loss: 0.408567\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015752; batch adversarial loss: 0.475799\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016922; batch adversarial loss: 0.489346\n",
      "epoch 165; iter: 0; batch classifier loss: 0.045404; batch adversarial loss: 0.424297\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012968; batch adversarial loss: 0.478482\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022529; batch adversarial loss: 0.435795\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035934; batch adversarial loss: 0.468308\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020352; batch adversarial loss: 0.436449\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034291; batch adversarial loss: 0.407684\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018625; batch adversarial loss: 0.511568\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018914; batch adversarial loss: 0.446639\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030148; batch adversarial loss: 0.346897\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007143; batch adversarial loss: 0.457911\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010979; batch adversarial loss: 0.447349\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028346; batch adversarial loss: 0.445895\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010240; batch adversarial loss: 0.456358\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034080; batch adversarial loss: 0.480044\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030601; batch adversarial loss: 0.423686\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009166; batch adversarial loss: 0.437695\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011129; batch adversarial loss: 0.327952\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022766; batch adversarial loss: 0.439664\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031576; batch adversarial loss: 0.461684\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038841; batch adversarial loss: 0.538549\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024445; batch adversarial loss: 0.387394\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028675; batch adversarial loss: 0.447589\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027670; batch adversarial loss: 0.401356\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011810; batch adversarial loss: 0.399596\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029617; batch adversarial loss: 0.508315\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026062; batch adversarial loss: 0.466935\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027760; batch adversarial loss: 0.457052\n",
      "epoch 192; iter: 0; batch classifier loss: 0.003791; batch adversarial loss: 0.438473\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005707; batch adversarial loss: 0.492210\n",
      "epoch 194; iter: 0; batch classifier loss: 0.082335; batch adversarial loss: 0.491828\n",
      "epoch 195; iter: 0; batch classifier loss: 0.052428; batch adversarial loss: 0.398183\n",
      "epoch 196; iter: 0; batch classifier loss: 0.043187; batch adversarial loss: 0.492804\n",
      "epoch 197; iter: 0; batch classifier loss: 0.046095; batch adversarial loss: 0.405949\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028514; batch adversarial loss: 0.486416\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020225; batch adversarial loss: 0.421091\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694657; batch adversarial loss: 0.664593\n",
      "epoch 1; iter: 0; batch classifier loss: 0.557502; batch adversarial loss: 0.633088\n",
      "epoch 2; iter: 0; batch classifier loss: 0.393477; batch adversarial loss: 0.613909\n",
      "epoch 3; iter: 0; batch classifier loss: 0.406447; batch adversarial loss: 0.607109\n",
      "epoch 4; iter: 0; batch classifier loss: 0.394422; batch adversarial loss: 0.600855\n",
      "epoch 5; iter: 0; batch classifier loss: 0.388146; batch adversarial loss: 0.561489\n",
      "epoch 6; iter: 0; batch classifier loss: 0.386631; batch adversarial loss: 0.519910\n",
      "epoch 7; iter: 0; batch classifier loss: 0.352872; batch adversarial loss: 0.532017\n",
      "epoch 8; iter: 0; batch classifier loss: 0.431507; batch adversarial loss: 0.546324\n",
      "epoch 9; iter: 0; batch classifier loss: 0.335178; batch adversarial loss: 0.528345\n",
      "epoch 10; iter: 0; batch classifier loss: 0.299230; batch adversarial loss: 0.469637\n",
      "epoch 11; iter: 0; batch classifier loss: 0.235188; batch adversarial loss: 0.533921\n",
      "epoch 12; iter: 0; batch classifier loss: 0.353802; batch adversarial loss: 0.521200\n",
      "epoch 13; iter: 0; batch classifier loss: 0.323173; batch adversarial loss: 0.467890\n",
      "epoch 14; iter: 0; batch classifier loss: 0.280383; batch adversarial loss: 0.663409\n",
      "epoch 15; iter: 0; batch classifier loss: 0.273101; batch adversarial loss: 0.480461\n",
      "epoch 16; iter: 0; batch classifier loss: 0.251754; batch adversarial loss: 0.452997\n",
      "epoch 17; iter: 0; batch classifier loss: 0.272991; batch adversarial loss: 0.541604\n",
      "epoch 18; iter: 0; batch classifier loss: 0.222087; batch adversarial loss: 0.474021\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237602; batch adversarial loss: 0.476803\n",
      "epoch 20; iter: 0; batch classifier loss: 0.271367; batch adversarial loss: 0.423860\n",
      "epoch 21; iter: 0; batch classifier loss: 0.305371; batch adversarial loss: 0.497944\n",
      "epoch 22; iter: 0; batch classifier loss: 0.238078; batch adversarial loss: 0.482928\n",
      "epoch 23; iter: 0; batch classifier loss: 0.222398; batch adversarial loss: 0.483007\n",
      "epoch 24; iter: 0; batch classifier loss: 0.274889; batch adversarial loss: 0.394224\n",
      "epoch 25; iter: 0; batch classifier loss: 0.246000; batch adversarial loss: 0.452694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.235692; batch adversarial loss: 0.464276\n",
      "epoch 27; iter: 0; batch classifier loss: 0.319172; batch adversarial loss: 0.401508\n",
      "epoch 28; iter: 0; batch classifier loss: 0.218091; batch adversarial loss: 0.504148\n",
      "epoch 29; iter: 0; batch classifier loss: 0.250135; batch adversarial loss: 0.449211\n",
      "epoch 30; iter: 0; batch classifier loss: 0.280137; batch adversarial loss: 0.479226\n",
      "epoch 31; iter: 0; batch classifier loss: 0.246522; batch adversarial loss: 0.405372\n",
      "epoch 32; iter: 0; batch classifier loss: 0.210712; batch adversarial loss: 0.438059\n",
      "epoch 33; iter: 0; batch classifier loss: 0.307911; batch adversarial loss: 0.405119\n",
      "epoch 34; iter: 0; batch classifier loss: 0.252068; batch adversarial loss: 0.490186\n",
      "epoch 35; iter: 0; batch classifier loss: 0.261301; batch adversarial loss: 0.478690\n",
      "epoch 36; iter: 0; batch classifier loss: 0.271903; batch adversarial loss: 0.407132\n",
      "epoch 37; iter: 0; batch classifier loss: 0.205247; batch adversarial loss: 0.412332\n",
      "epoch 38; iter: 0; batch classifier loss: 0.235290; batch adversarial loss: 0.535089\n",
      "epoch 39; iter: 0; batch classifier loss: 0.220278; batch adversarial loss: 0.532975\n",
      "epoch 40; iter: 0; batch classifier loss: 0.216891; batch adversarial loss: 0.394589\n",
      "epoch 41; iter: 0; batch classifier loss: 0.260872; batch adversarial loss: 0.389225\n",
      "epoch 42; iter: 0; batch classifier loss: 0.225204; batch adversarial loss: 0.406196\n",
      "epoch 43; iter: 0; batch classifier loss: 0.247732; batch adversarial loss: 0.495817\n",
      "epoch 44; iter: 0; batch classifier loss: 0.278685; batch adversarial loss: 0.460549\n",
      "epoch 45; iter: 0; batch classifier loss: 0.201706; batch adversarial loss: 0.485428\n",
      "epoch 46; iter: 0; batch classifier loss: 0.275138; batch adversarial loss: 0.377439\n",
      "epoch 47; iter: 0; batch classifier loss: 0.202169; batch adversarial loss: 0.365063\n",
      "epoch 48; iter: 0; batch classifier loss: 0.179342; batch adversarial loss: 0.458980\n",
      "epoch 49; iter: 0; batch classifier loss: 0.191206; batch adversarial loss: 0.412361\n",
      "epoch 50; iter: 0; batch classifier loss: 0.129982; batch adversarial loss: 0.458525\n",
      "epoch 51; iter: 0; batch classifier loss: 0.138277; batch adversarial loss: 0.496509\n",
      "epoch 52; iter: 0; batch classifier loss: 0.200815; batch adversarial loss: 0.435487\n",
      "epoch 53; iter: 0; batch classifier loss: 0.186635; batch adversarial loss: 0.312594\n",
      "epoch 54; iter: 0; batch classifier loss: 0.157327; batch adversarial loss: 0.410672\n",
      "epoch 55; iter: 0; batch classifier loss: 0.221435; batch adversarial loss: 0.446385\n",
      "epoch 56; iter: 0; batch classifier loss: 0.263073; batch adversarial loss: 0.372972\n",
      "epoch 57; iter: 0; batch classifier loss: 0.135000; batch adversarial loss: 0.421249\n",
      "epoch 58; iter: 0; batch classifier loss: 0.156052; batch adversarial loss: 0.520958\n",
      "epoch 59; iter: 0; batch classifier loss: 0.332757; batch adversarial loss: 0.397913\n",
      "epoch 60; iter: 0; batch classifier loss: 0.183297; batch adversarial loss: 0.531693\n",
      "epoch 61; iter: 0; batch classifier loss: 0.154017; batch adversarial loss: 0.495737\n",
      "epoch 62; iter: 0; batch classifier loss: 0.102888; batch adversarial loss: 0.483381\n",
      "epoch 63; iter: 0; batch classifier loss: 0.155372; batch adversarial loss: 0.432118\n",
      "epoch 64; iter: 0; batch classifier loss: 0.197164; batch adversarial loss: 0.409360\n",
      "epoch 65; iter: 0; batch classifier loss: 0.125953; batch adversarial loss: 0.396549\n",
      "epoch 66; iter: 0; batch classifier loss: 0.079275; batch adversarial loss: 0.568490\n",
      "epoch 67; iter: 0; batch classifier loss: 0.135354; batch adversarial loss: 0.507789\n",
      "epoch 68; iter: 0; batch classifier loss: 0.177784; batch adversarial loss: 0.471374\n",
      "epoch 69; iter: 0; batch classifier loss: 0.137675; batch adversarial loss: 0.372063\n",
      "epoch 70; iter: 0; batch classifier loss: 0.141120; batch adversarial loss: 0.492947\n",
      "epoch 71; iter: 0; batch classifier loss: 0.232819; batch adversarial loss: 0.468814\n",
      "epoch 72; iter: 0; batch classifier loss: 0.223945; batch adversarial loss: 0.519870\n",
      "epoch 73; iter: 0; batch classifier loss: 0.215872; batch adversarial loss: 0.398215\n",
      "epoch 74; iter: 0; batch classifier loss: 0.154255; batch adversarial loss: 0.458842\n",
      "epoch 75; iter: 0; batch classifier loss: 0.152884; batch adversarial loss: 0.321778\n",
      "epoch 76; iter: 0; batch classifier loss: 0.140378; batch adversarial loss: 0.349065\n",
      "epoch 77; iter: 0; batch classifier loss: 0.143426; batch adversarial loss: 0.557653\n",
      "epoch 78; iter: 0; batch classifier loss: 0.113878; batch adversarial loss: 0.433770\n",
      "epoch 79; iter: 0; batch classifier loss: 0.125756; batch adversarial loss: 0.383106\n",
      "epoch 80; iter: 0; batch classifier loss: 0.163704; batch adversarial loss: 0.482451\n",
      "epoch 81; iter: 0; batch classifier loss: 0.220683; batch adversarial loss: 0.497123\n",
      "epoch 82; iter: 0; batch classifier loss: 0.199639; batch adversarial loss: 0.520578\n",
      "epoch 83; iter: 0; batch classifier loss: 0.183601; batch adversarial loss: 0.459060\n",
      "epoch 84; iter: 0; batch classifier loss: 0.148431; batch adversarial loss: 0.408921\n",
      "epoch 85; iter: 0; batch classifier loss: 0.229894; batch adversarial loss: 0.397012\n",
      "epoch 86; iter: 0; batch classifier loss: 0.218329; batch adversarial loss: 0.484316\n",
      "epoch 87; iter: 0; batch classifier loss: 0.222982; batch adversarial loss: 0.397195\n",
      "epoch 88; iter: 0; batch classifier loss: 0.092402; batch adversarial loss: 0.458356\n",
      "epoch 89; iter: 0; batch classifier loss: 0.089985; batch adversarial loss: 0.406767\n",
      "epoch 90; iter: 0; batch classifier loss: 0.126578; batch adversarial loss: 0.457430\n",
      "epoch 91; iter: 0; batch classifier loss: 0.161647; batch adversarial loss: 0.482966\n",
      "epoch 92; iter: 0; batch classifier loss: 0.111028; batch adversarial loss: 0.531864\n",
      "epoch 93; iter: 0; batch classifier loss: 0.116369; batch adversarial loss: 0.451643\n",
      "epoch 94; iter: 0; batch classifier loss: 0.082813; batch adversarial loss: 0.446239\n",
      "epoch 95; iter: 0; batch classifier loss: 0.083620; batch adversarial loss: 0.493716\n",
      "epoch 96; iter: 0; batch classifier loss: 0.071904; batch adversarial loss: 0.516784\n",
      "epoch 97; iter: 0; batch classifier loss: 0.100655; batch adversarial loss: 0.451496\n",
      "epoch 98; iter: 0; batch classifier loss: 0.128364; batch adversarial loss: 0.427060\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067150; batch adversarial loss: 0.446556\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054714; batch adversarial loss: 0.447186\n",
      "epoch 101; iter: 0; batch classifier loss: 0.127935; batch adversarial loss: 0.453928\n",
      "epoch 102; iter: 0; batch classifier loss: 0.086420; batch adversarial loss: 0.512829\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066387; batch adversarial loss: 0.481870\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041811; batch adversarial loss: 0.427451\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052808; batch adversarial loss: 0.414557\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050281; batch adversarial loss: 0.541487\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069892; batch adversarial loss: 0.426446\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056237; batch adversarial loss: 0.493466\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041505; batch adversarial loss: 0.477860\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053709; batch adversarial loss: 0.439080\n",
      "epoch 111; iter: 0; batch classifier loss: 0.109358; batch adversarial loss: 0.502882\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039665; batch adversarial loss: 0.456423\n",
      "epoch 113; iter: 0; batch classifier loss: 0.071617; batch adversarial loss: 0.356927\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060112; batch adversarial loss: 0.545066\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036060; batch adversarial loss: 0.450423\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062297; batch adversarial loss: 0.400075\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052348; batch adversarial loss: 0.433715\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031595; batch adversarial loss: 0.504259\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032642; batch adversarial loss: 0.504784\n",
      "epoch 120; iter: 0; batch classifier loss: 0.058672; batch adversarial loss: 0.399253\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049278; batch adversarial loss: 0.500982\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045999; batch adversarial loss: 0.400539\n",
      "epoch 123; iter: 0; batch classifier loss: 0.061942; batch adversarial loss: 0.367522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.025042; batch adversarial loss: 0.532088\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027413; batch adversarial loss: 0.418827\n",
      "epoch 126; iter: 0; batch classifier loss: 0.056700; batch adversarial loss: 0.421955\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025267; batch adversarial loss: 0.432143\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027555; batch adversarial loss: 0.472373\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020805; batch adversarial loss: 0.563685\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022425; batch adversarial loss: 0.467193\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035549; batch adversarial loss: 0.381790\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024848; batch adversarial loss: 0.423237\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038933; batch adversarial loss: 0.414205\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040178; batch adversarial loss: 0.491105\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025076; batch adversarial loss: 0.433337\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030897; batch adversarial loss: 0.355226\n",
      "epoch 137; iter: 0; batch classifier loss: 0.050039; batch adversarial loss: 0.476729\n",
      "epoch 138; iter: 0; batch classifier loss: 0.012675; batch adversarial loss: 0.446825\n",
      "epoch 139; iter: 0; batch classifier loss: 0.006695; batch adversarial loss: 0.491507\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019105; batch adversarial loss: 0.470595\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030277; batch adversarial loss: 0.375744\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029828; batch adversarial loss: 0.417596\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041840; batch adversarial loss: 0.516018\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012670; batch adversarial loss: 0.470941\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027901; batch adversarial loss: 0.414198\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013533; batch adversarial loss: 0.504610\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018163; batch adversarial loss: 0.444695\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033847; batch adversarial loss: 0.436661\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024856; batch adversarial loss: 0.459672\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012326; batch adversarial loss: 0.491776\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040160; batch adversarial loss: 0.433561\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017296; batch adversarial loss: 0.506885\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027233; batch adversarial loss: 0.572872\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018059; batch adversarial loss: 0.494860\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040620; batch adversarial loss: 0.410613\n",
      "epoch 156; iter: 0; batch classifier loss: 0.053380; batch adversarial loss: 0.544325\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014993; batch adversarial loss: 0.514614\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017048; batch adversarial loss: 0.444100\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024618; batch adversarial loss: 0.495043\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035582; batch adversarial loss: 0.398005\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012826; batch adversarial loss: 0.504587\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012486; batch adversarial loss: 0.478272\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021234; batch adversarial loss: 0.454869\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038347; batch adversarial loss: 0.417188\n",
      "epoch 165; iter: 0; batch classifier loss: 0.045442; batch adversarial loss: 0.464279\n",
      "epoch 166; iter: 0; batch classifier loss: 0.055221; batch adversarial loss: 0.465353\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012058; batch adversarial loss: 0.489094\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009246; batch adversarial loss: 0.344069\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019982; batch adversarial loss: 0.387641\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008953; batch adversarial loss: 0.386636\n",
      "epoch 171; iter: 0; batch classifier loss: 0.058803; batch adversarial loss: 0.364361\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017098; batch adversarial loss: 0.390737\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025836; batch adversarial loss: 0.532562\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008747; batch adversarial loss: 0.384903\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020427; batch adversarial loss: 0.401794\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014914; batch adversarial loss: 0.387424\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030116; batch adversarial loss: 0.401047\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021438; batch adversarial loss: 0.413409\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028342; batch adversarial loss: 0.443566\n",
      "epoch 180; iter: 0; batch classifier loss: 0.005199; batch adversarial loss: 0.406995\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023273; batch adversarial loss: 0.381932\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012712; batch adversarial loss: 0.389488\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031328; batch adversarial loss: 0.478626\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009434; batch adversarial loss: 0.401440\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018151; batch adversarial loss: 0.399657\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010822; batch adversarial loss: 0.389664\n",
      "epoch 187; iter: 0; batch classifier loss: 0.044374; batch adversarial loss: 0.436749\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006374; batch adversarial loss: 0.467977\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018231; batch adversarial loss: 0.443289\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024212; batch adversarial loss: 0.476509\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019807; batch adversarial loss: 0.493433\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016933; batch adversarial loss: 0.472495\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016045; batch adversarial loss: 0.490124\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012373; batch adversarial loss: 0.455503\n",
      "epoch 195; iter: 0; batch classifier loss: 0.059905; batch adversarial loss: 0.380921\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025214; batch adversarial loss: 0.398795\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004474; batch adversarial loss: 0.429649\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007670; batch adversarial loss: 0.500316\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035434; batch adversarial loss: 0.479415\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693876; batch adversarial loss: 0.758236\n",
      "epoch 1; iter: 0; batch classifier loss: 0.535333; batch adversarial loss: 0.712199\n",
      "epoch 2; iter: 0; batch classifier loss: 0.590039; batch adversarial loss: 0.686146\n",
      "epoch 3; iter: 0; batch classifier loss: 0.504465; batch adversarial loss: 0.620201\n",
      "epoch 4; iter: 0; batch classifier loss: 0.444560; batch adversarial loss: 0.581485\n",
      "epoch 5; iter: 0; batch classifier loss: 0.296489; batch adversarial loss: 0.557271\n",
      "epoch 6; iter: 0; batch classifier loss: 0.310259; batch adversarial loss: 0.560180\n",
      "epoch 7; iter: 0; batch classifier loss: 0.349387; batch adversarial loss: 0.557820\n",
      "epoch 8; iter: 0; batch classifier loss: 0.342582; batch adversarial loss: 0.513280\n",
      "epoch 9; iter: 0; batch classifier loss: 0.304035; batch adversarial loss: 0.535221\n",
      "epoch 10; iter: 0; batch classifier loss: 0.252641; batch adversarial loss: 0.513390\n",
      "epoch 11; iter: 0; batch classifier loss: 0.253246; batch adversarial loss: 0.510900\n",
      "epoch 12; iter: 0; batch classifier loss: 0.263289; batch adversarial loss: 0.539536\n",
      "epoch 13; iter: 0; batch classifier loss: 0.208752; batch adversarial loss: 0.461174\n",
      "epoch 14; iter: 0; batch classifier loss: 0.239751; batch adversarial loss: 0.436743\n",
      "epoch 15; iter: 0; batch classifier loss: 0.229084; batch adversarial loss: 0.530622\n",
      "epoch 16; iter: 0; batch classifier loss: 0.200385; batch adversarial loss: 0.541827\n",
      "epoch 17; iter: 0; batch classifier loss: 0.248323; batch adversarial loss: 0.533868\n",
      "epoch 18; iter: 0; batch classifier loss: 0.234063; batch adversarial loss: 0.553974\n",
      "epoch 19; iter: 0; batch classifier loss: 0.250729; batch adversarial loss: 0.443384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.242725; batch adversarial loss: 0.508183\n",
      "epoch 21; iter: 0; batch classifier loss: 0.222833; batch adversarial loss: 0.480309\n",
      "epoch 22; iter: 0; batch classifier loss: 0.191770; batch adversarial loss: 0.472650\n",
      "epoch 23; iter: 0; batch classifier loss: 0.224297; batch adversarial loss: 0.496447\n",
      "epoch 24; iter: 0; batch classifier loss: 0.133132; batch adversarial loss: 0.557450\n",
      "epoch 25; iter: 0; batch classifier loss: 0.160846; batch adversarial loss: 0.489780\n",
      "epoch 26; iter: 0; batch classifier loss: 0.185806; batch adversarial loss: 0.461901\n",
      "epoch 27; iter: 0; batch classifier loss: 0.183829; batch adversarial loss: 0.416409\n",
      "epoch 28; iter: 0; batch classifier loss: 0.177794; batch adversarial loss: 0.366898\n",
      "epoch 29; iter: 0; batch classifier loss: 0.126114; batch adversarial loss: 0.445897\n",
      "epoch 30; iter: 0; batch classifier loss: 0.160152; batch adversarial loss: 0.468438\n",
      "epoch 31; iter: 0; batch classifier loss: 0.179588; batch adversarial loss: 0.424492\n",
      "epoch 32; iter: 0; batch classifier loss: 0.134663; batch adversarial loss: 0.459622\n",
      "epoch 33; iter: 0; batch classifier loss: 0.150477; batch adversarial loss: 0.518969\n",
      "epoch 34; iter: 0; batch classifier loss: 0.143137; batch adversarial loss: 0.449101\n",
      "epoch 35; iter: 0; batch classifier loss: 0.186225; batch adversarial loss: 0.440934\n",
      "epoch 36; iter: 0; batch classifier loss: 0.113001; batch adversarial loss: 0.552400\n",
      "epoch 37; iter: 0; batch classifier loss: 0.108023; batch adversarial loss: 0.515131\n",
      "epoch 38; iter: 0; batch classifier loss: 0.144882; batch adversarial loss: 0.508230\n",
      "epoch 39; iter: 0; batch classifier loss: 0.143278; batch adversarial loss: 0.511696\n",
      "epoch 40; iter: 0; batch classifier loss: 0.115808; batch adversarial loss: 0.437642\n",
      "epoch 41; iter: 0; batch classifier loss: 0.116343; batch adversarial loss: 0.392308\n",
      "epoch 42; iter: 0; batch classifier loss: 0.094501; batch adversarial loss: 0.586230\n",
      "epoch 43; iter: 0; batch classifier loss: 0.091519; batch adversarial loss: 0.471123\n",
      "epoch 44; iter: 0; batch classifier loss: 0.115039; batch adversarial loss: 0.446755\n",
      "epoch 45; iter: 0; batch classifier loss: 0.115599; batch adversarial loss: 0.420912\n",
      "epoch 46; iter: 0; batch classifier loss: 0.134710; batch adversarial loss: 0.343439\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106605; batch adversarial loss: 0.409626\n",
      "epoch 48; iter: 0; batch classifier loss: 0.123262; batch adversarial loss: 0.428850\n",
      "epoch 49; iter: 0; batch classifier loss: 0.076897; batch adversarial loss: 0.520692\n",
      "epoch 50; iter: 0; batch classifier loss: 0.152853; batch adversarial loss: 0.384414\n",
      "epoch 51; iter: 0; batch classifier loss: 0.110868; batch adversarial loss: 0.416027\n",
      "epoch 52; iter: 0; batch classifier loss: 0.070094; batch adversarial loss: 0.451019\n",
      "epoch 53; iter: 0; batch classifier loss: 0.125598; batch adversarial loss: 0.450186\n",
      "epoch 54; iter: 0; batch classifier loss: 0.136715; batch adversarial loss: 0.471976\n",
      "epoch 55; iter: 0; batch classifier loss: 0.075760; batch adversarial loss: 0.516466\n",
      "epoch 56; iter: 0; batch classifier loss: 0.093862; batch adversarial loss: 0.468938\n",
      "epoch 57; iter: 0; batch classifier loss: 0.094473; batch adversarial loss: 0.374017\n",
      "epoch 58; iter: 0; batch classifier loss: 0.084283; batch adversarial loss: 0.456257\n",
      "epoch 59; iter: 0; batch classifier loss: 0.057505; batch adversarial loss: 0.482296\n",
      "epoch 60; iter: 0; batch classifier loss: 0.090598; batch adversarial loss: 0.455137\n",
      "epoch 61; iter: 0; batch classifier loss: 0.076232; batch adversarial loss: 0.433316\n",
      "epoch 62; iter: 0; batch classifier loss: 0.098469; batch adversarial loss: 0.509516\n",
      "epoch 63; iter: 0; batch classifier loss: 0.096326; batch adversarial loss: 0.396834\n",
      "epoch 64; iter: 0; batch classifier loss: 0.092665; batch adversarial loss: 0.480052\n",
      "epoch 65; iter: 0; batch classifier loss: 0.106204; batch adversarial loss: 0.393162\n",
      "epoch 66; iter: 0; batch classifier loss: 0.067475; batch adversarial loss: 0.457135\n",
      "epoch 67; iter: 0; batch classifier loss: 0.130251; batch adversarial loss: 0.434864\n",
      "epoch 68; iter: 0; batch classifier loss: 0.105218; batch adversarial loss: 0.407333\n",
      "epoch 69; iter: 0; batch classifier loss: 0.097012; batch adversarial loss: 0.487312\n",
      "epoch 70; iter: 0; batch classifier loss: 0.106446; batch adversarial loss: 0.515970\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078238; batch adversarial loss: 0.477871\n",
      "epoch 72; iter: 0; batch classifier loss: 0.049799; batch adversarial loss: 0.417839\n",
      "epoch 73; iter: 0; batch classifier loss: 0.055968; batch adversarial loss: 0.509149\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069628; batch adversarial loss: 0.442233\n",
      "epoch 75; iter: 0; batch classifier loss: 0.098237; batch adversarial loss: 0.506407\n",
      "epoch 76; iter: 0; batch classifier loss: 0.113283; batch adversarial loss: 0.431733\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084553; batch adversarial loss: 0.402056\n",
      "epoch 78; iter: 0; batch classifier loss: 0.065829; batch adversarial loss: 0.523688\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044019; batch adversarial loss: 0.498276\n",
      "epoch 80; iter: 0; batch classifier loss: 0.043796; batch adversarial loss: 0.509107\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057745; batch adversarial loss: 0.396366\n",
      "epoch 82; iter: 0; batch classifier loss: 0.044087; batch adversarial loss: 0.442358\n",
      "epoch 83; iter: 0; batch classifier loss: 0.089221; batch adversarial loss: 0.481217\n",
      "epoch 84; iter: 0; batch classifier loss: 0.042727; batch adversarial loss: 0.407762\n",
      "epoch 85; iter: 0; batch classifier loss: 0.036907; batch adversarial loss: 0.515497\n",
      "epoch 86; iter: 0; batch classifier loss: 0.033814; batch adversarial loss: 0.439928\n",
      "epoch 87; iter: 0; batch classifier loss: 0.044895; batch adversarial loss: 0.376250\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058200; batch adversarial loss: 0.511738\n",
      "epoch 89; iter: 0; batch classifier loss: 0.062886; batch adversarial loss: 0.506195\n",
      "epoch 90; iter: 0; batch classifier loss: 0.070242; batch adversarial loss: 0.387228\n",
      "epoch 91; iter: 0; batch classifier loss: 0.054404; batch adversarial loss: 0.441243\n",
      "epoch 92; iter: 0; batch classifier loss: 0.056721; batch adversarial loss: 0.473817\n",
      "epoch 93; iter: 0; batch classifier loss: 0.021192; batch adversarial loss: 0.385215\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042253; batch adversarial loss: 0.443132\n",
      "epoch 95; iter: 0; batch classifier loss: 0.028142; batch adversarial loss: 0.392120\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057309; batch adversarial loss: 0.524469\n",
      "epoch 97; iter: 0; batch classifier loss: 0.045736; batch adversarial loss: 0.544827\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050153; batch adversarial loss: 0.410327\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039104; batch adversarial loss: 0.433552\n",
      "epoch 100; iter: 0; batch classifier loss: 0.085936; batch adversarial loss: 0.425565\n",
      "epoch 101; iter: 0; batch classifier loss: 0.091534; batch adversarial loss: 0.439805\n",
      "epoch 102; iter: 0; batch classifier loss: 0.034818; batch adversarial loss: 0.456706\n",
      "epoch 103; iter: 0; batch classifier loss: 0.100591; batch adversarial loss: 0.477420\n",
      "epoch 104; iter: 0; batch classifier loss: 0.029084; batch adversarial loss: 0.579403\n",
      "epoch 105; iter: 0; batch classifier loss: 0.023108; batch adversarial loss: 0.424052\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046331; batch adversarial loss: 0.418049\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046327; batch adversarial loss: 0.400560\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055738; batch adversarial loss: 0.480898\n",
      "epoch 109; iter: 0; batch classifier loss: 0.020768; batch adversarial loss: 0.494607\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028540; batch adversarial loss: 0.502531\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057844; batch adversarial loss: 0.495340\n",
      "epoch 112; iter: 0; batch classifier loss: 0.032984; batch adversarial loss: 0.459605\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042254; batch adversarial loss: 0.473201\n",
      "epoch 114; iter: 0; batch classifier loss: 0.031493; batch adversarial loss: 0.475001\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035365; batch adversarial loss: 0.500398\n",
      "epoch 116; iter: 0; batch classifier loss: 0.018143; batch adversarial loss: 0.446765\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032504; batch adversarial loss: 0.477439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.059679; batch adversarial loss: 0.455825\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030358; batch adversarial loss: 0.552946\n",
      "epoch 120; iter: 0; batch classifier loss: 0.081031; batch adversarial loss: 0.423560\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028637; batch adversarial loss: 0.488202\n",
      "epoch 122; iter: 0; batch classifier loss: 0.014800; batch adversarial loss: 0.503867\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028019; batch adversarial loss: 0.514571\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021167; batch adversarial loss: 0.348684\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043270; batch adversarial loss: 0.410971\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021304; batch adversarial loss: 0.478082\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033791; batch adversarial loss: 0.472742\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019418; batch adversarial loss: 0.523900\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038163; batch adversarial loss: 0.372448\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036490; batch adversarial loss: 0.473318\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019557; batch adversarial loss: 0.463660\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041408; batch adversarial loss: 0.479259\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021814; batch adversarial loss: 0.442185\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021213; batch adversarial loss: 0.567008\n",
      "epoch 135; iter: 0; batch classifier loss: 0.017049; batch adversarial loss: 0.501958\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036639; batch adversarial loss: 0.403573\n",
      "epoch 137; iter: 0; batch classifier loss: 0.061874; batch adversarial loss: 0.416554\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027267; batch adversarial loss: 0.434759\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014051; batch adversarial loss: 0.490582\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030949; batch adversarial loss: 0.474428\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035824; batch adversarial loss: 0.471360\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030136; batch adversarial loss: 0.479446\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030625; batch adversarial loss: 0.549321\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036793; batch adversarial loss: 0.399888\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040151; batch adversarial loss: 0.429188\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039080; batch adversarial loss: 0.464250\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030386; batch adversarial loss: 0.415425\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014620; batch adversarial loss: 0.433199\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024773; batch adversarial loss: 0.594428\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012706; batch adversarial loss: 0.494107\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032863; batch adversarial loss: 0.398612\n",
      "epoch 152; iter: 0; batch classifier loss: 0.046873; batch adversarial loss: 0.452899\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029414; batch adversarial loss: 0.570776\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030486; batch adversarial loss: 0.539463\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027962; batch adversarial loss: 0.480609\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026180; batch adversarial loss: 0.508546\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022601; batch adversarial loss: 0.463714\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038991; batch adversarial loss: 0.403726\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026236; batch adversarial loss: 0.485475\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032783; batch adversarial loss: 0.494324\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008812; batch adversarial loss: 0.498900\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010704; batch adversarial loss: 0.339369\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035917; batch adversarial loss: 0.521802\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017872; batch adversarial loss: 0.468932\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035591; batch adversarial loss: 0.498708\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021914; batch adversarial loss: 0.426747\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024268; batch adversarial loss: 0.537996\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025588; batch adversarial loss: 0.442316\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019250; batch adversarial loss: 0.523051\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020079; batch adversarial loss: 0.532263\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027436; batch adversarial loss: 0.463677\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018685; batch adversarial loss: 0.427505\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018569; batch adversarial loss: 0.445188\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014416; batch adversarial loss: 0.410045\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017024; batch adversarial loss: 0.437167\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012734; batch adversarial loss: 0.467633\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015699; batch adversarial loss: 0.426575\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008568; batch adversarial loss: 0.479565\n",
      "epoch 179; iter: 0; batch classifier loss: 0.047328; batch adversarial loss: 0.523475\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012107; batch adversarial loss: 0.418029\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030599; batch adversarial loss: 0.494505\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020088; batch adversarial loss: 0.371152\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030795; batch adversarial loss: 0.460783\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038233; batch adversarial loss: 0.442050\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011207; batch adversarial loss: 0.450250\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026398; batch adversarial loss: 0.587517\n",
      "epoch 187; iter: 0; batch classifier loss: 0.063073; batch adversarial loss: 0.433550\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006708; batch adversarial loss: 0.434410\n",
      "epoch 189; iter: 0; batch classifier loss: 0.044973; batch adversarial loss: 0.408805\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017889; batch adversarial loss: 0.519265\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005037; batch adversarial loss: 0.495767\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022688; batch adversarial loss: 0.500946\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021321; batch adversarial loss: 0.487890\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013779; batch adversarial loss: 0.434667\n",
      "epoch 195; iter: 0; batch classifier loss: 0.039790; batch adversarial loss: 0.457537\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015573; batch adversarial loss: 0.484111\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024584; batch adversarial loss: 0.433936\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008523; batch adversarial loss: 0.492161\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033994; batch adversarial loss: 0.414191\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668678; batch adversarial loss: 0.703190\n",
      "epoch 1; iter: 0; batch classifier loss: 0.494968; batch adversarial loss: 0.658351\n",
      "epoch 2; iter: 0; batch classifier loss: 0.459752; batch adversarial loss: 0.632655\n",
      "epoch 3; iter: 0; batch classifier loss: 0.427569; batch adversarial loss: 0.592357\n",
      "epoch 4; iter: 0; batch classifier loss: 0.381854; batch adversarial loss: 0.609494\n",
      "epoch 5; iter: 0; batch classifier loss: 0.349502; batch adversarial loss: 0.541274\n",
      "epoch 6; iter: 0; batch classifier loss: 0.387215; batch adversarial loss: 0.581087\n",
      "epoch 7; iter: 0; batch classifier loss: 0.388681; batch adversarial loss: 0.568022\n",
      "epoch 8; iter: 0; batch classifier loss: 0.338885; batch adversarial loss: 0.536899\n",
      "epoch 9; iter: 0; batch classifier loss: 0.347443; batch adversarial loss: 0.533086\n",
      "epoch 10; iter: 0; batch classifier loss: 0.311526; batch adversarial loss: 0.549525\n",
      "epoch 11; iter: 0; batch classifier loss: 0.438815; batch adversarial loss: 0.506772\n",
      "epoch 12; iter: 0; batch classifier loss: 0.291342; batch adversarial loss: 0.533919\n",
      "epoch 13; iter: 0; batch classifier loss: 0.325618; batch adversarial loss: 0.485379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.334948; batch adversarial loss: 0.561048\n",
      "epoch 15; iter: 0; batch classifier loss: 0.422984; batch adversarial loss: 0.470026\n",
      "epoch 16; iter: 0; batch classifier loss: 0.425145; batch adversarial loss: 0.466657\n",
      "epoch 17; iter: 0; batch classifier loss: 0.345320; batch adversarial loss: 0.477077\n",
      "epoch 18; iter: 0; batch classifier loss: 0.333533; batch adversarial loss: 0.485262\n",
      "epoch 19; iter: 0; batch classifier loss: 0.362597; batch adversarial loss: 0.507674\n",
      "epoch 20; iter: 0; batch classifier loss: 0.319214; batch adversarial loss: 0.406455\n",
      "epoch 21; iter: 0; batch classifier loss: 0.351655; batch adversarial loss: 0.457316\n",
      "epoch 22; iter: 0; batch classifier loss: 0.404045; batch adversarial loss: 0.490911\n",
      "epoch 23; iter: 0; batch classifier loss: 0.257168; batch adversarial loss: 0.524439\n",
      "epoch 24; iter: 0; batch classifier loss: 0.320835; batch adversarial loss: 0.489567\n",
      "epoch 25; iter: 0; batch classifier loss: 0.274942; batch adversarial loss: 0.555739\n",
      "epoch 26; iter: 0; batch classifier loss: 0.238592; batch adversarial loss: 0.426577\n",
      "epoch 27; iter: 0; batch classifier loss: 0.303365; batch adversarial loss: 0.439779\n",
      "epoch 28; iter: 0; batch classifier loss: 0.257060; batch adversarial loss: 0.438218\n",
      "epoch 29; iter: 0; batch classifier loss: 0.272108; batch adversarial loss: 0.420727\n",
      "epoch 30; iter: 0; batch classifier loss: 0.195980; batch adversarial loss: 0.518727\n",
      "epoch 31; iter: 0; batch classifier loss: 0.242246; batch adversarial loss: 0.494779\n",
      "epoch 32; iter: 0; batch classifier loss: 0.259008; batch adversarial loss: 0.483488\n",
      "epoch 33; iter: 0; batch classifier loss: 0.225139; batch adversarial loss: 0.442827\n",
      "epoch 34; iter: 0; batch classifier loss: 0.247686; batch adversarial loss: 0.415180\n",
      "epoch 35; iter: 0; batch classifier loss: 0.282901; batch adversarial loss: 0.493666\n",
      "epoch 36; iter: 0; batch classifier loss: 0.214164; batch adversarial loss: 0.508341\n",
      "epoch 37; iter: 0; batch classifier loss: 0.264095; batch adversarial loss: 0.372479\n",
      "epoch 38; iter: 0; batch classifier loss: 0.224769; batch adversarial loss: 0.419770\n",
      "epoch 39; iter: 0; batch classifier loss: 0.248485; batch adversarial loss: 0.499591\n",
      "epoch 40; iter: 0; batch classifier loss: 0.252266; batch adversarial loss: 0.464035\n",
      "epoch 41; iter: 0; batch classifier loss: 0.213824; batch adversarial loss: 0.463420\n",
      "epoch 42; iter: 0; batch classifier loss: 0.306396; batch adversarial loss: 0.494660\n",
      "epoch 43; iter: 0; batch classifier loss: 0.310487; batch adversarial loss: 0.365693\n",
      "epoch 44; iter: 0; batch classifier loss: 0.290354; batch adversarial loss: 0.457724\n",
      "epoch 45; iter: 0; batch classifier loss: 0.236242; batch adversarial loss: 0.614888\n",
      "epoch 46; iter: 0; batch classifier loss: 0.300016; batch adversarial loss: 0.447289\n",
      "epoch 47; iter: 0; batch classifier loss: 0.248195; batch adversarial loss: 0.519435\n",
      "epoch 48; iter: 0; batch classifier loss: 0.244315; batch adversarial loss: 0.411092\n",
      "epoch 49; iter: 0; batch classifier loss: 0.142510; batch adversarial loss: 0.422859\n",
      "epoch 50; iter: 0; batch classifier loss: 0.193549; batch adversarial loss: 0.410200\n",
      "epoch 51; iter: 0; batch classifier loss: 0.288165; batch adversarial loss: 0.458303\n",
      "epoch 52; iter: 0; batch classifier loss: 0.217961; batch adversarial loss: 0.397438\n",
      "epoch 53; iter: 0; batch classifier loss: 0.249289; batch adversarial loss: 0.557253\n",
      "epoch 54; iter: 0; batch classifier loss: 0.127274; batch adversarial loss: 0.446212\n",
      "epoch 55; iter: 0; batch classifier loss: 0.158574; batch adversarial loss: 0.445330\n",
      "epoch 56; iter: 0; batch classifier loss: 0.240057; batch adversarial loss: 0.571369\n",
      "epoch 57; iter: 0; batch classifier loss: 0.219027; batch adversarial loss: 0.521533\n",
      "epoch 58; iter: 0; batch classifier loss: 0.167944; batch adversarial loss: 0.434655\n",
      "epoch 59; iter: 0; batch classifier loss: 0.145983; batch adversarial loss: 0.447608\n",
      "epoch 60; iter: 0; batch classifier loss: 0.189469; batch adversarial loss: 0.434601\n",
      "epoch 61; iter: 0; batch classifier loss: 0.139718; batch adversarial loss: 0.459304\n",
      "epoch 62; iter: 0; batch classifier loss: 0.126237; batch adversarial loss: 0.409028\n",
      "epoch 63; iter: 0; batch classifier loss: 0.116028; batch adversarial loss: 0.409388\n",
      "epoch 64; iter: 0; batch classifier loss: 0.212976; batch adversarial loss: 0.508754\n",
      "epoch 65; iter: 0; batch classifier loss: 0.168094; batch adversarial loss: 0.458687\n",
      "epoch 66; iter: 0; batch classifier loss: 0.230999; batch adversarial loss: 0.446546\n",
      "epoch 67; iter: 0; batch classifier loss: 0.262079; batch adversarial loss: 0.446455\n",
      "epoch 68; iter: 0; batch classifier loss: 0.165980; batch adversarial loss: 0.346711\n",
      "epoch 69; iter: 0; batch classifier loss: 0.163004; batch adversarial loss: 0.471380\n",
      "epoch 70; iter: 0; batch classifier loss: 0.175376; batch adversarial loss: 0.535025\n",
      "epoch 71; iter: 0; batch classifier loss: 0.181319; batch adversarial loss: 0.471704\n",
      "epoch 72; iter: 0; batch classifier loss: 0.200393; batch adversarial loss: 0.470874\n",
      "epoch 73; iter: 0; batch classifier loss: 0.355373; batch adversarial loss: 0.396373\n",
      "epoch 74; iter: 0; batch classifier loss: 0.162809; batch adversarial loss: 0.432553\n",
      "epoch 75; iter: 0; batch classifier loss: 0.127068; batch adversarial loss: 0.432083\n",
      "epoch 76; iter: 0; batch classifier loss: 0.097102; batch adversarial loss: 0.428671\n",
      "epoch 77; iter: 0; batch classifier loss: 0.268531; batch adversarial loss: 0.522478\n",
      "epoch 78; iter: 0; batch classifier loss: 0.247677; batch adversarial loss: 0.383368\n",
      "epoch 79; iter: 0; batch classifier loss: 0.208382; batch adversarial loss: 0.497858\n",
      "epoch 80; iter: 0; batch classifier loss: 0.137075; batch adversarial loss: 0.421323\n",
      "epoch 81; iter: 0; batch classifier loss: 0.235635; batch adversarial loss: 0.471425\n",
      "epoch 82; iter: 0; batch classifier loss: 0.276679; batch adversarial loss: 0.485182\n",
      "epoch 83; iter: 0; batch classifier loss: 0.175528; batch adversarial loss: 0.346779\n",
      "epoch 84; iter: 0; batch classifier loss: 0.200094; batch adversarial loss: 0.532362\n",
      "epoch 85; iter: 0; batch classifier loss: 0.229504; batch adversarial loss: 0.358535\n",
      "epoch 86; iter: 0; batch classifier loss: 0.193887; batch adversarial loss: 0.346339\n",
      "epoch 87; iter: 0; batch classifier loss: 0.231888; batch adversarial loss: 0.510317\n",
      "epoch 88; iter: 0; batch classifier loss: 0.193158; batch adversarial loss: 0.458827\n",
      "epoch 89; iter: 0; batch classifier loss: 0.230538; batch adversarial loss: 0.421355\n",
      "epoch 90; iter: 0; batch classifier loss: 0.127492; batch adversarial loss: 0.433924\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082109; batch adversarial loss: 0.448111\n",
      "epoch 92; iter: 0; batch classifier loss: 0.129943; batch adversarial loss: 0.420775\n",
      "epoch 93; iter: 0; batch classifier loss: 0.208121; batch adversarial loss: 0.394559\n",
      "epoch 94; iter: 0; batch classifier loss: 0.210278; batch adversarial loss: 0.433554\n",
      "epoch 95; iter: 0; batch classifier loss: 0.194606; batch adversarial loss: 0.383038\n",
      "epoch 96; iter: 0; batch classifier loss: 0.177633; batch adversarial loss: 0.446069\n",
      "epoch 97; iter: 0; batch classifier loss: 0.157500; batch adversarial loss: 0.458763\n",
      "epoch 98; iter: 0; batch classifier loss: 0.141712; batch adversarial loss: 0.343903\n",
      "epoch 99; iter: 0; batch classifier loss: 0.207441; batch adversarial loss: 0.459182\n",
      "epoch 100; iter: 0; batch classifier loss: 0.236119; batch adversarial loss: 0.420455\n",
      "epoch 101; iter: 0; batch classifier loss: 0.221578; batch adversarial loss: 0.434887\n",
      "epoch 102; iter: 0; batch classifier loss: 0.219531; batch adversarial loss: 0.471863\n",
      "epoch 103; iter: 0; batch classifier loss: 0.226614; batch adversarial loss: 0.422554\n",
      "epoch 104; iter: 0; batch classifier loss: 0.209629; batch adversarial loss: 0.385440\n",
      "epoch 105; iter: 0; batch classifier loss: 0.169282; batch adversarial loss: 0.371438\n",
      "epoch 106; iter: 0; batch classifier loss: 0.160599; batch adversarial loss: 0.509559\n",
      "epoch 107; iter: 0; batch classifier loss: 0.128326; batch adversarial loss: 0.446383\n",
      "epoch 108; iter: 0; batch classifier loss: 0.149747; batch adversarial loss: 0.409745\n",
      "epoch 109; iter: 0; batch classifier loss: 0.158271; batch adversarial loss: 0.371609\n",
      "epoch 110; iter: 0; batch classifier loss: 0.182487; batch adversarial loss: 0.508377\n",
      "epoch 111; iter: 0; batch classifier loss: 0.188757; batch adversarial loss: 0.433594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.168694; batch adversarial loss: 0.421457\n",
      "epoch 113; iter: 0; batch classifier loss: 0.121310; batch adversarial loss: 0.432981\n",
      "epoch 114; iter: 0; batch classifier loss: 0.107263; batch adversarial loss: 0.469365\n",
      "epoch 115; iter: 0; batch classifier loss: 0.089745; batch adversarial loss: 0.478958\n",
      "epoch 116; iter: 0; batch classifier loss: 0.087341; batch adversarial loss: 0.430615\n",
      "epoch 117; iter: 0; batch classifier loss: 0.069119; batch adversarial loss: 0.466991\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059999; batch adversarial loss: 0.458393\n",
      "epoch 119; iter: 0; batch classifier loss: 0.080161; batch adversarial loss: 0.359373\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038603; batch adversarial loss: 0.440170\n",
      "epoch 121; iter: 0; batch classifier loss: 0.055848; batch adversarial loss: 0.448659\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062163; batch adversarial loss: 0.290110\n",
      "epoch 123; iter: 0; batch classifier loss: 0.065789; batch adversarial loss: 0.513453\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051337; batch adversarial loss: 0.366311\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047369; batch adversarial loss: 0.485387\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031833; batch adversarial loss: 0.513947\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036796; batch adversarial loss: 0.410522\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027015; batch adversarial loss: 0.461953\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020868; batch adversarial loss: 0.395938\n",
      "epoch 130; iter: 0; batch classifier loss: 0.063620; batch adversarial loss: 0.361880\n",
      "epoch 131; iter: 0; batch classifier loss: 0.079733; batch adversarial loss: 0.333711\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023077; batch adversarial loss: 0.513674\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030847; batch adversarial loss: 0.516218\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031079; batch adversarial loss: 0.419678\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037451; batch adversarial loss: 0.471970\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032513; batch adversarial loss: 0.477693\n",
      "epoch 137; iter: 0; batch classifier loss: 0.053697; batch adversarial loss: 0.506427\n",
      "epoch 138; iter: 0; batch classifier loss: 0.063511; batch adversarial loss: 0.472800\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023410; batch adversarial loss: 0.539939\n",
      "epoch 140; iter: 0; batch classifier loss: 0.016196; batch adversarial loss: 0.482176\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025835; batch adversarial loss: 0.391992\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026588; batch adversarial loss: 0.397323\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020448; batch adversarial loss: 0.482478\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013665; batch adversarial loss: 0.494602\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015255; batch adversarial loss: 0.439495\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023724; batch adversarial loss: 0.426398\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021998; batch adversarial loss: 0.509750\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015298; batch adversarial loss: 0.498385\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033959; batch adversarial loss: 0.434364\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013093; batch adversarial loss: 0.518277\n",
      "epoch 151; iter: 0; batch classifier loss: 0.009315; batch adversarial loss: 0.653421\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024181; batch adversarial loss: 0.437074\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024049; batch adversarial loss: 0.494647\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041197; batch adversarial loss: 0.506724\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032368; batch adversarial loss: 0.422810\n",
      "epoch 156; iter: 0; batch classifier loss: 0.008934; batch adversarial loss: 0.421214\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012060; batch adversarial loss: 0.460851\n",
      "epoch 158; iter: 0; batch classifier loss: 0.053540; batch adversarial loss: 0.449898\n",
      "epoch 159; iter: 0; batch classifier loss: 0.006980; batch adversarial loss: 0.453158\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015794; batch adversarial loss: 0.374497\n",
      "epoch 161; iter: 0; batch classifier loss: 0.053071; batch adversarial loss: 0.383211\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019615; batch adversarial loss: 0.375997\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016693; batch adversarial loss: 0.425640\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009353; batch adversarial loss: 0.342352\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016496; batch adversarial loss: 0.429459\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019133; batch adversarial loss: 0.518640\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024104; batch adversarial loss: 0.487412\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013606; batch adversarial loss: 0.428010\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025682; batch adversarial loss: 0.390609\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014640; batch adversarial loss: 0.514688\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014502; batch adversarial loss: 0.496430\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009867; batch adversarial loss: 0.513576\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023552; batch adversarial loss: 0.431154\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009599; batch adversarial loss: 0.493163\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009384; batch adversarial loss: 0.462620\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029040; batch adversarial loss: 0.515206\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028342; batch adversarial loss: 0.366121\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015398; batch adversarial loss: 0.419841\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031751; batch adversarial loss: 0.559757\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024922; batch adversarial loss: 0.464429\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019943; batch adversarial loss: 0.483695\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023472; batch adversarial loss: 0.433600\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016795; batch adversarial loss: 0.491403\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027433; batch adversarial loss: 0.412940\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006057; batch adversarial loss: 0.431387\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006572; batch adversarial loss: 0.416402\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013355; batch adversarial loss: 0.419986\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015806; batch adversarial loss: 0.423718\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019593; batch adversarial loss: 0.360581\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007702; batch adversarial loss: 0.522146\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014797; batch adversarial loss: 0.457765\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025281; batch adversarial loss: 0.422739\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014048; batch adversarial loss: 0.417163\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005297; batch adversarial loss: 0.443759\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028596; batch adversarial loss: 0.436211\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008775; batch adversarial loss: 0.424887\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024772; batch adversarial loss: 0.456447\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008019; batch adversarial loss: 0.495391\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010318; batch adversarial loss: 0.442917\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696166; batch adversarial loss: 0.791228\n",
      "epoch 1; iter: 0; batch classifier loss: 0.480472; batch adversarial loss: 0.740154\n",
      "epoch 2; iter: 0; batch classifier loss: 0.577585; batch adversarial loss: 0.701443\n",
      "epoch 3; iter: 0; batch classifier loss: 0.629882; batch adversarial loss: 0.659003\n",
      "epoch 4; iter: 0; batch classifier loss: 0.445831; batch adversarial loss: 0.598441\n",
      "epoch 5; iter: 0; batch classifier loss: 0.399926; batch adversarial loss: 0.581305\n",
      "epoch 6; iter: 0; batch classifier loss: 0.443460; batch adversarial loss: 0.566193\n",
      "epoch 7; iter: 0; batch classifier loss: 0.380373; batch adversarial loss: 0.541047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.380930; batch adversarial loss: 0.573503\n",
      "epoch 9; iter: 0; batch classifier loss: 0.362218; batch adversarial loss: 0.532982\n",
      "epoch 10; iter: 0; batch classifier loss: 0.338543; batch adversarial loss: 0.556759\n",
      "epoch 11; iter: 0; batch classifier loss: 0.311984; batch adversarial loss: 0.537674\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251935; batch adversarial loss: 0.549838\n",
      "epoch 13; iter: 0; batch classifier loss: 0.360565; batch adversarial loss: 0.509099\n",
      "epoch 14; iter: 0; batch classifier loss: 0.311244; batch adversarial loss: 0.460939\n",
      "epoch 15; iter: 0; batch classifier loss: 0.375257; batch adversarial loss: 0.472408\n",
      "epoch 16; iter: 0; batch classifier loss: 0.283332; batch adversarial loss: 0.489746\n",
      "epoch 17; iter: 0; batch classifier loss: 0.382566; batch adversarial loss: 0.498435\n",
      "epoch 18; iter: 0; batch classifier loss: 0.329106; batch adversarial loss: 0.496083\n",
      "epoch 19; iter: 0; batch classifier loss: 0.302756; batch adversarial loss: 0.504070\n",
      "epoch 20; iter: 0; batch classifier loss: 0.291603; batch adversarial loss: 0.486383\n",
      "epoch 21; iter: 0; batch classifier loss: 0.252593; batch adversarial loss: 0.389397\n",
      "epoch 22; iter: 0; batch classifier loss: 0.331459; batch adversarial loss: 0.417868\n",
      "epoch 23; iter: 0; batch classifier loss: 0.325538; batch adversarial loss: 0.444303\n",
      "epoch 24; iter: 0; batch classifier loss: 0.286682; batch adversarial loss: 0.436617\n",
      "epoch 25; iter: 0; batch classifier loss: 0.203654; batch adversarial loss: 0.476807\n",
      "epoch 26; iter: 0; batch classifier loss: 0.279358; batch adversarial loss: 0.513136\n",
      "epoch 27; iter: 0; batch classifier loss: 0.265942; batch adversarial loss: 0.469074\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184922; batch adversarial loss: 0.477566\n",
      "epoch 29; iter: 0; batch classifier loss: 0.266769; batch adversarial loss: 0.493102\n",
      "epoch 30; iter: 0; batch classifier loss: 0.297040; batch adversarial loss: 0.422300\n",
      "epoch 31; iter: 0; batch classifier loss: 0.215742; batch adversarial loss: 0.454341\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238857; batch adversarial loss: 0.442726\n",
      "epoch 33; iter: 0; batch classifier loss: 0.166857; batch adversarial loss: 0.428364\n",
      "epoch 34; iter: 0; batch classifier loss: 0.191657; batch adversarial loss: 0.452687\n",
      "epoch 35; iter: 0; batch classifier loss: 0.241378; batch adversarial loss: 0.492436\n",
      "epoch 36; iter: 0; batch classifier loss: 0.216734; batch adversarial loss: 0.423734\n",
      "epoch 37; iter: 0; batch classifier loss: 0.221061; batch adversarial loss: 0.429834\n",
      "epoch 38; iter: 0; batch classifier loss: 0.150061; batch adversarial loss: 0.451514\n",
      "epoch 39; iter: 0; batch classifier loss: 0.174280; batch adversarial loss: 0.439857\n",
      "epoch 40; iter: 0; batch classifier loss: 0.200881; batch adversarial loss: 0.422940\n",
      "epoch 41; iter: 0; batch classifier loss: 0.187694; batch adversarial loss: 0.475542\n",
      "epoch 42; iter: 0; batch classifier loss: 0.190445; batch adversarial loss: 0.345034\n",
      "epoch 43; iter: 0; batch classifier loss: 0.212928; batch adversarial loss: 0.425266\n",
      "epoch 44; iter: 0; batch classifier loss: 0.226257; batch adversarial loss: 0.486930\n",
      "epoch 45; iter: 0; batch classifier loss: 0.223410; batch adversarial loss: 0.471862\n",
      "epoch 46; iter: 0; batch classifier loss: 0.190203; batch adversarial loss: 0.527792\n",
      "epoch 47; iter: 0; batch classifier loss: 0.168862; batch adversarial loss: 0.411919\n",
      "epoch 48; iter: 0; batch classifier loss: 0.162915; batch adversarial loss: 0.473284\n",
      "epoch 49; iter: 0; batch classifier loss: 0.168301; batch adversarial loss: 0.469247\n",
      "epoch 50; iter: 0; batch classifier loss: 0.252771; batch adversarial loss: 0.360907\n",
      "epoch 51; iter: 0; batch classifier loss: 0.170978; batch adversarial loss: 0.421976\n",
      "epoch 52; iter: 0; batch classifier loss: 0.182942; batch adversarial loss: 0.545165\n",
      "epoch 53; iter: 0; batch classifier loss: 0.141559; batch adversarial loss: 0.527415\n",
      "epoch 54; iter: 0; batch classifier loss: 0.150294; batch adversarial loss: 0.442116\n",
      "epoch 55; iter: 0; batch classifier loss: 0.198965; batch adversarial loss: 0.469960\n",
      "epoch 56; iter: 0; batch classifier loss: 0.122217; batch adversarial loss: 0.464309\n",
      "epoch 57; iter: 0; batch classifier loss: 0.143651; batch adversarial loss: 0.420946\n",
      "epoch 58; iter: 0; batch classifier loss: 0.162598; batch adversarial loss: 0.421577\n",
      "epoch 59; iter: 0; batch classifier loss: 0.181805; batch adversarial loss: 0.397478\n",
      "epoch 60; iter: 0; batch classifier loss: 0.142251; batch adversarial loss: 0.507167\n",
      "epoch 61; iter: 0; batch classifier loss: 0.125666; batch adversarial loss: 0.428291\n",
      "epoch 62; iter: 0; batch classifier loss: 0.075789; batch adversarial loss: 0.489126\n",
      "epoch 63; iter: 0; batch classifier loss: 0.124142; batch adversarial loss: 0.417133\n",
      "epoch 64; iter: 0; batch classifier loss: 0.141758; batch adversarial loss: 0.424651\n",
      "epoch 65; iter: 0; batch classifier loss: 0.102705; batch adversarial loss: 0.484268\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075532; batch adversarial loss: 0.486764\n",
      "epoch 67; iter: 0; batch classifier loss: 0.109871; batch adversarial loss: 0.504530\n",
      "epoch 68; iter: 0; batch classifier loss: 0.125024; batch adversarial loss: 0.436355\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065164; batch adversarial loss: 0.468452\n",
      "epoch 70; iter: 0; batch classifier loss: 0.177256; batch adversarial loss: 0.433136\n",
      "epoch 71; iter: 0; batch classifier loss: 0.118909; batch adversarial loss: 0.467179\n",
      "epoch 72; iter: 0; batch classifier loss: 0.136144; batch adversarial loss: 0.468350\n",
      "epoch 73; iter: 0; batch classifier loss: 0.059124; batch adversarial loss: 0.408491\n",
      "epoch 74; iter: 0; batch classifier loss: 0.103597; batch adversarial loss: 0.391624\n",
      "epoch 75; iter: 0; batch classifier loss: 0.094919; batch adversarial loss: 0.592858\n",
      "epoch 76; iter: 0; batch classifier loss: 0.110138; batch adversarial loss: 0.469929\n",
      "epoch 77; iter: 0; batch classifier loss: 0.104963; batch adversarial loss: 0.458897\n",
      "epoch 78; iter: 0; batch classifier loss: 0.096408; batch adversarial loss: 0.469320\n",
      "epoch 79; iter: 0; batch classifier loss: 0.096792; batch adversarial loss: 0.486011\n",
      "epoch 80; iter: 0; batch classifier loss: 0.121483; batch adversarial loss: 0.443905\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120950; batch adversarial loss: 0.466252\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083193; batch adversarial loss: 0.430691\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056946; batch adversarial loss: 0.514038\n",
      "epoch 84; iter: 0; batch classifier loss: 0.125153; batch adversarial loss: 0.414024\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064073; batch adversarial loss: 0.509417\n",
      "epoch 86; iter: 0; batch classifier loss: 0.125886; batch adversarial loss: 0.526712\n",
      "epoch 87; iter: 0; batch classifier loss: 0.087342; batch adversarial loss: 0.466829\n",
      "epoch 88; iter: 0; batch classifier loss: 0.081198; batch adversarial loss: 0.404305\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057209; batch adversarial loss: 0.487519\n",
      "epoch 90; iter: 0; batch classifier loss: 0.095310; batch adversarial loss: 0.445966\n",
      "epoch 91; iter: 0; batch classifier loss: 0.072179; batch adversarial loss: 0.498415\n",
      "epoch 92; iter: 0; batch classifier loss: 0.100228; batch adversarial loss: 0.462121\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067928; batch adversarial loss: 0.409984\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061883; batch adversarial loss: 0.467246\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042614; batch adversarial loss: 0.427572\n",
      "epoch 96; iter: 0; batch classifier loss: 0.031831; batch adversarial loss: 0.529936\n",
      "epoch 97; iter: 0; batch classifier loss: 0.045611; batch adversarial loss: 0.425519\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051873; batch adversarial loss: 0.431556\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058622; batch adversarial loss: 0.470408\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059470; batch adversarial loss: 0.498120\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057786; batch adversarial loss: 0.445921\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037809; batch adversarial loss: 0.459735\n",
      "epoch 103; iter: 0; batch classifier loss: 0.070417; batch adversarial loss: 0.366264\n",
      "epoch 104; iter: 0; batch classifier loss: 0.055101; batch adversarial loss: 0.464850\n",
      "epoch 105; iter: 0; batch classifier loss: 0.033005; batch adversarial loss: 0.414784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.060007; batch adversarial loss: 0.548035\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046166; batch adversarial loss: 0.453543\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041056; batch adversarial loss: 0.470654\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033853; batch adversarial loss: 0.474501\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046023; batch adversarial loss: 0.391031\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061408; batch adversarial loss: 0.451438\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042811; batch adversarial loss: 0.494443\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027738; batch adversarial loss: 0.523455\n",
      "epoch 114; iter: 0; batch classifier loss: 0.019006; batch adversarial loss: 0.393450\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024393; batch adversarial loss: 0.516544\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037491; batch adversarial loss: 0.563237\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040432; batch adversarial loss: 0.479477\n",
      "epoch 118; iter: 0; batch classifier loss: 0.067682; batch adversarial loss: 0.425436\n",
      "epoch 119; iter: 0; batch classifier loss: 0.019962; batch adversarial loss: 0.478356\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042106; batch adversarial loss: 0.461204\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032389; batch adversarial loss: 0.292603\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034697; batch adversarial loss: 0.425814\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019606; batch adversarial loss: 0.475685\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022999; batch adversarial loss: 0.448431\n",
      "epoch 125; iter: 0; batch classifier loss: 0.007917; batch adversarial loss: 0.462400\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050508; batch adversarial loss: 0.335460\n",
      "epoch 127; iter: 0; batch classifier loss: 0.013657; batch adversarial loss: 0.481902\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021573; batch adversarial loss: 0.554854\n",
      "epoch 129; iter: 0; batch classifier loss: 0.010380; batch adversarial loss: 0.495321\n",
      "epoch 130; iter: 0; batch classifier loss: 0.010945; batch adversarial loss: 0.513912\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033361; batch adversarial loss: 0.471996\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019498; batch adversarial loss: 0.414350\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041400; batch adversarial loss: 0.469740\n",
      "epoch 134; iter: 0; batch classifier loss: 0.011102; batch adversarial loss: 0.417450\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025930; batch adversarial loss: 0.443472\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031529; batch adversarial loss: 0.444980\n",
      "epoch 137; iter: 0; batch classifier loss: 0.011342; batch adversarial loss: 0.537392\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027178; batch adversarial loss: 0.533855\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030361; batch adversarial loss: 0.470716\n",
      "epoch 140; iter: 0; batch classifier loss: 0.011257; batch adversarial loss: 0.433299\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032037; batch adversarial loss: 0.470548\n",
      "epoch 142; iter: 0; batch classifier loss: 0.011446; batch adversarial loss: 0.379498\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018629; batch adversarial loss: 0.382883\n",
      "epoch 144; iter: 0; batch classifier loss: 0.053402; batch adversarial loss: 0.382032\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046158; batch adversarial loss: 0.516174\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019901; batch adversarial loss: 0.542282\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019890; batch adversarial loss: 0.480830\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024756; batch adversarial loss: 0.456895\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030725; batch adversarial loss: 0.513941\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018102; batch adversarial loss: 0.465090\n",
      "epoch 151; iter: 0; batch classifier loss: 0.007646; batch adversarial loss: 0.502239\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044858; batch adversarial loss: 0.551793\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012871; batch adversarial loss: 0.387806\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031046; batch adversarial loss: 0.408233\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012708; batch adversarial loss: 0.442274\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045156; batch adversarial loss: 0.565681\n",
      "epoch 157; iter: 0; batch classifier loss: 0.008822; batch adversarial loss: 0.409362\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020784; batch adversarial loss: 0.427361\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022770; batch adversarial loss: 0.429333\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015978; batch adversarial loss: 0.439717\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012822; batch adversarial loss: 0.416872\n",
      "epoch 162; iter: 0; batch classifier loss: 0.008970; batch adversarial loss: 0.468171\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017227; batch adversarial loss: 0.547860\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027952; batch adversarial loss: 0.568378\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009630; batch adversarial loss: 0.367774\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017483; batch adversarial loss: 0.412343\n",
      "epoch 167; iter: 0; batch classifier loss: 0.004475; batch adversarial loss: 0.474677\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022221; batch adversarial loss: 0.420148\n",
      "epoch 169; iter: 0; batch classifier loss: 0.041701; batch adversarial loss: 0.512982\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017824; batch adversarial loss: 0.464730\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022824; batch adversarial loss: 0.452562\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031190; batch adversarial loss: 0.437046\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010321; batch adversarial loss: 0.447460\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013709; batch adversarial loss: 0.469888\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013814; batch adversarial loss: 0.439715\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018683; batch adversarial loss: 0.463094\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014029; batch adversarial loss: 0.481739\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015442; batch adversarial loss: 0.460700\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008664; batch adversarial loss: 0.496189\n",
      "epoch 180; iter: 0; batch classifier loss: 0.055081; batch adversarial loss: 0.489670\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008375; batch adversarial loss: 0.522196\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015284; batch adversarial loss: 0.395303\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019869; batch adversarial loss: 0.465892\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015923; batch adversarial loss: 0.382453\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028789; batch adversarial loss: 0.528288\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008192; batch adversarial loss: 0.424665\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015564; batch adversarial loss: 0.466948\n",
      "epoch 188; iter: 0; batch classifier loss: 0.003907; batch adversarial loss: 0.455713\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014466; batch adversarial loss: 0.437757\n",
      "epoch 190; iter: 0; batch classifier loss: 0.001979; batch adversarial loss: 0.494193\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009803; batch adversarial loss: 0.404687\n",
      "epoch 192; iter: 0; batch classifier loss: 0.003778; batch adversarial loss: 0.484398\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028696; batch adversarial loss: 0.456756\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026058; batch adversarial loss: 0.441168\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012400; batch adversarial loss: 0.493323\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009568; batch adversarial loss: 0.483037\n",
      "epoch 197; iter: 0; batch classifier loss: 0.047328; batch adversarial loss: 0.437812\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029077; batch adversarial loss: 0.469465\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005003; batch adversarial loss: 0.432699\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671746; batch adversarial loss: 0.589738\n",
      "epoch 1; iter: 0; batch classifier loss: 0.474788; batch adversarial loss: 0.616781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.390735; batch adversarial loss: 0.602832\n",
      "epoch 3; iter: 0; batch classifier loss: 0.401106; batch adversarial loss: 0.627377\n",
      "epoch 4; iter: 0; batch classifier loss: 0.377917; batch adversarial loss: 0.570172\n",
      "epoch 5; iter: 0; batch classifier loss: 0.295706; batch adversarial loss: 0.573633\n",
      "epoch 6; iter: 0; batch classifier loss: 0.445659; batch adversarial loss: 0.590615\n",
      "epoch 7; iter: 0; batch classifier loss: 0.383906; batch adversarial loss: 0.597184\n",
      "epoch 8; iter: 0; batch classifier loss: 0.338368; batch adversarial loss: 0.526856\n",
      "epoch 9; iter: 0; batch classifier loss: 0.297256; batch adversarial loss: 0.579419\n",
      "epoch 10; iter: 0; batch classifier loss: 0.438275; batch adversarial loss: 0.519245\n",
      "epoch 11; iter: 0; batch classifier loss: 0.450512; batch adversarial loss: 0.624756\n",
      "epoch 12; iter: 0; batch classifier loss: 0.619983; batch adversarial loss: 0.555809\n",
      "epoch 13; iter: 0; batch classifier loss: 0.510903; batch adversarial loss: 0.506226\n",
      "epoch 14; iter: 0; batch classifier loss: 0.373304; batch adversarial loss: 0.499812\n",
      "epoch 15; iter: 0; batch classifier loss: 0.336405; batch adversarial loss: 0.489391\n",
      "epoch 16; iter: 0; batch classifier loss: 0.300628; batch adversarial loss: 0.501573\n",
      "epoch 17; iter: 0; batch classifier loss: 0.292937; batch adversarial loss: 0.483455\n",
      "epoch 18; iter: 0; batch classifier loss: 0.278887; batch adversarial loss: 0.504407\n",
      "epoch 19; iter: 0; batch classifier loss: 0.142839; batch adversarial loss: 0.435342\n",
      "epoch 20; iter: 0; batch classifier loss: 0.249734; batch adversarial loss: 0.546863\n",
      "epoch 21; iter: 0; batch classifier loss: 0.205027; batch adversarial loss: 0.475650\n",
      "epoch 22; iter: 0; batch classifier loss: 0.216766; batch adversarial loss: 0.470028\n",
      "epoch 23; iter: 0; batch classifier loss: 0.206136; batch adversarial loss: 0.433116\n",
      "epoch 24; iter: 0; batch classifier loss: 0.225645; batch adversarial loss: 0.483291\n",
      "epoch 25; iter: 0; batch classifier loss: 0.216062; batch adversarial loss: 0.383743\n",
      "epoch 26; iter: 0; batch classifier loss: 0.230683; batch adversarial loss: 0.520721\n",
      "epoch 27; iter: 0; batch classifier loss: 0.211667; batch adversarial loss: 0.434963\n",
      "epoch 28; iter: 0; batch classifier loss: 0.151212; batch adversarial loss: 0.519060\n",
      "epoch 29; iter: 0; batch classifier loss: 0.140978; batch adversarial loss: 0.467813\n",
      "epoch 30; iter: 0; batch classifier loss: 0.133188; batch adversarial loss: 0.487145\n",
      "epoch 31; iter: 0; batch classifier loss: 0.199718; batch adversarial loss: 0.462254\n",
      "epoch 32; iter: 0; batch classifier loss: 0.189213; batch adversarial loss: 0.391481\n",
      "epoch 33; iter: 0; batch classifier loss: 0.209354; batch adversarial loss: 0.472877\n",
      "epoch 34; iter: 0; batch classifier loss: 0.159144; batch adversarial loss: 0.469565\n",
      "epoch 35; iter: 0; batch classifier loss: 0.162977; batch adversarial loss: 0.382917\n",
      "epoch 36; iter: 0; batch classifier loss: 0.156530; batch adversarial loss: 0.491384\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166170; batch adversarial loss: 0.571650\n",
      "epoch 38; iter: 0; batch classifier loss: 0.228999; batch adversarial loss: 0.354749\n",
      "epoch 39; iter: 0; batch classifier loss: 0.167648; batch adversarial loss: 0.470716\n",
      "epoch 40; iter: 0; batch classifier loss: 0.156076; batch adversarial loss: 0.409953\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125394; batch adversarial loss: 0.414281\n",
      "epoch 42; iter: 0; batch classifier loss: 0.214449; batch adversarial loss: 0.470334\n",
      "epoch 43; iter: 0; batch classifier loss: 0.186282; batch adversarial loss: 0.471713\n",
      "epoch 44; iter: 0; batch classifier loss: 0.233999; batch adversarial loss: 0.444610\n",
      "epoch 45; iter: 0; batch classifier loss: 0.183128; batch adversarial loss: 0.519078\n",
      "epoch 46; iter: 0; batch classifier loss: 0.121989; batch adversarial loss: 0.408495\n",
      "epoch 47; iter: 0; batch classifier loss: 0.121080; batch adversarial loss: 0.562155\n",
      "epoch 48; iter: 0; batch classifier loss: 0.141675; batch adversarial loss: 0.493251\n",
      "epoch 49; iter: 0; batch classifier loss: 0.124525; batch adversarial loss: 0.503802\n",
      "epoch 50; iter: 0; batch classifier loss: 0.214813; batch adversarial loss: 0.458375\n",
      "epoch 51; iter: 0; batch classifier loss: 0.112977; batch adversarial loss: 0.498208\n",
      "epoch 52; iter: 0; batch classifier loss: 0.186934; batch adversarial loss: 0.434728\n",
      "epoch 53; iter: 0; batch classifier loss: 0.192597; batch adversarial loss: 0.493454\n",
      "epoch 54; iter: 0; batch classifier loss: 0.155628; batch adversarial loss: 0.494797\n",
      "epoch 55; iter: 0; batch classifier loss: 0.197472; batch adversarial loss: 0.459271\n",
      "epoch 56; iter: 0; batch classifier loss: 0.186598; batch adversarial loss: 0.540263\n",
      "epoch 57; iter: 0; batch classifier loss: 0.173605; batch adversarial loss: 0.437103\n",
      "epoch 58; iter: 0; batch classifier loss: 0.179573; batch adversarial loss: 0.461316\n",
      "epoch 59; iter: 0; batch classifier loss: 0.223825; batch adversarial loss: 0.450911\n",
      "epoch 60; iter: 0; batch classifier loss: 0.203058; batch adversarial loss: 0.448642\n",
      "epoch 61; iter: 0; batch classifier loss: 0.163429; batch adversarial loss: 0.446690\n",
      "epoch 62; iter: 0; batch classifier loss: 0.189569; batch adversarial loss: 0.481671\n",
      "epoch 63; iter: 0; batch classifier loss: 0.217551; batch adversarial loss: 0.565988\n",
      "epoch 64; iter: 0; batch classifier loss: 0.167938; batch adversarial loss: 0.494995\n",
      "epoch 65; iter: 0; batch classifier loss: 0.253234; batch adversarial loss: 0.434808\n",
      "epoch 66; iter: 0; batch classifier loss: 0.151099; batch adversarial loss: 0.446942\n",
      "epoch 67; iter: 0; batch classifier loss: 0.176716; batch adversarial loss: 0.519045\n",
      "epoch 68; iter: 0; batch classifier loss: 0.197942; batch adversarial loss: 0.411180\n",
      "epoch 69; iter: 0; batch classifier loss: 0.135307; batch adversarial loss: 0.494796\n",
      "epoch 70; iter: 0; batch classifier loss: 0.113894; batch adversarial loss: 0.445666\n",
      "epoch 71; iter: 0; batch classifier loss: 0.150791; batch adversarial loss: 0.470552\n",
      "epoch 72; iter: 0; batch classifier loss: 0.192774; batch adversarial loss: 0.458585\n",
      "epoch 73; iter: 0; batch classifier loss: 0.142373; batch adversarial loss: 0.436140\n",
      "epoch 74; iter: 0; batch classifier loss: 0.162253; batch adversarial loss: 0.567615\n",
      "epoch 75; iter: 0; batch classifier loss: 0.170402; batch adversarial loss: 0.411433\n",
      "epoch 76; iter: 0; batch classifier loss: 0.211095; batch adversarial loss: 0.506945\n",
      "epoch 77; iter: 0; batch classifier loss: 0.248411; batch adversarial loss: 0.458905\n",
      "epoch 78; iter: 0; batch classifier loss: 0.274059; batch adversarial loss: 0.410454\n",
      "epoch 79; iter: 0; batch classifier loss: 0.154805; batch adversarial loss: 0.410370\n",
      "epoch 80; iter: 0; batch classifier loss: 0.203501; batch adversarial loss: 0.387385\n",
      "epoch 81; iter: 0; batch classifier loss: 0.217017; batch adversarial loss: 0.362049\n",
      "epoch 82; iter: 0; batch classifier loss: 0.149555; batch adversarial loss: 0.493611\n",
      "epoch 83; iter: 0; batch classifier loss: 0.198946; batch adversarial loss: 0.446115\n",
      "epoch 84; iter: 0; batch classifier loss: 0.216716; batch adversarial loss: 0.531610\n",
      "epoch 85; iter: 0; batch classifier loss: 0.222541; batch adversarial loss: 0.398751\n",
      "epoch 86; iter: 0; batch classifier loss: 0.226418; batch adversarial loss: 0.422902\n",
      "epoch 87; iter: 0; batch classifier loss: 0.125929; batch adversarial loss: 0.542960\n",
      "epoch 88; iter: 0; batch classifier loss: 0.144048; batch adversarial loss: 0.509468\n",
      "epoch 89; iter: 0; batch classifier loss: 0.147301; batch adversarial loss: 0.458188\n",
      "epoch 90; iter: 0; batch classifier loss: 0.145965; batch adversarial loss: 0.604126\n",
      "epoch 91; iter: 0; batch classifier loss: 0.180949; batch adversarial loss: 0.519586\n",
      "epoch 92; iter: 0; batch classifier loss: 0.224406; batch adversarial loss: 0.495014\n",
      "epoch 93; iter: 0; batch classifier loss: 0.181328; batch adversarial loss: 0.483082\n",
      "epoch 94; iter: 0; batch classifier loss: 0.169185; batch adversarial loss: 0.458311\n",
      "epoch 95; iter: 0; batch classifier loss: 0.171630; batch adversarial loss: 0.422004\n",
      "epoch 96; iter: 0; batch classifier loss: 0.184978; batch adversarial loss: 0.410571\n",
      "epoch 97; iter: 0; batch classifier loss: 0.200850; batch adversarial loss: 0.494903\n",
      "epoch 98; iter: 0; batch classifier loss: 0.130862; batch adversarial loss: 0.326612\n",
      "epoch 99; iter: 0; batch classifier loss: 0.200547; batch adversarial loss: 0.482512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.108578; batch adversarial loss: 0.482339\n",
      "epoch 101; iter: 0; batch classifier loss: 0.148024; batch adversarial loss: 0.520084\n",
      "epoch 102; iter: 0; batch classifier loss: 0.194698; batch adversarial loss: 0.482856\n",
      "epoch 103; iter: 0; batch classifier loss: 0.153395; batch adversarial loss: 0.448347\n",
      "epoch 104; iter: 0; batch classifier loss: 0.181356; batch adversarial loss: 0.494742\n",
      "epoch 105; iter: 0; batch classifier loss: 0.226948; batch adversarial loss: 0.374329\n",
      "epoch 106; iter: 0; batch classifier loss: 0.213855; batch adversarial loss: 0.458820\n",
      "epoch 107; iter: 0; batch classifier loss: 0.149472; batch adversarial loss: 0.399089\n",
      "epoch 108; iter: 0; batch classifier loss: 0.131390; batch adversarial loss: 0.410865\n",
      "epoch 109; iter: 0; batch classifier loss: 0.127375; batch adversarial loss: 0.447016\n",
      "epoch 110; iter: 0; batch classifier loss: 0.269096; batch adversarial loss: 0.459139\n",
      "epoch 111; iter: 0; batch classifier loss: 0.157890; batch adversarial loss: 0.434661\n",
      "epoch 112; iter: 0; batch classifier loss: 0.196919; batch adversarial loss: 0.495550\n",
      "epoch 113; iter: 0; batch classifier loss: 0.160479; batch adversarial loss: 0.410420\n",
      "epoch 114; iter: 0; batch classifier loss: 0.144641; batch adversarial loss: 0.433681\n",
      "epoch 115; iter: 0; batch classifier loss: 0.156901; batch adversarial loss: 0.434319\n",
      "epoch 116; iter: 0; batch classifier loss: 0.130784; batch adversarial loss: 0.433170\n",
      "epoch 117; iter: 0; batch classifier loss: 0.146369; batch adversarial loss: 0.423469\n",
      "epoch 118; iter: 0; batch classifier loss: 0.127018; batch adversarial loss: 0.495551\n",
      "epoch 119; iter: 0; batch classifier loss: 0.100123; batch adversarial loss: 0.495158\n",
      "epoch 120; iter: 0; batch classifier loss: 0.156200; batch adversarial loss: 0.518419\n",
      "epoch 121; iter: 0; batch classifier loss: 0.143011; batch adversarial loss: 0.458691\n",
      "epoch 122; iter: 0; batch classifier loss: 0.182545; batch adversarial loss: 0.471768\n",
      "epoch 123; iter: 0; batch classifier loss: 0.147090; batch adversarial loss: 0.422862\n",
      "epoch 124; iter: 0; batch classifier loss: 0.135152; batch adversarial loss: 0.448750\n",
      "epoch 125; iter: 0; batch classifier loss: 0.153397; batch adversarial loss: 0.529299\n",
      "epoch 126; iter: 0; batch classifier loss: 0.175273; batch adversarial loss: 0.519070\n",
      "epoch 127; iter: 0; batch classifier loss: 0.122320; batch adversarial loss: 0.434030\n",
      "epoch 128; iter: 0; batch classifier loss: 0.121389; batch adversarial loss: 0.408422\n",
      "epoch 129; iter: 0; batch classifier loss: 0.123870; batch adversarial loss: 0.371528\n",
      "epoch 130; iter: 0; batch classifier loss: 0.113273; batch adversarial loss: 0.465206\n",
      "epoch 131; iter: 0; batch classifier loss: 0.086080; batch adversarial loss: 0.458451\n",
      "epoch 132; iter: 0; batch classifier loss: 0.067814; batch adversarial loss: 0.470736\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042987; batch adversarial loss: 0.543109\n",
      "epoch 134; iter: 0; batch classifier loss: 0.070423; batch adversarial loss: 0.494198\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018312; batch adversarial loss: 0.432251\n",
      "epoch 136; iter: 0; batch classifier loss: 0.048634; batch adversarial loss: 0.420000\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054616; batch adversarial loss: 0.462107\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018939; batch adversarial loss: 0.590948\n",
      "epoch 139; iter: 0; batch classifier loss: 0.064333; batch adversarial loss: 0.423179\n",
      "epoch 140; iter: 0; batch classifier loss: 0.089024; batch adversarial loss: 0.403951\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036405; batch adversarial loss: 0.510176\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048111; batch adversarial loss: 0.410073\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026762; batch adversarial loss: 0.449875\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020370; batch adversarial loss: 0.433139\n",
      "epoch 145; iter: 0; batch classifier loss: 0.047499; batch adversarial loss: 0.444841\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022999; batch adversarial loss: 0.480269\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018950; batch adversarial loss: 0.507390\n",
      "epoch 148; iter: 0; batch classifier loss: 0.056620; batch adversarial loss: 0.363353\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028621; batch adversarial loss: 0.413677\n",
      "epoch 150; iter: 0; batch classifier loss: 0.062077; batch adversarial loss: 0.424734\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036339; batch adversarial loss: 0.499038\n",
      "epoch 152; iter: 0; batch classifier loss: 0.043068; batch adversarial loss: 0.439549\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021171; batch adversarial loss: 0.467020\n",
      "epoch 154; iter: 0; batch classifier loss: 0.058375; batch adversarial loss: 0.472648\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018267; batch adversarial loss: 0.495793\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035007; batch adversarial loss: 0.474580\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012847; batch adversarial loss: 0.494544\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042522; batch adversarial loss: 0.447010\n",
      "epoch 159; iter: 0; batch classifier loss: 0.042385; batch adversarial loss: 0.491609\n",
      "epoch 160; iter: 0; batch classifier loss: 0.055032; batch adversarial loss: 0.437365\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033416; batch adversarial loss: 0.449214\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029271; batch adversarial loss: 0.435002\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034424; batch adversarial loss: 0.522811\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014712; batch adversarial loss: 0.452689\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038967; batch adversarial loss: 0.427689\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019751; batch adversarial loss: 0.559020\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019305; batch adversarial loss: 0.397986\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023380; batch adversarial loss: 0.396299\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015546; batch adversarial loss: 0.458305\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029545; batch adversarial loss: 0.427052\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015420; batch adversarial loss: 0.497687\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017767; batch adversarial loss: 0.447613\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015618; batch adversarial loss: 0.395845\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021597; batch adversarial loss: 0.422175\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012154; batch adversarial loss: 0.357737\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013989; batch adversarial loss: 0.488711\n",
      "epoch 177; iter: 0; batch classifier loss: 0.007496; batch adversarial loss: 0.467007\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019045; batch adversarial loss: 0.422393\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012206; batch adversarial loss: 0.515234\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012843; batch adversarial loss: 0.478769\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018891; batch adversarial loss: 0.441670\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042888; batch adversarial loss: 0.444925\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015393; batch adversarial loss: 0.470003\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004823; batch adversarial loss: 0.502743\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023248; batch adversarial loss: 0.467117\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008588; batch adversarial loss: 0.514403\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022490; batch adversarial loss: 0.383914\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018238; batch adversarial loss: 0.380155\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015182; batch adversarial loss: 0.407386\n",
      "epoch 190; iter: 0; batch classifier loss: 0.053278; batch adversarial loss: 0.410027\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025338; batch adversarial loss: 0.572439\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028417; batch adversarial loss: 0.433255\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020057; batch adversarial loss: 0.411658\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012578; batch adversarial loss: 0.394070\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012211; batch adversarial loss: 0.420520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.009850; batch adversarial loss: 0.422947\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009087; batch adversarial loss: 0.476352\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038829; batch adversarial loss: 0.473622\n",
      "epoch 199; iter: 0; batch classifier loss: 0.036507; batch adversarial loss: 0.537723\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529bdf4e",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e910a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "172f9427",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:16.632770Z",
     "start_time": "2024-01-04T20:53:16.629083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 600,\n",
      " 'experiment_iteration': 'Exp_iter_6',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 600,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2670abffe30e4a388a7a09306feb6673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 600, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f28080438649c0aa4a0f71f4b322c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511b20dacfe5420981d3cf173f60fc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a989d937f483784b5138783479302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c5fe28a14a47118da3a7d485a77e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed0cf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
